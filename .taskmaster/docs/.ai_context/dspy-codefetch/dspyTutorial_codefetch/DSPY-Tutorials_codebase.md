Project Structure:
├── agents
│   ├── index.ipynb
│   └── mlflow-tracing-agent.png
├── ai_text_game
│   └── index.md
├── async
│   └── index.md
├── audio
│   └── index.ipynb
├── build_ai_program
│   └── index.md
├── cache
│   └── index.md
├── classification
│   └── index.md
├── classification_finetuning
│   ├── index.ipynb
│   └── mlflow-tracing-classification.png
├── conversation_history
│   └── index.md
├── core_development
│   └── index.md
├── custom_module
│   ├── index.ipynb
│   └── mlflow-tracing-custom-module.png
├── customer_service_agent
│   ├── index.ipynb
│   └── mlflow-tracing-customer-service-agent.png
├── deployment
│   ├── dspy_mlflow_ui.png
│   └── index.md
├── email_extraction
│   ├── index.md
│   └── mlflow-tracing-email-extraction.png
├── entity_extraction
│   ├── index.ipynb
│   └── mlflow-tracing-entity-extraction.png
├── games
│   ├── index.ipynb
│   └── mlflow-tracing-agent.png
├── gepa_ai_program
│   └── index.md
├── gepa_aime
│   ├── index.ipynb
│   ├── mlflow-tracing-gepa-aime.png
│   └── mlflow-tracking-gepa-aime-optimization.png
├── gepa_facilitysupportanalyzer
│   ├── index.ipynb
│   ├── mlflow-tracing-gepa-support.png
│   └── mlflow-tracking-gepa-support-optimization.png
├── gepa_papillon
│   ├── index.ipynb
│   ├── mlflow-tracing-gepa-papilon.png
│   └── mlflow-tracking-gepa-papilon-optimization.png
├── image_generation_prompting
│   └── index.ipynb
├── index.md
├── llms_txt_generation
│   └── index.md
├── math
│   ├── index.ipynb
│   └── mlflow-tracing-math.png
├── mcp
│   └── index.md
├── mem0_react_agent
│   └── index.md
├── multihop_search
│   ├── index.ipynb
│   └── mlflow-tracing-multi-hop.png
├── observability
│   ├── index.md
│   ├── mlflow_trace_ui.png
│   ├── mlflow_trace_ui_navigation.gif
│   └── mlflow_trace_view.png
├── optimize_ai_program
│   └── index.md
├── optimizer_tracking
│   ├── child_run.png
│   ├── experiment.png
│   ├── index.md
│   └── parent_run.png
├── output_refinement
│   └── best-of-n-and-refine.md
├── papillon
│   └── index.md
├── program_of_thought
│   └── index.ipynb
├── rag
│   ├── index.ipynb
│   └── mlflow-tracing-rag.png
├── real_world_examples
│   └── index.md
├── rl_ai_program
│   └── index.md
├── rl_multihop
│   └── index.ipynb
├── rl_papillon
│   └── index.ipynb
├── sample_code_generation
│   └── index.md
├── saving
│   └── index.md
├── streaming
│   └── index.md
├── tool_use
│   └── index.ipynb
└── yahoo_finance_react
    └── index.md


index.md
```
1 | Welcome to DSPy tutorials! We've organized our tutorials into three main categories to help you get started:
2 |
3 | - **Build AI Programs with DSPy**: These hands-on tutorials guide you through building production-ready AI
4 |   applications. From implementing RAG systems to creating intelligent agents, each tutorial demonstrates
5 |   practical use cases. You'll also learn how to leverage DSPy optimizers to enhance your program's performance.
6 |
7 | - **Optimize AI Programs with DSPy Optimizers**: These tutorials deep dive into DSPy's optimization capabilities. While
8 |   lighter on programming concepts, they focus on how to systematically improve your AI programs using DSPy
9 |   optimizers, and showcase how DSPy optimizers help improve the quality automatically.
10 |
11 | - **DSPy Core Development**: These tutorials cover essential DSPy features and best practices. Learn how to implement
12 |   key functionalities like streaming, caching, deployment, and monitoring in your DSPy applications.
13 |
14 |
15 | - Build AI Programs with DSPy
16 |     - [Managing Conversation History](conversation_history/index.md)
17 |     - [Building AI Agents with DSPy](customer_service_agent/index.ipynb)
18 |     - [Building AI Applications by Customizing DSPy Modules](custom_module/index.ipynb)
19 |     - [Retrieval-Augmented Generation (RAG)](rag/index.ipynb)
20 |     - [Building RAG as Agent](agents/index.ipynb)
21 |     - [Entity Extraction](entity_extraction/index.ipynb)
22 |     - [Classification](classification/index.md)
23 |     - [Multi-Hop RAG](multihop_search/index.ipynb)
24 |     - [Privacy-Conscious Delegation](papillon/index.md)
25 |     - [Program Of Thought](program_of_thought/index.ipynb)
26 |     - [Image Generation Prompt iteration](image_generation_prompting/index.ipynb)
27 |     - [Audio](audio/index.ipynb)
28 |
29 |
30 | - Optimize AI Programs with DSPy
31 |     - [Math Reasoning](math/index.ipynb)
32 |     - [Classification Finetuning](classification_finetuning/index.ipynb)
33 |     - [Advanced Tool Use](tool_use/index.ipynb)
34 |     - [Finetuning Agents](games/index.ipynb)
35 |
36 |
37 | - Reflective Prompt Evolution with dspy.GEPA:
38 |     - [Overview](gepa_ai_program/index.md)
39 |     - [GEPA for AIME](gepa_aime/index.ipynb)
40 |     - [GEPA for PAPILLON](gepa_papillon/index.ipynb)
41 |     - [GEPA for Enterprise classification task](gepa_facilitysupportanalyzer/index.ipynb)
42 |
43 |
44 | - Tools, Development, and Deployment
45 |     - [Use MCP in DSPy](mcp/index.md)
46 |     - [Output Refinement](output_refinement/best-of-n-and-refine.md)
47 |     - [Saving and Loading](saving/index.md)
48 |     - [Cache](cache/index.md)
49 |     - [Deployment](deployment/index.md)
50 |     - [Debugging & Observability](observability/index.md)
51 |     - [Tracking DSPy Optimizers](optimizer_tracking/index.md)
52 |     - [Streaming](streaming/index.md)
53 |     - [Async](async/index.md)
54 |
55 |
```

agents/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: Agents\n",
8 |     "\n",
9 |     "Let's walk through a quick example of setting up a `dspy.ReAct` agent with a couple of tools and optimizing it to conduct advanced browsing for multi-hop search.\n",
10 |     "\n",
11 |     "Install the latest DSPy via `pip install -U dspy` and follow along. You also need to run `pip install datasets`.\n",
12 |     "\n",
13 |     "<details>\n",
14 |     "<summary>Recommended: Set up MLflow Tracing to understand what's happening under the hood.</summary>\n",
15 |     "\n",
16 |     "### MLflow DSPy Integration\n",
17 |     "\n",
18 |     "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. In this tutorial, you can use MLflow to visualize prompts and optimization progress as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
19 |     "\n",
20 |     "![MLflow Trace](./mlflow-tracing-agent.png)\n",
21 |     "\n",
22 |     "1. Install MLflow\n",
23 |     "\n",
24 |     "```bash\n",
25 |     "%pip install mlflow>=2.20\n",
26 |     "```\n",
27 |     "\n",
28 |     "2. Start MLflow UI in a separate terminal\n",
29 |     "```bash\n",
30 |     "mlflow ui --port 5000\n",
31 |     "```\n",
32 |     "\n",
33 |     "3. Connect the notebook to MLflow\n",
34 |     "```python\n",
35 |     "import mlflow\n",
36 |     "\n",
37 |     "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
38 |     "mlflow.set_experiment(\"DSPy\")\n",
39 |     "```\n",
40 |     "\n",
41 |     "4. Enabling tracing.\n",
42 |     "```python\n",
43 |     "mlflow.dspy.autolog()\n",
44 |     "```\n",
45 |     "\n",
46 |     "Once you have completed the steps above, you can see traces for each program execution on the notebook. They provide great visibility into the model's behavior and helps you understand the DSPy's concepts better throughout the tutorial.\n",
47 |     "\n",
48 |     "To kearn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
49 |     "\n",
50 |     "</details>"
51 |    ]
52 |   },
53 |   {
54 |    "cell_type": "markdown",
55 |    "metadata": {},
56 |    "source": [
57 |     "In this tutorial, we'll use an extremely small LM, Meta's `Llama-3.2-3B-Instruct` which has 3 billion parameters.\n",
58 |     "\n",
59 |     "A model like this is not very reliable out of the box for long or complex agent loops. However, it's extremely fast and cheap to host, as it needs very little RAM.\n",
60 |     "\n",
61 |     "You might be able to host the 3B model on your laptop with Ollama, on your GPU server with SGLang, or via a provider that hosts it for you like Databricks or Together.\n",
62 |     "\n",
63 |     "In the snippet below, we'll configure our main LM as `Llama-3.2-3B`. We'll also set up a larger LM, i.e. `GPT-4o`, as a teacher that we'll invoke a very small number of times to help teach the small LM."
64 |    ]
65 |   },
66 |   {
67 |    "cell_type": "code",
68 |    "execution_count": 1,
69 |    "metadata": {},
70 |    "outputs": [],
71 |    "source": [
72 |     "import dspy\n",
73 |     "\n",
74 |     "llama3b = dspy.LM('<provider>/Llama-3.2-3B-Instruct', temperature=0.7)\n",
75 |     "gpt4o = dspy.LM('openai/gpt-4o', temperature=0.7)\n",
76 |     "\n",
77 |     "dspy.configure(lm=llama3b)"
78 |    ]
79 |   },
80 |   {
81 |    "cell_type": "markdown",
82 |    "metadata": {},
83 |    "source": [
84 |     "Let's load a dataset for our task. We'll load examples from the HoVer multi-hop task, where the input is a (really!) complex claim and the output we're seeking is the set of Wikipedia pages that are required to fact-check that claim."
85 |    ]
86 |   },
87 |   {
88 |    "cell_type": "code",
89 |    "execution_count": 2,
90 |    "metadata": {},
91 |    "outputs": [],
92 |    "source": [
93 |     "import random\n",
94 |     "from dspy.datasets import DataLoader\n",
95 |     "\n",
96 |     "kwargs = dict(fields=(\"claim\", \"supporting_facts\", \"hpqa_id\", \"num_hops\"), input_keys=(\"claim\",))\n",
97 |     "hover = DataLoader().from_huggingface(dataset_name=\"hover-nlp/hover\", split=\"train\", trust_remote_code=True, **kwargs)\n",
98 |     "\n",
99 |     "hpqa_ids = set()\n",
100 |     "hover = [\n",
101 |     "    dspy.Example(claim=x.claim, titles=list(set([y[\"key\"] for y in x.supporting_facts]))).with_inputs(\"claim\")\n",
102 |     "    for x in hover\n",
103 |     "    if x[\"num_hops\"] == 3 and x[\"hpqa_id\"] not in hpqa_ids and not hpqa_ids.add(x[\"hpqa_id\"])\n",
104 |     "]\n",
105 |     "\n",
106 |     "random.Random(0).shuffle(hover)\n",
107 |     "trainset, devset, testset = hover[:100], hover[100:200], hover[650:]"
108 |    ]
109 |   },
110 |   {
111 |    "cell_type": "markdown",
112 |    "metadata": {},
113 |    "source": [
114 |     "Let's view an example of this task:"
115 |    ]
116 |   },
117 |   {
118 |    "cell_type": "code",
119 |    "execution_count": 3,
120 |    "metadata": {},
121 |    "outputs": [
122 |     {
123 |      "name": "stdout",
124 |      "output_type": "stream",
125 |      "text": [
126 |       "Claim: This director is known for his work on Miss Potter. The Academy of Motion Picture Arts and Sciences presents the award in which he was nominated for his work in \"Babe\".\n",
127 |       "Pages that must be retrieved: ['Miss Potter', 'Chris Noonan', 'Academy Award for Best Director']\n"
128 |      ]
129 |     }
130 |    ],
131 |    "source": [
132 |     "example = trainset[0]\n",
133 |     "\n",
134 |     "print(\"Claim:\", example.claim)\n",
135 |     "print(\"Pages that must be retrieved:\", example.titles)"
136 |    ]
137 |   },
138 |   {
139 |    "cell_type": "markdown",
140 |    "metadata": {},
141 |    "source": [
142 |     "Now, let's define a function to do the search in Wikipedia. We'll rely on a ColBERTv2 server that can search the \"abstracts\" (i.e., first paragraphs) of every article that existed in Wikipedia in 2017, which is the data used in HoVer."
143 |    ]
144 |   },
145 |   {
146 |    "cell_type": "code",
147 |    "execution_count": 4,
148 |    "metadata": {},
149 |    "outputs": [],
150 |    "source": [
151 |     "DOCS = {}\n",
152 |     "\n",
153 |     "def search(query: str, k: int) -> list[str]:\n",
154 |     "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=k)\n",
155 |     "    results = [x['text'] for x in results]\n",
156 |     "\n",
157 |     "    for result in results:\n",
158 |     "        title, text = result.split(\" | \", 1)\n",
159 |     "        DOCS[title] = text\n",
160 |     "\n",
161 |     "    return results"
162 |    ]
163 |   },
164 |   {
165 |    "cell_type": "markdown",
166 |    "metadata": {},
167 |    "source": [
168 |     "Now, let's use the `search` function to define two tools for our ReAct agent:"
169 |    ]
170 |   },
171 |   {
172 |    "cell_type": "code",
173 |    "execution_count": 5,
174 |    "metadata": {},
175 |    "outputs": [],
176 |    "source": [
177 |     "def search_wikipedia(query: str) -> list[str]:\n",
178 |     "    \"\"\"Returns top-5 results and then the titles of the top-5 to top-30 results.\"\"\"\n",
179 |     "\n",
180 |     "    topK = search(query, 30)\n",
181 |     "    titles, topK = [f\"`{x.split(' | ')[0]}`\" for x in topK[5:30]], topK[:5]\n",
182 |     "    return topK + [f\"Other retrieved pages have titles: {', '.join(titles)}.\"]\n",
183 |     "\n",
184 |     "def lookup_wikipedia(title: str) -> str:\n",
185 |     "    \"\"\"Returns the text of the Wikipedia page, if it exists.\"\"\"\n",
186 |     "\n",
187 |     "    if title in DOCS:\n",
188 |     "        return DOCS[title]\n",
189 |     "\n",
190 |     "    results = [x for x in search(title, 10) if x.startswith(title + \" | \")]\n",
191 |     "    if not results:\n",
192 |     "        return f\"No Wikipedia page found for title: {title}\"\n",
193 |     "    return results[0]"
194 |    ]
195 |   },
196 |   {
197 |    "cell_type": "markdown",
198 |    "metadata": {},
199 |    "source": [
200 |     "Now, let's define the ReAct agent in DSPy. It's going to be super simple: it'll take a `claim` and produce a list `titles: list[str]`.\n",
201 |     "\n",
202 |     "We'll instruct it to find all Wikipedia titles that are needed to fact-check the claim."
203 |    ]
204 |   },
205 |   {
206 |    "cell_type": "code",
207 |    "execution_count": 6,
208 |    "metadata": {},
209 |    "outputs": [],
210 |    "source": [
211 |     "instructions = \"Find all Wikipedia titles relevant to verifying (or refuting) the claim.\"\n",
212 |     "signature = dspy.Signature(\"claim -> titles: list[str]\", instructions)\n",
213 |     "react = dspy.ReAct(signature, tools=[search_wikipedia, lookup_wikipedia], max_iters=20)"
214 |    ]
215 |   },
216 |   {
217 |    "cell_type": "markdown",
218 |    "metadata": {},
219 |    "source": [
220 |     "Let's try it with a really simple claim to see if our tiny 3B model can do it!"
221 |    ]
222 |   },
223 |   {
224 |    "cell_type": "code",
225 |    "execution_count": 7,
226 |    "metadata": {},
227 |    "outputs": [
228 |     {
229 |      "data": {
230 |       "text/plain": [
231 |        "['David Gregory (physician)', 'David A. Gregory', 'David Harry Gregory']"
232 |       ]
233 |      },
234 |      "execution_count": 8,
235 |      "metadata": {},
236 |      "output_type": "execute_result"
237 |     }
238 |    ],
239 |    "source": [
240 |     "react(claim=\"David Gregory was born in 1625.\").titles[:3]"
241 |    ]
242 |   },
243 |   {
244 |    "cell_type": "markdown",
245 |    "metadata": {},
246 |    "source": [
247 |     "Great. Now let's set up an evaluation metric, `top5_recall`.\n",
248 |     "\n",
249 |     "It will return the fraction of the gold pages (which are always 3) that are retrieved in the top-5 titles returned by the agent."
250 |    ]
251 |   },
252 |   {
253 |    "cell_type": "code",
254 |    "execution_count": 9,
255 |    "metadata": {},
256 |    "outputs": [],
257 |    "source": [
258 |     "def top5_recall(example, pred, trace=None):\n",
259 |     "    gold_titles = example.titles\n",
260 |     "    recall = sum(x in pred.titles[:5] for x in gold_titles) / len(gold_titles)\n",
261 |     "\n",
262 |     "    # If we're \"bootstrapping\" for optimization, return True if and only if the recall is perfect.\n",
263 |     "    if trace is not None:\n",
264 |     "        return recall >= 1.0\n",
265 |     "    \n",
266 |     "    # If we're just doing inference, just measure the recall.\n",
267 |     "    return recall\n",
268 |     "\n",
269 |     "evaluate = dspy.Evaluate(devset=devset, metric=top5_recall, num_threads=16, display_progress=True, display_table=5)"
270 |    ]
271 |   },
272 |   {
273 |    "cell_type": "markdown",
274 |    "metadata": {},
275 |    "source": [
276 |     "Let's evaluate our off-the-shelf agent, with `Llama-3.2-8B`, to see how far we can go already.\n",
277 |     "\n",
278 |     "This model is tiny, so it can complain fairly often. Let's wrap it in a try/except block to hide those."
279 |    ]
280 |   },
281 |   {
282 |    "cell_type": "code",
283 |    "execution_count": 10,
284 |    "metadata": {},
285 |    "outputs": [
286 |     {
287 |      "name": "stdout",
288 |      "output_type": "stream",
289 |      "text": [
290 |       "  0%|          | 0/100 [00:00<?, ?it/s]"
291 |      ]
292 |     },
293 |     {
294 |      "name": "stdout",
295 |      "output_type": "stream",
296 |      "text": [
297 |       "Average Metric: 8.00 / 100 (8.0%): 100%|██████████| 100/100 [05:22<00:00,  3.22s/it]"
298 |      ]
299 |     },
300 |     {
301 |      "name": "stderr",
302 |      "output_type": "stream",
303 |      "text": [
304 |       "2024/12/17 14:09:47 INFO dspy.evaluate.evaluate: Average Metric: 7.999999999999997 / 100 (8.0%)\n"
305 |      ]
306 |     },
307 |     {
308 |      "name": "stdout",
309 |      "output_type": "stream",
310 |      "text": [
311 |       "\n"
312 |      ]
313 |     },
314 |     {
315 |      "data": {
316 |       "text/html": [
317 |        "<div>\n",
318 |        "<style scoped>\n",
319 |        "    .dataframe tbody tr th:only-of-type {\n",
320 |        "        vertical-align: middle;\n",
321 |        "    }\n",
322 |        "\n",
323 |        "    .dataframe tbody tr th {\n",
324 |        "        vertical-align: top;\n",
325 |        "    }\n",
326 |        "\n",
327 |        "    .dataframe thead th {\n",
328 |        "        text-align: right;\n",
329 |        "    }\n",
330 |        "</style>\n",
331 |        "<table border=\"1\" class=\"dataframe\">\n",
332 |        "  <thead>\n",
333 |        "    <tr style=\"text-align: right;\">\n",
334 |        "      <th></th>\n",
335 |        "      <th>claim</th>\n",
336 |        "      <th>example_titles</th>\n",
337 |        "      <th>trajectory</th>\n",
338 |        "      <th>reasoning</th>\n",
339 |        "      <th>pred_titles</th>\n",
340 |        "      <th>top5_success</th>\n",
341 |        "    </tr>\n",
342 |        "  </thead>\n",
343 |        "  <tbody>\n",
344 |        "    <tr>\n",
345 |        "      <th>0</th>\n",
346 |        "      <td>The Church of England's movement that inspired the Trinity Episcop...</td>\n",
347 |        "      <td>[Oxford Movement, Trinity Episcopal Church (Houghton, Michigan), S...</td>\n",
348 |        "      <td>{'thought_0': 'The claim suggests that there is a specific movemen...</td>\n",
349 |        "      <td>The search results seem to be a mix of different churches with sim...</td>\n",
350 |        "      <td>['Trinity Episcopal Church (Houghton, Michigan)', 'Trinity Episcop...</td>\n",
351 |        "      <td>✔️ [0.333]</td>\n",
352 |        "    </tr>\n",
353 |        "    <tr>\n",
354 |        "      <th>1</th>\n",
355 |        "      <td>Red, White &amp; Crüe and this athlete both fight. The french fighter ...</td>\n",
356 |        "      <td>[Red, White &amp;amp; Crüe, Mike Tyson, Bobby Stewart]</td>\n",
357 |        "      <td>NaN</td>\n",
358 |        "      <td>NaN</td>\n",
359 |        "      <td>[]</td>\n",
360 |        "      <td></td>\n",
361 |        "    </tr>\n",
362 |        "    <tr>\n",
363 |        "      <th>2</th>\n",
364 |        "      <td>The writer/director/actor from Glen or Glenda and Fernand Rivers s...</td>\n",
365 |        "      <td>[Ed Wood, Glen or Glenda, Fernand Rivers]</td>\n",
366 |        "      <td>NaN</td>\n",
367 |        "      <td>NaN</td>\n",
368 |        "      <td>[]</td>\n",
369 |        "      <td></td>\n",
370 |        "    </tr>\n",
371 |        "    <tr>\n",
372 |        "      <th>3</th>\n",
373 |        "      <td>The film by Sandi Sissel was released before The End of Suburbia.</td>\n",
374 |        "      <td>[Chicken Ranch (film), Sandi Sissel, The End of Suburbia]</td>\n",
375 |        "      <td>NaN</td>\n",
376 |        "      <td>NaN</td>\n",
377 |        "      <td>[]</td>\n",
378 |        "      <td></td>\n",
379 |        "    </tr>\n",
380 |        "    <tr>\n",
381 |        "      <th>4</th>\n",
382 |        "      <td>The actor who played captain hook in the live production with Tayl...</td>\n",
383 |        "      <td>[Christopher Walken, Taylor Louderman, Peter Pan Live!]</td>\n",
384 |        "      <td>NaN</td>\n",
385 |        "      <td>NaN</td>\n",
386 |        "      <td>[]</td>\n",
387 |        "      <td></td>\n",
388 |        "    </tr>\n",
389 |        "  </tbody>\n",
390 |        "</table>\n",
391 |        "</div>"
392 |       ],
393 |       "text/plain": [
394 |        "                                                                   claim  \\\n",
395 |        "0  The Church of England's movement that inspired the Trinity Episcop...   \n",
396 |        "1  Red, White & Crüe and this athlete both fight. The french fighter ...   \n",
397 |        "2  The writer/director/actor from Glen or Glenda and Fernand Rivers s...   \n",
398 |        "3      The film by Sandi Sissel was released before The End of Suburbia.   \n",
399 |        "4  The actor who played captain hook in the live production with Tayl...   \n",
400 |        "\n",
401 |        "                                                          example_titles  \\\n",
402 |        "0  [Oxford Movement, Trinity Episcopal Church (Houghton, Michigan), S...   \n",
403 |        "1                     [Red, White &amp; Crüe, Mike Tyson, Bobby Stewart]   \n",
404 |        "2                              [Ed Wood, Glen or Glenda, Fernand Rivers]   \n",
405 |        "3              [Chicken Ranch (film), Sandi Sissel, The End of Suburbia]   \n",
406 |        "4                [Christopher Walken, Taylor Louderman, Peter Pan Live!]   \n",
407 |        "\n",
408 |        "                                                              trajectory  \\\n",
409 |        "0  {'thought_0': 'The claim suggests that there is a specific movemen...   \n",
410 |        "1                                                                    NaN   \n",
411 |        "2                                                                    NaN   \n",
412 |        "3                                                                    NaN   \n",
413 |        "4                                                                    NaN   \n",
414 |        "\n",
415 |        "                                                               reasoning  \\\n",
416 |        "0  The search results seem to be a mix of different churches with sim...   \n",
417 |        "1                                                                    NaN   \n",
418 |        "2                                                                    NaN   \n",
419 |        "3                                                                    NaN   \n",
420 |        "4                                                                    NaN   \n",
421 |        "\n",
422 |        "                                                             pred_titles  \\\n",
423 |        "0  ['Trinity Episcopal Church (Houghton, Michigan)', 'Trinity Episcop...   \n",
424 |        "1                                                                     []   \n",
425 |        "2                                                                     []   \n",
426 |        "3                                                                     []   \n",
427 |        "4                                                                     []   \n",
428 |        "\n",
429 |        "  top5_success  \n",
430 |        "0   ✔️ [0.333]  \n",
431 |        "1               \n",
432 |        "2               \n",
433 |        "3               \n",
434 |        "4               "
435 |       ]
436 |      },
437 |      "metadata": {},
438 |      "output_type": "display_data"
439 |     },
440 |     {
441 |      "data": {
442 |       "text/html": [
443 |        "\n",
444 |        "                <div style='\n",
445 |        "                    text-align: center;\n",
446 |        "                    font-size: 16px;\n",
447 |        "                    font-weight: bold;\n",
448 |        "                    color: #555;\n",
449 |        "                    margin: 10px 0;'>\n",
450 |        "                    ... 95 more rows not displayed ...\n",
451 |        "                </div>\n",
452 |        "                "
453 |       ],
454 |       "text/plain": [
455 |        "<IPython.core.display.HTML object>"
456 |       ]
457 |      },
458 |      "metadata": {},
459 |      "output_type": "display_data"
460 |     },
461 |     {
462 |      "data": {
463 |       "text/plain": [
464 |        "8.0"
465 |       ]
466 |      },
467 |      "execution_count": 11,
468 |      "metadata": {},
469 |      "output_type": "execute_result"
470 |     }
471 |    ],
472 |    "source": [
473 |     "def safe_react(claim: str):\n",
474 |     "    try:\n",
475 |     "        return react(claim=claim)\n",
476 |     "    except Exception as e:\n",
477 |     "        return dspy.Prediction(titles=[])\n",
478 |     "\n",
479 |     "evaluate(safe_react)"
480 |    ]
481 |   },
482 |   {
483 |    "cell_type": "markdown",
484 |    "metadata": {},
485 |    "source": [
486 |     "<details>\n",
487 |     "<summary>Tracking Evaluation Results in MLflow Experiment</summary>\n",
488 |     "\n",
489 |     "<br/>\n",
490 |     "\n",
491 |     "To track and visualize the evaluation results over time, you can record the results in MLflow Experiment.\n",
492 |     "\n",
493 |     "\n",
494 |     "```python\n",
495 |     "import mlflow\n",
496 |     "\n",
497 |     "with mlflow.start_run(run_name=\"agent_evaluation\"):\n",
498 |     "    evaluate = dspy.Evaluate(\n",
499 |     "        devset=devset,\n",
500 |     "        metric=top5_recall,\n",
501 |     "        num_threads=16,\n",
502 |     "        display_progress=True,\n",
503 |     "    )\n",
504 |     "\n",
505 |     "    # Evaluate the program as usual\n",
506 |     "    result = evaluate(cot)\n",
507 |     "\n",
508 |     "    # Log the aggregated score\n",
509 |     "    mlflow.log_metric(\"top5_recall\", result.score)\n",
510 |     "    # Log the detailed evaluation results as a table\n",
511 |     "    mlflow.log_table(\n",
512 |     "        {\n",
513 |     "            \"Claim\": [example.claim for example in eval_set],\n",
514 |     "            \"Expected Titles\": [example.titles for example in eval_set],\n",
515 |     "            \"Predicted Titles\": [output[1] for output in result.results],\n",
516 |     "            \"Top 5 Recall\": [output[2] for output in result.results],\n",
517 |     "        },\n",
518 |     "        artifact_file=\"eval_results.json\",\n",
519 |     "    )\n",
520 |     "```\n",
521 |     "\n",
522 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
523 |     "\n",
524 |     "</details>"
525 |    ]
526 |   },
527 |   {
528 |    "cell_type": "markdown",
529 |    "metadata": {},
530 |    "source": [
531 |     "Wow. It only scores 8% in terms of recall. Not that good!\n",
532 |     "\n",
533 |     "Let's now optimize the two prompts inside `dspy.ReAct` jointly to maximize the recall of our agent. This may take around 30 minutes and make some $5 worth of calls to GPT-4o to optimize Llama-3.2-3B."
534 |    ]
535 |   },
536 |   {
537 |    "cell_type": "code",
538 |    "execution_count": 12,
539 |    "metadata": {},
540 |    "outputs": [],
541 |    "source": [
542 |     "kwargs = dict(teacher_settings=dict(lm=gpt4o), prompt_model=gpt4o, max_errors=999)\n",
543 |     "\n",
544 |     "tp = dspy.MIPROv2(metric=top5_recall, auto=\"medium\", num_threads=16, **kwargs)\n",
545 |     "optimized_react = tp.compile(react, trainset=trainset, max_bootstrapped_demos=3, max_labeled_demos=0)"
546 |    ]
547 |   },
548 |   {
549 |    "cell_type": "markdown",
550 |    "metadata": {},
551 |    "source": [
552 |     "Let's now evaluate again, after optimization."
553 |    ]
554 |   },
555 |   {
556 |    "cell_type": "code",
557 |    "execution_count": 13,
558 |    "metadata": {},
559 |    "outputs": [
560 |     {
561 |      "name": "stdout",
562 |      "output_type": "stream",
563 |      "text": [
564 |       "Average Metric: 41.67 / 100 (41.7%): 100%|██████████| 100/100 [03:00<00:00,  1.81s/it]"
565 |      ]
566 |     },
567 |     {
568 |      "name": "stderr",
569 |      "output_type": "stream",
570 |      "text": [
571 |       "2024/12/17 15:12:06 INFO dspy.evaluate.evaluate: Average Metric: 41.66666666666667 / 100 (41.7%)\n"
572 |      ]
573 |     },
574 |     {
575 |      "name": "stdout",
576 |      "output_type": "stream",
577 |      "text": [
578 |       "\n"
579 |      ]
580 |     },
581 |     {
582 |      "data": {
583 |       "text/html": [
584 |        "<div>\n",
585 |        "<style scoped>\n",
586 |        "    .dataframe tbody tr th:only-of-type {\n",
587 |        "        vertical-align: middle;\n",
588 |        "    }\n",
589 |        "\n",
590 |        "    .dataframe tbody tr th {\n",
591 |        "        vertical-align: top;\n",
592 |        "    }\n",
593 |        "\n",
594 |        "    .dataframe thead th {\n",
595 |        "        text-align: right;\n",
596 |        "    }\n",
597 |        "</style>\n",
598 |        "<table border=\"1\" class=\"dataframe\">\n",
599 |        "  <thead>\n",
600 |        "    <tr style=\"text-align: right;\">\n",
601 |        "      <th></th>\n",
602 |        "      <th>claim</th>\n",
603 |        "      <th>example_titles</th>\n",
604 |        "      <th>trajectory</th>\n",
605 |        "      <th>reasoning</th>\n",
606 |        "      <th>pred_titles</th>\n",
607 |        "      <th>top5_success</th>\n",
608 |        "    </tr>\n",
609 |        "  </thead>\n",
610 |        "  <tbody>\n",
611 |        "    <tr>\n",
612 |        "      <th>0</th>\n",
613 |        "      <td>The Church of England's movement that inspired the Trinity Episcop...</td>\n",
614 |        "      <td>[Oxford Movement, Trinity Episcopal Church (Houghton, Michigan), S...</td>\n",
615 |        "      <td>{'thought_0': 'To verify the claim, I need to identify the Church ...</td>\n",
616 |        "      <td>The claim states that the Church of England's movement that inspir...</td>\n",
617 |        "      <td>['Trinity Episcopal Church (Houghton, Michigan)', 'Church of All S...</td>\n",
618 |        "      <td>✔️ [0.667]</td>\n",
619 |        "    </tr>\n",
620 |        "    <tr>\n",
621 |        "      <th>1</th>\n",
622 |        "      <td>Red, White &amp; Crüe and this athlete both fight. The french fighter ...</td>\n",
623 |        "      <td>[Red, White &amp;amp; Crüe, Mike Tyson, Bobby Stewart]</td>\n",
624 |        "      <td>{'thought_0': 'To verify the claim, I need to identify the French ...</td>\n",
625 |        "      <td>The claim states that Red, White &amp; Crüe is a term applied to sport...</td>\n",
626 |        "      <td>[Bobby Stewart, Bernardin Ledoux Kingue Matam, Mötley Crüe, Milan ...</td>\n",
627 |        "      <td>✔️ [0.333]</td>\n",
628 |        "    </tr>\n",
629 |        "    <tr>\n",
630 |        "      <th>2</th>\n",
631 |        "      <td>The writer/director/actor from Glen or Glenda and Fernand Rivers s...</td>\n",
632 |        "      <td>[Ed Wood, Glen or Glenda, Fernand Rivers]</td>\n",
633 |        "      <td>{'thought_0': 'To verify the claim, I need to identify the writer/...</td>\n",
634 |        "      <td>The claim states that Glen or Glenda and Fernand Rivers share the ...</td>\n",
635 |        "      <td>[Ed Wood, Bela Lugosi, Dolores Fuller]</td>\n",
636 |        "      <td>✔️ [0.333]</td>\n",
637 |        "    </tr>\n",
638 |        "    <tr>\n",
639 |        "      <th>3</th>\n",
640 |        "      <td>The film by Sandi Sissel was released before The End of Suburbia.</td>\n",
641 |        "      <td>[Chicken Ranch (film), Sandi Sissel, The End of Suburbia]</td>\n",
642 |        "      <td>{'thought_0': 'To verify the claim, I need to find the release dat...</td>\n",
643 |        "      <td>The claim states that the film by Sandi Sissel was released before...</td>\n",
644 |        "      <td>[Sandi Sissel, The End of Suburbia (film)]</td>\n",
645 |        "      <td>✔️ [0.333]</td>\n",
646 |        "    </tr>\n",
647 |        "    <tr>\n",
648 |        "      <th>4</th>\n",
649 |        "      <td>The actor who played captain hook in the live production with Tayl...</td>\n",
650 |        "      <td>[Christopher Walken, Taylor Louderman, Peter Pan Live!]</td>\n",
651 |        "      <td>{'thought_0': 'To verify the claim, I need to find the actor who p...</td>\n",
652 |        "      <td>The claim suggests that the actor who played Captain Hook in the l...</td>\n",
653 |        "      <td>[Cyril Ritchard, Ruth Connell]</td>\n",
654 |        "      <td></td>\n",
655 |        "    </tr>\n",
656 |        "  </tbody>\n",
657 |        "</table>\n",
658 |        "</div>"
659 |       ],
660 |       "text/plain": [
661 |        "                                                                   claim  \\\n",
662 |        "0  The Church of England's movement that inspired the Trinity Episcop...   \n",
663 |        "1  Red, White & Crüe and this athlete both fight. The french fighter ...   \n",
664 |        "2  The writer/director/actor from Glen or Glenda and Fernand Rivers s...   \n",
665 |        "3      The film by Sandi Sissel was released before The End of Suburbia.   \n",
666 |        "4  The actor who played captain hook in the live production with Tayl...   \n",
667 |        "\n",
668 |        "                                                          example_titles  \\\n",
669 |        "0  [Oxford Movement, Trinity Episcopal Church (Houghton, Michigan), S...   \n",
670 |        "1                     [Red, White &amp; Crüe, Mike Tyson, Bobby Stewart]   \n",
671 |        "2                              [Ed Wood, Glen or Glenda, Fernand Rivers]   \n",
672 |        "3              [Chicken Ranch (film), Sandi Sissel, The End of Suburbia]   \n",
673 |        "4                [Christopher Walken, Taylor Louderman, Peter Pan Live!]   \n",
674 |        "\n",
675 |        "                                                              trajectory  \\\n",
676 |        "0  {'thought_0': 'To verify the claim, I need to identify the Church ...   \n",
677 |        "1  {'thought_0': 'To verify the claim, I need to identify the French ...   \n",
678 |        "2  {'thought_0': 'To verify the claim, I need to identify the writer/...   \n",
679 |        "3  {'thought_0': 'To verify the claim, I need to find the release dat...   \n",
680 |        "4  {'thought_0': 'To verify the claim, I need to find the actor who p...   \n",
681 |        "\n",
682 |        "                                                               reasoning  \\\n",
683 |        "0  The claim states that the Church of England's movement that inspir...   \n",
684 |        "1  The claim states that Red, White & Crüe is a term applied to sport...   \n",
685 |        "2  The claim states that Glen or Glenda and Fernand Rivers share the ...   \n",
686 |        "3  The claim states that the film by Sandi Sissel was released before...   \n",
687 |        "4  The claim suggests that the actor who played Captain Hook in the l...   \n",
688 |        "\n",
689 |        "                                                             pred_titles  \\\n",
690 |        "0  ['Trinity Episcopal Church (Houghton, Michigan)', 'Church of All S...   \n",
691 |        "1  [Bobby Stewart, Bernardin Ledoux Kingue Matam, Mötley Crüe, Milan ...   \n",
692 |        "2                                 [Ed Wood, Bela Lugosi, Dolores Fuller]   \n",
693 |        "3                             [Sandi Sissel, The End of Suburbia (film)]   \n",
694 |        "4                                         [Cyril Ritchard, Ruth Connell]   \n",
695 |        "\n",
696 |        "  top5_success  \n",
697 |        "0   ✔️ [0.667]  \n",
698 |        "1   ✔️ [0.333]  \n",
699 |        "2   ✔️ [0.333]  \n",
700 |        "3   ✔️ [0.333]  \n",
701 |        "4               "
702 |       ]
703 |      },
704 |      "metadata": {},
705 |      "output_type": "display_data"
706 |     },
707 |     {
708 |      "data": {
709 |       "text/html": [
710 |        "\n",
711 |        "                <div style='\n",
712 |        "                    text-align: center;\n",
713 |        "                    font-size: 16px;\n",
714 |        "                    font-weight: bold;\n",
715 |        "                    color: #555;\n",
716 |        "                    margin: 10px 0;'>\n",
717 |        "                    ... 95 more rows not displayed ...\n",
718 |        "                </div>\n",
719 |        "                "
720 |       ],
721 |       "text/plain": [
722 |        "<IPython.core.display.HTML object>"
723 |       ]
724 |      },
725 |      "metadata": {},
726 |      "output_type": "display_data"
727 |     },
728 |     {
729 |      "data": {
730 |       "text/plain": [
731 |        "41.67"
732 |       ]
733 |      },
734 |      "execution_count": 14,
735 |      "metadata": {},
736 |      "output_type": "execute_result"
737 |     }
738 |    ],
739 |    "source": [
740 |     "evaluate(optimized_react)"
741 |    ]
742 |   },
743 |   {
744 |    "cell_type": "markdown",
745 |    "metadata": {},
746 |    "source": [
747 |     "Awesome. It looks like the system improved drastically from 8% recall to around 40% recall. That was a pretty straightforward approach, but DSPy gives you many tools to continue iterating on this from here.\n",
748 |     "\n",
749 |     "Next, let's inspect the optimized prompts to understand what it has learned. We'll run one query and then inspect the last two prompts, which will show us the prompts used for both ReAct sub-modules, the one that does the agentic loop and the other than prepares the final results. (Alternatively, if you enabled MLflow Tracing following the instructions above, you can see all steps done by the agent including LLM calls, prompts, tool execution, in a rich tree-view.)"
750 |    ]
751 |   },
752 |   {
753 |    "cell_type": "code",
754 |    "execution_count": 15,
755 |    "metadata": {},
756 |    "outputs": [
757 |     {
758 |      "data": {
759 |       "text/plain": [
760 |        "['Bernard-Marie Koltès', 'Joe Orton']"
761 |       ]
762 |      },
763 |      "execution_count": 16,
764 |      "metadata": {},
765 |      "output_type": "execute_result"
766 |     }
767 |    ],
768 |    "source": [
769 |     "optimized_react(claim=\"The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\").titles"
770 |    ]
771 |   },
772 |   {
773 |    "cell_type": "code",
774 |    "execution_count": 17,
775 |    "metadata": {},
776 |    "outputs": [
777 |     {
778 |      "name": "stdout",
779 |      "output_type": "stream",
780 |      "text": [
781 |       "\n",
782 |       "\n",
783 |       "\n",
784 |       "\n",
785 |       "\u001b[34m[2024-12-17T15:13:25.420335]\u001b[0m\n",
786 |       "\n",
787 |       "\u001b[31mSystem message:\u001b[0m\n",
788 |       "\n",
789 |       "Your input fields are:\n",
790 |       "1. `claim` (str)\n",
791 |       "2. `trajectory` (str)\n",
792 |       "\n",
793 |       "Your output fields are:\n",
794 |       "1. `next_thought` (str)\n",
795 |       "2. `next_tool_name` (Literal[search_wikipedia, lookup_wikipedia, finish])\n",
796 |       "3. `next_tool_args` (dict[str, Any])\n",
797 |       "\n",
798 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
799 |       "\n",
800 |       "[[ ## claim ## ]]\n",
801 |       "{claim}\n",
802 |       "\n",
803 |       "[[ ## trajectory ## ]]\n",
804 |       "{trajectory}\n",
805 |       "\n",
806 |       "[[ ## next_thought ## ]]\n",
807 |       "{next_thought}\n",
808 |       "\n",
809 |       "[[ ## next_tool_name ## ]]\n",
810 |       "{next_tool_name}        # note: the value you produce must be one of: search_wikipedia; lookup_wikipedia; finish\n",
811 |       "\n",
812 |       "[[ ## next_tool_args ## ]]\n",
813 |       "{next_tool_args}        # note: the value you produce must be pareseable according to the following JSON schema: {\"type\": \"object\"}\n",
814 |       "\n",
815 |       "[[ ## completed ## ]]\n",
816 |       "\n",
817 |       "In adhering to this structure, your objective is: \n",
818 |       "        Find all Wikipedia titles relevant to verifying (or refuting) the claim.\n",
819 |       "        \n",
820 |       "        You will be given `claim` and your goal is to finish with `titles`.\n",
821 |       "        \n",
822 |       "        To do this, you will interleave Thought, Tool Name, and Tool Args, and receive a resulting Observation.\n",
823 |       "        \n",
824 |       "        Thought can reason about the current situation, and Tool Name can be the following types:\n",
825 |       "        \n",
826 |       "        (1) search_wikipedia, whose description is <desc>Returns top-5 results and then the titles of the top-5 to top-30 results.</desc>. It takes arguments {'query': 'str'} in JSON format.\n",
827 |       "        (2) lookup_wikipedia, whose description is <desc>Returns the text of the Wikipedia page, if it exists.</desc>. It takes arguments {'title': 'str'} in JSON format.\n",
828 |       "        (3) finish, whose description is <desc>Signals that the final outputs, i.e. `titles`, are now available and marks the task as complete.</desc>. It takes arguments {} in JSON format.\n",
829 |       "\n",
830 |       "\n",
831 |       "\u001b[31mUser message:\u001b[0m\n",
832 |       "\n",
833 |       "[[ ## claim ## ]]\n",
834 |       "1990 Film that Khiladiyon Ka Khiladi is loosely based on stars this actor who is best known for martial arts action films.\n",
835 |       "\n",
836 |       "[[ ## trajectory ## ]]\n",
837 |       "[[ ## thought_0 ## ]]\n",
838 |       "To verify the claim, I need to identify the 1990 film that \"Khiladiyon Ka Khiladi\" is loosely based on and the actor known for martial arts action films who starred in it. I will start by searching for information on \"Khiladiyon Ka Khiladi\" to find details about its inspiration.\n",
839 |       "\n",
840 |       "[[ ## tool_name_0 ## ]]\n",
841 |       "search_wikipedia\n",
842 |       "\n",
843 |       "[[ ## tool_args_0 ## ]]\n",
844 |       "{\"query\": \"Khiladiyon Ka Khiladi\"}\n",
845 |       "\n",
846 |       "[[ ## observation_0 ## ]]\n",
847 |       "[1] «Khiladiyon Ka Khiladi | Khiladiyon Ka Khiladi (English: Player of Players) is a 1996 Indian action film starring Rekha in her first villain role, Akshay Kumar, Raveena Tandon and former WWE wrestlers \"Crush\" and Brian Lee as \"The Undertaker\". It was the 5th highest grossing movie of the year 1996 and was declared 'SuperHit' by Box Office India. It was the fourth installment in the Khiladi (film series). The movie is loosely based based on Hollywood film Lionheart»\n",
848 |       "[2] «Khiladi 420 | Khiladi 420 (English: \"Con Player\") is an Indian Hindi action film directed by Neeraj Vora and starring Akshay Kumar and Mahima Chaudhry. The film was written by Uttam Gudda and released on 29 December 2000. It is the seventh installment in the \"Khiladi\" series starring Kumar, which included \"Khiladi\" (1992), \"Main Khiladi Tu Anari\" (1994), \"Sabse Bada Khiladi\" (1995), \"Khiladiyon Ka Khiladi\" (1996), \"Mr. and Mrs. Khiladi\" (1997) and \"International Khiladi\" (1999).»\n",
849 |       "[3] «Khiladi (1992 film) | Khiladi (English: \"Player\" ) is a 1992 Indian suspense thriller film directed by Abbas Mustan. The film was Akshay Kumar's breakthrough role and also stars Ayesha Jhulka, Deepak Tijori, Sabeeha. While Prem Chopra, Shakti Kapoor, Anant Mahadevan and Johnny Lever played supporting roles. \"Khiladi\" was the first installment in the Khiladi (film series) which had \"Khiladi\" in the title and Akshay Kumar in the leading role. It was followed by \"Main Khiladi Tu Anari\" (1994), \"Sabse Bada Khiladi\" (1995), \"Khiladiyon Ka Khiladi\" (1996), \"Mr. and Mrs. Khiladi\" (1997), \"International Khiladi\" (1999), \"Khiladi 420\"(2000) and \"Khiladi 786\" (2012). Khiladi was critically and commercially success at the box-office and the tenth highest grossing film of 1992. It was Akshay Kumar's first successful movie and was declared a \"Super Hit\" at the box office. The basic premise of the story is similar to 1975 released movie Khel Khel Mein starring Rishi Kapoor and Neetu Singh. The film was remade in Kannada as \"Aata Hudugaata\".»\n",
850 |       "[4] «Khiladi (film series) | Khiladi series is a Bollywood action film series starring Akshay Kumar in the lead role. However, unlike other film series, other than having Akshay Kumar in lead role, and other than having the word \"Khiladi\" in the title, these films have nothing in common. The producers, directors and stories of these films are totally different. \" Khiladi\" (1992) was the first in a series of films which had Akshay Kumar in the title role and gave it his first breakthrough role. It was followed by \"Main Khiladi Tu Anari\" (1994), \"Sabse Bada Khiladi\" (1995), \"Khiladiyon Ka Khiladi\" (1996), \"Mr. and Mrs. Khiladi\" (1997), \"International Khiladi\" (1999) and \"Khiladi 420\" (2000), all featuring Kumar in the lead role. The latest film in the franchise is \"Khiladi 786\" (2012).»\n",
851 |       "[5] «Khiladi 786 | Khiladi 786 (खिलाड़ी 786) is a 2012 Indian Hindi Punjabi action comedy film directed by Ashish R Mohan, featuring Akshay Kumar in the title role alongside Asin playing the female lead. It features Himesh Reshammiya, Mithun Chakraborty, Raj Babbar and Mukesh Rishi in supporting roles. The film marks the return of Akshay Kumar to his \"Khiladi\" series after 12 years. It is mostly shot in Mumbai and Punjab. Khiladi786 is AkshayKumar 100th film.»\n",
852 |       "[6] «Other retrieved pages have titles: `Khiladi (2013 film)`, `Khiladi (1968 film)`, `International Khiladi`, `Khatron Ke Khiladi (1988 film)`, `Khatron Ke Khiladi (2001 film)`, `Umesh Mehra`, `Shatranj ke Khiladi`, `Main Khiladi Tu Anari`, `Fear Factor: Khatron Ke Khiladi (season 7)`, `Fear Factor: Khatron Ke Khiladi`, `Mr. and Mrs. Khiladi`, `Sabse Bada Khiladi`, `Ek Khiladi Bawan Pattey`, `Ek Khiladi Ek Haseena (TV series)`, `Do Khiladi`, `Ek Khiladi Ek Haseena (film)`, `Khel Khilari Ka`, `Fear Factor: Khatron Ke Khiladi (season 8)`, `Fear Factor: Khatron Ke Khiladi Darr Ka Blockbuster`, `Khilona (1942 film)`, `Fear Factor: Khatron Ke Khiladi Darr Ka Blockbuster Returns`, `Chhota Bheem: Dholakpur ke Khiladi`, `Khilani`, `Kandireega`, `Khilaaf`.»\n",
853 |       "\n",
854 |       "[[ ## thought_1 ## ]]\n",
855 |       "The search results indicate that \"Khiladiyon Ka Khiladi\" is loosely based on the Hollywood film \"Lionheart\". I should now verify which actor, known for martial arts action films, starred in \"Lionheart\".\n",
856 |       "\n",
857 |       "[[ ## tool_name_1 ## ]]\n",
858 |       "search_wikipedia\n",
859 |       "\n",
860 |       "[[ ## tool_args_1 ## ]]\n",
861 |       "{\"query\": \"Lionheart 1990 film\"}\n",
862 |       "\n",
863 |       "[[ ## observation_1 ## ]]\n",
864 |       "[1] «Lionheart (1990 film) | Lionheart (also known as Wrong Bet, A.W.O.L.: Absent Without Leave, Leon and Full Contact) is a 1990 action film, directed by Sheldon Lettich, starring Jean-Claude Van Damme and co-starring Brian Thompson, along with Harrison Page, Deborah Rennard, Lisa Pelikan, and Ashley Johnson.»\n",
865 |       "[2] «Truly, Madly, Deeply | Truly, Madly, Deeply is a 1990 British fantasy drama film made for the BBC's \"Screen Two\" series, by BBC Films, Lionheart and Winston Pictures. The film, written and directed by Anthony Minghella, stars Juliet Stevenson and Alan Rickman.»\n",
866 |       "[3] «Lionheart (1987 film) | Lionheart, also known as Lionheart: The Children's Crusade, is a 1987 adventure film directed by Franklin J. Schaffner and produced by Talia Shire and Stanley O'Toole. Shire's brother, Francis Ford Coppola, initially planned to direct the film but instead opted to be executive producer along with Shire's husband, Jack Schwartzman. The screenplay was written by Menno Meyjes and Richard Outten from a story by Meyjes. The composer Jerry Goldsmith wrote the score. The film was released in August 1987. It was distributed by Orion Pictures.»\n",
867 |       "[4] «Lionheart (2016 film) | Lionheart is a 2016 American boxing film short written and produced by Oscar DeRosa and Orlando Cicilia III. The film stars Oscar DeRosa and Marc Macaulay. The film portrays struggling professional boxer Max Rossi who is finally presented with the fight he's been waiting for that will launch his career to the next level but when he is suddenly confronted with a life-changing opportunity he must decide which path to take.»\n",
868 |       "[5] «Richard the Lionheart (2013 film) | Richard The Lionheart is a 2013 film, starring Chandler Maness as Richard the Lionheart, Malcolm McDowell as King Henry II and Andrea Zirio as Henry the Young.»\n",
869 |       "[6] «Other retrieved pages have titles: `Richard the Lionheart: Rebellion`, `The Brothers Lionheart (1977 film)`, `Kodama Simham`, `Jean-Claude Van Damme`, `Lionsheart`, `A Day for Lionhearts`, `The Lion in Winter (1968 film)`, `Lion Jagapathi Rao`, `Theatre of Blood`, `Young Lions (album)`, `Richard the Lion-Hearted (1923 film)`, `Bullseye! (1990 film)`, `Fear (1990 film)`, `The Guard (1990 film)`, `Ironheart`, `The Guardian (1990 film)`, `Tiger Cage 2`, `Lion Rampant (game publisher)`, `Success (1991 film)`, `Lion in the Streets`, `The King of the Kickboxers`, `Lionheart (video game)`, `Richard the Lionheart (TV series)`, `Dermot Walsh`, `Lars Söderdahl`.»\n",
870 |       "\n",
871 |       "Respond with the corresponding output fields, starting with the field `[[ ## next_thought ## ]]`, then `[[ ## next_tool_name ## ]]` (must be formatted as a valid Python Literal[search_wikipedia, lookup_wikipedia, finish]), then `[[ ## next_tool_args ## ]]` (must be formatted as a valid Python dict[str, Any]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
872 |       "\n",
873 |       "\n",
874 |       "\u001b[31mAssistant message:\u001b[0m\n",
875 |       "\n",
876 |       "[[ ## next_thought ## ]]\n",
877 |       "The search results confirm that the 1990 film \"Lionheart\" stars Jean-Claude Van Damme, who is well-known for his martial arts action films. This information aligns with what is needed to verify the claim. I now have the relevant titles related to the claim: \"Khiladiyon Ka Khiladi\" and \"Lionheart.\"\n",
878 |       "\n",
879 |       "[[ ## next_tool_name ## ]]\n",
880 |       "finish\n",
881 |       "\n",
882 |       "[[ ## next_tool_args ## ]]\n",
883 |       "{}\n",
884 |       "\n",
885 |       "[[ ## completed ## ]]\n",
886 |       "\n",
887 |       "\n",
888 |       "\u001b[31mUser message:\u001b[0m\n",
889 |       "\n",
890 |       "[[ ## claim ## ]]\n",
891 |       "The figure who currently holds the role Michael Noonan held from 2001 to 2002, was the Minister for Social Protection from 2016 until 2017.\n",
892 |       "\n",
893 |       "[[ ## trajectory ## ]]\n",
894 |       "\n",
895 |       "\n",
896 |       "Respond with the corresponding output fields, starting with the field `[[ ## next_thought ## ]]`, then `[[ ## next_tool_name ## ]]` (must be formatted as a valid Python Literal[search_wikipedia, lookup_wikipedia, finish]), then `[[ ## next_tool_args ## ]]` (must be formatted as a valid Python dict[str, Any]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
897 |       "\n",
898 |       "\n",
899 |       "\u001b[31mAssistant message:\u001b[0m\n",
900 |       "\n",
901 |       "[[ ## next_thought ## ]]\n",
902 |       "To verify the claim, I need to identify the role Michael Noonan held from 2001 to 2002. Then, I can find out who currently holds this role and check if they were the Minister for Social Protection from 2016 to 2017.\n",
903 |       "\n",
904 |       "[[ ## next_tool_name ## ]]\n",
905 |       "search_wikipedia\n",
906 |       "\n",
907 |       "[[ ## next_tool_args ## ]]\n",
908 |       "{\"query\": \"Michael Noonan role 2001 to 2002\"}\n",
909 |       "\n",
910 |       "[[ ## completed ## ]]\n",
911 |       "\n",
912 |       "\n",
913 |       "\u001b[31mUser message:\u001b[0m\n",
914 |       "\n",
915 |       "[[ ## claim ## ]]\n",
916 |       "An actor in a musical film was also a United States Navy Combat veteran in World War II. This film was awarded The Golden Bear at the 50th Berlin International Film Festival.\n",
917 |       "\n",
918 |       "[[ ## trajectory ## ]]\n",
919 |       "[[ ## thought_0 ## ]]\n",
920 |       "To verify the claim, I need to find out which musical film was awarded The Golden Bear at the 50th Berlin International Film Festival and check if an actor from that film was a United States Navy Combat veteran in World War II. I will start by searching for the musical films that won the Golden Bear around the time of the 50th Berlin International Film Festival.\n",
921 |       "\n",
922 |       "[[ ## tool_name_0 ## ]]\n",
923 |       "search_wikipedia\n",
924 |       "\n",
925 |       "[[ ## tool_args_0 ## ]]\n",
926 |       "{\"query\": \"Golden Bear 50th Berlin International Film Festival musical film\"}\n",
927 |       "\n",
928 |       "[[ ## observation_0 ## ]]\n",
929 |       "[1] «53rd Berlin International Film Festival | The 54th annual Berlin International Film Festival was held from February 6–16, 2003. The festival opened with musical film \"Chicago\" by Rob Marshall and closed with Martin Scorsese's \"Gangs of New York\", both films played out of competition at the festival. The Golden Bear was awarded to British film \"In This World\" directed by Michael Winterbottom.»\n",
930 |       "[2] «50th Berlin International Film Festival | The 50th annual Berlin International Film Festival was held from February 9 to 20, 2000. The festival opened with \"The Million Dollar Hotel\" by Wim Wenders. \" Bossa Nova\" by Bruno Barreto, screened out of competition was the closing film of the festival. The Golden Bear was awarded to American film \"Magnolia\" directed by Paul Thomas Anderson.»\n",
931 |       "[3] «40th Berlin International Film Festival | The 40th annual Berlin International Film Festival was held from 9 to 20 February 1990. The festival opened with \"Steel Magnolias\" by Herbert Ross, which was shown out of competition. The Golden Bear was awarded to the American film \"Music Box\" directed by Costa-Gavras and Czech film \"Skřivánci na niti\" directed by Jiří Menzel.»\n",
932 |       "[4] «66th Berlin International Film Festival | The 66th Berlin International Film Festival was held from 11 to 21 February 2016, with American actress Meryl Streep as the President of the Jury. The Honorary Golden Bear for lifetime achievement was presented to German cinematographer Michael Ballhaus. \" Hail, Caesar! \", directed by Joel and Ethan Coen, was selected to open the festival. The Golden Bear was awarded to the Italian documentary \"Fire at Sea\", directed by Gianfranco Rosi, which also serves as closing night film.»\n",
933 |       "[5] «49th Berlin International Film Festival | The 49th annual Berlin International Film Festival was held from February 10 to 21, 1999. The festival opened with \"Aimée & Jaguar\" by Max Färberböck. The Golden Bear was awarded to Canadian-American film \"The Thin Red Line\" directed by Terrence Malick.»\n",
934 |       "[6] «Other retrieved pages have titles: `38th Berlin International Film Festival`, `48th Berlin International Film Festival`, `45th Berlin International Film Festival`, `47th Berlin International Film Festival`, `64th Berlin International Film Festival`, `65th Berlin International Film Festival`, `46th Berlin International Film Festival`, `54th Berlin International Film Festival`, `62nd Berlin International Film Festival`, `25th Berlin International Film Festival`, `35th Berlin International Film Festival`, `43rd Berlin International Film Festival`, `67th Berlin International Film Festival`, `Golden Bear`, `44th Berlin International Film Festival`, `60th Berlin International Film Festival`, `13th Berlin International Film Festival`, `34th Berlin International Film Festival`, `51st Berlin International Film Festival`, `1st Berlin International Film Festival`, `30th Berlin International Film Festival`, `42nd Berlin International Film Festival`, `27th Berlin International Film Festival`, `31st Berlin International Film Festival`, `32nd Berlin International Film Festival`.»\n",
935 |       "\n",
936 |       "[[ ## thought_1 ## ]]\n",
937 |       "The Golden Bear at the 50th Berlin International Film Festival was awarded to the American film \"Magnolia\" directed by Paul Thomas Anderson. I need to verify if any actor in \"Magnolia\" was a United States Navy Combat veteran in World War II.\n",
938 |       "\n",
939 |       "[[ ## tool_name_1 ## ]]\n",
940 |       "search_wikipedia\n",
941 |       "\n",
942 |       "[[ ## tool_args_1 ## ]]\n",
943 |       "{\"query\": \"Magnolia film cast\"}\n",
944 |       "\n",
945 |       "[[ ## observation_1 ## ]]\n",
946 |       "[1] «Magnolia (film) | Magnolia is a 1999 American ensemble drama film written, co-produced and directed by Paul Thomas Anderson. The film stars Jeremy Blackman, Tom Cruise, Melinda Dillon, Philip Baker Hall, Philip Seymour Hoffman, Ricky Jay, William H. Macy, Alfred Molina, Julianne Moore, John C. Reilly, Jason Robards and Melora Walters, and is a mosaic of interrelated characters in search of happiness, forgiveness and meaning in the San Fernando Valley.»\n",
947 |       "[2] «Steel Magnolias (2012 film) | Steel Magnolias is an American comedy-drama television film directed by Kenny Leon that premiered at Lifetime Network on October 7, 2012. It is a contemporary retelling of the play \"Steel Magnolias\" and its 1989 film adaptation. The new film stars an all-Black American cast, including Queen Latifah as M'Lynn, Jill Scott as Truvy, Condola Rashād as Shelby, Adepero Oduye as Annelle, with Phylicia Rashād as Clairee and Alfre Woodard as Ouiser.»\n",
948 |       "[3] «Baller Blockin' | Baller Blockin' is a 2000 drama film set in New Orleans's Magnolia Projects. It stars Bryan “Birdman” Williams, Ronald \"Slim\" Williams, Juvenile, Manuel Vazquez, B.G., Lil Wayne, Turk, and Mannie Fresh with cameos by comedians Anthony Johnson and T.K. Kirkland.»\n",
949 |       "[4] «360 (film) | 360 is a 2011 ensemble drama film starring Anthony Hopkins, Ben Foster, Rachel Weisz, Jude Law and other international actors. The film, directed by Fernando Meirelles, opened the 2011 London Film Festival. Magnolia Pictures released the film on video on demand on 29 June 2012 and was released in United States theaters on 3 August 2012.»\n",
950 |       "[5] «River of Romance | River of Romance is a 1929 American drama film directed by Richard Wallace and written by Ethel Doherty, Joseph L. Mankiewicz, Dan Totheroh and John V.A. Weaver. The film stars Charles 'Buddy' Rogers, Mary Brian, June Collyer, Henry B. Walthall, Wallace Beery, Fred Kohler and Natalie Kingston. It is based on the play \"Magnolia\" by Booth Tarkington. The film was released on June 29, 1929, by Paramount Pictures.»\n",
951 |       "[6] «Other retrieved pages have titles: `Ira &amp; Abby`, `The Seat Filler`, `Serious Moonlight (2009 film)`, `Experimenter (film)`, `Humpday`, `Roadie (2011 film)`, `A Kind of Murder`, `The Magic of Belle Isle`, `The Hero of Color City`, `The War Within (film)`, `Claudia Lee`, `Steel Magnolias`, `Dina Bonnevie`, `Deadline (1987 film)`, `Creative Control (film)`, `Humboldt County (film)`, `Temptation Island (1980 film)`, `Gina Beck`, `Magnolia (score)`, `Cashback (film)`, `Cynthia Zamora`, `Straight Talk`, `Magnolia (soundtrack)`, `The Great Buck Howard`, `Binta and the Great Idea`.»\n",
952 |       "\n",
953 |       "[[ ## thought_2 ## ]]\n",
954 |       "The cast of the film \"Magnolia\" includes several well-known actors. I need to investigate whether any of these actors, such as Tom Cruise, Philip Baker Hall, or Jason Robards, were United States Navy Combat veterans in World War II.\n",
955 |       "\n",
956 |       "[[ ## tool_name_2 ## ]]\n",
957 |       "search_wikipedia\n",
958 |       "\n",
959 |       "[[ ## tool_args_2 ## ]]\n",
960 |       "{\"query\": \"Jason Robards military service\"}\n",
961 |       "\n",
962 |       "[[ ## observation_2 ## ]]\n",
963 |       "[1] «Jason Robards | Jason Nelson Robards Jr. (July 26, 1922 – December 26, 2000) was an American stage, film, and television actor. He was a winner of the Tony Award, two Academy Awards and an Emmy Award. He was also a United States Navy combat veteran of World War II.»\n",
964 |       "[2] «Jason Robards Sr. | Jason Nelson Robards Sr. (December 31, 1892 – April 4, 1963) was an American stage and screen actor, and the father of Oscar-winning actor Jason Robards Jr. Robards appeared in many films, initially as a leading man, then in character roles and occasional bits. Most of his final roles were in television.»\n",
965 |       "[3] «Jason Wingard | Jason Wingard, Ph.D. (born December 13, 1971) is Dean and Professor of the School of Professional Studies (SPS) at Columbia University. He is a leading academic and executive in the areas of leadership development, professional learning, and human capital management. As part of this work, he has 1) authored several books; 2) provided keynote, speaking, and consulting services to global Fortune 500 organizations, professional events, and conferences; 3) served as a board member and facilitator; and 4) held senior executive roles in corporate, academic, and non-profit organizations.»\n",
966 |       "[4] «Jason Torpy | Jason Torpy is president of the Military Association of Atheists and Freethinkers (MAAF), an advocacy group focused on non-religious service members and veterans. He is a veteran of the U.S. Army and a Humanist Celebrant who works to increase the visibility of \"atheists in foxholes\".»\n",
967 |       "[5] «Jason Dunkerley | Jason Joseph Dunkerley (born August 21, 1977, Newtownards, Northern Ireland) is a Canadian Paralympian athlete competing mainly in category T11 and T12 middle distance events.»\n",
968 |       "[6] «Other retrieved pages have titles: `Jase Daniels`, `Jason Dunham`, `Jason Schauble`, `Frederick C. Billard`, `Wilfred C. Menard, Jr.`, `Jason Millard`, `George C. Rickards`, `Jason Amerine`, `USS Jason (AR-8)`, `Rob (dog)`, `USS Jason Dunham`, `Robert Lee Bullard`, `Jason Chee (para-athlete)`, `The War Between Men and Women`, `Thomas Byard`, `Ralph Baker (general)`, `Jason Lamont`, `Jason Rother incident`, `William H. G. Bullard`, `Sidney Gerald Burrard`, `Jason Gilardi`, `Reunion (1989 film)`, `JASON (advisory group)`, `The Great American West`, `Samuel Robison`.»\n",
969 |       "\n",
970 |       "Respond with the corresponding output fields, starting with the field `[[ ## next_thought ## ]]`, then `[[ ## next_tool_name ## ]]` (must be formatted as a valid Python Literal[search_wikipedia, lookup_wikipedia, finish]), then `[[ ## next_tool_args ## ]]` (must be formatted as a valid Python dict[str, Any]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
971 |       "\n",
972 |       "\n",
973 |       "\u001b[31mAssistant message:\u001b[0m\n",
974 |       "\n",
975 |       "[[ ## next_thought ## ]]\n",
976 |       "I have confirmed that Jason Robards, an actor in the film \"Magnolia,\" was a United States Navy combat veteran of World War II. Since \"Magnolia\" was awarded The Golden Bear at the 50th Berlin International Film Festival, this satisfies the claim. I can now finish with the relevant Wikipedia titles.\n",
977 |       "\n",
978 |       "[[ ## next_tool_name ## ]]\n",
979 |       "finish\n",
980 |       "\n",
981 |       "[[ ## next_tool_args ## ]]\n",
982 |       "{}\n",
983 |       "\n",
984 |       "[[ ## completed ## ]]\n",
985 |       "\n",
986 |       "\n",
987 |       "\u001b[31mUser message:\u001b[0m\n",
988 |       "\n",
989 |       "[[ ## claim ## ]]\n",
990 |       "The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\n",
991 |       "\n",
992 |       "[[ ## trajectory ## ]]\n",
993 |       "[[ ## thought_0 ## ]]\n",
994 |       "To verify the claim, I need to identify the playwrights who wrote the unproduced script for \"Up Against It\" and \"The Beatles\".\n",
995 |       "\n",
996 |       "[[ ## tool_name_0 ## ]]\n",
997 |       "search_wikipedia\n",
998 |       "\n",
999 |       "[[ ## tool_args_0 ## ]]\n",
1000 |       "{\"query\": \"Up Against It script writer Bernard-Marie Koltès\"}\n",
1001 |       "\n",
1002 |       "[[ ## observation_0 ## ]]\n",
1003 |       "[1] «Bernard-Marie Koltès | Bernard-Marie Koltès (] ; 9 April 1948 – 15 April 1989) was a French playwright and theatre director best known for his plays \"La Nuit juste avant les Forêts\" (\"The Night Just Before the Forests\", 1976), \"Sallinger\" (1977) and \"Dans la Solitude des Champs de Coton\" (\"In the Solitude of Cotton Fields\", 1986).»\n",
1004 |       "[2] «In the Solitude of Cotton Fields | In the Solitude of Cotton Fields is a play written by Bernard Marie Koltès in 1985. It is a two-person play involving The Client and Dealer. They negotiate a deal on the streets late at night. The play moves through mutual solitude with the Dealer unable to sell and the Client unable to buy. It’s never clear what each character has to offer each other. Koltès is interested in negotiation, power and violence and the way we treat each other.»\n",
1005 |       "[3] «Bernard Toublanc-Michel | Bernard Toublanc-Michel (born 6 December 1927) is a French film director and screenwriter. His 1964 film \"La Difficulté d'être infidèle\" was entered into the 14th Berlin International Film Festival.»\n",
1006 |       "[4] «Not For, or Against | Not For, or Against (Quite the Contrary) (original title: Ni pour, ni contre (bien au contraire)) is a 2003 French crime drama film directed and co-written by Cédric Klapisch. It stars Marie Gillain and Vincent Elbaz.»\n",
1007 |       "[5] «Bernard Comment | Bernard Comment (born April 20, 1960) is a Swiss writer, translator, scriptwriter, and publisher of books.»\n",
1008 |       "[6] «Other retrieved pages have titles: `Wrong (film)`, `Bernard Bellefroid`, `Too Beautiful for You`, `Bernard Paul`, `Jean-Jacques Bernard`, `Anahareo`, `Bernard Émond`, `Bernard Nabonne`, `Marie-Christine Bernard`, `Bernard Giraudeau`, `Bernard Kops`, `Bernard Charlès`, `Bernard Assiniwi`, `Bernard C. Schoenfeld`, `Jean Bernard-Luc`, `Bernard Stora`, `Bernard Quiriny`, `De contemptu mundi`, `Marie Françoise Bernard`, `Marc Bernard`, `Up Against It`, `Bernard Gui`, `Bernard Lecache`, `Bernard Le Nail`, `Bernard Zimmer`.»\n",
1009 |       "\n",
1010 |       "[[ ## thought_1 ## ]]\n",
1011 |       "I have found that Bernard-Marie Koltès wrote the unproduced script for \"Up Against It\". I need to verify if the author of \"Up Against It\" is also a playwright.\n",
1012 |       "\n",
1013 |       "[[ ## tool_name_1 ## ]]\n",
1014 |       "search_wikipedia\n",
1015 |       "\n",
1016 |       "[[ ## tool_args_1 ## ]]\n",
1017 |       "{\"query\": \"Up Against It author\"}\n",
1018 |       "\n",
1019 |       "[[ ## observation_1 ## ]]\n",
1020 |       "[1] «Up Against It | Up Against It is an unproduced script by Joe Orton, written in 1967 for The Beatles at the height of their fame.»\n",
1021 |       "[2] «Up Against It! (Todd Rundgren album) | Up Against It! is a 1997 album by Todd Rundgren, essentially consisting of Rundgren's song demos for the Off Broadway show that were Written and Recorded by Todd from 1986-88. The project was inspired by the never-produced Up Against It which was a play originally written by Joe Orton for The Beatles.»\n",
1022 |       "[3] «Up Against It (album) | Up Against It is the fifth album by West London Post punk and Indie band The Times released in 1986.»\n",
1023 |       "[4] «Up Against It (1912 film) | The 1912 American short film Up Against It is a romantic comedy directed by Otis Turner and starring King Baggot. It was produced by the Independent Moving Pictures (IMP) Company of New York.»\n",
1024 |       "[5] «Against the Odds (novel) | Against the Odds is a science fiction novel by Elizabeth Moon. It is her seventh and last novel set in the Familias Regnant fictional universe. It does not fall in either informal trilogy (the Heris Serrano and the Esmay Suiza trilogies); fittingly it does not focus on any particular character, instead a more general, almost kaleidoscopic perspective of the upheaval in the Familias Regnant, and the rise to power of a new and more capable Speaker. It can be seen as a conclusion to the series, resolving or at least making a good start at resolving many issues and peoples and ending as it does on a memorializing elegiac note.»\n",
1025 |       "[6] «Other retrieved pages have titles: `Against All Things Ending`, `Mark Greif`, `The Man Who Wouldn't Stand Up`, `Against the Day`, `Against a Dark Background`, `Against the Day (1999)`, `Against Happiness`, `Seventeen Against the Dealer`, `Against Our Will`, `Fredy Perlman`, `The Case Against Barack Obama`, `Against the Fall of Night`, `Against Therapy`, `The War Against the Assholes`, `Thirteen Against Fate`, `Hollywood, Interrupted`, `The Opposing Shore`, `Tim Weiner`, `Against Democracy`, `Against Equality of Opportunity`, `H. P. Lovecraft: Against the World, Against Life`, `Against All Enemies`, `Against All Enemies (novel)`, `The Plot Against America`, `Resistance (creativity)`.»\n",
1026 |       "\n",
1027 |       "[[ ## thought_2 ## ]]\n",
1028 |       "I have confirmed that the author of the unproduced script for \"Up Against It\" is Joe Orton, a playwright.\n",
1029 |       "\n",
1030 |       "[[ ## tool_name_2 ## ]]\n",
1031 |       "lookup_wikipedia\n",
1032 |       "\n",
1033 |       "[[ ## tool_args_2 ## ]]\n",
1034 |       "{\"title\": \"Joe Orton\"}\n",
1035 |       "\n",
1036 |       "[[ ## observation_2 ## ]]\n",
1037 |       "John Kingsley \"Joe\" Orton (1 January 1933 – 9 August 1967) was an English playwright and author. His public career was short but prolific, lasting from 1964 until his death three years later. During this brief period he shocked, outraged, and amused audiences with his scandalous black comedies. The adjective \"Ortonesque\" is sometimes used to refer to work characterised by a similarly dark yet farcical cynicism.\n",
1038 |       "\n",
1039 |       "Respond with the corresponding output fields, starting with the field `[[ ## next_thought ## ]]`, then `[[ ## next_tool_name ## ]]` (must be formatted as a valid Python Literal[search_wikipedia, lookup_wikipedia, finish]), then `[[ ## next_tool_args ## ]]` (must be formatted as a valid Python dict[str, Any]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1040 |       "\n",
1041 |       "\n",
1042 |       "\u001b[31mResponse:\u001b[0m\n",
1043 |       "\n",
1044 |       "\u001b[32m[[ ## next_thought ## ]]\n",
1045 |       "I have identified both playwrights as Bernard-Marie Koltès and Joe Orton, who both wrote the unproduced script for \"Up Against It\".\n",
1046 |       "\n",
1047 |       "[[ ## next_tool_name ## ]]\n",
1048 |       "finish\n",
1049 |       "\n",
1050 |       "[[ ## next_tool_args ## ]]\n",
1051 |       "{}\n",
1052 |       "\n",
1053 |       "[[ ## completed ## ]]\u001b[0m\n",
1054 |       "\n",
1055 |       "\n",
1056 |       "\n",
1057 |       "\n",
1058 |       "\n",
1059 |       "\u001b[34m[2024-12-17T15:13:27.562128]\u001b[0m\n",
1060 |       "\n",
1061 |       "\u001b[31mSystem message:\u001b[0m\n",
1062 |       "\n",
1063 |       "Your input fields are:\n",
1064 |       "1. `claim` (str)\n",
1065 |       "2. `trajectory` (str)\n",
1066 |       "\n",
1067 |       "Your output fields are:\n",
1068 |       "1. `reasoning` (str)\n",
1069 |       "2. `titles` (list[str])\n",
1070 |       "\n",
1071 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
1072 |       "\n",
1073 |       "[[ ## claim ## ]]\n",
1074 |       "{claim}\n",
1075 |       "\n",
1076 |       "[[ ## trajectory ## ]]\n",
1077 |       "{trajectory}\n",
1078 |       "\n",
1079 |       "[[ ## reasoning ## ]]\n",
1080 |       "{reasoning}\n",
1081 |       "\n",
1082 |       "[[ ## titles ## ]]\n",
1083 |       "{titles}        # note: the value you produce must be pareseable according to the following JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
1084 |       "\n",
1085 |       "[[ ## completed ## ]]\n",
1086 |       "\n",
1087 |       "In adhering to this structure, your objective is: \n",
1088 |       "        You are a fact-checking assistant tasked with verifying or refuting claims using Wikipedia as your primary source. Your goal is to identify all relevant Wikipedia titles that can help substantiate or invalidate the given claim. Approach the task by reasoning through the claim step-by-step, using your knowledge to determine the best tools for gathering evidence. Utilize the available tools to search for and look up Wikipedia articles, and compile a list of titles that are pertinent to the claim. Finish the process by ensuring the list of titles accurately reflects the information needed to assess the claim's validity.\n",
1089 |       "\n",
1090 |       "\n",
1091 |       "\u001b[31mUser message:\u001b[0m\n",
1092 |       "\n",
1093 |       "[[ ## claim ## ]]\n",
1094 |       "1990 Film that Khiladiyon Ka Khiladi is loosely based on stars this actor who is best known for martial arts action films.\n",
1095 |       "\n",
1096 |       "[[ ## trajectory ## ]]\n",
1097 |       "[[ ## thought_0 ## ]]\n",
1098 |       "To verify the claim, I need to identify the 1990 film that \"Khiladiyon Ka Khiladi\" is loosely based on and the actor known for martial arts action films who starred in it. I will start by searching for information on \"Khiladiyon Ka Khiladi\" to find details about its inspiration.\n",
1099 |       "\n",
1100 |       "[[ ## tool_name_0 ## ]]\n",
1101 |       "search_wikipedia\n",
1102 |       "\n",
1103 |       "[[ ## tool_args_0 ## ]]\n",
1104 |       "{\"query\": \"Khiladiyon Ka Khiladi\"}\n",
1105 |       "\n",
1106 |       "[[ ## observation_0 ## ]]\n",
1107 |       "[1] «Khiladiyon Ka Khiladi | Khiladiyon Ka Khiladi (English: Player of Players) is a 1996 Indian action film starring Rekha in her first villain role, Akshay Kumar, Raveena Tandon and former WWE wrestlers \"Crush\" and Brian Lee as \"The Undertaker\". It was the 5th highest grossing movie of the year 1996 and was declared 'SuperHit' by Box Office India. It was the fourth installment in the Khiladi (film series). The movie is loosely based based on Hollywood film Lionheart»\n",
1108 |       "[2] «Khiladi 420 | Khiladi 420 (English: \"Con Player\") is an Indian Hindi action film directed by Neeraj Vora and starring Akshay Kumar and Mahima Chaudhry. The film was written by Uttam Gudda and released on 29 December 2000. It is the seventh installment in the \"Khiladi\" series starring Kumar, which included \"Khiladi\" (1992), \"Main Khiladi Tu Anari\" (1994), \"Sabse Bada Khiladi\" (1995), \"Khiladiyon Ka Khiladi\" (1996), \"Mr. and Mrs. Khiladi\" (1997) and \"International Khiladi\" (1999).»\n",
1109 |       "[3] «Khiladi (1992 film) | Khiladi (English: \"Player\" ) is a 1992 Indian suspense thriller film directed by Abbas Mustan. The film was Akshay Kumar's breakthrough role and also stars Ayesha Jhulka, Deepak Tijori, Sabeeha. While Prem Chopra, Shakti Kapoor, Anant Mahadevan and Johnny Lever played supporting roles. \"Khiladi\" was the first installment in the Khiladi (film series) which had \"Khiladi\" in the title and Akshay Kumar in the leading role. It was followed by \"Main Khiladi Tu Anari\" (1994), \"Sabse Bada Khiladi\" (1995), \"Khiladiyon Ka Khiladi\" (1996), \"Mr. and Mrs. Khiladi\" (1997), \"International Khiladi\" (1999), \"Khiladi 420\"(2000) and \"Khiladi 786\" (2012). Khiladi was critically and commercially success at the box-office and the tenth highest grossing film of 1992. It was Akshay Kumar's first successful movie and was declared a \"Super Hit\" at the box office. The basic premise of the story is similar to 1975 released movie Khel Khel Mein starring Rishi Kapoor and Neetu Singh. The film was remade in Kannada as \"Aata Hudugaata\".»\n",
1110 |       "[4] «Khiladi (film series) | Khiladi series is a Bollywood action film series starring Akshay Kumar in the lead role. However, unlike other film series, other than having Akshay Kumar in lead role, and other than having the word \"Khiladi\" in the title, these films have nothing in common. The producers, directors and stories of these films are totally different. \" Khiladi\" (1992) was the first in a series of films which had Akshay Kumar in the title role and gave it his first breakthrough role. It was followed by \"Main Khiladi Tu Anari\" (1994), \"Sabse Bada Khiladi\" (1995), \"Khiladiyon Ka Khiladi\" (1996), \"Mr. and Mrs. Khiladi\" (1997), \"International Khiladi\" (1999) and \"Khiladi 420\" (2000), all featuring Kumar in the lead role. The latest film in the franchise is \"Khiladi 786\" (2012).»\n",
1111 |       "[5] «Khiladi 786 | Khiladi 786 (खिलाड़ी 786) is a 2012 Indian Hindi Punjabi action comedy film directed by Ashish R Mohan, featuring Akshay Kumar in the title role alongside Asin playing the female lead. It features Himesh Reshammiya, Mithun Chakraborty, Raj Babbar and Mukesh Rishi in supporting roles. The film marks the return of Akshay Kumar to his \"Khiladi\" series after 12 years. It is mostly shot in Mumbai and Punjab. Khiladi786 is AkshayKumar 100th film.»\n",
1112 |       "[6] «Other retrieved pages have titles: `Khiladi (2013 film)`, `Khiladi (1968 film)`, `International Khiladi`, `Khatron Ke Khiladi (1988 film)`, `Khatron Ke Khiladi (2001 film)`, `Umesh Mehra`, `Shatranj ke Khiladi`, `Main Khiladi Tu Anari`, `Fear Factor: Khatron Ke Khiladi (season 7)`, `Fear Factor: Khatron Ke Khiladi`, `Mr. and Mrs. Khiladi`, `Sabse Bada Khiladi`, `Ek Khiladi Bawan Pattey`, `Ek Khiladi Ek Haseena (TV series)`, `Do Khiladi`, `Ek Khiladi Ek Haseena (film)`, `Khel Khilari Ka`, `Fear Factor: Khatron Ke Khiladi (season 8)`, `Fear Factor: Khatron Ke Khiladi Darr Ka Blockbuster`, `Khilona (1942 film)`, `Fear Factor: Khatron Ke Khiladi Darr Ka Blockbuster Returns`, `Chhota Bheem: Dholakpur ke Khiladi`, `Khilani`, `Kandireega`, `Khilaaf`.»\n",
1113 |       "\n",
1114 |       "[[ ## thought_1 ## ]]\n",
1115 |       "The search results indicate that \"Khiladiyon Ka Khiladi\" is loosely based on the Hollywood film \"Lionheart\". I should now verify which actor, known for martial arts action films, starred in \"Lionheart\".\n",
1116 |       "\n",
1117 |       "[[ ## tool_name_1 ## ]]\n",
1118 |       "search_wikipedia\n",
1119 |       "\n",
1120 |       "[[ ## tool_args_1 ## ]]\n",
1121 |       "{\"query\": \"Lionheart 1990 film\"}\n",
1122 |       "\n",
1123 |       "[[ ## observation_1 ## ]]\n",
1124 |       "[1] «Lionheart (1990 film) | Lionheart (also known as Wrong Bet, A.W.O.L.: Absent Without Leave, Leon and Full Contact) is a 1990 action film, directed by Sheldon Lettich, starring Jean-Claude Van Damme and co-starring Brian Thompson, along with Harrison Page, Deborah Rennard, Lisa Pelikan, and Ashley Johnson.»\n",
1125 |       "[2] «Truly, Madly, Deeply | Truly, Madly, Deeply is a 1990 British fantasy drama film made for the BBC's \"Screen Two\" series, by BBC Films, Lionheart and Winston Pictures. The film, written and directed by Anthony Minghella, stars Juliet Stevenson and Alan Rickman.»\n",
1126 |       "[3] «Lionheart (1987 film) | Lionheart, also known as Lionheart: The Children's Crusade, is a 1987 adventure film directed by Franklin J. Schaffner and produced by Talia Shire and Stanley O'Toole. Shire's brother, Francis Ford Coppola, initially planned to direct the film but instead opted to be executive producer along with Shire's husband, Jack Schwartzman. The screenplay was written by Menno Meyjes and Richard Outten from a story by Meyjes. The composer Jerry Goldsmith wrote the score. The film was released in August 1987. It was distributed by Orion Pictures.»\n",
1127 |       "[4] «Lionheart (2016 film) | Lionheart is a 2016 American boxing film short written and produced by Oscar DeRosa and Orlando Cicilia III. The film stars Oscar DeRosa and Marc Macaulay. The film portrays struggling professional boxer Max Rossi who is finally presented with the fight he's been waiting for that will launch his career to the next level but when he is suddenly confronted with a life-changing opportunity he must decide which path to take.»\n",
1128 |       "[5] «Richard the Lionheart (2013 film) | Richard The Lionheart is a 2013 film, starring Chandler Maness as Richard the Lionheart, Malcolm McDowell as King Henry II and Andrea Zirio as Henry the Young.»\n",
1129 |       "[6] «Other retrieved pages have titles: `Richard the Lionheart: Rebellion`, `The Brothers Lionheart (1977 film)`, `Kodama Simham`, `Jean-Claude Van Damme`, `Lionsheart`, `A Day for Lionhearts`, `The Lion in Winter (1968 film)`, `Lion Jagapathi Rao`, `Theatre of Blood`, `Young Lions (album)`, `Richard the Lion-Hearted (1923 film)`, `Bullseye! (1990 film)`, `Fear (1990 film)`, `The Guard (1990 film)`, `Ironheart`, `The Guardian (1990 film)`, `Tiger Cage 2`, `Lion Rampant (game publisher)`, `Success (1991 film)`, `Lion in the Streets`, `The King of the Kickboxers`, `Lionheart (video game)`, `Richard the Lionheart (TV series)`, `Dermot Walsh`, `Lars Söderdahl`.»\n",
1130 |       "\n",
1131 |       "[[ ## thought_2 ## ]]\n",
1132 |       "The search results confirm that the 1990 film \"Lionheart\" stars Jean-Claude Van Damme, who is well-known for his martial arts action films. This information aligns with what is needed to verify the claim. I now have the relevant titles related to the claim: \"Khiladiyon Ka Khiladi\" and \"Lionheart.\"\n",
1133 |       "\n",
1134 |       "[[ ## tool_name_2 ## ]]\n",
1135 |       "finish\n",
1136 |       "\n",
1137 |       "[[ ## tool_args_2 ## ]]\n",
1138 |       "{}\n",
1139 |       "\n",
1140 |       "[[ ## observation_2 ## ]]\n",
1141 |       "Completed.\n",
1142 |       "\n",
1143 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1144 |       "\n",
1145 |       "\n",
1146 |       "\u001b[31mAssistant message:\u001b[0m\n",
1147 |       "\n",
1148 |       "[[ ## reasoning ## ]]\n",
1149 |       "The claim suggests that the 1990 film which \"Khiladiyon Ka Khiladi\" is loosely based on stars an actor known for martial arts action films. Upon investigation, \"Khiladiyon Ka Khiladi\" is indeed loosely based on the Hollywood film \"Lionheart\". The 1990 film \"Lionheart\" stars Jean-Claude Van Damme, who is recognized for his roles in martial arts action films. This information supports the claim.\n",
1150 |       "\n",
1151 |       "[[ ## titles ## ]]\n",
1152 |       "[\"Khiladiyon Ka Khiladi\", \"Lionheart (1990 film)\", \"Jean-Claude Van Damme\"]\n",
1153 |       "\n",
1154 |       "[[ ## completed ## ]]\n",
1155 |       "\n",
1156 |       "\n",
1157 |       "\u001b[31mUser message:\u001b[0m\n",
1158 |       "\n",
1159 |       "[[ ## claim ## ]]\n",
1160 |       "Both the Chengiopanax sciadophylloides and Amaryllis are genus.\n",
1161 |       "\n",
1162 |       "[[ ## trajectory ## ]]\n",
1163 |       "[[ ## thought_0 ## ]]\n",
1164 |       "To verify the claim, I need to search for information regarding both \"Chengiopanax sciadophylloides\" and \"Amaryllis\" to see if they are indeed classified as genus.\n",
1165 |       "\n",
1166 |       "[[ ## tool_name_0 ## ]]\n",
1167 |       "search_wikipedia\n",
1168 |       "\n",
1169 |       "[[ ## tool_args_0 ## ]]\n",
1170 |       "{\"query\": \"Chengiopanax sciadophylloides\"}\n",
1171 |       "\n",
1172 |       "[[ ## observation_0 ## ]]\n",
1173 |       "[1] «Chengiopanax sciadophylloides | Chengiopanax sciadophylloides is a flowering tree in the family Araliaceae native to Japan. Previously included in the genus \"Eleutherococcus\", it is distinguished from other members of that genus by not having spines or prickles and ITS sequence data confirmed the separation.»\n",
1174 |       "[2] «Hunaniopanax hypoglaucus | Hunaniopanax hypoglaucus is a species of flowering plant of family Araliaceae, and the only species of genus Hunanioglaucus, named after the Chinese province of Hunan. Some authorities suggest merging this species into the genus \"Aralia\".»\n",
1175 |       "[3] «Cortinarius caesiophylloides | Cortinarius caesiophylloides is a species of fungus in the large mushroom genus \"Cortinarius\" (subgenus \"Phlegmacium\"). Found in Fennoscandia, where it grows on the ground in mesic coniferous forests, it was described as new to science in 2014. The specific epithet \"caesiophylloides\" alludes to both its similarity to \"Cortinarius multiformis\" var. \"caesiophyllus\" (now named \"C. caesiolamellatus\"), and the bluish tints in the gills. It has since been found in Slovakia.»\n",
1176 |       "[4] «Merrilliopanax | Merrilliopanax is a genus of flowering plant of family Araliaceae, comprising 3 species of the sub-genus Airampora. They are found in western China, Myanmar, northeast India, Bhutan, and Nepal.»\n",
1177 |       "[5] «Schefflera morototoni | Schefflera morototoni (yagrumo macho; syn. \"Didymopanax morototoni\" (Aubl. ) Decne. & Planch. , \"Didymopanax morototoni\" var. \"angustipetalum\" March; \"Panax morototoni\" Aublet; \"Sciadophyllum paniculatum\" Britton ) is a timber tree native to southern Mexico, the Greater Antilles, Central America, and South America. It grows in a variety of habitats, such as the Caatinga, Cerrado, and Amazon Rainforest of Brazil.»\n",
1178 |       "[6] «Other retrieved pages have titles: `Merrilliopanax chinensis`, `Harmsiopanax ingens`, `Gunniopsis zygophylloides`, `Merrilliopanax alpinus`, `Sciadophyton`, `Sinopanax formosanus`, `Tabelliscolex`, `Tetragonia tetragonioides`, `Chengjiangocaris`, `Wan Chun Cheng`, `Cheng Weigao`, `Chengguan, Chamdo`, `Nocardioides panzhihuensis`, `Cardiodictyon`, `Scyphiphora`, `Puschkinia scilloides`, `Liao Chengzhi`, `Lilaea scilloides`, `Chenggao`, `Chengjiao Subdistrict, Ningxiang`, `Seioglobal`, `Chengjiangaspis`, `Cheng Shikai`, `Xenocyprioides`, `Chenggong fire belly newt`.»\n",
1179 |       "\n",
1180 |       "[[ ## thought_1 ## ]]\n",
1181 |       "The search results indicate that \"Chengiopanax sciadophylloides\" is described as a flowering tree and doesn't specifically mention it being a genus. It was previously included in the genus \"Eleutherococcus\". To verify the claim, I need to ensure \"Amaryllis\" is classified as a genus.\n",
1182 |       "\n",
1183 |       "[[ ## tool_name_1 ## ]]\n",
1184 |       "search_wikipedia\n",
1185 |       "\n",
1186 |       "[[ ## tool_args_1 ## ]]\n",
1187 |       "{\"query\": \"Amaryllis\"}\n",
1188 |       "\n",
1189 |       "[[ ## observation_1 ## ]]\n",
1190 |       "[1] «Amaryllis (disambiguation) | Amaryllis is a small genus of flowering bulbs, with two species.»\n",
1191 |       "[2] «Amaryllis | Amaryllis ( ) is the only genus in the subtribe Amaryllidinae (tribe Amaryllideae). It is a small genus of flowering bulbs, with two species. The better known of the two, \"Amaryllis belladonna\", is a native of the Western Cape region of South Africa, particularly the rocky southwest area between the Olifants River Valley to Knysna. For many years there was confusion among botanists over the generic names \"Amaryllis\" and \"Hippeastrum\", one result of which is that the common name \"amaryllis\" is mainly used for cultivars of the genus \"Hippeastrum\", widely sold in the winter months for their ability to bloom indoors. Plants of the genus \"Amaryllis\" are known as belladonna lily, Jersey lily, naked lady, amarillo, Easter lily in Southern Australia or, in South Africa, March lily due to its propensity to flower around March. This is one of numerous genera with the common name \"lily\" due to their flower shape and growth habit. However, they are only distantly related to the true lily, \"Lilium\".»\n",
1192 |       "[3] «Amaryllis (given name) | Amaryllis (Αμαρυλλίς) is a female ancient Greek name and means \"sparkling\". According the mythology, the name of the beautiful flower Amaryllis derived from the nymph Amaryllis.»\n",
1193 |       "[4] «Amaryllidaceae | The Amaryllidaceae are a family of herbaceous, mainly perennial and bulbous (rarely rhizomatous) flowering plants in the monocot order Asparagales. The family takes its name from the genus \"Amaryllis\" and is commonly known as the amaryllis family. The leaves are usually linear, and the flowers are usually bisexual and symmetrical, arranged in umbels on the stem. The petals and sepals are undifferentiated as tepals, which may be fused at the base into a floral tube. Some also display a corona. Allyl sulfide compounds produce the characteristic odour of the onion subfamily (Allioideae).»\n",
1194 |       "[5] «Amaryllis paradisicola | Amaryllis paradisicola is a species of bulbous perennial plant from South Africa.»\n",
1195 |       "[6] «Other retrieved pages have titles: `Amaryllis (catamaran)`, `Amaryllis (yacht)`, `Amaryllis belladonna`, `Schinia amaryllis`, `Hippeastrum reticulatum`, `Pirangoclytus amaryllis`, `Amaryllis (ship)`, `Hippeastrum psittacinum`, `Ogyris amaryllis`, `Amaryllis (Shinedown album)`, `Amaryllis (restaurant)`, `1085 Amaryllis`, `Apatelodes amaryllis`, `Premolis amaryllis`, `Amaryllideae`, `Amaryllis Garnett`, `Amaryllis Chamber Ensemble`, `Amaryllis Fleming`, `Brithys crini`, `Amaryllis (Marilyn Crispell, Gary Peacock and Paul Motian album)`, `Amarylloidinae`, `Amaryllidoideae`, `Amaryllis Night and Day`, `Amaryllididae`, `Aecidium amaryllidis`.»\n",
1196 |       "\n",
1197 |       "[[ ## thought_2 ## ]]\n",
1198 |       "The search results confirm that \"Amaryllis\" is a genus, specifically a small genus of flowering bulbs. However, the earlier results for \"Chengiopanax sciadophylloides\" do not confirm it as a genus; it is described more as a species of flowering tree. Therefore, Chengiopanax sciadophylloides might not be a genus itself but belongs to a different classification. I will now verify if \"Chengiopanax\" itself is recognized as a genus.\n",
1199 |       "\n",
1200 |       "[[ ## tool_name_2 ## ]]\n",
1201 |       "search_wikipedia\n",
1202 |       "\n",
1203 |       "[[ ## tool_args_2 ## ]]\n",
1204 |       "{\"query\": \"Chengiopanax\"}\n",
1205 |       "\n",
1206 |       "[[ ## observation_2 ## ]]\n",
1207 |       "[1] «Chengiopanax sciadophylloides | Chengiopanax sciadophylloides is a flowering tree in the family Araliaceae native to Japan. Previously included in the genus \"Eleutherococcus\", it is distinguished from other members of that genus by not having spines or prickles and ITS sequence data confirmed the separation.»\n",
1208 |       "[2] «Hunaniopanax hypoglaucus | Hunaniopanax hypoglaucus is a species of flowering plant of family Araliaceae, and the only species of genus Hunanioglaucus, named after the Chinese province of Hunan. Some authorities suggest merging this species into the genus \"Aralia\".»\n",
1209 |       "[3] «Merrilliopanax | Merrilliopanax is a genus of flowering plant of family Araliaceae, comprising 3 species of the sub-genus Airampora. They are found in western China, Myanmar, northeast India, Bhutan, and Nepal.»\n",
1210 |       "[4] «Xiaxue | Cheng Yan Yan Wendy (born Cheng Yan Yan; 28 April 1984), better known by her pseudonym Xiaxue, is a Singaporean blogger and online television personality who writes about her life, fashion and local issues in a provocative style. Her main blog, which attracts about 50,000 readers daily, has won prestigious blog awards and earned her sponsorship deals, as well as stints as a columnist and TV show host, but some of her posts have sparked national controversies. She is married to American engineer Mike Sayre and they have one child.»\n",
1211 |       "[5] «Sinopanax formosanus | Sinopanax formosanus is a species of flowering plant of family Araliaceae and the only species of genus Sinopanax. It is endemic to Taiwan. It is a small, evergreen tree, up to 12 m in height, that grows in open areas in mountainous forests at altitudes between 2300 - .»\n",
1212 |       "[6] «Other retrieved pages have titles: `Merrilliopanax chinensis`, `Linpan in Chengdu Plain`, `Pan Chengdong`, `Merrilliopanax alpinus`, `Pan Cheng-tsung`, `Pan Chengyou`, `Seioglobal`, `Harmsiopanax ingens`, `Kalopanax`, `Cheng Jiao`, `Chengo`, `Chengguan, Chamdo`, `Chenguang`, `Chenggao`, `Chengdu University of Information Technology`, `Chengai Sivam`, `Chênggo`, `Cheng Weigao`, `Cheng Xunzhao`, `Gan Peck Cheng`, `Cheng Hong`, `Chengdu Qianbao F.C.`, `Cheng I`, `Cheng Yu-tung`, `Sun Chengyao`.»\n",
1213 |       "\n",
1214 |       "[[ ## thought_3 ## ]]\n",
1215 |       "The search results do not definitively confirm \"Chengiopanax\" as a genus, rather they focus on the species \"Chengiopanax sciadophylloides\" which was previously part of the \"Eleutherococcus\" genus. There is no clear indication in the search results that \"Chengiopanax\" is recognized as a genus. To ensure a comprehensive understanding, I will look up the \"Chengiopanax sciadophylloides\" page directly to see if there is further clarification on its classification as a genus.\n",
1216 |       "\n",
1217 |       "[[ ## tool_name_3 ## ]]\n",
1218 |       "lookup_wikipedia\n",
1219 |       "\n",
1220 |       "[[ ## tool_args_3 ## ]]\n",
1221 |       "{\"title\": \"Chengiopanax sciadophylloides\"}\n",
1222 |       "\n",
1223 |       "[[ ## observation_3 ## ]]\n",
1224 |       "Chengiopanax sciadophylloides is a flowering tree in the family Araliaceae native to Japan. Previously included in the genus \"Eleutherococcus\", it is distinguished from other members of that genus by not having spines or prickles and ITS sequence data confirmed the separation.\n",
1225 |       "\n",
1226 |       "[[ ## thought_4 ## ]]\n",
1227 |       "The lookup did not provide any new information suggesting that \"Chengiopanax\" is a genus. It seems that \"Chengiopanax sciadophylloides\" is a species and not a genus. On the other hand, \"Amaryllis\" is confirmed to be a genus. Therefore, the claim that both \"Chengiopanax sciadophylloides\" and \"Amaryllis\" are genus is only partially correct. I will now finish with the titles that I have verified.\n",
1228 |       "\n",
1229 |       "[[ ## tool_name_4 ## ]]\n",
1230 |       "finish\n",
1231 |       "\n",
1232 |       "[[ ## tool_args_4 ## ]]\n",
1233 |       "{}\n",
1234 |       "\n",
1235 |       "[[ ## observation_4 ## ]]\n",
1236 |       "Completed.\n",
1237 |       "\n",
1238 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1239 |       "\n",
1240 |       "\n",
1241 |       "\u001b[31mAssistant message:\u001b[0m\n",
1242 |       "\n",
1243 |       "[[ ## reasoning ## ]]\n",
1244 |       "The claim states that both \"Chengiopanax sciadophylloides\" and \"Amaryllis\" are genus. Upon investigation, it was found that \"Chengiopanax sciadophylloides\" is a species of flowering tree, and there is no confirmation that \"Chengiopanax\" itself is a recognized genus. It was previously included in the genus \"Eleutherococcus\". On the other hand, \"Amaryllis\" is confirmed to be a genus, specifically a small genus of flowering bulbs with two species. Therefore, the claim is only partially correct as \"Chengiopanax sciadophylloides\" is not a genus.\n",
1245 |       "\n",
1246 |       "[[ ## titles ## ]]\n",
1247 |       "[\"Amaryllis\", \"Eleutherococcus\", \"Chengiopanax sciadophylloides\"]\n",
1248 |       "\n",
1249 |       "[[ ## completed ## ]]\n",
1250 |       "\n",
1251 |       "\n",
1252 |       "\u001b[31mUser message:\u001b[0m\n",
1253 |       "\n",
1254 |       "[[ ## claim ## ]]\n",
1255 |       "200,000 people go through the airport where the headquarters of the airline that acquired Baboo Airlines are located.\n",
1256 |       "\n",
1257 |       "[[ ## trajectory ## ]]\n",
1258 |       "[[ ## thought_0 ## ]]\n",
1259 |       "I need to identify which airline acquired Baboo Airlines to verify the claim. Once I have the name of the airline, I can find out where its headquarters are located and then look for information on the airport's passenger traffic.\n",
1260 |       "\n",
1261 |       "[[ ## tool_name_0 ## ]]\n",
1262 |       "search_wikipedia\n",
1263 |       "\n",
1264 |       "[[ ## tool_args_0 ## ]]\n",
1265 |       "{\"query\": \"Baboo Airlines acquisition\"}\n",
1266 |       "\n",
1267 |       "[[ ## observation_0 ## ]]\n",
1268 |       "[1] «Baboo (airline) | Fly Baboo SA, marketed as Baboo, was a regional airline based on the grounds of Geneva International Airport and in Grand-Saconnex, Switzerland. In November 2010, the company was saved from bankruptcy and acquired by Darwin Airline Group from Lugano.»\n",
1269 |       "[2] «Okada Air | Okada Air was an airline based in Benin City, Nigeria. The carrier was established in 1983 with a fleet of BAC-One Eleven 300s. and started charter operations in the same year. In 1984, a Boeing 707-355C was acquired for cargo operations. By 1990, ten BAC One-Elevens were bought, and eight more were acquired in 1991. The company was granted the right of operating international flights in 1992.»\n",
1270 |       "[3] «Go (airline) | Go Fly (styled and trading as Go) was the name of a British low-cost airline, founded by British Airways (BA) in 1998. It operated flights between London Stansted Airport and destinations in Europe. The airline was purchased from BA in a management buy-out backed by the private equity firm 3i in 2001. In 2002 it was bought by its rival EasyJet, and was merged into the airline's operations. Its head office was in the Enterprise House in London Stansted Airport in Stansted Mountfitchet, Essex.»\n",
1271 |       "[4] «BAX Global | BAX Global is an American international shipping company that is headquartered in Irvine, California, and has other major offices in Australia, Singapore, London, the Netherlands and Toledo, Ohio. The company which was founded in 1971 also operates an airline. After having been acquired by DB Logistics in January 2006, Bax Global is currently being integrated with Schenker, the land, sea, and air freight branch of DB Logistics. DB Logistics is the freight and logistics division of Deutsche Bahn, the State-owned German railway company.»\n",
1272 |       "[5] «Iloilo-Negros Air Express | Iloilo-Negros Air Express Company, Inc., which operated as Iloilo-Negros Air Express or INAEC and later as FEATI, was an airline based in the Philippines. The airline was folded into the operation of Philippine Airlines (PAL) which was re-nationalized by the Philippine government and became the national flag carrier. The company built the Bacolod International Airport in Bacolod City, which was bought by PAL after the acquisition of the airline.»\n",
1273 |       "[6] «Other retrieved pages have titles: `Babool (brand)`, `British Aircraft Corporation`, `Boeing Aircraft Holding Company`, `Bakhtar Afghan Airlines`, `Baboo destinations`, `Baboo (band)`, `Baboom`, `Bond Aviation Group`, `Mark Darby`, `AGS Airports`, `BA Connect`, `AirMall`, `BAT Baboon`, `National Shipping Company of Saudi Arabia`, `Aviesa`, `British Airways Ltd (2012–15)`, `BA CityFlyer`, `Baboon (album)`, `Qingdao Haili Helicopters`, `Business Express Airlines`, `Babo Airport`, `Baboon lymphocryptovirus`, `BxB`, `British Airways`, `Manchester Airports Group`.»\n",
1274 |       "\n",
1275 |       "[[ ## thought_1 ## ]]\n",
1276 |       "The observation indicates that Baboo Airlines was acquired by Darwin Airline Group. Next, I should search for the headquarters location of Darwin Airline Group to identify the associated airport and find out the passenger traffic.\n",
1277 |       "\n",
1278 |       "[[ ## tool_name_1 ## ]]\n",
1279 |       "search_wikipedia\n",
1280 |       "\n",
1281 |       "[[ ## tool_args_1 ## ]]\n",
1282 |       "{\"query\": \"Darwin Airline Group headquarters\"}\n",
1283 |       "\n",
1284 |       "[[ ## observation_1 ## ]]\n",
1285 |       "[1] «Darwin Airline | Darwin Airline SA is a Swiss regional airline with its head office in Bioggio, Lugano flying under the brand name Adria Airways Switzerland. It has been operating scheduled domestic and international services throughout some western European countries using the brand name Etihad Regional from January 2014 until July 2017 when it was sold from Etihad Airways to Adria Airways as well as formerly also on behalf of Alitalia. Its bases are Geneva Airport and Lugano Airport.»\n",
1286 |       "[2] «Airnorth | Capiteq Limited, trading as Airnorth, is a regional airline based at Darwin International Airport in Darwin, Northern Territory, Australia. It operates scheduled and charter services in the Northern Territory, Queensland, Victoria, Western Australia, and East Timor.»\n",
1287 |       "[3] «Fly Tiwi | Fly Tiwi is an Australian airline based in Darwin, Northern Territory, offering scheduled passenger services between the Northern Territory capital and communities located on the Tiwi, South Goulburn and Croker islands, as well as a number of remote Arnhem Land communities and the town of Tennant Creek. The company is wholly owned by the Hardy Aviation group, Australia's largest general aviation company and was founded in 2008 in association with the Tiwi Land Council and now operates over 50 flights per week between 9 destinations.»\n",
1288 |       "[4] «RAAF Base Darwin | RAAF Base Darwin (IATA: DRW, ICAO: YPDN) is a Royal Australian Air Force (RAAF) military air base located in the city of Darwin, in the Northern Territory, Australia. The base shares its runway with Darwin International Airport, for civil aviation purposes. The heritage-listed RAAF Base Darwin is a forward operating base with year round activity with approximately 400 personnel.»\n",
1289 |       "[5] «Lugano Airport | Lugano Airport (IATA: LUG, ICAO: LSZA) is a regional airport located 4 km west of the Swiss city of Lugano, approximately 80 km north of Milan, in the municipalities of Agno, Bioggio and Muzzano. It lies closer to the village of Agno than to Lugano itself, and is sometimes known as Lugano-Agno. Around 200,000 passengers use the airport each year, using some 2,400 flights. There are also limited freight operations, a flying club and flight school. The headquarters of Darwin Airline are located at the airport.»\n",
1290 |       "[6] «Other retrieved pages have titles: `No. 76 Wing RAAF`, `No. 13 Squadron RAAF`, `Mount Darwin Airport`, `Darwin International Airport`, `Baboo (airline)`, `Virgin Australia Regional Airlines`, `No. 1 Wing RAAF`, `No. 114 Mobile Control and Reporting Unit RAAF`, `Air Austral`, `Tigerair Australia destinations`, `Marine Rotational Force – Darwin`, `Austral Líneas Aéreas`, `Australian Aviation Heritage Centre`, `AirAsia`, `Flight Centre Australia`, `Flight Centre`, `North-Western Area Command (RAAF)`, `No. 5 Fighter Sector RAAF`, `McMillans Road`, `Cobham Aviation Services Australia`, `Asia Pacific Transport Consortium`, `1st Aviation Regiment (Australia)`, `Charles Darwin Foundation`, `Brindabella Airlines`, `Kulula.com`.»\n",
1291 |       "\n",
1292 |       "[[ ## thought_2 ## ]]\n",
1293 |       "The headquarters of Darwin Airline are located at Lugano Airport, which has around 200,000 passengers using the airport each year. This aligns with the claim about the passenger traffic at the airport where the headquarters of the airline that acquired Baboo Airlines are located.\n",
1294 |       "\n",
1295 |       "[[ ## tool_name_2 ## ]]\n",
1296 |       "finish\n",
1297 |       "\n",
1298 |       "[[ ## tool_args_2 ## ]]\n",
1299 |       "{}\n",
1300 |       "\n",
1301 |       "[[ ## observation_2 ## ]]\n",
1302 |       "Completed.\n",
1303 |       "\n",
1304 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1305 |       "\n",
1306 |       "\n",
1307 |       "\u001b[31mAssistant message:\u001b[0m\n",
1308 |       "\n",
1309 |       "[[ ## reasoning ## ]]\n",
1310 |       "The claim states that 200,000 people go through the airport where the headquarters of the airline that acquired Baboo Airlines are located. Through the information found, Baboo Airlines was acquired by Darwin Airline Group. The headquarters of Darwin Airline Group are located at Lugano Airport. Further research revealed that Lugano Airport handles approximately 200,000 passengers per year. This confirms the accuracy of the claim regarding passenger traffic at the airport associated with Darwin Airline Group's headquarters.\n",
1311 |       "\n",
1312 |       "[[ ## titles ## ]]\n",
1313 |       "[\"Baboo (airline)\", \"Darwin Airline\", \"Lugano Airport\"]\n",
1314 |       "\n",
1315 |       "[[ ## completed ## ]]\n",
1316 |       "\n",
1317 |       "\n",
1318 |       "\u001b[31mUser message:\u001b[0m\n",
1319 |       "\n",
1320 |       "[[ ## claim ## ]]\n",
1321 |       "The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\n",
1322 |       "\n",
1323 |       "[[ ## trajectory ## ]]\n",
1324 |       "[[ ## thought_0 ## ]]\n",
1325 |       "To verify the claim, I need to identify the playwrights who wrote the unproduced script for \"Up Against It\" and \"The Beatles\".\n",
1326 |       "\n",
1327 |       "[[ ## tool_name_0 ## ]]\n",
1328 |       "search_wikipedia\n",
1329 |       "\n",
1330 |       "[[ ## tool_args_0 ## ]]\n",
1331 |       "{\"query\": \"Up Against It script writer Bernard-Marie Koltès\"}\n",
1332 |       "\n",
1333 |       "[[ ## observation_0 ## ]]\n",
1334 |       "[1] «Bernard-Marie Koltès | Bernard-Marie Koltès (] ; 9 April 1948 – 15 April 1989) was a French playwright and theatre director best known for his plays \"La Nuit juste avant les Forêts\" (\"The Night Just Before the Forests\", 1976), \"Sallinger\" (1977) and \"Dans la Solitude des Champs de Coton\" (\"In the Solitude of Cotton Fields\", 1986).»\n",
1335 |       "[2] «In the Solitude of Cotton Fields | In the Solitude of Cotton Fields is a play written by Bernard Marie Koltès in 1985. It is a two-person play involving The Client and Dealer. They negotiate a deal on the streets late at night. The play moves through mutual solitude with the Dealer unable to sell and the Client unable to buy. It’s never clear what each character has to offer each other. Koltès is interested in negotiation, power and violence and the way we treat each other.»\n",
1336 |       "[3] «Bernard Toublanc-Michel | Bernard Toublanc-Michel (born 6 December 1927) is a French film director and screenwriter. His 1964 film \"La Difficulté d'être infidèle\" was entered into the 14th Berlin International Film Festival.»\n",
1337 |       "[4] «Not For, or Against | Not For, or Against (Quite the Contrary) (original title: Ni pour, ni contre (bien au contraire)) is a 2003 French crime drama film directed and co-written by Cédric Klapisch. It stars Marie Gillain and Vincent Elbaz.»\n",
1338 |       "[5] «Bernard Comment | Bernard Comment (born April 20, 1960) is a Swiss writer, translator, scriptwriter, and publisher of books.»\n",
1339 |       "[6] «Other retrieved pages have titles: `Wrong (film)`, `Bernard Bellefroid`, `Too Beautiful for You`, `Bernard Paul`, `Jean-Jacques Bernard`, `Anahareo`, `Bernard Émond`, `Bernard Nabonne`, `Marie-Christine Bernard`, `Bernard Giraudeau`, `Bernard Kops`, `Bernard Charlès`, `Bernard Assiniwi`, `Bernard C. Schoenfeld`, `Jean Bernard-Luc`, `Bernard Stora`, `Bernard Quiriny`, `De contemptu mundi`, `Marie Françoise Bernard`, `Marc Bernard`, `Up Against It`, `Bernard Gui`, `Bernard Lecache`, `Bernard Le Nail`, `Bernard Zimmer`.»\n",
1340 |       "\n",
1341 |       "[[ ## thought_1 ## ]]\n",
1342 |       "I have found that Bernard-Marie Koltès wrote the unproduced script for \"Up Against It\". I need to verify if the author of \"Up Against It\" is also a playwright.\n",
1343 |       "\n",
1344 |       "[[ ## tool_name_1 ## ]]\n",
1345 |       "search_wikipedia\n",
1346 |       "\n",
1347 |       "[[ ## tool_args_1 ## ]]\n",
1348 |       "{\"query\": \"Up Against It author\"}\n",
1349 |       "\n",
1350 |       "[[ ## observation_1 ## ]]\n",
1351 |       "[1] «Up Against It | Up Against It is an unproduced script by Joe Orton, written in 1967 for The Beatles at the height of their fame.»\n",
1352 |       "[2] «Up Against It! (Todd Rundgren album) | Up Against It! is a 1997 album by Todd Rundgren, essentially consisting of Rundgren's song demos for the Off Broadway show that were Written and Recorded by Todd from 1986-88. The project was inspired by the never-produced Up Against It which was a play originally written by Joe Orton for The Beatles.»\n",
1353 |       "[3] «Up Against It (album) | Up Against It is the fifth album by West London Post punk and Indie band The Times released in 1986.»\n",
1354 |       "[4] «Up Against It (1912 film) | The 1912 American short film Up Against It is a romantic comedy directed by Otis Turner and starring King Baggot. It was produced by the Independent Moving Pictures (IMP) Company of New York.»\n",
1355 |       "[5] «Against the Odds (novel) | Against the Odds is a science fiction novel by Elizabeth Moon. It is her seventh and last novel set in the Familias Regnant fictional universe. It does not fall in either informal trilogy (the Heris Serrano and the Esmay Suiza trilogies); fittingly it does not focus on any particular character, instead a more general, almost kaleidoscopic perspective of the upheaval in the Familias Regnant, and the rise to power of a new and more capable Speaker. It can be seen as a conclusion to the series, resolving or at least making a good start at resolving many issues and peoples and ending as it does on a memorializing elegiac note.»\n",
1356 |       "[6] «Other retrieved pages have titles: `Against All Things Ending`, `Mark Greif`, `The Man Who Wouldn't Stand Up`, `Against the Day`, `Against a Dark Background`, `Against the Day (1999)`, `Against Happiness`, `Seventeen Against the Dealer`, `Against Our Will`, `Fredy Perlman`, `The Case Against Barack Obama`, `Against the Fall of Night`, `Against Therapy`, `The War Against the Assholes`, `Thirteen Against Fate`, `Hollywood, Interrupted`, `The Opposing Shore`, `Tim Weiner`, `Against Democracy`, `Against Equality of Opportunity`, `H. P. Lovecraft: Against the World, Against Life`, `Against All Enemies`, `Against All Enemies (novel)`, `The Plot Against America`, `Resistance (creativity)`.»\n",
1357 |       "\n",
1358 |       "[[ ## thought_2 ## ]]\n",
1359 |       "I have confirmed that the author of the unproduced script for \"Up Against It\" is Joe Orton, a playwright.\n",
1360 |       "\n",
1361 |       "[[ ## tool_name_2 ## ]]\n",
1362 |       "lookup_wikipedia\n",
1363 |       "\n",
1364 |       "[[ ## tool_args_2 ## ]]\n",
1365 |       "{\"title\": \"Joe Orton\"}\n",
1366 |       "\n",
1367 |       "[[ ## observation_2 ## ]]\n",
1368 |       "John Kingsley \"Joe\" Orton (1 January 1933 – 9 August 1967) was an English playwright and author. His public career was short but prolific, lasting from 1964 until his death three years later. During this brief period he shocked, outraged, and amused audiences with his scandalous black comedies. The adjective \"Ortonesque\" is sometimes used to refer to work characterised by a similarly dark yet farcical cynicism.\n",
1369 |       "\n",
1370 |       "[[ ## thought_3 ## ]]\n",
1371 |       "I have identified both playwrights as Bernard-Marie Koltès and Joe Orton, who both wrote the unproduced script for \"Up Against It\".\n",
1372 |       "\n",
1373 |       "[[ ## tool_name_3 ## ]]\n",
1374 |       "finish\n",
1375 |       "\n",
1376 |       "[[ ## tool_args_3 ## ]]\n",
1377 |       "{}\n",
1378 |       "\n",
1379 |       "[[ ## observation_3 ## ]]\n",
1380 |       "Completed.\n",
1381 |       "\n",
1382 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1383 |       "\n",
1384 |       "\n",
1385 |       "\u001b[31mResponse:\u001b[0m\n",
1386 |       "\n",
1387 |       "\u001b[32m[[ ## reasoning ## ]]\n",
1388 |       "The claim states that the authors of the unproduced script for \"Up Against It\" are both playwrights. Investigation revealed that Bernard-Marie Koltès wrote the unproduced script, and further research confirmed that Joe Orton was also a playwright who wrote the script. Therefore, both playwrights are indeed the authors of the unproduced script for \"Up Against It\".\n",
1389 |       "\n",
1390 |       "[[ ## titles ## ]]\n",
1391 |       "[\"Bernard-Marie Koltès\", \"Joe Orton\"]\n",
1392 |       "\n",
1393 |       "[[ ## completed ## ]]\u001b[0m\n",
1394 |       "\n",
1395 |       "\n",
1396 |       "\n",
1397 |       "\n",
1398 |       "\n"
1399 |      ]
1400 |     }
1401 |    ],
1402 |    "source": [
1403 |     "dspy.inspect_history(n=2)"
1404 |    ]
1405 |   },
1406 |   {
1407 |    "cell_type": "markdown",
1408 |    "metadata": {},
1409 |    "source": [
1410 |     "Finally, let's save our optimized program so we can use it again later."
1411 |    ]
1412 |   },
1413 |   {
1414 |    "cell_type": "code",
1415 |    "execution_count": 18,
1416 |    "metadata": {},
1417 |    "outputs": [
1418 |     {
1419 |      "data": {
1420 |       "text/plain": [
1421 |        "['Bernard-Marie Koltès', 'Joe Orton']"
1422 |       ]
1423 |      },
1424 |      "execution_count": 19,
1425 |      "metadata": {},
1426 |      "output_type": "execute_result"
1427 |     }
1428 |    ],
1429 |    "source": [
1430 |     "optimized_react.save(\"optimized_react.json\")\n",
1431 |     "\n",
1432 |     "loaded_react = dspy.ReAct(\"claim -> titles: list[str]\", tools=[search_wikipedia, lookup_wikipedia], max_iters=20)\n",
1433 |     "loaded_react.load(\"optimized_react.json\")\n",
1434 |     "\n",
1435 |     "loaded_react(claim=\"The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\").titles"
1436 |    ]
1437 |   },
1438 |   {
1439 |    "cell_type": "markdown",
1440 |    "metadata": {},
1441 |    "source": [
1442 |     "<details>\n",
1443 |     "<summary>Saving programs in MLflow Experiment</summary>\n",
1444 |     "\n",
1445 |     "<br/>\n",
1446 |     "\n",
1447 |     "Instead of saving the program to a local file, you can track it in MLflow for better reproducibility and collaboration.\n",
1448 |     "\n",
1449 |     "1. **Dependency Management**: MLflow automatically save the frozen environment metadata along with the program to ensure reproducibility.\n",
1450 |     "2. **Experiment Tracking**: With MLflow, you can track the program's performance and cost along with the program itself.\n",
1451 |     "3. **Collaboration**: You can share the program and results with your team members by sharing the MLflow experiment.\n",
1452 |     "\n",
1453 |     "To save the program in MLflow, run the following code:\n",
1454 |     "\n",
1455 |     "```python\n",
1456 |     "import mlflow\n",
1457 |     "\n",
1458 |     "# Start an MLflow Run and save the program\n",
1459 |     "with mlflow.start_run(run_name=\"optimized_rag\"):\n",
1460 |     "    model_info = mlflow.dspy.log_model(\n",
1461 |     "        optimized_react,\n",
1462 |     "        artifact_path=\"model\", # Any name to save the program in MLflow\n",
1463 |     "    )\n",
1464 |     "\n",
1465 |     "# Load the program back from MLflow\n",
1466 |     "loaded = mlflow.dspy.load_model(model_info.model_uri)\n",
1467 |     "```\n",
1468 |     "\n",
1469 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
1470 |     "\n",
1471 |     "</details>"
1472 |    ]
1473 |   }
1474 |  ],
1475 |  "metadata": {
1476 |   "kernelspec": {
1477 |    "display_name": "jun2024_py310",
1478 |    "language": "python",
1479 |    "name": "python3"
1480 |   },
1481 |   "language_info": {
1482 |    "codemirror_mode": {
1483 |     "name": "ipython",
1484 |     "version": 3
1485 |    },
1486 |    "file_extension": ".py",
1487 |    "mimetype": "text/x-python",
1488 |    "name": "python",
1489 |    "nbconvert_exporter": "python",
1490 |    "pygments_lexer": "ipython3",
1491 |    "version": "3.10.14"
1492 |   }
1493 |  },
1494 |  "nbformat": 4,
1495 |  "nbformat_minor": 2
1496 | }
```

ai_text_game/index.md
```
1 | # Building a Creative Text-Based AI Game with DSPy
2 |
3 | This tutorial demonstrates how to create an interactive text-based adventure game using DSPy's modular programming approach. You'll build a dynamic game where AI handles narrative generation, character interactions, and adaptive gameplay.
4 |
5 | ## What You'll Build
6 |
7 | An intelligent text-based adventure game featuring:
8 |
9 | - Dynamic story generation and branching narratives
10 | - AI-powered character interactions and dialogue
11 | - Adaptive gameplay that responds to player choices
12 | - Inventory and character progression systems
13 | - Save/load game state functionality
14 |
15 | ## Setup
16 |
17 | ```bash
18 | pip install dspy rich typer
19 | ```
20 |
21 | ## Step 1: Core Game Framework
22 |
23 | ```python
24 | import dspy
25 | import json
26 | from typing import Dict, List, Optional, Any
27 | from dataclasses import dataclass, field
28 | from enum import Enum
29 | import random
30 | from rich.console import Console
31 | from rich.panel import Panel
32 | from rich.text import Text
33 | import typer
34 |
35 | # Configure DSPy
36 | lm = dspy.LM(model='openai/gpt-4o-mini')
37 | dspy.configure(lm=lm)
38 |
39 | console = Console()
40 |
41 | class GameState(Enum):
42 |     MENU = "menu"
43 |     PLAYING = "playing"
44 |     INVENTORY = "inventory"
45 |     CHARACTER = "character"
46 |     GAME_OVER = "game_over"
47 |
48 | @dataclass
49 | class Player:
50 |     name: str
51 |     health: int = 100
52 |     level: int = 1
53 |     experience: int = 0
54 |     inventory: list[str] = field(default_factory=list)
55 |     skills: dict[str, int] = field(default_factory=lambda: {
56 |         "strength": 10,
57 |         "intelligence": 10,
58 |         "charisma": 10,
59 |         "stealth": 10
60 |     })
61 |
62 |     def add_item(self, item: str):
63 |         self.inventory.append(item)
64 |         console.print(f"[green]Added {item} to inventory![/green]")
65 |
66 |     def remove_item(self, item: str) -> bool:
67 |         if item in self.inventory:
68 |             self.inventory.remove(item)
69 |             return True
70 |         return False
71 |
72 |     def gain_experience(self, amount: int):
73 |         self.experience += amount
74 |         old_level = self.level
75 |         self.level = 1 + (self.experience // 100)
76 |         if self.level > old_level:
77 |             console.print(f"[bold yellow]Level up! You are now level {self.level}![/bold yellow]")
78 |
79 | @dataclass
80 | class GameContext:
81 |     current_location: str = "Village Square"
82 |     story_progress: int = 0
83 |     visited_locations: list[str] = field(default_factory=list)
84 |     npcs_met: list[str] = field(default_factory=list)
85 |     completed_quests: list[str] = field(default_factory=list)
86 |     game_flags: dict[str, bool] = field(default_factory=dict)
87 |
88 |     def add_flag(self, flag: str, value: bool = True):
89 |         self.game_flags[flag] = value
90 |
91 |     def has_flag(self, flag: str) -> bool:
92 |         return self.game_flags.get(flag, False)
93 |
94 | class GameEngine:
95 |     def __init__(self):
96 |         self.player = None
97 |         self.context = GameContext()
98 |         self.state = GameState.MENU
99 |         self.running = True
100 |
101 |     def save_game(self, filename: str = "savegame.json"):
102 |         """Save current game state."""
103 |         save_data = {
104 |             "player": {
105 |                 "name": self.player.name,
106 |                 "health": self.player.health,
107 |                 "level": self.player.level,
108 |                 "experience": self.player.experience,
109 |                 "inventory": self.player.inventory,
110 |                 "skills": self.player.skills
111 |             },
112 |             "context": {
113 |                 "current_location": self.context.current_location,
114 |                 "story_progress": self.context.story_progress,
115 |                 "visited_locations": self.context.visited_locations,
116 |                 "npcs_met": self.context.npcs_met,
117 |                 "completed_quests": self.context.completed_quests,
118 |                 "game_flags": self.context.game_flags
119 |             }
120 |         }
121 |
122 |         with open(filename, 'w') as f:
123 |             json.dump(save_data, f, indent=2)
124 |         console.print(f"[green]Game saved to {filename}![/green]")
125 |
126 |     def load_game(self, filename: str = "savegame.json") -> bool:
127 |         """Load game state from file."""
128 |         try:
129 |             with open(filename, 'r') as f:
130 |                 save_data = json.load(f)
131 |
132 |             # Reconstruct player
133 |             player_data = save_data["player"]
134 |             self.player = Player(
135 |                 name=player_data["name"],
136 |                 health=player_data["health"],
137 |                 level=player_data["level"],
138 |                 experience=player_data["experience"],
139 |                 inventory=player_data["inventory"],
140 |                 skills=player_data["skills"]
141 |             )
142 |
143 |             # Reconstruct context
144 |             context_data = save_data["context"]
145 |             self.context = GameContext(
146 |                 current_location=context_data["current_location"],
147 |                 story_progress=context_data["story_progress"],
148 |                 visited_locations=context_data["visited_locations"],
149 |                 npcs_met=context_data["npcs_met"],
150 |                 completed_quests=context_data["completed_quests"],
151 |                 game_flags=context_data["game_flags"]
152 |             )
153 |
154 |             console.print(f"[green]Game loaded from {filename}![/green]")
155 |             return True
156 |
157 |         except FileNotFoundError:
158 |             console.print(f"[red]Save file {filename} not found![/red]")
159 |             return False
160 |         except Exception as e:
161 |             console.print(f"[red]Error loading game: {e}![/red]")
162 |             return False
163 |
164 | # Initialize game engine
165 | game = GameEngine()
166 | ```
167 |
168 | ## Step 2: AI-Powered Story Generation
169 |
170 | ```python
171 | class StoryGenerator(dspy.Signature):
172 |     """Generate dynamic story content based on current game state."""
173 |     location: str = dspy.InputField(desc="Current location")
174 |     player_info: str = dspy.InputField(desc="Player information and stats")
175 |     story_progress: int = dspy.InputField(desc="Current story progress level")
176 |     recent_actions: str = dspy.InputField(desc="Player's recent actions")
177 |
178 |     scene_description: str = dspy.OutputField(desc="Vivid description of current scene")
179 |     available_actions: list[str] = dspy.OutputField(desc="List of possible player actions")
180 |     npcs_present: list[str] = dspy.OutputField(desc="NPCs present in this location")
181 |     items_available: list[str] = dspy.OutputField(desc="Items that can be found or interacted with")
182 |
183 | class DialogueGenerator(dspy.Signature):
184 |     """Generate NPC dialogue and responses."""
185 |     npc_name: str = dspy.InputField(desc="Name and type of NPC")
186 |     npc_personality: str = dspy.InputField(desc="NPC personality and background")
187 |     player_input: str = dspy.InputField(desc="What the player said or did")
188 |     context: str = dspy.InputField(desc="Current game context and history")
189 |
190 |     npc_response: str = dspy.OutputField(desc="NPC's dialogue response")
191 |     mood_change: str = dspy.OutputField(desc="How NPC's mood changed (positive/negative/neutral)")
192 |     quest_offered: bool = dspy.OutputField(desc="Whether NPC offers a quest")
193 |     information_revealed: str = dspy.OutputField(desc="Any important information shared")
194 |
195 | class ActionResolver(dspy.Signature):
196 |     """Resolve player actions and determine outcomes."""
197 |     action: str = dspy.InputField(desc="Player's chosen action")
198 |     player_stats: str = dspy.InputField(desc="Player's current stats and skills")
199 |     context: str = dspy.InputField(desc="Current game context")
200 |     difficulty: str = dspy.InputField(desc="Difficulty level of the action")
201 |
202 |     success: bool = dspy.OutputField(desc="Whether the action succeeded")
203 |     outcome_description: str = dspy.OutputField(desc="Description of what happened")
204 |     stat_changes: dict[str, int] = dspy.OutputField(desc="Changes to player stats")
205 |     items_gained: list[str] = dspy.OutputField(desc="Items gained from this action")
206 |     experience_gained: int = dspy.OutputField(desc="Experience points gained")
207 |
208 | class GameAI(dspy.Module):
209 |     """Main AI module for game logic and narrative."""
210 |
211 |     def __init__(self):
212 |         super().__init__()
213 |         self.story_gen = dspy.ChainOfThought(StoryGenerator)
214 |         self.dialogue_gen = dspy.ChainOfThought(DialogueGenerator)
215 |         self.action_resolver = dspy.ChainOfThought(ActionResolver)
216 |
217 |     def generate_scene(self, player: Player, context: GameContext, recent_actions: str = "") -> Dict:
218 |         """Generate current scene description and options."""
219 |
220 |         player_info = f"Level {player.level} {player.name}, Health: {player.health}, Skills: {player.skills}"
221 |
222 |         scene = self.story_gen(
223 |             location=context.current_location,
224 |             player_info=player_info,
225 |             story_progress=context.story_progress,
226 |             recent_actions=recent_actions
227 |         )
228 |
229 |         return {
230 |             "description": scene.scene_description,
231 |             "actions": scene.available_actions,
232 |             "npcs": scene.npcs_present,
233 |             "items": scene.items_available
234 |         }
235 |
236 |     def handle_dialogue(self, npc_name: str, player_input: str, context: GameContext) -> Dict:
237 |         """Handle conversation with NPCs."""
238 |
239 |         # Create NPC personality based on name and context
240 |         personality_map = {
241 |             "Village Elder": "Wise, knowledgeable, speaks in riddles, has ancient knowledge",
242 |             "Merchant": "Greedy but fair, loves to bargain, knows about valuable items",
243 |             "Guard": "Dutiful, suspicious of strangers, follows rules strictly",
244 |             "Thief": "Sneaky, untrustworthy, has information about hidden things",
245 |             "Wizard": "Mysterious, powerful, speaks about magic and ancient forces"
246 |         }
247 |
248 |         personality = personality_map.get(npc_name, "Friendly villager with local knowledge")
249 |         game_context = f"Location: {context.current_location}, Story progress: {context.story_progress}"
250 |
251 |         response = self.dialogue_gen(
252 |             npc_name=npc_name,
253 |             npc_personality=personality,
254 |             player_input=player_input,
255 |             context=game_context
256 |         )
257 |
258 |         return {
259 |             "response": response.npc_response,
260 |             "mood": response.mood_change,
261 |             "quest": response.quest_offered,
262 |             "info": response.information_revealed
263 |         }
264 |
265 |     def resolve_action(self, action: str, player: Player, context: GameContext) -> Dict:
266 |         """Resolve player actions and determine outcomes."""
267 |
268 |         player_stats = f"Level {player.level}, Health {player.health}, Skills: {player.skills}"
269 |         game_context = f"Location: {context.current_location}, Progress: {context.story_progress}"
270 |
271 |         # Determine difficulty based on action type
272 |         difficulty = "medium"
273 |         if any(word in action.lower() for word in ["fight", "battle", "attack"]):
274 |             difficulty = "hard"
275 |         elif any(word in action.lower() for word in ["look", "examine", "talk"]):
276 |             difficulty = "easy"
277 |
278 |         result = self.action_resolver(
279 |             action=action,
280 |             player_stats=player_stats,
281 |             context=game_context,
282 |             difficulty=difficulty
283 |         )
284 |
285 |         return {
286 |             "success": result.success,
287 |             "description": result.outcome_description,
288 |             "stat_changes": result.stat_changes,
289 |             "items": result.items_gained,
290 |             "experience": result.experience_gained
291 |         }
292 |
293 | # Initialize AI
294 | ai = GameAI()
295 | ```
296 |
297 | ## Step 3: Game Interface and Interaction
298 |
299 | ```python
300 | def display_game_header():
301 |     """Display the game header."""
302 |     header = Text("🏰 MYSTIC REALM ADVENTURE 🏰", style="bold magenta")
303 |     console.print(Panel(header, style="bright_blue"))
304 |
305 | def display_player_status(player: Player):
306 |     """Display player status panel."""
307 |     status = f"""
308 | [bold]Name:[/bold] {player.name}
309 | [bold]Level:[/bold] {player.level} (XP: {player.experience})
310 | [bold]Health:[/bold] {player.health}/100
311 | [bold]Skills:[/bold]
312 |   • Strength: {player.skills['strength']}
313 |   • Intelligence: {player.skills['intelligence']}
314 |   • Charisma: {player.skills['charisma']}
315 |   • Stealth: {player.skills['stealth']}
316 | [bold]Inventory:[/bold] {len(player.inventory)} items
317 |     """
318 |     console.print(Panel(status.strip(), title="Player Status", style="green"))
319 |
320 | def display_location(context: GameContext, scene: Dict):
321 |     """Display current location and scene."""
322 |     location_panel = f"""
323 | [bold yellow]{context.current_location}[/bold yellow]
324 |
325 | {scene['description']}
326 |     """
327 |
328 |     if scene['npcs']:
329 |         location_panel += f"\n\n[bold]NPCs present:[/bold] {', '.join(scene['npcs'])}"
330 |
331 |     if scene['items']:
332 |         location_panel += f"\n[bold]Items visible:[/bold] {', '.join(scene['items'])}"
333 |
334 |     console.print(Panel(location_panel.strip(), title="Current Location", style="cyan"))
335 |
336 | def display_actions(actions: list[str]):
337 |     """Display available actions."""
338 |     action_text = "\n".join([f"{i+1}. {action}" for i, action in enumerate(actions)])
339 |     console.print(Panel(action_text, title="Available Actions", style="yellow"))
340 |
341 | def get_player_choice(max_choices: int) -> int:
342 |     """Get player's choice with input validation."""
343 |     while True:
344 |         try:
345 |             choice = typer.prompt("Choose an action (number)")
346 |             choice_num = int(choice)
347 |             if 1 <= choice_num <= max_choices:
348 |                 return choice_num - 1
349 |             else:
350 |                 console.print(f"[red]Please enter a number between 1 and {max_choices}[/red]")
351 |         except ValueError:
352 |             console.print("[red]Please enter a valid number[/red]")
353 |
354 | def show_inventory(player: Player):
355 |     """Display player inventory."""
356 |     if not player.inventory:
357 |         console.print(Panel("Your inventory is empty.", title="Inventory", style="red"))
358 |     else:
359 |         items = "\n".join([f"• {item}" for item in player.inventory])
360 |         console.print(Panel(items, title="Inventory", style="green"))
361 |
362 | def main_menu():
363 |     """Display main menu and handle selection."""
364 |     console.clear()
365 |     display_game_header()
366 |
367 |     menu_options = [
368 |         "1. New Game",
369 |         "2. Load Game",
370 |         "3. How to Play",
371 |         "4. Exit"
372 |     ]
373 |
374 |     menu_text = "\n".join(menu_options)
375 |     console.print(Panel(menu_text, title="Main Menu", style="bright_blue"))
376 |
377 |     choice = typer.prompt("Select an option")
378 |     return choice
379 |
380 | def show_help():
381 |     """Display help information."""
382 |     help_text = """
383 | [bold]How to Play:[/bold]
384 |
385 | • This is a text-based adventure game powered by AI
386 | • Make choices by selecting numbered options
387 | • Talk to NPCs to learn about the world and get quests
388 | • Explore different locations to find items and adventures
389 | • Your choices affect the story and character development
390 | • Use 'inventory' to check your items
391 | • Use 'status' to see your character info
392 | • Type 'save' to save your progress
393 | • Type 'quit' to return to main menu
394 |
395 | [bold]Tips:[/bold]
396 | • Different skills affect your success in various actions
397 | • NPCs remember your previous interactions
398 | • Explore thoroughly - there are hidden secrets!
399 | • Your reputation affects how NPCs treat you
400 |     """
401 |     console.print(Panel(help_text.strip(), title="Game Help", style="blue"))
402 |     typer.prompt("Press Enter to continue")
403 | ```
404 |
405 | ## Step 4: Main Game Loop
406 |
407 | ```python
408 | def create_new_character():
409 |     """Create a new player character."""
410 |     console.clear()
411 |     display_game_header()
412 |
413 |     name = typer.prompt("Enter your character's name")
414 |
415 |     # Character creation with skill point allocation
416 |     console.print("\n[bold]Character Creation[/bold]")
417 |     console.print("You have 10 extra skill points to distribute among your skills.")
418 |     console.print("Base skills start at 10 each.\n")
419 |
420 |     skills = {"strength": 10, "intelligence": 10, "charisma": 10, "stealth": 10}
421 |     points_remaining = 10
422 |
423 |     for skill in skills.keys():
424 |         if points_remaining > 0:
425 |             console.print(f"Points remaining: {points_remaining}")
426 |             while True:
427 |                 try:
428 |                     points = int(typer.prompt(f"Points to add to {skill} (0-{points_remaining})"))
429 |                     if 0 <= points <= points_remaining:
430 |                         skills[skill] += points
431 |                         points_remaining -= points
432 |                         break
433 |                     else:
434 |                         console.print(f"[red]Enter a number between 0 and {points_remaining}[/red]")
435 |                 except ValueError:
436 |                     console.print("[red]Please enter a valid number[/red]")
437 |
438 |     player = Player(name=name, skills=skills)
439 |     console.print(f"\n[green]Welcome to Mystic Realm, {name}![/green]")
440 |     return player
441 |
442 | def game_loop():
443 |     """Main game loop."""
444 |     recent_actions = ""
445 |
446 |     while game.running and game.state == GameState.PLAYING:
447 |         console.clear()
448 |         display_game_header()
449 |
450 |         # Generate current scene
451 |         scene = ai.generate_scene(game.player, game.context, recent_actions)
452 |
453 |         # Display game state
454 |         display_player_status(game.player)
455 |         display_location(game.context, scene)
456 |
457 |         # Add standard actions
458 |         all_actions = scene['actions'] + ["Check inventory", "Character status", "Save game", "Quit to menu"]
459 |         display_actions(all_actions)
460 |
461 |         # Get player choice
462 |         choice_idx = get_player_choice(len(all_actions))
463 |         chosen_action = all_actions[choice_idx]
464 |
465 |         # Handle special commands
466 |         if chosen_action == "Check inventory":
467 |             show_inventory(game.player)
468 |             typer.prompt("Press Enter to continue")
469 |             continue
470 |         elif chosen_action == "Character status":
471 |             display_player_status(game.player)
472 |             typer.prompt("Press Enter to continue")
473 |             continue
474 |         elif chosen_action == "Save game":
475 |             game.save_game()
476 |             typer.prompt("Press Enter to continue")
477 |             continue
478 |         elif chosen_action == "Quit to menu":
479 |             game.state = GameState.MENU
480 |             break
481 |
482 |         # Handle game actions
483 |         if chosen_action in scene['actions']:
484 |             # Check if it's dialogue with an NPC
485 |             npc_target = None
486 |             for npc in scene['npcs']:
487 |                 if npc.lower() in chosen_action.lower():
488 |                     npc_target = npc
489 |                     break
490 |
491 |             if npc_target:
492 |                 # Handle NPC interaction
493 |                 console.print(f"\n[bold]Talking to {npc_target}...[/bold]")
494 |                 dialogue = ai.handle_dialogue(npc_target, chosen_action, game.context)
495 |
496 |                 console.print(f"\n[italic]{npc_target}:[/italic] \"{dialogue['response']}\"")
497 |
498 |                 if dialogue['quest']:
499 |                     console.print(f"[yellow]💼 Quest opportunity detected![/yellow]")
500 |
501 |                 if dialogue['info']:
502 |                     console.print(f"[blue]ℹ️  {dialogue['info']}[/blue]")
503 |
504 |                 # Add NPC to met list
505 |                 if npc_target not in game.context.npcs_met:
506 |                     game.context.npcs_met.append(npc_target)
507 |
508 |                 recent_actions = f"Talked to {npc_target}: {chosen_action}"
509 |             else:
510 |                 # Handle general action
511 |                 result = ai.resolve_action(chosen_action, game.player, game.context)
512 |
513 |                 console.print(f"\n{result['description']}")
514 |
515 |                 # Apply results
516 |                 if result['success']:
517 |                     console.print("[green]✅ Success![/green]")
518 |
519 |                     # Apply stat changes
520 |                     for stat, change in result['stat_changes'].items():
521 |                         if stat in game.player.skills:
522 |                             game.player.skills[stat] += change
523 |                             if change > 0:
524 |                                 console.print(f"[green]{stat.title()} increased by {change}![/green]")
525 |                         elif stat == "health":
526 |                             game.player.health = max(0, min(100, game.player.health + change))
527 |                             if change > 0:
528 |                                 console.print(f"[green]Health restored by {change}![/green]")
529 |                             elif change < 0:
530 |                                 console.print(f"[red]Health decreased by {abs(change)}![/red]")
531 |
532 |                     # Add items
533 |                     for item in result['items']:
534 |                         game.player.add_item(item)
535 |
536 |                     # Give experience
537 |                     if result['experience'] > 0:
538 |                         game.player.gain_experience(result['experience'])
539 |
540 |                     # Update story progress
541 |                     game.context.story_progress += 1
542 |                 else:
543 |                     console.print("[red]❌ The action didn't go as planned...[/red]")
544 |
545 |                 recent_actions = f"Attempted: {chosen_action}"
546 |
547 |             # Check for game over conditions
548 |             if game.player.health <= 0:
549 |                 console.print("\n[bold red]💀 You have died! Game Over![/bold red]")
550 |                 game.state = GameState.GAME_OVER
551 |                 break
552 |
553 |             typer.prompt("\nPress Enter to continue")
554 |
555 | def main():
556 |     """Main game function."""
557 |     while game.running:
558 |         if game.state == GameState.MENU:
559 |             choice = main_menu()
560 |
561 |             if choice == "1":
562 |                 game.player = create_new_character()
563 |                 game.context = GameContext()
564 |                 game.state = GameState.PLAYING
565 |                 console.print("\n[italic]Your adventure begins...[/italic]")
566 |                 typer.prompt("Press Enter to start")
567 |
568 |             elif choice == "2":
569 |                 if game.load_game():
570 |                     game.state = GameState.PLAYING
571 |                 typer.prompt("Press Enter to continue")
572 |
573 |             elif choice == "3":
574 |                 show_help()
575 |
576 |             elif choice == "4":
577 |                 game.running = False
578 |                 console.print("[bold]Thanks for playing! Goodbye![/bold]")
579 |
580 |         elif game.state == GameState.PLAYING:
581 |             game_loop()
582 |
583 |         elif game.state == GameState.GAME_OVER:
584 |             console.print("\n[bold]Game Over[/bold]")
585 |             restart = typer.confirm("Would you like to return to the main menu?")
586 |             if restart:
587 |                 game.state = GameState.MENU
588 |             else:
589 |                 game.running = False
590 |
591 | if __name__ == "__main__":
592 |     main()
593 | ```
594 |
595 | ## Example Gameplay
596 |
597 | When you run the game, you'll experience:
598 |
599 | **Character Creation:**
600 | ```
601 | 🏰 MYSTIC REALM ADVENTURE 🏰
602 |
603 | Enter your character's name: Aria
604 |
605 | Character Creation
606 | You have 10 extra skill points to distribute among your skills.
607 | Base skills start at 10 each.
608 |
609 | Points remaining: 10
610 | Points to add to strength (0-10): 2
611 | Points to add to intelligence (0-8): 4
612 | Points to add to charisma (0-4): 3
613 | Points to add to stealth (0-1): 1
614 |
615 | Welcome to Mystic Realm, Aria!
616 | ```
617 |
618 | **Dynamic Scene Generation:**
619 | ```
620 | ┌──────────── Current Location ────────────┐
621 | │ Village Square                           │
622 | │                                          │
623 | │ You stand in the bustling heart of       │
624 | │ Willowbrook Village. The ancient stone   │
625 | │ fountain bubbles cheerfully as merchants │
626 | │ hawk their wares and children play. A    │
627 | │ mysterious hooded figure lurks near the  │
628 | │ shadows of the old oak tree.             │
629 | │                                          │
630 | │ NPCs present: Village Elder, Merchant    │
631 | │ Items visible: Strange Medallion, Herbs  │
632 | └──────────────────────────────────────────┘
633 |
634 | ┌────────── Available Actions ─────────────┐
635 | │ 1. Approach the hooded figure            │
636 | │ 2. Talk to the Village Elder             │
637 | │ 3. Browse the merchant's wares           │
638 | │ 4. Examine the strange medallion         │
639 | │ 5. Gather herbs near the fountain        │
640 | │ 6. Head to the forest path               │
641 | └───────────────────────────────────────────┘
642 | ```
643 |
644 | **AI-Generated Dialogue:**
645 | ```
646 | Talking to Village Elder...
647 |
648 | Village Elder: "Ah, young traveler, I sense a great destiny
649 | surrounds you like morning mist. The ancient prophecy speaks
650 | of one who would come bearing the mark of courage. Tell me,
651 | have you noticed anything... unusual in your travels?"
652 |
653 | 💼 Quest opportunity detected!
654 | ℹ️ The Village Elder knows about an ancient prophecy that might involve you
655 | ```
656 |
657 | ## Next Steps
658 |
659 | - **Combat System**: Add turn-based battles with strategy
660 | - **Magic System**: Spellcasting with resource management
661 | - **Multiplayer**: Network support for cooperative adventures
662 | - **Quest System**: Complex multi-step missions with branching outcomes
663 | - **World Building**: Procedurally generated locations and characters
664 | - **Audio**: Add sound effects and background music
665 |
666 | This tutorial demonstrates how DSPy's modular approach enables complex, interactive systems where AI handles creative content generation while maintaining consistent game logic and player agency.
```

audio/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: Using Audio in DSPy Programs\n",
8 |     "\n",
9 |     "This tutorial walks through building pipelines for audio-based applications using DSPy."
10 |    ]
11 |   },
12 |   {
13 |    "cell_type": "markdown",
14 |    "metadata": {},
15 |    "source": [
16 |     "### Install Dependencies\n",
17 |     "\n",
18 |     "Ensure you're using the latest DSPy version:\n",
19 |     "\n",
20 |     "```shell\n",
21 |     "pip install -U dspy\n",
22 |     "```\n",
23 |     "\n",
24 |     "To handle audio data, install the following dependencies:\n",
25 |     "\n",
26 |     "```shell\n",
27 |     "pip install datasets soundfile torch==2.0.1+cu118 torchaudio==2.0.2+cu118\n",
28 |     "```\n"
29 |    ]
30 |   },
31 |   {
32 |    "cell_type": "markdown",
33 |    "metadata": {},
34 |    "source": [
35 |     "### Load the Spoken-SQuAD Dataset\n",
36 |     "\n",
37 |     "We'll use the Spoken-SQuAD dataset ([Official](https://github.com/Chia-Hsuan-Lee/Spoken-SQuAD) & [HuggingFace version](https://huggingface.co/datasets/AudioLLMs/spoken_squad_test) for tutorial demonstration), which contains spoken audio passages used for question-answering:"
38 |    ]
39 |   },
40 |   {
41 |    "cell_type": "code",
42 |    "execution_count": null,
43 |    "metadata": {},
44 |    "outputs": [],
45 |    "source": [
46 |     "import random\n",
47 |     "import dspy\n",
48 |     "from dspy.datasets import DataLoader\n",
49 |     "\n",
50 |     "kwargs = dict(fields=(\"context\", \"instruction\", \"answer\"), input_keys=(\"context\", \"instruction\"))\n",
51 |     "spoken_squad = DataLoader().from_huggingface(dataset_name=\"AudioLLMs/spoken_squad_test\", split=\"train\", trust_remote_code=True, **kwargs)\n",
52 |     "\n",
53 |     "random.Random(42).shuffle(spoken_squad)\n",
54 |     "spoken_squad = spoken_squad[:100]\n",
55 |     "\n",
56 |     "split_idx = len(spoken_squad) // 2\n",
57 |     "trainset_raw, testset_raw = spoken_squad[:split_idx], spoken_squad[split_idx:]"
58 |    ]
59 |   },
60 |   {
61 |    "cell_type": "markdown",
62 |    "metadata": {},
63 |    "source": [
64 |     "### Preprocess Audio Data\n",
65 |     "\n",
66 |     "The audio clips in the dataset require some preprocessing into byte arrays with their corresponding sampling rates."
67 |    ]
68 |   },
69 |   {
70 |    "cell_type": "code",
71 |    "execution_count": null,
72 |    "metadata": {},
73 |    "outputs": [],
74 |    "source": [
75 |     "def preprocess(x):\n",
76 |     "    audio = dspy.Audio.from_array(x.context[\"array\"], x.context[\"sampling_rate\"])\n",
77 |     "    return dspy.Example(\n",
78 |     "        passage_audio=audio,\n",
79 |     "        question=x.instruction,\n",
80 |     "        answer=x.answer\n",
81 |     "    ).with_inputs(\"passage_audio\", \"question\")\n",
82 |     "\n",
83 |     "trainset = [preprocess(x) for x in trainset_raw]\n",
84 |     "testset = [preprocess(x) for x in testset_raw]\n",
85 |     "\n",
86 |     "len(trainset), len(testset)"
87 |    ]
88 |   },
89 |   {
90 |    "cell_type": "markdown",
91 |    "metadata": {},
92 |    "source": [
93 |     "## DSPy program for spoken question answering\n",
94 |     "\n",
95 |     "Let's define a simple DSPy program that uses audio inputs to answer questions directly. This is very similar to the [BasicQA](https://dspy.ai/cheatsheet/?h=basicqa#dspysignature) task, with the only difference being that the passage context is provided as an audio file for the model to listen to and answer the question:"
96 |    ]
97 |   },
98 |   {
99 |    "cell_type": "code",
100 |    "execution_count": null,
101 |    "metadata": {},
102 |    "outputs": [],
103 |    "source": [
104 |     "class SpokenQASignature(dspy.Signature):\n",
105 |     "    \"\"\"Answer the question based on the audio clip.\"\"\"\n",
106 |     "    passage_audio: dspy.Audio = dspy.InputField()\n",
107 |     "    question: str = dspy.InputField()\n",
108 |     "    answer: str = dspy.OutputField(desc = 'factoid answer between 1 and 5 words')\n",
109 |     "\n",
110 |     "spoken_qa = dspy.ChainOfThought(SpokenQASignature)\n"
111 |    ]
112 |   },
113 |   {
114 |    "cell_type": "markdown",
115 |    "metadata": {},
116 |    "source": [
117 |     "Now let's configure our LLM which can process input audio. \n",
118 |     "\n",
119 |     "```python\n",
120 |     "dspy.settings.configure(lm=dspy.LM(model='gpt-4o-mini-audio-preview-2024-12-17'))\n",
121 |     "```\n",
122 |     "\n",
123 |     "Note: Using `dspy.Audio` in signatures allows passing in audio directly to the model. "
124 |    ]
125 |   },
126 |   {
127 |    "cell_type": "markdown",
128 |    "metadata": {},
129 |    "source": [
130 |     "### Define Evaluation Metric\n",
131 |     "\n",
132 |     "We'll use the Exact Match metric (`dspy.evaluate.answer_exact_match`) to measure answer accuracy compared to the provided reference answers:"
133 |    ]
134 |   },
135 |   {
136 |    "cell_type": "code",
137 |    "execution_count": null,
138 |    "metadata": {},
139 |    "outputs": [],
140 |    "source": [
141 |     "evaluate_program = dspy.Evaluate(devset=testset, metric=dspy.evaluate.answer_exact_match,display_progress=True, num_threads = 10, display_table=True)\n",
142 |     "\n",
143 |     "evaluate_program(spoken_qa)"
144 |    ]
145 |   },
146 |   {
147 |    "cell_type": "markdown",
148 |    "metadata": {},
149 |    "source": [
150 |     "### Optimize with DSPy\n",
151 |     "\n",
152 |     "You can optimize this audio-based program as you would for any DSPy program using any DSPy optimizer.\n",
153 |     "\n",
154 |     "Note: Audio tokens can be costly so it is recommended to configure optimizers like `dspy.BootstrapFewShotWithRandomSearch` or `dspy.MIPROv2` conservatively with 0-2 few shot examples and less candidates / trials than the optimizer default parameters."
155 |    ]
156 |   },
157 |   {
158 |    "cell_type": "code",
159 |    "execution_count": null,
160 |    "metadata": {},
161 |    "outputs": [],
162 |    "source": [
163 |     "optimizer = dspy.BootstrapFewShotWithRandomSearch(metric = dspy.evaluate.answer_exact_match, max_bootstrapped_demos=2, max_labeled_demos=2, num_candidate_programs=5)\n",
164 |     "\n",
165 |     "optimized_program = optimizer.compile(spoken_qa, trainset = trainset)\n",
166 |     "\n",
167 |     "evaluate_program(optimized_program)"
168 |    ]
169 |   },
170 |   {
171 |    "cell_type": "code",
172 |    "execution_count": null,
173 |    "metadata": {},
174 |    "outputs": [],
175 |    "source": [
176 |     "prompt_lm = dspy.LM(model='gpt-4o-mini') #NOTE - this is the LLM guiding the MIPROv2 instruction candidate proposal\n",
177 |     "optimizer = dspy.MIPROv2(metric=dspy.evaluate.answer_exact_match, auto=\"light\", prompt_model = prompt_lm)\n",
178 |     "\n",
179 |     "#NOTE - MIPROv2's dataset summarizer cannot process the audio files in the dataset, so we turn off the data_aware_proposer \n",
180 |     "optimized_program = optimizer.compile(spoken_qa, trainset=trainset, max_bootstrapped_demos=2, max_labeled_demos=2, data_aware_proposer=False)\n",
181 |     "\n",
182 |     "evaluate_program(optimized_program)"
183 |    ]
184 |   },
185 |   {
186 |    "cell_type": "markdown",
187 |    "metadata": {},
188 |    "source": [
189 |     "With this small subset, MIPROv2 led to a ~10% improvement over baseline performance."
190 |    ]
191 |   },
192 |   {
193 |    "cell_type": "markdown",
194 |    "metadata": {},
195 |    "source": [
196 |     "---"
197 |    ]
198 |   },
199 |   {
200 |    "cell_type": "markdown",
201 |    "metadata": {},
202 |    "source": [
203 |     "Now that we’ve seen how to use an audio-input-capable LLM in DSPy, let’s flip the setup.\n",
204 |     "\n",
205 |     "In this next task, we'll use a standard text-based LLM to generate prompts for a text-to-speech model and then evaluate the quality of the produced speech for some downstream task. This approach is generally more cost-effective than asking an LLM like `gpt-4o-mini-audio-preview-2024-12-17` to generate audio directly, while still enabling a pipeline that can be optimized for higher-quality speech output."
206 |    ]
207 |   },
208 |   {
209 |    "cell_type": "markdown",
210 |    "metadata": {},
211 |    "source": [
212 |     "### Load the CREMA-D Dataset\n",
213 |     "\n",
214 |     "We'll use the CREMA-D dataset ([Official](https://github.com/CheyneyComputerScience/CREMA-D) & [HuggingFace version](https://huggingface.co/datasets/myleslinder/crema-d) for tutorial demonstration), which includes audio clips of chosen participants speaking the same line with one of six target emotions: neutral, happy, sad, anger, fear, and disgust."
215 |    ]
216 |   },
217 |   {
218 |    "cell_type": "code",
219 |    "execution_count": null,
220 |    "metadata": {},
221 |    "outputs": [],
222 |    "source": [
223 |     "from collections import defaultdict\n",
224 |     "\n",
225 |     "label_map = ['neutral', 'happy', 'sad', 'anger', 'fear', 'disgust']\n",
226 |     "\n",
227 |     "kwargs = dict(fields=(\"sentence\", \"label\", \"audio\"), input_keys=(\"sentence\", \"label\"))\n",
228 |     "crema_d = DataLoader().from_huggingface(dataset_name=\"myleslinder/crema-d\", split=\"train\", trust_remote_code=True, **kwargs)\n",
229 |     "\n",
230 |     "def preprocess(x):\n",
231 |     "    return dspy.Example(\n",
232 |     "        raw_line=x.sentence,\n",
233 |     "        target_style=label_map[x.label],\n",
234 |     "        reference_audio=dspy.Audio.from_array(x.audio[\"array\"], x.audio[\"sampling_rate\"])\n",
235 |     "    ).with_inputs(\"raw_line\", \"target_style\")\n",
236 |     "\n",
237 |     "random.Random(42).shuffle(crema_d)\n",
238 |     "crema_d = crema_d[:100]\n",
239 |     "\n",
240 |     "random.seed(42)\n",
241 |     "label_to_indices = defaultdict(list)\n",
242 |     "for idx, x in enumerate(crema_d):\n",
243 |     "    label_to_indices[x.label].append(idx)\n",
244 |     "\n",
245 |     "per_label = 100 // len(label_map)\n",
246 |     "train_indices, test_indices = [], []\n",
247 |     "for indices in label_to_indices.values():\n",
248 |     "    selected = random.sample(indices, min(per_label, len(indices)))\n",
249 |     "    split = len(selected) // 2\n",
250 |     "    train_indices.extend(selected[:split])\n",
251 |     "    test_indices.extend(selected[split:])\n",
252 |     "\n",
253 |     "trainset = [preprocess(crema_d[idx]) for idx in train_indices]\n",
254 |     "testset = [preprocess(crema_d[idx]) for idx in test_indices]"
255 |    ]
256 |   },
257 |   {
258 |    "cell_type": "markdown",
259 |    "metadata": {},
260 |    "source": [
261 |     "## DSPy pipeline for generating TTS instructions for speaking with a target emotion\n",
262 |     "\n",
263 |     "We’ll now build a pipeline that generates emotionally expressive speech by prompting a TTS model with both a line of text and an instruction on how to say it. \n",
264 |     "The goal of this task will be to use DSPy to generate prompts that guide the TTS output to match the emotion and style of reference audio from the dataset.\n",
265 |     "\n",
266 |     "First let’s set up the TTS generator to produce generate spoken audio with a specified emotion or style. \n",
267 |     "We utilize `gpt-4o-mini-tts` as it supports prompting the model with raw input and speaking and produces an audio response as a `.wav` file processed with `dspy.Audio`. \n",
268 |     "We also set up a cache for the TTS outputs."
269 |    ]
270 |   },
271 |   {
272 |    "cell_type": "code",
273 |    "execution_count": null,
274 |    "metadata": {},
275 |    "outputs": [],
276 |    "source": [
277 |     "import os\n",
278 |     "import base64\n",
279 |     "import hashlib\n",
280 |     "from openai import OpenAI\n",
281 |     "\n",
282 |     "CACHE_DIR = \".audio_cache\"\n",
283 |     "os.makedirs(CACHE_DIR, exist_ok=True)\n",
284 |     "\n",
285 |     "def hash_key(raw_line: str, prompt: str) -> str:\n",
286 |     "    return hashlib.sha256(f\"{raw_line}|||{prompt}\".encode(\"utf-8\")).hexdigest()\n",
287 |     "\n",
288 |     "def generate_dspy_audio(raw_line: str, prompt: str) -> dspy.Audio:\n",
289 |     "    client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
290 |     "    key = hash_key(raw_line, prompt)\n",
291 |     "    wav_path = os.path.join(CACHE_DIR, f\"{key}.wav\")\n",
292 |     "    if not os.path.exists(wav_path):\n",
293 |     "        response = client.audio.speech.create(\n",
294 |     "            model=\"gpt-4o-mini-tts\",\n",
295 |     "            voice=\"coral\", #NOTE - this can be configured to any of the 11 offered OpenAI TTS voices - https://platform.openai.com/docs/guides/text-to-speech#voice-options. \n",
296 |     "            input=raw_line,\n",
297 |     "            instructions=prompt,\n",
298 |     "            response_format=\"wav\"\n",
299 |     "        )\n",
300 |     "        with open(wav_path, \"wb\") as f:\n",
301 |     "            f.write(response.content)\n",
302 |     "    with open(wav_path, \"rb\") as f:\n",
303 |     "        encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
304 |     "    return dspy.Audio(data=encoded, format=\"wav\")"
305 |    ]
306 |   },
307 |   {
308 |    "cell_type": "markdown",
309 |    "metadata": {},
310 |    "source": [
311 |     "Now let's define the DSPy program for generating TTS instructions. For this program, we can use standard text-based LLMs again since we're just generating instructions."
312 |    ]
313 |   },
314 |   {
315 |    "cell_type": "code",
316 |    "execution_count": null,
317 |    "metadata": {},
318 |    "outputs": [],
319 |    "source": [
320 |     "class EmotionStylePromptSignature(dspy.Signature):\n",
321 |     "    \"\"\"Generate an OpenAI TTS instruction that makes the TTS model speak the given line with the target emotion or style.\"\"\"\n",
322 |     "    raw_line: str = dspy.InputField()\n",
323 |     "    target_style: str = dspy.InputField()\n",
324 |     "    openai_instruction: str = dspy.OutputField()\n",
325 |     "\n",
326 |     "class EmotionStylePrompter(dspy.Module):\n",
327 |     "    def __init__(self):\n",
328 |     "        self.prompter = dspy.ChainOfThought(EmotionStylePromptSignature)\n",
329 |     "\n",
330 |     "    def forward(self, raw_line, target_style):\n",
331 |     "        out = self.prompter(raw_line=raw_line, target_style=target_style)\n",
332 |     "        audio = generate_dspy_audio(raw_line, out.openai_instruction)\n",
333 |     "        return dspy.Prediction(audio=audio)\n",
334 |     "    \n",
335 |     "dspy.settings.configure(lm=dspy.LM(model='gpt-4o-mini'))"
336 |    ]
337 |   },
338 |   {
339 |    "cell_type": "markdown",
340 |    "metadata": {},
341 |    "source": [
342 |     "### Define Evaluation Metric\n",
343 |     "\n",
344 |     "Audio reference comparisons is generally a non-trivial task due to subjective variations of evaluating speech, especially with emotional expression. For the purposes of this tutorial, we use an embedding-based similarity metric for objective evaluation, leveraging Wav2Vec 2.0 to convert audio into embeddings and computing cosine similarity between the reference and generated audio. To evaluate audio quality more accurately, human feedback or perceptual metrics would be more suitable. "
345 |    ]
346 |   },
347 |   {
348 |    "cell_type": "code",
349 |    "execution_count": null,
350 |    "metadata": {},
351 |    "outputs": [],
352 |    "source": [
353 |     "import torch\n",
354 |     "import torchaudio\n",
355 |     "import soundfile as sf\n",
356 |     "import io\n",
357 |     "\n",
358 |     "bundle = torchaudio.pipelines.WAV2VEC2_BASE\n",
359 |     "model = bundle.get_model().eval()\n",
360 |     "\n",
361 |     "def decode_dspy_audio(dspy_audio):\n",
362 |     "    audio_bytes = base64.b64decode(dspy_audio.data)\n",
363 |     "    array, _ = sf.read(io.BytesIO(audio_bytes), dtype=\"float32\")\n",
364 |     "    return torch.tensor(array).unsqueeze(0)\n",
365 |     "\n",
366 |     "def extract_embedding(audio_tensor):\n",
367 |     "    with torch.inference_mode():\n",
368 |     "        return model(audio_tensor)[0].mean(dim=1)\n",
369 |     "\n",
370 |     "def cosine_similarity(a, b):\n",
371 |     "    return torch.nn.functional.cosine_similarity(a, b).item()\n",
372 |     "\n",
373 |     "def audio_similarity_metric(example, pred, trace=None):\n",
374 |     "    ref_audio = decode_dspy_audio(example.reference_audio)\n",
375 |     "    gen_audio = decode_dspy_audio(pred.audio)\n",
376 |     "\n",
377 |     "    ref_embed = extract_embedding(ref_audio)\n",
378 |     "    gen_embed = extract_embedding(gen_audio)\n",
379 |     "\n",
380 |     "    score = cosine_similarity(ref_embed, gen_embed)\n",
381 |     "\n",
382 |     "    if trace is not None:\n",
383 |     "        return score > 0.8 \n",
384 |     "    return score\n",
385 |     "\n",
386 |     "evaluate_program = dspy.Evaluate(devset=testset, metric=audio_similarity_metric, display_progress=True, num_threads = 10, display_table=True)\n",
387 |     "\n",
388 |     "evaluate_program(EmotionStylePrompter())"
389 |    ]
390 |   },
391 |   {
392 |    "cell_type": "markdown",
393 |    "metadata": {},
394 |    "source": [
395 |     "We can look at an example to see what instructions the DSPy program generated and the corresponding score:"
396 |    ]
397 |   },
398 |   {
399 |    "cell_type": "code",
400 |    "execution_count": 24,
401 |    "metadata": {},
402 |    "outputs": [
403 |     {
404 |      "name": "stdout",
405 |      "output_type": "stream",
406 |      "text": [
407 |       "\n",
408 |       "\n",
409 |       "\n",
410 |       "\n",
411 |       "\u001b[34m[2025-05-15T22:01:22.667596]\u001b[0m\n",
412 |       "\n",
413 |       "\u001b[31mSystem message:\u001b[0m\n",
414 |       "\n",
415 |       "Your input fields are:\n",
416 |       "1. `raw_line` (str)\n",
417 |       "2. `target_style` (str)\n",
418 |       "Your output fields are:\n",
419 |       "1. `reasoning` (str)\n",
420 |       "2. `openai_instruction` (str)\n",
421 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
422 |       "\n",
423 |       "[[ ## raw_line ## ]]\n",
424 |       "{raw_line}\n",
425 |       "\n",
426 |       "[[ ## target_style ## ]]\n",
427 |       "{target_style}\n",
428 |       "\n",
429 |       "[[ ## reasoning ## ]]\n",
430 |       "{reasoning}\n",
431 |       "\n",
432 |       "[[ ## openai_instruction ## ]]\n",
433 |       "{openai_instruction}\n",
434 |       "\n",
435 |       "[[ ## completed ## ]]\n",
436 |       "In adhering to this structure, your objective is: \n",
437 |       "        Generate an OpenAI TTS instruction that makes the TTS model speak the given line with the target emotion or style.\n",
438 |       "\n",
439 |       "\n",
440 |       "\u001b[31mUser message:\u001b[0m\n",
441 |       "\n",
442 |       "[[ ## raw_line ## ]]\n",
443 |       "It's eleven o'clock\n",
444 |       "\n",
445 |       "[[ ## target_style ## ]]\n",
446 |       "disgust\n",
447 |       "\n",
448 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## openai_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
449 |       "\n",
450 |       "\n",
451 |       "\u001b[31mResponse:\u001b[0m\n",
452 |       "\n",
453 |       "\u001b[32m[[ ## reasoning ## ]]\n",
454 |       "To generate the OpenAI TTS instruction, we need to specify the target emotion or style, which in this case is 'disgust'. We will use the OpenAI TTS instruction format, which includes the text to be spoken and the desired emotion or style.\n",
455 |       "\n",
456 |       "[[ ## openai_instruction ## ]]\n",
457 |       "\"Speak the following line with a tone of disgust: It's eleven o'clock\"\n",
458 |       "\n",
459 |       "[[ ## completed ## ]]\u001b[0m\n",
460 |       "\n",
461 |       "\n",
462 |       "\n",
463 |       "\n",
464 |       "\n"
465 |      ]
466 |     }
467 |    ],
468 |    "source": [
469 |     "program = EmotionStylePrompter()\n",
470 |     "\n",
471 |     "pred = program(raw_line=testset[1].raw_line, target_style=testset[1].target_style)\n",
472 |     "\n",
473 |     "print(audio_similarity_metric(testset[1], pred)) #0.5725605487823486\n",
474 |     "\n",
475 |     "dspy.inspect_history(n=1)"
476 |    ]
477 |   },
478 |   {
479 |    "cell_type": "markdown",
480 |    "metadata": {},
481 |    "source": [
482 |     "TTS Instruction: \n",
483 |     "```text\n",
484 |     "Speak the following line with a tone of disgust: It's eleven o'clock\n",
485 |     "```\n"
486 |    ]
487 |   },
488 |   {
489 |    "cell_type": "code",
490 |    "execution_count": null,
491 |    "metadata": {},
492 |    "outputs": [
493 |     {
494 |      "data": {
495 |       "text/html": [
496 |        "\n",
497 |        "                <audio  controls=\"controls\" >\n",
498 |        "                    <source src=\"data:audio/wav;base64,
499 |        "                    Your browser does not support the audio element.\n",
500 |        "                </audio>\n",
501 |        "              "
502 |       ],
503 |       "text/plain": [
504 |        "<IPython.lib.display.Audio object>"
505 |       ]
506 |      },
507 |      "execution_count": 28,
508 |      "metadata": {},
509 |      "output_type": "execute_result"
510 |     }
511 |    ],
512 |    "source": [
513 |     "from IPython.display import Audio\n",
514 |     "\n",
515 |     "audio_bytes = base64.b64decode(pred.audio.data)\n",
516 |     "array, rate = sf.read(io.BytesIO(audio_bytes), dtype=\"float32\")\n",
517 |     "Audio(array, rate=rate)"
518 |    ]
519 |   },
520 |   {
521 |    "cell_type": "markdown",
522 |    "metadata": {},
523 |    "source": [
524 |     "The instruction specifies the target emotion, but is not too informative beyond that. We can also see that the audio score for this sample is not too high. Let's see if we can do better by optimizing this pipeline."
525 |    ]
526 |   },
527 |   {
528 |    "cell_type": "markdown",
529 |    "metadata": {},
530 |    "source": [
531 |     "### Optimize with DSPy\n",
532 |     "\n",
533 |     "We can leverage `dspy.MIPROv2` to refine the downstream task objective and produce higher quality TTS instructions, leading to more accurate and expressive audio generations:"
534 |    ]
535 |   },
536 |   {
537 |    "cell_type": "code",
538 |    "execution_count": null,
539 |    "metadata": {},
540 |    "outputs": [],
541 |    "source": [
542 |     "prompt_lm = dspy.LM(model='gpt-4o-mini')\n",
543 |     "\n",
544 |     "teleprompter = dspy.MIPROv2(metric=audio_similarity_metric, auto=\"light\", prompt_model = prompt_lm)\n",
545 |     "\n",
546 |     "optimized_program = teleprompter.compile(EmotionStylePrompter(),trainset=trainset)\n",
547 |     "\n",
548 |     "evaluate_program(optimized_program)\n"
549 |    ]
550 |   },
551 |   {
552 |    "cell_type": "markdown",
553 |    "metadata": {},
554 |    "source": [
555 |     "Let's take a look at how the optimized program performs:"
556 |    ]
557 |   },
558 |   {
559 |    "cell_type": "code",
560 |    "execution_count": 27,
561 |    "metadata": {},
562 |    "outputs": [
563 |     {
564 |      "name": "stdout",
565 |      "output_type": "stream",
566 |      "text": [
567 |       "\n",
568 |       "\n",
569 |       "\n",
570 |       "\n",
571 |       "\u001b[34m[2025-05-15T22:09:40.088592]\u001b[0m\n",
572 |       "\n",
573 |       "\u001b[31mSystem message:\u001b[0m\n",
574 |       "\n",
575 |       "Your input fields are:\n",
576 |       "1. `raw_line` (str)\n",
577 |       "2. `target_style` (str)\n",
578 |       "Your output fields are:\n",
579 |       "1. `reasoning` (str)\n",
580 |       "2. `openai_instruction` (str)\n",
581 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
582 |       "\n",
583 |       "[[ ## raw_line ## ]]\n",
584 |       "{raw_line}\n",
585 |       "\n",
586 |       "[[ ## target_style ## ]]\n",
587 |       "{target_style}\n",
588 |       "\n",
589 |       "[[ ## reasoning ## ]]\n",
590 |       "{reasoning}\n",
591 |       "\n",
592 |       "[[ ## openai_instruction ## ]]\n",
593 |       "{openai_instruction}\n",
594 |       "\n",
595 |       "[[ ## completed ## ]]\n",
596 |       "In adhering to this structure, your objective is: \n",
597 |       "        Generate an OpenAI TTS instruction that makes the TTS model speak the given line with the target emotion or style, as if the speaker is a [insert persona relevant to the task, e.g. \"irate customer\", \"angry boss\", etc.]. The instruction should specify the tone, pitch, and other characteristics of the speaker's voice to convey the target emotion.\n",
598 |       "\n",
599 |       "\n",
600 |       "\u001b[31mUser message:\u001b[0m\n",
601 |       "\n",
602 |       "[[ ## raw_line ## ]]\n",
603 |       "It's eleven o'clock\n",
604 |       "\n",
605 |       "[[ ## target_style ## ]]\n",
606 |       "disgust\n",
607 |       "\n",
608 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## openai_instruction ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
609 |       "\n",
610 |       "\n",
611 |       "\u001b[31mResponse:\u001b[0m\n",
612 |       "\n",
613 |       "\u001b[32m[[ ## reasoning ## ]]\n",
614 |       "To convey disgust, the speaker's voice should be characterized by a high-pitched tone, a slightly nasal quality, and a sense of revulsion. The speaker's words should be delivered with a sense of distaste and aversion, as if the speaker is trying to convey their strong negative emotions.\n",
615 |       "\n",
616 |       "[[ ## openai_instruction ## ]]\n",
617 |       "Generate a text-to-speech synthesis of the input text \"It's eleven o'clock\" with the following characteristics: \n",
618 |       "- Tone: Disgusted\n",
619 |       "- Pitch: High-pitched, slightly nasal\n",
620 |       "- Emphasis: Emphasize the words to convey a sense of distaste and aversion\n",
621 |       "- Volume: Moderate to loud, with a sense of rising inflection at the end to convey the speaker's strong negative emotions\n",
622 |       "- Speaker: A person who is visibly and audibly disgusted, such as a character who has just been served a spoiled meal.\n",
623 |       "\n",
624 |       "[[ ## completed ## ]]\u001b[0m\n",
625 |       "\n",
626 |       "\n",
627 |       "\n",
628 |       "\n",
629 |       "\n"
630 |      ]
631 |     }
632 |    ],
633 |    "source": [
634 |     "pred = optimized_program(raw_line=testset[1].raw_line, target_style=testset[1].target_style)\n",
635 |     "\n",
636 |     "print(audio_similarity_metric(testset[1], pred)) #0.6691027879714966\n",
637 |     "\n",
638 |     "dspy.inspect_history(n=1)"
639 |    ]
640 |   },
641 |   {
642 |    "cell_type": "markdown",
643 |    "metadata": {},
644 |    "source": [
645 |     "MIPROv2 Optimized Program Instruction: \n",
646 |     "```text \n",
647 |     "Generate an OpenAI TTS instruction that makes the TTS model speak the given line with the target emotion or style, as if the speaker is a [insert persona relevant to the task, e.g. \"irate customer\", \"angry boss\", etc.]. The instruction should specify the tone, pitch, and other characteristics of the speaker's voice to convey the target emotion.\n",
648 |     "```\n",
649 |     "\n",
650 |     "TTS Instruction: \n",
651 |     "```text\n",
652 |     "Generate a text-to-speech synthesis of the input text \"It's eleven o'clock\" with the following characteristics: \n",
653 |     "- Tone: Disgusted\n",
654 |     "- Pitch: High-pitched, slightly nasal\n",
655 |     "- Emphasis: Emphasize the words to convey a sense of distaste and aversion\n",
656 |     "- Volume: Moderate to loud, with a sense of rising inflection at the end to convey the speaker's strong negative emotions\n",
657 |     "- Speaker: A person who is visibly and audibly disgusted, such as a character who has just been served a spoiled meal.\n",
658 |     "```"
659 |    ]
660 |   },
661 |   {
662 |    "cell_type": "code",
663 |    "execution_count": null,
664 |    "metadata": {},
665 |    "outputs": [
666 |     {
667 |      "data": {
668 |       "text/html": [
669 |        "\n",
670 |        "                <audio  controls=\"controls\" >\n",
[TRUNCATED]
```

async/index.md
```
1 | # Async DSPy Programming
2 |
3 | DSPy provides native support for asynchronous programming, allowing you to build more efficient and
4 | scalable applications. This guide will walk you through how to leverage async capabilities in DSPy,
5 | covering both built-in modules and custom implementations.
6 |
7 | ## Why Use Async in DSPy?
8 |
9 | Asynchronous programming in DSPy offers several benefits:
10 | - Improved performance through concurrent operations
11 | - Better resource utilization
12 | - Reduced waiting time for I/O-bound operations
13 | - Enhanced scalability for handling multiple requests
14 |
15 | ## When Should I use Sync or Async?
16 |
17 | Choosing between synchronous and asynchronous programming in DSPy depends on your specific use case.
18 | Here's a guide to help you make the right choice:
19 |
20 | Use Synchronous Programming When
21 |
22 | - You're exploring or prototyping new ideas
23 | - You're conducting research or experiments
24 | - You're building small to medium-sized applications
25 | - You need simpler, more straightforward code
26 | - You want easier debugging and error tracking
27 |
28 | Use Asynchronous Programming When:
29 |
30 | - You're building a high-throughput service (high QPS)
31 | - You're working with tools that only support async operations
32 | - You need to handle multiple concurrent requests efficiently
33 | - You're building a production service that requires high scalability
34 |
35 | ### Important Considerations
36 |
37 | While async programming offers performance benefits, it comes with some trade-offs:
38 |
39 | - More complex error handling and debugging
40 | - Potential for subtle, hard-to-track bugs
41 | - More complex code structure
42 | - Different code between ipython (Colab, Jupyter lab, Databricks notebooks, ...) and normal python runtime.
43 |
44 | We recommend starting with synchronous programming for most development scenarios and switching to async
45 | only when you have a clear need for its benefits. This approach allows you to focus on the core logic of
46 | your application before dealing with the additional complexity of async programming.
47 |
48 | ## Using Built-in Modules Asynchronously
49 |
50 | Most DSPy built-in modules support asynchronous operations through the `acall()` method. This method
51 | maintains the same interface as the synchronous `__call__` method but operates asynchronously.
52 |
53 | Here's a basic example using `dspy.Predict`:
54 |
55 | ```python
56 | import dspy
57 | import asyncio
58 | import os
59 |
60 | os.environ["OPENAI_API_KEY"] = "your_api_key"
61 |
62 | dspy.configure(lm=dspy.LM("openai/gpt-4o-mini"))
63 | predict = dspy.Predict("question->answer")
64 |
65 | async def main():
66 |     # Use acall() for async execution
67 |     output = await predict.acall(question="why did a chicken cross the kitchen?")
68 |     print(output)
69 |
70 |
71 | asyncio.run(main())
72 | ```
73 |
74 | ### Working with Async Tools
75 |
76 | DSPy's `Tool` class seamlessly integrates with async functions. When you provide an async
77 | function to `dspy.Tool`, you can execute it using `acall()`. This is particularly useful
78 | for I/O-bound operations or when working with external services.
79 |
80 | ```python
81 | import asyncio
82 | import dspy
83 | import os
84 |
85 | os.environ["OPENAI_API_KEY"] = "your_api_key"
86 |
87 | async def foo(x):
88 |     # Simulate an async operation
89 |     await asyncio.sleep(0.1)
90 |     print(f"I get: {x}")
91 |
92 | # Create a tool from the async function
93 | tool = dspy.Tool(foo)
94 |
95 | async def main():
96 |     # Execute the tool asynchronously
97 |     await tool.acall(x=2)
98 |
99 | asyncio.run(main())
100 | ```
101 |
102 | Note: When using `dspy.ReAct` with tools, calling `acall()` on the ReAct instance will automatically
103 | execute all tools asynchronously using their `acall()` methods.
104 |
105 | ## Creating Custom Async DSPy Modules
106 |
107 | To create your own async DSPy module, implement the `aforward()` method instead of `forward()`. This method
108 | should contain your module's async logic. Here's an example of a custom module that chains two async operations:
109 |
110 | ```python
111 | import dspy
112 | import asyncio
113 | import os
114 |
115 | os.environ["OPENAI_API_KEY"] = "your_api_key"
116 | dspy.configure(lm=dspy.LM("openai/gpt-4o-mini"))
117 |
118 | class MyModule(dspy.Module):
119 |     def __init__(self):
120 |         self.predict1 = dspy.ChainOfThought("question->answer")
121 |         self.predict2 = dspy.ChainOfThought("answer->simplified_answer")
122 |
123 |     async def aforward(self, question, **kwargs):
124 |         # Execute predictions sequentially but asynchronously
125 |         answer = await self.predict1.acall(question=question)
126 |         return await self.predict2.acall(answer=answer)
127 |
128 |
129 | async def main():
130 |     mod = MyModule()
131 |     result = await mod.acall(question="Why did a chicken cross the kitchen?")
132 |     print(result)
133 |
134 |
135 | asyncio.run(main())
136 | ```
```

build_ai_program/index.md
```
1 | # Build AI Programs with DSPy
2 |
3 | This section contains hands-on tutorials that guide you through building production-ready AI applications using DSPy. Each tutorial demonstrates practical use cases and shows you how to leverage DSPy's modular programming approach to create robust, maintainable AI systems.
4 |
5 | ## Core Applications
6 |
7 | ### [Managing Conversation History](../conversation_history/index.md)
8 | Learn how to manage conversation history in DSPy applications.
9 |
10 | ### [Building AI Agents with DSPy](../customer_service_agent/index.ipynb)
11 | Learn to create intelligent agents that can handle complex customer service scenarios. This tutorial shows how to build agents that can understand context, maintain conversation state, and provide helpful responses.
12 |
13 | ### [Building AI Applications by Customizing DSPy Modules](../custom_module/index.ipynb)
14 | Discover how to create custom DSPy modules tailored to your specific needs. Learn the patterns for building reusable, composable components that can be shared across different applications.
15 |
16 | ## Retrieval-Augmented Generation (RAG)
17 |
18 | ### [Retrieval-Augmented Generation (RAG)](../rag/index.ipynb)
19 | Master the fundamentals of RAG systems with DSPy. Learn how to combine retrieval mechanisms with language models to build systems that can answer questions using external knowledge sources.
20 |
21 | ### [Building RAG as Agent](../agents/index.ipynb)
22 | Take RAG to the next level by building `ReAct` agent-based systems that can reason about when and how to retrieve information, making your RAG systems more intelligent and adaptive.
23 |
24 | ### [Multi-Hop RAG](../multihop_search/index.ipynb)
25 | Build sophisticated RAG systems that can perform multi-step reasoning across multiple information sources, perfect for complex research and analysis tasks.
26 |
27 | ## Specialized Use Cases
28 |
29 | ### [Entity Extraction](../entity_extraction/index.ipynb)
30 | Learn to build systems that can identify and extract specific entities from text, essential for information processing and data analysis applications.
31 |
32 | ### [Classification](../classification/index.md)
33 | Build robust text classification systems using DSPy's modular approach with a topic classification example.
34 |
35 | ### [Privacy-Conscious Delegation](../papillon/index.md)
36 | Explore advanced techniques for building AI systems that respect privacy constraints while maintaining high performance by combining a small local model and an advanced external model.
37 |
38 | ## Advanced Reasoning
39 |
40 | ### [Program Of Thought](../program_of_thought/index.ipynb)
41 | Learn to build systems that can generate and execute code to solve complex problems, combining the power of language models with programmatic reasoning.
42 |
43 | ## Multimodal Applications
44 |
45 | ### [Image Generation Prompt iteration](../image_generation_prompting/index.ipynb)
46 | Discover how to use DSPy to iteratively improve image generation prompts, creating better visual content through systematic optimization.
47 |
48 | ### [Audio](../audio/index.ipynb)
49 | Explore audio processing applications with DSPy, learning to build systems that can understand, process, and generate audio content.
```

cache/index.md
```
1 | # Use and Customize DSPy Cache
2 |
3 | In this tutorial, we will explore the design of DSPy's caching mechanism and demonstrate how to effectively use and customize it.
4 |
5 | ## DSPy Cache Structure
6 |
7 | DSPy's caching system is architected in three distinct layers:
8 |
9 | 1.  **In-memory cache**: Implemented using `cachetools.LRUCache`, this layer provides fast access to frequently used data.
10 | 2.  **On-disk cache**: Leveraging `diskcache.FanoutCache`, this layer offers persistent storage for cached items.
11 | 3.  **Prompt cache (Server-side cache)**: This layer is managed by the LLM service provider (e.g., OpenAI, Anthropic).
12 |
13 | While DSPy does not directly control the server-side prompt cache, it offers users the flexibility to enable, disable, and customize the in-memory and on-disk caches to suit their specific requirements.
14 |
15 | ## Using DSPy Cache
16 |
17 | By default, both in-memory and on-disk caching are automatically enabled in DSPy. No specific action is required to start using the cache. When a cache hit occurs, you will observe a significant reduction in the module call's execution time. Furthermore, if usage tracking is enabled, the usage metrics for a cached call will be `None`.
18 |
19 | Consider the following example:
20 |
21 | ```python
22 | import dspy
23 | import os
24 | import time
25 |
26 | os.environ["OPENAI_API_KEY"] = "{your_openai_key}"
27 |
28 | dspy.settings.configure(lm=dspy.LM("openai/gpt-4o-mini"), track_usage=True)
29 |
30 | predict = dspy.Predict("question->answer")
31 |
32 | start = time.time()
33 | result1 = predict(question="Who is the GOAT of basketball?")
34 | print(f"Time elapse: {time.time() - start: 2f}\n\nTotal usage: {result1.get_lm_usage()}")
35 |
36 | start = time.time()
37 | result2 = predict(question="Who is the GOAT of basketball?")
38 | print(f"Time elapse: {time.time() - start: 2f}\n\nTotal usage: {result2.get_lm_usage()}")
39 | ```
40 |
41 | A sample output looks like:
42 |
43 | ```
44 | Time elapse:  4.384113
45 | Total usage: {'openai/gpt-4o-mini': {'completion_tokens': 97, 'prompt_tokens': 144, 'total_tokens': 241, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'text_tokens': None}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0, 'text_tokens': None, 'image_tokens': None}}}
46 |
47 | Time elapse:  0.000529
48 | Total usage: {}
49 | ```
50 |
51 | ## Disabling/Enabling DSPy Cache
52 |
53 | There are scenarios where you might need to disable caching, either entirely or selectively for in-memory or on-disk caches. For instance:
54 |
55 | - You require different responses for identical LM requests.
56 | - You lack disk write permissions and need to disable the on-disk cache.
57 | - You have limited memory resources and wish to disable the in-memory cache.
58 |
59 | DSPy provides the `dspy.configure_cache()` utility function for this purpose. You can use the corresponding flags to control the enabled/disabled state of each cache type:
60 |
61 | ```python
62 | dspy.configure_cache(
63 |     enable_disk_cache=False,
64 |     enable_memory_cache=False,
65 | )
66 | ```
67 |
68 | In additions, you can manage the capacity of the in-memory and on-disk caches:
69 |
70 | ```python
71 | dspy.configure_cache(
72 |     enable_disk_cache=True,
73 |     enable_memory_cache=True,
74 |     disk_size_limit_bytes=YOUR_DESIRED_VALUE,
75 |     memory_max_entries=YOUR_DESIRED_VALUE,
76 | )
77 | ```
78 |
79 | Please note that `disk_size_limit_bytes` defines the maximum size in bytes for the on-disk cache, while `memory_max_entries` specifies the maximum number of entries for the in-memory cache.
80 |
81 | ## Understanding and Customizing the Cache
82 |
83 | In specific situations, you might want to implement a custom cache, for example, to gain finer control over how cache keys are generated. By default, the cache key is derived from a hash of all request arguments sent to `litellm`, excluding credentials like `api_key`.
84 |
85 | To create a custom cache, you need to subclass `dspy.clients.Cache` and override the relevant methods:
86 |
87 | ```python
88 | class CustomCache(dspy.clients.Cache):
89 |     def __init__(self, **kwargs):
90 |         {write your own constructor}
91 |
92 |     def cache_key(self, request: dict[str, Any], ignored_args_for_cache_key: Optional[list[str]] = None) -> str:
93 |         {write your logic of computing cache key}
94 |
95 |     def get(self, request: dict[str, Any], ignored_args_for_cache_key: Optional[list[str]] = None) -> Any:
96 |         {write your cache read logic}
97 |
98 |     def put(
99 |         self,
100 |         request: dict[str, Any],
101 |         value: Any,
102 |         ignored_args_for_cache_key: Optional[list[str]] = None,
103 |         enable_memory_cache: bool = True,
104 |     ) -> None:
105 |         {write your cache write logic}
106 | ```
107 |
108 | To ensure seamless integration with the rest of DSPy, it is recommended to implement your custom cache using the same method signatures as the base class, or at a minimum, include `**kwargs` in your method definitions to prevent runtime errors during cache read/write operations.
109 |
110 | Once your custom cache class is defined, you can instruct DSPy to use it:
111 |
112 | ```python
113 | dspy.cache = CustomCache()
114 | ```
115 |
116 | Let's illustrate this with a practical example. Suppose we want the cache key computation to depend solely on the request message content, ignoring other parameters like the specific LM being called. We can create a custom cache as follows:
117 |
118 | ```python
119 | class CustomCache(dspy.clients.Cache):
120 |
121 |     def cache_key(self, request: dict[str, Any], ignored_args_for_cache_key: Optional[list[str]] = None) -> str:
122 |         messages = request.get("messages", [])
123 |         return sha256(ujson.dumps(messages, sort_keys=True).encode()).hexdigest()
124 |
125 | dspy.cache = CustomCache(enable_disk_cache=True, enable_memory_cache=True, disk_cache_dir=dspy.clients.DISK_CACHE_DIR)
126 | ```
127 |
128 | For comparison, consider executing the code below without the custom cache:
129 |
130 | ```python
131 | import dspy
132 | import os
133 | import time
134 |
135 | os.environ["OPENAI_API_KEY"] = "{your_openai_key}"
136 |
137 | dspy.settings.configure(lm=dspy.LM("openai/gpt-4o-mini"))
138 |
139 | predict = dspy.Predict("question->answer")
140 |
141 | start = time.time()
142 | result1 = predict(question="Who is the GOAT of soccer?")
143 | print(f"Time elapse: {time.time() - start: 2f}")
144 |
145 | start = time.time()
146 | with dspy.context(lm=dspy.LM("openai/gpt-4.1-mini")):
147 |     result2 = predict(question="Who is the GOAT of soccer?")
148 | print(f"Time elapse: {time.time() - start: 2f}")
149 | ```
150 |
151 | The time elapsed will indicate that the cache is not hit on the second call. However, when using the custom cache:
152 |
153 | ```python
154 | import dspy
155 | import os
156 | import time
157 | from typing import Dict, Any, Optional
158 | import ujson
159 | from hashlib import sha256
160 |
161 | os.environ["OPENAI_API_KEY"] = "{your_openai_key}"
162 |
163 | dspy.settings.configure(lm=dspy.LM("openai/gpt-4o-mini"))
164 |
165 | class CustomCache(dspy.clients.Cache):
166 |
167 |     def cache_key(self, request: dict[str, Any], ignored_args_for_cache_key: Optional[list[str]] = None) -> str:
168 |         messages = request.get("messages", [])
169 |         return sha256(ujson.dumps(messages, sort_keys=True).encode()).hexdigest()
170 |
171 | dspy.cache = CustomCache(enable_disk_cache=True, enable_memory_cache=True, disk_cache_dir=dspy.clients.DISK_CACHE_DIR)
172 |
173 | predict = dspy.Predict("question->answer")
174 |
175 | start = time.time()
176 | result1 = predict(question="Who is the GOAT of volleyball?")
177 | print(f"Time elapse: {time.time() - start: 2f}")
178 |
179 | start = time.time()
180 | with dspy.context(lm=dspy.LM("openai/gpt-4.1-mini")):
181 |     result2 = predict(question="Who is the GOAT of volleyball?")
182 | print(f"Time elapse: {time.time() - start: 2f}")
183 | ```
184 |
185 | You will observe that the cache is hit on the second call, demonstrating the effect of the custom cache key logic.
```

classification/index.md
```
1 | Please refer to [this tutorial from Drew Breunig](https://www.dbreunig.com/2024/12/12/pipelines-prompt-optimization-with-dspy.html) using DSPy.
2 |
3 | This tutorial demonstrates a few aspects of using DSPy in a highly-accessible, concrete context for categorizing historic events with a tiny LM.
```

classification_finetuning/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: Classification Fine-tuning\n",
8 |     "\n",
9 |     "Let's walk through a quick example of fine-tuning the LM weights within a DSPy program. We'll apply to a simple 77-way classification task.\n",
10 |     "\n",
11 |     "Our finetuned program will use a tiny `Llama-3.2-1B` language model, hosted locally on your GPU. To make this more interesting, we'll assume that (i) we don't have **any training labels** but (ii) we have 500 unlabeled training examples.\n",
12 |     "\n",
13 |     "### Install dependencies and download data\n",
14 |     "\n",
15 |     "Install the latest DSPy via `pip install -U dspy` and follow along (or `uv pip`, if you prefer). This tutorial depends on DSPy >= 2.6.0. You also need to run `pip install datasets`.\n",
16 |     "\n",
17 |     "This tutorial requires a local GPU at the moment for inference, though we plan to support ollama serving for finetuned models as well.\n",
18 |     "\n",
19 |     "You will also need the following dependencies:\n",
20 |     "1. Inference: We use SGLang to run local inference servers. You can install the latest version by following the instructions here: https://docs.sglang.ai/start/install.html\n",
21 |     "Shared below is the most recent install command as of 04/02/2025, but we recommend that you follow the instructions in the most up to date version by navigating to the installation link.\n",
22 |     "This ensures that the fine-tuning packages and the `sglang` package are in sync.\n",
23 |     "    ```shell\n",
24 |     "    > pip install --upgrade pip\n",
25 |     "    > pip install uv\n",
26 |     "    > uv pip install \"sglang[all]>=0.4.4.post3\" --find-links https://flashinfer.ai/whl/cu124/torch2.5/flashinfer-python\n",
27 |     "    ```\n",
28 |     "1. Fine-tuning: We use the following packages. Note that we specify the version for the transformers package as a temporary fix to a recent issue: https://github.com/huggingface/trl/issues/2338\n",
29 |     "    ```shell\n",
30 |     "    > uv pip install -U torch transformers==4.48.3 accelerate trl peft\n",
31 |     "    ```\n",
32 |     "\n",
33 |     "We recommend using `uv` package manager to speed up the installation."
34 |    ]
35 |   },
36 |   {
37 |    "cell_type": "markdown",
38 |    "metadata": {},
39 |    "source": [
40 |     "<details>\n",
41 |     "<summary>Recommended: Set up MLflow Tracing to understand what's happening under the hood.</summary>\n",
42 |     "\n",
43 |     "### MLflow DSPy Integration\n",
44 |     "\n",
45 |     "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. In this tutorial, you can use MLflow to visualize prompts and optimization progress as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
46 |     "\n",
47 |     "![MLflow Trace](./mlflow-tracing-classification.png)\n",
48 |     "\n",
49 |     "1. Install MLflow\n",
50 |     "\n",
51 |     "```bash\n",
52 |     "%pip install mlflow>=2.20\n",
53 |     "```\n",
54 |     "\n",
55 |     "2. Start MLflow UI in a separate terminal\n",
56 |     "```bash\n",
57 |     "mlflow ui --port 5000\n",
58 |     "```\n",
59 |     "\n",
60 |     "3. Connect the notebook to MLflow\n",
61 |     "```python\n",
62 |     "import mlflow\n",
63 |     "\n",
64 |     "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
65 |     "mlflow.set_experiment(\"DSPy\")\n",
66 |     "```\n",
67 |     "\n",
68 |     "4. Enabling tracing.\n",
69 |     "```python\n",
70 |     "mlflow.dspy.autolog()\n",
71 |     "```\n",
72 |     "\n",
73 |     "\n",
74 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
75 |     "</details>"
76 |    ]
77 |   },
78 |   {
79 |    "cell_type": "markdown",
80 |    "metadata": {},
81 |    "source": [
82 |     "### Dataset\n",
83 |     "\n",
84 |     "For this tutorial, we will use the Banking77 dataset."
85 |    ]
86 |   },
87 |   {
88 |    "cell_type": "code",
89 |    "execution_count": 1,
90 |    "metadata": {},
91 |    "outputs": [],
92 |    "source": [
93 |     "import dspy\n",
94 |     "import random\n",
95 |     "from dspy.datasets import DataLoader\n",
96 |     "from datasets import load_dataset\n",
97 |     "\n",
98 |     "# Load the Banking77 dataset.\n",
99 |     "CLASSES = load_dataset(\"PolyAI/banking77\", split=\"train\", trust_remote_code=True).features['label'].names\n",
100 |     "kwargs = dict(fields=(\"text\", \"label\"), input_keys=(\"text\",), split=\"train\", trust_remote_code=True)\n",
101 |     "\n",
102 |     "# Load the first 2000 examples from the dataset, and assign a hint to each *training* example.\n",
103 |     "raw_data = [\n",
104 |     "    dspy.Example(x, label=CLASSES[x.label]).with_inputs(\"text\")\n",
105 |     "    for x in DataLoader().from_huggingface(dataset_name=\"PolyAI/banking77\", **kwargs)[:1000]\n",
106 |     "]\n",
107 |     "\n",
108 |     "random.Random(0).shuffle(raw_data)"
109 |    ]
110 |   },
111 |   {
112 |    "cell_type": "markdown",
113 |    "metadata": {},
114 |    "source": [
115 |     "This dataset has 77 different categories for classification. Let's review some of them."
116 |    ]
117 |   },
118 |   {
119 |    "cell_type": "code",
120 |    "execution_count": 2,
121 |    "metadata": {},
122 |    "outputs": [
123 |     {
124 |      "data": {
125 |       "text/plain": [
126 |        "(77,\n",
127 |        " ['activate_my_card',\n",
128 |        "  'age_limit',\n",
129 |        "  'apple_pay_or_google_pay',\n",
130 |        "  'atm_support',\n",
131 |        "  'automatic_top_up',\n",
132 |        "  'balance_not_updated_after_bank_transfer',\n",
133 |        "  'balance_not_updated_after_cheque_or_cash_deposit',\n",
134 |        "  'beneficiary_not_allowed',\n",
135 |        "  'cancel_transfer',\n",
136 |        "  'card_about_to_expire'])"
137 |       ]
138 |      },
139 |      "execution_count": 2,
140 |      "metadata": {},
141 |      "output_type": "execute_result"
142 |     }
143 |    ],
144 |    "source": [
145 |     "len(CLASSES), CLASSES[:10]"
146 |    ]
147 |   },
148 |   {
149 |    "cell_type": "markdown",
150 |    "metadata": {},
151 |    "source": [
152 |     "Let us sample 500 (unlabeled) queries from Banking77. We'll use these for our bootstrapped finetuning."
153 |    ]
154 |   },
155 |   {
156 |    "cell_type": "code",
157 |    "execution_count": 3,
158 |    "metadata": {},
159 |    "outputs": [
160 |     {
161 |      "data": {
162 |       "text/plain": [
163 |        "Example({'text': 'What if there is an error on the exchange rate?'}) (input_keys={'text'})"
164 |       ]
165 |      },
166 |      "execution_count": 3,
167 |      "metadata": {},
168 |      "output_type": "execute_result"
169 |     }
170 |    ],
171 |    "source": [
172 |     "unlabeled_trainset = [dspy.Example(text=x.text).with_inputs(\"text\") for x in raw_data[:500]]\n",
173 |     "\n",
174 |     "unlabeled_trainset[0]"
175 |    ]
176 |   },
177 |   {
178 |    "cell_type": "markdown",
179 |    "metadata": {},
180 |    "source": [
181 |     "### DSPy program\n",
182 |     "\n",
183 |     "Let's say that we want a program that takes the `text` and reasons step by step and then selects one of the classes from Banking77.\n",
184 |     "\n",
185 |     "Note that this is meant mainly for illustration, or for cases where you want to inspect the model's reasoning, e.g. for a small degree of explainability. In other words, this type of task is not necessarily likely to benefit very much from explicit reasoning."
186 |    ]
187 |   },
188 |   {
189 |    "cell_type": "code",
190 |    "execution_count": 4,
191 |    "metadata": {},
192 |    "outputs": [],
193 |    "source": [
194 |     "from typing import Literal\n",
195 |     "\n",
196 |     "classify = dspy.ChainOfThought(f\"text -> label: Literal{CLASSES}\")"
197 |    ]
198 |   },
199 |   {
200 |    "cell_type": "markdown",
201 |    "metadata": {},
202 |    "source": [
203 |     "### Bootstrapped finetuning\n",
204 |     "\n",
205 |     "There are many ways to go about this, e.g. allowing the model to teach itself or using inference-time compute (e.g., ensembling) to identify cases of high confidence without labels.\n",
206 |     "\n",
207 |     "Perhaps the simplest is to use a model that we'd expect can do a reasonable job at this task as a teacher of reasoning and classification, and to distill that to our small model. All of these patterns can be expressed in a handful of lines of code.\n",
208 |     "\n",
209 |     "Let's set up the tiny `Llama-3.2-1B-Instruct` as a student LM. We'll use GPT-4o-mini as a teacher LM."
210 |    ]
211 |   },
212 |   {
213 |    "cell_type": "code",
214 |    "execution_count": null,
215 |    "metadata": {},
216 |    "outputs": [],
217 |    "source": [
218 |     "from dspy.clients.lm_local import LocalProvider\n",
219 |     "\n",
220 |     "student_lm_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
221 |     "student_lm = dspy.LM(model=f\"openai/local:{student_lm_name}\", provider=LocalProvider(), max_tokens=2000)\n",
222 |     "teacher_lm = dspy.LM('openai/gpt-4o-mini', max_tokens=3000)"
223 |    ]
224 |   },
225 |   {
226 |    "cell_type": "markdown",
227 |    "metadata": {},
228 |    "source": [
229 |     "Now, let's assign classifiers to our LMs."
230 |    ]
231 |   },
232 |   {
233 |    "cell_type": "code",
234 |    "execution_count": 6,
235 |    "metadata": {},
236 |    "outputs": [],
237 |    "source": [
238 |     "student_classify = classify.deepcopy()\n",
239 |     "student_classify.set_lm(student_lm)\n",
240 |     "\n",
241 |     "teacher_classify = classify.deepcopy()\n",
242 |     "teacher_classify.set_lm(teacher_lm)"
243 |    ]
244 |   },
245 |   {
246 |    "cell_type": "markdown",
247 |    "metadata": {},
248 |    "source": [
249 |     "Let's now launch the bootstrapped finetuning. The word \"bootstrapped\" here means that the program itself will be invoked on the training inputs and the resulting traces seen over all modules will be recorded and used for finetuning. This is the weight-optimizing variant of the various BootstrapFewShot methods in DSPy.\n",
250 |     "\n",
251 |     "On every question in the (unlabeled) training set, this will invoke the teacher program, which will produce reasoning and select a class. This will be traced and then constitute a training set for all modules (in this case, just the one CoT module) in the student program.\n",
252 |     "\n",
253 |     "When the `compile` method is called, the `BootstrapFinetune` optimizer will use the passed teacher program (or programs, you can pass a list!) to create a training dataset.\n",
254 |     "It will then use this training dataset to create a fine-tuned version of the LM set for the `student` program, replacing it with the trained LM.\n",
255 |     "Note that the trained LM will be a new LM instance (the `student_lm` object we instantiated here will be untouched!)\n",
256 |     "\n",
257 |     "Note: If you have labels, you can pass `metric` to the constructor of `BootstrapFinetune`. If you want to apply this in practice, you can pass `train_kwargs` to the constructor to control local LM training settings: `device`, `use_peft`, `num_train_epochs`, `per_device_train_batch_size`, `gradient_accumulation_steps`, `learning_rate`, `max_seq_length`, `packing`, `bf16`, and `output_dir`."
258 |    ]
259 |   },
260 |   {
261 |    "cell_type": "code",
262 |    "execution_count": null,
263 |    "metadata": {},
264 |    "outputs": [],
265 |    "source": [
266 |     "# Optional:\n",
267 |     "# [1] You can set `DSPY_FINETUNEDIR` environment variable to control where the directory that will be used to store the\n",
268 |     "#     checkpoints and fine-tuning data. If this is not set, `DSPY_CACHEDIR` is used by default.\n",
269 |     "# [2] You can set the `CUDA_VISIBLE_DEVICES` environment variable to control the GPU that will be used for fine-tuning\n",
270 |     "#     and inference. If this is not set and the default GPU that's used by HuggingFace's `transformers` library is\n",
271 |     "#     occupied, an OutOfMemoryError might be raised.\n",
272 |     "#\n",
273 |     "# import os\n",
274 |     "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
275 |     "# os.environ[\"DSPY_FINETUNEDIR\"] = \"/path/to/dir\""
276 |    ]
277 |   },
278 |   {
279 |    "cell_type": "code",
280 |    "execution_count": 7,
281 |    "metadata": {},
282 |    "outputs": [],
283 |    "source": [
284 |     "dspy.settings.experimental = True  # fine-tuning is an experimental feature, so we set a flag to enable it\n",
285 |     "\n",
286 |     "optimizer = dspy.BootstrapFinetune(num_threads=16)  # if you *do* have labels, pass metric=your_metric here!\n",
287 |     "classify_ft = optimizer.compile(student_classify, teacher=teacher_classify, trainset=unlabeled_trainset)"
288 |    ]
289 |   },
290 |   {
291 |    "cell_type": "markdown",
292 |    "metadata": {},
293 |    "source": [
294 |     "Since this is a local model, we need to explicitly launch it."
295 |    ]
296 |   },
297 |   {
298 |    "cell_type": "code",
299 |    "execution_count": 8,
300 |    "metadata": {},
301 |    "outputs": [],
302 |    "source": [
303 |     "classify_ft.get_lm().launch()"
304 |    ]
305 |   },
306 |   {
307 |    "cell_type": "markdown",
308 |    "metadata": {},
309 |    "source": [
310 |     "### Validating the finetuned program\n",
311 |     "\n",
312 |     "Let's now figure out if this was successful. We can ask the system one question and inspect its behavior."
313 |    ]
314 |   },
315 |   {
316 |    "cell_type": "code",
317 |    "execution_count": 9,
318 |    "metadata": {},
319 |    "outputs": [
320 |     {
321 |      "data": {
322 |       "text/plain": [
323 |        "Prediction(\n",
324 |        "    reasoning='The user is inquiring about a specific issue, which they did not receive and is still showing as a pending transaction. This situation typically indicates a problem with the cash withdrawal process, as the user is not receiving the money they attempted to withdraw. The appropriate label for this scenario is \"pending_cash_withdrawal,\" as it directly relates to the status of the cash withdrawal transaction.',\n",
325 |        "    label='pending_cash_withdrawal'\n",
326 |        ")"
327 |       ]
328 |      },
329 |      "execution_count": 9,
330 |      "metadata": {},
331 |      "output_type": "execute_result"
332 |     }
333 |    ],
334 |    "source": [
335 |     "classify_ft(text=\"I didn't receive my money earlier and it says the transaction is still in progress. Can you fix it?\")"
336 |    ]
337 |   },
338 |   {
339 |    "cell_type": "markdown",
340 |    "metadata": {},
341 |    "source": [
342 |     "We could also get a small set of gold labels and see if the system can generalize to unseen queries."
343 |    ]
344 |   },
345 |   {
346 |    "cell_type": "code",
347 |    "execution_count": 10,
348 |    "metadata": {},
349 |    "outputs": [
350 |     {
351 |      "data": {
352 |       "text/plain": [
353 |        "Example({'text': 'Which fiat currencies do you currently support? Will this change in this future?', 'label': 'fiat_currency_support'}) (input_keys={'text'})"
354 |       ]
355 |      },
356 |      "execution_count": 10,
357 |      "metadata": {},
358 |      "output_type": "execute_result"
359 |     }
360 |    ],
361 |    "source": [
362 |     "devset = raw_data[500:600]\n",
363 |     "devset[0]"
364 |    ]
365 |   },
366 |   {
367 |    "cell_type": "markdown",
368 |    "metadata": {},
369 |    "source": [
370 |     "Let's define an evaluator on this small dev set, where the metric ignores the reasoning and checks that the label is exactly correct."
371 |    ]
372 |   },
373 |   {
374 |    "cell_type": "code",
375 |    "execution_count": 11,
376 |    "metadata": {},
377 |    "outputs": [],
378 |    "source": [
379 |     "metric = (lambda x, y, trace=None: x.label == y.label)\n",
380 |     "evaluate = dspy.Evaluate(devset=devset, metric=metric, display_progress=True, display_table=5, num_threads=16)"
381 |    ]
382 |   },
383 |   {
384 |    "cell_type": "markdown",
385 |    "metadata": {},
386 |    "source": [
387 |     "Now, let's evaluate the finetuned 1B classifier."
388 |    ]
389 |   },
390 |   {
391 |    "cell_type": "code",
392 |    "execution_count": 12,
393 |    "metadata": {},
394 |    "outputs": [
395 |     {
396 |      "name": "stdout",
397 |      "output_type": "stream",
398 |      "text": [
399 |       "Average Metric: 51.00 / 99 (51.5%): 100%|██████████| 100/100 [00:35<00:00,  2.79it/s]"
400 |      ]
401 |     },
402 |     {
403 |      "data": {
404 |       "text/html": [
405 |        "<div>\n",
406 |        "<style scoped>\n",
407 |        "    .dataframe tbody tr th:only-of-type {\n",
408 |        "        vertical-align: middle;\n",
409 |        "    }\n",
410 |        "\n",
411 |        "    .dataframe tbody tr th {\n",
412 |        "        vertical-align: top;\n",
413 |        "    }\n",
414 |        "\n",
415 |        "    .dataframe thead th {\n",
416 |        "        text-align: right;\n",
417 |        "    }\n",
418 |        "</style>\n",
419 |        "<table border=\"1\" class=\"dataframe\">\n",
420 |        "  <thead>\n",
421 |        "    <tr style=\"text-align: right;\">\n",
422 |        "      <th></th>\n",
423 |        "      <th>text</th>\n",
424 |        "      <th>example_label</th>\n",
425 |        "      <th>reasoning</th>\n",
426 |        "      <th>pred_label</th>\n",
427 |        "      <th>&lt;lambda&gt;</th>\n",
428 |        "      <th>label</th>\n",
429 |        "    </tr>\n",
430 |        "  </thead>\n",
431 |        "  <tbody>\n",
432 |        "    <tr>\n",
433 |        "      <th>0</th>\n",
434 |        "      <td>Which fiat currencies do you currently support? Will this change i...</td>\n",
435 |        "      <td>fiat_currency_support</td>\n",
436 |        "      <td>The user is inquiring about the current support for fiat currencie...</td>\n",
437 |        "      <td>fiat_currency_support</td>\n",
438 |        "      <td>✔️ [True]</td>\n",
439 |        "      <td>NaN</td>\n",
440 |        "    </tr>\n",
441 |        "    <tr>\n",
442 |        "      <th>1</th>\n",
443 |        "      <td>I didn't receive my money earlier and it says the transaction is s...</td>\n",
444 |        "      <td>pending_cash_withdrawal</td>\n",
445 |        "      <td>The user is inquiring about a specific issue, which they did not r...</td>\n",
446 |        "      <td>pending_cash_withdrawal</td>\n",
447 |        "      <td>✔️ [True]</td>\n",
448 |        "      <td>NaN</td>\n",
449 |        "    </tr>\n",
450 |        "    <tr>\n",
451 |        "      <th>2</th>\n",
452 |        "      <td>what currencies do you accept?</td>\n",
453 |        "      <td>fiat_currency_support</td>\n",
454 |        "      <td>The user is inquiring about the currencies that are accepted, whic...</td>\n",
455 |        "      <td>fiat_currency_support</td>\n",
456 |        "      <td>✔️ [True]</td>\n",
457 |        "      <td>NaN</td>\n",
458 |        "    </tr>\n",
459 |        "    <tr>\n",
460 |        "      <th>3</th>\n",
461 |        "      <td>Where can I find your exchange rates?</td>\n",
462 |        "      <td>exchange_rate</td>\n",
463 |        "      <td>The user is inquiring about where to find exchange rates, which re...</td>\n",
464 |        "      <td>exchange_rate</td>\n",
465 |        "      <td>✔️ [True]</td>\n",
466 |        "      <td>NaN</td>\n",
467 |        "    </tr>\n",
468 |        "    <tr>\n",
469 |        "      <th>4</th>\n",
470 |        "      <td>why hasnt my card come in yet?</td>\n",
471 |        "      <td>card_arrival</td>\n",
472 |        "      <td>The user is inquiring about the status of their card, which sugges...</td>\n",
473 |        "      <td>card_arrival</td>\n",
474 |        "      <td>✔️ [True]</td>\n",
475 |        "      <td>NaN</td>\n",
476 |        "    </tr>\n",
477 |        "  </tbody>\n",
478 |        "</table>\n",
479 |        "</div>"
480 |       ],
481 |       "text/plain": [
482 |        "                                                                    text  \\\n",
483 |        "0  Which fiat currencies do you currently support? Will this change i...   \n",
484 |        "1  I didn't receive my money earlier and it says the transaction is s...   \n",
485 |        "2                                         what currencies do you accept?   \n",
486 |        "3                                  Where can I find your exchange rates?   \n",
487 |        "4                                         why hasnt my card come in yet?   \n",
488 |        "\n",
489 |        "             example_label  \\\n",
490 |        "0    fiat_currency_support   \n",
491 |        "1  pending_cash_withdrawal   \n",
492 |        "2    fiat_currency_support   \n",
493 |        "3            exchange_rate   \n",
494 |        "4             card_arrival   \n",
495 |        "\n",
496 |        "                                                               reasoning  \\\n",
497 |        "0  The user is inquiring about the current support for fiat currencie...   \n",
498 |        "1  The user is inquiring about a specific issue, which they did not r...   \n",
499 |        "2  The user is inquiring about the currencies that are accepted, whic...   \n",
500 |        "3  The user is inquiring about where to find exchange rates, which re...   \n",
501 |        "4  The user is inquiring about the status of their card, which sugges...   \n",
502 |        "\n",
503 |        "                pred_label   <lambda> label  \n",
504 |        "0    fiat_currency_support  ✔️ [True]   NaN  \n",
505 |        "1  pending_cash_withdrawal  ✔️ [True]   NaN  \n",
506 |        "2    fiat_currency_support  ✔️ [True]   NaN  \n",
507 |        "3            exchange_rate  ✔️ [True]   NaN  \n",
508 |        "4             card_arrival  ✔️ [True]   NaN  "
509 |       ]
510 |      },
511 |      "metadata": {},
512 |      "output_type": "display_data"
513 |     },
514 |     {
515 |      "data": {
516 |       "text/html": [
517 |        "\n",
518 |        "                <div style='\n",
519 |        "                    text-align: center;\n",
520 |        "                    font-size: 16px;\n",
521 |        "                    font-weight: bold;\n",
522 |        "                    color: #555;\n",
523 |        "                    margin: 10px 0;'>\n",
524 |        "                    ... 95 more rows not displayed ...\n",
525 |        "                </div>\n",
526 |        "                "
527 |       ],
528 |       "text/plain": [
529 |        "<IPython.core.display.HTML object>"
530 |       ]
531 |      },
532 |      "metadata": {},
533 |      "output_type": "display_data"
534 |     },
535 |     {
536 |      "data": {
537 |       "text/plain": [
538 |        "51.0"
539 |       ]
540 |      },
541 |      "execution_count": 13,
542 |      "metadata": {},
543 |      "output_type": "execute_result"
544 |     }
545 |    ],
546 |    "source": [
547 |     "evaluate(classify_ft)"
548 |    ]
549 |   },
550 |   {
551 |    "cell_type": "markdown",
552 |    "metadata": {},
553 |    "source": [
554 |     "<details>\n",
555 |     "<summary>Tracking Evaluation Results in MLflow Experiment</summary>\n",
556 |     "\n",
557 |     "<br/>\n",
558 |     "\n",
559 |     "To track and visualize the evaluation results over time, you can record the results in MLflow Experiment.\n",
560 |     "\n",
561 |     "\n",
562 |     "```python\n",
563 |     "import mlflow\n",
564 |     "\n",
565 |     "with mlflow.start_run(run_name=\"classifier_evaluation\"):\n",
566 |     "    evaluate_correctness = dspy.Evaluate(\n",
567 |     "        devset=devset,\n",
568 |     "        metric=extraction_correctness_metric,\n",
569 |     "        num_threads=16,\n",
570 |     "        display_progress=True,\n",
571 |     "    )\n",
572 |     "\n",
573 |     "    # Evaluate the program as usual\n",
574 |     "    result = evaluate_correctness(people_extractor)\n",
575 |     "\n",
576 |     "    # Log the aggregated score\n",
577 |     "    mlflow.log_metric(\"exact_match\", result.score)\n",
578 |     "    # Log the detailed evaluation results as a table\n",
579 |     "    mlflow.log_table(\n",
580 |     "        {\n",
581 |     "            \"Text\": [example.text for example in devset],\n",
582 |     "            \"Expected\": [example.example_label for example in devset],\n",
583 |     "            \"Predicted\": [output[1] for output in result.results],\n",
584 |     "            \"Exact match\": [output[2] for output in result.results],\n",
585 |     "        },\n",
586 |     "        artifact_file=\"eval_results.json\",\n",
587 |     "    )\n",
588 |     "```\n",
589 |     "\n",
590 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
591 |     "\n",
592 |     "</details>"
593 |    ]
594 |   },
595 |   {
596 |    "cell_type": "markdown",
597 |    "metadata": {},
598 |    "source": [
599 |     "Not bad, given that we started with no labels of the task. Even though we have no labels, you can use various strategies to boost the quality of the bootstrapped training data.\n",
600 |     "\n",
601 |     "To try that next, let's free our GPU memory by killing the finetuned LM."
602 |    ]
603 |   },
604 |   {
605 |    "cell_type": "code",
606 |    "execution_count": 14,
607 |    "metadata": {},
608 |    "outputs": [],
609 |    "source": [
610 |     "classify_ft.get_lm().kill()"
611 |    ]
612 |   },
613 |   {
614 |    "cell_type": "markdown",
615 |    "metadata": {},
616 |    "source": [
617 |     "### Bootstrapped finetuning against a metric\n",
618 |     "\n",
619 |     "If you have labels, you can generally boost this by a large margin. To do so, you can pass a `metric` to BootstrapFinetune, which it will use for filtering the trajectories over your program before it builds the finetuning data."
620 |    ]
621 |   },
622 |   {
623 |    "cell_type": "code",
624 |    "execution_count": 15,
625 |    "metadata": {},
626 |    "outputs": [],
627 |    "source": [
628 |     "optimizer = dspy.BootstrapFinetune(num_threads=16, metric=metric)\n",
629 |     "classify_ft = optimizer.compile(student_classify, teacher=teacher_classify, trainset=raw_data[:500])"
630 |    ]
631 |   },
632 |   {
633 |    "cell_type": "markdown",
634 |    "metadata": {},
635 |    "source": [
636 |     "Let's now launch and evaluate this."
637 |    ]
638 |   },
639 |   {
640 |    "cell_type": "code",
641 |    "execution_count": 16,
642 |    "metadata": {},
643 |    "outputs": [],
644 |    "source": [
645 |     "classify_ft.get_lm().launch()"
646 |    ]
647 |   },
648 |   {
649 |    "cell_type": "code",
650 |    "execution_count": 17,
651 |    "metadata": {},
652 |    "outputs": [
653 |     {
654 |      "name": "stdout",
655 |      "output_type": "stream",
656 |      "text": [
657 |       "Average Metric: 85.00 / 98 (86.7%): 100%|██████████| 100/100 [00:46<00:00,  2.14it/s]"
658 |      ]
659 |     },
660 |     {
661 |      "name": "stdout",
662 |      "output_type": "stream",
663 |      "text": [
664 |       "\n"
665 |      ]
666 |     },
667 |     {
668 |      "data": {
669 |       "text/html": [
670 |        "<div>\n",
671 |        "<style scoped>\n",
672 |        "    .dataframe tbody tr th:only-of-type {\n",
673 |        "        vertical-align: middle;\n",
674 |        "    }\n",
675 |        "\n",
676 |        "    .dataframe tbody tr th {\n",
677 |        "        vertical-align: top;\n",
678 |        "    }\n",
679 |        "\n",
680 |        "    .dataframe thead th {\n",
681 |        "        text-align: right;\n",
682 |        "    }\n",
683 |        "</style>\n",
684 |        "<table border=\"1\" class=\"dataframe\">\n",
685 |        "  <thead>\n",
686 |        "    <tr style=\"text-align: right;\">\n",
687 |        "      <th></th>\n",
688 |        "      <th>text</th>\n",
689 |        "      <th>example_label</th>\n",
690 |        "      <th>reasoning</th>\n",
691 |        "      <th>pred_label</th>\n",
692 |        "      <th>&lt;lambda&gt;</th>\n",
693 |        "      <th>label</th>\n",
694 |        "    </tr>\n",
695 |        "  </thead>\n",
696 |        "  <tbody>\n",
697 |        "    <tr>\n",
698 |        "      <th>0</th>\n",
699 |        "      <td>Which fiat currencies do you currently support? Will this change i...</td>\n",
700 |        "      <td>fiat_currency_support</td>\n",
701 |        "      <td>The user is inquiring about the fiat currencies currently supporte...</td>\n",
702 |        "      <td>fiat_currency_support</td>\n",
703 |        "      <td>✔️ [True]</td>\n",
704 |        "      <td>NaN</td>\n",
705 |        "    </tr>\n",
706 |        "    <tr>\n",
707 |        "      <th>1</th>\n",
708 |        "      <td>I didn't receive my money earlier and it says the transaction is s...</td>\n",
709 |        "      <td>pending_cash_withdrawal</td>\n",
710 |        "      <td>The user is inquiring about an unexpected fee on their account, wh...</td>\n",
711 |        "      <td>extra_charge_on_statement</td>\n",
712 |        "      <td></td>\n",
713 |        "      <td>NaN</td>\n",
714 |        "    </tr>\n",
715 |        "    <tr>\n",
716 |        "      <th>2</th>\n",
717 |        "      <td>what currencies do you accept?</td>\n",
718 |        "      <td>fiat_currency_support</td>\n",
719 |        "      <td>The user is inquiring about the types of currencies that are accep...</td>\n",
720 |        "      <td>fiat_currency_support</td>\n",
721 |        "      <td>✔️ [True]</td>\n",
722 |        "      <td>NaN</td>\n",
723 |        "    </tr>\n",
724 |        "    <tr>\n",
725 |        "      <th>3</th>\n",
726 |        "      <td>Where can I find your exchange rates?</td>\n",
727 |        "      <td>exchange_rate</td>\n",
728 |        "      <td>The user is inquiring about where to find exchange rates, which re...</td>\n",
729 |        "      <td>exchange_rate</td>\n",
730 |        "      <td>✔️ [True]</td>\n",
731 |        "      <td>NaN</td>\n",
732 |        "    </tr>\n",
733 |        "    <tr>\n",
734 |        "      <th>4</th>\n",
735 |        "      <td>why hasnt my card come in yet?</td>\n",
736 |        "      <td>card_arrival</td>\n",
737 |        "      <td>The user is inquiring about the status of their card delivery, whi...</td>\n",
738 |        "      <td>card_arrival</td>\n",
739 |        "      <td>✔️ [True]</td>\n",
740 |        "      <td>NaN</td>\n",
741 |        "    </tr>\n",
742 |        "  </tbody>\n",
743 |        "</table>\n",
744 |        "</div>"
745 |       ],
746 |       "text/plain": [
747 |        "                                                                    text  \\\n",
748 |        "0  Which fiat currencies do you currently support? Will this change i...   \n",
749 |        "1  I didn't receive my money earlier and it says the transaction is s...   \n",
750 |        "2                                         what currencies do you accept?   \n",
751 |        "3                                  Where can I find your exchange rates?   \n",
752 |        "4                                         why hasnt my card come in yet?   \n",
753 |        "\n",
754 |        "             example_label  \\\n",
755 |        "0    fiat_currency_support   \n",
756 |        "1  pending_cash_withdrawal   \n",
757 |        "2    fiat_currency_support   \n",
758 |        "3            exchange_rate   \n",
759 |        "4             card_arrival   \n",
760 |        "\n",
761 |        "                                                               reasoning  \\\n",
762 |        "0  The user is inquiring about the fiat currencies currently supporte...   \n",
763 |        "1  The user is inquiring about an unexpected fee on their account, wh...   \n",
764 |        "2  The user is inquiring about the types of currencies that are accep...   \n",
765 |        "3  The user is inquiring about where to find exchange rates, which re...   \n",
766 |        "4  The user is inquiring about the status of their card delivery, whi...   \n",
767 |        "\n",
768 |        "                  pred_label   <lambda> label  \n",
769 |        "0      fiat_currency_support  ✔️ [True]   NaN  \n",
770 |        "1  extra_charge_on_statement              NaN  \n",
771 |        "2      fiat_currency_support  ✔️ [True]   NaN  \n",
772 |        "3              exchange_rate  ✔️ [True]   NaN  \n",
773 |        "4               card_arrival  ✔️ [True]   NaN  "
774 |       ]
775 |      },
776 |      "metadata": {},
777 |      "output_type": "display_data"
778 |     },
779 |     {
780 |      "data": {
781 |       "text/html": [
782 |        "\n",
783 |        "                <div style='\n",
784 |        "                    text-align: center;\n",
785 |        "                    font-size: 16px;\n",
786 |        "                    font-weight: bold;\n",
787 |        "                    color: #555;\n",
788 |        "                    margin: 10px 0;'>\n",
789 |        "                    ... 95 more rows not displayed ...\n",
790 |        "                </div>\n",
791 |        "                "
792 |       ],
793 |       "text/plain": [
794 |        "<IPython.core.display.HTML object>"
795 |       ]
796 |      },
797 |      "metadata": {},
798 |      "output_type": "display_data"
799 |     },
800 |     {
801 |      "data": {
802 |       "text/plain": [
803 |        "85.0"
804 |       ]
805 |      },
806 |      "execution_count": 29,
807 |      "metadata": {},
808 |      "output_type": "execute_result"
809 |     }
810 |    ],
811 |    "source": [
812 |     "evaluate(classify_ft)"
813 |    ]
814 |   },
815 |   {
816 |    "cell_type": "markdown",
817 |    "metadata": {},
818 |    "source": [
819 |     "That's quite a bit better, given just 500 labels. In fact, it seems to be a lot stronger than the teacher LM gets out of the box!"
820 |    ]
821 |   },
822 |   {
823 |    "cell_type": "code",
824 |    "execution_count": 30,
825 |    "metadata": {},
826 |    "outputs": [
827 |     {
828 |      "name": "stdout",
829 |      "output_type": "stream",
830 |      "text": [
831 |       "Average Metric: 55.00 / 100 (55.0%): 100%|██████████| 100/100 [00:11<00:00,  8.88it/s]"
832 |      ]
833 |     },
834 |     {
835 |      "name": "stderr",
836 |      "output_type": "stream",
837 |      "text": [
838 |       "2025/01/08 12:38:35 INFO dspy.evaluate.evaluate: Average Metric: 55 / 100 (55.0%)\n"
839 |      ]
840 |     },
841 |     {
842 |      "name": "stdout",
843 |      "output_type": "stream",
844 |      "text": [
845 |       "\n"
846 |      ]
847 |     },
848 |     {
849 |      "data": {
850 |       "text/html": [
851 |        "<div>\n",
852 |        "<style scoped>\n",
853 |        "    .dataframe tbody tr th:only-of-type {\n",
854 |        "        vertical-align: middle;\n",
855 |        "    }\n",
856 |        "\n",
857 |        "    .dataframe tbody tr th {\n",
858 |        "        vertical-align: top;\n",
859 |        "    }\n",
860 |        "\n",
861 |        "    .dataframe thead th {\n",
862 |        "        text-align: right;\n",
863 |        "    }\n",
864 |        "</style>\n",
865 |        "<table border=\"1\" class=\"dataframe\">\n",
866 |        "  <thead>\n",
867 |        "    <tr style=\"text-align: right;\">\n",
868 |        "      <th></th>\n",
869 |        "      <th>text</th>\n",
870 |        "      <th>example_label</th>\n",
871 |        "      <th>reasoning</th>\n",
872 |        "      <th>pred_label</th>\n",
873 |        "      <th>&lt;lambda&gt;</th>\n",
874 |        "    </tr>\n",
875 |        "  </thead>\n",
876 |        "  <tbody>\n",
877 |        "    <tr>\n",
878 |        "      <th>0</th>\n",
879 |        "      <td>Which fiat currencies do you currently support? Will this change i...</td>\n",
880 |        "      <td>fiat_currency_support</td>\n",
881 |        "      <td>The user is inquiring about the fiat currencies supported by the s...</td>\n",
882 |        "      <td>fiat_currency_support</td>\n",
883 |        "      <td>✔️ [True]</td>\n",
884 |        "    </tr>\n",
885 |        "    <tr>\n",
886 |        "      <th>1</th>\n",
887 |        "      <td>I didn't receive my money earlier and it says the transaction is s...</td>\n",
888 |        "      <td>pending_cash_withdrawal</td>\n",
889 |        "      <td>The user is experiencing an issue with a transaction that is still...</td>\n",
890 |        "      <td>pending_transfer</td>\n",
891 |        "      <td></td>\n",
892 |        "    </tr>\n",
893 |        "    <tr>\n",
894 |        "      <th>2</th>\n",
895 |        "      <td>what currencies do you accept?</td>\n",
896 |        "      <td>fiat_currency_support</td>\n",
897 |        "      <td>The question is asking about the types of currencies accepted, whi...</td>\n",
898 |        "      <td>fiat_currency_support</td>\n",
899 |        "      <td>✔️ [True]</td>\n",
900 |        "    </tr>\n",
901 |        "    <tr>\n",
902 |        "      <th>3</th>\n",
903 |        "      <td>Where can I find your exchange rates?</td>\n",
904 |        "      <td>exchange_rate</td>\n",
905 |        "      <td>The user is inquiring about where to find exchange rates, which re...</td>\n",
906 |        "      <td>exchange_rate</td>\n",
907 |        "      <td>✔️ [True]</td>\n",
908 |        "    </tr>\n",
909 |        "    <tr>\n",
910 |        "      <th>4</th>\n",
911 |        "      <td>why hasnt my card come in yet?</td>\n",
912 |        "      <td>card_arrival</td>\n",
913 |        "      <td>The user is inquiring about the status of their card delivery, whi...</td>\n",
914 |        "      <td>card_delivery_estimate</td>\n",
915 |        "      <td></td>\n",
916 |        "    </tr>\n",
917 |        "  </tbody>\n",
918 |        "</table>\n",
919 |        "</div>"
920 |       ],
921 |       "text/plain": [
922 |        "                                                                    text  \\\n",
923 |        "0  Which fiat currencies do you currently support? Will this change i...   \n",
924 |        "1  I didn't receive my money earlier and it says the transaction is s...   \n",
925 |        "2                                         what currencies do you accept?   \n",
926 |        "3                                  Where can I find your exchange rates?   \n",
927 |        "4                                         why hasnt my card come in yet?   \n",
928 |        "\n",
929 |        "             example_label  \\\n",
930 |        "0    fiat_currency_support   \n",
931 |        "1  pending_cash_withdrawal   \n",
932 |        "2    fiat_currency_support   \n",
933 |        "3            exchange_rate   \n",
934 |        "4             card_arrival   \n",
935 |        "\n",
936 |        "                                                               reasoning  \\\n",
937 |        "0  The user is inquiring about the fiat currencies supported by the s...   \n",
938 |        "1  The user is experiencing an issue with a transaction that is still...   \n",
939 |        "2  The question is asking about the types of currencies accepted, whi...   \n",
940 |        "3  The user is inquiring about where to find exchange rates, which re...   \n",
941 |        "4  The user is inquiring about the status of their card delivery, whi...   \n",
942 |        "\n",
943 |        "               pred_label   <lambda>  \n",
944 |        "0   fiat_currency_support  ✔️ [True]  \n",
945 |        "1        pending_transfer             \n",
946 |        "2   fiat_currency_support  ✔️ [True]  \n",
947 |        "3           exchange_rate  ✔️ [True]  \n",
948 |        "4  card_delivery_estimate             "
949 |       ]
950 |      },
951 |      "metadata": {},
952 |      "output_type": "display_data"
953 |     },
954 |     {
955 |      "data": {
956 |       "text/html": [
957 |        "\n",
958 |        "                <div style='\n",
959 |        "                    text-align: center;\n",
960 |        "                    font-size: 16px;\n",
961 |        "                    font-weight: bold;\n",
962 |        "                    color: #555;\n",
963 |        "                    margin: 10px 0;'>\n",
964 |        "                    ... 95 more rows not displayed ...\n",
965 |        "                </div>\n",
966 |        "                "
967 |       ],
968 |       "text/plain": [
969 |        "<IPython.core.display.HTML object>"
970 |       ]
971 |      },
972 |      "metadata": {},
973 |      "output_type": "display_data"
974 |     },
975 |     {
976 |      "data": {
977 |       "text/plain": [
978 |        "55.0"
979 |       ]
980 |      },
981 |      "execution_count": 17,
982 |      "metadata": {},
983 |      "output_type": "execute_result"
984 |     }
985 |    ],
986 |    "source": [
987 |     "evaluate(teacher_classify)"
988 |    ]
989 |   },
990 |   {
991 |    "cell_type": "markdown",
992 |    "metadata": {},
993 |    "source": [
994 |     "And thanks to bootstrapping, the model learns to apply our modules to get the right label, in this case, reasoning explicitly:"
995 |    ]
996 |   },
997 |   {
998 |    "cell_type": "code",
999 |    "execution_count": 18,
1000 |    "metadata": {},
1001 |    "outputs": [
1002 |     {
1003 |      "name": "stdout",
1004 |      "output_type": "stream",
1005 |      "text": [
1006 |       "\n",
1007 |       "\n",
1008 |       "\n",
1009 |       "\n",
1010 |       "\u001b[34m[2025-01-08T12:39:42.143798]\u001b[0m\n",
1011 |       "\n",
1012 |       "\u001b[31mSystem message:\u001b[0m\n",
1013 |       "\n",
1014 |       "Your input fields are:\n",
1015 |       "1. `text` (str)\n",
1016 |       "\n",
1017 |       "Your output fields are:\n",
1018 |       "1. `reasoning` (str)\n",
1019 |       "2. `label` (Literal[activate_my_card, age_limit, apple_pay_or_google_pay, atm_support, automatic_top_up, balance_not_updated_after_bank_transfer, balance_not_updated_after_cheque_or_cash_deposit, beneficiary_not_allowed, cancel_transfer, card_about_to_expire, card_acceptance, card_arrival, card_delivery_estimate, card_linking, card_not_working, card_payment_fee_charged, card_payment_not_recognised, card_payment_wrong_exchange_rate, card_swallowed, cash_withdrawal_charge, cash_withdrawal_not_recognised, change_pin, compromised_card, contactless_not_working, country_support, declined_card_payment, declined_cash_withdrawal, declined_transfer, direct_debit_payment_not_recognised, disposable_card_limits, edit_personal_details, exchange_charge, exchange_rate, exchange_via_app, extra_charge_on_statement, failed_transfer, fiat_currency_support, get_disposable_virtual_card, get_physical_card, getting_spare_card, getting_virtual_card, lost_or_stolen_card, lost_or_stolen_phone, order_physical_card, passcode_forgotten, pending_card_payment, pending_cash_withdrawal, pending_top_up, pending_transfer, pin_blocked, receiving_money, Refund_not_showing_up, request_refund, reverted_card_payment?, supported_cards_and_currencies, terminate_account, top_up_by_bank_transfer_charge, top_up_by_card_charge, top_up_by_cash_or_cheque, top_up_failed, top_up_limits, top_up_reverted, topping_up_by_card, transaction_charged_twice, transfer_fee_charged, transfer_into_account, transfer_not_received_by_recipient, transfer_timing, unable_to_verify_identity, verify_my_identity, verify_source_of_funds, verify_top_up, virtual_card_not_working, visa_or_mastercard, why_verify_identity, wrong_amount_of_cash_received, wrong_exchange_rate_for_cash_withdrawal])\n",
1020 |       "\n",
1021 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
1022 |       "\n",
1023 |       "[[ ## text ## ]]\n",
1024 |       "{text}\n",
1025 |       "\n",
1026 |       "[[ ## reasoning ## ]]\n",
1027 |       "{reasoning}\n",
1028 |       "\n",
1029 |       "[[ ## label ## ]]\n",
1030 |       "{label}        # note: the value you produce must be one of: activate_my_card; age_limit; apple_pay_or_google_pay; atm_support; automatic_top_up; balance_not_updated_after_bank_transfer; balance_not_updated_after_cheque_or_cash_deposit; beneficiary_not_allowed; cancel_transfer; card_about_to_expire; card_acceptance; card_arrival; card_delivery_estimate; card_linking; card_not_working; card_payment_fee_charged; card_payment_not_recognised; card_payment_wrong_exchange_rate; card_swallowed; cash_withdrawal_charge; cash_withdrawal_not_recognised; change_pin; compromised_card; contactless_not_working; country_support; declined_card_payment; declined_cash_withdrawal; declined_transfer; direct_debit_payment_not_recognised; disposable_card_limits; edit_personal_details; exchange_charge; exchange_rate; exchange_via_app; extra_charge_on_statement; failed_transfer; fiat_currency_support; get_disposable_virtual_card; get_physical_card; getting_spare_card; getting_virtual_card; lost_or_stolen_card; lost_or_stolen_phone; order_physical_card; passcode_forgotten; pending_card_payment; pending_cash_withdrawal; pending_top_up; pending_transfer; pin_blocked; receiving_money; Refund_not_showing_up; request_refund; reverted_card_payment?; supported_cards_and_currencies; terminate_account; top_up_by_bank_transfer_charge; top_up_by_card_charge; top_up_by_cash_or_cheque; top_up_failed; top_up_limits; top_up_reverted; topping_up_by_card; transaction_charged_twice; transfer_fee_charged; transfer_into_account; transfer_not_received_by_recipient; transfer_timing; unable_to_verify_identity; verify_my_identity; verify_source_of_funds; verify_top_up; virtual_card_not_working; visa_or_mastercard; why_verify_identity; wrong_amount_of_cash_received; wrong_exchange_rate_for_cash_withdrawal\n",
1031 |       "\n",
1032 |       "[[ ## completed ## ]]\n",
1033 |       "\n",
1034 |       "In adhering to this structure, your objective is: \n",
1035 |       "        Given the fields `text`, produce the fields `label`.\n",
1036 |       "\n",
1037 |       "\n",
1038 |       "\u001b[31mUser message:\u001b[0m\n",
1039 |       "\n",
1040 |       "[[ ## text ## ]]\n",
1041 |       "why hasnt my card come in yet?\n",
1042 |       "\n",
1043 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## label ## ]]` (must be formatted as a valid Python Literal[activate_my_card, age_limit, apple_pay_or_google_pay, atm_support, automatic_top_up, balance_not_updated_after_bank_transfer, balance_not_updated_after_cheque_or_cash_deposit, beneficiary_not_allowed, cancel_transfer, card_about_to_expire, card_acceptance, card_arrival, card_delivery_estimate, card_linking, card_not_working, card_payment_fee_charged, card_payment_not_recognised, card_payment_wrong_exchange_rate, card_swallowed, cash_withdrawal_charge, cash_withdrawal_not_recognised, change_pin, compromised_card, contactless_not_working, country_support, declined_card_payment, declined_cash_withdrawal, declined_transfer, direct_debit_payment_not_recognised, disposable_card_limits, edit_personal_details, exchange_charge, exchange_rate, exchange_via_app, extra_charge_on_statement, failed_transfer, fiat_currency_support, get_disposable_virtual_card, get_physical_card, getting_spare_card, getting_virtual_card, lost_or_stolen_card, lost_or_stolen_phone, order_physical_card, passcode_forgotten, pending_card_payment, pending_cash_withdrawal, pending_top_up, pending_transfer, pin_blocked, receiving_money, Refund_not_showing_up, request_refund, reverted_card_payment?, supported_cards_and_currencies, terminate_account, top_up_by_bank_transfer_charge, top_up_by_card_charge, top_up_by_cash_or_cheque, top_up_failed, top_up_limits, top_up_reverted, topping_up_by_card, transaction_charged_twice, transfer_fee_charged, transfer_into_account, transfer_not_received_by_recipient, transfer_timing, unable_to_verify_identity, verify_my_identity, verify_source_of_funds, verify_top_up, virtual_card_not_working, visa_or_mastercard, why_verify_identity, wrong_amount_of_cash_received, wrong_exchange_rate_for_cash_withdrawal]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1044 |       "\n",
1045 |       "\n",
1046 |       "\u001b[31mResponse:\u001b[0m\n",
1047 |       "\n",
1048 |       "\u001b[32m[[ ## reasoning ## ]]\n",
1049 |       "The user is inquiring about the status of their card delivery, which suggests they are concerned about when they will receive their card. This aligns with the topic of card arrival and delivery estimates.\n",
1050 |       "\n",
1051 |       "[[ ## label ## ]]\n",
1052 |       "card_arrival\n",
1053 |       "\n",
1054 |       "[[ ## completed ## ]]\u001b[0m\n",
1055 |       "\n",
1056 |       "\n",
1057 |       "\n",
1058 |       "\n",
1059 |       "\n"
1060 |      ]
1061 |     }
1062 |    ],
1063 |    "source": [
1064 |     "classify_ft(text=\"why hasnt my card come in yet?\")\n",
1065 |     "dspy.inspect_history()"
1066 |    ]
1067 |   },
1068 |   {
1069 |    "cell_type": "markdown",
1070 |    "metadata": {},
1071 |    "source": [
1072 |     "<details>\n",
1073 |     "<summary>Saving fine-tuned programs in MLflow Experiment</summary>\n",
1074 |     "\n",
1075 |     "<br/>\n",
1076 |     "\n",
1077 |     "To deploy the fine-tuned program in production or share it with your team, you can save it in MLflow Experiment. Compared to simply saving it to a local file, MLflow offers the following benefits:\n",
1078 |     "\n",
1079 |     "1. **Dependency Management**: MLflow automatically save the frozen environment metadata along with the program to ensure reproducibility.\n",
1080 |     "2. **Experiment Tracking**: With MLflow, you can track the program's performance and cost along with the program itself.\n",
1081 |     "3. **Collaboration**: You can share the program and results with your team members by sharing the MLflow experiment.\n",
1082 |     "\n",
1083 |     "To save the program in MLflow, run the following code:\n",
1084 |     "\n",
1085 |     "```python\n",
1086 |     "import mlflow\n",
1087 |     "\n",
1088 |     "# Start an MLflow Run and save the program\n",
1089 |     "with mlflow.start_run(run_name=\"optimized_classifier\"):\n",
1090 |     "    model_info = mlflow.dspy.log_model(\n",
1091 |     "        classify_ft,\n",
1092 |     "        artifact_path=\"model\", # Any name to save the program in MLflow\n",
1093 |     "    )\n",
1094 |     "\n",
1095 |     "# Load the program back from MLflow\n",
1096 |     "loaded = mlflow.dspy.load_model(model_info.model_uri)\n",
1097 |     "```\n",
1098 |     "\n",
1099 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
1100 |     "\n",
1101 |     "</details>"
1102 |    ]
1103 |   }
1104 |  ],
1105 |  "metadata": {
1106 |   "kernelspec": {
1107 |    "display_name": "py311_202501",
1108 |    "language": "python",
1109 |    "name": "python3"
1110 |   },
1111 |   "language_info": {
1112 |    "codemirror_mode": {
1113 |     "name": "ipython",
1114 |     "version": 3
1115 |    },
1116 |    "file_extension": ".py",
1117 |    "mimetype": "text/x-python",
1118 |    "name": "python",
1119 |    "nbconvert_exporter": "python",
1120 |    "pygments_lexer": "ipython3",
1121 |    "version": "3.11.11"
1122 |   }
1123 |  },
1124 |  "nbformat": 4,
1125 |  "nbformat_minor": 2
1126 | }
```

conversation_history/index.md
```
1 | # Managing Conversation History
2 |
3 | Maintaining conversation history is a fundamental feature when building AI applications such as chatbots. While DSPy does not provide automatic conversation history management within `dspy.Module`, it offers the `dspy.History` utility to help you manage conversation history effectively.
4 |
5 | ## Using `dspy.History` to Manage Conversation History
6 |
7 | The `dspy.History` class can be used as an input field type, containing a `messages: list[dict[str, Any]]` attribute that stores the conversation history. Each entry in this list is a dictionary with keys corresponding to the fields defined in your signature. See the example below:
8 |
9 | ```python
10 | import dspy
11 | import os
12 |
13 | os.environ["OPENAI_API_KEY"] = "{your_openai_api_key}"
14 |
15 | dspy.settings.configure(lm=dspy.LM("openai/gpt-4o-mini"))
16 |
17 | class QA(dspy.Signature):
18 |     question: str = dspy.InputField()
19 |     history: dspy.History = dspy.InputField()
20 |     answer: str = dspy.OutputField()
21 |
22 | predict = dspy.Predict(QA)
23 | history = dspy.History(messages=[])
24 |
25 | while True:
26 |     question = input("Type your question, end conversation by typing 'finish': ")
27 |     if question == "finish":
28 |         break
29 |     outputs = predict(question=question, history=history)
30 |     print(f"\n{outputs.answer}\n")
31 |     history.messages.append({"question": question, **outputs})
32 |
33 | dspy.inspect_history()
34 | ```
35 |
36 | There are two key steps when using the conversation history:
37 |
38 | - **Include a field of type `dspy.History` in your Signature.**
39 | - **Maintain a history instance at runtime, appending new conversation turns to it.** Each entry should include all relevant input and output field information.
40 |
41 | A sample run might look like this:
42 |
43 | ```
44 | Type your question, end conversation by typing 'finish': do you know the competition between pytorch and tensorflow?
45 |
46 | Yes, there is a notable competition between PyTorch and TensorFlow, which are two of the most popular deep learning frameworks. PyTorch, developed by Facebook, is known for its dynamic computation graph, which allows for more flexibility and ease of use, especially in research settings. TensorFlow, developed by Google, initially used a static computation graph but has since introduced eager execution to improve usability. TensorFlow is often favored in production environments due to its scalability and deployment capabilities. Both frameworks have strong communities and extensive libraries, and the choice between them often depends on specific project requirements and personal preference.
47 |
48 | Type your question, end conversation by typing 'finish': which one won the battle? just tell me the result, don't include any reasoning, thanks!
49 |
50 | There is no definitive winner; both PyTorch and TensorFlow are widely used and have their own strengths.
51 | Type your question, end conversation by typing 'finish': finish
52 |
53 |
54 |
55 |
56 | [2025-07-11T16:35:57.592762]
57 |
58 | System message:
59 |
60 | Your input fields are:
61 | 1. `question` (str):
62 | 2. `history` (History):
63 | Your output fields are:
64 | 1. `answer` (str):
65 | All interactions will be structured in the following way, with the appropriate values filled in.
66 |
67 | [[ ## question ## ]]
68 | {question}
69 |
70 | [[ ## history ## ]]
71 | {history}
72 |
73 | [[ ## answer ## ]]
74 | {answer}
75 |
76 | [[ ## completed ## ]]
77 | In adhering to this structure, your objective is:
78 |         Given the fields `question`, `history`, produce the fields `answer`.
79 |
80 |
81 | User message:
82 |
83 | [[ ## question ## ]]
84 | do you know the competition between pytorch and tensorflow?
85 |
86 |
87 | Assistant message:
88 |
89 | [[ ## answer ## ]]
90 | Yes, there is a notable competition between PyTorch and TensorFlow, which are two of the most popular deep learning frameworks. PyTorch, developed by Facebook, is known for its dynamic computation graph, which allows for more flexibility and ease of use, especially in research settings. TensorFlow, developed by Google, initially used a static computation graph but has since introduced eager execution to improve usability. TensorFlow is often favored in production environments due to its scalability and deployment capabilities. Both frameworks have strong communities and extensive libraries, and the choice between them often depends on specific project requirements and personal preference.
91 |
92 | [[ ## completed ## ]]
93 |
94 |
95 | User message:
96 |
97 | [[ ## question ## ]]
98 | which one won the battle? just tell me the result, don't include any reasoning, thanks!
99 |
100 | Respond with the corresponding output fields, starting with the field `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.
101 |
102 |
103 | Response:
104 |
105 | [[ ## answer ## ]]
106 | There is no definitive winner; both PyTorch and TensorFlow are widely used and have their own strengths.
107 |
108 | [[ ## completed ## ]]
109 | ```
110 |
111 | Notice how each user input and assistant response is appended to the history, allowing the model to maintain context across turns.
112 |
113 | The actual prompt sent to the language model is a multi-turn message, as shown by the output of `dspy.inspect_history`. Each conversation turn is represented as a user message followed by an assistant message.
114 |
115 | ## History in Few-shot Examples
116 |
117 | You may notice that `history` does not appear in the input fields section of the prompt, even though it is listed as an input field (e.g., "2. `history` (History):" in the system message). This is intentional: when formatting few-shot examples that include conversation history, DSPy does not expand the history into multiple turns. Instead, to remain compatible with the OpenAI standard format, each few-shot example is represented as a single turn.
118 |
119 | For example:
120 |
121 | ```
122 | import dspy
123 |
124 | dspy.settings.configure(lm=dspy.LM("openai/gpt-4o-mini"))
125 |
126 |
127 | class QA(dspy.Signature):
128 |     question: str = dspy.InputField()
129 |     history: dspy.History = dspy.InputField()
130 |     answer: str = dspy.OutputField()
131 |
132 |
133 | predict = dspy.Predict(QA)
134 | history = dspy.History(messages=[])
135 |
136 | predict.demos.append(
137 |     dspy.Example(
138 |         question="What is the capital of France?",
139 |         history=dspy.History(
140 |             messages=[{"question": "What is the capital of Germany?", "answer": "The capital of Germany is Berlin."}]
141 |         ),
142 |         answer="The capital of France is Paris.",
143 |     )
144 | )
145 |
146 | predict(question="What is the capital of America?", history=dspy.History(messages=[]))
147 | dspy.inspect_history()
148 | ```
149 |
150 | The resulting history will look like this:
151 |
152 | ```
153 | [2025-07-11T16:53:10.994111]
154 |
155 | System message:
156 |
157 | Your input fields are:
158 | 1. `question` (str):
159 | 2. `history` (History):
160 | Your output fields are:
161 | 1. `answer` (str):
162 | All interactions will be structured in the following way, with the appropriate values filled in.
163 |
164 | [[ ## question ## ]]
165 | {question}
166 |
167 | [[ ## history ## ]]
168 | {history}
169 |
170 | [[ ## answer ## ]]
171 | {answer}
172 |
173 | [[ ## completed ## ]]
174 | In adhering to this structure, your objective is:
175 |         Given the fields `question`, `history`, produce the fields `answer`.
176 |
177 |
178 | User message:
179 |
180 | [[ ## question ## ]]
181 | What is the capital of France?
182 |
183 | [[ ## history ## ]]
184 | {"messages": [{"question": "What is the capital of Germany?", "answer": "The capital of Germany is Berlin."}]}
185 |
186 |
187 | Assistant message:
188 |
189 | [[ ## answer ## ]]
190 | The capital of France is Paris.
191 |
192 | [[ ## completed ## ]]
193 |
194 |
195 | User message:
196 |
197 | [[ ## question ## ]]
198 | What is the capital of Germany?
199 |
200 | Respond with the corresponding output fields, starting with the field `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.
201 |
202 |
203 | Response:
204 |
205 | [[ ## answer ## ]]
206 | The capital of Germany is Berlin.
207 |
208 | [[ ## completed ## ]]
209 | ```
210 |
211 | As you can see, the few-shot example does not expand the conversation history into multiple turns. Instead, it represents the history as JSON data within its section:
212 |
213 | ```
214 | [[ ## history ## ]]
215 | {"messages": [{"question": "What is the capital of Germany?", "answer": "The capital of Germany is Berlin."}]}
216 | ```
217 |
218 | This approach ensures compatibility with standard prompt formats while still providing the model with relevant conversational context.
219 |
```

core_development/index.md
```
1 | # Tools, Development, and Deployment
2 |
3 | This section covers essential DSPy features and best practices for professional AI development. Learn how to implement key functionalities like streaming, caching, deployment, and monitoring in your DSPy applications. These tutorials focus on the practical aspects of building production-ready systems.
4 |
5 | ## Integration and Tooling
6 |
7 | ### [Use MCP in DSPy](../mcp/index.md)
8 | Learn to integrate Model Context Protocol (MCP) with DSPy applications. This tutorial shows how to leverage MCP for enhanced context management and more sophisticated AI interactions.
9 |
10 | ### [Output Refinement](../output_refinement/best-of-n-and-refine.md)
11 | Master techniques for improving output quality through refinement strategies. Learn how to implement best-of-N sampling and iterative refinement to get higher-quality results from your DSPy programs.
12 |
13 | ## Data Management and Persistence
14 |
15 | ### [Saving and Loading](../saving/index.md)
16 | Understand how to persist and restore DSPy programs and their optimized states. Learn best practices for model versioning, checkpoint management, and program serialization.
17 |
18 | ### [Cache](../cache/index.md)
19 | Implement efficient caching strategies to improve performance and reduce API costs. Learn how to configure and use DSPy's caching mechanisms effectively in different scenarios.
20 |
21 | ## Production Deployment
22 |
23 | ### [Deployment](../deployment/index.md)
24 | Learn to deploy DSPy applications in production environments. This tutorial covers multiple deployment strategies such as FastAPI and MLflow.
25 |
26 | ### [Streaming](../streaming/index.md)
27 | Implement real-time streaming capabilities in your DSPy applications. Learn how to handle streaming responses for better user experience in interactive applications.
28 |
29 | ### [Async](../async/index.md)
30 | Build asynchronous DSPy applications for improved performance and scalability. Learn async/await patterns and concurrent execution strategies for high-throughput systems.
31 |
32 | ## Monitoring and Optimization
33 |
34 | ### [Debugging & Observability](../observability/index.md)
35 | Master debugging and monitoring techniques for DSPy applications. Learn to use comprehensive logging, tracing, and error handling for production systems.
36 |
37 | ### [Tracking DSPy Optimizers](../optimizer_tracking/index.md)
38 | Learn to track and analyze optimizer performance and behavior. Understand how to monitor optimization processes and enhance the reproducibility of the optimization.
```

custom_module/index.ipynb
```
1 | {
2 |   "cells": [
3 |     {
4 |       "cell_type": "markdown",
5 |       "metadata": {
6 |         "id": "1cR_pjqz1AsF"
7 |       },
8 |       "source": [
9 |         "# Building AI Applications by Customizing DSPy Modules\n",
10 |         "\n",
11 |         "In this guide, we will walk you through how to build a GenAI application by customizing `dspy.Module`.\n",
12 |         "\n",
13 |         "A [DSPy module](https://dspy.ai/learn/programming/modules/) is the building block for DSPy programs.\n",
14 |         "\n",
15 |         "- Each built-in module abstracts a prompting technique (like chain of thought or ReAct). Crucially, they are generalized to handle any signature.\n",
16 |         "\n",
17 |         "- A DSPy module has learnable parameters (i.e., the little pieces comprising the prompt and the LM weights) and can be invoked (called) to process inputs and return outputs.\n",
18 |         "\n",
19 |         "- Multiple modules can be composed into bigger modules (programs). DSPy modules are inspired directly by NN modules in PyTorch, but applied to LM programs.\n",
20 |         "\n",
21 |         "Although you can build a DSPy program without implementing a custom module, we highly recommend putting your logic with a custom module so that you can use other DSPy features, like DSPy optimizer or MLflow DSPy tracing."
22 |       ]
23 |     },
24 |     {
25 |       "cell_type": "markdown",
26 |       "metadata": {
27 |         "id": "KBYjBQtv3Cn5"
28 |       },
29 |       "source": [
30 |         "Before getting started, make sure you have DSPy installed:\n",
31 |         "\n",
32 |         "```\n",
33 |         "!pip install dspy\n",
34 |         "```"
35 |       ]
36 |     },
37 |     {
38 |       "cell_type": "markdown",
39 |       "metadata": {},
40 |       "source": [
41 |         "<details>\n",
42 |         "<summary>Recommended: Set up MLflow Tracing to understand what's happening under the hood.</summary>\n",
43 |         "\n",
44 |         "### MLflow DSPy Integration\n",
45 |         "\n",
46 |         "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. In this tutorial, you can use MLflow to visualize prompts and optimization progress as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
47 |         "\n",
48 |         "![MLflow Trace](./mlflow-tracing-custom-module.png)\n",
49 |         "\n",
50 |         "1. Install MLflow\n",
51 |         "\n",
52 |         "```bash\n",
53 |         "%pip install mlflow>=3.0.0\n",
54 |         "```\n",
55 |         "\n",
56 |         "2. Start MLflow UI in a separate terminal\n",
57 |         "```bash\n",
58 |         "mlflow ui --port 5000 --backend-store-uri sqlite:///mlruns.db\n",
59 |         "```\n",
60 |         "\n",
61 |         "3. Connect the notebook to MLflow\n",
62 |         "```python\n",
63 |         "import mlflow\n",
64 |         "\n",
65 |         "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
66 |         "mlflow.set_experiment(\"DSPy\")\n",
67 |         "```\n",
68 |         "\n",
69 |         "4. Enabling tracing.\n",
70 |         "```python\n",
71 |         "mlflow.dspy.autolog()\n",
72 |         "```\n",
73 |         "\n",
74 |         "\n",
75 |         "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
76 |         "</details>"
77 |       ]
78 |     },
79 |     {
80 |       "cell_type": "markdown",
81 |       "metadata": {
82 |         "id": "reQSTM8a8qMf"
83 |       },
84 |       "source": [
85 |         "## Customize DSPy Module\n",
86 |         "\n",
87 |         "You can implement custom prompting logic and integrate external tools or services by customizing a DSPy module. To achieve this, subclass from `dspy.Module` and implement the following two key methods:\n",
88 |         "\n",
89 |         "- `__init__`: This is the constructor, where you define the attributes and sub-modules of your program.\n",
90 |         "- `forward`: This method contains the core logic of your DSPy program.\n",
91 |         "\n",
92 |         "Within the `forward()` method, you are not limited to calling only other DSPy modules; you can also integrate any standard Python functions, such as those for interacting with Langchain/Agno agents, MCP tools, database handlers, and more.\n",
93 |         "\n",
94 |         "The basic structure for a custom DSPy module looks like this:\n",
95 |         "\n",
96 |         "```python\n",
97 |         "class MyProgram(dspy.Module):\n",
98 |         "    \n",
99 |         "    def __init__(self, ...):\n",
100 |         "        # Define attributes and sub-modules here\n",
101 |         "        {constructor_code}\n",
102 |         "\n",
103 |         "    def forward(self, input_name1, input_name2, ...):\n",
104 |         "        # Implement your program's logic here\n",
105 |         "        {custom_logic_code}\n",
106 |         "```"
107 |       ]
108 |     },
109 |     {
110 |       "cell_type": "markdown",
111 |       "metadata": {
112 |         "id": "DziTWwT8_TrY"
113 |       },
114 |       "source": [
115 |         "Let's illustrate this with a practical code example. We will build a simple Retrieval-Augmented Generation (RAG) application with multiple stages:\n",
116 |         "\n",
117 |         "1.  **Query Generation:** Generate a suitable query based on the user's question to retrieve relevant context.\n",
118 |         "2.  **Context Retrieval:** Fetch context using the generated query.\n",
119 |         "3.  **Answer Generation:** Produce a final answer based on the retrieved context and the original question.\n",
120 |         "\n",
121 |         "The code implementation for this multi-stage program is shown below."
122 |       ]
123 |     },
124 |     {
125 |       "cell_type": "code",
126 |       "execution_count": 3,
127 |       "metadata": {
128 |         "id": "lAoV5_v7YlvN"
129 |       },
130 |       "outputs": [],
131 |       "source": [
132 |         "import dspy\n",
133 |         "\n",
134 |         "class QueryGenerator(dspy.Signature):\n",
135 |         "    \"\"\"Generate a query based on question to fetch relevant context\"\"\"\n",
136 |         "    question: str = dspy.InputField()\n",
137 |         "    query: str = dspy.OutputField()\n",
138 |         "\n",
139 |         "def search_wikipedia(query: str) -> list[str]:\n",
140 |         "    \"\"\"Query ColBERT endpoint, which is a knowledge source based on wikipedia data\"\"\"\n",
141 |         "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=1)\n",
142 |         "    return [x[\"text\"] for x in results]\n",
143 |         "\n",
144 |         "class RAG(dspy.Module):\n",
145 |         "    def __init__(self):\n",
146 |         "        self.query_generator = dspy.Predict(QueryGenerator)\n",
147 |         "        self.answer_generator = dspy.ChainOfThought(\"question,context->answer\")\n",
148 |         "\n",
149 |         "    def forward(self, question, **kwargs):\n",
150 |         "        query = self.query_generator(question=question).query\n",
151 |         "        context = search_wikipedia(query)[0]\n",
152 |         "        return self.answer_generator(question=question, context=context).answer"
153 |       ]
154 |     },
155 |     {
156 |       "cell_type": "markdown",
157 |       "metadata": {},
158 |       "source": [
159 |         "Let's take a look at the `forward` method. We first send the question to `self.query_generator`, which is a `dspy.Predict`, to get the query for context retrieving. Then we use the query to call ColBERT and keep the first context retrieved. Finally, we send the question and context into `self.answer_generator`, which is a `dspy.ChainOfThought` to generate the final answer."
160 |       ]
161 |     },
162 |     {
163 |       "cell_type": "markdown",
164 |       "metadata": {
165 |         "id": "FBq_4e8NamwY"
166 |       },
167 |       "source": [
168 |         "Next, we'll create an instance of our `RAG` module to run the program.\n",
169 |         "\n",
170 |         "**Important:** When invoking a custom DSPy module, you should use the module instance directly (which calls the `__call__` method internally), rather than calling the `forward()` method explicitly. The `__call__` method handles necessary internal processing before executing the `forward` logic."
171 |       ]
172 |     },
173 |     {
174 |       "cell_type": "code",
175 |       "execution_count": 7,
176 |       "metadata": {
177 |         "colab": {
178 |           "base_uri": "https://localhost:8080/"
179 |         },
180 |         "id": "ZR7xcFSTa596",
181 |         "outputId": "f3427754-8a16-48fe-c540-8c9f31d9a30d"
182 |       },
183 |       "outputs": [
184 |         {
185 |           "name": "stdout",
186 |           "output_type": "stream",
187 |           "text": [
188 |             "The question of whether LeBron James is the basketball GOAT is subjective and depends on personal opinions. Many consider him one of the greatest due to his achievements and impact on the game, but others may argue for different players like Michael Jordan.\n"
189 |           ]
190 |         }
191 |       ],
192 |       "source": [
193 |         "import os\n",
194 |         "\n",
195 |         "os.environ[\"OPENAI_API_KEY\"] = \"{your_openai_api_key}\"\n",
196 |         "\n",
197 |         "dspy.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"))\n",
198 |         "rag = RAG()\n",
199 |         "print(rag(question=\"Is Lebron James the basketball GOAT?\"))"
200 |       ]
201 |     },
202 |     {
203 |       "cell_type": "markdown",
204 |       "metadata": {},
205 |       "source": [
206 |         "That's it! In summary, to build your GenAI applications, we just put the custom logic into the `forward()` method, then create a module instance and call the instance itself."
207 |       ]
208 |     },
209 |     {
210 |       "cell_type": "markdown",
211 |       "metadata": {
212 |         "id": "aYAYc-Hg39ri"
213 |       },
214 |       "source": [
215 |         "## Why Customizing Module?\n",
216 |         "\n",
217 |         "DSPy is a lightweight authoring and optimization framework, and our focus is to resolve the mess of prompt engineering by transforming prompting (string in, string out) LLM into programming LLM (structured inputs in, structured outputs out) for robust AI system.\n",
218 |         "\n",
219 |         "While we provide pre-built modules which have custom prompting logic like `dspy.ChainOfThought` for reasoning, `dspy.ReAct` for tool calling agent to facilitate building your AI applications, we don't aim at standardizing how you build agents.\n",
220 |         "\n",
221 |         "In DSPy, your application logic simply goes to the `forward` method of your custom Module, which doesn't have any constraint as long as you are writing python code. With this layout, DSPy is easy to migrate to from other frameworks or vanilla SDK usage, and easy to migrate off because essentially it's just python code.\n"
222 |       ]
223 |     }
224 |   ],
225 |   "metadata": {
226 |     "colab": {
227 |       "provenance": []
228 |     },
229 |     "kernelspec": {
230 |       "display_name": "Python 3",
231 |       "name": "python3"
232 |     },
233 |     "language_info": {
234 |       "name": "python"
235 |     }
236 |   },
237 |   "nbformat": 4,
238 |   "nbformat_minor": 0
239 | }
```

customer_service_agent/index.ipynb
```
1 | {
2 |   "cells": [
3 |     {
4 |       "cell_type": "markdown",
5 |       "metadata": {
6 |         "id": "XicO2XPbEBVD"
7 |       },
8 |       "source": [
9 |         "# Build AI Agents with DSPy\n",
10 |         "\n",
11 |         "In this tutorial, we will walk you through how to build an AI agents with DSPy. AI agents refer to the system that can autonomously perceive its environment, make decisions, and take actions to achieve specific goals. Unlike a single model prompt, an agent typically follows a loop of reasoning, planning, and acting, often integrating tools like search engines, APIs, or memory to complete complex tasks.\n",
12 |         "\n",
13 |         "This tutorial focuses on a popular architecture of AI agents called ReAct, standing for **Re**asoning and **Act**ing, which provides a task description along with a list of tools to LM, then lets LM decide whether to call tools for more obseravations, or generate the final output.\n",
14 |         "\n",
15 |         "As the demo, let's build a simple airline customer service agent that can do the following:\n",
16 |         "\n",
17 |         "- Book new trips on behalf of the user.\n",
18 |         "- Modify existing trips, including flight change and cancellation.\n",
19 |         "- On tasks it cannot handle, raise a customer support ticket.\n",
20 |         "\n",
21 |         "We will build it from `dspy.ReAct` module.\n"
22 |       ]
23 |     },
24 |     {
25 |       "cell_type": "markdown",
26 |       "metadata": {
27 |         "id": "8dYvGkoWG3C7"
28 |       },
29 |       "source": [
30 |         "## Install Dependencies\n",
31 |         "\n",
32 |         "Before starting, let's install the required packages:\n",
33 |         "\n",
34 |         "```\n",
35 |         "!pip install -qU dspy pydantic\n",
36 |         "```"
37 |       ]
38 |     },
39 |     {
40 |       "cell_type": "markdown",
41 |       "metadata": {},
42 |       "source": [
43 |         "<details>\n",
44 |         "<summary>Recommended: Set up MLflow Tracing to understand what's happening under the hood.</summary>\n",
45 |         "\n",
46 |         "### MLflow DSPy Integration\n",
47 |         "\n",
48 |         "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. In this tutorial, you can use MLflow to visualize prompts and optimization progress as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
49 |         "\n",
50 |         "![MLflow Trace](./mlflow-tracing-customer-service-agent.png)\n",
51 |         "\n",
52 |         "1. Install MLflow\n",
53 |         "\n",
54 |         "```bash\n",
55 |         "%pip install mlflow>=3.0.0\n",
56 |         "```\n",
57 |         "\n",
58 |         "2. Start MLflow UI in a separate terminal\n",
59 |         "```bash\n",
60 |         "mlflow ui --port 5000 --backend-store-uri sqlite:///mlruns.db\n",
61 |         "```\n",
62 |         "\n",
63 |         "3. Connect the notebook to MLflow\n",
64 |         "```python\n",
65 |         "import mlflow\n",
66 |         "\n",
67 |         "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
68 |         "mlflow.set_experiment(\"DSPy\")\n",
69 |         "```\n",
70 |         "\n",
71 |         "4. Enabling tracing.\n",
72 |         "```python\n",
73 |         "mlflow.dspy.autolog()\n",
74 |         "```\n",
75 |         "\n",
76 |         "\n",
77 |         "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
78 |         "</details>"
79 |       ]
80 |     },
81 |     {
82 |       "cell_type": "markdown",
83 |       "metadata": {
84 |         "id": "W_rhpcE2HAMO"
85 |       },
86 |       "source": [
87 |         "## Define Tools\n",
88 |         "\n",
89 |         "We need to prepare a list of tools so that the agent can behave like a human airline service agent:\n",
90 |         "\n",
91 |         "- `fetch_flight_info`: get flight information for certain dates.\n",
92 |         "- `pick_flight`: pick the best flight based on some criteria.\n",
93 |         "- `book_flight`: book a flight on behalf of the user.\n",
94 |         "- `fetch_itinerary`: get the information of a booked itinerary.\n",
95 |         "- `cancel_itinerary`: cancel a booked itinerary.\n",
96 |         "- `get_user_info`: get users' information.\n",
97 |         "- `file_ticket`: file a backlog ticket to have human assist.\n"
98 |       ]
99 |     },
100 |     {
101 |       "cell_type": "markdown",
102 |       "metadata": {
103 |         "id": "Zr0r8FVgI8vQ"
104 |       },
105 |       "source": [
106 |         "### Define Data Structure\n",
107 |         "\n",
108 |         "Before defining the tools, we need to define the data structure. In real production, this will be the database schema. As a demo, we just define the data structure as [pydantic models](https://docs.pydantic.dev/latest/concepts/models/) for simplicity."
109 |       ]
110 |     },
111 |     {
112 |       "cell_type": "code",
113 |       "execution_count": 1,
114 |       "metadata": {
115 |         "id": "nKjBVt3MJQR-"
116 |       },
117 |       "outputs": [],
118 |       "source": [
119 |         "from pydantic import BaseModel\n",
120 |         "\n",
121 |         "class Date(BaseModel):\n",
122 |         "    # Somehow LLM is bad at specifying `datetime.datetime`, so\n",
123 |         "    # we define a custom class to represent the date.\n",
124 |         "    year: int\n",
125 |         "    month: int\n",
126 |         "    day: int\n",
127 |         "    hour: int\n",
128 |         "\n",
129 |         "class UserProfile(BaseModel):\n",
130 |         "    user_id: str\n",
131 |         "    name: str\n",
132 |         "    email: str\n",
133 |         "\n",
134 |         "class Flight(BaseModel):\n",
135 |         "    flight_id: str\n",
136 |         "    date_time: Date\n",
137 |         "    origin: str\n",
138 |         "    destination: str\n",
139 |         "    duration: float\n",
140 |         "    price: float\n",
141 |         "\n",
142 |         "class Itinerary(BaseModel):\n",
143 |         "    confirmation_number: str\n",
144 |         "    user_profile: UserProfile\n",
145 |         "    flight: Flight\n",
146 |         "\n",
147 |         "class Ticket(BaseModel):\n",
148 |         "    user_request: str\n",
149 |         "    user_profile: UserProfile"
150 |       ]
151 |     },
152 |     {
153 |       "cell_type": "markdown",
154 |       "metadata": {
155 |         "id": "JrZkTeI4JbcW"
156 |       },
157 |       "source": [
158 |         "### Create Dummy Data\n",
159 |         "\n",
160 |         "Let's also create some dummy data so that the airline agent can do the work. We need to create a few flights and a few users, and initialize empty dictionaries for the itineraries and custom support tickets."
161 |       ]
162 |     },
163 |     {
164 |       "cell_type": "code",
165 |       "execution_count": 2,
166 |       "metadata": {
167 |         "id": "FJDzsHjKJwWb"
168 |       },
169 |       "outputs": [],
170 |       "source": [
171 |         "user_database = {\n",
172 |         "    \"Adam\": UserProfile(user_id=\"1\", name=\"Adam\", email=\"adam@gmail.com\"),\n",
173 |         "    \"Bob\": UserProfile(user_id=\"2\", name=\"Bob\", email=\"bob@gmail.com\"),\n",
174 |         "    \"Chelsie\": UserProfile(user_id=\"3\", name=\"Chelsie\", email=\"chelsie@gmail.com\"),\n",
175 |         "    \"David\": UserProfile(user_id=\"4\", name=\"David\", email=\"david@gmail.com\"),\n",
176 |         "}\n",
177 |         "\n",
178 |         "flight_database = {\n",
179 |         "    \"DA123\": Flight(\n",
180 |         "        flight_id=\"DA123\",  # DSPy Airline 123\n",
181 |         "        origin=\"SFO\",\n",
182 |         "        destination=\"JFK\",\n",
183 |         "        date_time=Date(year=2025, month=9, day=1, hour=1),\n",
184 |         "        duration=3,\n",
185 |         "        price=200,\n",
186 |         "    ),\n",
187 |         "    \"DA125\": Flight(\n",
188 |         "        flight_id=\"DA125\",\n",
189 |         "        origin=\"SFO\",\n",
190 |         "        destination=\"JFK\",\n",
191 |         "        date_time=Date(year=2025, month=9, day=1, hour=7),\n",
192 |         "        duration=9,\n",
193 |         "        price=500,\n",
194 |         "    ),\n",
195 |         "    \"DA456\": Flight(\n",
196 |         "        flight_id=\"DA456\",\n",
197 |         "        origin=\"SFO\",\n",
198 |         "        destination=\"SNA\",\n",
199 |         "        date_time=Date(year=2025, month=10, day=1, hour=1),\n",
200 |         "        duration=2,\n",
201 |         "        price=100,\n",
202 |         "    ),\n",
203 |         "    \"DA460\": Flight(\n",
204 |         "        flight_id=\"DA460\",\n",
205 |         "        origin=\"SFO\",\n",
206 |         "        destination=\"SNA\",\n",
207 |         "        date_time=Date(year=2025, month=10, day=1, hour=9),\n",
208 |         "        duration=2,\n",
209 |         "        price=120,\n",
210 |         "    ),\n",
211 |         "}\n",
212 |         "\n",
213 |         "itinery_database = {}\n",
214 |         "ticket_database = {}"
215 |       ]
216 |     },
217 |     {
218 |       "cell_type": "markdown",
219 |       "metadata": {
220 |         "id": "-iGVa5WiKFp_"
221 |       },
222 |       "source": [
223 |         "### Define the Tools\n",
224 |         "\n",
225 |         "Now we can define the tools. In order to have `dspy.ReAct` function properly, every function should:\n",
226 |         "\n",
227 |         "- Have a docstring which defines what the tool does. If the function name is self-explanable, then you can leave the docstring empty.\n",
228 |         "- Have type hint for the arguments, which is necessary for LM to generate the arguments in the right format."
229 |       ]
230 |     },
231 |     {
232 |       "cell_type": "code",
233 |       "execution_count": 3,
234 |       "metadata": {
235 |         "id": "-wQGzf6qK7P5"
236 |       },
237 |       "outputs": [],
238 |       "source": [
239 |         "import random\n",
240 |         "import string\n",
241 |         "\n",
242 |         "\n",
243 |         "def fetch_flight_info(date: Date, origin: str, destination: str):\n",
244 |         "    \"\"\"Fetch flight information from origin to destination on the given date\"\"\"\n",
245 |         "    flights = []\n",
246 |         "\n",
247 |         "    for flight_id, flight in flight_database.items():\n",
248 |         "        if (\n",
249 |         "            flight.date_time.year == date.year\n",
250 |         "            and flight.date_time.month == date.month\n",
251 |         "            and flight.date_time.day == date.day\n",
252 |         "            and flight.origin == origin\n",
253 |         "            and flight.destination == destination\n",
254 |         "        ):\n",
255 |         "            flights.append(flight)\n",
256 |         "    if len(flights) == 0:\n",
257 |         "        raise ValueError(\"No matching flight found!\")\n",
258 |         "    return flights\n",
259 |         "\n",
260 |         "\n",
261 |         "def fetch_itinerary(confirmation_number: str):\n",
262 |         "    \"\"\"Fetch a booked itinerary information from database\"\"\"\n",
263 |         "    return itinery_database.get(confirmation_number)\n",
264 |         "\n",
265 |         "\n",
266 |         "def pick_flight(flights: list[Flight]):\n",
267 |         "    \"\"\"Pick up the best flight that matches users' request. we pick the shortest, and cheaper one on ties.\"\"\"\n",
268 |         "    sorted_flights = sorted(\n",
269 |         "        flights,\n",
270 |         "        key=lambda x: (\n",
271 |         "            x.get(\"duration\") if isinstance(x, dict) else x.duration,\n",
272 |         "            x.get(\"price\") if isinstance(x, dict) else x.price,\n",
273 |         "        ),\n",
274 |         "    )\n",
275 |         "    return sorted_flights[0]\n",
276 |         "\n",
277 |         "\n",
278 |         "def _generate_id(length=8):\n",
279 |         "    chars = string.ascii_lowercase + string.digits\n",
280 |         "    return \"\".join(random.choices(chars, k=length))\n",
281 |         "\n",
282 |         "\n",
283 |         "def book_flight(flight: Flight, user_profile: UserProfile):\n",
284 |         "    \"\"\"Book a flight on behalf of the user.\"\"\"\n",
285 |         "    confirmation_number = _generate_id()\n",
286 |         "    while confirmation_number in itinery_database:\n",
287 |         "        confirmation_number = _generate_id()\n",
288 |         "    itinery_database[confirmation_number] = Itinerary(\n",
289 |         "        confirmation_number=confirmation_number,\n",
290 |         "        user_profile=user_profile,\n",
291 |         "        flight=flight,\n",
292 |         "    )\n",
293 |         "    return confirmation_number, itinery_database[confirmation_number]\n",
294 |         "\n",
295 |         "\n",
296 |         "def cancel_itinerary(confirmation_number: str, user_profile: UserProfile):\n",
297 |         "    \"\"\"Cancel an itinerary on behalf of the user.\"\"\"\n",
298 |         "    if confirmation_number in itinery_database:\n",
299 |         "        del itinery_database[confirmation_number]\n",
300 |         "        return\n",
301 |         "    raise ValueError(\"Cannot find the itinerary, please check your confirmation number.\")\n",
302 |         "\n",
303 |         "\n",
304 |         "def get_user_info(name: str):\n",
305 |         "    \"\"\"Fetch the user profile from database with given name.\"\"\"\n",
306 |         "    return user_database.get(name)\n",
307 |         "\n",
308 |         "\n",
309 |         "def file_ticket(user_request: str, user_profile: UserProfile):\n",
310 |         "    \"\"\"File a customer support ticket if this is something the agent cannot handle.\"\"\"\n",
311 |         "    ticket_id = _generate_id(length=6)\n",
312 |         "    ticket_database[ticket_id] = Ticket(\n",
313 |         "        user_request=user_request,\n",
314 |         "        user_profile=user_profile,\n",
315 |         "    )\n",
316 |         "    return ticket_id\n"
317 |       ]
318 |     },
319 |     {
320 |       "cell_type": "markdown",
321 |       "metadata": {
322 |         "id": "rzibYLS0LqXc"
323 |       },
324 |       "source": [
325 |         "### Create ReAct Agent\n",
326 |         "\n",
327 |         "Now we can create the ReAct agent via `dspy.ReAct`. We need to provide a signature to `dspy.ReAct` to define task, and the inputs and outputs of the agent, and tell it about the tools it can access."
328 |       ]
329 |     },
330 |     {
331 |       "cell_type": "code",
332 |       "execution_count": 4,
333 |       "metadata": {
334 |         "id": "OZ2qOWLGLk2J"
335 |       },
336 |       "outputs": [],
337 |       "source": [
338 |         "import dspy\n",
339 |         "\n",
340 |         "class DSPyAirlineCustomerService(dspy.Signature):\n",
341 |         "    \"\"\"You are an airline customer service agent that helps user book and manage flights.\n",
342 |         "\n",
343 |         "    You are given a list of tools to handle user request, and you should decide the right tool to use in order to\n",
344 |         "    fulfill users' request.\"\"\"\n",
345 |         "\n",
346 |         "    user_request: str = dspy.InputField()\n",
347 |         "    process_result: str = dspy.OutputField(\n",
348 |         "        desc=(\n",
349 |         "                \"Message that summarizes the process result, and the information users need, e.g., the \"\n",
350 |         "                \"confirmation_number if a new flight is booked.\"\n",
351 |         "            )\n",
352 |         "        )"
353 |       ]
354 |     },
355 |     {
356 |       "cell_type": "code",
357 |       "execution_count": 5,
358 |       "metadata": {
359 |         "id": "ooDb84LIM5Pn"
360 |       },
361 |       "outputs": [],
362 |       "source": [
363 |         "agent = dspy.ReAct(\n",
364 |         "    DSPyAirlineCustomerService,\n",
365 |         "    tools = [\n",
366 |         "        fetch_flight_info,\n",
367 |         "        fetch_itinerary,\n",
368 |         "        pick_flight,\n",
369 |         "        book_flight,\n",
370 |         "        cancel_itinerary,\n",
371 |         "        get_user_info,\n",
372 |         "        file_ticket,\n",
373 |         "    ]\n",
374 |         ")"
375 |       ]
376 |     },
377 |     {
378 |       "cell_type": "markdown",
379 |       "metadata": {
380 |         "id": "4NA2QtQgNyrO"
381 |       },
382 |       "source": [
383 |         "## Use the Agent\n",
384 |         "\n",
385 |         "To interact with the agent, simply provide the request through `user_request`, and the agent will start doing its job."
386 |       ]
387 |     },
388 |     {
389 |       "cell_type": "markdown",
390 |       "metadata": {
391 |         "id": "CXnSE6P1OHbm"
392 |       },
393 |       "source": [
394 |         "Select a language model and set up the API keys. We are using gpt-4o-mini here, but you can change to other models. For how to configure the language model, please refer to [this guide](https://dspy.ai/learn/programming/language_models/)."
395 |       ]
396 |     },
397 |     {
398 |       "cell_type": "code",
399 |       "execution_count": 6,
400 |       "metadata": {
401 |         "id": "5F3TVB1DOW82"
402 |       },
403 |       "outputs": [],
404 |       "source": [
405 |         "import os\n",
406 |         "\n",
407 |         "os.environ[\"OPENAI_API_KEY\"] = \"{your openai key}\"\n",
408 |         "\n",
409 |         "dspy.configure(lm=dspy.LM(\"openai/gpt-4o-mini\"))"
410 |       ]
411 |     },
412 |     {
413 |       "cell_type": "code",
414 |       "execution_count": 7,
415 |       "metadata": {
416 |         "colab": {
417 |           "base_uri": "https://localhost:8080/"
418 |         },
419 |         "id": "hL3q0iS4Nwn8",
420 |         "outputId": "460af1b7-bceb-4edc-8d51-30f87eb7d454"
421 |       },
422 |       "outputs": [
423 |         {
424 |           "name": "stdout",
425 |           "output_type": "stream",
426 |           "text": [
427 |             "Prediction(\n",
428 |             "    trajectory={'thought_0': 'I need to fetch flight information for the route from SFO to JFK on the specified date of 09/01/2025. Once I have the flight options, I can help Adam pick the best flight and proceed with the booking.', 'tool_name_0': 'fetch_flight_info', 'tool_args_0': {'date': {'year': 2025, 'month': 9, 'day': 1, 'hour': 0}, 'origin': 'SFO', 'destination': 'JFK'}, 'observation_0': [Flight(flight_id='DA123', date_time=Date(year=2025, month=9, day=1, hour=1), origin='SFO', destination='JFK', duration=3.0, price=200.0), Flight(flight_id='DA125', date_time=Date(year=2025, month=9, day=1, hour=7), origin='SFO', destination='JFK', duration=9.0, price=500.0)], 'thought_1': 'I have received the flight options from SFO to JFK on 09/01/2025. There are two flights available: DA123 at 1 AM for $200 and DA125 at 7 AM for $500. I will now pick the best flight, which is the cheaper option, DA123.', 'tool_name_1': 'pick_flight', 'tool_args_1': {'flights': [{'flight_id': 'DA123', 'date_time': {'year': 2025, 'month': 9, 'day': 1, 'hour': 1}, 'origin': 'SFO', 'destination': 'JFK', 'duration': 3.0, 'price': 200.0}, {'flight_id': 'DA125', 'date_time': {'year': 2025, 'month': 9, 'day': 1, 'hour': 7}, 'origin': 'SFO', 'destination': 'JFK', 'duration': 9.0, 'price': 500.0}]}, 'observation_1': Flight(flight_id='DA123', date_time=Date(year=2025, month=9, day=1, hour=1), origin='SFO', destination='JFK', duration=3.0, price=200.0), 'thought_2': \"I have successfully picked the best flight, which is DA123. Now, I need to gather Adam's user profile information to proceed with the booking.\", 'tool_name_2': 'get_user_info', 'tool_args_2': {'name': 'Adam'}, 'observation_2': UserProfile(user_id='1', name='Adam', email='adam@gmail.com'), 'thought_3': \"I have gathered Adam's user profile information. Now I can proceed to book the selected flight DA123 for him.\", 'tool_name_3': 'book_flight', 'tool_args_3': {'flight': {'flight_id': 'DA123', 'date_time': {'year': 2025, 'month': 9, 'day': 1, 'hour': 1}, 'origin': 'SFO', 'destination': 'JFK', 'duration': 3.0, 'price': 200.0}, 'user_profile': {'user_id': '1', 'name': 'Adam', 'email': 'adam@gmail.com'}}, 'observation_3': ('94ldyhsx', Itinerary(confirmation_number='94ldyhsx', user_profile=UserProfile(user_id='1', name='Adam', email='adam@gmail.com'), flight=Flight(flight_id='DA123', date_time=Date(year=2025, month=9, day=1, hour=1), origin='SFO', destination='JFK', duration=3.0, price=200.0))), 'thought_4': \"Adam's flight has been successfully booked, and I have received the confirmation number. I will now mark the task as complete.\", 'tool_name_4': 'finish', 'tool_args_4': {}, 'observation_4': 'Completed.'},\n",
429 |             "    reasoning=\"I successfully fetched flight information for the route from SFO to JFK on 09/01/2025. There were two available flights: DA123 at 1 AM for $200 and DA125 at 7 AM for $500. I selected the cheaper option, DA123, and then retrieved Adam's user profile information to proceed with the booking. After booking the flight, I received a confirmation number for the reservation.\",\n",
430 |             "    process_result='Your flight from SFO to JFK on 09/01/2025 has been successfully booked. Your confirmation number is 94ldyhsx.'\n",
431 |             ")\n"
432 |           ]
433 |         }
434 |       ],
435 |       "source": [
436 |         "result = agent(user_request=\"please help me book a flight from SFO to JFK on 09/01/2025, my name is Adam\")\n",
437 |         "print(result)"
438 |       ]
439 |     },
440 |     {
441 |       "cell_type": "markdown",
442 |       "metadata": {
443 |         "id": "5kwbgMNUWQUX"
444 |       },
445 |       "source": [
446 |         "We can see the booked itinerarie in the database."
447 |       ]
448 |     },
449 |     {
450 |       "cell_type": "code",
451 |       "execution_count": 8,
452 |       "metadata": {
453 |         "colab": {
454 |           "base_uri": "https://localhost:8080/"
455 |         },
456 |         "id": "J3fO7G3yVtoa",
457 |         "outputId": "76f665ca-81a4-45df-bf08-d66b946a45c7"
458 |       },
459 |       "outputs": [
460 |         {
461 |           "name": "stdout",
462 |           "output_type": "stream",
463 |           "text": [
464 |             "{'94ldyhsx': Itinerary(confirmation_number='94ldyhsx', user_profile=UserProfile(user_id='1', name='Adam', email='adam@gmail.com'), flight=Flight(flight_id='DA123', date_time=Date(year=2025, month=9, day=1, hour=1), origin='SFO', destination='JFK', duration=3.0, price=200.0))}\n"
465 |           ]
466 |         }
467 |       ],
468 |       "source": [
469 |         "print(itinery_database)"
470 |       ]
471 |     },
472 |     {
473 |       "cell_type": "markdown",
474 |       "metadata": {
475 |         "id": "mxFF1tMrWU_7"
476 |       },
477 |       "source": [
478 |         "### Interpret the Result\n",
479 |         "\n",
480 |         "The result contains the the `process_result` as required by the user, and a `reasoning` field that carries the reasoning behind the answer. In addition, it has a `trajectory` field which contains:\n",
481 |         "\n",
482 |         "- Reasoning (thought) at each step\n",
483 |         "- Tools picked by LM at each step\n",
484 |         "- Arguments for tool calling, determined by LM at each step\n",
485 |         "- Tool execution results at each step\n",
486 |         "\n",
487 |         "Behind scene, the `dspy.ReAct` is executing a loop, which accumulates tool call information along with the task description, and send to the LM until hits `max_iters` or the LM decides to wrap up. To better interpret the process, let's use `dspy.inspect_history()` to see what's happening inside each step.\n"
488 |       ]
489 |     },
490 |     {
491 |       "cell_type": "code",
492 |       "execution_count": 9,
493 |       "metadata": {
494 |         "colab": {
495 |           "base_uri": "https://localhost:8080/"
496 |         },
497 |         "id": "Pm7lZhLZV_ko",
498 |         "outputId": "e4387b2d-7368-4aea-8705-1127c9c8fd31"
499 |       },
500 |       "outputs": [
501 |         {
502 |           "name": "stdout",
503 |           "output_type": "stream",
504 |           "text": [
505 |             "\n",
506 |             "\n",
507 |             "\n",
508 |             "\n",
509 |             "\u001b[34m[2025-05-28T01:06:46.819048]\u001b[0m\n",
510 |             "\n",
511 |             "\u001b[31mSystem message:\u001b[0m\n",
512 |             "\n",
513 |             "Your input fields are:\n",
514 |             "1. `user_request` (str)\n",
515 |             "2. `trajectory` (str)\n",
516 |             "Your output fields are:\n",
517 |             "1. `next_thought` (str)\n",
518 |             "2. `next_tool_name` (Literal['fetch_flight_info', 'fetch_itinerary', 'pick_flight', 'book_flight', 'cancel_itinerary', 'get_user_info', 'file_ticket', 'finish'])\n",
519 |             "3. `next_tool_args` (dict[str, Any])\n",
520 |             "All interactions will be structured in the following way, with the appropriate values filled in.\n",
521 |             "\n",
522 |             "[[ ## user_request ## ]]\n",
523 |             "{user_request}\n",
524 |             "\n",
525 |             "[[ ## trajectory ## ]]\n",
526 |             "{trajectory}\n",
527 |             "\n",
528 |             "[[ ## next_thought ## ]]\n",
529 |             "{next_thought}\n",
530 |             "\n",
531 |             "[[ ## next_tool_name ## ]]\n",
532 |             "{next_tool_name}        # note: the value you produce must exactly match (no extra characters) one of: fetch_flight_info; fetch_itinerary; pick_flight; book_flight; cancel_itinerary; get_user_info; file_ticket; finish\n",
533 |             "\n",
534 |             "[[ ## next_tool_args ## ]]\n",
535 |             "{next_tool_args}        # note: the value you produce must adhere to the JSON schema: {\"type\": \"object\", \"additionalProperties\": true}\n",
536 |             "\n",
537 |             "[[ ## completed ## ]]\n",
538 |             "In adhering to this structure, your objective is: \n",
539 |             "        You are an airline customer service agent that helps user book and manage flights. \n",
540 |             "        \n",
541 |             "        You are given a list of tools to handle user request, and you should decide the right tool to use in order to\n",
542 |             "        fulfill users' request.\n",
543 |             "        \n",
544 |             "        You are an Agent. In each episode, you will be given the fields `user_request` as input. And you can see your past trajectory so far.\n",
545 |             "        Your goal is to use one or more of the supplied tools to collect any necessary information for producing `process_result`.\n",
546 |             "        \n",
547 |             "        To do this, you will interleave next_thought, next_tool_name, and next_tool_args in each turn, and also when finishing the task.\n",
548 |             "        After each tool call, you receive a resulting observation, which gets appended to your trajectory.\n",
549 |             "        \n",
550 |             "        When writing next_thought, you may reason about the current situation and plan for future steps.\n",
551 |             "        When selecting the next_tool_name and its next_tool_args, the tool must be one of:\n",
552 |             "        \n",
553 |             "        (1) fetch_flight_info, whose description is <desc>Fetch flight information from origin to destination on the given date</desc>. It takes arguments {'date': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'origin': {'type': 'string'}, 'destination': {'type': 'string'}} in JSON format.\n",
554 |             "        (2) fetch_itinerary, whose description is <desc>Fetch a booked itinerary information from database</desc>. It takes arguments {'confirmation_number': {'type': 'string'}} in JSON format.\n",
555 |             "        (3) pick_flight, whose description is <desc>Pick up the best flight that matches users' request. we pick the shortest, and cheaper one on ties.</desc>. It takes arguments {'flights': {'$defs': {'Date': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'Flight': {'properties': {'flight_id': {'title': 'Flight Id', 'type': 'string'}, 'date_time': {'$ref': '#/$defs/Date'}, 'origin': {'title': 'Origin', 'type': 'string'}, 'destination': {'title': 'Destination', 'type': 'string'}, 'duration': {'title': 'Duration', 'type': 'number'}, 'price': {'title': 'Price', 'type': 'number'}}, 'required': ['flight_id', 'date_time', 'origin', 'destination', 'duration', 'price'], 'title': 'Flight', 'type': 'object'}}, 'items': {'$ref': '#/$defs/Flight'}, 'type': 'array'}} in JSON format.\n",
556 |             "        (4) book_flight, whose description is <desc>Book a flight on behalf of the user.</desc>. It takes arguments {'flight': {'properties': {'flight_id': {'title': 'Flight Id', 'type': 'string'}, 'date_time': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'origin': {'title': 'Origin', 'type': 'string'}, 'destination': {'title': 'Destination', 'type': 'string'}, 'duration': {'title': 'Duration', 'type': 'number'}, 'price': {'title': 'Price', 'type': 'number'}}, 'required': ['flight_id', 'date_time', 'origin', 'destination', 'duration', 'price'], 'title': 'Flight', 'type': 'object'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
557 |             "        (5) cancel_itinerary, whose description is <desc>Cancel an itinerary on behalf of the user.</desc>. It takes arguments {'confirmation_number': {'type': 'string'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
558 |             "        (6) get_user_info, whose description is <desc>Fetch the user profile from database with given name.</desc>. It takes arguments {'name': {'type': 'string'}} in JSON format.\n",
559 |             "        (7) file_ticket, whose description is <desc>File a customer support ticket if this is something the agent cannot handle.</desc>. It takes arguments {'user_request': {'type': 'string'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
560 |             "        (8) finish, whose description is <desc>Marks the task as complete. That is, signals that all information for producing the outputs, i.e. `process_result`, are now available to be extracted.</desc>. It takes arguments {} in JSON format.\n",
561 |             "\n",
562 |             "\n",
563 |             "\u001b[31mUser message:\u001b[0m\n",
564 |             "\n",
565 |             "[[ ## user_request ## ]]\n",
566 |             "please help me book a flight from SFO to JFK on 09/01/2025, my name is Adam\n",
567 |             "\n",
568 |             "[[ ## trajectory ## ]]\n",
569 |             "\n",
570 |             "\n",
571 |             "Respond with the corresponding output fields, starting with the field `[[ ## next_thought ## ]]`, then `[[ ## next_tool_name ## ]]` (must be formatted as a valid Python Literal['fetch_flight_info', 'fetch_itinerary', 'pick_flight', 'book_flight', 'cancel_itinerary', 'get_user_info', 'file_ticket', 'finish']), then `[[ ## next_tool_args ## ]]` (must be formatted as a valid Python dict[str, Any]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
572 |             "\n",
573 |             "\n",
574 |             "\u001b[31mResponse:\u001b[0m\n",
575 |             "\n",
576 |             "\u001b[32m[[ ## next_thought ## ]]\n",
577 |             "I need to fetch flight information for the route from SFO to JFK on the specified date of 09/01/2025. Once I have the flight options, I can help Adam pick the best flight and proceed with the booking.\n",
578 |             "\n",
579 |             "[[ ## next_tool_name ## ]]\n",
580 |             "fetch_flight_info\n",
581 |             "\n",
582 |             "[[ ## next_tool_args ## ]]\n",
583 |             "{\"date\":{\"year\":2025,\"month\":9,\"day\":1,\"hour\":0},\"origin\":\"SFO\",\"destination\":\"JFK\"}\n",
584 |             "\n",
585 |             "[[ ## completed ## ]]\u001b[0m\n",
586 |             "\n",
587 |             "\n",
588 |             "\n",
589 |             "\n",
590 |             "\n",
591 |             "\u001b[34m[2025-05-28T01:06:46.832209]\u001b[0m\n",
592 |             "\n",
593 |             "\u001b[31mSystem message:\u001b[0m\n",
594 |             "\n",
595 |             "Your input fields are:\n",
596 |             "1. `user_request` (str)\n",
597 |             "2. `trajectory` (str)\n",
598 |             "Your output fields are:\n",
599 |             "1. `next_thought` (str)\n",
600 |             "2. `next_tool_name` (Literal['fetch_flight_info', 'fetch_itinerary', 'pick_flight', 'book_flight', 'cancel_itinerary', 'get_user_info', 'file_ticket', 'finish'])\n",
601 |             "3. `next_tool_args` (dict[str, Any])\n",
602 |             "All interactions will be structured in the following way, with the appropriate values filled in.\n",
603 |             "\n",
604 |             "[[ ## user_request ## ]]\n",
605 |             "{user_request}\n",
606 |             "\n",
607 |             "[[ ## trajectory ## ]]\n",
608 |             "{trajectory}\n",
609 |             "\n",
610 |             "[[ ## next_thought ## ]]\n",
611 |             "{next_thought}\n",
612 |             "\n",
613 |             "[[ ## next_tool_name ## ]]\n",
614 |             "{next_tool_name}        # note: the value you produce must exactly match (no extra characters) one of: fetch_flight_info; fetch_itinerary; pick_flight; book_flight; cancel_itinerary; get_user_info; file_ticket; finish\n",
615 |             "\n",
616 |             "[[ ## next_tool_args ## ]]\n",
617 |             "{next_tool_args}        # note: the value you produce must adhere to the JSON schema: {\"type\": \"object\", \"additionalProperties\": true}\n",
618 |             "\n",
619 |             "[[ ## completed ## ]]\n",
620 |             "In adhering to this structure, your objective is: \n",
621 |             "        You are an airline customer service agent that helps user book and manage flights. \n",
622 |             "        \n",
623 |             "        You are given a list of tools to handle user request, and you should decide the right tool to use in order to\n",
624 |             "        fulfill users' request.\n",
625 |             "        \n",
626 |             "        You are an Agent. In each episode, you will be given the fields `user_request` as input. And you can see your past trajectory so far.\n",
627 |             "        Your goal is to use one or more of the supplied tools to collect any necessary information for producing `process_result`.\n",
628 |             "        \n",
629 |             "        To do this, you will interleave next_thought, next_tool_name, and next_tool_args in each turn, and also when finishing the task.\n",
630 |             "        After each tool call, you receive a resulting observation, which gets appended to your trajectory.\n",
631 |             "        \n",
632 |             "        When writing next_thought, you may reason about the current situation and plan for future steps.\n",
633 |             "        When selecting the next_tool_name and its next_tool_args, the tool must be one of:\n",
634 |             "        \n",
635 |             "        (1) fetch_flight_info, whose description is <desc>Fetch flight information from origin to destination on the given date</desc>. It takes arguments {'date': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'origin': {'type': 'string'}, 'destination': {'type': 'string'}} in JSON format.\n",
636 |             "        (2) fetch_itinerary, whose description is <desc>Fetch a booked itinerary information from database</desc>. It takes arguments {'confirmation_number': {'type': 'string'}} in JSON format.\n",
637 |             "        (3) pick_flight, whose description is <desc>Pick up the best flight that matches users' request. we pick the shortest, and cheaper one on ties.</desc>. It takes arguments {'flights': {'$defs': {'Date': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'Flight': {'properties': {'flight_id': {'title': 'Flight Id', 'type': 'string'}, 'date_time': {'$ref': '#/$defs/Date'}, 'origin': {'title': 'Origin', 'type': 'string'}, 'destination': {'title': 'Destination', 'type': 'string'}, 'duration': {'title': 'Duration', 'type': 'number'}, 'price': {'title': 'Price', 'type': 'number'}}, 'required': ['flight_id', 'date_time', 'origin', 'destination', 'duration', 'price'], 'title': 'Flight', 'type': 'object'}}, 'items': {'$ref': '#/$defs/Flight'}, 'type': 'array'}} in JSON format.\n",
638 |             "        (4) book_flight, whose description is <desc>Book a flight on behalf of the user.</desc>. It takes arguments {'flight': {'properties': {'flight_id': {'title': 'Flight Id', 'type': 'string'}, 'date_time': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'origin': {'title': 'Origin', 'type': 'string'}, 'destination': {'title': 'Destination', 'type': 'string'}, 'duration': {'title': 'Duration', 'type': 'number'}, 'price': {'title': 'Price', 'type': 'number'}}, 'required': ['flight_id', 'date_time', 'origin', 'destination', 'duration', 'price'], 'title': 'Flight', 'type': 'object'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
639 |             "        (5) cancel_itinerary, whose description is <desc>Cancel an itinerary on behalf of the user.</desc>. It takes arguments {'confirmation_number': {'type': 'string'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
640 |             "        (6) get_user_info, whose description is <desc>Fetch the user profile from database with given name.</desc>. It takes arguments {'name': {'type': 'string'}} in JSON format.\n",
641 |             "        (7) file_ticket, whose description is <desc>File a customer support ticket if this is something the agent cannot handle.</desc>. It takes arguments {'user_request': {'type': 'string'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
642 |             "        (8) finish, whose description is <desc>Marks the task as complete. That is, signals that all information for producing the outputs, i.e. `process_result`, are now available to be extracted.</desc>. It takes arguments {} in JSON format.\n",
643 |             "\n",
644 |             "\n",
645 |             "\u001b[31mUser message:\u001b[0m\n",
646 |             "\n",
647 |             "[[ ## user_request ## ]]\n",
648 |             "please help me book a flight from SFO to JFK on 09/01/2025, my name is Adam\n",
649 |             "\n",
650 |             "[[ ## trajectory ## ]]\n",
651 |             "[[ ## thought_0 ## ]]\n",
652 |             "I need to fetch flight information for the route from SFO to JFK on the specified date of 09/01/2025. Once I have the flight options, I can help Adam pick the best flight and proceed with the booking.\n",
653 |             "\n",
654 |             "[[ ## tool_name_0 ## ]]\n",
655 |             "fetch_flight_info\n",
656 |             "\n",
657 |             "[[ ## tool_args_0 ## ]]\n",
658 |             "{\"date\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 0}, \"origin\": \"SFO\", \"destination\": \"JFK\"}\n",
659 |             "\n",
660 |             "[[ ## observation_0 ## ]]\n",
661 |             "[1] «flight_id='DA123' date_time=Date(year=2025, month=9, day=1, hour=1) origin='SFO' destination='JFK' duration=3.0 price=200.0»\n",
662 |             "[2] «flight_id='DA125' date_time=Date(year=2025, month=9, day=1, hour=7) origin='SFO' destination='JFK' duration=9.0 price=500.0»\n",
663 |             "\n",
664 |             "Respond with the corresponding output fields, starting with the field `[[ ## next_thought ## ]]`, then `[[ ## next_tool_name ## ]]` (must be formatted as a valid Python Literal['fetch_flight_info', 'fetch_itinerary', 'pick_flight', 'book_flight', 'cancel_itinerary', 'get_user_info', 'file_ticket', 'finish']), then `[[ ## next_tool_args ## ]]` (must be formatted as a valid Python dict[str, Any]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
665 |             "\n",
666 |             "\n",
667 |             "\u001b[31mResponse:\u001b[0m\n",
668 |             "\n",
669 |             "\u001b[32m[[ ## next_thought ## ]]\n",
670 |             "I have received the flight options from SFO to JFK on 09/01/2025. There are two flights available: DA123 at 1 AM for $200 and DA125 at 7 AM for $500. I will now pick the best flight, which is the cheaper option, DA123.\n",
671 |             "\n",
672 |             "[[ ## next_tool_name ## ]]\n",
673 |             "pick_flight\n",
674 |             "\n",
675 |             "[[ ## next_tool_args ## ]]\n",
676 |             "{\"flights\":[{\"flight_id\":\"DA123\",\"date_time\":{\"year\":2025,\"month\":9,\"day\":1,\"hour\":1},\"origin\":\"SFO\",\"destination\":\"JFK\",\"duration\":3.0,\"price\":200.0},{\"flight_id\":\"DA125\",\"date_time\":{\"year\":2025,\"month\":9,\"day\":1,\"hour\":7},\"origin\":\"SFO\",\"destination\":\"JFK\",\"duration\":9.0,\"price\":500.0}]}\n",
677 |             "\n",
678 |             "[[ ## completed ## ]]\u001b[0m\n",
679 |             "\n",
680 |             "\n",
681 |             "\n",
682 |             "\n",
683 |             "\n",
684 |             "\u001b[34m[2025-05-28T01:06:46.844268]\u001b[0m\n",
685 |             "\n",
686 |             "\u001b[31mSystem message:\u001b[0m\n",
687 |             "\n",
688 |             "Your input fields are:\n",
689 |             "1. `user_request` (str)\n",
690 |             "2. `trajectory` (str)\n",
691 |             "Your output fields are:\n",
692 |             "1. `next_thought` (str)\n",
693 |             "2. `next_tool_name` (Literal['fetch_flight_info', 'fetch_itinerary', 'pick_flight', 'book_flight', 'cancel_itinerary', 'get_user_info', 'file_ticket', 'finish'])\n",
694 |             "3. `next_tool_args` (dict[str, Any])\n",
695 |             "All interactions will be structured in the following way, with the appropriate values filled in.\n",
696 |             "\n",
697 |             "[[ ## user_request ## ]]\n",
698 |             "{user_request}\n",
699 |             "\n",
700 |             "[[ ## trajectory ## ]]\n",
701 |             "{trajectory}\n",
702 |             "\n",
703 |             "[[ ## next_thought ## ]]\n",
704 |             "{next_thought}\n",
705 |             "\n",
706 |             "[[ ## next_tool_name ## ]]\n",
707 |             "{next_tool_name}        # note: the value you produce must exactly match (no extra characters) one of: fetch_flight_info; fetch_itinerary; pick_flight; book_flight; cancel_itinerary; get_user_info; file_ticket; finish\n",
708 |             "\n",
709 |             "[[ ## next_tool_args ## ]]\n",
710 |             "{next_tool_args}        # note: the value you produce must adhere to the JSON schema: {\"type\": \"object\", \"additionalProperties\": true}\n",
711 |             "\n",
712 |             "[[ ## completed ## ]]\n",
713 |             "In adhering to this structure, your objective is: \n",
714 |             "        You are an airline customer service agent that helps user book and manage flights. \n",
715 |             "        \n",
716 |             "        You are given a list of tools to handle user request, and you should decide the right tool to use in order to\n",
717 |             "        fulfill users' request.\n",
718 |             "        \n",
719 |             "        You are an Agent. In each episode, you will be given the fields `user_request` as input. And you can see your past trajectory so far.\n",
720 |             "        Your goal is to use one or more of the supplied tools to collect any necessary information for producing `process_result`.\n",
721 |             "        \n",
722 |             "        To do this, you will interleave next_thought, next_tool_name, and next_tool_args in each turn, and also when finishing the task.\n",
723 |             "        After each tool call, you receive a resulting observation, which gets appended to your trajectory.\n",
724 |             "        \n",
725 |             "        When writing next_thought, you may reason about the current situation and plan for future steps.\n",
726 |             "        When selecting the next_tool_name and its next_tool_args, the tool must be one of:\n",
727 |             "        \n",
728 |             "        (1) fetch_flight_info, whose description is <desc>Fetch flight information from origin to destination on the given date</desc>. It takes arguments {'date': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'origin': {'type': 'string'}, 'destination': {'type': 'string'}} in JSON format.\n",
729 |             "        (2) fetch_itinerary, whose description is <desc>Fetch a booked itinerary information from database</desc>. It takes arguments {'confirmation_number': {'type': 'string'}} in JSON format.\n",
730 |             "        (3) pick_flight, whose description is <desc>Pick up the best flight that matches users' request. we pick the shortest, and cheaper one on ties.</desc>. It takes arguments {'flights': {'$defs': {'Date': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'Flight': {'properties': {'flight_id': {'title': 'Flight Id', 'type': 'string'}, 'date_time': {'$ref': '#/$defs/Date'}, 'origin': {'title': 'Origin', 'type': 'string'}, 'destination': {'title': 'Destination', 'type': 'string'}, 'duration': {'title': 'Duration', 'type': 'number'}, 'price': {'title': 'Price', 'type': 'number'}}, 'required': ['flight_id', 'date_time', 'origin', 'destination', 'duration', 'price'], 'title': 'Flight', 'type': 'object'}}, 'items': {'$ref': '#/$defs/Flight'}, 'type': 'array'}} in JSON format.\n",
731 |             "        (4) book_flight, whose description is <desc>Book a flight on behalf of the user.</desc>. It takes arguments {'flight': {'properties': {'flight_id': {'title': 'Flight Id', 'type': 'string'}, 'date_time': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'origin': {'title': 'Origin', 'type': 'string'}, 'destination': {'title': 'Destination', 'type': 'string'}, 'duration': {'title': 'Duration', 'type': 'number'}, 'price': {'title': 'Price', 'type': 'number'}}, 'required': ['flight_id', 'date_time', 'origin', 'destination', 'duration', 'price'], 'title': 'Flight', 'type': 'object'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
732 |             "        (5) cancel_itinerary, whose description is <desc>Cancel an itinerary on behalf of the user.</desc>. It takes arguments {'confirmation_number': {'type': 'string'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
733 |             "        (6) get_user_info, whose description is <desc>Fetch the user profile from database with given name.</desc>. It takes arguments {'name': {'type': 'string'}} in JSON format.\n",
734 |             "        (7) file_ticket, whose description is <desc>File a customer support ticket if this is something the agent cannot handle.</desc>. It takes arguments {'user_request': {'type': 'string'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
735 |             "        (8) finish, whose description is <desc>Marks the task as complete. That is, signals that all information for producing the outputs, i.e. `process_result`, are now available to be extracted.</desc>. It takes arguments {} in JSON format.\n",
736 |             "\n",
737 |             "\n",
738 |             "\u001b[31mUser message:\u001b[0m\n",
739 |             "\n",
740 |             "[[ ## user_request ## ]]\n",
741 |             "please help me book a flight from SFO to JFK on 09/01/2025, my name is Adam\n",
742 |             "\n",
743 |             "[[ ## trajectory ## ]]\n",
744 |             "[[ ## thought_0 ## ]]\n",
745 |             "I need to fetch flight information for the route from SFO to JFK on the specified date of 09/01/2025. Once I have the flight options, I can help Adam pick the best flight and proceed with the booking.\n",
746 |             "\n",
747 |             "[[ ## tool_name_0 ## ]]\n",
748 |             "fetch_flight_info\n",
749 |             "\n",
750 |             "[[ ## tool_args_0 ## ]]\n",
751 |             "{\"date\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 0}, \"origin\": \"SFO\", \"destination\": \"JFK\"}\n",
752 |             "\n",
753 |             "[[ ## observation_0 ## ]]\n",
754 |             "[1] «flight_id='DA123' date_time=Date(year=2025, month=9, day=1, hour=1) origin='SFO' destination='JFK' duration=3.0 price=200.0»\n",
755 |             "[2] «flight_id='DA125' date_time=Date(year=2025, month=9, day=1, hour=7) origin='SFO' destination='JFK' duration=9.0 price=500.0»\n",
756 |             "\n",
757 |             "[[ ## thought_1 ## ]]\n",
758 |             "I have received the flight options from SFO to JFK on 09/01/2025. There are two flights available: DA123 at 1 AM for $200 and DA125 at 7 AM for $500. I will now pick the best flight, which is the cheaper option, DA123.\n",
759 |             "\n",
760 |             "[[ ## tool_name_1 ## ]]\n",
761 |             "pick_flight\n",
762 |             "\n",
763 |             "[[ ## tool_args_1 ## ]]\n",
764 |             "{\"flights\": [{\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}, {\"flight_id\": \"DA125\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 7}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 9.0, \"price\": 500.0}]}\n",
765 |             "\n",
766 |             "[[ ## observation_1 ## ]]\n",
767 |             "{\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}\n",
768 |             "\n",
769 |             "Respond with the corresponding output fields, starting with the field `[[ ## next_thought ## ]]`, then `[[ ## next_tool_name ## ]]` (must be formatted as a valid Python Literal['fetch_flight_info', 'fetch_itinerary', 'pick_flight', 'book_flight', 'cancel_itinerary', 'get_user_info', 'file_ticket', 'finish']), then `[[ ## next_tool_args ## ]]` (must be formatted as a valid Python dict[str, Any]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
770 |             "\n",
771 |             "\n",
772 |             "\u001b[31mResponse:\u001b[0m\n",
773 |             "\n",
774 |             "\u001b[32m[[ ## next_thought ## ]]\n",
775 |             "I have successfully picked the best flight, which is DA123. Now, I need to gather Adam's user profile information to proceed with the booking.\n",
776 |             "\n",
777 |             "[[ ## next_tool_name ## ]]\n",
778 |             "get_user_info\n",
779 |             "\n",
780 |             "[[ ## next_tool_args ## ]]\n",
781 |             "{\"name\": \"Adam\"}\n",
782 |             "\n",
783 |             "[[ ## completed ## ]]\u001b[0m\n",
784 |             "\n",
785 |             "\n",
786 |             "\n",
787 |             "\n",
788 |             "\n",
789 |             "\u001b[34m[2025-05-28T01:06:46.851917]\u001b[0m\n",
790 |             "\n",
791 |             "\u001b[31mSystem message:\u001b[0m\n",
792 |             "\n",
793 |             "Your input fields are:\n",
794 |             "1. `user_request` (str)\n",
795 |             "2. `trajectory` (str)\n",
796 |             "Your output fields are:\n",
797 |             "1. `next_thought` (str)\n",
798 |             "2. `next_tool_name` (Literal['fetch_flight_info', 'fetch_itinerary', 'pick_flight', 'book_flight', 'cancel_itinerary', 'get_user_info', 'file_ticket', 'finish'])\n",
799 |             "3. `next_tool_args` (dict[str, Any])\n",
800 |             "All interactions will be structured in the following way, with the appropriate values filled in.\n",
801 |             "\n",
802 |             "[[ ## user_request ## ]]\n",
803 |             "{user_request}\n",
804 |             "\n",
805 |             "[[ ## trajectory ## ]]\n",
806 |             "{trajectory}\n",
807 |             "\n",
808 |             "[[ ## next_thought ## ]]\n",
809 |             "{next_thought}\n",
810 |             "\n",
811 |             "[[ ## next_tool_name ## ]]\n",
812 |             "{next_tool_name}        # note: the value you produce must exactly match (no extra characters) one of: fetch_flight_info; fetch_itinerary; pick_flight; book_flight; cancel_itinerary; get_user_info; file_ticket; finish\n",
813 |             "\n",
814 |             "[[ ## next_tool_args ## ]]\n",
815 |             "{next_tool_args}        # note: the value you produce must adhere to the JSON schema: {\"type\": \"object\", \"additionalProperties\": true}\n",
816 |             "\n",
817 |             "[[ ## completed ## ]]\n",
818 |             "In adhering to this structure, your objective is: \n",
819 |             "        You are an airline customer service agent that helps user book and manage flights. \n",
820 |             "        \n",
821 |             "        You are given a list of tools to handle user request, and you should decide the right tool to use in order to\n",
822 |             "        fulfill users' request.\n",
823 |             "        \n",
824 |             "        You are an Agent. In each episode, you will be given the fields `user_request` as input. And you can see your past trajectory so far.\n",
825 |             "        Your goal is to use one or more of the supplied tools to collect any necessary information for producing `process_result`.\n",
826 |             "        \n",
827 |             "        To do this, you will interleave next_thought, next_tool_name, and next_tool_args in each turn, and also when finishing the task.\n",
828 |             "        After each tool call, you receive a resulting observation, which gets appended to your trajectory.\n",
829 |             "        \n",
830 |             "        When writing next_thought, you may reason about the current situation and plan for future steps.\n",
831 |             "        When selecting the next_tool_name and its next_tool_args, the tool must be one of:\n",
832 |             "        \n",
833 |             "        (1) fetch_flight_info, whose description is <desc>Fetch flight information from origin to destination on the given date</desc>. It takes arguments {'date': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'origin': {'type': 'string'}, 'destination': {'type': 'string'}} in JSON format.\n",
834 |             "        (2) fetch_itinerary, whose description is <desc>Fetch a booked itinerary information from database</desc>. It takes arguments {'confirmation_number': {'type': 'string'}} in JSON format.\n",
835 |             "        (3) pick_flight, whose description is <desc>Pick up the best flight that matches users' request. we pick the shortest, and cheaper one on ties.</desc>. It takes arguments {'flights': {'$defs': {'Date': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'Flight': {'properties': {'flight_id': {'title': 'Flight Id', 'type': 'string'}, 'date_time': {'$ref': '#/$defs/Date'}, 'origin': {'title': 'Origin', 'type': 'string'}, 'destination': {'title': 'Destination', 'type': 'string'}, 'duration': {'title': 'Duration', 'type': 'number'}, 'price': {'title': 'Price', 'type': 'number'}}, 'required': ['flight_id', 'date_time', 'origin', 'destination', 'duration', 'price'], 'title': 'Flight', 'type': 'object'}}, 'items': {'$ref': '#/$defs/Flight'}, 'type': 'array'}} in JSON format.\n",
836 |             "        (4) book_flight, whose description is <desc>Book a flight on behalf of the user.</desc>. It takes arguments {'flight': {'properties': {'flight_id': {'title': 'Flight Id', 'type': 'string'}, 'date_time': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'origin': {'title': 'Origin', 'type': 'string'}, 'destination': {'title': 'Destination', 'type': 'string'}, 'duration': {'title': 'Duration', 'type': 'number'}, 'price': {'title': 'Price', 'type': 'number'}}, 'required': ['flight_id', 'date_time', 'origin', 'destination', 'duration', 'price'], 'title': 'Flight', 'type': 'object'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
837 |             "        (5) cancel_itinerary, whose description is <desc>Cancel an itinerary on behalf of the user.</desc>. It takes arguments {'confirmation_number': {'type': 'string'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
838 |             "        (6) get_user_info, whose description is <desc>Fetch the user profile from database with given name.</desc>. It takes arguments {'name': {'type': 'string'}} in JSON format.\n",
839 |             "        (7) file_ticket, whose description is <desc>File a customer support ticket if this is something the agent cannot handle.</desc>. It takes arguments {'user_request': {'type': 'string'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
840 |             "        (8) finish, whose description is <desc>Marks the task as complete. That is, signals that all information for producing the outputs, i.e. `process_result`, are now available to be extracted.</desc>. It takes arguments {} in JSON format.\n",
841 |             "\n",
842 |             "\n",
843 |             "\u001b[31mUser message:\u001b[0m\n",
844 |             "\n",
845 |             "[[ ## user_request ## ]]\n",
846 |             "please help me book a flight from SFO to JFK on 09/01/2025, my name is Adam\n",
847 |             "\n",
848 |             "[[ ## trajectory ## ]]\n",
849 |             "[[ ## thought_0 ## ]]\n",
850 |             "I need to fetch flight information for the route from SFO to JFK on the specified date of 09/01/2025. Once I have the flight options, I can help Adam pick the best flight and proceed with the booking.\n",
851 |             "\n",
852 |             "[[ ## tool_name_0 ## ]]\n",
853 |             "fetch_flight_info\n",
854 |             "\n",
855 |             "[[ ## tool_args_0 ## ]]\n",
856 |             "{\"date\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 0}, \"origin\": \"SFO\", \"destination\": \"JFK\"}\n",
857 |             "\n",
858 |             "[[ ## observation_0 ## ]]\n",
859 |             "[1] «flight_id='DA123' date_time=Date(year=2025, month=9, day=1, hour=1) origin='SFO' destination='JFK' duration=3.0 price=200.0»\n",
860 |             "[2] «flight_id='DA125' date_time=Date(year=2025, month=9, day=1, hour=7) origin='SFO' destination='JFK' duration=9.0 price=500.0»\n",
861 |             "\n",
862 |             "[[ ## thought_1 ## ]]\n",
863 |             "I have received the flight options from SFO to JFK on 09/01/2025. There are two flights available: DA123 at 1 AM for $200 and DA125 at 7 AM for $500. I will now pick the best flight, which is the cheaper option, DA123.\n",
864 |             "\n",
865 |             "[[ ## tool_name_1 ## ]]\n",
866 |             "pick_flight\n",
867 |             "\n",
868 |             "[[ ## tool_args_1 ## ]]\n",
869 |             "{\"flights\": [{\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}, {\"flight_id\": \"DA125\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 7}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 9.0, \"price\": 500.0}]}\n",
870 |             "\n",
871 |             "[[ ## observation_1 ## ]]\n",
872 |             "{\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}\n",
873 |             "\n",
874 |             "[[ ## thought_2 ## ]]\n",
875 |             "I have successfully picked the best flight, which is DA123. Now, I need to gather Adam's user profile information to proceed with the booking.\n",
876 |             "\n",
877 |             "[[ ## tool_name_2 ## ]]\n",
878 |             "get_user_info\n",
879 |             "\n",
880 |             "[[ ## tool_args_2 ## ]]\n",
881 |             "{\"name\": \"Adam\"}\n",
882 |             "\n",
883 |             "[[ ## observation_2 ## ]]\n",
884 |             "{\"user_id\": \"1\", \"name\": \"Adam\", \"email\": \"adam@gmail.com\"}\n",
885 |             "\n",
886 |             "Respond with the corresponding output fields, starting with the field `[[ ## next_thought ## ]]`, then `[[ ## next_tool_name ## ]]` (must be formatted as a valid Python Literal['fetch_flight_info', 'fetch_itinerary', 'pick_flight', 'book_flight', 'cancel_itinerary', 'get_user_info', 'file_ticket', 'finish']), then `[[ ## next_tool_args ## ]]` (must be formatted as a valid Python dict[str, Any]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
887 |             "\n",
888 |             "\n",
889 |             "\u001b[31mResponse:\u001b[0m\n",
890 |             "\n",
891 |             "\u001b[32m[[ ## next_thought ## ]]\n",
892 |             "I have gathered Adam's user profile information. Now I can proceed to book the selected flight DA123 for him.\n",
893 |             "\n",
894 |             "[[ ## next_tool_name ## ]]\n",
895 |             "book_flight\n",
896 |             "\n",
897 |             "[[ ## next_tool_args ## ]]\n",
898 |             "{\"flight\":{\"flight_id\":\"DA123\",\"date_time\":{\"year\":2025,\"month\":9,\"day\":1,\"hour\":1},\"origin\":\"SFO\",\"destination\":\"JFK\",\"duration\":3.0,\"price\":200.0},\"user_profile\":{\"user_id\":\"1\",\"name\":\"Adam\",\"email\":\"adam@gmail.com\"}}\n",
899 |             "\n",
900 |             "[[ ## completed ## ]]\u001b[0m\n",
901 |             "\n",
902 |             "\n",
903 |             "\n",
904 |             "\n",
905 |             "\n",
906 |             "\u001b[34m[2025-05-28T01:06:49.025746]\u001b[0m\n",
907 |             "\n",
908 |             "\u001b[31mSystem message:\u001b[0m\n",
909 |             "\n",
910 |             "Your input fields are:\n",
911 |             "1. `user_request` (str)\n",
912 |             "2. `trajectory` (str)\n",
913 |             "Your output fields are:\n",
914 |             "1. `next_thought` (str)\n",
915 |             "2. `next_tool_name` (Literal['fetch_flight_info', 'fetch_itinerary', 'pick_flight', 'book_flight', 'cancel_itinerary', 'get_user_info', 'file_ticket', 'finish'])\n",
916 |             "3. `next_tool_args` (dict[str, Any])\n",
917 |             "All interactions will be structured in the following way, with the appropriate values filled in.\n",
918 |             "\n",
919 |             "[[ ## user_request ## ]]\n",
920 |             "{user_request}\n",
921 |             "\n",
922 |             "[[ ## trajectory ## ]]\n",
923 |             "{trajectory}\n",
924 |             "\n",
925 |             "[[ ## next_thought ## ]]\n",
926 |             "{next_thought}\n",
927 |             "\n",
928 |             "[[ ## next_tool_name ## ]]\n",
929 |             "{next_tool_name}        # note: the value you produce must exactly match (no extra characters) one of: fetch_flight_info; fetch_itinerary; pick_flight; book_flight; cancel_itinerary; get_user_info; file_ticket; finish\n",
930 |             "\n",
931 |             "[[ ## next_tool_args ## ]]\n",
932 |             "{next_tool_args}        # note: the value you produce must adhere to the JSON schema: {\"type\": \"object\", \"additionalProperties\": true}\n",
933 |             "\n",
934 |             "[[ ## completed ## ]]\n",
935 |             "In adhering to this structure, your objective is: \n",
936 |             "        You are an airline customer service agent that helps user book and manage flights. \n",
937 |             "        \n",
938 |             "        You are given a list of tools to handle user request, and you should decide the right tool to use in order to\n",
939 |             "        fulfill users' request.\n",
940 |             "        \n",
941 |             "        You are an Agent. In each episode, you will be given the fields `user_request` as input. And you can see your past trajectory so far.\n",
942 |             "        Your goal is to use one or more of the supplied tools to collect any necessary information for producing `process_result`.\n",
943 |             "        \n",
944 |             "        To do this, you will interleave next_thought, next_tool_name, and next_tool_args in each turn, and also when finishing the task.\n",
945 |             "        After each tool call, you receive a resulting observation, which gets appended to your trajectory.\n",
946 |             "        \n",
947 |             "        When writing next_thought, you may reason about the current situation and plan for future steps.\n",
948 |             "        When selecting the next_tool_name and its next_tool_args, the tool must be one of:\n",
949 |             "        \n",
950 |             "        (1) fetch_flight_info, whose description is <desc>Fetch flight information from origin to destination on the given date</desc>. It takes arguments {'date': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'origin': {'type': 'string'}, 'destination': {'type': 'string'}} in JSON format.\n",
951 |             "        (2) fetch_itinerary, whose description is <desc>Fetch a booked itinerary information from database</desc>. It takes arguments {'confirmation_number': {'type': 'string'}} in JSON format.\n",
952 |             "        (3) pick_flight, whose description is <desc>Pick up the best flight that matches users' request. we pick the shortest, and cheaper one on ties.</desc>. It takes arguments {'flights': {'$defs': {'Date': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'Flight': {'properties': {'flight_id': {'title': 'Flight Id', 'type': 'string'}, 'date_time': {'$ref': '#/$defs/Date'}, 'origin': {'title': 'Origin', 'type': 'string'}, 'destination': {'title': 'Destination', 'type': 'string'}, 'duration': {'title': 'Duration', 'type': 'number'}, 'price': {'title': 'Price', 'type': 'number'}}, 'required': ['flight_id', 'date_time', 'origin', 'destination', 'duration', 'price'], 'title': 'Flight', 'type': 'object'}}, 'items': {'$ref': '#/$defs/Flight'}, 'type': 'array'}} in JSON format.\n",
953 |             "        (4) book_flight, whose description is <desc>Book a flight on behalf of the user.</desc>. It takes arguments {'flight': {'properties': {'flight_id': {'title': 'Flight Id', 'type': 'string'}, 'date_time': {'properties': {'year': {'title': 'Year', 'type': 'integer'}, 'month': {'title': 'Month', 'type': 'integer'}, 'day': {'title': 'Day', 'type': 'integer'}, 'hour': {'title': 'Hour', 'type': 'integer'}}, 'required': ['year', 'month', 'day', 'hour'], 'title': 'Date', 'type': 'object'}, 'origin': {'title': 'Origin', 'type': 'string'}, 'destination': {'title': 'Destination', 'type': 'string'}, 'duration': {'title': 'Duration', 'type': 'number'}, 'price': {'title': 'Price', 'type': 'number'}}, 'required': ['flight_id', 'date_time', 'origin', 'destination', 'duration', 'price'], 'title': 'Flight', 'type': 'object'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
954 |             "        (5) cancel_itinerary, whose description is <desc>Cancel an itinerary on behalf of the user.</desc>. It takes arguments {'confirmation_number': {'type': 'string'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
955 |             "        (6) get_user_info, whose description is <desc>Fetch the user profile from database with given name.</desc>. It takes arguments {'name': {'type': 'string'}} in JSON format.\n",
956 |             "        (7) file_ticket, whose description is <desc>File a customer support ticket if this is something the agent cannot handle.</desc>. It takes arguments {'user_request': {'type': 'string'}, 'user_profile': {'properties': {'user_id': {'title': 'User Id', 'type': 'string'}, 'name': {'title': 'Name', 'type': 'string'}, 'email': {'title': 'Email', 'type': 'string'}}, 'required': ['user_id', 'name', 'email'], 'title': 'UserProfile', 'type': 'object'}} in JSON format.\n",
957 |             "        (8) finish, whose description is <desc>Marks the task as complete. That is, signals that all information for producing the outputs, i.e. `process_result`, are now available to be extracted.</desc>. It takes arguments {} in JSON format.\n",
958 |             "\n",
959 |             "\n",
960 |             "\u001b[31mUser message:\u001b[0m\n",
961 |             "\n",
962 |             "[[ ## user_request ## ]]\n",
963 |             "please help me book a flight from SFO to JFK on 09/01/2025, my name is Adam\n",
964 |             "\n",
965 |             "[[ ## trajectory ## ]]\n",
966 |             "[[ ## thought_0 ## ]]\n",
967 |             "I need to fetch flight information for the route from SFO to JFK on the specified date of 09/01/2025. Once I have the flight options, I can help Adam pick the best flight and proceed with the booking.\n",
968 |             "\n",
969 |             "[[ ## tool_name_0 ## ]]\n",
970 |             "fetch_flight_info\n",
971 |             "\n",
972 |             "[[ ## tool_args_0 ## ]]\n",
973 |             "{\"date\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 0}, \"origin\": \"SFO\", \"destination\": \"JFK\"}\n",
974 |             "\n",
975 |             "[[ ## observation_0 ## ]]\n",
976 |             "[1] «flight_id='DA123' date_time=Date(year=2025, month=9, day=1, hour=1) origin='SFO' destination='JFK' duration=3.0 price=200.0»\n",
977 |             "[2] «flight_id='DA125' date_time=Date(year=2025, month=9, day=1, hour=7) origin='SFO' destination='JFK' duration=9.0 price=500.0»\n",
978 |             "\n",
979 |             "[[ ## thought_1 ## ]]\n",
980 |             "I have received the flight options from SFO to JFK on 09/01/2025. There are two flights available: DA123 at 1 AM for $200 and DA125 at 7 AM for $500. I will now pick the best flight, which is the cheaper option, DA123.\n",
981 |             "\n",
982 |             "[[ ## tool_name_1 ## ]]\n",
983 |             "pick_flight\n",
984 |             "\n",
985 |             "[[ ## tool_args_1 ## ]]\n",
986 |             "{\"flights\": [{\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}, {\"flight_id\": \"DA125\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 7}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 9.0, \"price\": 500.0}]}\n",
987 |             "\n",
988 |             "[[ ## observation_1 ## ]]\n",
989 |             "{\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}\n",
990 |             "\n",
991 |             "[[ ## thought_2 ## ]]\n",
992 |             "I have successfully picked the best flight, which is DA123. Now, I need to gather Adam's user profile information to proceed with the booking.\n",
993 |             "\n",
994 |             "[[ ## tool_name_2 ## ]]\n",
995 |             "get_user_info\n",
996 |             "\n",
997 |             "[[ ## tool_args_2 ## ]]\n",
998 |             "{\"name\": \"Adam\"}\n",
999 |             "\n",
1000 |             "[[ ## observation_2 ## ]]\n",
1001 |             "{\"user_id\": \"1\", \"name\": \"Adam\", \"email\": \"adam@gmail.com\"}\n",
1002 |             "\n",
1003 |             "[[ ## thought_3 ## ]]\n",
1004 |             "I have gathered Adam's user profile information. Now I can proceed to book the selected flight DA123 for him.\n",
1005 |             "\n",
1006 |             "[[ ## tool_name_3 ## ]]\n",
1007 |             "book_flight\n",
1008 |             "\n",
1009 |             "[[ ## tool_args_3 ## ]]\n",
1010 |             "{\"flight\": {\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}, \"user_profile\": {\"user_id\": \"1\", \"name\": \"Adam\", \"email\": \"adam@gmail.com\"}}\n",
1011 |             "\n",
1012 |             "[[ ## observation_3 ## ]]\n",
1013 |             "[\"94ldyhsx\", {\"confirmation_number\": \"94ldyhsx\", \"user_profile\": {\"user_id\": \"1\", \"name\": \"Adam\", \"email\": \"adam@gmail.com\"}, \"flight\": {\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}}]\n",
1014 |             "\n",
1015 |             "Respond with the corresponding output fields, starting with the field `[[ ## next_thought ## ]]`, then `[[ ## next_tool_name ## ]]` (must be formatted as a valid Python Literal['fetch_flight_info', 'fetch_itinerary', 'pick_flight', 'book_flight', 'cancel_itinerary', 'get_user_info', 'file_ticket', 'finish']), then `[[ ## next_tool_args ## ]]` (must be formatted as a valid Python dict[str, Any]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1016 |             "\n",
1017 |             "\n",
1018 |             "\u001b[31mResponse:\u001b[0m\n",
1019 |             "\n",
1020 |             "\u001b[32m[[ ## next_thought ## ]]\n",
1021 |             "Adam's flight has been successfully booked, and I have received the confirmation number. I will now mark the task as complete.\n",
1022 |             "\n",
1023 |             "[[ ## next_tool_name ## ]]\n",
1024 |             "finish\n",
1025 |             "\n",
1026 |             "[[ ## next_tool_args ## ]]\n",
1027 |             "{}\n",
1028 |             "\n",
1029 |             "[[ ## completed ## ]]\u001b[0m\n",
1030 |             "\n",
1031 |             "\n",
1032 |             "\n",
1033 |             "\n",
1034 |             "\n",
1035 |             "\u001b[34m[2025-05-28T01:06:51.599439]\u001b[0m\n",
1036 |             "\n",
1037 |             "\u001b[31mSystem message:\u001b[0m\n",
1038 |             "\n",
1039 |             "Your input fields are:\n",
1040 |             "1. `user_request` (str)\n",
1041 |             "2. `trajectory` (str)\n",
1042 |             "Your output fields are:\n",
1043 |             "1. `reasoning` (str)\n",
1044 |             "2. `process_result` (str): Message that summarizes the process result, and the information users need, e.g., the confirmation_number if a new flight is booked.\n",
1045 |             "All interactions will be structured in the following way, with the appropriate values filled in.\n",
1046 |             "\n",
1047 |             "[[ ## user_request ## ]]\n",
1048 |             "{user_request}\n",
1049 |             "\n",
1050 |             "[[ ## trajectory ## ]]\n",
1051 |             "{trajectory}\n",
1052 |             "\n",
1053 |             "[[ ## reasoning ## ]]\n",
1054 |             "{reasoning}\n",
1055 |             "\n",
1056 |             "[[ ## process_result ## ]]\n",
1057 |             "{process_result}\n",
1058 |             "\n",
1059 |             "[[ ## completed ## ]]\n",
1060 |             "In adhering to this structure, your objective is: \n",
1061 |             "        You are an airline customer service agent that helps user book and manage flights. \n",
1062 |             "        \n",
1063 |             "        You are given a list of tools to handle user request, and you should decide the right tool to use in order to\n",
1064 |             "        fulfill users' request.\n",
1065 |             "\n",
1066 |             "\n",
1067 |             "\u001b[31mUser message:\u001b[0m\n",
1068 |             "\n",
1069 |             "[[ ## user_request ## ]]\n",
1070 |             "please help me book a flight from SFO to JFK on 09/01/2025, my name is Adam\n",
1071 |             "\n",
1072 |             "[[ ## trajectory ## ]]\n",
1073 |             "[[ ## thought_0 ## ]]\n",
1074 |             "I need to fetch flight information for the route from SFO to JFK on the specified date of 09/01/2025. Once I have the flight options, I can help Adam pick the best flight and proceed with the booking.\n",
1075 |             "\n",
1076 |             "[[ ## tool_name_0 ## ]]\n",
1077 |             "fetch_flight_info\n",
1078 |             "\n",
1079 |             "[[ ## tool_args_0 ## ]]\n",
1080 |             "{\"date\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 0}, \"origin\": \"SFO\", \"destination\": \"JFK\"}\n",
1081 |             "\n",
1082 |             "[[ ## observation_0 ## ]]\n",
1083 |             "[1] «flight_id='DA123' date_time=Date(year=2025, month=9, day=1, hour=1) origin='SFO' destination='JFK' duration=3.0 price=200.0»\n",
1084 |             "[2] «flight_id='DA125' date_time=Date(year=2025, month=9, day=1, hour=7) origin='SFO' destination='JFK' duration=9.0 price=500.0»\n",
1085 |             "\n",
1086 |             "[[ ## thought_1 ## ]]\n",
1087 |             "I have received the flight options from SFO to JFK on 09/01/2025. There are two flights available: DA123 at 1 AM for $200 and DA125 at 7 AM for $500. I will now pick the best flight, which is the cheaper option, DA123.\n",
1088 |             "\n",
1089 |             "[[ ## tool_name_1 ## ]]\n",
1090 |             "pick_flight\n",
1091 |             "\n",
1092 |             "[[ ## tool_args_1 ## ]]\n",
1093 |             "{\"flights\": [{\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}, {\"flight_id\": \"DA125\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 7}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 9.0, \"price\": 500.0}]}\n",
1094 |             "\n",
1095 |             "[[ ## observation_1 ## ]]\n",
1096 |             "{\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}\n",
1097 |             "\n",
1098 |             "[[ ## thought_2 ## ]]\n",
1099 |             "I have successfully picked the best flight, which is DA123. Now, I need to gather Adam's user profile information to proceed with the booking.\n",
1100 |             "\n",
1101 |             "[[ ## tool_name_2 ## ]]\n",
1102 |             "get_user_info\n",
1103 |             "\n",
1104 |             "[[ ## tool_args_2 ## ]]\n",
1105 |             "{\"name\": \"Adam\"}\n",
1106 |             "\n",
1107 |             "[[ ## observation_2 ## ]]\n",
1108 |             "{\"user_id\": \"1\", \"name\": \"Adam\", \"email\": \"adam@gmail.com\"}\n",
1109 |             "\n",
1110 |             "[[ ## thought_3 ## ]]\n",
1111 |             "I have gathered Adam's user profile information. Now I can proceed to book the selected flight DA123 for him.\n",
1112 |             "\n",
1113 |             "[[ ## tool_name_3 ## ]]\n",
1114 |             "book_flight\n",
1115 |             "\n",
1116 |             "[[ ## tool_args_3 ## ]]\n",
1117 |             "{\"flight\": {\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}, \"user_profile\": {\"user_id\": \"1\", \"name\": \"Adam\", \"email\": \"adam@gmail.com\"}}\n",
1118 |             "\n",
1119 |             "[[ ## observation_3 ## ]]\n",
1120 |             "[\"94ldyhsx\", {\"confirmation_number\": \"94ldyhsx\", \"user_profile\": {\"user_id\": \"1\", \"name\": \"Adam\", \"email\": \"adam@gmail.com\"}, \"flight\": {\"flight_id\": \"DA123\", \"date_time\": {\"year\": 2025, \"month\": 9, \"day\": 1, \"hour\": 1}, \"origin\": \"SFO\", \"destination\": \"JFK\", \"duration\": 3.0, \"price\": 200.0}}]\n",
1121 |             "\n",
1122 |             "[[ ## thought_4 ## ]]\n",
1123 |             "Adam's flight has been successfully booked, and I have received the confirmation number. I will now mark the task as complete.\n",
1124 |             "\n",
1125 |             "[[ ## tool_name_4 ## ]]\n",
1126 |             "finish\n",
1127 |             "\n",
1128 |             "[[ ## tool_args_4 ## ]]\n",
1129 |             "{}\n",
1130 |             "\n",
1131 |             "[[ ## observation_4 ## ]]\n",
1132 |             "Completed.\n",
1133 |             "\n",
1134 |             "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## process_result ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
1135 |             "\n",
1136 |             "\n",
1137 |             "\u001b[31mResponse:\u001b[0m\n",
1138 |             "\n",
1139 |             "\u001b[32m[[ ## reasoning ## ]]\n",
1140 |             "I successfully fetched flight information for the route from SFO to JFK on 09/01/2025. There were two available flights: DA123 at 1 AM for $200 and DA125 at 7 AM for $500. I selected the cheaper option, DA123, and then retrieved Adam's user profile information to proceed with the booking. After booking the flight, I received a confirmation number for the reservation.\n",
1141 |             "\n",
1142 |             "[[ ## process_result ## ]]\n",
1143 |             "Your flight from SFO to JFK on 09/01/2025 has been successfully booked. Your confirmation number is 94ldyhsx.\n",
1144 |             "\n",
1145 |             "[[ ## completed ## ]]\u001b[0m\n",
1146 |             "\n",
1147 |             "\n",
1148 |             "\n",
1149 |             "\n",
1150 |             "\n"
1151 |           ]
1152 |         }
1153 |       ],
1154 |       "source": [
1155 |         "dspy.inspect_history(n=10)"
1156 |       ]
1157 |     },
1158 |     {
1159 |       "cell_type": "markdown",
1160 |       "metadata": {
1161 |         "id": "TXu6hnIDZLjn"
1162 |       },
1163 |       "source": [
1164 |         "We can see that in each LM call, the user message includes the information of previous tool calls, along with the task description."
1165 |       ]
1166 |     },
1167 |     {
1168 |       "cell_type": "markdown",
1169 |       "metadata": {
1170 |         "id": "qhMU7V0SZcU1"
1171 |       },
1172 |       "source": [
1173 |         "Let's try a different task."
1174 |       ]
1175 |     },
1176 |     {
1177 |       "cell_type": "code",
1178 |       "execution_count": 10,
1179 |       "metadata": {
1180 |         "colab": {
1181 |           "base_uri": "https://localhost:8080/"
1182 |         },
1183 |         "id": "iN2XoVmGYs1e",
1184 |         "outputId": "93df2938-3560-4976-d6cc-a64e911d9030"
1185 |       },
1186 |       "outputs": [
1187 |         {
1188 |           "name": "stdout",
1189 |           "output_type": "stream",
1190 |           "text": [
1191 |             "Prediction(\n",
1192 |             "    trajectory={'thought_0': \"I need to fetch the user's current itinerary using the confirmation number provided (7zokt5v5) to understand the details of their existing booking before making any modifications.\", 'tool_name_0': 'fetch_itinerary', 'tool_args_0': {'confirmation_number': '7zokt5v5'}, 'observation_0': None, 'thought_1': \"I need to fetch the user's current itinerary using the confirmation number provided (7zokt5v5) to understand the details of their existing booking before making any modifications.\", 'tool_name_1': 'fetch_itinerary', 'tool_args_1': {'confirmation_number': '7zokt5v5'}, 'observation_1': None, 'thought_2': \"I need to file a customer support ticket since I am unable to fetch the user's itinerary with the provided confirmation number.\", 'tool_name_2': 'file_ticket', 'tool_args_2': {'user_request': 'i want to take DA125 instead on 09/01, please help me modify my itinerary 7zokt5v5', 'user_profile': {'user_id': '', 'name': '', 'email': ''}}, 'observation_2': 'lf3n2t', 'thought_3': \"Since I have filed a customer support ticket for the user's request, I will wait for a response from the support team regarding the modification of the itinerary.\", 'tool_name_3': 'finish', 'tool_args_3': {}, 'observation_3': 'Completed.'},\n",
1193 |             "    reasoning=\"I attempted to modify the user's itinerary by fetching the current details using the provided confirmation number (7zokt5v5). However, I was unable to retrieve the itinerary. As a result, I filed a customer support ticket to address the issue and request the modification to the user's itinerary for flight DA125 on 09/01.\",\n",
1194 |             "    process_result='A customer support ticket has been filed regarding your request to modify your itinerary. The ticket number is lf3n2t. Please wait for a response from the support team for further assistance.'\n",
1195 |             ")\n"
1196 |           ]
1197 |         }
1198 |       ],
1199 |       "source": [
1200 |         "confirmation_number = \"{copy the confirmation number here}\"\n",
1201 |         "\n",
1202 |         "result = agent(user_request=f\"i want to take DA125 instead on 09/01, please help me modify my itinerary {confirmation_number}\")\n",
1203 |         "print(result)"
1204 |       ]
1205 |     },
1206 |     {
1207 |       "cell_type": "markdown",
1208 |       "metadata": {
1209 |         "id": "vkxpCJ6OZXQK"
1210 |       },
1211 |       "source": [
1212 |         "## Conclusion\n",
1213 |         "\n",
1214 |         "Congrats on finishing the tutorial! In this tutorial we have seen how to build a customer service agent with DSPy. The gists are:\n",
1215 |         "\n",
1216 |         "- Define the tools as python function, and **add docstring and type hints**.\n",
1217 |         "- Provide the tools to `dspy.ReAct` along with a signature to define the task.\n",
1218 |         "- Invoke the `dspy.ReAct` with the inputs field defined in the signature, and it will start the reasoning and acting loop behind the scene."
1219 |       ]
1220 |     }
1221 |   ],
1222 |   "metadata": {
1223 |     "colab": {
1224 |       "provenance": []
1225 |     },
1226 |     "kernelspec": {
1227 |       "display_name": "Python 3",
1228 |       "name": "python3"
1229 |     },
1230 |     "language_info": {
1231 |       "name": "python"
1232 |     }
1233 |   },
1234 |   "nbformat": 4,
1235 |   "nbformat_minor": 0
1236 | }
```

deployment/index.md
```
1 | # Tutorial: Deploying your DSPy program
2 |
3 | This guide demonstrates two potential ways to deploy your DSPy program in production: FastAPI for lightweight deployments and MLflow for more production-grade deployments with program versioning and management.
4 |
5 | Below, we'll assume you have the following simple DSPy program that you want to deploy. You can replace this with something more sophisticated.
6 |
7 | ```python
8 | import dspy
9 |
10 | dspy.settings.configure(lm=dspy.LM("openai/gpt-4o-mini"))
11 | dspy_program = dspy.ChainOfThought("question -> answer")
12 | ```
13 |
14 | ## Deploying with FastAPI
15 |
16 | FastAPI offers a straightforward way to serve your DSPy program as a REST API. This is ideal when you have direct access to your program code and need a lightweight deployment solution.
17 |
18 | ```bash
19 | > pip install fastapi uvicorn
20 | > export OPENAI_API_KEY="your-openai-api-key"
21 | ```
22 |
23 | Let's create a FastAPI application to serve your `dspy_program` defined above.
24 |
25 | ```python
26 | from fastapi import FastAPI, HTTPException
27 | from pydantic import BaseModel
28 |
29 | import dspy
30 |
31 | app = FastAPI(
32 |     title="DSPy Program API",
33 |     description="A simple API serving a DSPy Chain of Thought program",
34 |     version="1.0.0"
35 | )
36 |
37 | # Define request model for better documentation and validation
38 | class Question(BaseModel):
39 |     text: str
40 |
41 | # Configure your language model and 'asyncify' your DSPy program.
42 | lm = dspy.LM("openai/gpt-4o-mini")
43 | dspy.settings.configure(lm=lm, async_max_workers=4) # default is 8
44 | dspy_program = dspy.ChainOfThought("question -> answer")
45 | dspy_program = dspy.asyncify(dspy_program)
46 |
47 | @app.post("/predict")
48 | async def predict(question: Question):
49 |     try:
50 |         result = await dspy_program(question=question.text)
51 |         return {
52 |             "status": "success",
53 |             "data": result.toDict()
54 |         }
55 |     except Exception as e:
56 |         raise HTTPException(status_code=500, detail=str(e))
57 | ```
58 |
59 | In the code above, we call `dspy.asyncify` to convert the dspy program to run in async mode for high-throughput FastAPI
60 | deployments. Currently, this runs the dspy program in a separate thread and awaits its result.
61 |
62 | By default, the limit of spawned threads is 8. Think of this like a worker pool.
63 | If you have 8 in-flight programs and call it once more, the 9th call will wait until one of the 8 returns.
64 | You can configure the async capacity using the new `async_max_workers` setting.
65 |
66 | ??? "Streaming, in DSPy 2.6.0+"
67 |
68 |     Streaming is also supported in DSPy 2.6.0+, which can be installed via `pip install -U dspy`.
69 |
70 |     We can use `dspy.streamify` to convert the dspy program to a streaming mode. This is useful when you want to stream
71 |     the intermediate outputs (i.e. O1-style reasoning) to the client before the final prediction is ready. This uses
72 |     asyncify under the hood and inherits the execution semantics.
73 |
74 |     ```python
75 |     dspy_program = dspy.asyncify(dspy.ChainOfThought("question -> answer"))
76 |     streaming_dspy_program = dspy.streamify(dspy_program)
77 |
78 |     @app.post("/predict/stream")
79 |     async def stream(question: Question):
80 |         async def generate():
81 |             async for value in streaming_dspy_program(question=question.text):
82 |                 if isinstance(value, dspy.Prediction):
83 |                     data = {"prediction": value.labels().toDict()}
84 |                 elif isinstance(value, litellm.ModelResponse):
85 |                     data = {"chunk": value.json()}
86 |                 yield f"data: {ujson.dumps(data)}\n\n"
87 |             yield "data: [DONE]\n\n"
88 |
89 |         return StreamingResponse(generate(), media_type="text/event-stream")
90 |
91 |     # Since you're often going to want to stream the result of a DSPy program as server-sent events,
92 |     # we've included a helper function for that, which is equivalent to the code above.
93 |
94 |     from dspy.utils.streaming import streaming_response
95 |
96 |     @app.post("/predict/stream")
97 |     async def stream(question: Question):
98 |         stream = streaming_dspy_program(question=question.text)
99 |         return StreamingResponse(streaming_response(stream), media_type="text/event-stream")
100 |     ```
101 |
102 | Write your code to a file, e.g., `fastapi_dspy.py`. Then you can serve the app with:
103 |
104 | ```bash
105 | > uvicorn fastapi_dspy:app --reload
106 | ```
107 |
108 | It will start a local server at `http://127.0.0.1:8000/`. You can test it with the python code below:
109 |
110 | ```python
111 | import requests
112 |
113 | response = requests.post(
114 |     "http://127.0.0.1:8000/predict",
115 |     json={"text": "What is the capital of France?"}
116 | )
117 | print(response.json())
118 | ```
119 |
120 | You should see the response like below:
121 |
122 | ```json
123 | {
124 |   "status": "success",
125 |   "data": {
126 |     "reasoning": "The capital of France is a well-known fact, commonly taught in geography classes and referenced in various contexts. Paris is recognized globally as the capital city, serving as the political, cultural, and economic center of the country.",
127 |     "answer": "The capital of France is Paris."
128 |   }
129 | }
130 | ```
131 |
132 | ## Deploying with MLflow
133 |
134 | We recommend deploying with MLflow if you are looking to package your DSPy program and deploy in an isolated environment.
135 | MLflow is a popular platform for managing machine learning workflows, including versioning, tracking, and deployment.
136 |
137 | ```bash
138 | > pip install mlflow>=2.18.0
139 | ```
140 |
141 | Let's spin up the MLflow tracking server, where we will store our DSPy program. The command below will start a local server at
142 | `http://127.0.0.1:5000/`.
143 |
144 | ```bash
145 | > mlflow ui
146 | ```
147 |
148 | Then we can define the DSPy program and log it to the MLflow server. "log" is an overloaded term in MLflow, basically it means
149 | we store the program information along with environment requirements in the MLflow server. This is done via the `mlflow.dspy.log_model()`
150 | function, please see the code below:
151 |
152 | > [!NOTE]
153 | > As of MLflow 2.22.0, there is a caveat that you must wrap your DSPy program in a custom DSPy Module class when deploying with MLflow.
154 | > This is because MLflow requires positional arguments while DSPy pre-built modules disallow positional arguments, e.g., `dspy.Predict`
155 | > or `dspy.ChainOfThought`. To work around this, create a wrapper class that inherits from `dspy.Module` and implement your program's
156 | > logic in the `forward()` method, as shown in the example below.
157 |
158 | ```python
159 | import dspy
160 | import mlflow
161 |
162 | mlflow.set_tracking_uri("http://127.0.0.1:5000/")
163 | mlflow.set_experiment("deploy_dspy_program")
164 |
165 | lm = dspy.LM("openai/gpt-4o-mini")
166 | dspy.settings.configure(lm=lm)
167 |
168 | class MyProgram(dspy.Module):
169 |     def __init__(self):
170 |         super().__init__()
171 |         self.cot = dspy.ChainOfThought("question -> answer")
172 |
173 |     def forward(self, messages):
174 |         return self.cot(question=messages[0]["content"])
175 |
176 | dspy_program = MyProgram()
177 |
178 | with mlflow.start_run():
179 |     mlflow.dspy.log_model(
180 |         dspy_program,
181 |         "dspy_program",
182 |         input_example={"messages": [{"role": "user", "content": "What is LLM agent?"}]},
183 |         task="llm/v1/chat",
184 |     )
185 | ```
186 |
187 | We recommend you to set `task="llm/v1/chat"` so that the deployed program automatically takes input and generate output in
188 | the same format as the OpenAI chat API, which is a common interface for LM applications. Write the code above into
189 | a file, e.g. `mlflow_dspy.py`, and run it.
190 |
191 | After you logged the program, you can view the saved information in MLflow UI. Open `http://127.0.0.1:5000/` and select
192 | the `deploy_dspy_program` experiment, then select the run your just created, under the `Artifacts` tab, you should see the
193 | logged program information, similar to the following screenshot:
194 |
195 | ![MLflow UI](./dspy_mlflow_ui.png)
196 |
197 | Grab your run id from UI (or the console print when you execute `mlflow_dspy.py`), now you can deploy the logged program
198 | with the following command:
199 |
200 | ```bash
201 | > mlflow models serve -m runs:/{run_id}/model -p 6000
202 | ```
203 |
204 | After the program is deployed, you can test it with the following command:
205 |
206 | ```bash
207 | > curl http://127.0.0.1:6000/invocations -H "Content-Type:application/json"  --data '{"messages": [{"content": "what is 2 + 2?", "role": "user"}]}'
208 | ```
209 |
210 | You should see the response like below:
211 |
212 | ```json
213 | {
214 |   "choices": [
215 |     {
216 |       "index": 0,
217 |       "message": {
218 |         "role": "assistant",
219 |         "content": "{\"reasoning\": \"The question asks for the sum of 2 and 2. To find the answer, we simply add the two numbers together: 2 + 2 = 4.\", \"answer\": \"4\"}"
220 |       },
221 |       "finish_reason": "stop"
222 |     }
223 |   ]
224 | }
225 | ```
226 |
227 | For complete guide on how to deploy a DSPy program with MLflow, and how to customize the deployment, please refer to the
228 | [MLflow documentation](https://mlflow.org/docs/latest/llms/dspy/index.html).
229 |
230 | ### Best Practices for MLflow Deployment
231 |
232 | 1. **Environment Management**: Always specify your Python dependencies in a `conda.yaml` or `requirements.txt` file.
233 | 2. **Versioning**: Use meaningful tags and descriptions for your model versions.
234 | 3. **Input Validation**: Define clear input schemas and examples.
235 | 4. **Monitoring**: Set up proper logging and monitoring for production deployments.
236 |
237 | For production deployments, consider using MLflow with containerization:
238 |
239 | ```bash
240 | > mlflow models build-docker -m "runs:/{run_id}/model" -n "dspy-program"
241 | > docker run -p 6000:8080 dspy-program
242 | ```
243 |
244 | For a complete guide on production deployment options and best practices, refer to the
245 | [MLflow documentation](https://mlflow.org/docs/latest/llms/dspy/index.html).
```

email_extraction/index.md
```
1 | # Extracting Information from Emails with DSPy
2 |
3 | This tutorial demonstrates how to build an intelligent email processing system using DSPy. We'll create a system that can automatically extract key information from various types of emails, classify their intent, and structure the data for further processing.
4 |
5 | ## What You'll Build
6 |
7 | By the end of this tutorial, you'll have a DSPy-powered email processing system that can:
8 |
9 | - **Classify email types** (order confirmation, support request, meeting invitation, etc.)
10 | - **Extract key entities** (dates, amounts, product names, contact info)
11 | - **Determine urgency levels** and required actions
12 | - **Structure extracted data** into consistent formats
13 | - **Handle multiple email formats** robustly
14 |
15 | ## Prerequisites
16 |
17 | - Basic understanding of DSPy modules and signatures
18 | - Python 3.9+ installed
19 | - OpenAI API key (or access to another supported LLM)
20 |
21 | ## Installation and Setup
22 |
23 | ```bash
24 | pip install dspy
25 | ```
26 |
27 | <details>
28 | <summary>Recommended: Set up MLflow Tracing to understand what's happening under the hood.</summary>
29 |
30 | ### MLflow DSPy Integration
31 |
32 | <a href="https://mlflow.org/">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. In this tutorial, you can use MLflow to visualize prompts and optimization progress as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.
33 |
34 | ![MLflow Trace](./mlflow-tracing-email-extraction.png)
35 |
36 | 1. Install MLflow
37 |
38 | ```bash
39 | %pip install mlflow>=3.0.0
40 | ```
41 |
42 | 2. Start MLflow UI in a separate terminal
43 | ```bash
44 | mlflow ui --port 5000 --backend-store-uri sqlite:///mlruns.db
45 | ```
46 |
47 | 3. Connect the notebook to MLflow
48 | ```python
49 | import mlflow
50 |
51 | mlflow.set_tracking_uri("http://localhost:5000")
52 | mlflow.set_experiment("DSPy")
53 | ```
54 |
55 | 4. Enabling tracing.
56 | ```python
57 | mlflow.dspy.autolog()
58 | ```
59 |
60 |
61 | To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.
62 | </details>
63 |
64 | ## Step 1: Define Our Data Structures
65 |
66 | First, let's define the types of information we want to extract from emails:
67 |
68 | ```python
69 | import dspy
70 | from typing import List, Optional, Literal
71 | from datetime import datetime
72 | from pydantic import BaseModel
73 | from enum import Enum
74 |
75 | class EmailType(str, Enum):
76 |     ORDER_CONFIRMATION = "order_confirmation"
77 |     SUPPORT_REQUEST = "support_request"
78 |     MEETING_INVITATION = "meeting_invitation"
79 |     NEWSLETTER = "newsletter"
80 |     PROMOTIONAL = "promotional"
81 |     INVOICE = "invoice"
82 |     SHIPPING_NOTIFICATION = "shipping_notification"
83 |     OTHER = "other"
84 |
85 | class UrgencyLevel(str, Enum):
86 |     LOW = "low"
87 |     MEDIUM = "medium"
88 |     HIGH = "high"
89 |     CRITICAL = "critical"
90 |
91 | class ExtractedEntity(BaseModel):
92 |     entity_type: str
93 |     value: str
94 |     confidence: float
95 | ```
96 |
97 | ## Step 2: Create DSPy Signatures
98 |
99 | Now let's define the signatures for our email processing pipeline:
100 |
101 | ```python
102 | class ClassifyEmail(dspy.Signature):
103 |     """Classify the type and urgency of an email based on its content."""
104 |
105 |     email_subject: str = dspy.InputField(desc="The subject line of the email")
106 |     email_body: str = dspy.InputField(desc="The main content of the email")
107 |     sender: str = dspy.InputField(desc="Email sender information")
108 |
109 |     email_type: EmailType = dspy.OutputField(desc="The classified type of email")
110 |     urgency: UrgencyLevel = dspy.OutputField(desc="The urgency level of the email")
111 |     reasoning: str = dspy.OutputField(desc="Brief explanation of the classification")
112 |
113 | class ExtractEntities(dspy.Signature):
114 |     """Extract key entities and information from email content."""
115 |
116 |     email_content: str = dspy.InputField(desc="The full email content including subject and body")
117 |     email_type: EmailType = dspy.InputField(desc="The classified type of email")
118 |
119 |     key_entities: list[ExtractedEntity] = dspy.OutputField(desc="List of extracted entities with type, value, and confidence")
120 |     financial_amount: Optional[float] = dspy.OutputField(desc="Any monetary amounts found (e.g., '$99.99')")
121 |     important_dates: list[str] = dspy.OutputField(desc="List of important dates found in the email")
122 |     contact_info: list[str] = dspy.OutputField(desc="Relevant contact information extracted")
123 |
124 | class GenerateActionItems(dspy.Signature):
125 |     """Determine what actions are needed based on the email content and extracted information."""
126 |
127 |     email_type: EmailType = dspy.InputField()
128 |     urgency: UrgencyLevel = dspy.InputField()
129 |     email_summary: str = dspy.InputField(desc="Brief summary of the email content")
130 |     extracted_entities: list[ExtractedEntity] = dspy.InputField(desc="Key entities found in the email")
131 |
132 |     action_required: bool = dspy.OutputField(desc="Whether any action is required")
133 |     action_items: list[str] = dspy.OutputField(desc="List of specific actions needed")
134 |     deadline: Optional[str] = dspy.OutputField(desc="Deadline for action if applicable")
135 |     priority_score: int = dspy.OutputField(desc="Priority score from 1-10")
136 |
137 | class SummarizeEmail(dspy.Signature):
138 |     """Create a concise summary of the email content."""
139 |
140 |     email_subject: str = dspy.InputField()
141 |     email_body: str = dspy.InputField()
142 |     key_entities: list[ExtractedEntity] = dspy.InputField()
143 |
144 |     summary: str = dspy.OutputField(desc="A 2-3 sentence summary of the email's main points")
145 | ```
146 |
147 | ## Step 3: Build the Email Processing Module
148 |
149 | Now let's create our main email processing module:
150 |
151 | ```python
152 | class EmailProcessor(dspy.Module):
153 |     """A comprehensive email processing system using DSPy."""
154 |
155 |     def __init__(self):
156 |         super().__init__()
157 |
158 |         # Initialize our processing components
159 |         self.classifier = dspy.ChainOfThought(ClassifyEmail)
160 |         self.entity_extractor = dspy.ChainOfThought(ExtractEntities)
161 |         self.action_generator = dspy.ChainOfThought(GenerateActionItems)
162 |         self.summarizer = dspy.ChainOfThought(SummarizeEmail)
163 |
164 |     def forward(self, email_subject: str, email_body: str, sender: str = ""):
165 |         """Process an email and extract structured information."""
166 |
167 |         # Step 1: Classify the email
168 |         classification = self.classifier(
169 |             email_subject=email_subject,
170 |             email_body=email_body,
171 |             sender=sender
172 |         )
173 |
174 |         # Step 2: Extract entities
175 |         full_content = f"Subject: {email_subject}\n\nFrom: {sender}\n\n{email_body}"
176 |         entities = self.entity_extractor(
177 |             email_content=full_content,
178 |             email_type=classification.email_type
179 |         )
180 |
181 |         # Step 3: Generate summary
182 |         summary = self.summarizer(
183 |             email_subject=email_subject,
184 |             email_body=email_body,
185 |             key_entities=entities.key_entities
186 |         )
187 |
188 |         # Step 4: Determine actions
189 |         actions = self.action_generator(
190 |             email_type=classification.email_type,
191 |             urgency=classification.urgency,
192 |             email_summary=summary.summary,
193 |             extracted_entities=entities.key_entities
194 |         )
195 |
196 |         # Step 5: Structure the results
197 |         return dspy.Prediction(
198 |             email_type=classification.email_type,
199 |             urgency=classification.urgency,
200 |             summary=summary.summary,
201 |             key_entities=entities.key_entities,
202 |             financial_amount=entities.financial_amount,
203 |             important_dates=entities.important_dates,
204 |             action_required=actions.action_required,
205 |             action_items=actions.action_items,
206 |             deadline=actions.deadline,
207 |             priority_score=actions.priority_score,
208 |             reasoning=classification.reasoning,
209 |             contact_info=entities.contact_info
210 |         )
211 | ```
212 |
213 | ## Step 4: Running the Email Processing System
214 |
215 | Let's create a simple function to test our email processing system:
216 |
217 | ```python
218 | import os
219 | def run_email_processing_demo():
220 |     """Demonstration of the email processing system."""
221 |
222 |     # Configure DSPy
223 |     lm = dspy.LM(model='openai/gpt-4o-mini')
224 |     dspy.configure(lm=lm)
225 |     os.environ["OPENAI_API_KEY"] = "<YOUR OPENAI KEY>"
226 |
227 |     # Create our email processor
228 |     processor = EmailProcessor()
229 |
230 |     # Sample emails for testing
231 |     sample_emails = [
232 |         {
233 |             "subject": "Order Confirmation #12345 - Your MacBook Pro is on the way!",
234 |             "body": """Dear John Smith,
235 |
236 | Thank you for your order! We're excited to confirm that your order #12345 has been processed.
237 |
238 | Order Details:
239 | - MacBook Pro 14-inch (Space Gray)
240 | - Order Total: $2,399.00
241 | - Estimated Delivery: December 15, 2024
242 | - Tracking Number: 1Z999AA1234567890
243 |
244 | If you have any questions, please contact our support team at support@techstore.com.
245 |
246 | Best regards,
247 | TechStore Team""",
248 |             "sender": "orders@techstore.com"
249 |         },
250 |         {
251 |             "subject": "URGENT: Server Outage - Immediate Action Required",
252 |             "body": """Hi DevOps Team,
253 |
254 | We're experiencing a critical server outage affecting our production environment.
255 |
256 | Impact: All users unable to access the platform
257 | Started: 2:30 PM EST
258 |
259 | Please join the emergency call immediately: +1-555-123-4567
260 |
261 | This is our highest priority.
262 |
263 | Thanks,
264 | Site Reliability Team""",
265 |             "sender": "alerts@company.com"
266 |         },
267 |         {
268 |             "subject": "Meeting Invitation: Q4 Planning Session",
269 |             "body": """Hello team,
270 |
271 | You're invited to our Q4 planning session.
272 |
273 | When: Friday, December 20, 2024 at 2:00 PM - 4:00 PM EST
274 | Where: Conference Room A
275 |
276 | Please confirm your attendance by December 18th.
277 |
278 | Best,
279 | Sarah Johnson""",
280 |             "sender": "sarah.johnson@company.com"
281 |         }
282 |     ]
283 |
284 |     # Process each email and display results
285 |     print("🚀 Email Processing Demo")
286 |     print("=" * 50)
287 |
288 |     for i, email in enumerate(sample_emails):
289 |         print(f"\n📧 EMAIL {i+1}: {email['subject'][:50]}...")
290 |
291 |         # Process the email
292 |         result = processor(
293 |             email_subject=email["subject"],
294 |             email_body=email["body"],
295 |             sender=email["sender"]
296 |         )
297 |
298 |         # Display key results
299 |         print(f"   📊 Type: {result.email_type}")
300 |         print(f"   🚨 Urgency: {result.urgency}")
301 |         print(f"   📝 Summary: {result.summary}")
302 |
303 |         if result.financial_amount:
304 |             print(f"   💰 Amount: ${result.financial_amount:,.2f}")
305 |
306 |         if result.action_required:
307 |             print(f"   ✅ Action Required: Yes")
308 |             if result.deadline:
309 |                 print(f"   ⏰ Deadline: {result.deadline}")
310 |         else:
311 |             print(f"   ✅ Action Required: No")
312 |
313 | # Run the demo
314 | if __name__ == "__main__":
315 |     run_email_processing_demo()
316 | ```
317 |
318 | ## Expected Output
319 | ```
320 | 🚀 Email Processing Demo
321 | ==================================================
322 |
323 | 📧 EMAIL 1: Order Confirmation #12345 - Your MacBook Pro is on...
324 |    📊 Type: order_confirmation
325 |    🚨 Urgency: low
326 |    📝 Summary: The email confirms John Smith's order #12345 for a MacBook Pro 14-inch in Space Gray, totaling $2,399.00, with an estimated delivery date of December 15, 2024. It includes a tracking number and contact information for customer support.
327 |    💰 Amount: $2,399.00
328 |    ✅ Action Required: No
329 |
330 | 📧 EMAIL 2: URGENT: Server Outage - Immediate Action Required...
331 |    📊 Type: other
332 |    🚨 Urgency: critical
333 |    📝 Summary: The Site Reliability Team has reported a critical server outage that began at 2:30 PM EST, preventing all users from accessing the platform. They have requested the DevOps Team to join an emergency call immediately to address the issue.
334 |    ✅ Action Required: Yes
335 |    ⏰ Deadline: Immediately
336 |
337 | 📧 EMAIL 3: Meeting Invitation: Q4 Planning Session...
338 |    📊 Type: meeting_invitation
339 |    🚨 Urgency: medium
340 |    📝 Summary: Sarah Johnson has invited the team to a Q4 planning session on December 20, 2024, from 2:00 PM to 4:00 PM EST in Conference Room A. Attendees are asked to confirm their participation by December 18th.
341 |    ✅ Action Required: Yes
342 |    ⏰ Deadline: December 18th
343 | ```
344 |
345 | ## Next Steps
346 |
347 | - **Add more email types** and refine classification (newsletter, promotional, etc.)
348 | - **Add integration** with email providers (Gmail API, Outlook, IMAP)
349 | - **Experiment with different LLMs** and optimization strategies
350 | - **Add multilingual support** for international email processing
351 | - **Optimization** for increasing the performance of your program
```

entity_extraction/index.ipynb
```
1 | {
2 |   "cells": [
3 |     {
4 |       "cell_type": "markdown",
5 |       "metadata": {},
6 |       "source": [
7 |         "# Tutorial: Entity Extraction\n",
8 |         "\n",
9 |         "This tutorial demonstrates how to perform **entity extraction** using the CoNLL-2003 dataset with DSPy. The focus is on extracting entities referring to people. We will:\n",
10 |         "\n",
11 |         "- Extract and label entities from the CoNLL-2003 dataset that refer to people\n",
12 |         "- Define a DSPy program for extracting entities that refer to people\n",
13 |         "- Optimize and evaluate the program on a subset of the CoNLL-2003 dataset\n",
14 |         "\n",
15 |         "By the end of this tutorial, you'll understand how to structure tasks in DSPy using signatures and modules, evaluate your system's performance, and improve its quality with optimizers.\n",
16 |         "\n",
17 |         "Install the latest version of DSPy and follow along. If you're looking instead for a conceptual overview of DSPy, this [recent lecture](https://www.youtube.com/live/JEMYuzrKLUw) is a good place to start."
18 |       ]
19 |     },
20 |     {
21 |       "cell_type": "code",
22 |       "execution_count": 1,
23 |       "metadata": {},
24 |       "outputs": [],
25 |       "source": [
26 |         "# Install the latest version of DSPy\n",
27 |         "%pip install -U dspy\n",
28 |         "# Install the Hugging Face datasets library to load the CoNLL-2003 dataset\n",
29 |         "%pip install datasets"
30 |       ]
31 |     },
32 |     {
33 |       "cell_type": "markdown",
34 |       "metadata": {},
35 |       "source": [
36 |         "<details>\n",
37 |         "<summary>Recommended: Set up MLflow Tracing to understand what's happening under the hood.</summary>\n",
38 |         "\n",
39 |         "### MLflow DSPy Integration\n",
40 |         "\n",
41 |         "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. In this tutorial, you can use MLflow to visualize prompts and optimization progress as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
42 |         "\n",
43 |         "![MLflow Trace](./mlflow-tracing-entity-extraction.png)\n",
44 |         "\n",
45 |         "1. Install MLflow\n",
46 |         "\n",
47 |         "```bash\n",
48 |         "%pip install mlflow>=2.20\n",
49 |         "```\n",
50 |         "\n",
51 |         "2. Start MLflow UI in a separate terminal\n",
52 |         "```bash\n",
53 |         "mlflow ui --port 5000\n",
54 |         "```\n",
55 |         "\n",
56 |         "3. Connect the notebook to MLflow\n",
57 |         "```python\n",
58 |         "import mlflow\n",
59 |         "\n",
60 |         "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
61 |         "mlflow.set_experiment(\"DSPy\")\n",
62 |         "```\n",
63 |         "\n",
64 |         "4. Enabling tracing.\n",
65 |         "```python\n",
66 |         "mlflow.dspy.autolog()\n",
67 |         "```\n",
68 |         "\n",
69 |         "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
70 |         "</details>"
71 |       ]
72 |     },
73 |     {
74 |       "cell_type": "markdown",
75 |       "metadata": {},
76 |       "source": [
77 |         "## Load and Prepare the Dataset\n",
78 |         "\n",
79 |         "In this section, we prepare the CoNLL-2003 dataset, which is commonly used for entity extraction tasks. The dataset includes tokens annotated with entity labels such as persons, organizations, and locations.\n",
80 |         "\n",
81 |         "We will:\n",
82 |         "1. Load the dataset using the Hugging Face `datasets` library.\n",
83 |         "2. Define a function to extract tokens referring to people.\n",
84 |         "3. Slice the dataset to create smaller subsets for training and testing.\n",
85 |         "\n",
86 |         "DSPy expects examples in a structured format, so we'll also transform the dataset into DSPy `Examples` for easy integration."
87 |       ]
88 |     },
89 |     {
90 |       "cell_type": "code",
91 |       "execution_count": 2,
92 |       "metadata": {},
93 |       "outputs": [],
94 |       "source": [
95 |         "import os\n",
96 |         "import tempfile\n",
97 |         "from datasets import load_dataset\n",
98 |         "from typing import Dict, Any, List\n",
99 |         "import dspy\n",
100 |         "\n",
101 |         "def load_conll_dataset() -> dict:\n",
102 |         "    \"\"\"\n",
103 |         "    Loads the CoNLL-2003 dataset into train, validation, and test splits.\n",
104 |         "    \n",
105 |         "    Returns:\n",
106 |         "        dict: Dataset splits with keys 'train', 'validation', and 'test'.\n",
107 |         "    \"\"\"\n",
108 |         "    with tempfile.TemporaryDirectory() as temp_dir:\n",
109 |         "        # Use a temporary Hugging Face cache directory for compatibility with certain hosted notebook\n",
110 |         "        # environments that don't support the default Hugging Face cache directory\n",
111 |         "        os.environ[\"HF_DATASETS_CACHE\"] = temp_dir\n",
112 |         "        return load_dataset(\"conll2003\", trust_remote_code=True)\n",
113 |         "\n",
114 |         "def extract_people_entities(data_row: dict[str, Any]) -> list[str]:\n",
115 |         "    \"\"\"\n",
116 |         "    Extracts entities referring to people from a row of the CoNLL-2003 dataset.\n",
117 |         "    \n",
118 |         "    Args:\n",
119 |         "        data_row (dict[str, Any]): A row from the dataset containing tokens and NER tags.\n",
120 |         "    \n",
121 |         "    Returns:\n",
122 |         "        list[str]: List of tokens tagged as people.\n",
123 |         "    \"\"\"\n",
124 |         "    return [\n",
125 |         "        token\n",
126 |         "        for token, ner_tag in zip(data_row[\"tokens\"], data_row[\"ner_tags\"])\n",
127 |         "        if ner_tag in (1, 2)  # CoNLL entity codes 1 and 2 refer to people\n",
128 |         "    ]\n",
129 |         "\n",
130 |         "def prepare_dataset(data_split, start: int, end: int) -> list[dspy.Example]:\n",
131 |         "    \"\"\"\n",
132 |         "    Prepares a sliced dataset split for use with DSPy.\n",
133 |         "    \n",
134 |         "    Args:\n",
135 |         "        data_split: The dataset split (e.g., train or test).\n",
136 |         "        start (int): Starting index of the slice.\n",
137 |         "        end (int): Ending index of the slice.\n",
138 |         "    \n",
139 |         "    Returns:\n",
140 |         "        list[dspy.Example]: List of DSPy Examples with tokens and expected labels.\n",
141 |         "    \"\"\"\n",
142 |         "    return [\n",
143 |         "        dspy.Example(\n",
144 |         "            tokens=row[\"tokens\"],\n",
145 |         "            expected_extracted_people=extract_people_entities(row)\n",
146 |         "        ).with_inputs(\"tokens\")\n",
147 |         "        for row in data_split.select(range(start, end))\n",
148 |         "    ]\n",
149 |         "\n",
150 |         "# Load the dataset\n",
151 |         "dataset = load_conll_dataset()\n",
152 |         "\n",
153 |         "# Prepare the training and test sets\n",
154 |         "train_set = prepare_dataset(dataset[\"train\"], 0, 50)\n",
155 |         "test_set = prepare_dataset(dataset[\"test\"], 0, 200)"
156 |       ]
157 |     },
158 |     {
159 |       "cell_type": "markdown",
160 |       "metadata": {},
161 |       "source": [
162 |         "## Configure DSPy and create an Entity Extraction Program\n",
163 |         "\n",
164 |         "Here, we define a DSPy program for extracting entities referring to people from tokenized text.\n",
165 |         "\n",
166 |         "Then, we configure DSPy to use a particular language model (`gpt-4o-mini`) for all invocations of the program.\n",
167 |         "\n",
168 |         "**Key DSPy Concepts Introduced:**\n",
169 |         "- **Signatures:** Define structured input/output schemas for your program.\n",
170 |         "- **Modules:** Encapsulate program logic in reusable, composable units.\n",
171 |         "\n",
172 |         "Specifically, we'll:\n",
173 |         "- Create a `PeopleExtraction` DSPy Signature to specify the input (`tokens`) and output (`extracted_people`) fields.\n",
174 |         "- Define a `people_extractor` program that uses DSPy's built-in `dspy.ChainOfThought` module to implement the `PeopleExtraction` signature. The program extracts entities referring to people from a list of input tokens using language model (LM) prompting.\n",
175 |         "- Use the `dspy.LM` class and `dspy.settings.configure()` method to configure the language model that DSPy will use when invoking the program."
176 |       ]
177 |     },
178 |     {
179 |       "cell_type": "code",
180 |       "execution_count": 3,
181 |       "metadata": {},
182 |       "outputs": [],
183 |       "source": [
184 |         "from typing import List\n",
185 |         "\n",
186 |         "class PeopleExtraction(dspy.Signature):\n",
187 |         "    \"\"\"\n",
188 |         "    Extract contiguous tokens referring to specific people, if any, from a list of string tokens.\n",
189 |         "    Output a list of tokens. In other words, do not combine multiple tokens into a single value.\n",
190 |         "    \"\"\"\n",
191 |         "    tokens: list[str] = dspy.InputField(desc=\"tokenized text\")\n",
192 |         "    extracted_people: list[str] = dspy.OutputField(desc=\"all tokens referring to specific people extracted from the tokenized text\")\n",
193 |         "\n",
194 |         "people_extractor = dspy.ChainOfThought(PeopleExtraction)"
195 |       ]
196 |     },
197 |     {
198 |       "cell_type": "markdown",
199 |       "metadata": {},
200 |       "source": [
201 |         "Here, we tell DSPy to use OpenAI's `gpt-4o-mini` model in our program. To authenticate, DSPy reads your `OPENAI_API_KEY`. You can easily swap this out for [other providers or local models](https://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb)."
202 |       ]
203 |     },
204 |     {
205 |       "cell_type": "code",
206 |       "execution_count": 4,
207 |       "metadata": {},
208 |       "outputs": [],
209 |       "source": [
210 |         "lm = dspy.LM(model=\"openai/gpt-4o-mini\")\n",
211 |         "dspy.settings.configure(lm=lm)"
212 |       ]
213 |     },
214 |     {
215 |       "cell_type": "markdown",
216 |       "metadata": {},
217 |       "source": [
218 |         "## Define Metric and Evaluation Functions\n",
219 |         "\n",
220 |         "In DSPy, evaluating a program's performance is critical for iterative development. A good evaluation framework allows us to:\n",
221 |         "- Measure the quality of our program's outputs.\n",
222 |         "- Compare outputs against ground-truth labels.\n",
223 |         "- Identify areas for improvement.\n",
224 |         "\n",
225 |         "**What We'll Do:**\n",
226 |         "- Define a custom metric (`extraction_correctness_metric`) to evaluate whether the extracted entities match the ground truth.\n",
227 |         "- Create an evaluation function (`evaluate_correctness`) to apply this metric to a training or test dataset and compute the overall accuracy.\n",
228 |         "\n",
229 |         "The evaluation function uses DSPy's `Evaluate` utility to handle parallelism and visualization of results."
230 |       ]
231 |     },
232 |     {
233 |       "cell_type": "code",
234 |       "execution_count": 5,
235 |       "metadata": {},
236 |       "outputs": [],
237 |       "source": [
238 |         "def extraction_correctness_metric(example: dspy.Example, prediction: dspy.Prediction, trace=None) -> bool:\n",
239 |         "    \"\"\"\n",
240 |         "    Computes correctness of entity extraction predictions.\n",
241 |         "    \n",
242 |         "    Args:\n",
243 |         "        example (dspy.Example): The dataset example containing expected people entities.\n",
244 |         "        prediction (dspy.Prediction): The prediction from the DSPy people extraction program.\n",
245 |         "        trace: Optional trace object for debugging.\n",
246 |         "    \n",
247 |         "    Returns:\n",
248 |         "        bool: True if predictions match expectations, False otherwise.\n",
249 |         "    \"\"\"\n",
250 |         "    return prediction.extracted_people == example.expected_extracted_people\n",
251 |         "\n",
252 |         "evaluate_correctness = dspy.Evaluate(\n",
253 |         "    devset=test_set,\n",
254 |         "    metric=extraction_correctness_metric,\n",
255 |         "    num_threads=24,\n",
256 |         "    display_progress=True,\n",
257 |         "    display_table=True\n",
258 |         ")"
259 |       ]
260 |     },
261 |     {
262 |       "cell_type": "markdown",
263 |       "metadata": {},
264 |       "source": [
265 |         "## Evaluate Initial Extractor\n",
266 |         "\n",
267 |         "Before optimizing our program, we need a baseline evaluation to understand its current performance. This helps us:\n",
268 |         "- Establish a reference point for comparison after optimization.\n",
269 |         "- Identify potential weaknesses in the initial implementation.\n",
270 |         "\n",
271 |         "In this step, we'll run our `people_extractor` program on the test set and measure its accuracy using the evaluation framework defined earlier."
272 |       ]
273 |     },
274 |     {
275 |       "cell_type": "code",
276 |       "execution_count": 6,
277 |       "metadata": {},
278 |       "outputs": [
279 |         {
280 |           "name": "stdout",
281 |           "output_type": "stream",
282 |           "text": [
283 |             "Average Metric: 172.00 / 200 (86.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:16<00:00, 11.94it/s]"
284 |           ]
285 |         },
286 |         {
287 |           "name": "stderr",
288 |           "output_type": "stream",
289 |           "text": [
290 |             "2024/11/18 21:08:04 INFO dspy.evaluate.evaluate: Average Metric: 172 / 200 (86.0%)\n"
291 |           ]
292 |         },
293 |         {
294 |           "name": "stdout",
295 |           "output_type": "stream",
296 |           "text": [
297 |             "\n"
298 |           ]
299 |         },
300 |         {
301 |           "data": {
302 |             "text/html": [
303 |               "<div>\n",
304 |               "<style scoped>\n",
305 |               "    .dataframe tbody tr th:only-of-type {\n",
306 |               "        vertical-align: middle;\n",
307 |               "    }\n",
308 |               "\n",
309 |               "    .dataframe tbody tr th {\n",
310 |               "        vertical-align: top;\n",
311 |               "    }\n",
312 |               "\n",
313 |               "    .dataframe thead th {\n",
314 |               "        text-align: right;\n",
315 |               "    }\n",
316 |               "</style>\n",
317 |               "<table border=\"1\" class=\"dataframe\">\n",
318 |               "  <thead>\n",
319 |               "    <tr style=\"text-align: right;\">\n",
320 |               "      <th></th>\n",
321 |               "      <th>tokens</th>\n",
322 |               "      <th>expected_extracted_people</th>\n",
323 |               "      <th>rationale</th>\n",
324 |               "      <th>extracted_people</th>\n",
325 |               "      <th>extraction_correctness_metric</th>\n",
326 |               "    </tr>\n",
327 |               "  </thead>\n",
328 |               "  <tbody>\n",
329 |               "    <tr>\n",
330 |               "      <th>0</th>\n",
331 |               "      <td>[SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...</td>\n",
332 |               "      <td>[CHINA]</td>\n",
333 |               "      <td>We extracted \"JAPAN\" and \"CHINA\" as they refer to specific countri...</td>\n",
334 |               "      <td>[JAPAN, CHINA]</td>\n",
335 |               "      <td></td>\n",
336 |               "    </tr>\n",
337 |               "    <tr>\n",
338 |               "      <th>1</th>\n",
339 |               "      <td>[Nadim, Ladki]</td>\n",
340 |               "      <td>[Nadim, Ladki]</td>\n",
341 |               "      <td>We extracted the tokens \"Nadim\" and \"Ladki\" as they refer to speci...</td>\n",
342 |               "      <td>[Nadim, Ladki]</td>\n",
343 |               "      <td>✔️ [True]</td>\n",
344 |               "    </tr>\n",
345 |               "    <tr>\n",
346 |               "      <th>2</th>\n",
347 |               "      <td>[AL-AIN, ,, United, Arab, Emirates, 1996-12-06]</td>\n",
348 |               "      <td>[]</td>\n",
349 |               "      <td>There are no tokens referring to specific people in the provided l...</td>\n",
350 |               "      <td>[]</td>\n",
351 |               "      <td>✔️ [True]</td>\n",
352 |               "    </tr>\n",
353 |               "    <tr>\n",
354 |               "      <th>3</th>\n",
355 |               "      <td>[Japan, began, the, defence, of, their, Asian, Cup, title, with, a...</td>\n",
356 |               "      <td>[]</td>\n",
357 |               "      <td>We did not find any tokens referring to specific people in the pro...</td>\n",
358 |               "      <td>[]</td>\n",
359 |               "      <td>✔️ [True]</td>\n",
360 |               "    </tr>\n",
361 |               "    <tr>\n",
362 |               "      <th>4</th>\n",
363 |               "      <td>[But, China, saw, their, luck, desert, them, in, the, second, matc...</td>\n",
364 |               "      <td>[]</td>\n",
365 |               "      <td>The extracted tokens referring to specific people are \"China\" and ...</td>\n",
366 |               "      <td>[China, Uzbekistan]</td>\n",
367 |               "      <td></td>\n",
368 |               "    </tr>\n",
369 |               "    <tr>\n",
370 |               "      <th>...</th>\n",
371 |               "      <td>...</td>\n",
372 |               "      <td>...</td>\n",
373 |               "      <td>...</td>\n",
374 |               "      <td>...</td>\n",
375 |               "      <td>...</td>\n",
376 |               "    </tr>\n",
377 |               "    <tr>\n",
378 |               "      <th>195</th>\n",
379 |               "      <td>['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...</td>\n",
380 |               "      <td>[David, Campese]</td>\n",
381 |               "      <td>The extracted_people includes \"David Campese\" as it refers to a sp...</td>\n",
382 |               "      <td>[David, Campese]</td>\n",
383 |               "      <td>✔️ [True]</td>\n",
384 |               "    </tr>\n",
385 |               "    <tr>\n",
386 |               "      <th>196</th>\n",
387 |               "      <td>['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...</td>\n",
388 |               "      <td>[]</td>\n",
389 |               "      <td>The extracted_people includes \"Wallabies\" as it refers to a specif...</td>\n",
390 |               "      <td>[]</td>\n",
391 |               "      <td>✔️ [True]</td>\n",
392 |               "    </tr>\n",
393 |               "    <tr>\n",
394 |               "      <th>197</th>\n",
395 |               "      <td>['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...</td>\n",
396 |               "      <td>[Campese, Rob, Andrew]</td>\n",
397 |               "      <td>The extracted tokens refer to specific people mentioned in the tex...</td>\n",
398 |               "      <td>[Campese, Rob, Andrew]</td>\n",
399 |               "      <td>✔️ [True]</td>\n",
400 |               "    </tr>\n",
401 |               "    <tr>\n",
402 |               "      <th>198</th>\n",
403 |               "      <td>['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...</td>\n",
404 |               "      <td>[Campo, Andrew]</td>\n",
405 |               "      <td>The extracted tokens referring to specific people include \"Campo\" ...</td>\n",
406 |               "      <td>[Campo, Andrew]</td>\n",
407 |               "      <td>✔️ [True]</td>\n",
408 |               "    </tr>\n",
409 |               "    <tr>\n",
410 |               "      <th>199</th>\n",
411 |               "      <td>['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...</td>\n",
412 |               "      <td>[]</td>\n",
413 |               "      <td>We extracted the names of specific people from the tokenized text....</td>\n",
414 |               "      <td>[]</td>\n",
415 |               "      <td>✔️ [True]</td>\n",
416 |               "    </tr>\n",
417 |               "  </tbody>\n",
418 |               "</table>\n",
419 |               "<p>200 rows × 5 columns</p>\n",
420 |               "</div>"
421 |             ],
422 |             "text/plain": [
423 |               "                                                                    tokens  \\\n",
424 |               "0    [SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...   \n",
425 |               "1                                                           [Nadim, Ladki]   \n",
426 |               "2                          [AL-AIN, ,, United, Arab, Emirates, 1996-12-06]   \n",
427 |               "3    [Japan, began, the, defence, of, their, Asian, Cup, title, with, a...   \n",
428 |               "4    [But, China, saw, their, luck, desert, them, in, the, second, matc...   \n",
429 |               "..                                                                     ...   \n",
430 |               "195  ['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...   \n",
431 |               "196  ['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...   \n",
432 |               "197  ['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...   \n",
433 |               "198  ['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...   \n",
434 |               "199  ['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...   \n",
435 |               "\n",
436 |               "    expected_extracted_people  \\\n",
437 |               "0                     [CHINA]   \n",
438 |               "1              [Nadim, Ladki]   \n",
439 |               "2                          []   \n",
440 |               "3                          []   \n",
441 |               "4                          []   \n",
442 |               "..                        ...   \n",
443 |               "195          [David, Campese]   \n",
444 |               "196                        []   \n",
445 |               "197    [Campese, Rob, Andrew]   \n",
446 |               "198           [Campo, Andrew]   \n",
447 |               "199                        []   \n",
448 |               "\n",
449 |               "                                                                 rationale  \\\n",
450 |               "0    We extracted \"JAPAN\" and \"CHINA\" as they refer to specific countri...   \n",
451 |               "1    We extracted the tokens \"Nadim\" and \"Ladki\" as they refer to speci...   \n",
452 |               "2    There are no tokens referring to specific people in the provided l...   \n",
453 |               "3    We did not find any tokens referring to specific people in the pro...   \n",
454 |               "4    The extracted tokens referring to specific people are \"China\" and ...   \n",
455 |               "..                                                                     ...   \n",
456 |               "195  The extracted_people includes \"David Campese\" as it refers to a sp...   \n",
457 |               "196  The extracted_people includes \"Wallabies\" as it refers to a specif...   \n",
458 |               "197  The extracted tokens refer to specific people mentioned in the tex...   \n",
459 |               "198  The extracted tokens referring to specific people include \"Campo\" ...   \n",
460 |               "199  We extracted the names of specific people from the tokenized text....   \n",
461 |               "\n",
462 |               "           extracted_people extraction_correctness_metric  \n",
463 |               "0            [JAPAN, CHINA]                                \n",
464 |               "1            [Nadim, Ladki]                     ✔️ [True]  \n",
465 |               "2                        []                     ✔️ [True]  \n",
466 |               "3                        []                     ✔️ [True]  \n",
467 |               "4       [China, Uzbekistan]                                \n",
468 |               "..                      ...                           ...  \n",
469 |               "195        [David, Campese]                     ✔️ [True]  \n",
470 |               "196                      []                     ✔️ [True]  \n",
471 |               "197  [Campese, Rob, Andrew]                     ✔️ [True]  \n",
472 |               "198         [Campo, Andrew]                     ✔️ [True]  \n",
473 |               "199                      []                     ✔️ [True]  \n",
474 |               "\n",
475 |               "[200 rows x 5 columns]"
476 |             ]
477 |           },
478 |           "metadata": {},
479 |           "output_type": "display_data"
480 |         },
481 |         {
482 |           "data": {
483 |             "text/plain": [
484 |               "86.0"
485 |             ]
486 |           },
487 |           "execution_count": 6,
488 |           "metadata": {},
489 |           "output_type": "execute_result"
490 |         }
491 |       ],
492 |       "source": [
493 |         "evaluate_correctness(people_extractor, devset=test_set)"
494 |       ]
495 |     },
496 |     {
497 |       "cell_type": "markdown",
498 |       "metadata": {},
499 |       "source": [
500 |         "<details>\n",
501 |         "<summary>Tracking Evaluation Results in MLflow Experiment</summary>\n",
502 |         "\n",
503 |         "<br/>\n",
504 |         "\n",
505 |         "To track and visualize the evaluation results over time, you can record the results in MLflow Experiment.\n",
506 |         "\n",
507 |         "\n",
508 |         "```python\n",
509 |         "import mlflow\n",
510 |         "\n",
511 |         "with mlflow.start_run(run_name=\"extractor_evaluation\"):\n",
512 |         "    evaluate_correctness = dspy.Evaluate(\n",
513 |         "        devset=test_set,\n",
514 |         "        metric=extraction_correctness_metric,\n",
515 |         "        num_threads=24,\n",
516 |         "        display_progress=True,\n",
517 |         "    )\n",
518 |         "\n",
519 |         "    # Evaluate the program as usual\n",
520 |         "    result = evaluate_correctness(people_extractor)\n",
521 |         "\n",
522 |         "    # Log the aggregated score\n",
523 |         "    mlflow.log_metric(\"exact_match\", result.score)\n",
524 |         "    # Log the detailed evaluation results as a table\n",
525 |         "    mlflow.log_table(\n",
526 |         "        {\n",
527 |         "            \"Tokens\": [example.tokens for example in test_set],\n",
528 |         "            \"Expected\": [example.expected_extracted_people for example in test_set],\n",
529 |         "            \"Predicted\": [output[1] for output in result.results],\n",
530 |         "            \"Exact match\": [output[2] for output in result.results],\n",
531 |         "        },\n",
532 |         "        artifact_file=\"eval_results.json\",\n",
533 |         "    )\n",
534 |         "```\n",
535 |         "\n",
536 |         "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
537 |         "\n",
538 |         "</details>"
539 |       ]
540 |     },
541 |     {
542 |       "cell_type": "markdown",
543 |       "metadata": {},
544 |       "source": [
545 |         "## Optimize the Model\n",
546 |         "\n",
547 |         "DSPy includes powerful optimizers that can improve the quality of your system.\n",
548 |         "\n",
549 |         "Here, we use DSPy's `MIPROv2` optimizer to:\n",
550 |         "- Automatically tune the program's language model (LM) prompt by 1. using the LM to adjust the prompt's instructions and 2. building few-shot examples from the training dataset that are augmented with reasoning generated from `dspy.ChainOfThought`.\n",
551 |         "- Maximize correctness on the training set.\n",
552 |         "\n",
553 |         "This optimization process is automated, saving time and effort while improving accuracy."
554 |       ]
555 |     },
556 |     {
557 |       "cell_type": "code",
558 |       "execution_count": null,
559 |       "metadata": {},
560 |       "outputs": [],
561 |       "source": [
562 |         "mipro_optimizer = dspy.MIPROv2(\n",
563 |         "    metric=extraction_correctness_metric,\n",
564 |         "    auto=\"medium\",\n",
565 |         ")\n",
566 |         "optimized_people_extractor = mipro_optimizer.compile(\n",
567 |         "    people_extractor,\n",
568 |         "    trainset=train_set,\n",
569 |         "    max_bootstrapped_demos=4,\n",
570 |         "    minibatch=False\n",
571 |         ")"
572 |       ]
573 |     },
574 |     {
575 |       "cell_type": "markdown",
576 |       "metadata": {},
577 |       "source": [
578 |         "## Evaluate Optimized Program\n",
579 |         "\n",
580 |         "After optimization, we re-evaluate the program on the test set to measure improvements. Comparing the optimized and initial results allows us to:\n",
581 |         "- Quantify the benefits of optimization.\n",
582 |         "- Validate that the program generalizes well to unseen data.\n",
583 |         "\n",
584 |         "In this case, we see that accuracy of the program on the test dataset has improved significantly."
585 |       ]
586 |     },
587 |     {
588 |       "cell_type": "code",
589 |       "execution_count": 8,
590 |       "metadata": {},
591 |       "outputs": [
592 |         {
593 |           "name": "stdout",
594 |           "output_type": "stream",
595 |           "text": [
596 |             "Average Metric: 186.00 / 200 (93.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:23<00:00,  8.58it/s]"
597 |           ]
598 |         },
599 |         {
600 |           "name": "stderr",
601 |           "output_type": "stream",
602 |           "text": [
603 |             "2024/11/18 21:15:00 INFO dspy.evaluate.evaluate: Average Metric: 186 / 200 (93.0%)\n"
604 |           ]
605 |         },
606 |         {
607 |           "name": "stdout",
608 |           "output_type": "stream",
609 |           "text": [
610 |             "\n"
611 |           ]
612 |         },
613 |         {
614 |           "data": {
615 |             "text/html": [
616 |               "<div>\n",
617 |               "<style scoped>\n",
618 |               "    .dataframe tbody tr th:only-of-type {\n",
619 |               "        vertical-align: middle;\n",
620 |               "    }\n",
621 |               "\n",
622 |               "    .dataframe tbody tr th {\n",
623 |               "        vertical-align: top;\n",
624 |               "    }\n",
625 |               "\n",
626 |               "    .dataframe thead th {\n",
627 |               "        text-align: right;\n",
628 |               "    }\n",
629 |               "</style>\n",
630 |               "<table border=\"1\" class=\"dataframe\">\n",
631 |               "  <thead>\n",
632 |               "    <tr style=\"text-align: right;\">\n",
633 |               "      <th></th>\n",
634 |               "      <th>tokens</th>\n",
635 |               "      <th>expected_extracted_people</th>\n",
636 |               "      <th>rationale</th>\n",
637 |               "      <th>extracted_people</th>\n",
638 |               "      <th>extraction_correctness_metric</th>\n",
639 |               "    </tr>\n",
640 |               "  </thead>\n",
641 |               "  <tbody>\n",
642 |               "    <tr>\n",
643 |               "      <th>0</th>\n",
644 |               "      <td>[SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...</td>\n",
645 |               "      <td>[CHINA]</td>\n",
646 |               "      <td>There are no specific people mentioned in the provided tokens. The...</td>\n",
647 |               "      <td>[]</td>\n",
648 |               "      <td></td>\n",
649 |               "    </tr>\n",
650 |               "    <tr>\n",
651 |               "      <th>1</th>\n",
652 |               "      <td>[Nadim, Ladki]</td>\n",
653 |               "      <td>[Nadim, Ladki]</td>\n",
654 |               "      <td>The tokens \"Nadim Ladki\" refer to a specific individual. Both toke...</td>\n",
655 |               "      <td>[Nadim, Ladki]</td>\n",
656 |               "      <td>✔️ [True]</td>\n",
657 |               "    </tr>\n",
658 |               "    <tr>\n",
659 |               "      <th>2</th>\n",
660 |               "      <td>[AL-AIN, ,, United, Arab, Emirates, 1996-12-06]</td>\n",
661 |               "      <td>[]</td>\n",
662 |               "      <td>There are no tokens referring to specific people in the provided l...</td>\n",
663 |               "      <td>[]</td>\n",
664 |               "      <td>✔️ [True]</td>\n",
665 |               "    </tr>\n",
666 |               "    <tr>\n",
667 |               "      <th>3</th>\n",
668 |               "      <td>[Japan, began, the, defence, of, their, Asian, Cup, title, with, a...</td>\n",
669 |               "      <td>[]</td>\n",
670 |               "      <td>There are no specific people mentioned in the provided tokens. The...</td>\n",
671 |               "      <td>[]</td>\n",
672 |               "      <td>✔️ [True]</td>\n",
673 |               "    </tr>\n",
674 |               "    <tr>\n",
675 |               "      <th>4</th>\n",
676 |               "      <td>[But, China, saw, their, luck, desert, them, in, the, second, matc...</td>\n",
677 |               "      <td>[]</td>\n",
678 |               "      <td>There are no tokens referring to specific people in the provided l...</td>\n",
679 |               "      <td>[]</td>\n",
680 |               "      <td>✔️ [True]</td>\n",
681 |               "    </tr>\n",
682 |               "    <tr>\n",
683 |               "      <th>...</th>\n",
684 |               "      <td>...</td>\n",
685 |               "      <td>...</td>\n",
686 |               "      <td>...</td>\n",
687 |               "      <td>...</td>\n",
688 |               "      <td>...</td>\n",
689 |               "    </tr>\n",
690 |               "    <tr>\n",
691 |               "      <th>195</th>\n",
692 |               "      <td>['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...</td>\n",
693 |               "      <td>[David, Campese]</td>\n",
694 |               "      <td>The extracted tokens refer to a specific person mentioned in the t...</td>\n",
695 |               "      <td>[David, Campese]</td>\n",
696 |               "      <td>✔️ [True]</td>\n",
697 |               "    </tr>\n",
698 |               "    <tr>\n",
699 |               "      <th>196</th>\n",
700 |               "      <td>['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...</td>\n",
701 |               "      <td>[]</td>\n",
702 |               "      <td>There are no specific individuals mentioned in the provided tokens...</td>\n",
703 |               "      <td>[]</td>\n",
704 |               "      <td>✔️ [True]</td>\n",
705 |               "    </tr>\n",
706 |               "    <tr>\n",
707 |               "      <th>197</th>\n",
708 |               "      <td>['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...</td>\n",
709 |               "      <td>[Campese, Rob, Andrew]</td>\n",
710 |               "      <td>The tokens include the names \"Campese\" and \"Rob Andrew,\" both of w...</td>\n",
711 |               "      <td>[Campese, Rob, Andrew]</td>\n",
712 |               "      <td>✔️ [True]</td>\n",
713 |               "    </tr>\n",
714 |               "    <tr>\n",
715 |               "      <th>198</th>\n",
716 |               "      <td>['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...</td>\n",
717 |               "      <td>[Campo, Andrew]</td>\n",
718 |               "      <td>The extracted tokens refer to specific people mentioned in the tex...</td>\n",
719 |               "      <td>[Campo, Andrew]</td>\n",
720 |               "      <td>✔️ [True]</td>\n",
721 |               "    </tr>\n",
722 |               "    <tr>\n",
723 |               "      <th>199</th>\n",
724 |               "      <td>['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...</td>\n",
725 |               "      <td>[]</td>\n",
726 |               "      <td>There are no specific people mentioned in the provided tokens. The...</td>\n",
727 |               "      <td>[]</td>\n",
728 |               "      <td>✔️ [True]</td>\n",
729 |               "    </tr>\n",
730 |               "  </tbody>\n",
731 |               "</table>\n",
732 |               "<p>200 rows × 5 columns</p>\n",
733 |               "</div>"
734 |             ],
735 |             "text/plain": [
736 |               "                                                                    tokens  \\\n",
737 |               "0    [SOCCER, -, JAPAN, GET, LUCKY, WIN, ,, CHINA, IN, SURPRISE, DEFEAT...   \n",
738 |               "1                                                           [Nadim, Ladki]   \n",
739 |               "2                          [AL-AIN, ,, United, Arab, Emirates, 1996-12-06]   \n",
740 |               "3    [Japan, began, the, defence, of, their, Asian, Cup, title, with, a...   \n",
741 |               "4    [But, China, saw, their, luck, desert, them, in, the, second, matc...   \n",
742 |               "..                                                                     ...   \n",
743 |               "195  ['The', 'Wallabies', 'have', 'their', 'sights', 'set', 'on', 'a', ...   \n",
744 |               "196  ['The', 'Wallabies', 'currently', 'have', 'no', 'plans', 'to', 'ma...   \n",
745 |               "197  ['Campese', 'will', 'be', 'up', 'against', 'a', 'familiar', 'foe',...   \n",
746 |               "198  ['\"', 'Campo', 'has', 'a', 'massive', 'following', 'in', 'this', '...   \n",
747 |               "199  ['On', 'tour', ',', 'Australia', 'have', 'won', 'all', 'four', 'te...   \n",
748 |               "\n",
749 |               "    expected_extracted_people  \\\n",
750 |               "0                     [CHINA]   \n",
751 |               "1              [Nadim, Ladki]   \n",
752 |               "2                          []   \n",
753 |               "3                          []   \n",
754 |               "4                          []   \n",
755 |               "..                        ...   \n",
756 |               "195          [David, Campese]   \n",
757 |               "196                        []   \n",
758 |               "197    [Campese, Rob, Andrew]   \n",
759 |               "198           [Campo, Andrew]   \n",
760 |               "199                        []   \n",
761 |               "\n",
762 |               "                                                                 rationale  \\\n",
763 |               "0    There are no specific people mentioned in the provided tokens. The...   \n",
764 |               "1    The tokens \"Nadim Ladki\" refer to a specific individual. Both toke...   \n",
765 |               "2    There are no tokens referring to specific people in the provided l...   \n",
766 |               "3    There are no specific people mentioned in the provided tokens. The...   \n",
767 |               "4    There are no tokens referring to specific people in the provided l...   \n",
768 |               "..                                                                     ...   \n",
769 |               "195  The extracted tokens refer to a specific person mentioned in the t...   \n",
770 |               "196  There are no specific individuals mentioned in the provided tokens...   \n",
771 |               "197  The tokens include the names \"Campese\" and \"Rob Andrew,\" both of w...   \n",
772 |               "198  The extracted tokens refer to specific people mentioned in the tex...   \n",
773 |               "199  There are no specific people mentioned in the provided tokens. The...   \n",
774 |               "\n",
775 |               "           extracted_people extraction_correctness_metric  \n",
776 |               "0                        []                                \n",
777 |               "1            [Nadim, Ladki]                     ✔️ [True]  \n",
778 |               "2                        []                     ✔️ [True]  \n",
779 |               "3                        []                     ✔️ [True]  \n",
780 |               "4                        []                     ✔️ [True]  \n",
781 |               "..                      ...                           ...  \n",
782 |               "195        [David, Campese]                     ✔️ [True]  \n",
783 |               "196                      []                     ✔️ [True]  \n",
784 |               "197  [Campese, Rob, Andrew]                     ✔️ [True]  \n",
785 |               "198         [Campo, Andrew]                     ✔️ [True]  \n",
786 |               "199                      []                     ✔️ [True]  \n",
787 |               "\n",
788 |               "[200 rows x 5 columns]"
789 |             ]
790 |           },
791 |           "metadata": {},
792 |           "output_type": "display_data"
793 |         },
794 |         {
795 |           "data": {
796 |             "text/plain": [
797 |               "93.0"
798 |             ]
799 |           },
800 |           "execution_count": 8,
801 |           "metadata": {},
802 |           "output_type": "execute_result"
803 |         }
804 |       ],
805 |       "source": [
806 |         "evaluate_correctness(optimized_people_extractor, devset=test_set)"
807 |       ]
808 |     },
809 |     {
810 |       "cell_type": "markdown",
811 |       "metadata": {},
812 |       "source": [
813 |         "## Inspect Optimized Program's Prompt\n",
814 |         "\n",
815 |         "After optimizing the program, we can inspect the history of interactions to see how DSPy has augmented the program's prompt with few-shot examples. This step demonstrates:\n",
816 |         "- The structure of the prompt used by the program.\n",
817 |         "- How few-shot examples are added to guide the model's behavior.\n",
818 |         "\n",
819 |         "Use `inspect_history(n=1)` to view the last interaction and analyze the generated prompt."
820 |       ]
821 |     },
822 |     {
823 |       "cell_type": "code",
824 |       "execution_count": 9,
825 |       "metadata": {},
826 |       "outputs": [
827 |         {
828 |           "name": "stdout",
829 |           "output_type": "stream",
830 |           "text": [
831 |             "\n",
832 |             "\n",
833 |             "\n",
834 |             "\n",
835 |             "\u001b[34m[2024-11-18T21:15:00.584497]\u001b[0m\n",
836 |             "\n",
837 |             "\u001b[31mSystem message:\u001b[0m\n",
838 |             "\n",
839 |             "Your input fields are:\n",
840 |             "1. `tokens` (list[str]): tokenized text\n",
841 |             "\n",
842 |             "Your output fields are:\n",
843 |             "1. `rationale` (str): ${produce the extracted_people}. We ...\n",
844 |             "2. `extracted_people` (list[str]): all tokens referring to specific people extracted from the tokenized text\n",
845 |             "\n",
846 |             "All interactions will be structured in the following way, with the appropriate values filled in.\n",
847 |             "\n",
848 |             "[[ ## tokens ## ]]\n",
849 |             "{tokens}\n",
850 |             "\n",
851 |             "[[ ## rationale ## ]]\n",
852 |             "{rationale}\n",
853 |             "\n",
854 |             "[[ ## extracted_people ## ]]\n",
855 |             "{extracted_people}        # note: the value you produce must be pareseable according to the following JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
856 |             "\n",
857 |             "[[ ## completed ## ]]\n",
858 |             "\n",
859 |             "In adhering to this structure, your objective is: \n",
860 |             "        In a high-stakes situation where accurate identification of individuals is critical for regulatory compliance and public health communication, extract contiguous tokens referring to specific people from the provided list of string tokens. Ensure that you output each identified individual as separate tokens without combining multiple tokens into a single value. This task is essential for ensuring clarity and accountability in communications pertaining to EU regulations and health matters.\n",
861 |             "\n",
862 |             "\n",
863 |             "\u001b[31mUser message:\u001b[0m\n",
864 |             "\n",
865 |             "[[ ## tokens ## ]]\n",
866 |             "[\"He\", \"said\", \"further\", \"scientific\", \"study\", \"was\", \"required\", \"and\", \"if\", \"it\", \"was\", \"found\", \"that\", \"action\", \"was\", \"needed\", \"it\", \"should\", \"be\", \"taken\", \"by\", \"the\", \"European\", \"Union\", \".\"]\n",
867 |             "\n",
868 |             "Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
869 |             "\n",
870 |             "\n",
871 |             "\u001b[31mAssistant message:\u001b[0m\n",
872 |             "\n",
873 |             "[[ ## rationale ## ]]\n",
874 |             "There are no specific people mentioned in the provided tokens. The only reference is to the \"European Union,\" which is an organization rather than a specific person. We therefore conclude that there are no extracted people.\n",
875 |             "\n",
876 |             "[[ ## extracted_people ## ]]\n",
877 |             "[]\n",
878 |             "\n",
879 |             "[[ ## completed ## ]]\n",
880 |             "\n",
881 |             "\n",
882 |             "\u001b[31mUser message:\u001b[0m\n",
883 |             "\n",
884 |             "[[ ## tokens ## ]]\n",
885 |             "[\"BRUSSELS\", \"1996-08-22\"]\n",
886 |             "\n",
887 |             "Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
888 |             "\n",
889 |             "\n",
890 |             "\u001b[31mAssistant message:\u001b[0m\n",
891 |             "\n",
892 |             "[[ ## rationale ## ]]\n",
893 |             "There are no tokens referring to specific people in the provided list. We only have a location and a date.\n",
894 |             "\n",
895 |             "[[ ## extracted_people ## ]]\n",
896 |             "[]\n",
897 |             "\n",
898 |             "[[ ## completed ## ]]\n",
899 |             "\n",
900 |             "\n",
901 |             "\u001b[31mUser message:\u001b[0m\n",
902 |             "\n",
903 |             "[[ ## tokens ## ]]\n",
904 |             "[\"Fischler\", \"proposed\", \"EU-wide\", \"measures\", \"after\", \"reports\", \"from\", \"Britain\", \"and\", \"France\", \"that\", \"under\", \"laboratory\", \"conditions\", \"sheep\", \"could\", \"contract\", \"Bovine\", \"Spongiform\", \"Encephalopathy\", \"(\", \"BSE\", \")\", \"--\", \"mad\", \"cow\", \"disease\", \".\"]\n",
905 |             "\n",
906 |             "Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
907 |             "\n",
908 |             "\n",
909 |             "\u001b[31mAssistant message:\u001b[0m\n",
910 |             "\n",
911 |             "[[ ## rationale ## ]]\n",
912 |             "The extracted tokens refer to specific people mentioned in the text. In this case, \"Fischler\" is the only token that refers to a specific person. We extract this token as it is contiguous and represents an individual involved in the proposed measures.\n",
913 |             "\n",
914 |             "[[ ## extracted_people ## ]]\n",
915 |             "[\"Fischler\"]\n",
916 |             "\n",
917 |             "[[ ## completed ## ]]\n",
918 |             "\n",
919 |             "\n",
920 |             "\u001b[31mUser message:\u001b[0m\n",
921 |             "\n",
922 |             "[[ ## tokens ## ]]\n",
923 |             "[\"Germany\", \"'s\", \"representative\", \"to\", \"the\", \"European\", \"Union\", \"'s\", \"veterinary\", \"committee\", \"Werner\", \"Zwingmann\", \"said\", \"on\", \"Wednesday\", \"consumers\", \"should\", \"buy\", \"sheepmeat\", \"from\", \"countries\", \"other\", \"than\", \"Britain\", \"until\", \"the\", \"scientific\", \"advice\", \"was\", \"clearer\", \".\"]\n",
924 |             "\n",
925 |             "Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
926 |             "\n",
927 |             "\n",
928 |             "\u001b[31mAssistant message:\u001b[0m\n",
929 |             "\n",
930 |             "[[ ## rationale ## ]]\n",
931 |             "We extracted the name \"Werner Zwingmann\" from the tokenized text as it refers to a specific person mentioned in the context of a statement regarding sheepmeat consumption.\n",
932 |             "\n",
933 |             "[[ ## extracted_people ## ]]\n",
934 |             "[\"Werner\", \"Zwingmann\"]\n",
935 |             "\n",
936 |             "[[ ## completed ## ]]\n",
937 |             "\n",
938 |             "\n",
939 |             "\u001b[31mUser message:\u001b[0m\n",
940 |             "\n",
941 |             "[[ ## tokens ## ]]\n",
942 |             "[\"LONDON\", \"1996-12-06\"]\n",
943 |             "\n",
944 |             "Respond with the corresponding output fields, starting with the field `[[ ## rationale ## ]]`, then `[[ ## extracted_people ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
945 |             "\n",
946 |             "\n",
947 |             "\u001b[31mResponse:\u001b[0m\n",
948 |             "\n",
949 |             "\u001b[32m[[ ## rationale ## ]]\n",
950 |             "There are no tokens referring to specific people in the provided list. The tokens only include a location and a date.\n",
951 |             "\n",
952 |             "[[ ## extracted_people ## ]]\n",
953 |             "[]\n",
954 |             "\n",
955 |             "[[ ## completed ## ]]\u001b[0m\n",
956 |             "\n",
957 |             "\n",
958 |             "\n",
959 |             "\n",
960 |             "\n"
961 |           ]
962 |         }
963 |       ],
964 |       "source": [
965 |         "dspy.inspect_history(n=1)"
966 |       ]
967 |     },
968 |     {
969 |       "cell_type": "markdown",
970 |       "metadata": {},
971 |       "source": [
972 |         "## Keeping an eye on cost\n",
973 |         "\n",
974 |         "DSPy allows you to track the cost of your programs. The following code demonstrates how to obtain the cost of all LM calls made by the DSPy extractor program so far."
975 |       ]
976 |     },
977 |     {
978 |       "cell_type": "code",
979 |       "execution_count": 10,
980 |       "metadata": {},
981 |       "outputs": [
982 |         {
983 |           "data": {
984 |             "text/plain": [
985 |               "0.26362742999999983"
986 |             ]
987 |           },
988 |           "execution_count": 10,
989 |           "metadata": {},
990 |           "output_type": "execute_result"
991 |         }
992 |       ],
993 |       "source": [
994 |         "cost = sum([x['cost'] for x in lm.history if x['cost'] is not None])  # cost in USD, as calculated by LiteLLM for certain providers\n",
995 |         "cost"
996 |       ]
997 |     },
998 |     {
999 |       "cell_type": "markdown",
1000 |       "metadata": {},
1001 |       "source": [
1002 |         "## Saving and Loading Optimized Programs\n",
1003 |         "\n",
1004 |         "DSPy supports saving and loading programs, enabling you to reuse optimized systems without the need to re-optimize from scratch. This feature is especially useful for deploying your programs in production environments or sharing them with collaborators.\n",
1005 |         "\n",
1006 |         "In this step, we'll save the optimized program to a file and demonstrate how to load it back for future use."
1007 |       ]
1008 |     },
1009 |     {
1010 |       "cell_type": "code",
1011 |       "execution_count": 11,
1012 |       "metadata": {},
1013 |       "outputs": [
1014 |         {
1015 |           "data": {
1016 |             "text/plain": [
1017 |               "['Marcello', 'Cuttitta']"
1018 |             ]
1019 |           },
1020 |           "execution_count": 11,
1021 |           "metadata": {},
1022 |           "output_type": "execute_result"
1023 |         }
1024 |       ],
1025 |       "source": [
1026 |         "optimized_people_extractor.save(\"optimized_extractor.json\")\n",
1027 |         "\n",
1028 |         "loaded_people_extractor = dspy.ChainOfThought(PeopleExtraction)\n",
1029 |         "loaded_people_extractor.load(\"optimized_extractor.json\")\n",
1030 |         "\n",
1031 |         "loaded_people_extractor(tokens=[\"Italy\", \"recalled\", \"Marcello\", \"Cuttitta\"]).extracted_people"
1032 |       ]
1033 |     },
1034 |     {
1035 |       "cell_type": "markdown",
1036 |       "metadata": {},
1037 |       "source": [
1038 |         "<details>\n",
1039 |         "<summary>Saving programs in MLflow Experiment</summary>\n",
1040 |         "\n",
1041 |         "<br/>\n",
1042 |         "\n",
1043 |         "Instead of saving the program to a local file, you can track it in MLflow for better reproducibility and collaboration.\n",
1044 |         "\n",
1045 |         "1. **Dependency Management**: MLflow automatically save the frozen environment metadata along with the program to ensure reproducibility.\n",
1046 |         "2. **Experiment Tracking**: With MLflow, you can track the program's performance and cost along with the program itself.\n",
1047 |         "3. **Collaboration**: You can share the program and results with your team members by sharing the MLflow experiment.\n",
1048 |         "\n",
1049 |         "To save the program in MLflow, run the following code:\n",
1050 |         "\n",
1051 |         "```python\n",
1052 |         "import mlflow\n",
1053 |         "\n",
1054 |         "# Start an MLflow Run and save the program\n",
1055 |         "with mlflow.start_run(run_name=\"optimized_extractor\"):\n",
1056 |         "    model_info = mlflow.dspy.log_model(\n",
1057 |         "        optimized_people_extractor,\n",
1058 |         "        artifact_path=\"model\", # Any name to save the program in MLflow\n",
1059 |         "    )\n",
1060 |         "\n",
1061 |         "# Load the program back from MLflow\n",
1062 |         "loaded = mlflow.dspy.load_model(model_info.model_uri)\n",
1063 |         "```\n",
1064 |         "\n",
1065 |         "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
1066 |         "\n",
1067 |         "</details>"
1068 |       ]
1069 |     },
1070 |     {
1071 |       "cell_type": "markdown",
1072 |       "metadata": {},
1073 |       "source": [
1074 |         "## Conclusion\n",
1075 |         "\n",
1076 |         "In this tutorial, we demonstrated how to:\n",
1077 |         "- Use DSPy to build a modular, interpretable system for entity extraction.\n",
1078 |         "- Evaluate and optimize the system using DSPy's built-in tools.\n",
1079 |         "\n",
1080 |         "By leveraging structured inputs and outputs, we ensured that the system was easy to understand and improve. The optimization process allowed us to quickly improve performance without manually crafting prompts or tweaking parameters.\n",
1081 |         "\n",
1082 |         "**Next Steps:**\n",
1083 |         "- Experiment with extraction of other entity types (e.g., locations or organizations).\n",
1084 |         "- Explore DSPy's other builtin modules like `ReAct` for more complex reasoning tasks.\n",
1085 |         "- Use the system in larger workflows, such as large scale document processing or summarization."
1086 |       ]
1087 |     }
1088 |   ],
1089 |   "metadata": {
1090 |     "kernelspec": {
1091 |       "display_name": "Python 3 (ipykernel)",
1092 |       "language": "python",
1093 |       "name": "python3"
1094 |     },
1095 |     "language_info": {
1096 |       "codemirror_mode": {
1097 |         "name": "ipython",
1098 |         "version": 3
1099 |       },
1100 |       "file_extension": ".py",
1101 |       "mimetype": "text/x-python",
1102 |       "name": "python",
1103 |       "nbconvert_exporter": "python",
1104 |       "pygments_lexer": "ipython3",
1105 |       "version": "3.10.12"
1106 |     }
1107 |   },
1108 |   "nbformat": 4,
1109 |   "nbformat_minor": 4
1110 | }
```

games/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: Fine-tuning Agents\n",
8 |     "\n",
9 |     "Let's walk through a quick example of optimizing the _language model weights_ (i.e., fine-tuning) inside a DSPy module that represents a ReAct agent playing a game with 50-step tasks.\n",
10 |     "\n",
11 |     "### Install dependencies and download data\n",
12 |     "\n",
13 |     "Install the latest DSPy via `pip install -U dspy` and follow along. This tutorial uses the AlfWorld dataset, which depends on DSPy 2.6.0.\n",
14 |     "\n",
15 |     "You will also need the following dependencies:\n",
16 |     "\n",
17 |     "```shell\n",
18 |     "> pip install -U alfworld==0.3.5 multiprocess\n",
19 |     "> alfworld-download\n",
20 |     "```"
21 |    ]
22 |   },
23 |   {
24 |    "cell_type": "markdown",
25 |    "metadata": {},
26 |    "source": [
27 |     "<details>\n",
28 |     "<summary>Recommended: Setup MLflow Tracing for learning what's happening under the hood</summary>\n",
29 |     "\n",
30 |     "### MLflow DSPy Integration\n",
31 |     "\n",
32 |     "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. In this tutorial, you can use MLflow to visualize prompts and optimization progress as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
33 |     "\n",
34 |     "![MLflow Trace](./mlflow-tracing-agent.png)\n",
35 |     "\n",
36 |     "1. Install MLflow\n",
37 |     "\n",
38 |     "```bash\n",
39 |     "%pip install mlflow>=2.20\n",
40 |     "```\n",
41 |     "\n",
42 |     "2. Start MLflow UI in a separate terminal\n",
43 |     "```bash\n",
44 |     "mlflow ui --port 5000\n",
45 |     "```\n",
46 |     "\n",
47 |     "3. Connect the notebook to MLflow\n",
48 |     "```python\n",
49 |     "import mlflow\n",
50 |     "\n",
51 |     "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
52 |     "mlflow.set_experiment(\"DSPy\")\n",
53 |     "```\n",
54 |     "\n",
55 |     "4. Enabling tracing.\n",
56 |     "```python\n",
57 |     "mlflow.dspy.autolog()\n",
58 |     "```\n",
59 |     "\n",
60 |     "\n",
61 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
62 |     "</details>"
63 |    ]
64 |   },
65 |   {
66 |    "cell_type": "markdown",
67 |    "metadata": {},
68 |    "source": [
69 |     "### Set up the language models\n",
70 |     "\n",
71 |     "Our goal is to allow `gpt-4o-mini` to play the AlfWorld household game proficiently, without tinkering with string prompts or example trajectories by hand.\n",
72 |     "\n",
73 |     "Though it's not strictly necessary, we'll make our job a little easier by using the larger `gpt-4o` for prompt optimization and fine-tuning, building our small `gpt-4o-mini` agent."
74 |    ]
75 |   },
76 |   {
77 |    "cell_type": "code",
78 |    "execution_count": 1,
79 |    "metadata": {},
80 |    "outputs": [],
81 |    "source": [
82 |     "import dspy\n",
83 |     "\n",
84 |     "gpt4o_mini = dspy.LM('gpt-4o-mini-2024-07-18')\n",
85 |     "gpt4o = dspy.LM('openai/gpt-4o')\n",
86 |     "dspy.configure(experimental=True)"
87 |    ]
88 |   },
89 |   {
90 |    "cell_type": "markdown",
91 |    "metadata": {},
92 |    "source": [
93 |     "Let's load 200 training and 200 development tasks from AlfWorld. The dataset is much larger, but a small number of examples will help keep this tutorial run in 1-2 hours, including fine-tuning.\n",
94 |     "\n",
95 |     "With just 100 training tasks, we'll teach 4o-mini to go from 19% (can barely play the game) to 72%. If you use 500 tasks and retain the demonstrations during fine-tuning, you can push that easily to 82%."
96 |    ]
97 |   },
98 |   {
99 |    "cell_type": "code",
100 |    "execution_count": 2,
101 |    "metadata": {},
102 |    "outputs": [
103 |     {
104 |      "data": {
105 |       "text/plain": [
106 |        "(200, 200)"
107 |       ]
108 |      },
109 |      "execution_count": 2,
110 |      "metadata": {},
111 |      "output_type": "execute_result"
112 |     }
113 |    ],
114 |    "source": [
115 |     "from dspy.datasets.alfworld import AlfWorld\n",
116 |     "\n",
117 |     "alfworld = AlfWorld()\n",
118 |     "trainset, devset = alfworld.trainset[:200], alfworld.devset[-200:]\n",
119 |     "len(trainset), len(devset)"
120 |    ]
121 |   },
122 |   {
123 |    "cell_type": "markdown",
124 |    "metadata": {},
125 |    "source": [
126 |     "Before we proceed, let's view an example of this task."
127 |    ]
128 |   },
129 |   {
130 |    "cell_type": "code",
131 |    "execution_count": 3,
132 |    "metadata": {},
133 |    "outputs": [
134 |     {
135 |      "name": "stdout",
136 |      "output_type": "stream",
137 |      "text": [
138 |       "-= Welcome to TextWorld, ALFRED! =-\n",
139 |       "\n",
140 |       "You are in the middle of a room. Looking quickly around you, you see a countertop 1, a drawer 8, a drawer 7, a drawer 6, a drawer 5, a drawer 4, a drawer 3, a drawer 2, a drawer 1, a garbagecan 1, a handtowelholder 1, a sinkbasin 2, a sinkbasin 1, a toilet 1, a toiletpaperhanger 1, and a towelholder 1.\n",
141 |       "\n",
142 |       "Your task is to: put a clean soapbar in garbagecan.\n"
143 |      ]
144 |     }
145 |    ],
146 |    "source": [
147 |     "example = trainset[0]\n",
148 |     "\n",
149 |     "with alfworld.POOL.session() as env:\n",
150 |     "    task, info = env.init(**example.inputs())\n",
151 |     "\n",
152 |     "print(task)"
153 |    ]
154 |   },
155 |   {
156 |    "cell_type": "markdown",
157 |    "metadata": {},
158 |    "source": [
159 |     "### Defining the Agent program\n",
160 |     "\n",
161 |     "The agent is a pretty simple `dspy.Module` with one sub-module called `self.react`.\n",
162 |     "\n",
163 |     "This sub-module consumes a definition of a specific `task`, sees its previous `trajectory`, and sees a list of\n",
164 |     "`possible_actions` it can take. It responds simply with the next action.\n",
165 |     "\n",
166 |     "In the `forward` method, we just initialize an environment for the given task `idx`. And we loop up to `self.max_iters`,\n",
167 |     "repeatedly invoking the `self.react` module to take the next action."
168 |    ]
169 |   },
170 |   {
171 |    "cell_type": "code",
172 |    "execution_count": 4,
173 |    "metadata": {},
174 |    "outputs": [],
175 |    "source": [
176 |     "class Agent(dspy.Module):\n",
177 |     "    def __init__(self, max_iters=50, verbose=False):\n",
178 |     "        self.max_iters = max_iters\n",
179 |     "        self.verbose = verbose\n",
180 |     "        self.react = dspy.Predict(\"task, trajectory, possible_actions: list[str] -> action\")\n",
181 |     "\n",
182 |     "    def forward(self, idx):\n",
183 |     "        with alfworld.POOL.session() as env:\n",
184 |     "            trajectory = []\n",
185 |     "            task, info = env.init(idx)\n",
186 |     "            if self.verbose:\n",
187 |     "                print(f\"Task: {task}\")\n",
188 |     "\n",
189 |     "            for _ in range(self.max_iters):\n",
190 |     "                trajectory_ = \"\\n\".join(trajectory)\n",
191 |     "                possible_actions = info[\"admissible_commands\"][0] + [\"think: ${...thoughts...}\"]\n",
192 |     "                prediction = self.react(task=task, trajectory=trajectory_, possible_actions=possible_actions)\n",
193 |     "                trajectory.append(f\"> {prediction.action}\")\n",
194 |     "\n",
195 |     "                if prediction.action.startswith(\"think:\"):\n",
196 |     "                    trajectory.append(\"OK.\")\n",
197 |     "                    continue\n",
198 |     "\n",
199 |     "                obs, reward, done, info = env.step(prediction.action)\n",
200 |     "                obs, reward, done = obs[0], reward[0], done[0]\n",
201 |     "                trajectory.append(obs)\n",
202 |     "\n",
203 |     "                if self.verbose:\n",
204 |     "                    print(\"\\n\".join(trajectory[-2:]))\n",
205 |     "\n",
206 |     "                if done:\n",
207 |     "                    break\n",
208 |     "\n",
209 |     "        assert reward == int(info[\"won\"][0]), (reward, info[\"won\"][0])\n",
210 |     "        return dspy.Prediction(trajectory=trajectory, success=reward)"
211 |    ]
212 |   },
213 |   {
214 |    "cell_type": "markdown",
215 |    "metadata": {},
216 |    "source": [
217 |     "#### Aside: If you wanted to include instructions for your agent...\n",
218 |     "\n",
219 |     "Above, we opted to keep the agent super simple, without even providing short instructions that describe the task.\n",
220 |     "\n",
221 |     "In principle, you can copy a short definition of the AlfWorld task (based on Yao et al., 2022) and use that as the\n",
222 |     "instruction for your agent. This is not inherently essential, but it helps illustrate the role that\n",
223 |     "instructions play in DSPy: they're not for coercing the model to exhibit a certain behavior, but they're there to\n",
224 |     "describe the fundamentals of the task in a straightforward, human-readable way.\n",
225 |     "\n",
226 |     "If you want to do that, you can simply replace this:\n",
227 |     "\n",
228 |     "```python\n",
229 |     "self.react = dspy.Predict(\"task, trajectory, possible_actions: list[str] -> action\")\n",
230 |     "```\n",
231 |     "\n",
232 |     "with this:\n",
233 |     "\n",
234 |     "```python\n",
235 |     "INSTRUCTIONS = \"\"\"\n",
236 |     "Interact with a simulated household to achieve a high-level goal. Make sure to plan, track subgoals,\n",
237 |     "determine likely locations for common household items (e.g. desklamps will likely be on desks, shelfs, or dressers),\n",
238 |     "and explore systematically (e.g. check all desks one by one for desklamp).\n",
239 |     "\"\"\".strip()\n",
240 |     "\n",
241 |     "self.react = dspy.Predict(dspy.Signature(\"task, trajectory, possible_actions: list[str] -> action\", INSTRUCTIONS))\n",
242 |     "```"
243 |    ]
244 |   },
245 |   {
246 |    "cell_type": "markdown",
247 |    "metadata": {},
248 |    "source": [
249 |     "### Zero-shot evaluation"
250 |    ]
251 |   },
252 |   {
253 |    "cell_type": "markdown",
254 |    "metadata": {},
255 |    "source": [
256 |     "Now, let's try this simple program, prior to any optimization work."
257 |    ]
258 |   },
259 |   {
260 |    "cell_type": "code",
261 |    "execution_count": 5,
262 |    "metadata": {},
263 |    "outputs": [
264 |     {
265 |      "name": "stdout",
266 |      "output_type": "stream",
267 |      "text": [
268 |       "Task: -= Welcome to TextWorld, ALFRED! =-\n",
269 |       "\n",
270 |       "You are in the middle of a room. Looking quickly around you, you see a countertop 1, a drawer 8, a drawer 7, a drawer 6, a drawer 5, a drawer 4, a drawer 3, a drawer 2, a drawer 1, a garbagecan 1, a handtowelholder 1, a sinkbasin 2, a sinkbasin 1, a toilet 1, a toiletpaperhanger 1, and a towelholder 1.\n",
271 |       "\n",
272 |       "Your task is to: put a clean soapbar in garbagecan.\n",
273 |       "> go to countertop 1\n",
274 |       "You arrive at countertop 1. On the countertop 1, you see a candle 1, a soapbar 1, a soapbottle 2, a soapbottle 1, and a spraybottle 1.\n",
275 |       "> take soapbar 1 from countertop 1\n",
276 |       "You pick up the soapbar 1 from the countertop 1.\n",
277 |       "> go to garbagecan 1\n",
278 |       "You arrive at garbagecan 1. On the garbagecan 1, you see nothing.\n",
279 |       "> move soapbar 1 to garbagecan 1\n",
280 |       "You move the soapbar 1 to the garbagecan 1.\n",
281 |       "> examine garbagecan 1\n",
282 |       "On the garbagecan 1, you see a soapbar 1.\n",
283 |       "> examine garbagecan 1\n",
284 |       "On the garbagecan 1, you see a soapbar 1.\n",
285 |       "> examine garbagecan 1\n",
286 |       "On the garbagecan 1, you see a soapbar 1.\n",
287 |       "> examine garbagecan 1\n",
288 |       "On the garbagecan 1, you see a soapbar 1.\n",
289 |       "> look\n",
290 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
291 |       "> look\n",
292 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
293 |       "> look\n",
294 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
295 |       "> take soapbar 1 from garbagecan 1\n",
296 |       "You pick up the soapbar 1 from the garbagecan 1.\n",
297 |       "> move soapbar 1 to garbagecan 1\n",
298 |       "You move the soapbar 1 to the garbagecan 1.\n",
299 |       "> examine garbagecan 1\n",
300 |       "On the garbagecan 1, you see a soapbar 1.\n",
301 |       "> examine garbagecan 1\n",
302 |       "On the garbagecan 1, you see a soapbar 1.\n",
303 |       "> examine garbagecan 1\n",
304 |       "On the garbagecan 1, you see a soapbar 1.\n",
305 |       "> examine garbagecan 1\n",
306 |       "On the garbagecan 1, you see a soapbar 1.\n",
307 |       "> examine garbagecan 1\n",
308 |       "On the garbagecan 1, you see a soapbar 1.\n",
309 |       "> look\n",
310 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
311 |       "> look\n",
312 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
313 |       "> look\n",
314 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
315 |       "> look\n",
316 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
317 |       "> examine garbagecan 1\n",
318 |       "On the garbagecan 1, you see a soapbar 1.\n",
319 |       "> look\n",
320 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
321 |       "> look\n",
322 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
323 |       "> look\n",
324 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
325 |       "> look\n",
326 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
327 |       "> look\n",
328 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
329 |       "> examine garbagecan 1\n",
330 |       "On the garbagecan 1, you see a soapbar 1.\n",
331 |       "> look\n",
332 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
333 |       "> look\n",
334 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
335 |       "> look\n",
336 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
337 |       "> look\n",
338 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
339 |       "> look\n",
340 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
341 |       "> look\n",
342 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
343 |       "> look\n",
344 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
345 |       "> look\n",
346 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
347 |       "> look\n",
348 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
349 |       "> look\n",
350 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
351 |       "> look\n",
352 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
353 |       "> look\n",
354 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
355 |       "> look\n",
356 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
357 |       "> look\n",
358 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
359 |       "> look\n",
360 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
361 |       "> look\n",
362 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
363 |       "> look\n",
364 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
365 |       "> look\n",
366 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
367 |       "> look\n",
368 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n",
369 |       "> examine garbagecan 1\n",
370 |       "On the garbagecan 1, you see a soapbar 1.\n",
371 |       "> look\n",
372 |       "You are facing the garbagecan 1. Next to it, you see nothing.\n"
373 |      ]
374 |     },
375 |     {
376 |      "data": {
377 |       "text/plain": [
378 |        "Prediction(\n",
379 |        "    trajectory=['> go to countertop 1', 'You arrive at countertop 1. On the countertop 1, you see a candle 1, a soapbar 1, a soapbottle 2, a soapbottle 1, and a spraybottle 1.', '> take soapbar 1 from countertop 1', 'You pick up the soapbar 1 from the countertop 1.', '> go to garbagecan 1', 'You arrive at garbagecan 1. On the garbagecan 1, you see nothing.', '> move soapbar 1 to garbagecan 1', 'You move the soapbar 1 to the garbagecan 1.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> take soapbar 1 from garbagecan 1', 'You pick up the soapbar 1 from the garbagecan 1.', '> move soapbar 1 to garbagecan 1', 'You move the soapbar 1 to the garbagecan 1.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.', '> examine garbagecan 1', 'On the garbagecan 1, you see a soapbar 1.', '> look', 'You are facing the garbagecan 1. Next to it, you see nothing.'],\n",
380 |        "    success=0\n",
381 |        ")"
382 |       ]
383 |      },
384 |      "execution_count": 5,
385 |      "metadata": {},
386 |      "output_type": "execute_result"
387 |     }
388 |    ],
389 |    "source": [
390 |     "agent_4o = Agent()\n",
391 |     "agent_4o.set_lm(gpt4o)\n",
392 |     "agent_4o.verbose = True\n",
393 |     "\n",
394 |     "agent_4o(**example.inputs())"
395 |    ]
396 |   },
397 |   {
398 |    "cell_type": "markdown",
399 |    "metadata": {},
400 |    "source": [
401 |     "Okay, in this case it couldn't solve this example! Now, let's check the average quality of 4o and 4o-mini."
402 |    ]
403 |   },
404 |   {
405 |    "cell_type": "code",
406 |    "execution_count": 6,
407 |    "metadata": {},
408 |    "outputs": [],
409 |    "source": [
410 |     "metric = lambda x, y, trace=None: y.success\n",
411 |     "evaluate = dspy.Evaluate(devset=devset, metric=metric, display_progress=True, num_threads=16)"
412 |    ]
413 |   },
414 |   {
415 |    "cell_type": "markdown",
416 |    "metadata": {},
417 |    "source": [
418 |     "<details>\n",
419 |     "<summary>Tracking Evaluation Results in MLflow Experiment</summary>\n",
420 |     "\n",
421 |     "<br/>\n",
422 |     "\n",
423 |     "To track and visualize the evaluation results over time, you can record the results in MLflow Experiment.\n",
424 |     "\n",
425 |     "\n",
426 |     "```python\n",
427 |     "import mlflow\n",
428 |     "\n",
429 |     "with mlflow.start_run(run_name=\"agent_evaluation\"):\n",
430 |     "    evaluate = dspy.Evaluate(\n",
431 |     "        devset=devset,\n",
432 |     "        metric=metric,\n",
433 |     "        num_threads=16,\n",
434 |     "        display_progress=True,\n",
435 |     "        # To record the outputs and detailed scores to MLflow\n",
436 |     "        return_all_scores=True,\n",
437 |     "        return_outputs=True,\n",
438 |     "    )\n",
439 |     "\n",
440 |     "    # Evaluate the program as usual\n",
441 |     "    aggregated_score, outputs, all_scores = evaluate(cot)\n",
442 |     "\n",
443 |     "    # Log the aggregated score\n",
444 |     "    mlflow.log_metric(\"success_rate\", aggregated_score)\n",
445 |     "    # Log the detailed evaluation results as a table\n",
446 |     "    mlflow.log_table(\n",
447 |     "        {\n",
448 |     "            \"Idx\": [example.idx for example in eval_set],\n",
449 |     "            \"Result\": outputs,\n",
450 |     "            \"Success\": all_scores,\n",
451 |     "        },\n",
452 |     "        artifact_file=\"eval_results.json\",\n",
453 |     "    )\n",
454 |     "```\n",
455 |     "\n",
456 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
457 |     "\n",
458 |     "</details>"
459 |    ]
460 |   },
461 |   {
462 |    "cell_type": "code",
463 |    "execution_count": 7,
464 |    "metadata": {},
465 |    "outputs": [
466 |     {
467 |      "name": "stdout",
468 |      "output_type": "stream",
469 |      "text": [
470 |       "Average Metric: 115.00 / 200 (57.5%): 100%|██████████| 200/200 [06:14<00:00,  1.87s/it]"
471 |      ]
472 |     },
473 |     {
474 |      "name": "stderr",
475 |      "output_type": "stream",
476 |      "text": [
477 |       "2024/12/28 11:10:25 INFO dspy.evaluate.evaluate: Average Metric: 115 / 200 (57.5%)\n"
478 |      ]
479 |     },
480 |     {
481 |      "name": "stdout",
482 |      "output_type": "stream",
483 |      "text": [
484 |       "\n"
485 |      ]
486 |     },
487 |     {
488 |      "data": {
489 |       "text/plain": [
490 |        "57.5"
491 |       ]
492 |      },
493 |      "execution_count": 7,
494 |      "metadata": {},
495 |      "output_type": "execute_result"
496 |     }
497 |    ],
498 |    "source": [
499 |     "agent_4o.verbose = False\n",
500 |     "evaluate(agent_4o)"
501 |    ]
502 |   },
503 |   {
504 |    "cell_type": "code",
505 |    "execution_count": 8,
506 |    "metadata": {},
507 |    "outputs": [
508 |     {
509 |      "name": "stdout",
510 |      "output_type": "stream",
511 |      "text": [
512 |       "Average Metric: 30.00 / 200 (15.0%): 100%|██████████| 200/200 [08:33<00:00,  2.57s/it]"
513 |      ]
514 |     },
515 |     {
516 |      "name": "stderr",
517 |      "output_type": "stream",
518 |      "text": [
519 |       "2024/12/28 11:18:59 INFO dspy.evaluate.evaluate: Average Metric: 30 / 200 (15.0%)\n"
520 |      ]
521 |     },
522 |     {
523 |      "name": "stdout",
524 |      "output_type": "stream",
525 |      "text": [
526 |       "\n"
527 |      ]
528 |     },
529 |     {
530 |      "data": {
531 |       "text/plain": [
532 |        "15.0"
533 |       ]
534 |      },
535 |      "execution_count": 8,
536 |      "metadata": {},
537 |      "output_type": "execute_result"
538 |     }
539 |    ],
540 |    "source": [
541 |     "agent_4o_mini = Agent()\n",
542 |     "agent_4o_mini.set_lm(gpt4o_mini)\n",
543 |     "\n",
544 |     "evaluate(agent_4o_mini)"
545 |    ]
546 |   },
547 |   {
548 |    "cell_type": "markdown",
549 |    "metadata": {},
550 |    "source": [
551 |     "Out of the box, on this task, 4o is decent (58% success rate) while 4o-mini struggles (15% success rate).\n",
552 |     "\n",
553 |     "Let's apply the following strategy:\n",
554 |     "\n",
555 |     "1. We'll optimize the _prompts_ for gpt-4o in a lightweight way.\n",
556 |     "2. We'll then use this prompt-optimized agent as a teacher to fine-tune gpt-4o-mini on the task. This will increase its quality from 19% to 72% (or 82% if you use 500 trainset examples)."
557 |    ]
558 |   },
559 |   {
560 |    "cell_type": "markdown",
561 |    "metadata": {},
562 |    "source": [
563 |     "### Prompt-optimizing GPT-4o"
564 |    ]
565 |   },
566 |   {
567 |    "cell_type": "code",
568 |    "execution_count": 9,
569 |    "metadata": {},
570 |    "outputs": [],
571 |    "source": [
572 |     "optimizer = dspy.MIPROv2(metric=metric, auto=\"light\", num_threads=16, prompt_model=gpt4o)\n",
573 |     "\n",
574 |     "config = dict(max_bootstrapped_demos=1, max_labeled_demos=0, minibatch_size=40)\n",
575 |     "optimized_4o = optimizer.compile(agent_4o, trainset=trainset, **config)"
576 |    ]
577 |   },
578 |   {
579 |    "cell_type": "markdown",
580 |    "metadata": {},
581 |    "source": [
582 |     "### Fine-tuning GPT-4o-mini\n",
583 |     "\n",
584 |     "For fine-tuning, we'll need a teacher program (`optimized_4o` above) and a student program derived from it (`student_4om` below)."
585 |    ]
586 |   },
587 |   {
588 |    "cell_type": "code",
589 |    "execution_count": 10,
590 |    "metadata": {},
591 |    "outputs": [],
592 |    "source": [
593 |     "student_4o_mini = optimized_4o.deepcopy()\n",
594 |     "student_4o_mini.set_lm(gpt4o_mini)\n",
595 |     "# student_4o_mini.react.demos = []  # you can optionally reset the demos"
596 |    ]
597 |   },
598 |   {
599 |    "cell_type": "code",
600 |    "execution_count": 11,
601 |    "metadata": {},
602 |    "outputs": [],
603 |    "source": [
604 |     "optimizer = dspy.BootstrapFinetune(metric=metric, num_threads=16)\n",
605 |     "finetuned_4o_mini = optimizer.compile(student_4o_mini, teacher=optimized_4o, trainset=trainset)"
606 |    ]
607 |   },
608 |   {
609 |    "cell_type": "markdown",
610 |    "metadata": {},
611 |    "source": [
612 |     "### Evaluate the finetuned GPT-4o-mini agent"
613 |    ]
614 |   },
615 |   {
616 |    "cell_type": "code",
617 |    "execution_count": 12,
618 |    "metadata": {},
619 |    "outputs": [
620 |     {
621 |      "name": "stdout",
622 |      "output_type": "stream",
623 |      "text": [
624 |       "Average Metric: 143.00 / 200 (71.5%): 100%|██████████| 200/200 [03:15<00:00,  1.05it/s]"
625 |      ]
626 |     }
627 |    ],
628 |    "source": [
629 |     "evaluate(finetuned_4o_mini)"
630 |    ]
631 |   },
632 |   {
633 |    "cell_type": "markdown",
634 |    "metadata": {},
635 |    "source": [
636 |     "Having done all this optimization, let's save our program so we can use it later! This will keep a reference to the fine-tuned model as well, as long as it continued to exist with the same identifier at the provider side."
637 |    ]
638 |   },
639 |   {
640 |    "cell_type": "code",
641 |    "execution_count": 13,
642 |    "metadata": {},
643 |    "outputs": [],
644 |    "source": [
645 |     "finetuned_4o_mini.save('finetuned_4o_mini_001.pkl')"
646 |    ]
647 |   },
648 |   {
649 |    "cell_type": "markdown",
650 |    "metadata": {},
651 |    "source": [
652 |     "<details>\n",
653 |     "<summary>Saving programs in MLflow Experiment</summary>\n",
654 |     "\n",
655 |     "<br/>\n",
656 |     "\n",
657 |     "Instead of saving the program to a local file, you can track it in MLflow for better reproducibility and collaboration.\n",
658 |     "\n",
659 |     "1. **Dependency Management**: MLflow automatically save the frozen environment metadata along with the program to ensure reproducibility.\n",
660 |     "2. **Experiment Tracking**: With MLflow, you can track the program's performance and cost along with the program itself.\n",
661 |     "3. **Collaboration**: You can share the program and results with your team members by sharing the MLflow experiment.\n",
662 |     "\n",
663 |     "To save the program in MLflow, run the following code:\n",
664 |     "\n",
665 |     "```python\n",
666 |     "import mlflow\n",
667 |     "\n",
668 |     "# Start an MLflow Run and save the program\n",
669 |     "with mlflow.start_run(run_name=\"optimized\"):\n",
670 |     "    model_info = mlflow.dspy.log_model(\n",
671 |     "        finetuned_4o_mini,\n",
672 |     "        artifact_path=\"model\", # Any name to save the program in MLflow\n",
673 |     "    )\n",
674 |     "\n",
675 |     "# Load the program back from MLflow\n",
676 |     "loaded = mlflow.dspy.load_model(model_info.model_uri)\n",
677 |     "```\n",
678 |     "\n",
679 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
680 |     "\n",
681 |     "</details>"
682 |    ]
683 |   },
684 |   {
685 |    "cell_type": "markdown",
686 |    "metadata": {},
687 |    "source": [
688 |     "Let's now check out one task using our fine-tuned agent program!"
689 |    ]
690 |   },
691 |   {
692 |    "cell_type": "code",
693 |    "execution_count": 14,
694 |    "metadata": {},
695 |    "outputs": [
696 |     {
697 |      "name": "stdout",
698 |      "output_type": "stream",
699 |      "text": [
700 |       "Task: -= Welcome to TextWorld, ALFRED! =-\n",
701 |       "\n",
702 |       "You are in the middle of a room. Looking quickly around you, you see a armchair 1, a cabinet 1, a drawer 21, a drawer 20, a drawer 19, a drawer 18, a drawer 17, a drawer 16, a drawer 15, a drawer 14, a drawer 13, a drawer 12, a drawer 11, a drawer 10, a drawer 9, a drawer 8, a drawer 7, a drawer 6, a drawer 5, a drawer 4, a drawer 3, a drawer 2, a drawer 1, a dresser 1, a garbagecan 1, a sidetable 5, a sidetable 4, a sidetable 3, a sidetable 2, a sidetable 1, and a sofa 1.\n",
703 |       "\n",
704 |       "Your task is to: put some box on dresser.\n",
705 |       "> go to cabinet 1\n",
706 |       "You arrive at cabinet 1. On the cabinet 1, you see nothing.\n",
707 |       "> go to dresser 1\n",
708 |       "You arrive at dresser 1. On the dresser 1, you see a book 1, a newspaper 1, a remotecontrol 1, a statue 3, and a television 1.\n",
709 |       "> look\n",
710 |       "You are facing the dresser 1. Next to it, you see nothing.\n",
711 |       "> go to sidetable 1\n",
712 |       "You arrive at sidetable 1. On the sidetable 1, you see a cellphone 1, and a desklamp 1.\n",
713 |       "> go to sidetable 2\n",
714 |       "You arrive at sidetable 2. On the sidetable 2, you see a box 2.\n",
715 |       "> take box 2 from sidetable 2\n",
716 |       "You pick up the box 2 from the sidetable 2.\n",
717 |       "> go to dresser 1\n",
718 |       "You arrive at dresser 1. On the dresser 1, you see a book 1, a newspaper 1, a remotecontrol 1, a statue 3, and a television 1.\n",
719 |       "> move box 2 to dresser 1\n",
720 |       "You move the box 2 to the dresser 1.\n"
721 |      ]
722 |     },
723 |     {
724 |      "data": {
725 |       "text/plain": [
726 |        "Prediction(\n",
727 |        "    trajectory=['> go to cabinet 1', 'You arrive at cabinet 1. On the cabinet 1, you see nothing.', '> go to dresser 1', 'You arrive at dresser 1. On the dresser 1, you see a book 1, a newspaper 1, a remotecontrol 1, a statue 3, and a television 1.', '> look', 'You are facing the dresser 1. Next to it, you see nothing.', '> go to sidetable 1', 'You arrive at sidetable 1. On the sidetable 1, you see a cellphone 1, and a desklamp 1.', '> go to sidetable 2', 'You arrive at sidetable 2. On the sidetable 2, you see a box 2.', '> take box 2 from sidetable 2', 'You pick up the box 2 from the sidetable 2.', '> go to dresser 1', 'You arrive at dresser 1. On the dresser 1, you see a book 1, a newspaper 1, a remotecontrol 1, a statue 3, and a television 1.', '> move box 2 to dresser 1', 'You move the box 2 to the dresser 1.'],\n",
728 |        "    success=1\n",
729 |        ")"
730 |       ]
731 |      },
732 |      "execution_count": 15,
733 |      "metadata": {},
734 |      "output_type": "execute_result"
735 |     }
736 |    ],
737 |    "source": [
738 |     "finetuned_4o_mini.verbose = True\n",
739 |     "finetuned_4o_mini(**devset[0].inputs())"
740 |    ]
741 |   },
742 |   {
743 |    "cell_type": "markdown",
744 |    "metadata": {},
745 |    "source": [
746 |     "If you want to load and use the agent program, you can do that as follows."
747 |    ]
748 |   },
749 |   {
750 |    "cell_type": "code",
751 |    "execution_count": 16,
752 |    "metadata": {},
753 |    "outputs": [],
754 |    "source": [
755 |     "loaded = Agent()\n",
756 |     "loaded.load('finetuned_4o_mini_001.pkl')"
757 |    ]
758 |   }
759 |  ],
760 |  "metadata": {
761 |   "kernelspec": {
762 |    "display_name": "jun2024_py310",
763 |    "language": "python",
764 |    "name": "python3"
765 |   },
766 |   "language_info": {
767 |    "codemirror_mode": {
768 |     "name": "ipython",
769 |     "version": 3
770 |    },
771 |    "file_extension": ".py",
772 |    "mimetype": "text/x-python",
773 |    "name": "python",
774 |    "nbconvert_exporter": "python",
775 |    "pygments_lexer": "ipython3",
776 |    "version": "3.10.14"
777 |   }
778 |  },
779 |  "nbformat": 4,
780 |  "nbformat_minor": 2
781 | }
```

gepa_ai_program/index.md
```
1 | # Reflective Prompt Evolution with GEPA
2 |
3 | This section introduces GEPA, a reflective prompt optimizer for DSPy. GEPA works by leveraging LM's ability to reflect on the DSPy program's trajectory, identifying what went well, what didn't, and what can be improved. Based on this reflection, GEPA proposes new prompts, building a tree of evolved prompt candidates, accumulating improvements as the optimization progresses. Since GEPA can leverage domain-specific text feedback (as opposed to only the scalar metric), GEPA can often propose high performing prompts in very few rollouts. GEPA was introduced in the paper [GEPA: Reflective Prompt Evolution Can Outperform Reinforcement Learning](https://arxiv.org/abs/2507.19457) and available as `dspy.GEPA` which internally uses the GEPA implementation provided in [gepa-ai/gepa](https://github.com/gepa-ai/gepa).
4 |
5 | ## `dspy.GEPA` Tutorials
6 |
7 | ### [GEPA for AIME (Math)](../gepa_aime/index.ipynb)
8 |
9 | This tutorial explores how GEPA can optimize a single `dspy.ChainOfThought` based program to achieve 10% gains on AIME 2025 with GPT-4.1 Mini!
10 |
11 | ### [GEPA for Structured Information Extraction for Enterprise Tasks](../gepa_facilitysupportanalyzer/index.ipynb)
12 |
13 | This tutorial explores how GEPA leverages predictor-level feedback to improve GPT-4.1 Nano's performance on a three-part task for structured information extraction and classification in an enterprise setting.
14 |
15 | ### [GEPA for Privacy-Conscious Delegation](../gepa_papillon/index.ipynb)
16 |
17 | This tutorial explores how GEPA can improve rapidly in as few as 1 iteration, while leveraging a simple feedback provided by a LLM-as-a-judge metric. The tutorial also explores how GEPA benefits from the textual feedback showing a breakdown of aggregate metrics into sub-components, allowing the reflection LM to identify what aspects of the task need improvement.
```

gepa_aime/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "id": "23b9ab7f",
6 |    "metadata": {},
7 |    "source": [
8 |     "# Tutorial: GEPA for AIME (Math)\n",
9 |     "In this tutorial, we optimize GPT-4.1 Mini's Chain of Thought (`dspy.ChainOfThought`) for solving math problems (AIME) using the `dspy.GEPA` optimizer!"
10 |    ]
11 |   },
12 |   {
13 |    "cell_type": "markdown",
14 |    "id": "782f0cf1",
15 |    "metadata": {},
16 |    "source": [
17 |     "<details>\n",
18 |     "<summary>Recommended: Set up MLflow Autologging to understand what's happening under the hood.</summary>\n",
19 |     "\n",
20 |     "### MLflow DSPy Integration\n",
21 |     "\n",
22 |     "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. MLflow's autologging capability automatically tracks progress of GEPA optimization, as well as visualizes prompts and module executions as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
23 |     "\n",
24 |     "**Visualize module executions as traces**\n",
25 |     "\n",
26 |     "![MLflow Trace](./mlflow-tracing-gepa-aime.png)\n",
27 |     "\n",
28 |     "**Automatically track optimization progress and results**\n",
29 |     "\n",
30 |     "![MLflow Tracking](./mlflow-tracking-gepa-aime-optimization.png)\n",
31 |     "\n",
32 |     "\n",
33 |     "**Setup MLflow**\n",
34 |     "\n",
35 |     "1. Install MLflow\n",
36 |     "\n",
37 |     "```bash\n",
38 |     "%pip install mlflow>=3.0.0\n",
39 |     "```\n",
40 |     "\n",
41 |     "2. Start MLflow UI in a separate terminal\n",
42 |     "```bash\n",
43 |     "mlflow ui --port 5000 --backend-store-uri sqlite:///mlruns.db\n",
44 |     "```\n",
45 |     "\n",
46 |     "3. Connect the notebook to MLflow\n",
47 |     "```python\n",
48 |     "import mlflow\n",
49 |     "\n",
50 |     "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
51 |     "mlflow.set_experiment(\"DSPy\")\n",
52 |     "```\n",
53 |     "\n",
54 |     "4. Enabling autologging.\n",
55 |     "\n",
56 |     "```python\n",
57 |     "mlflow.dspy.autolog(\n",
58 |     "    # Log the optimization progress\n",
59 |     "    log_compiles=True,\n",
60 |     "    # Log the evaluation results\n",
61 |     "    log_evals=True,\n",
62 |     "    # Log traces from module executions\n",
63 |     "    log_traces=True\n",
64 |     ")\n",
65 |     "```\n",
66 |     "\n",
67 |     "\n",
68 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
69 |     "</details>"
70 |    ]
71 |   },
72 |   {
73 |    "cell_type": "code",
74 |    "execution_count": 1,
75 |    "id": "283588ae",
76 |    "metadata": {},
77 |    "outputs": [],
78 |    "source": [
79 |     "api_key = input(\"Enter your OpenAI API key: \")\n",
80 |     "import dspy\n",
81 |     "lm = dspy.LM(\"openai/gpt-4.1-mini\", temperature=1, api_key=api_key, max_tokens=32000)\n",
82 |     "dspy.configure(lm=lm)"
83 |    ]
84 |   },
85 |   {
86 |    "cell_type": "markdown",
87 |    "id": "fb853f2c",
88 |    "metadata": {},
89 |    "source": [
90 |     "### Loading the AIME dataset\n",
91 |     "\n",
92 |     "The AIME exam consists of 2 problem sets of size 15 for each year. For this tutorial, we will use AIME problem sets from previous years (2022-2024) for optimization (amounting to total 3 years x 2 sets x 15 problems = 90 problems, split equally between train and validation sets), and test the performance on AIME 2025 (2 sets x 15 problems = 30 problems). Since AIME 2025 is a small set, we repeat it 5 times for statistical stability in evaluation."
93 |    ]
94 |   },
95 |   {
96 |    "cell_type": "code",
97 |    "execution_count": null,
98 |    "id": "c9e78285",
99 |    "metadata": {},
100 |    "outputs": [],
101 |    "source": [
102 |     "import dspy\n",
103 |     "from datasets import load_dataset\n",
104 |     "\n",
105 |     "def init_dataset():\n",
106 |     "    train_split = load_dataset(\"AI-MO/aimo-validation-aime\")['train']\n",
107 |     "    train_split = [\n",
108 |     "        dspy.Example({\n",
109 |     "            \"problem\": x['problem'],\n",
110 |     "            'solution': x['solution'],\n",
111 |     "            'answer': x['answer'],\n",
112 |     "        }).with_inputs(\"problem\")\n",
113 |     "        for x in train_split\n",
114 |     "    ]\n",
115 |     "    import random\n",
116 |     "    random.Random(0).shuffle(train_split)\n",
117 |     "    tot_num = len(train_split)\n",
118 |     "\n",
119 |     "    test_split = load_dataset(\"MathArena/aime_2025\")['train']\n",
120 |     "    test_split = [\n",
121 |     "        dspy.Example({\n",
122 |     "            \"problem\": x['problem'],\n",
123 |     "            'answer': x['answer'],\n",
124 |     "        }).with_inputs(\"problem\")\n",
125 |     "        for x in test_split\n",
126 |     "    ]\n",
127 |     "\n",
128 |     "    train_set = train_split[:int(0.5 * tot_num)]\n",
129 |     "    val_set = train_split[int(0.5 * tot_num):]\n",
130 |     "    test_set = test_split * 5\n",
131 |     "\n",
132 |     "    return train_set, val_set, test_set"
133 |    ]
134 |   },
135 |   {
136 |    "cell_type": "code",
137 |    "execution_count": 3,
138 |    "id": "51822ab6",
139 |    "metadata": {},
140 |    "outputs": [
141 |     {
142 |      "data": {
143 |       "text/plain": [
144 |        "(45, 45, 150)"
145 |       ]
146 |      },
147 |      "execution_count": 3,
148 |      "metadata": {},
149 |      "output_type": "execute_result"
150 |     }
151 |    ],
152 |    "source": [
153 |     "train_set, val_set, test_set = init_dataset()\n",
154 |     "\n",
155 |     "len(train_set), len(val_set), len(test_set)"
156 |    ]
157 |   },
158 |   {
159 |    "cell_type": "markdown",
160 |    "id": "d9f36cd4",
161 |    "metadata": {},
162 |    "source": [
163 |     "Let's view an example task input"
164 |    ]
165 |   },
166 |   {
167 |    "cell_type": "code",
168 |    "execution_count": 4,
169 |    "id": "96f1e064",
170 |    "metadata": {},
171 |    "outputs": [
172 |     {
173 |      "name": "stdout",
174 |      "output_type": "stream",
175 |      "text": [
176 |       "Problem:\n",
177 |       "In isosceles trapezoid $ABCD$, parallel bases $\\overline{AB}$ and $\\overline{CD}$ have lengths $500$ and $650$, respectively, and $AD=BC=333$. The angle bisectors of $\\angle{A}$ and $\\angle{D}$ meet at $P$, and the angle bisectors of $\\angle{B}$ and $\\angle{C}$ meet at $Q$. Find $PQ$.\n",
178 |       "\n",
179 |       "\n",
180 |       "Solution:\n",
181 |       "We have the following diagram:\n",
182 |       "\n",
183 |       "Let $X$ and $W$ be the points where $AP$ and $BQ$ extend to meet $CD$, and $YZ$ be the height of $\\triangle AZB$. As proven in Solution 2, triangles $APD$ and $DPW$ are congruent right triangles. Therefore, $AD = DW = 333$. We can apply this logic to triangles $BCQ$ and $XCQ$ as well, giving us $BC = CX = 333$. Since $CD = 650$, $XW = DW + CX - CD = 16$.\n",
184 |       "Additionally, we can see that $\\triangle XZW$ is similar to $\\triangle PQZ$ and $\\triangle AZB$. We know that $\\frac{XW}{AB} = \\frac{16}{500}$. So, we can say that the height of the triangle $AZB$ is $500u$ while the height of the triangle $XZW$ is $16u$. After that, we can figure out the distance from $Y$ to $PQ: \\frac{500+16}{2} = 258u$ and the height of triangle $PZQ: 500-258 = 242u$.\n",
185 |       "Finally, since the ratio between the height of $PZQ$ to the height of $AZB$ is $242:500$ and $AB$ is $500$, $PQ = \\boxed{242}.$\n",
186 |       "~Cytronical\n",
187 |       "Extend line $PQ$ to meet $AD$ at $P'$ and $BC$ at $Q'$. The diagram looks like this:\n",
188 |       "[asy] /* Made by MRENTHUSIASM */ size(300); pair A, B, C, D, A1, B1, C1, D1, P, Q, P1, Q1; A = (-250,6*sqrt(731)); B = (250,6*sqrt(731)); C = (325,-6*sqrt(731)); D = (-325,-6*sqrt(731)); A1 = bisectorpoint(B,A,D); B1 = bisectorpoint(A,B,C); C1 = bisectorpoint(B,C,D); D1 = bisectorpoint(A,D,C); P = intersectionpoint(A--300*(A1-A)+A,D--300*(D1-D)+D); Q = intersectionpoint(B--300*(B1-B)+B,C--300*(C1-C)+C); P1 = intersectionpoint(A--D,P--(-300)*(Q-P)+P); Q1 = intersectionpoint(B--C,Q--300*(Q-P)+Q); draw(anglemark(P,A,B,1000),red); draw(anglemark(D,A,P,1000),red); draw(anglemark(A,B,Q,1000),red); draw(anglemark(Q,B,C,1000),red); draw(anglemark(P,D,A,1000),red); draw(anglemark(C,D,P,1000),red); draw(anglemark(Q,C,D,1000),red); draw(anglemark(B,C,Q,1000),red); add(pathticks(anglemark(P,A,B,1000), n = 1, r = 0.15, s = 750, red)); add(pathticks(anglemark(D,A,P,1000), n = 1, r = 0.15, s = 750, red)); add(pathticks(anglemark(A,B,Q,1000), n = 1, r = 0.15, s = 750, red)); add(pathticks(anglemark(Q,B,C,1000), n = 1, r = 0.15, s = 750, red)); add(pathticks(anglemark(P,D,A,1000), n = 2, r = 0.12, spacing = 150, s = 750, red)); add(pathticks(anglemark(C,D,P,1000), n = 2, r = 0.12, spacing = 150, s = 750, red)); add(pathticks(anglemark(Q,C,D,1000), n = 2, r = 0.12, spacing = 150, s = 750, red)); add(pathticks(anglemark(B,C,Q,1000), n = 2, r = 0.12, spacing = 150, s = 750, red)); dot(\"$A$\",A,1.5*dir(A),linewidth(4)); dot(\"$B$\",B,1.5*dir(B),linewidth(4)); dot(\"$C$\",C,1.5*dir(C),linewidth(4)); dot(\"$D$\",D,1.5*dir(D),linewidth(4)); dot(\"$P$\",P,1.5*NE,linewidth(4)); dot(\"$Q$\",Q,1.5*NW,linewidth(4)); dot(\"$P'$\",P1,1.5*W,linewidth(4)); dot(\"$Q'$\",Q1,1.5*E,linewidth(4)); draw(A--B--C--D--cycle^^A--P--D^^B--Q--C^^P--Q); draw(P--P1^^Q--Q1,dashed); [/asy]\n",
189 |       "Because the trapezoid is isosceles, by symmetry $PQ$ is parallel to $AB$ and $CD$. Therefore, $\\angle PAB \\cong \\angle APP'$ by interior angles and $\\angle PAB \\cong \\angle PAD$ by the problem statement. Thus, $\\triangle P'AP$ is isosceles with $P'P = P'A$. By symmetry, $P'DP$ is also isosceles, and thus $P'A = \\frac{AD}{2}$. Similarly, the same thing is happening on the right side of the trapezoid, and thus $P'Q'$ is the midline of the trapezoid. Then, $PQ = P'Q' - (P'P + Q'Q)$.\n",
190 |       "Since $P'P = P'A = \\frac{AD}{2}, Q'Q = Q'B = \\frac{BC}{2}$ and $AD = BC = 333$, we have $P'P + Q'Q = \\frac{333}{2} + \\frac{333}{2} = 333$. The length of the midline of a trapezoid is the average of their bases, so $P'Q' = \\frac{500+650}{2} = 575$. Finally, $PQ = 575 - 333 = \\boxed{242}$.\n",
191 |       "~KingRavi\n",
192 |       "We have the following diagram:\n",
193 |       "\n",
194 |       "Extend lines $AP$ and $BQ$ to meet line $DC$ at points $W$ and $X$, respectively, and extend lines $DP$ and $CQ$ to meet $AB$ at points $Z$ and $Y$, respectively.\n",
195 |       "Claim: quadrilaterals $AZWD$ and $BYXC$ are rhombuses.\n",
196 |       "Proof: Since $\\angle DAB + \\angle ADC = 180^{\\circ}$, $\\angle ADP + \\angle PAD = 90^{\\circ}$. Therefore, triangles $APD$, $APZ$, $DPW$ and $PZW$ are all right triangles. By SAA congruence, the first three triangles are congruent; by SAS congruence, $\\triangle PZW$ is congruent to the other three. Therefore, $AD = DW = WZ = AZ$, so $AZWD$ is a rhombus. By symmetry, $BYXC$ is also a rhombus.\n",
197 |       "Extend line $PQ$ to meet $\\overline{AD}$ and $\\overline{BC}$ at $R$ and $S$, respectively. Because of rhombus properties, $RP = QS = \\frac{333}{2}$. Also, by rhombus properties, $R$ and $S$ are the midpoints of segments $AD$ and $BC$, respectively; therefore, by trapezoid properties, $RS = \\frac{AB + CD}{2} = 575$. Finally, $PQ = RS - RP - QS = \\boxed{242}$.\n",
198 |       "~ihatemath123\n",
199 |       "Let $X$ and $Y$ be the feet of the altitudes from $P$ and $Q$, respectively, to $AB$, and let $Z$ and $W$ be the feet of the altitudes from $P$ and $Q$, respectively, to $CD$. Side $AB$ is parallel to side $CD$, so $XYWZ$ is a rectangle with width $PQ$. Furthermore, because $CD - AB = 650-500 = 150$ and trapezoid $ABCD$ is isosceles, $WC - YB = ZD - XA = 75$. \n",
200 |       "Also because $ABCD$ is isosceles, $\\angle ABC + \\angle BCD$ is half the total sum of angles in $ABCD$, or $180^{\\circ}$. Since $BQ$ and $CQ$ bisect $\\angle ABC$ and $\\angle BCD$, respectively, we have $\\angle QBC + \\angle QCB = 90^{\\circ}$, so $\\angle BQC = 90^{\\circ}$. \n",
201 |       "Letting $BQ = 333k$, applying Pythagoras to $\\triangle BQC$ yields $QC = 333\\sqrt{1-k^2}$. We then proceed using similar triangles: $\\angle BYQ = \\angle BQC = 90^{\\circ}$ and $\\angle YBQ = \\angle QBC$, so by AA similarity $YB = 333k^2$. Likewise, $\\angle CWQ = \\angle BQC = 90^{\\circ}$ and $\\angle WCQ = \\angle QCB$, so by AA similarity $WC = 333(1 - k^2)$. Thus $WC + YB = 333$.\n",
202 |       "Adding our two equations for $WC$ and $YB$ gives $2WC = 75 + 333 = 408$. Therefore, the answer is $PQ = ZW = CD - 2WC = 650 - 408 = \\boxed{242}$.\n",
203 |       "~Orange_Quail_9\n",
204 |       "This will be my first solution on AoPS. My apologies in advance for any errors. \n",
205 |       "Angle bisectors can be thought of as the locus of all points equidistant from the lines whose angle they bisect. It can thus be seen that $P$ is equidistant from  $AB, AD,$ and $CD$ and $Q$ is equidistant from  $AB, BC,$ and $CD.$ If we let the feet of the altitudes from $P$ to $AB, AD,$ and $CD$ be called $E, F,$ and $G$ respectively, we can say that $PE = PF = PG.$ Analogously, we let the feet of the altitudes from $Q$ to $AB, BC,$ and $CD$ be $H, I,$ and $J$ respectively. Thus, $QH = QI = QJ.$ Because $ABCD$ is an isosceles trapezoid, we can say that all of the altitudes are equal to each other. \n",
206 |       "By SA as well as SS congruence for right triangles, we find that triangles $AEP, AFP, BHQ,$ and $BIQ$ are congruent. Similarly, $DFP, DGP, CJQ,$ and $CIQ$ by the same reasoning. Additionally, $EH = GJ = PQ$ since $EHQP$ and $GJQP$ are congruent rectangles. \n",
207 |       "If we then let $x = AE = AF = BH = BI,$ let $y = CI = CJ = DG = DF,$ and let $z = EH = GJ = PQ,$ we can create the following system of equations with the given side length information:\n",
208 |       "\\begin{align*} 2x + z &= 500, \\\\ 2y + z &= 650, \\\\ x + y &= 333. \\end{align*}\n",
209 |       "Adding the first two equations, subtracting by twice the second, and dividing by $2$ yields $z = PQ = \\boxed{242}.$\n",
210 |       "~regular\n",
211 |       "Extend line $PQ$ to meet $AD$ at $P'$ and $BC$ at $Q'$. The diagram looks like this: \n",
212 |       "[asy] /* Made by MRENTHUSIASM */ size(300); pair A, B, C, D, A1, B1, C1, D1, P, Q, P1, Q1; A = (-250,6*sqrt(731)); B = (250,6*sqrt(731)); C = (325,-6*sqrt(731)); D = (-325,-6*sqrt(731)); A1 = bisectorpoint(B,A,D); B1 = bisectorpoint(A,B,C); C1 = bisectorpoint(B,C,D); D1 = bisectorpoint(A,D,C); P = intersectionpoint(A--300*(A1-A)+A,D--300*(D1-D)+D); Q = intersectionpoint(B--300*(B1-B)+B,C--300*(C1-C)+C); P1 = intersectionpoint(A--D,P--(-300)*(Q-P)+P); Q1 = intersectionpoint(B--C,Q--300*(Q-P)+Q); draw(anglemark(P,A,B,1000),red); draw(anglemark(D,A,P,1000),red); draw(anglemark(A,B,Q,1000),red); draw(anglemark(Q,B,C,1000),red); draw(anglemark(P,D,A,1000),red); draw(anglemark(C,D,P,1000),red); draw(anglemark(Q,C,D,1000),red); draw(anglemark(B,C,Q,1000),red); add(pathticks(anglemark(P,A,B,1000), n = 1, r = 0.15, s = 750, red)); add(pathticks(anglemark(D,A,P,1000), n = 1, r = 0.15, s = 750, red)); add(pathticks(anglemark(A,B,Q,1000), n = 1, r = 0.15, s = 750, red)); add(pathticks(anglemark(Q,B,C,1000), n = 1, r = 0.15, s = 750, red)); add(pathticks(anglemark(P,D,A,1000), n = 2, r = 0.12, spacing = 150, s = 750, red)); add(pathticks(anglemark(C,D,P,1000), n = 2, r = 0.12, spacing = 150, s = 750, red)); add(pathticks(anglemark(Q,C,D,1000), n = 2, r = 0.12, spacing = 150, s = 750, red)); add(pathticks(anglemark(B,C,Q,1000), n = 2, r = 0.12, spacing = 150, s = 750, red)); dot(\"$A$\",A,1.5*dir(A),linewidth(4)); dot(\"$B$\",B,1.5*dir(B),linewidth(4)); dot(\"$C$\",C,1.5*dir(C),linewidth(4)); dot(\"$D$\",D,1.5*dir(D),linewidth(4)); dot(\"$P$\",P,1.5*NE,linewidth(4)); dot(\"$Q$\",Q,1.5*NW,linewidth(4)); dot(\"$P'$\",P1,1.5*W,linewidth(4)); dot(\"$Q'$\",Q1,1.5*E,linewidth(4)); draw(A--B--C--D--cycle^^A--P--D^^B--Q--C^^P--Q); draw(P--P1^^Q--Q1,dashed); [/asy]\n",
213 |       "Since $\\angle A + \\angle D=\\angle B + \\angle C = 180^{\\circ}$, it follows that $\\angle P'AP+\\angle P'DP = \\angle Q'BQ + \\angle Q'CQ = 90^{\\circ}$. Thus, $\\angle APD = \\angle BQC = 90^{\\circ}$, implying that $\\triangle APD$ and $\\triangle BQC$ are right triangles. Since $P'P$ and $Q'Q$ are medians, $P'P+Q'Q=\\frac{333\\times2}{2}=333$. Since $P'Q'=\\frac{500+650}{2}=575$, we have $PQ+P'P+Q'Q=575$, or $PQ=575-333=\\boxed{242}$.\n",
214 |       "~sigma\n",
215 |       "Let $PQ = x$. Note that since $AP$ bisects $\\angle{A}$ and $DP$ bisects $\\angle{D}$, we have \\[\\angle{APD} = 180^{\\circ}-\\tfrac12 \\angle{A}-\\tfrac12 \\angle{D}=90^{\\circ}.\\] Let $\\angle{ADP}=\\theta$. We have that $\\angle{ADC} = 2\\theta.$ Now, drop an altitude from $A$ to $CD$ at $E$. Notice that $DE=\\tfrac{650-500}{2}=75$. By the definition of cosine, we have \\[\\cos{2\\theta}=1-2\\cos^2{\\theta}=\\tfrac{75}{333}=\\tfrac{25}{111} \\implies \\cos{\\theta}=\\tfrac{2\\sqrt{1887}}{111}.\\] Notice, however, that we can also apply this to $\\triangle{APD}$; we have \\[\\cos{\\theta}=\\tfrac{DP}{333} \\implies DP=6\\sqrt{1887}.\\] By the Pythagorean Theorem, we get \\[AP=\\sqrt{333^2-(6\\sqrt{1887})^2}=3\\sqrt{4773}.\\] Then, drop an altitude from $P$ to $AB$ at $F$; if $AF=y$, then $PQ=x=500-2y$. Because $AP$ is an angle bisector, we see that $\\angle{BAP}=\\angle{DAP}=90^{\\circ}-\\theta$. Again, by the definition of cosine, we have \\[\\cos{(90^{\\circ}-\\theta)}=\\sin{\\theta}=\\tfrac{\\sqrt{4773}}{111}=\\tfrac{y}{3\\sqrt{4773}} \\implies y=129.\\] Finally, $PQ=500-2y=\\boxed{242}$.\n",
216 |       "~pqr.\n",
217 |       "As in solution 4, $\\angle APD = 90^{\\circ}$. Set $k = AX$ and $x = DP$.\n",
218 |       "We know that $DZ = AX + \\frac{DC-AB}{2}$, so $DZ = k + \\frac{650-500}{2} = k + 75$.\n",
219 |       "$\\triangle DPZ \\sim \\triangle APD$ by AA, so we have $\\frac{PD}{AD} = \\frac{ZD}{PD}$, resulting in\n",
220 |       "\\[\\frac{x}{333} = \\frac{k+75}{x} \\text{ (1)}\\]\n",
221 |       "$\\triangle APX \\sim \\triangle ADP$ by AA, so we have $\\frac{AP}{AD} = \\frac{AX}{AP}$, resulting in\n",
222 |       "\\[\\frac{\\sqrt{333^2-x^2}}{333} = \\frac{k}{\\sqrt{333^2-k^2}} \\text{ (2)}\\]\n",
223 |       "From $\\text{(1)}$, we have $x^2 = 333k + 333(75) = 333k + 24975$. From $\\text{(2)}$, we have $333^2 - x^2 = 333k$, or $x^2 = 333^2 - 333k$. Thus, $333k + 24975 = 333^2 - 333k$. Solving for $k$ yields $k = 129$.\n",
224 |       "By symmetry, $YB = AX = 129$. Thus, $PQ = XY = AB - 2AX = 500 - 2(129) = \\boxed{242}$.\n",
225 |       "~ adam_zheng\n",
226 |       "\n",
227 |       "\n",
228 |       "Answer:\n",
229 |       "242\n"
230 |      ]
231 |     }
232 |    ],
233 |    "source": [
234 |     "print(\"Problem:\")\n",
235 |     "print(train_set[0]['problem'])\n",
236 |     "print(\"\\n\\nSolution:\")\n",
237 |     "print(train_set[0]['solution'])\n",
238 |     "print(\"\\n\\nAnswer:\")\n",
239 |     "print(train_set[0]['answer'])"
240 |    ]
241 |   },
242 |   {
243 |    "cell_type": "markdown",
244 |    "id": "552769fd",
245 |    "metadata": {},
246 |    "source": [
247 |     "### Let's define the program: A simple `dspy.ChainOfThought`"
248 |    ]
249 |   },
250 |   {
251 |    "cell_type": "code",
252 |    "execution_count": 5,
253 |    "id": "71598add",
254 |    "metadata": {},
255 |    "outputs": [],
256 |    "source": [
257 |     "class GenerateResponse(dspy.Signature):\n",
258 |     "    \"\"\"Solve the problem and provide the answer in the correct format.\"\"\"\n",
259 |     "    problem = dspy.InputField()\n",
260 |     "    answer = dspy.OutputField()\n",
261 |     "\n",
262 |     "program = dspy.ChainOfThought(GenerateResponse)"
263 |    ]
264 |   },
265 |   {
266 |    "cell_type": "markdown",
267 |    "id": "5e795e1b",
268 |    "metadata": {},
269 |    "source": [
270 |     "### Defining the evaluation metric\n",
271 |     "We simply check exact match between the predicted answer and the correct answer."
272 |    ]
273 |   },
274 |   {
275 |    "cell_type": "code",
276 |    "execution_count": 6,
277 |    "id": "1c0d2c5a",
278 |    "metadata": {},
279 |    "outputs": [],
280 |    "source": [
281 |     "def metric(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
282 |     "    correct_answer = int(example['answer'])\n",
283 |     "    try:\n",
284 |     "        llm_answer = int(prediction.answer)\n",
285 |     "    except ValueError as e:\n",
286 |     "        return 0\n",
287 |     "    return int(correct_answer == llm_answer)"
288 |    ]
289 |   },
290 |   {
291 |    "cell_type": "markdown",
292 |    "id": "785e4e74",
293 |    "metadata": {},
294 |    "source": [
295 |     "### Evaluating unoptimized Chain Of Thought"
296 |    ]
297 |   },
298 |   {
299 |    "cell_type": "code",
300 |    "execution_count": 7,
301 |    "id": "e52d3e50",
302 |    "metadata": {},
303 |    "outputs": [
304 |     {
305 |      "name": "stdout",
306 |      "output_type": "stream",
307 |      "text": [
308 |       "Average Metric: 70.00 / 150 (46.7%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [00:01<00:00, 119.75it/s]\n",
309 |       "2025/08/12 21:49:36 INFO dspy.evaluate.evaluate: Average Metric: 70 / 150 (46.7%)\n",
310 |       "\n"
311 |      ]
312 |     },
313 |     {
314 |      "name": "stderr",
315 |      "output_type": "stream",
316 |      "text": [
317 |       "2025/08/12 21:49:36 INFO dspy.evaluate.evaluate: Average Metric: 70 / 150 (46.7%)\n"
318 |      ]
319 |     },
320 |     {
321 |      "name": "stdout",
322 |      "output_type": "stream",
323 |      "text": [
324 |       "\n"
325 |      ]
326 |     },
327 |     {
328 |      "data": {
329 |       "text/html": [
330 |        "<div>\n",
331 |        "<style scoped>\n",
332 |        "    .dataframe tbody tr th:only-of-type {\n",
333 |        "        vertical-align: middle;\n",
334 |        "    }\n",
335 |        "\n",
336 |        "    .dataframe tbody tr th {\n",
337 |        "        vertical-align: top;\n",
338 |        "    }\n",
339 |        "\n",
340 |        "    .dataframe thead th {\n",
341 |        "        text-align: right;\n",
342 |        "    }\n",
343 |        "</style>\n",
344 |        "<table border=\"1\" class=\"dataframe\">\n",
345 |        "  <thead>\n",
346 |        "    <tr style=\"text-align: right;\">\n",
347 |        "      <th></th>\n",
348 |        "      <th>problem</th>\n",
349 |        "      <th>example_answer</th>\n",
350 |        "      <th>reasoning</th>\n",
351 |        "      <th>pred_answer</th>\n",
352 |        "      <th>metric</th>\n",
353 |        "    </tr>\n",
354 |        "  </thead>\n",
355 |        "  <tbody>\n",
356 |        "    <tr>\n",
357 |        "      <th>0</th>\n",
358 |        "      <td>Find the sum of all integer bases $b&gt;9$ for which $17_b$ is a divi...</td>\n",
359 |        "      <td>70</td>\n",
360 |        "      <td>We are looking for integer bases \\( b &gt; 9 \\) such that \\( 17_b \\) ...</td>\n",
361 |        "      <td>70</td>\n",
362 |        "      <td>✔️ [1]</td>\n",
363 |        "    </tr>\n",
364 |        "    <tr>\n",
365 |        "      <th>1</th>\n",
366 |        "      <td>On $\\triangle ABC$ points $A, D, E$, and $B$ lie in that order on ...</td>\n",
367 |        "      <td>588</td>\n",
368 |        "      <td>Let's analyze the problem step-by-step. We have triangle \\( ABC \\)...</td>\n",
369 |        "      <td>588</td>\n",
370 |        "      <td>✔️ [1]</td>\n",
371 |        "    </tr>\n",
372 |        "    <tr>\n",
373 |        "      <th>2</th>\n",
374 |        "      <td>The 9 members of a baseball team went to an ice-cream parlor after...</td>\n",
375 |        "      <td>16</td>\n",
376 |        "      <td>We have 9 players, each choosing one of three flavors: chocolate (...</td>\n",
377 |        "      <td>16</td>\n",
378 |        "      <td>✔️ [1]</td>\n",
379 |        "    </tr>\n",
380 |        "    <tr>\n",
381 |        "      <th>3</th>\n",
382 |        "      <td>Find the number of ordered pairs $(x,y)$, where both $x$ and $y$ a...</td>\n",
383 |        "      <td>117</td>\n",
384 |        "      <td>We start with the given equation: \\[12x^2 - xy - 6y^2 = 0.\\] Our g...</td>\n",
385 |        "      <td>117</td>\n",
386 |        "      <td>✔️ [1]</td>\n",
387 |        "    </tr>\n",
388 |        "    <tr>\n",
389 |        "      <th>4</th>\n",
390 |        "      <td>There are $8!= 40320$ eight-digit positive integers that use each ...</td>\n",
391 |        "      <td>279</td>\n",
392 |        "      <td>We are given that there are \\(8! = 40320\\) eight-digit numbers tha...</td>\n",
393 |        "      <td>279</td>\n",
394 |        "      <td>✔️ [1]</td>\n",
395 |        "    </tr>\n",
396 |        "    <tr>\n",
397 |        "      <th>...</th>\n",
398 |        "      <td>...</td>\n",
399 |        "      <td>...</td>\n",
400 |        "      <td>...</td>\n",
401 |        "      <td>...</td>\n",
402 |        "      <td>...</td>\n",
403 |        "    </tr>\n",
404 |        "    <tr>\n",
405 |        "      <th>145</th>\n",
406 |        "      <td>Let $S$ be the set of vertices of a regular $24$-gon. Find the num...</td>\n",
407 |        "      <td>113</td>\n",
408 |        "      <td>We have a regular 24-gon with vertex set \\( S \\) of size 24. We wa...</td>\n",
409 |        "      <td>1666</td>\n",
410 |        "      <td></td>\n",
411 |        "    </tr>\n",
412 |        "    <tr>\n",
413 |        "      <th>146</th>\n",
414 |        "      <td>Let $A_1 A_2 A_3 \\ldots A_{11}$ be an $11$-sided non-convex simple...</td>\n",
415 |        "      <td>19</td>\n",
416 |        "      <td>Let's analyze the problem step-by-step. We are given an 11-sided p...</td>\n",
417 |        "      <td>19</td>\n",
418 |        "      <td>✔️ [1]</td>\n",
419 |        "    </tr>\n",
420 |        "    <tr>\n",
421 |        "      <th>147</th>\n",
422 |        "      <td>Let $x_1, x_2, x_3, \\ldots$ be a sequence of rational numbers defi...</td>\n",
423 |        "      <td>248</td>\n",
424 |        "      <td>We have the sequence: \\[ x_1 = \\frac{25}{11}, \\quad x_{k+1} = \\fra...</td>\n",
425 |        "      <td>589</td>\n",
426 |        "      <td></td>\n",
427 |        "    </tr>\n",
428 |        "    <tr>\n",
429 |        "      <th>148</th>\n",
430 |        "      <td>Let $\\triangle ABC$ be a right triangle with $\\angle A = 90^\\circ$...</td>\n",
431 |        "      <td>104</td>\n",
432 |        "      <td>Given a right triangle \\(\\triangle ABC\\) with \\(\\angle A = 90^\\cir...</td>\n",
433 |        "      <td>98</td>\n",
434 |        "      <td></td>\n",
435 |        "    </tr>\n",
436 |        "    <tr>\n",
437 |        "      <th>149</th>\n",
438 |        "      <td>There are exactly three positive real numbers $k$ such that the fu...</td>\n",
439 |        "      <td>240</td>\n",
440 |        "      <td>We are given the function \\[ f(x) = \\frac{(x - 18)(x - 72)(x - 98)...</td>\n",
441 |        "      <td>240</td>\n",
442 |        "      <td>✔️ [1]</td>\n",
443 |        "    </tr>\n",
444 |        "  </tbody>\n",
445 |        "</table>\n",
446 |        "<p>150 rows × 5 columns</p>\n",
447 |        "</div>"
448 |       ],
449 |       "text/plain": [
450 |        "                                                                   problem  \\\n",
451 |        "0    Find the sum of all integer bases $b>9$ for which $17_b$ is a divi...   \n",
452 |        "1    On $\\triangle ABC$ points $A, D, E$, and $B$ lie in that order on ...   \n",
453 |        "2    The 9 members of a baseball team went to an ice-cream parlor after...   \n",
454 |        "3    Find the number of ordered pairs $(x,y)$, where both $x$ and $y$ a...   \n",
455 |        "4    There are $8!= 40320$ eight-digit positive integers that use each ...   \n",
456 |        "..                                                                     ...   \n",
457 |        "145  Let $S$ be the set of vertices of a regular $24$-gon. Find the num...   \n",
458 |        "146  Let $A_1 A_2 A_3 \\ldots A_{11}$ be an $11$-sided non-convex simple...   \n",
459 |        "147  Let $x_1, x_2, x_3, \\ldots$ be a sequence of rational numbers defi...   \n",
460 |        "148  Let $\\triangle ABC$ be a right triangle with $\\angle A = 90^\\circ$...   \n",
461 |        "149  There are exactly three positive real numbers $k$ such that the fu...   \n",
462 |        "\n",
463 |        "     example_answer  \\\n",
464 |        "0                70   \n",
465 |        "1               588   \n",
466 |        "2                16   \n",
467 |        "3               117   \n",
468 |        "4               279   \n",
469 |        "..              ...   \n",
470 |        "145             113   \n",
471 |        "146              19   \n",
472 |        "147             248   \n",
473 |        "148             104   \n",
474 |        "149             240   \n",
475 |        "\n",
476 |        "                                                                 reasoning  \\\n",
477 |        "0    We are looking for integer bases \\( b > 9 \\) such that \\( 17_b \\) ...   \n",
478 |        "1    Let's analyze the problem step-by-step. We have triangle \\( ABC \\)...   \n",
479 |        "2    We have 9 players, each choosing one of three flavors: chocolate (...   \n",
480 |        "3    We start with the given equation: \\[12x^2 - xy - 6y^2 = 0.\\] Our g...   \n",
481 |        "4    We are given that there are \\(8! = 40320\\) eight-digit numbers tha...   \n",
482 |        "..                                                                     ...   \n",
483 |        "145  We have a regular 24-gon with vertex set \\( S \\) of size 24. We wa...   \n",
484 |        "146  Let's analyze the problem step-by-step. We are given an 11-sided p...   \n",
485 |        "147  We have the sequence: \\[ x_1 = \\frac{25}{11}, \\quad x_{k+1} = \\fra...   \n",
486 |        "148  Given a right triangle \\(\\triangle ABC\\) with \\(\\angle A = 90^\\cir...   \n",
487 |        "149  We are given the function \\[ f(x) = \\frac{(x - 18)(x - 72)(x - 98)...   \n",
488 |        "\n",
489 |        "    pred_answer  metric  \n",
490 |        "0            70  ✔️ [1]  \n",
491 |        "1           588  ✔️ [1]  \n",
492 |        "2            16  ✔️ [1]  \n",
493 |        "3           117  ✔️ [1]  \n",
494 |        "4           279  ✔️ [1]  \n",
495 |        "..          ...     ...  \n",
496 |        "145        1666          \n",
497 |        "146          19  ✔️ [1]  \n",
498 |        "147         589          \n",
499 |        "148          98          \n",
500 |        "149         240  ✔️ [1]  \n",
501 |        "\n",
502 |        "[150 rows x 5 columns]"
503 |       ]
504 |      },
505 |      "metadata": {},
506 |      "output_type": "display_data"
507 |     },
508 |     {
509 |      "data": {
510 |       "text/plain": [
511 |        "EvaluationResult(score=46.67, results=<list of 150 results>)"
512 |       ]
513 |      },
514 |      "execution_count": 7,
515 |      "metadata": {},
516 |      "output_type": "execute_result"
517 |     }
518 |    ],
519 |    "source": [
520 |     "import dspy\n",
521 |     "evaluate = dspy.Evaluate(\n",
522 |     "    devset=test_set,\n",
523 |     "    metric=metric,\n",
524 |     "    num_threads=32,\n",
525 |     "    display_table=True,\n",
526 |     "    display_progress=True\n",
527 |     ")\n",
528 |     "\n",
529 |     "evaluate(program)"
530 |    ]
531 |   },
532 |   {
533 |    "cell_type": "markdown",
534 |    "id": "0aeb9bae",
535 |    "metadata": {},
536 |    "source": [
537 |     "### Optimize the program with `dspy.GEPA`\n",
538 |     "\n",
539 |     "GEPA is a _reflective_ prompt optimizer, and it's strength lies in being able to leverage additional sources of information, like the DSPy program's execution and evaluation pipelines, which provides GEPA more visibility into why the system got the score that it did, and then GEPA can introspect to identify how to improve the score. GEPA can also leverage additional supervision provided in this manner. For example, during optimization, we can return the correct solution's to the problems the program failed to solve.\n",
540 |     "\n",
541 |     "We note that while such explicit supervision is not available in all scenarios, GEPA can work very flexibly with different forms of feedback (for example, using LLM-as-a-judge feedback shown in the PAPILLON tutorial, or just using answer labels, as shown in the facility-support tutorial).\n",
542 |     "\n",
543 |     "Let's quickly modify the evaluation metric to become an optimization metric for GEPA, that can provide this additional supervision!"
544 |    ]
545 |   },
546 |   {
547 |    "cell_type": "code",
548 |    "execution_count": 8,
549 |    "id": "e21e86df",
550 |    "metadata": {},
551 |    "outputs": [],
552 |    "source": [
553 |     "def metric_with_feedback(example, prediction, trace=None, pred_name=None, pred_trace=None):\n",
554 |     "    correct_answer = int(example['answer'])\n",
555 |     "    written_solution = example.get('solution', '')\n",
556 |     "    try:\n",
557 |     "        llm_answer = int(prediction.answer)\n",
558 |     "    except ValueError as e:\n",
559 |     "        feedback_text = f\"The final answer must be a valid integer and nothing else. You responded with '{prediction.answer}', which couldn't be parsed as a python integer. Please ensure your answer is a valid integer without any additional text or formatting.\"\n",
560 |     "        feedback_text += f\" The correct answer is '{correct_answer}'.\"\n",
561 |     "        if written_solution:\n",
562 |     "            feedback_text += f\" Here's the full step-by-step solution:\\n{written_solution}\\n\\nThink about what takeaways you can learn from this solution to improve your future answers and approach to similar problems and ensure your final answer is a valid integer.\"\n",
563 |     "        return dspy.Prediction(score=0, feedback=feedback_text)\n",
564 |     "\n",
565 |     "    score = int(correct_answer == llm_answer)\n",
566 |     "\n",
567 |     "    feedback_text = \"\"\n",
568 |     "    if score == 1:\n",
569 |     "        feedback_text = f\"Your answer is correct. The correct answer is '{correct_answer}'.\"\n",
570 |     "    else:\n",
571 |     "        feedback_text = f\"Your answer is incorrect. The correct answer is '{correct_answer}'.\"\n",
572 |     "    \n",
573 |     "    if written_solution:\n",
574 |     "        feedback_text += f\" Here's the full step-by-step solution:\\n{written_solution}\\n\\nThink about what takeaways you can learn from this solution to improve your future answers and approach to similar problems.\"\n",
575 |     "\n",
576 |     "    return dspy.Prediction(score=score, feedback=feedback_text)"
577 |    ]
578 |   },
579 |   {
580 |    "cell_type": "code",
581 |    "execution_count": 9,
582 |    "id": "b1404077",
583 |    "metadata": {},
584 |    "outputs": [
585 |     {
586 |      "name": "stderr",
587 |      "output_type": "stream",
588 |      "text": [
589 |       "2025/08/12 21:49:36 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 560 metric calls of the program. This amounts to 6.22 full evals on the train+val set.\n",
590 |       "3\n",
591 |       "2025/08/12 21:49:36 INFO dspy.teleprompt.gepa.gepa: Using 45 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget.\n",
592 |       "2025/08/12 21:52:15 INFO dspy.evaluate.evaluate: Average Metric: 17.0 / 45 (37.8%)\n",
593 |       "2025/08/12 21:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.37777777777777777\n",
594 |       "2025/08/12 21:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.37777777777777777\n",
595 |       "Average Metric: 2.00 / 3 (66.7%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [03:10<00:00, 63.51s/it]\n",
596 |       "2025/08/12 21:55:26 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
597 |       "\n",
598 |       "2025/08/12 21:56:50 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Proposed new text for predict: You will be given a single math problem as plain text under an input key like “problem.” Your task is to solve it correctly and return:\n",
599 |       "\n",
600 |       "- reasoning: a concise, logically ordered solution that uses appropriate identities/constraints to minimize brute force and ends with a quick verification.\n",
601 |       "- answer: the final result only (just the number or expression requested, no extra words).\n",
602 |       "\n",
603 |       "Formatting:\n",
604 |       "- Use two top-level fields exactly named “reasoning” and “answer.”\n",
605 |       "- Keep the reasoning succinct but complete. Avoid heavy markup. Bullet points are fine.\n",
606 |       "- The answer field must contain only the final value requested (e.g., 227, 585, 601).\n",
607 |       "\n",
608 |       "General problem-solving guidance:\n",
609 |       "- Parse the problem type (e.g., base representation, palindrome constraints across bases, symmetric sums with constraints, counting ordered triples).\n",
610 |       "- Always enforce domain constraints (e.g., base-b digits are 0..b-1; leading digit in base-10 three-digit numbers is 1..9; ordered triples count permutations unless otherwise specified).\n",
611 |       "- Use algebraic identities and modular arithmetic to reduce the search space and ensure correctness.\n",
612 |       "\n",
613 |       "Domain-specific strategies (from common contest problems):\n",
614 |       "\n",
615 |       "1) Base-conversion/digit rearrangement:\n",
616 |       "- Translate positional notation correctly:\n",
617 |       "  For base 10: abc = 100a + 10b + c.\n",
618 |       "  For base 9 (or b): (b c a)_9 = b·9^2 + c·9 + a.\n",
619 |       "- Enforce digit ranges: in base 9, digits a, b, c ∈ {0,…,8}; if the base-10 number is three-digit, a ∈ {1,…,9} and also must satisfy the base-9 digit limit (so a ∈ {1,…,8}).\n",
620 |       "- Set up equality and simplify. Example pattern: 100a + 10b + c = 81b + 9c + a ⇒ 99a = 71b + 8c.\n",
621 |       "- Use modular constraints to prune:\n",
622 |       "  • Mod 9: 99a ≡ 0 and 71 ≡ 8 ⇒ 0 ≡ 8(b + c) ⇒ b + c ≡ 0 (mod 9), so b + c ∈ {0, 9} within digit bounds.\n",
623 |       "  • Mod 8: 99 ≡ 3, 71 ≡ 7 ⇒ 3a ≡ 7b (mod 8) ⇒ b ≡ −3a (mod 8).\n",
624 |       "- Solve within digit bounds and verify.\n",
625 |       "\n",
626 |       "2) Palindromes across bases (e.g., base 10 and base 8):\n",
627 |       "- Determine the base-8 length given the magnitude (n < 1000 ⇒ base-8 has 3 or 4 digits).\n",
628 |       "- Characterize base-8 palindromes:\n",
629 |       "  • 3-digit: (A B A)_8 = 64A + 8B + A = 65A + 8B.\n",
630 |       "  • 4-digit: (A B B A)_8 = 512A + 64B + 8B + A = 513A + 72B.\n",
631 |       "- For n < 1000 and 4-digit octal palindrome, A must be 1. Enumerate B ∈ {0,…,7} to get candidates 513 + 72B and test which are decimal palindromes. Choose the greatest valid n.\n",
632 |       "\n",
633 |       "3) Symmetric sums with a + b + c fixed (ordered triples of nonnegative integers):\n",
634 |       "- Convert sums like a^2b + a^2c + b^2a + b^2c + c^2a + c^2b using:\n",
635 |       "  S = ab(a + b) + bc(b + c) + ca(c + a) = (a + b + c)(ab + bc + ca) − 3abc.\n",
636 |       "- With a + b + c given (e.g., 300), plug into S = given constant to derive:\n",
637 |       "  100(ab + bc + ca) − abc = constant.\n",
638 |       "- Use the shift a = 100 + x, b = 100 + y, c = 100 + z, so x + y + z = 0. Then:\n",
639 |       "  (a − 100)(b − 100)(c − 100) = abc − 100(ab + bc + ca) + 2,000,000.\n",
640 |       "  Setting S correctly yields (a − 100)(b − 100)(c − 100) = 0.\n",
641 |       "- Count solutions:\n",
642 |       "  • If exactly one equals 100, the other two sum to 200 with both ≠ 100. Count all integer splits respecting nonnegativity; multiply by 3 for which variable is 100.\n",
643 |       "  • Include the case a = b = c = 100 once.\n",
644 |       "  • Treat (a, b, c) as ordered unless the problem explicitly asks for unordered.\n",
645 |       "\n",
646 |       "Quality checks:\n",
647 |       "- Verify digit/base constraints and final equality numerically.\n",
648 |       "- For “greatest/least” questions, justify why your candidate is optimal (structural argument or bounded enumeration).\n",
649 |       "- For counting, avoid over/undercounting; be explicit about ordered vs unordered.\n",
650 |       "\n",
651 |       "Finally:\n",
652 |       "- Place the clean final numeric result in the “answer” field.\n",
653 |       "2025/08/12 21:57:19 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
654 |       "2025/08/12 22:00:37 INFO dspy.evaluate.evaluate: Average Metric: 19.0 / 45 (42.2%)\n",
655 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program is on the linear pareto front\n",
656 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset score for new program: 0.4222222222222222\n",
657 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full train_val score for new program: 0.4222222222222222\n",
658 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Individual valset scores for new program: [0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
659 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New valset pareto front scores: [0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
660 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset pareto front score: 0.5111111111111111\n",
661 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Updated valset pareto front programs: [{0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}]\n",
662 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best valset aggregate score so far: 0.4222222222222222\n",
663 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on train_val: 1\n",
664 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on valset: 1\n",
665 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on valset: 0.4222222222222222\n",
666 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on train_val: 0.4222222222222222\n",
667 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Linear pareto front program index: 1\n",
668 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program candidate index: 1\n",
669 |       "2025/08/12 22:00:37 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Selected program 0 score: 0.37777777777777777\n",
670 |       "Average Metric: 2.00 / 3 (66.7%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:57<00:00, 59.20s/it]\n",
671 |       "2025/08/12 22:03:34 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
672 |       "\n",
673 |       "2025/08/12 22:04:41 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Proposed new text for predict: You will be given a single field:\n",
674 |       "- problem: a math contest-style problem (algebra/number theory/geometry/combinatorics).\n",
675 |       "\n",
676 |       "Your task:\n",
677 |       "1) Solve the problem correctly with clear, exact reasoning (avoid decimal approximations unless explicitly required).\n",
678 |       "2) Output in this exact format:\n",
679 |       "   ### reasoning\n",
680 |       "   [succinct, rigorous solution steps]\n",
681 |       "   ### answer\n",
682 |       "   [final answer only, no extra words]\n",
683 |       "\n",
684 |       "General guidance and domain-specific strategies:\n",
685 |       "- Keep the reasoning concise but complete enough to verify correctness. Prefer clean theoretical arguments over coordinate bashing or numeric approximations.\n",
686 |       "- For geometry (especially symmetric figures like isosceles trapezoids):\n",
687 |       "  - Exploit symmetry and parallelism.\n",
688 |       "  - Angle-bisector facts: the bisector at a vertex is the locus of points equidistant from the adjacent sides; in a cyclic or trapezoidal setup adjacent-angle bisectors may form right angles because A + D = 180° implies half-angles sum to 90°.\n",
689 |       "  - In right triangles, the midpoint of the hypotenuse is equidistant from the endpoints; medians and midlines are powerful.\n",
690 |       "  - In trapezoids, the midline length equals the average of the bases. A useful identity for an isosceles trapezoid with bases AB, CD and legs AD = BC is:\n",
691 |       "    PQ = (AB + CD)/2 − (AD + BC)/2; in the isosceles case this simplifies to PQ = (AB + CD)/2 − AD.\n",
692 |       "  - Angle-bisector constructions often yield congruent right triangles and rhombuses by equal-distance properties—use these to get exact lengths.\n",
693 |       "- For products over roots of unity:\n",
694 |       "  - If ω is a primitive n-th root (or any ω with ω^n = 1 and ω ≠ 1), then {ω^k}_{k=0}^{n−1} runs over all n-th roots; products of the form ∏ f(ω^k) are independent of the chosen ω.\n",
695 |       "  - Factor polynomials in terms of linear factors at convenient complex numbers and use\n",
696 |       "    ∏_{k=0}^{n−1} (a − ω^k) = a^n − 1.\n",
697 |       "    Example: for f(x) = x^2 − 2x + 2 = (x − (1+i))(x − (1−i)),\n",
698 |       "    ∏_{k=0}^{n−1} f(ω^k) = ((1+i)^n − 1)((1−i)^n − 1).\n",
699 |       "  - Use polar form for fast powers: (1 ± i) = √2 e^{±iπ/4}, so (1 ± i)^n = (√2)^n e^{±inπ/4}. Magnitude-squared yields clean integers like 65^2 + 64^2.\n",
700 |       "  - Reduce modulo as requested at the end.\n",
701 |       "- For counting rectangles in a regular polygon:\n",
702 |       "  - Rectangles correspond to choosing two perpendicular direction classes of chords (there are 6 distinct directions in a regular dodecagon).\n",
703 |       "  - Do careful casework by slope/direction classes. Typical split for a regular 12-gon: directions at 0°, 30°, 60° (and their perpendiculars), and directions at 15°, 45°, 75°. Count pairs of parallel chords in each case using combinatorial counts (often via binomial coefficients) and inclusion–exclusion to avoid double counting.\n",
704 |       "  - Do not assume only axis-aligned (or diameter-based) rectangles; many rectangles have sides along diagonals.\n",
705 |       "\n",
706 |       "Quality checks:\n",
707 |       "- Avoid overcounting; use inclusion–exclusion where overlaps occur.\n",
708 |       "- Prefer exact algebraic expressions; avoid rounding mid-solution.\n",
709 |       "- If a cleaner identity or symmetry shortcut exists, use it.\n",
710 |       "- The final line under ### answer must be only the final value/expression (e.g., 242 or 321), with no extra text.\n",
711 |       "2025/08/12 22:08:01 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
712 |       "2025/08/12 22:08:01 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New subsample score is not better, skipping\n",
713 |       "2025/08/12 22:08:01 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Selected program 1 score: 0.4222222222222222\n",
714 |       "Average Metric: 2.00 / 3 (66.7%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [03:16<00:00, 65.66s/it]\n",
715 |       "2025/08/12 22:11:18 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
716 |       "\n",
717 |       "2025/08/12 22:12:39 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Proposed new text for predict: You will be given a single math problem as plain text under an input key like “problem.” Your task is to solve it correctly and return:\n",
718 |       "\n",
719 |       "- reasoning: a concise, logically ordered solution that uses appropriate identities/constraints to minimize brute force and ends with a quick verification.\n",
720 |       "- answer: the final result only (just the number or expression requested, no extra words).\n",
721 |       "\n",
722 |       "Formatting:\n",
723 |       "- Use two top-level fields exactly named “reasoning” and “answer.”\n",
724 |       "- Keep the reasoning succinct but complete. Avoid heavy markup. Bullet points are fine.\n",
725 |       "- The answer field must contain only the final value requested (e.g., 227, 585, 601).\n",
726 |       "\n",
727 |       "General problem-solving guidance:\n",
728 |       "- Parse the problem type (e.g., base representation, palindromes across bases, symmetric sums under constraints, combinatorics with “exactly k,” geometry with slices/planes, 3D vector setups).\n",
729 |       "- Always enforce domain constraints (e.g., base-b digits ∈ {0,…,b−1}, no leading zero for a base-10 three-digit number, sphere radii > 0, lengths/areas/volumes ≥ 0, ordered vs unordered if counting).\n",
730 |       "- Use algebraic identities and modular arithmetic to reduce the search space and ensure correctness.\n",
731 |       "- Prefer structure/symmetry and key constraints over coordinate bash; introduce coordinates/vectors only when they simplify.\n",
732 |       "\n",
733 |       "Domain-specific strategies and identities:\n",
734 |       "\n",
735 |       "1) Base-conversion/digit rearrangement:\n",
736 |       "- Translate positional notation correctly:\n",
737 |       "  • Base 10: abc = 100a + 10b + c.\n",
738 |       "  • Base b: (x y z)_b = x·b^2 + y·b + z.\n",
739 |       "- Enforce digit bounds: in base 9, digits are 0..8; if also a base-10 three-digit integer, leading digit 1..9 and ≤ base-9 max digit ⇒ a ∈ {1,…,8}.\n",
740 |       "- Set up equality and simplify. Use modular constraints to prune:\n",
741 |       "  • Mod 9: reduce coefficients to constrain sums like b + c ≡ 0 (mod 9).\n",
742 |       "  • Mod 8 (or others): reduce to get congruences between digits.\n",
743 |       "\n",
744 |       "2) Palindromes across bases:\n",
745 |       "- Bound the number of digits from magnitude (e.g., n < 1000 ⇒ octal has 3–4 digits).\n",
746 |       "- Characterize palindromes:\n",
747 |       "  • 3-digit base-8: (A B A)_8 = 65A + 8B.\n",
748 |       "  • 4-digit base-8: (A B B A)_8 = 513A + 72B.\n",
749 |       "- For 4-digit octal palindrome < 1000, A must be 1. Enumerate B ∈ {0,…,7}, test decimal-palindrome property, and pick the greatest/least as required.\n",
750 |       "\n",
751 |       "3) Symmetric sums with a + b + c fixed (ordered triples of nonnegative integers):\n",
752 |       "- Use identities to collapse symmetric expressions:\n",
753 |       "  • S = Σ a^2b + a^2c + … = (a + b + c)(ab + bc + ca) − 3abc.\n",
754 |       "- With a + b + c given (e.g., 300), convert to a linear relation in (ab + bc + ca) and abc.\n",
755 |       "- Apply the shift a = m + x, b = m + y, c = m + z with x + y + z = 0 to factor:\n",
756 |       "  • (a − m)(b − m)(c − m) = abc − m(ab + bc + ca) + 2m^3 − m^3 = abc − m(ab + bc + ca) + m^3.\n",
757 |       "- Use the given constants to force one factor zero and count ordered solutions carefully:\n",
758 |       "  • Count cases where exactly one equals m and the others sum appropriately (excluding double-counts), plus the all-equal case once.\n",
759 |       "  • Treat triples as ordered unless the problem states otherwise.\n",
760 |       "\n",
761 |       "4) Sets with “exactly k” owners (inclusion-exclusion, baseline item owned by all):\n",
762 |       "- Let x1, x2, x3, x4 be counts of residents owning exactly 1, 2, 3, 4 of the given sets.\n",
763 |       "- Everyone owning a baseline item (e.g., candy hearts) still counts toward the “k of four” totals; do not drop it.\n",
764 |       "- Use:\n",
765 |       "  • x1 + x2 + x3 + x4 = N (total people),\n",
766 |       "  • Sum of set sizes = 1·x1 + 2·x2 + 3·x3 + 4·x4.\n",
767 |       "- Plug given x2, x3 (if provided) and total set counts to solve a small linear system for x4 (owners of all four).\n",
768 |       "\n",
769 |       "5) Spheres intersected by a plane (congruent circle sections, mutually tangent spheres):\n",
770 |       "- Mutually externally tangent spheres with radii R_i have center distances R_i + R_j.\n",
771 |       "- If a plane intersects spheres in congruent circles of radius r, and the perpendicular distances from centers to the plane are h_i, then:\n",
772 |       "  • r^2 = R_i^2 − h_i^2 for each sphere i (constant r across all).\n",
773 |       "  • For projections A, B, C of the centers onto the plane, the in-plane squared distances satisfy:\n",
774 |       "    |A_iA_j|^2 = |O_iO_j|^2 − (h_i − h_j)^2,\n",
775 |       "    hence |O_iO_j|^2 = |A_iA_j|^2 + (h_i − h_j)^2.\n",
776 |       "- Use AB^2 (in-plane) and known |O_iO_j| = R_i + R_j to get (h_i − h_j)^2, then solve for r^2 via R_i^2 − h_i^2 = constant. Verify by computing the target in-plane distance with |O_iO_k|^2 − (h_i − h_k)^2.\n",
777 |       "\n",
778 |       "6) Tilted cube, vertex heights, and a horizontal water plane:\n",
779 |       "- If the problem specifies a set of vertices with given heights above a fixed horizontal plane, and a specific rectangle/plane (e.g., ABDC) is perpendicular to the horizontal plane, exploit this geometry:\n",
780 |       "  • The height function over the cube is linear along cube edges.\n",
781 |       "  • First, find the side length s using robust constraints:\n",
782 |       "    - Face diagonals have length s√2; space diagonal s√3; edges length s.\n",
783 |       "    - Use similarity or slope along lines within the stated perpendicular face/rectangle (e.g., compare vertical rises along an edge vs along a face diagonal) to solve for s before proceeding.\n",
784 |       "  • Water volume at height H equals the volume below the horizontal plane z = H within the cube. Two reliable approaches:\n",
785 |       "    A) Frustum method (when two parallel cross-sections are similar):\n",
786 |       "       - If the complement above/below forms a prismatic frustum between two parallel planes cutting similar cross-sections (e.g., squares cut along a face direction), use:\n",
787 |       "         V_frustum = (h/3)·(S1 + √(S1 S2) + S2),\n",
788 |       "         where h is the distance between the planes (measured along the line perpendicular to the planes within the prism), and S1, S2 are the areas of the parallel cross-sections. Linear dimensions along a given straight direction scale linearly with height; areas scale with the square of that ratio.\n",
789 |       "       - Cube water volume = total cube volume − frustum volume (or vice versa), whichever is simpler.\n",
790 |       "    B) Linear-inequality integration over a unit cube:\n",
791 |       "       - Represent any point as A + u·e1 + v·e2 + w·e3 with u,v,w ∈ [0,1], where e1,e2,e3 are orthogonal edges of length s. The height is z = z0 + a u + b v + c w (linear).\n",
792 |       "       - To compute volume where z ≤ H, integrate over {u,v,w ∈ [0,1]: a u + b v + c w ≤ t} and multiply by s^3. If some coefficients are negative, perform a variable flip (e.g., u' = 1 − u converts coefficient sign and shifts t) to reduce to all-positive coefficients or use the complement region.\n",
793 |       "       - Partition the (u,v) domain by the line a u + b v = thresholds to integrate piecewise. Ensure the final volume is between 0 and s^3.\n",
794 |       "  • Sanity checks:\n",
795 |       "    - s must be determined consistently from the geometry (e.g., in a classic configuration, s = 6).\n",
796 |       "    - Cross-section areas and volumes must be nonnegative and not exceed bounding values.\n",
797 |       "    - If an attempted coordinate labeling yields contradictions (e.g., heights inconsistent with linearity), reconsider the assignment order or use a different method (similar triangles/frustum).\n",
798 |       "\n",
799 |       "Quality checks:\n",
800 |       "- Verify digit/base constraints and final equalities numerically.\n",
801 |       "- For “greatest/least” questions, justify optimality by bounding or short enumeration.\n",
802 |       "- For counting, avoid over/undercounting; be explicit about ordered vs unordered.\n",
803 |       "- For geometry, check intermediate values (e.g., differences of heights, r^2, s) and plausibility (lengths/areas/volumes ≥ 0, within expected ranges).\n",
804 |       "- End with a quick numeric verification plugging back into the original relation.\n",
805 |       "\n",
806 |       "Finally:\n",
807 |       "- Place the clean final numeric result in the “answer” field.\n",
808 |       "2025/08/12 22:14:20 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
809 |       "2025/08/12 22:14:20 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New subsample score is not better, skipping\n",
810 |       "2025/08/12 22:14:20 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Selected program 0 score: 0.37777777777777777\n",
811 |       "Average Metric: 2.00 / 3 (66.7%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:36<00:00, 52.14s/it]\n",
812 |       "2025/08/12 22:16:56 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
813 |       "\n",
814 |       "2025/08/12 22:18:15 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Proposed new text for predict: Instructions for solving and formatting contest-style math problems:\n",
815 |       "\n",
816 |       "1) Read the prompt carefully and determine exactly what to compute and how the answer must be reported.\n",
817 |       "   - If the problem asks for r^2 = p/q with p, q relatively prime and asks for p+q, return the integer p+q.\n",
818 |       "   - If it asks for a probability m/n in lowest terms and then m+n, return that integer.\n",
819 |       "   - If it asks for a single count, return that integer.\n",
820 |       "   - Always reduce fractions to lowest terms before extracting p+q or m+n.\n",
821 |       "   - Provide the final answer exactly in the requested format (usually a single integer). Keep any reasoning concise if shown; ensure the final line is the answer only.\n",
822 |       "\n",
823 |       "2) General problem-solving practices:\n",
824 |       "   - Translate given conditions into equations/constraints and identify what quantity should be maximized or minimized. Be precise about “for each” vs “exists” and “contains every” vs “contains a specific.”\n",
825 |       "   - Use symmetry to reduce variables when optimizing (extrema for symmetric constraints often occur when two variables are equal).\n",
826 |       "   - For boxes/spheres: for a rectangular box with edges x, y, z, the sphere that contains it must have radius at least half the space diagonal: r = sqrt(x^2 + y^2 + z^2)/2. Surface area SA = 2(xy + yz + zx). Volume V = xyz.\n",
827 |       "     • If asked for the smallest sphere that can contain every box in a set defined by constraints, you must maximize the required radius over that feasible set (worst case), not minimize it.\n",
828 |       "     • With fixed S2 = xy + yz + zx and S3 = xyz, note x^2 + y^2 + z^2 = (x + y + z)^2 − 2S2, so maximizing the diagonal corresponds to maximizing S1 = x + y + z. At extrema under symmetric constraints, set two variables equal (e.g., y = z) to reduce to one variable and solve (Lagrange multipliers or symmetry argument). Use Rational Root Theorem when a cubic arises. Select the root that actually maximizes the target.\n",
829 |       "   - For parity-based arrangement problems with pairs of identical items:\n",
830 |       "     • “Even number of items between identical colors” means the two copies occupy positions of opposite parity (one odd, one even).\n",
831 |       "     • If there are k colors with two copies each and positions 1..2k, count valid arrangements by: (i) pairing each odd position with an even position (k! ways), and (ii) assigning colors to the k pairs (k! ways). Total valid = (k!)^2. Total permutations with duplicates = (2k)! / (2!)^k. Simplify the resulting probability fully before computing m+n.\n",
832 |       "   - For grid/monochromatic row-column constraints with maximality:\n",
833 |       "     • “All chips in the same row and all chips in the same column have the same color” implies the grid is determined by sets of white rows W_r and white columns W_c: all cells in W_r × W_c are white; all cells in the complementary set of rows and columns B_r × B_c are black; the cross rectangles W_r × B_c and B_r × W_c must be empty to keep row/column uniformity.\n",
834 |       "     • “Any additional chip would violate” (maximality) rules out having both some empty rows and some empty columns simultaneously where their intersection would admit a valid placement. A clean equivalent counting for a 5×5 grid is:\n",
835 |       "       - Choose rows and columns occupied by white chips as any nonempty, not-all subsets: (2^5 − 2) choices for rows and (2^5 − 2) for columns. This yields (2^5 − 2)^2 configurations with both colors present.\n",
836 |       "       - Add 2 for the all-white and all-black full boards. The empty board is disallowed by “some chips.”\n",
837 |       "       - For 5×5, the total is (32 − 2)^2 + 2 = 900 + 2 = 902.\n",
838 |       "     • Chips are indistinguishable; once W_r and W_c are fixed, the configuration is uniquely determined.\n",
839 |       "\n",
840 |       "3) Algebraic care and verification:\n",
841 |       "   - Keep track of whether you are maximizing or minimizing; re-check interpretations like “smallest sphere that can contain each box” (maximize over the set) vs “for a given box” (minimize for that box).\n",
842 |       "   - When radicals appear but the problem expects a rational r^2, express r^2 directly from symmetric sums if possible to avoid unnecessary radicals.\n",
843 |       "   - Rationalize and reduce fractions; ensure p and q are coprime before summing.\n",
844 |       "   - Sanity-check candidate extrema numerically to ensure you selected the correct root (e.g., larger S1 for maximizing diagonal).\n",
845 |       "\n",
846 |       "4) Output formatting:\n",
847 |       "   - End with only the requested final answer (e.g., a single integer), with no extra text.\n",
848 |       "2025/08/12 22:18:35 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
849 |       "2025/08/12 22:18:35 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New subsample score is not better, skipping\n",
850 |       "2025/08/12 22:18:35 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Selected program 1 score: 0.4222222222222222\n",
851 |       "Average Metric: 0.00 / 3 (0.0%): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:27<00:00,  9.33s/it]\n",
852 |       "2025/08/12 22:19:03 INFO dspy.evaluate.evaluate: Average Metric: 0.0 / 3 (0.0%)\n",
853 |       "\n",
854 |       "2025/08/12 22:20:52 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Proposed new text for predict: You will be given one math problem as plain text under a key like “problem.” Your job is to solve it correctly and return:\n",
855 |       "\n",
856 |       "- reasoning: a concise, logically ordered solution that uses identities/structure to avoid brute force, ends with a quick verification.\n",
857 |       "- answer: the final requested number/expression only (no extra words).\n",
858 |       "\n",
859 |       "Formatting:\n",
860 |       "- Use exactly two top-level fields named “reasoning” and “answer.”\n",
861 |       "- Keep reasoning succinct but complete. Bullet points are fine.\n",
862 |       "- The answer field must contain only the final value requested (e.g., 227, 585, 601).\n",
863 |       "\n",
864 |       "General problem-solving guidance:\n",
865 |       "- Parse the problem type (e.g., base representation, intersecting families of subsets, avoiding arithmetic progressions, symmetric sums with constraints, ordered tuples counting).\n",
866 |       "- Always enforce domain constraints (e.g., base-b digits in 0..b−1; no leading zero for base-10 “three-digit”; ordered vs unordered families; strict increase conditions in sequences).\n",
867 |       "- Use algebraic identities and modular arithmetic to reduce the search space; prefer structural arguments over naive enumeration.\n",
868 |       "- For “greatest/least” questions, derive tight bounds and give a construction that attains them.\n",
869 |       "\n",
870 |       "Domain-specific strategies and pitfalls (learned from typical contest problems and prior feedback):\n",
871 |       "\n",
872 |       "1) Base-conversion/digit rearrangement:\n",
873 |       "- Translate positional notation correctly: in base b, (a b c)_b = a·b^2 + b·b + c; in base 10: abc = 100a + 10b + c.\n",
874 |       "- Enforce digit ranges strictly (e.g., in base 9, digits ∈ {0,…,8}; if also a is a base-10 leading digit, then a ∈ {1,…,8}).\n",
875 |       "- Set up equality and simplify. Use modular constraints to prune:\n",
876 |       "  • Mod 9 often collapses coefficients; e.g., 99a = 71b + 8c ⇒ mod 9 gives b + c ≡ 0 (mod 9).\n",
877 |       "  • Mod 8: 99 ≡ 3, 71 ≡ 7 ⇒ 3a ≡ 7b (mod 8) ⇒ b ≡ −3a (mod 8).\n",
878 |       "- Solve within digit bounds and verify numerically.\n",
879 |       "\n",
880 |       "2) Palindromes across bases:\n",
881 |       "- Bound the base length by magnitude (e.g., n < 1000 ⇒ octal has 3–4 digits).\n",
882 |       "- Characterize palindromes:\n",
883 |       "  • 3-digit octal: (A B A)_8 = 65A + 8B.\n",
884 |       "  • 4-digit octal: (A B B A)_8 = 513A + 72B (with A ≥ 1).\n",
885 |       "- Enumerate small parameter ranges and test the other-base palindrome constraint. For “greatest”, check candidates in descending order with justification.\n",
886 |       "\n",
887 |       "3) Symmetric sums with a + b + c fixed (ordered triples of nonnegative integers):\n",
888 |       "- Use identities to compress expressions:\n",
889 |       "  S = ab(a + b) + bc(b + c) + ca(c + a) = (a + b + c)(ab + bc + ca) − 3abc.\n",
890 |       "- With a + b + c known (e.g., 300), convert the given sum into a relation among ab + bc + ca and abc.\n",
891 |       "- Use the shift a = A + x etc. to isolate a product like (a−A)(b−A)(c−A) and deduce factorization constraints, enabling clean counting.\n",
892 |       "- Count ordered solutions carefully; include/exclude symmetric/degenerate cases precisely.\n",
893 |       "\n",
894 |       "4) Intersecting families of subsets (collections from the power set):\n",
895 |       "- Intersecting means every pair has nonempty intersection. The empty set cannot be included.\n",
896 |       "- Complement pairs: S and S^c cannot both be present. Use this to structure counts.\n",
897 |       "- Use size-based pigeonhole facts: In [n], any two subsets of size > n/2 must intersect. For n = 5, any two subsets of size ≥ 3 intersect; thus “all subsets of size ≥ 3” is an intersecting family (size 16).\n",
898 |       "- Do not assume that “stars” (all subsets containing a fixed element) are the only intersecting families of maximum size. For odd n, both the star and “all subsets of size > n/2” have size 2^{n−1}.\n",
899 |       "- When counting collections of a fixed size:\n",
900 |       "  • Consider the minimum set size N in the family and do casework on how many 2-element sets are included (for n=5), as these control which 3-sets must be excluded (complements).\n",
901 |       "  • Ensure completeness of cases and avoid double counting by parameterizing canonical patterns (e.g., how many 2-sets, how they overlap, whether they share a common element).\n",
902 |       "  • Remember order of subsets in a collection does not matter; count distinct families.\n",
903 |       "\n",
904 |       "5) Avoiding 4-term arithmetic progressions in a strictly increasing sequence with fixed anchors:\n",
905 |       "- First bound the variable terms by strict increase (e.g., if fixed terms are 3,4,5,...,30,40,50 then 6 ≤ a < b ≤ 29).\n",
906 |       "- Pre-eliminate values that cause a 4-term AP with three fixed terms:\n",
907 |       "  • 3,4,5,a forbids a = 6.\n",
908 |       "  • b,30,40,50 forbids b = 20.\n",
909 |       "  • Similarly, a,30,40,50 forbids a = 20.\n",
910 |       "- Start with the count of pairs from allowed values and then subtract specific pairs that complete APs with two fixed endpoints:\n",
911 |       "  • 3,5,a,b ⇒ (a,b) = (7,9).\n",
912 |       "  • 3,a,b,30 ⇒ (a,b) = (12,21).\n",
913 |       "  • 4,a,b,40 ⇒ (a,b) = (16,28).\n",
914 |       "  • 5,a,b,50 ⇒ (a,b) = (20,35) but may be outside bounds or pre-excluded (e.g., 20 banned).\n",
915 |       "- Systematically check all endpoint combinations; use the fact that if endpoints differ by Δ, then Δ must be divisible by 3 for a 4-term AP, and solve for integer a,b within bounds.\n",
916 |       "- Avoid double subtraction; ensure monotonicity and domain constraints are respected.\n",
917 |       "\n",
918 |       "6) Order statistics with sum and absolute-sum constraints (e.g., x_1 ≤ ... ≤ x_n, sum |x_i| = 1, sum x_i = 0):\n",
919 |       "- Total positive mass equals total negative mass: both = 1/2.\n",
920 |       "- For maximizing x_k (k near the top): if there are T largest terms from k to n (T = n − k + 1), then sum of these T terms ≥ T·x_k. Since the total positive mass ≤ 1/2, we get x_k ≤ (1/2)/T.\n",
921 |       "- For minimizing x_l (l near the bottom): if there are l smallest terms, sum of these l terms ≤ l·x_l. Since the total negative mass is −1/2, we get x_l ≥ (−1/2)/l.\n",
922 |       "- To attain these bounds, concentrate masses evenly on exactly those positions: set the smallest l terms equal to −1/(2l), the largest T terms equal to 1/(2T), and the middle to 0 (respecting monotonicity). Verify sums and absolute sums.\n",
923 |       "- Example: For n=100, maximize x_76 − x_16: T = 25 ⇒ x_76 ≤ 1/50; l = 16 ⇒ x_16 ≥ −1/32; construction with 16 negatives at −1/32, 59 zeros, 25 positives at 1/50 attains 1/50 − (−1/32) = 41/800.\n",
924 |       "\n",
925 |       "Quality checks:\n",
926 |       "- Verify digit/base constraints and final equalities numerically if applicable.\n",
927 |       "- For extremal problems, provide both a tight bound and an explicit construction achieving it.\n",
928 |       "- For counting, explicitly handle ordered vs unordered, exclude impossible/duplicate cases, and check complements/forbidden pairs.\n",
929 |       "- For AP-avoidance, confirm integrality and bounds; ensure no missed endpoint combinations.\n",
930 |       "- For “greatest/least” questions, justify optimality structurally (e.g., convexity/majorization/pigeonhole).\n",
931 |       "\n",
932 |       "Finally:\n",
933 |       "- Put the clean final numeric result in the “answer” field only.\n",
934 |       "2025/08/12 22:21:18 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
935 |       "2025/08/12 22:23:54 INFO dspy.evaluate.evaluate: Average Metric: 24.0 / 45 (53.3%)\n",
936 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New program is on the linear pareto front\n",
937 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full valset score for new program: 0.5333333333333333\n",
938 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full train_val score for new program: 0.5333333333333333\n",
939 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Individual valset scores for new program: [0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
940 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New valset pareto front scores: [0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
941 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full valset pareto front score: 0.6222222222222222\n",
942 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Updated valset pareto front programs: [{0, 1, 2}, {0, 1}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {0, 1}, {0, 2}, {0, 1, 2}, {0, 1, 2}, {0, 2}, {0, 1, 2}, {0, 1, 2}, {2}, {2}, {0, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {2}, {0, 1, 2}, {1}, {1, 2}, {2}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0, 1, 2}, {0}, {0, 1, 2}]\n",
943 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best valset aggregate score so far: 0.5333333333333333\n",
944 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best program as per aggregate score on train_val: 2\n",
945 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best program as per aggregate score on valset: 2\n",
946 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best score on valset: 0.5333333333333333\n",
947 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best score on train_val: 0.5333333333333333\n",
948 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Linear pareto front program index: 2\n",
949 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New program candidate index: 2\n",
950 |       "2025/08/12 22:23:54 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Selected program 1 score: 0.4222222222222222\n",
951 |       "Average Metric: 3.00 / 3 (100.0%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:20<00:00,  6.84s/it]\n",
952 |       "2025/08/12 22:24:14 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
953 |       "2025/08/12 22:24:14 INFO dspy.teleprompt.gepa.gepa: Iteration 6: All subsample scores perfect. Skipping.\n",
954 |       "2025/08/12 22:24:14 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Reflective mutation did not propose a new candidate\n",
955 |       "2025/08/12 22:24:14 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Selected program 2 score: 0.5333333333333333\n",
956 |       "\n",
957 |       "Average Metric: 1.00 / 3 (33.3%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:10<00:00, 23.53s/it]\n",
958 |       "2025/08/12 22:25:25 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
959 |       "\n",
960 |       "2025/08/12 22:27:47 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Proposed new text for predict: You will be given one math problem as plain text under a key like “problem.” Your job is to solve it correctly and return:\n",
961 |       "\n",
962 |       "- reasoning: a concise, logically ordered solution that uses identities/structure to avoid brute force, ends with a quick verification.\n",
963 |       "- answer: the final requested number/expression only (no extra words).\n",
964 |       "\n",
965 |       "Formatting:\n",
966 |       "- Use exactly two top-level fields named “reasoning” and “answer.”\n",
967 |       "- Keep reasoning succinct but complete. Bullet points are fine.\n",
968 |       "- The answer field must contain only the final value requested (e.g., 227, 585, 601).\n",
969 |       "\n",
970 |       "General problem-solving guidance:\n",
971 |       "- Parse the problem type (e.g., base representation, intersecting families of subsets, avoiding arithmetic progressions, symmetric sums with constraints, ordered tuples counting, classical Euclidean geometry with circles, secants/tangents).\n",
972 |       "- Always enforce domain constraints (digits in range, no leading zeros, ordered vs unordered, strict increases, segment/angle/parallel/perpendicular statements).\n",
973 |       "- Use algebraic identities and modular arithmetic to reduce the search space; prefer structural arguments over naive enumeration.\n",
974 |       "- For “greatest/least” questions, derive tight bounds and give a construction that attains them.\n",
975 |       "- Prefer classic geometry tools (power of a point, radical axis, homothety, parallelogram/rectangle characterizations, Apollonius/Stewart, cyclic angle/arc relations) over coordinate bashes unless necessary.\n",
976 |       "\n",
977 |       "Domain-specific strategies and pitfalls:\n",
978 |       "\n",
979 |       "1) Base-conversion/digit rearrangement:\n",
980 |       "- Translate positional notation correctly: in base b, (a b c)_b = a·b^2 + b·b + c; in base 10: abc = 100a + 10b + c.\n",
981 |       "- Enforce digit ranges strictly (e.g., in base 9, digits ∈ {0,…,8}; base-10 three-digit means a ∈ {1,…,9}).\n",
982 |       "- Use modular constraints to prune:\n",
983 |       "  • Example: 99a = 71b + 8c ⇒ mod 9 gives b + c ≡ 0 (mod 9).\n",
984 |       "  • Mod 8: 99 ≡ 3, 71 ≡ 7 ⇒ 3a ≡ 7b (mod 8) ⇒ b ≡ −3a (mod 8).\n",
985 |       "- Solve within digit bounds and verify numerically.\n",
986 |       "\n",
987 |       "2) Palindromes across bases:\n",
988 |       "- Bound the base length by magnitude (e.g., n < 1000 ⇒ octal has 3–4 digits).\n",
989 |       "- Characterize palindromes:\n",
990 |       "  • 3-digit octal: (A B A)_8 = 65A + 8B.\n",
991 |       "  • 4-digit octal: (A B B A)_8 = 513A + 72B (with A ≥ 1).\n",
992 |       "- Enumerate small parameter ranges and test the other-base palindrome constraint. For “greatest”, check candidates in descending order with justification.\n",
993 |       "\n",
994 |       "3) Symmetric sums with a + b + c fixed:\n",
995 |       "- Compress via identities:\n",
996 |       "  S = ab(a + b) + bc(b + c) + ca(c + a) = (a + b + c)(ab + bc + ca) − 3abc.\n",
997 |       "- With a + b + c known, convert into a relation among ab + bc + ca and abc.\n",
998 |       "- Use shifts (a = A + x, etc.) to isolate products like (a−A)(b−A)(c−A), enabling clean counting.\n",
999 |       "- Count ordered solutions carefully; handle symmetric/degenerate cases precisely.\n",
1000 |       "\n",
1001 |       "4) Intersecting families of subsets:\n",
1002 |       "- Intersecting ⇒ every pair has nonempty intersection; empty set excluded.\n",
1003 |       "- Complement pairs: S and S^c cannot both be present.\n",
1004 |       "- Size-based facts: In [n], any two subsets of size > n/2 intersect. For n = 5, all subsets of size ≥ 3 is intersecting (size 16).\n",
1005 |       "- When counting fixed-size families:\n",
1006 |       "  • Casework on minimal set size; 2-sets often control exclusions of complementary 3-sets (for n=5).\n",
1007 |       "  • Avoid double counting by parameterizing canonical overlap patterns.\n",
1008 |       "  • Collections are sets of sets (order doesn’t matter).\n",
1009 |       "\n",
1010 |       "5) Avoiding 4-term arithmetic progressions with fixed anchors:\n",
1011 |       "- Bound variable terms by strict increase.\n",
1012 |       "- Pre-eliminate values completing APs with three fixed terms (e.g., 3,4,5,a forbids a=6).\n",
1013 |       "- Count allowed pairs then subtract those completing APs with two fixed endpoints; use Δ divisible by 3 for 4-term APs.\n",
1014 |       "- Ensure integrality, bounds, and no double subtraction.\n",
1015 |       "\n",
1016 |       "6) Order statistics with sum and absolute-sum constraints:\n",
1017 |       "- Total positive mass = total negative mass = 1/2.\n",
1018 |       "- Bound x_k via T = n−k+1 largest terms: x_k ≤ (1/2)/T.\n",
1019 |       "- Bound x_l via l smallest terms: x_l ≥ (−1/2)/l.\n",
1020 |       "- Attain bounds by concentrating masses on extremes; verify sums.\n",
1021 |       "\n",
1022 |       "7) Two intersecting circles, common tangent, parallel through intersection (key lemmas):\n",
1023 |       "- Setup: Circles ω1, ω2 intersect at P, Q. Common external tangent closer to P touches ω1 at A and ω2 at B. Line through P parallel to AB meets ω1 (again) at X and ω2 (again) at Y.\n",
1024 |       "- Perpendicular-bisector fact: AO1 ⟂ AB and AO1 ⟂ XY; since AO1 is perpendicular to chord XY in ω1, it bisects chord PX. Thus CP = PX/2, where C = AO1 ∩ XY. Similarly, PD = PY/2 for D = BO2 ∩ XY.\n",
1025 |       "- Rectangle: Because AO1 and BO2 are both perpendicular to AB and XY, ABCD is a rectangle with C on XY and D on XY. Along XY, CD = CP + PD = PX/2 + PY/2. Hence AB = CD = (PX + PY)/2.\n",
1026 |       "- Radical axis: PQ is the radical axis of ω1 and ω2, so the locus of equal tangent lengths. Therefore PQ passes through the midpoint M of AB, and AM = MB = AB/2.\n",
1027 |       "- Tangent–secant at M on ω1: MA^2 = MP · MQ with MQ = MP + PQ. Solve for MP.\n",
1028 |       "- Height of trapezoid XABY: The distance between lines AB and XY equals AC (since AO1 ⟂ both). In right triangle with diagonal MP across the rectangle, AC^2 = MP^2 − (AM − CP)^2. Then area[XABY] = 1/2 · (AB + XY) · AC with XY = AB + (PX + PY)/2.\n",
1029 |       "- Quick numeric template (from PX, PY, PQ): AB = (PX + PY)/2, M on PQ gives MP from MA^2 = MP(MP+PQ), AC from MP and AM, area as above.\n",
1030 |       "\n",
1031 |       "8) Triangle with midpoint on a chord of circumcircle; “unique Q” with equal angles (key lemmas):\n",
1032 |       "- Apollonius/Stewart for median: In any triangle, with M midpoint of BC,\n",
1033 |       "  AM^2 = (AB^2 + AC^2)/2 − (BC^2)/4. For 13–14–15, AM = √148 = 2√37.\n",
1034 |       "- Power of a point at M wrt circumcircle (of ABC): MB·MC = power(M). If line through M meets the circumcircle at A and P (i.e., M lies on AP), then MA·MP = MB·MC ⇒ PM = (MB·MC)/AM. For 13–14–15: MB = MC = 7 ⇒ PM = 49/√148.\n",
1035 |       "- Unique-angle point implies parallelogram: If M is the midpoint of BC and lies on AP (A,P concyclic with ABC), the unique point Q on AM satisfying ∠PBQ = ∠PCQ is the reflection of P across M. Hence M is the midpoint of PQ (QM = PM), and BQCP is a parallelogram (diagonals BC and PQ bisect each other). Then, with PM < AM, Q lies on segment AM and AQ = AM − PM.\n",
1036 |       "- Alternative ratio route (if needed): In cyclic ABCP, ∠BPA = ∠C and ∠CPA = ∠B. From law of sines in triangles BPQ and CPQ with ∠PBQ = ∠PCQ, deduce BQ/sin C = CQ/sin B ⇒ BQ/CQ = AB/AC. Combine with law of cosines for BQ^2 and CQ^2 in terms of AQ and known sides/AM to solve for AQ.\n",
1037 |       "- 13–14–15 quick facts (if needed): Altitude from A to BC is 12, with foot L splitting BC into BL = 5, LC = 9.\n",
1038 |       "\n",
1039 |       "9) Rational “sum of numerator+denominator equal after scaling” (e.g., r and 55r):\n",
1040 |       "- Let r = a/b in lowest terms, d = gcd(55a, b). Then 55r reduces to (55a/d)/(b/d).\n",
1041 |       "- Sum equality: a + b = (55a + b)/d ⇒ a(d − 55) = b(1 − d).\n",
1042 |       "- Since gcd(a,b)=1 and d | 55 and d | b, d ∈ {1,5,11,55}. Test each d, write b = d·k, and solve for a integral and positive; enforce gcd(a,b)=1 to restrict k. Typical resulting solutions: r = 2/25 and r = 5/22; sum is 169/550 (already reduced since 169=13^2 and 550=2·5^2·11).\n",
1043 |       "\n",
1044 |       "Quality checks:\n",
1045 |       "- Verify all geometric constructions/length relations (power of a point, radical axis midpoint, perpendicular bisectors) and that derived points lie on specified segments (e.g., Q ∈ AM).\n",
1046 |       "- Keep radicals exact; avoid rounding. Ensure n in m√n is squarefree; for m/√n, present as stated (do not rationalize unless asked).\n",
1047 |       "- For extremal problems, provide both bound and attaining construction.\n",
1048 |       "- For counting, handle ordered vs unordered carefully; include/exclude degenerate cases.\n",
1049 |       "- For AP-avoidance, confirm integrality and bounds; ensure no missed endpoint combinations.\n",
1050 |       "\n",
1051 |       "Common pitfalls to avoid (seen in prior attempts):\n",
1052 |       "- Unnecessary coordinate bashes in clean geometric configurations; prefer power of a point, radical axis, and symmetry/reflective arguments.\n",
1053 |       "- Guessing parameters numerically; instead, derive exact values via structure.\n",
1054 |       "- Mishandling expression forms (e.g., incorrectly “forcing” m/√n by ad hoc rationalization). Output the exact requested form.\n",
1055 |       "2025/08/12 22:28:03 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
1056 |       "2025/08/12 22:30:10 INFO dspy.evaluate.evaluate: Average Metric: 21.0 / 45 (46.7%)\n",
1057 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Full valset score for new program: 0.4666666666666667\n",
1058 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Full train_val score for new program: 0.4666666666666667\n",
1059 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Individual valset scores for new program: [0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1]\n",
1060 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: New valset pareto front scores: [0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n",
1061 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Full valset pareto front score: 0.7333333333333333\n",
1062 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Updated valset pareto front programs: [{0, 1, 2, 3}, {0, 1, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 2}, {0, 1, 3}, {0, 2, 3}, {0, 1, 2}, {0, 1, 2, 3}, {0, 2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {2}, {2}, {0, 2, 3}, {0, 1, 2, 3}, {1, 2}, {3}, {0, 1, 2, 3}, {1, 2, 3}, {0, 1, 2}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {2}, {0, 1, 2, 3}, {0, 1, 2}, {0, 1, 2, 3}, {2, 3}, {3}, {1}, {1, 2, 3}, {2}, {1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {3}, {3}, {0, 1, 2, 3}, {0}, {3}]\n",
1063 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best valset aggregate score so far: 0.5333333333333333\n",
1064 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best program as per aggregate score on train_val: 2\n",
1065 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best program as per aggregate score on valset: 2\n",
1066 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best score on valset: 0.5333333333333333\n",
1067 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best score on train_val: 0.5333333333333333\n",
1068 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Linear pareto front program index: 2\n",
1069 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 7: New program candidate index: 3\n",
1070 |       "2025/08/12 22:30:10 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Selected program 2 score: 0.5333333333333333\n",
1071 |       "Average Metric: 1.00 / 3 (33.3%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:38<00:00, 32.75s/it]\n",
1072 |       "2025/08/12 22:31:48 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
1073 |       "\n",
1074 |       "2025/08/12 22:33:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Proposed new text for predict: You will be given one math problem as plain text under a key like “problem.” Your job is to solve it correctly and return:\n",
1075 |       "\n",
1076 |       "- reasoning: a concise, logically ordered solution that uses structure/identities to avoid brute force and ends with a quick verification.\n",
1077 |       "- answer: the final requested number/expression only (no extra words).\n",
1078 |       "\n",
1079 |       "Formatting:\n",
1080 |       "- Use exactly two top-level fields named “reasoning” and “answer.”\n",
1081 |       "- Keep reasoning succinct but complete. Bullet points are fine.\n",
1082 |       "- The answer field must contain only the final value requested (e.g., 227, 585, 601).\n",
1083 |       "\n",
1084 |       "General problem-solving guidance:\n",
1085 |       "- Parse the problem type (e.g., base representation, combinatorial configurations with symmetry, coefficient extraction via generating functions, motion with relative velocities).\n",
1086 |       "- Enforce domain constraints (e.g., digit bounds in base problems; “three-digit” means no leading zero; ordered vs unordered; strict increase; geometric constraints).\n",
1087 |       "- Use algebraic identities, modular arithmetic, and symmetry to reduce the search space; prefer structural arguments over naive enumeration.\n",
1088 |       "- For extremal/counting problems, derive tight bounds or clean case structures and justify completeness; for “greatest/least,” give both a bound and a construction.\n",
1089 |       "\n",
1090 |       "Quality checks:\n",
1091 |       "- Verify digit/base constraints and final equalities numerically if applicable.\n",
1092 |       "- For counting with cases, ensure cases are disjoint and exhaustive; check complements/forbidden patterns.\n",
1093 |       "- Avoid unjustified heuristics; keep arithmetic exact (avoid floating approximations when exact values are available).\n",
1094 |       "- Finish with a brief verification (e.g., plug back, check constraints).\n",
1095 |       "\n",
1096 |       "Domain-specific strategies and pitfalls (including lessons from prior feedback):\n",
1097 |       "\n",
1098 |       "A) Rectangles in regular polygons (2-colorings on a regular 2n-gon; e.g., dodecagon):\n",
1099 |       "- Geometry fact: In a regular 2n-gon, a quadrilateral formed by vertices is a rectangle if and only if its two diagonals pass through the center, i.e., it consists of two pairs of opposite vertices.\n",
1100 |       "- For the regular dodecagon (n = 6), partition vertices into 6 opposite pairs. A monochromatic rectangle occurs exactly when there exist two distinct opposite pairs both colored the same color.\n",
1101 |       "- Counting colorings with no monochromatic rectangle reduces to casework on opposite pairs:\n",
1102 |       "  • Case 0: No same-colored opposite pair (each pair has one red and one blue): 2^6.\n",
1103 |       "  • Case 1: Exactly one same-colored opposite pair (choose the pair 6 ways, choose its color 2 ways; remaining 5 pairs opposite-colored): 6·2·2^5.\n",
1104 |       "  • Case 2: Exactly two same-colored opposite pairs, but of different colors (choose the red pair 6 ways and the blue pair 5 ways; remaining 4 pairs opposite-colored): 6·5·2^4.\n",
1105 |       "  • Any additional same-colored opposite pair forces two of the same color, creating a monochromatic rectangle; hence disallowed.\n",
1106 |       "- Do not incorrectly reduce this to classical “monochromatic rectangle in an m×m grid” Ramsey facts; the structure here is specific to opposite pairs in the 12-gon.\n",
1107 |       "\n",
1108 |       "B) Coefficient extraction for polynomials of the form (x^N − 1)^k / ∏(x^{m_i} − 1) with 0 < x < 1:\n",
1109 |       "- Use x^n − 1 = −(1 − x^n). For 0 < x < 1, expand 1/(1 − x^{m}) as a geometric series; equivalently,\n",
1110 |       "  P(x) = (1 − x^N)^k / ∏(1 − x^{m_i}).\n",
1111 |       "- Expand the numerator via binomial theorem:\n",
1112 |       "  (1 − x^N)^k = ∑_{r=0}^k (−1)^r C(k, r) x^{Nr}.\n",
1113 |       "- The coefficient of x^t in P(x) equals:\n",
1114 |       "  ∑_{r=0}^{⌊t/N⌋} (−1)^r C(k, r) · a_{t − Nr}, where a_s is the number of nonnegative integer solutions to ∑ m_i n_i = s.\n",
1115 |       "  • If t < N, only r = 0 contributes.\n",
1116 |       "- Count a_s by:\n",
1117 |       "  • Modular pruning to constrain variables (e.g., reduce mod primes dividing some m_i but not others to fix residues).\n",
1118 |       "  • LCM structure: if L = lcm(m_i), then s modulo L often isolates a small adjustment term; decompose s = L·q + r and solve the small r-part explicitly.\n",
1119 |       "  • Stars-and-bars after reducing by gcds (e.g., forcing one variable’s congruence class mod a prime).\n",
1120 |       "- Example (as in t = 2022, N = 2310): since 2022 < 2310, only r = 0 contributes. Use modular constraints (e.g., mod 7) to fix one variable’s residue, reduce to a linear equation with equal coefficients, then apply stars-and-bars to get a binomial coefficient (e.g., C(12, 3) = 220).\n",
1121 |       "- Keep all arithmetic exact; avoid unnecessary cyclotomic factorization unless it simplifies the coefficient logic.\n",
1122 |       "\n",
1123 |       "C) Motion in a current (relative velocities; meeting at a point equidistant from two starts):\n",
1124 |       "- Set coordinates with the river as x-axis (east positive), south bank y = 0, north bank y = width W.\n",
1125 |       "- If they aim to a point on the north bank equidistant from their starts, its x-coordinate is the midpoint of the starts: x* = (x1 + x2)/2. If starts are (0,0) and (D,0), target is at (D/2, W).\n",
1126 |       "- Let current be (v_c, 0). Let swimmers’ speeds relative to water be s1, s2. They choose heading vectors so that ground velocity equals path direction.\n",
1127 |       "- Two standard exact methods:\n",
1128 |       "  1) Static-water reduction: If they swim for the same time t and arrive simultaneously, in still water they would both aim at a common point B shifted upstream by v_c·t from the actual target. Distances in still water are s1·t and s2·t. Use Pythagorean relations with horizontal shifts ±v_c·t to form two equations; subtract to solve for D in terms of t, then use vertical distance W to get t and hence D.\n",
1129 |       "     • For example, with speeds 80 and 60, current 14, width 264:\n",
1130 |       "       264^2 + (D/2 − 14t)^2 = (60t)^2,\n",
1131 |       "       264^2 + (D/2 + 14t)^2 = (80t)^2.\n",
1132 |       "       Subtract to get D = 100t; then from the first, solve t (here t = 11/2), giving D exactly (here 550).\n",
1133 |       "  2) Vector components: Let net (ground) velocity components be (±x, y) toward the target. Relative-to-water velocity = ground − current; impose speeds s1, s2 via squared norms to get two equations:\n",
1134 |       "     (x − 14)^2 + y^2 = s2^2 and (x + 14)^2 + y^2 = s1^2; solve for x, y, then t = W / y and D = 2x·t.\n",
1135 |       "- Avoid decimal approximations; keep all values exact.\n",
1136 |       "\n",
1137 |       "D) Other included standard tactics:\n",
1138 |       "1) Base-conversion/digit rearrangement:\n",
1139 |       "   - In base b, (a b c)_b = a·b^2 + b·b + c; digits in 0..b−1; no leading zero for “three-digit” base-10.\n",
1140 |       "   - Use modular constraints to prune digit choices and verify within bounds.\n",
1141 |       "\n",
1142 |       "2) Palindromes across bases:\n",
1143 |       "   - Bound digit lengths; parameterize palindromic forms; test constraints from the other base; for “greatest,” justify by descending search with structure.\n",
1144 |       "\n",
1145 |       "3) Symmetric sums with a + b + c fixed:\n",
1146 |       "   - Use identities like S = (a + b + c)(ab + bc + ca) − 3abc; shift to isolate products; count ordered solutions carefully.\n",
1147 |       "\n",
1148 |       "4) Intersecting families of subsets:\n",
1149 |       "   - Intersecting means every pair intersects; empty set excluded.\n",
1150 |       "   - Use complement pairs structure; size > n/2 pigeonhole facts; count families with careful casework on small-set inclusions.\n",
1151 |       "\n",
1152 |       "5) Avoiding 4-term APs in increasing sequences with anchors:\n",
1153 |       "   - Pre-eliminate values that form APs with fixed terms; count allowed pairs, subtract those completing APs with endpoints; ensure bounds/integrality and no double-subtraction.\n",
1154 |       "\n",
1155 |       "6) Order statistics with sum and absolute-sum constraints:\n",
1156 |       "   - Total positive mass = total negative mass; bound extremes by averaging over slots; construct distributions attaining bounds; verify sums.\n",
1157 |       "\n",
1158 |       "Finally:\n",
1159 |       "- Put the clean final numeric result in the “answer” field only.\n",
1160 |       "2025/08/12 22:33:58 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
1161 |       "2025/08/12 22:36:28 INFO dspy.evaluate.evaluate: Average Metric: 19.0 / 45 (42.2%)\n",
1162 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Full valset score for new program: 0.4222222222222222\n",
1163 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Full train_val score for new program: 0.4222222222222222\n",
1164 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Individual valset scores for new program: [0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
1165 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: New valset pareto front scores: [0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n",
1166 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Full valset pareto front score: 0.7333333333333333\n",
1167 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Updated valset pareto front programs: [{0, 1, 2, 3, 4}, {0, 1, 3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 2}, {0, 1, 3, 4}, {0, 2, 3, 4}, {0, 1, 2, 4}, {0, 1, 2, 3, 4}, {0, 2, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {2}, {2, 4}, {0, 2, 3, 4}, {0, 1, 2, 3, 4}, {1, 2, 4}, {3, 4}, {0, 1, 2, 3, 4}, {1, 2, 3, 4}, {0, 1, 2, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {2}, {0, 1, 2, 3, 4}, {0, 1, 2}, {0, 1, 2, 3, 4}, {2, 3}, {3}, {1, 4}, {1, 2, 3}, {2}, {1, 2, 3}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3, 4}, {3}, {3}, {0, 1, 2, 3, 4}, {0}, {3}]\n",
1168 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Best valset aggregate score so far: 0.5333333333333333\n",
1169 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Best program as per aggregate score on train_val: 2\n",
1170 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Best program as per aggregate score on valset: 2\n",
1171 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Best score on valset: 0.5333333333333333\n",
1172 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Best score on train_val: 0.5333333333333333\n",
1173 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Linear pareto front program index: 2\n",
1174 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 8: New program candidate index: 4\n",
1175 |       "2025/08/12 22:36:28 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Selected program 2 score: 0.5333333333333333\n",
1176 |       "Average Metric: 1.00 / 3 (33.3%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [02:28<00:00, 49.56s/it]\n",
1177 |       "2025/08/12 22:38:57 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
1178 |       "\n",
1179 |       "2025/08/12 22:40:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Proposed new text for predict: Your job: Solve one math problem and return exactly two top-level fields:\n",
1180 |       "- reasoning: a concise, logically ordered solution that leverages structure (identities, modular arithmetic, symmetry) and ends with a quick verification.\n",
1181 |       "- answer: the final requested number/expression only (no extra words or formatting).\n",
1182 |       "\n",
1183 |       "Formatting:\n",
1184 |       "- Use exactly the two fields “reasoning” and “answer.”\n",
1185 |       "- Keep the reasoning succinct but complete; bullet points are fine.\n",
1186 |       "- The answer field must contain only the final value requested (e.g., 227, 585, 601).\n",
1187 |       "\n",
1188 |       "General problem-solving guidance:\n",
1189 |       "- Identify the problem type (e.g., base/digit relations, repeating decimals, palindromes across bases, symmetric sums with fixed totals, intersecting subset families, avoiding arithmetic progressions, order statistics with absolute-sum constraints, floor-sum optimization).\n",
1190 |       "- Enforce domain constraints strictly (digit ranges in base b; no leading zero where prohibited; ordered vs unordered; strictly increasing where specified).\n",
1191 |       "- Prefer structural arguments over brute force: factor, complete squares, use modular arithmetic, apply symmetry/identities, bound and construct extremals.\n",
1192 |       "- For greatest/least questions, derive a tight bound and exhibit a construction attaining it.\n",
1193 |       "- Verify at the end (e.g., plug back into conditions, check mod constraints, count consistency).\n",
1194 |       "\n",
1195 |       "Domain-specific strategies and pitfalls:\n",
1196 |       "\n",
1197 |       "A) Base conversion/digit equations:\n",
1198 |       "- Translate positional notation correctly: (a b c)_b = a·b^2 + b·b + c; in base 10: abc = 100a + 10b + c.\n",
1199 |       "- Enforce digit ranges: in base 9, digits ∈ {0,…,8}; leading decimal digits ∈ {1,…,b−1} if specified.\n",
1200 |       "- Use modular constraints to prune search (e.g., mod 9, mod 8).\n",
1201 |       "- Solve within digit bounds and verify numerically.\n",
1202 |       "\n",
1203 |       "B) Repeating decimals 0.\\overline{abcd} and counting reduced numerators:\n",
1204 |       "- 0.\\overline{abcd} = m/9999 with m ∈ {1,…,9999}, and 9999 = 3^2·11·101.\n",
1205 |       "- Reduced numerator is x = m / gcd(m, 9999). The mapping m → x is not injective across m, so do NOT apply ∑_{d|n} φ(d) = n to count distinct numerators; that identity counts reduced fractions by denominator divisors, not distinct reduced numerators arising from a bounded numerator range.\n",
1206 |       "- Characterize x by existence of a divisor y | 9999 such that y ≥ x and gcd(x, y) = 1 (since m = x·(9999/y) with gcd(x, y) = 1 and m ≤ 9999).\n",
1207 |       "- Count x via casework on divisibility by the primes of 9999 with correct cancellation:\n",
1208 |       "  • Track whether x is divisible by 3, 9, 11, 101 and what remains in the denominator after canceling to keep m ≤ 9999.\n",
1209 |       "  • “3 vs 9” matters: if x is divisible by 3 but not 9, you can cancel one factor of 3; if divisible by 9, you may cancel two.\n",
1210 |       "  • Use inclusion–exclusion over the allowable ranges after dividing 9999 by the canceled factors.\n",
1211 |       "- Example outline (for abcd length 4): Totals break into mutually exclusive cases:\n",
1212 |       "  • gcd(x, 9999) = 1 contributes φ(9999) = 6000 (note: mod-1000 suffices if only remainder asked).\n",
1213 |       "  • x divisible by 3 only (not 9,11,101): count using floor(1111/3) minus multiples of 33 and 303, etc.\n",
1214 |       "  • x divisible by 11 only (not 3,101): analogously with 9999/11 = 909.\n",
1215 |       "  • x divisible by 3 and 11 (not 101): work with 9999/99 = 101.\n",
1216 |       "  • x divisible by 101: often yields 0 due to range constraints.\n",
1217 |       "- Sum cases carefully and reduce modulo as requested. Verify small endpoint counts and complementary exclusions.\n",
1218 |       "\n",
1219 |       "C) Palindromes across bases:\n",
1220 |       "- Bound number of digits by magnitude; characterize k-digit palindromes in base b (e.g., octal 3-digit ABA: 65A + 8B; 4-digit ABBA: 513A + 72B with A ≥ 1).\n",
1221 |       "- Test other-base palindrome constraints for candidates in justified order.\n",
1222 |       "\n",
1223 |       "D) Symmetric sums with a + b + c fixed:\n",
1224 |       "- Use identities to compress expressions, e.g.,\n",
1225 |       "  S = ab(a + b) + bc(b + c) + ca(c + a) = (a + b + c)(ab + bc + ca) − 3abc.\n",
1226 |       "- For counting, use shifts like a = A + x to isolate products and deduce factorization constraints.\n",
1227 |       "\n",
1228 |       "E) Intersecting families of subsets:\n",
1229 |       "- Intersecting means every pair intersects; empty set excluded.\n",
1230 |       "- Complement pairs cannot both be present. For n odd, both a star and “all subsets of size > n/2” have size 2^{n−1}.\n",
1231 |       "- When counting fixed-size collections, case on smallest set sizes and their overlaps; avoid double-counting via canonical patterns.\n",
1232 |       "\n",
1233 |       "F) Avoiding 4-term arithmetic progressions with fixed anchors:\n",
1234 |       "- Restrict variable terms by monotonicity.\n",
1235 |       "- Pre-eliminate values that create 4-term APs with fixed endpoints.\n",
1236 |       "- Count allowed pairs then subtract those forming APs with two endpoints; if endpoints differ by Δ, then Δ must be divisible by 3 for a 4-term AP; solve for integer interior terms within bounds. Avoid double subtraction.\n",
1237 |       "\n",
1238 |       "G) Order statistics with sum and absolute-sum constraints:\n",
1239 |       "- Sum |x_i| = 1, sum x_i = 0 ⇒ total positive mass = total negative mass = 1/2.\n",
1240 |       "- For maximizing x_k, with T = n−k+1 largest positions, x_k ≤ (1/2)/T; for minimizing x_l, x_l ≥ −(1/2)/l.\n",
1241 |       "- Achieve bounds by concentrating masses evenly on those positions; set the rest to 0. Verify sums.\n",
1242 |       "\n",
1243 |       "H) Systems with square-root bilinear forms (e.g., √(2x−xy)+√(2y−xy)=const):\n",
1244 |       "- Factor under roots: √(x(2−y)) + √(y(2−x)).\n",
1245 |       "- Two robust approaches:\n",
1246 |       "  • Algebraic: Let A=1−x, B=1−y, C=1−z; after squaring, obtain identities like\n",
1247 |       "    (AB−1/2)^2 = (1−A^2)(1−B^2), (BC)^2 = (1−B^2)(1−C^2), (AC+1/2)^2 = (1−A^2)(1−C^2),\n",
1248 |       "    which yield relations such as B^2 + C^2 = 1 and lead to a clean evaluation of [(1−x)(1−y)(1−z)]^2 = 1/32.\n",
1249 |       "  • Trig: Set x=2cos^2 α, etc., convert sums to sin(α+β)=k/2, solve angles, and compute the desired product, often reducing to standard trig constants (e.g., 1/32).\n",
1250 |       "- Conclude with exact value and minimal arithmetic.\n",
1251 |       "\n",
1252 |       "I) Sums of floors of quadratic forms with a parameter (e.g., U = ∑⌊(n^2 − na)/5⌋):\n",
1253 |       "- Separate continuous part U' = (1/5)(∑n^2 − a∑n) and fractional correction:\n",
1254 |       "  U = U' − ∑{(n^2 − na)/5}.\n",
1255 |       "- Choose a to minimize |U| by canceling the main term: with N terms, a ≈ (2N+1)/3; for N=2023, a = 1349 exactly makes U' = 0.\n",
1256 |       "- Argue uniqueness: the range constraint (e.g., −1000 < U < 1000) plus the step size |ΔU| = (∑n)/5 when a changes by 1 ensures only that a works.\n",
1257 |       "- Compute the correction via residue cycles:\n",
1258 |       "  • Let r_n be (n^2 − na) mod 5; fractional part is r_n/5.\n",
1259 |       "  • Count residues modulo 5 over 1..N: for N=2023, counts are 405 each for residues 1,2,3 and 404 each for residues 0,4.\n",
1260 |       "  • With a ≡ 4 (mod 5), the pattern r(n) for n ≡ 0,1,2,3,4 is (0,2,1,2,0); sum of fractional parts equals (405·(2+1+2))/5 = 405, hence U = −405.\n",
1261 |       "- Return the requested combination (e.g., a+U) and verify bounds.\n",
1262 |       "\n",
1263 |       "Quality checks:\n",
1264 |       "- Verify digit/base constraints and equalities numerically if applicable.\n",
1265 |       "- For extremal problems, provide both bound and construction achieving it.\n",
1266 |       "- For counting, be explicit about ordered vs unordered and avoid double counting.\n",
1267 |       "- For AP-avoidance, check integrality and bounds for all endpoint combinations.\n",
1268 |       "- For floor sums, ensure residue counts over partial cycles (non-multiples of modulus) are correct.\n",
1269 |       "\n",
1270 |       "Final step:\n",
1271 |       "- Put the clean final numeric result in the “answer” field only. No extra text or formatting.\n",
1272 |       "2025/08/12 22:40:42 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
1273 |       "2025/08/12 22:45:58 INFO dspy.evaluate.evaluate: Average Metric: 16.0 / 45 (35.6%)\n",
1274 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Full valset score for new program: 0.35555555555555557\n",
1275 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Full train_val score for new program: 0.35555555555555557\n",
1276 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Individual valset scores for new program: [0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
1277 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: New valset pareto front scores: [0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1]\n",
1278 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Full valset pareto front score: 0.7555555555555555\n",
1279 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Updated valset pareto front programs: [{0, 1, 2, 3, 4, 5}, {0, 1, 3}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {1, 2}, {0, 1, 3, 4}, {0, 2, 3, 4, 5}, {0, 1, 2, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 2, 4}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {2, 5}, {2, 4}, {0, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {1, 2, 4}, {3, 4}, {0, 1, 2, 3, 4, 5}, {1, 2, 3, 4, 5}, {0, 1, 2, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {2}, {0, 1, 2, 3, 4, 5}, {0, 1, 2}, {0, 1, 2, 3, 4, 5}, {2, 3}, {3}, {1, 4}, {1, 2, 3}, {2}, {1, 2, 3, 5}, {0, 1, 2, 3, 4, 5}, {5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {3}, {3}, {0, 1, 2, 3, 4, 5}, {0}, {3}]\n",
1280 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best valset aggregate score so far: 0.5333333333333333\n",
1281 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best program as per aggregate score on train_val: 2\n",
1282 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best program as per aggregate score on valset: 2\n",
1283 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best score on valset: 0.5333333333333333\n",
1284 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best score on train_val: 0.5333333333333333\n",
1285 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Linear pareto front program index: 2\n",
1286 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 9: New program candidate index: 5\n",
1287 |       "2025/08/12 22:45:58 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Selected program 3 score: 0.4666666666666667\n",
1288 |       "Average Metric: 1.00 / 3 (33.3%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:09<00:00, 23.23s/it]\n",
1289 |       "2025/08/12 22:47:07 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
1290 |       "\n",
1291 |       "2025/08/12 22:49:24 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Proposed new text for predict: You will receive one math problem as plain text under the key “problem.” Solve it and return:\n",
1292 |       "\n",
1293 |       "- reasoning: a concise, logically ordered solution that leverages structure/identities (not brute force), ending with a quick verification.\n",
1294 |       "- answer: the final requested number/expression only (no extra words).\n",
1295 |       "\n",
1296 |       "Formatting:\n",
1297 |       "- Use exactly two top-level fields named “reasoning” and “answer.”\n",
1298 |       "- Keep reasoning succinct but complete; bullet points are fine.\n",
1299 |       "- The answer field must contain only the final value requested (e.g., 227, 585, 601).\n",
1300 |       "\n",
1301 |       "General approach:\n",
1302 |       "- Parse the problem type (e.g., base representation, subset families, AP-avoidance, symmetric sums, ordered tuples, classical Euclidean geometry, polynomial/root structure).\n",
1303 |       "- Enforce domain constraints strictly (digit ranges, no leading zeros, ordered vs unordered, strict increases, integer bounds, segment/angle conditions).\n",
1304 |       "- Use modular arithmetic, algebraic identities, and structure to reduce cases; avoid naive enumeration.\n",
1305 |       "- For extremal problems, prove bounds tight and provide a construction attaining them.\n",
1306 |       "- Prefer classic geometry tools (power of a point, radical axis, homothety, cyclic angle relations, Ptolemy, Stewart/Apollonius, right-triangle/chord/arc formulas) over coordinates unless unavoidable.\n",
1307 |       "- End with a quick verification (substitution/check of conditions).\n",
1308 |       "\n",
1309 |       "Quality checks and common pitfalls:\n",
1310 |       "- Respect integer/divisibility constraints; ensure parameters that represent counts are integers and within bounds.\n",
1311 |       "- For polynomials with integer coefficients: if a monic cubic has two integer roots, the third is also integer (Vieta).\n",
1312 |       "- For “unique solution” conditions, consider multiplicities and all structural cases that yield uniqueness (not just one pattern).\n",
1313 |       "- Keep radicals exact and simplify; ensure squarefree radicands if appropriate.\n",
1314 |       "- When counting, avoid double-counting and handle degenerate/symmetric cases precisely.\n",
1315 |       "\n",
1316 |       "Domain-specific strategies and templates:\n",
1317 |       "\n",
1318 |       "1) Base conversion/digit rearrangements:\n",
1319 |       "- Positional notation: (a b c)_b = a·b^2 + b·b + c; in base 10: abc = 100a + 10b + c.\n",
1320 |       "- Enforce digit ranges (e.g., base 9 digits ∈ {0,…,8}; leading digit ≥ 1 if indicated).\n",
1321 |       "- Use modular constraints to prune and relate digits.\n",
1322 |       "\n",
1323 |       "2) Palindromes across bases:\n",
1324 |       "- Bound number of digits by magnitude in each base.\n",
1325 |       "- Characterize palindromes (e.g., octal 3-digit (A B A)_8 = 65A + 8B; 4-digit (A B B A)_8 = 513A + 72B).\n",
1326 |       "- For “greatest,” test candidates in decreasing order with structural justification.\n",
1327 |       "\n",
1328 |       "3) Symmetric sums with fixed a + b + c:\n",
1329 |       "- Use identities such as S = (a + b + c)(ab + bc + ca) − 3abc.\n",
1330 |       "- Shift variables to isolate symmetric products, e.g., (a−A)(b−A)(c−A), and count/solve cleanly.\n",
1331 |       "\n",
1332 |       "4) Intersecting families of subsets:\n",
1333 |       "- Intersecting ⇒ every pair intersects; empty set excluded.\n",
1334 |       "- Complement pairs cannot both be present.\n",
1335 |       "- Use size-based facts (e.g., in [5], all subsets of size ≥ 3 is intersecting).\n",
1336 |       "- Parameterize by minimal set sizes; avoid double counting.\n",
1337 |       "\n",
1338 |       "5) Avoiding 4-term arithmetic progressions with fixed anchors:\n",
1339 |       "- Maintain strict increase.\n",
1340 |       "- Pre-eliminate values that complete APs with anchored terms.\n",
1341 |       "- Count allowed pairs, then subtract those completing 4-term APs (Δ divisible by 3 consideration).\n",
1342 |       "- Ensure integrality and avoid double subtraction.\n",
1343 |       "\n",
1344 |       "6) Order statistics with sum and absolute-sum constraints:\n",
1345 |       "- Total positive mass = total negative mass = 1/2.\n",
1346 |       "- Bound kth values via concentration on extremes; verify with constructions that attain bounds.\n",
1347 |       "\n",
1348 |       "7) Two intersecting circles with common tangent and parallel through intersection (key lemmas):\n",
1349 |       "- Setup: ω1, ω2 intersect at P,Q; common external tangent touches at A,B. Line through P parallel to AB meets ω1 at X and ω2 at Y.\n",
1350 |       "- Facts: AO1 ⟂ AB and XY, so it bisects chord PX in ω1; similarly for BO2 and PY.\n",
1351 |       "- Rectangle ABCD with C,D on XY; AB = (PX + PY)/2.\n",
1352 |       "- Radical axis PQ passes through midpoint M of AB; AM = MB. Tangent–secant at M on ω1: MA^2 = MP·MQ = MP(MP+PQ). Solve MP, then trapezoid height and area as needed.\n",
1353 |       "\n",
1354 |       "8) Triangle with midpoint on a chord of circumcircle; “unique Q” with equal angles:\n",
1355 |       "- Median length via Apollonius/Stewart.\n",
1356 |       "- Power of a point from the midpoint on the chord through A gives PM = (MB·MC)/AM.\n",
1357 |       "- Unique-angle point Q is reflection of P across M (M is midpoint of PQ); BQCP is a parallelogram; deduce AQ = AM − PM.\n",
1358 |       "\n",
1359 |       "9) Rational “sum equal after scaling” (e.g., r and 55r):\n",
1360 |       "- Let r = a/b in lowest terms; reduce 55r accordingly via d = gcd(55a, b).\n",
1361 |       "- Solve a(d − 55) = b(1 − d) over d ∈ {1,5,11,55}, enforcing coprimality; sum or count as required.\n",
1362 |       "\n",
1363 |       "10) Ratio/crowd problems with added people (bus arrives):\n",
1364 |       "- Let initial total N and adult count A with A/N a given fraction ⇒ N is multiple of denominator, A of numerator.\n",
1365 |       "- After adding T people (e.g., 50), new total N+T must be a multiple of the new denominator.\n",
1366 |       "- If adults on bus = a (0 ≤ a ≤ T), then A + a = new fraction × (N + T). Parameterize N by LCM of denominators; deduce a must be integer in range; minimize/maximize adults as requested. Verify both initial and final ratios.\n",
1367 |       "\n",
1368 |       "11) Cubic polynomials with unique integer m ≠ 2 such that p(m) = p(2) (critical details):\n",
1369 |       "- Let p(x) = x^3 + ax^2 + bx + c with a, b, c in a bounded integer range (e.g., −20…20).\n",
1370 |       "- Consider q(x) = p(x) − p(2), a monic cubic with integer coefficients and q(2) = 0.\n",
1371 |       "- Because q has at least two integer roots (2 and m), the third root is an integer (Vieta).\n",
1372 |       "- “Unique integer m ≠ 2 with p(m)=p(2)” arises in exactly two multiplicity patterns:\n",
1373 |       "  • Case A: q(x) = (x − 2)^2 (x − m), m ≠ 2.\n",
1374 |       "    - Expand: q(x) = x^3 − (m + 4)x^2 + (4 + 4m)x − 4m.\n",
1375 |       "    - Thus p(x) = x^3 + ax^2 + bx + c with:\n",
1376 |       "      a = −(m + 4), b = 4 + 4m, c = −4m + p(2).\n",
1377 |       "    - Coefficient bounds impose |b| ≤ B and |a| ≤ A; typically |4 + 4m| ≤ 20 ⇒ −6 ≤ m ≤ 4; exclude m = 2. For each valid m, c can vary freely over its 41 allowed integer values (since c and p(2) shift together), giving 41 polynomials per m.\n",
1378 |       "  • Case B: q(x) = (x − 2)(x − m)^2, m ≠ 2.\n",
1379 |       "    - Expand: q(x) = x^3 − (2m + 2)x^2 + (m^2 + 4m)x − 2m^2.\n",
1380 |       "    - Thus a = −2m − 2, b = m^2 + 4m, c = p(2) − 2m^2.\n",
1381 |       "    - Coefficient bounds typically yield m ∈ {−6, −5, −4, −3, −2, −1, 0, 1}. Again 41 choices for c per m.\n",
1382 |       "- Alternatively (algebraic route): From p(m) = p(2) and m ≠ 2, divide by (m − 2) to get the quadratic in m:\n",
1383 |       "  m^2 + (a + 2)m + (4 + 2a + b) = 0.\n",
1384 |       "  • Case 1 (one m): discriminant zero ⇒ (a − 2)^2 = 4(4 + b); ensure m ≠ 2; count valid (a, b).\n",
1385 |       "  • Case 2 (two m’s with one equal to 2): enforce m = 2 is a root ⇒ 4a + b + 12 = 0, and exclude the double-root outlier (a, b) = (−6, 12).\n",
1386 |       "  • In both cases, c is free (41 values).\n",
1387 |       "- Whichever route, count both cases and sum; do not forget c contributes an independent factor of 41 when unconstrained by the equality.\n",
1388 |       "\n",
1389 |       "12) Geometry with two externally tangent circles and a third circle Ω through the centers (AIME 2022 II #15 pattern):\n",
1390 |       "- Setup: ω1 ⟂ ω2 externally tangent at T with centers O1, O2 and O1O2 = r1 + r2. Ω passes through O1 and O2 and meets ω2 at A, D and ω1 at B, C. Hexagon ABO1CDO2 is convex with given chord lengths AB and CD.\n",
1391 |       "- Symmetry via reflection: Reflect A, B across the perpendicular bisector of O1O2 to A′, B′ on Ω. Then:\n",
1392 |       "  • Quadrilaterals ABO1O2 and B′A′O2O1 are congruent; hexagons ABO1CDO2 and A′B′O1CDO2 have equal area.\n",
1393 |       "  • A′B′CD is an isosceles trapezoid; also B′D = O1O2 and A′C = O1O2 (often equal to the center distance).\n",
1394 |       "  • Use Ptolemy on cyclic A′B′CD to solve unknown diagonals (e.g., A′D = B′C = √193 when AB = 2, CD = 16, O1O2 = 15), and compute height (often 12) ⇒ area of trapezoid = 1/2 · height · (AB + CD).\n",
1395 |       "  • Radii: let O1C = O2A′ = r1 and O2D = O1B′ = r2, with r1 + r2 = O1O2. From triangle A′O2D and the angle from the trapezoid (e.g., cos = −3/5, sin = 4/5), apply Law of Cosines to get r1r2 (e.g., r1r2 = 40), so area of each triangle A′O1C and B′O2D is (1/2) r1r2 sin(angle) (e.g., 16 each). Sum areas: trapezoid + two triangles (e.g., 108 + 16 + 16 = 140).\n",
1396 |       "- Alternative trig on Ω: Let 2θ = ∠O1OO2, α = ∠OOB, β = ∠OOA. Then O1O2 = 2R sin θ, AB = 2R sin((2θ − α − β)/2), CD = 2R sin((2π − 2θ − α − β)/2). From AB, CD, and O1O2, solve for cos((α+β)/2), sin((α+β)/2), 2R cos θ; then deduce height and areas.\n",
1397 |       "\n",
1398 |       "Verification:\n",
1399 |       "- Substitute/check final values against all given constraints (lengths/ratios/root-counts/uniqueness).\n",
1400 |       "- Ensure coefficient bounds and integrality are satisfied; confirm exclusions (e.g., m ≠ 2).\n",
1401 |       "\n",
1402 |       "Output exactly two fields: “reasoning” and “answer”.\n",
1403 |       "2025/08/12 22:50:00 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
1404 |       "2025/08/12 22:52:15 INFO dspy.evaluate.evaluate: Average Metric: 18.0 / 45 (40.0%)\n",
1405 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full valset score for new program: 0.4\n",
1406 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full train_val score for new program: 0.4\n",
1407 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Individual valset scores for new program: [0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
1408 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New valset pareto front scores: [0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1]\n",
1409 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full valset pareto front score: 0.7777777777777778\n",
1410 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Updated valset pareto front programs: [{0, 1, 2, 3, 4, 5, 6}, {0, 1, 3}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {1, 2}, {0, 1, 3, 4}, {0, 2, 3, 4, 5, 6}, {0, 1, 2, 4, 5, 6}, {6}, {0, 2, 4}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {2, 5, 6}, {2, 4, 6}, {0, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {1, 2, 4, 6}, {3, 4}, {0, 1, 2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {0, 1, 2, 4, 5}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {2}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2}, {0, 1, 2, 3, 4, 5, 6}, {2, 3}, {3}, {1, 4}, {1, 2, 3}, {2}, {1, 2, 3, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {5}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {3}, {3, 6}, {0, 1, 2, 3, 4, 5, 6}, {0}, {3}]\n",
1411 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best valset aggregate score so far: 0.5333333333333333\n",
1412 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best program as per aggregate score on train_val: 2\n",
1413 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best program as per aggregate score on valset: 2\n",
1414 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best score on valset: 0.5333333333333333\n",
1415 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best score on train_val: 0.5333333333333333\n",
1416 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Linear pareto front program index: 2\n",
1417 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New program candidate index: 6\n",
1418 |       "2025/08/12 22:52:15 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Selected program 0 score: 0.37777777777777777\n",
1419 |       "Average Metric: 3.00 / 3 (100.0%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:24<00:00,  8.24s/it]\n",
1420 |       "2025/08/12 22:52:40 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
1421 |       "2025/08/12 22:52:40 INFO dspy.teleprompt.gepa.gepa: Iteration 11: All subsample scores perfect. Skipping.\n",
1422 |       "2025/08/12 22:52:40 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Reflective mutation did not propose a new candidate\n",
1423 |       "2025/08/12 22:52:40 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Selected program 2 score: 0.5333333333333333\n",
1424 |       "\n",
1425 |       "Average Metric: 1.00 / 3 (33.3%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [01:20<00:00, 26.70s/it]\n",
1426 |       "2025/08/12 22:54:00 INFO dspy.evaluate.evaluate: Average Metric: 1.0 / 3 (33.3%)\n",
1427 |       "\n",
1428 |       "2025/08/12 22:56:06 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Proposed new text for predict: You will be given one math problem as plain text under a key like “problem.” Your job is to solve it correctly and return:\n",
1429 |       "\n",
1430 |       "- reasoning: a concise, logically ordered solution that uses identities/structure to avoid brute force, ends with a quick verification.\n",
1431 |       "- answer: the final requested number/expression only (no extra words).\n",
1432 |       "\n",
1433 |       "Formatting:\n",
1434 |       "- Use exactly two top-level fields named “reasoning” and “answer.”\n",
[TRUNCATED]
```

gepa_facilitysupportanalyzer/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "id": "23b9ab7f",
6 |    "metadata": {},
7 |    "source": [
8 |     "# Tutorial: GEPA for Structured Information Extraction for Enterprise Tasks"
9 |    ]
10 |   },
11 |   {
12 |    "cell_type": "markdown",
13 |    "id": "1114c356",
14 |    "metadata": {},
15 |    "source": [
16 |     "In this tutorial, we'll explore a three-part task for structured information extraction and classification using the [Facility Support Analyzer](https://github.com/meta-llama/llama-prompt-ops/tree/main/use-cases/facility-support-analyzer) dataset released by Meta. Given an email or message sent in an enterprise setting related to facility maintenance or support requests, the goal is to extract its urgency, assess the sentiment, and identify all relevant service request categories.\n",
17 |     "\n",
18 |     "We will build a simple DSPy program, and then use the `dspy.GEPA` optimizer to optimize it for the task.\n",
19 |     "\n",
20 |     "<details>\n",
21 |     "<summary>Recommended: Set up MLflow Autologging to understand what's happening under the hood.</summary>\n",
22 |     "\n",
23 |     "### MLflow DSPy Integration\n",
24 |     "\n",
25 |     "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. MLflow's autologging capability automatically tracks progress of GEPA optimization, as well as visualizes prompts and module executions as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
26 |     "\n",
27 |     "**Visualize module executions as traces**\n",
28 |     "\n",
29 |     "![MLflow Trace](./mlflow-tracing-gepa-support.png)\n",
30 |     "\n",
31 |     "**Automatically track optimization progress and results**\n",
32 |     "\n",
33 |     "![MLflow Tracking](./mlflow-tracking-gepa-support-optimization.png)\n",
34 |     "\n",
35 |     "\n",
36 |     "**Setup MLflow**\n",
37 |     "\n",
38 |     "1. Install MLflow\n",
39 |     "\n",
40 |     "```bash\n",
41 |     "%pip install mlflow>=3.0.0\n",
42 |     "```\n",
43 |     "\n",
44 |     "2. Start MLflow UI in a separate terminal\n",
45 |     "```bash\n",
46 |     "mlflow ui --port 5000 --backend-store-uri sqlite:///mlruns.db\n",
47 |     "```\n",
48 |     "\n",
49 |     "3. Connect the notebook to MLflow\n",
50 |     "```python\n",
51 |     "import mlflow\n",
52 |     "\n",
53 |     "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
54 |     "mlflow.set_experiment(\"DSPy\")\n",
55 |     "```\n",
56 |     "\n",
57 |     "4. Enabling autologging.\n",
58 |     "\n",
59 |     "```python\n",
60 |     "mlflow.dspy.autolog(\n",
61 |     "    # Log the optimization progress\n",
62 |     "    log_compiles=True,\n",
63 |     "    # Log the evaluation results\n",
64 |     "    log_evals=True,\n",
65 |     "    # Log traces from module executions\n",
66 |     "    log_traces=True\n",
67 |     ")\n",
68 |     "```\n",
69 |     "\n",
70 |     "\n",
71 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
72 |     "</details>"
73 |    ]
74 |   },
75 |   {
76 |    "cell_type": "markdown",
77 |    "id": "990d074e",
78 |    "metadata": {},
79 |    "source": [
80 |     "### Setup the LM\n",
81 |     "\n",
82 |     "We use GPT-4.1 nano to demonstrate how a small model can be tuned with GEPA."
83 |    ]
84 |   },
85 |   {
86 |    "cell_type": "code",
87 |    "execution_count": 1,
88 |    "id": "283588ae",
89 |    "metadata": {},
90 |    "outputs": [],
91 |    "source": [
92 |     "api_key = input(\"Enter your OpenAI API key: \")\n",
93 |     "import dspy\n",
94 |     "lm = dspy.LM(\"openai/gpt-4.1-nano\", temperature=1, api_key=api_key)\n",
95 |     "dspy.configure(lm=lm)"
96 |    ]
97 |   },
98 |   {
99 |    "cell_type": "markdown",
100 |    "id": "014f3da6",
101 |    "metadata": {},
102 |    "source": [
103 |     "### Load the dataset"
104 |    ]
105 |   },
106 |   {
107 |    "cell_type": "code",
108 |    "execution_count": 2,
109 |    "id": "c9e78285",
110 |    "metadata": {},
111 |    "outputs": [],
112 |    "source": [
113 |     "import requests\n",
114 |     "import dspy\n",
115 |     "import json\n",
116 |     "import random\n",
117 |     "\n",
118 |     "def init_dataset():\n",
119 |     "    # Load from the url\n",
120 |     "    url = \"https://raw.githubusercontent.com/meta-llama/llama-prompt-ops/refs/heads/main/use-cases/facility-support-analyzer/dataset.json\"\n",
121 |     "    dataset = json.loads(requests.get(url).text)\n",
122 |     "    dspy_dataset = [\n",
123 |     "        dspy.Example({\n",
124 |     "            \"message\": d['fields']['input'],\n",
125 |     "            \"answer\": d['answer'],\n",
126 |     "        }).with_inputs(\"message\")\n",
127 |     "        for d in dataset\n",
128 |     "    ]\n",
129 |     "    random.Random(0).shuffle(dspy_dataset)\n",
130 |     "    train_set = dspy_dataset[:int(len(dspy_dataset) * 0.33)]\n",
131 |     "    val_set = dspy_dataset[int(len(dspy_dataset) * 0.33):int(len(dspy_dataset) * 0.66)]\n",
132 |     "    test_set = dspy_dataset[int(len(dspy_dataset) * 0.66):]\n",
133 |     "\n",
134 |     "    return train_set, val_set, test_set"
135 |    ]
136 |   },
137 |   {
138 |    "cell_type": "code",
139 |    "execution_count": 3,
140 |    "id": "51822ab6",
141 |    "metadata": {},
142 |    "outputs": [
143 |     {
144 |      "data": {
145 |       "text/plain": [
146 |        "(66, 66, 68)"
147 |       ]
148 |      },
149 |      "execution_count": 3,
150 |      "metadata": {},
151 |      "output_type": "execute_result"
152 |     }
153 |    ],
154 |    "source": [
155 |     "train_set, val_set, test_set = init_dataset()\n",
156 |     "\n",
157 |     "len(train_set), len(val_set), len(test_set)"
158 |    ]
159 |   },
160 |   {
161 |    "cell_type": "markdown",
162 |    "id": "d9f36cd4",
163 |    "metadata": {},
164 |    "source": [
165 |     "Let's view an example task input"
166 |    ]
167 |   },
168 |   {
169 |    "cell_type": "code",
170 |    "execution_count": 4,
171 |    "id": "96f1e064",
172 |    "metadata": {},
173 |    "outputs": [
174 |     {
175 |      "name": "stdout",
176 |      "output_type": "stream",
177 |      "text": [
178 |       "Input Message:\n",
179 |       "Subject: Adjusting Bi-Weekly Cleaning Schedule for My Office\n",
180 |       "\n",
181 |       "Dear ProCare Facility Solutions Support Team,\n",
182 |       "\n",
183 |       "I hope this message finds you well. My name is Dr. Alex Turner, and I have been utilizing your services for my office space for the past year. I must say, your team's dedication to maintaining a pristine environment has been commendable and greatly appreciated.\n",
184 |       "\n",
185 |       "I am reaching out to discuss the scheduling of our regular cleaning services. While I find the logistical challenges of coordinating these services intellectually stimulating, I believe we could optimize the current schedule to better suit the needs of my team and our workflow. Specifically, I would like to explore the possibility of adjusting our cleaning schedule to a bi-weekly arrangement, ideally on Tuesdays and Fridays, to ensure our workspace remains consistently clean without disrupting our research activities.\n",
186 |       "\n",
187 |       "Previously, I have attempted to adjust the schedule through the online portal, but I encountered some difficulties in finalizing the changes. I would appreciate your assistance in making these adjustments or guiding me through the process if there is a more efficient way to do so.\n",
188 |       "\n",
189 |       "Thank you for your attention to this matter. I look forward to your response and continued excellent service.\n",
190 |       "\n",
191 |       "Best regards,\n",
192 |       "\n",
193 |       "Dr. Alex Turner\n",
194 |       "Cryptography Researcher\n",
195 |       "\n",
196 |       "\n",
197 |       "Gold Answer:\n",
198 |       "categories: {'routine_maintenance_requests': False, 'customer_feedback_and_complaints': False, 'training_and_support_requests': False, 'quality_and_safety_concerns': False, 'sustainability_and_environmental_practices': False, 'cleaning_services_scheduling': True, 'specialized_cleaning_services': False, 'emergency_repair_services': False, 'facility_management_issues': False, 'general_inquiries': False}\n",
199 |       "sentiment: neutral\n",
200 |       "urgency: low\n"
201 |      ]
202 |     }
203 |    ],
204 |    "source": [
205 |     "print(\"Input Message:\")\n",
206 |     "print(train_set[0]['message'])\n",
207 |     "\n",
208 |     "print(\"\\n\\nGold Answer:\")\n",
209 |     "for k, v in json.loads(train_set[0]['answer']).items():\n",
210 |     "    print(f\"{k}: {v}\")"
211 |    ]
212 |   },
213 |   {
214 |    "cell_type": "markdown",
215 |    "id": "552769fd",
216 |    "metadata": {},
217 |    "source": [
218 |     "### Defining a DSPy program to solve the task\n",
219 |     "The program is a 3-module system, each of which handles the urgency, sentiment and categories classification respectively"
220 |    ]
221 |   },
222 |   {
223 |    "cell_type": "code",
224 |    "execution_count": 5,
225 |    "id": "71598add",
226 |    "metadata": {},
227 |    "outputs": [],
228 |    "source": [
229 |     "from typing import List, Literal\n",
230 |     "\n",
231 |     "\n",
232 |     "class FacilitySupportAnalyzerUrgency(dspy.Signature):\n",
233 |     "    \"\"\"\n",
234 |     "    Read the provided message and determine the urgency.\n",
235 |     "    \"\"\"\n",
236 |     "    message: str = dspy.InputField()\n",
237 |     "    urgency: Literal['low', 'medium', 'high'] = dspy.OutputField()\n",
238 |     "\n",
239 |     "class FacilitySupportAnalyzerSentiment(dspy.Signature):\n",
240 |     "    \"\"\"\n",
241 |     "    Read the provided message and determine the sentiment.\n",
242 |     "    \"\"\"\n",
243 |     "    message: str = dspy.InputField()\n",
244 |     "    sentiment: Literal['positive', 'neutral', 'negative'] = dspy.OutputField()\n",
245 |     "\n",
246 |     "class FacilitySupportAnalyzerCategories(dspy.Signature):\n",
247 |     "    \"\"\"\n",
248 |     "    Read the provided message and determine the set of categories applicable to the message.\n",
249 |     "    \"\"\"\n",
250 |     "    message: str = dspy.InputField()\n",
251 |     "    categories: List[Literal[\"emergency_repair_services\", \"routine_maintenance_requests\", \"quality_and_safety_concerns\", \"specialized_cleaning_services\", \"general_inquiries\", \"sustainability_and_environmental_practices\", \"training_and_support_requests\", \"cleaning_services_scheduling\", \"customer_feedback_and_complaints\", \"facility_management_issues\"]] = dspy.OutputField()\n",
252 |     "\n",
253 |     "class FacilitySupportAnalyzerMM(dspy.Module):\n",
254 |     "    def __init__(self):\n",
255 |     "        self.urgency_module = dspy.ChainOfThought(FacilitySupportAnalyzerUrgency)\n",
256 |     "        self.sentiment_module = dspy.ChainOfThought(FacilitySupportAnalyzerSentiment)\n",
257 |     "        self.categories_module = dspy.ChainOfThought(FacilitySupportAnalyzerCategories)\n",
258 |     "    \n",
259 |     "    def forward(self, message: str):\n",
260 |     "        urgency = self.urgency_module(message=message)\n",
261 |     "        sentiment = self.sentiment_module(message=message)\n",
262 |     "        categories = self.categories_module(message=message)\n",
263 |     "\n",
264 |     "        return dspy.Prediction(\n",
265 |     "            urgency=urgency.urgency,\n",
266 |     "            sentiment=sentiment.sentiment,\n",
267 |     "            categories=categories.categories\n",
268 |     "        )\n",
269 |     "\n",
270 |     "program = FacilitySupportAnalyzerMM()"
271 |    ]
272 |   },
273 |   {
274 |    "cell_type": "markdown",
275 |    "id": "6e57234e",
276 |    "metadata": {},
277 |    "source": [
278 |     "### Define the metric to evaluate the outputs\n",
279 |     "The metric evaluates the output of all the three tasks, and returns the aggregate score"
280 |    ]
281 |   },
282 |   {
283 |    "cell_type": "code",
284 |    "execution_count": 6,
285 |    "id": "1c0d2c5a",
286 |    "metadata": {},
287 |    "outputs": [],
288 |    "source": [
289 |     "def score_urgency(gold_urgency, pred_urgency):\n",
290 |     "    \"\"\"\n",
291 |     "    Compute score for the urgency module.\n",
292 |     "    \"\"\"\n",
293 |     "    score = 1.0 if gold_urgency == pred_urgency else 0.0\n",
294 |     "    return score\n",
295 |     "\n",
296 |     "def score_sentiment(gold_sentiment, pred_sentiment):\n",
297 |     "    \"\"\"\n",
298 |     "    Compute score for the sentiment module.\n",
299 |     "    \"\"\"\n",
300 |     "    score = 1.0 if gold_sentiment == pred_sentiment else 0.0\n",
301 |     "    return score\n",
302 |     "\n",
303 |     "def score_categories(gold_categories, pred_categories):\n",
304 |     "    \"\"\"\n",
305 |     "    Compute score for the categories module.\n",
306 |     "    Uses the same match/mismatch logic as category accuracy in the score.\n",
307 |     "    \"\"\"\n",
308 |     "    correct = 0\n",
309 |     "    for k, v in gold_categories.items():\n",
310 |     "        if v and k in pred_categories:\n",
311 |     "            correct += 1\n",
312 |     "        elif not v and k not in pred_categories:\n",
313 |     "            correct += 1\n",
314 |     "    score = correct / len(gold_categories)\n",
315 |     "    return score\n",
316 |     "\n",
317 |     "def metric(example, pred, trace=None, pred_name=None, pred_trace=None):\n",
318 |     "    \"\"\"\n",
319 |     "    Computes a score based on agreement between prediction and gold standard for categories, sentiment, and urgency.\n",
320 |     "    Returns the score (float).\n",
321 |     "    \"\"\"\n",
322 |     "    # Parse gold standard from example\n",
323 |     "    gold = json.loads(example['answer'])\n",
324 |     "\n",
325 |     "    # Compute scores for all modules\n",
326 |     "    score_urgency_val = score_urgency(gold['urgency'], pred.urgency)\n",
327 |     "    score_sentiment_val = score_sentiment(gold['sentiment'], pred.sentiment)\n",
328 |     "    score_categories_val = score_categories(gold['categories'], pred.categories)\n",
329 |     "\n",
330 |     "    # Overall score: average of the three accuracies\n",
331 |     "    total = (score_urgency_val + score_sentiment_val + score_categories_val) / 3\n",
332 |     "\n",
333 |     "    return total"
334 |    ]
335 |   },
336 |   {
337 |    "cell_type": "markdown",
338 |    "id": "785e4e74",
339 |    "metadata": {},
340 |    "source": [
341 |     "### Evaluating the unoptimized program (running with GPT-4.1 nano)"
342 |    ]
343 |   },
344 |   {
345 |    "cell_type": "code",
346 |    "execution_count": 7,
347 |    "id": "e52d3e50",
348 |    "metadata": {},
349 |    "outputs": [
350 |     {
351 |      "name": "stdout",
352 |      "output_type": "stream",
353 |      "text": [
354 |       "Average Metric: 51.30 / 68 (75.4%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68/68 [00:00<00:00, 322.00it/s]"
355 |      ]
356 |     },
357 |     {
358 |      "name": "stderr",
359 |      "output_type": "stream",
360 |      "text": [
361 |       "2025/08/12 18:09:18 INFO dspy.evaluate.evaluate: Average Metric: 51.3 / 68 (75.4%)\n"
362 |      ]
363 |     },
364 |     {
365 |      "name": "stdout",
366 |      "output_type": "stream",
367 |      "text": [
368 |       "\n"
369 |      ]
370 |     },
371 |     {
372 |      "data": {
373 |       "text/html": [
374 |        "<div>\n",
375 |        "<style scoped>\n",
376 |        "    .dataframe tbody tr th:only-of-type {\n",
377 |        "        vertical-align: middle;\n",
378 |        "    }\n",
379 |        "\n",
380 |        "    .dataframe tbody tr th {\n",
381 |        "        vertical-align: top;\n",
382 |        "    }\n",
383 |        "\n",
384 |        "    .dataframe thead th {\n",
385 |        "        text-align: right;\n",
386 |        "    }\n",
387 |        "</style>\n",
388 |        "<table border=\"1\" class=\"dataframe\">\n",
389 |        "  <thead>\n",
390 |        "    <tr style=\"text-align: right;\">\n",
391 |        "      <th></th>\n",
392 |        "      <th>message</th>\n",
393 |        "      <th>answer</th>\n",
394 |        "      <th>urgency</th>\n",
395 |        "      <th>sentiment</th>\n",
396 |        "      <th>categories</th>\n",
397 |        "      <th>metric</th>\n",
398 |        "    </tr>\n",
399 |        "  </thead>\n",
400 |        "  <tbody>\n",
401 |        "    <tr>\n",
402 |        "      <th>0</th>\n",
403 |        "      <td>Hey ProCare Support Team, Hope you all are doing great! My name is...</td>\n",
404 |        "      <td>{\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...</td>\n",
405 |        "      <td>low</td>\n",
406 |        "      <td>positive</td>\n",
407 |        "      <td>[sustainability_and_environmental_practices]</td>\n",
408 |        "      <td>✔️ [1.000]</td>\n",
409 |        "    </tr>\n",
410 |        "    <tr>\n",
411 |        "      <th>1</th>\n",
412 |        "      <td>Hey ProCare Team, Hope you’re all doing well! My name’s Jake, and ...</td>\n",
413 |        "      <td>{\"categories\": {\"routine_maintenance_requests\": true, \"customer_fe...</td>\n",
414 |        "      <td>medium</td>\n",
415 |        "      <td>positive</td>\n",
416 |        "      <td>[routine_maintenance_requests, customer_feedback_and_complaints]</td>\n",
417 |        "      <td>✔️ [0.967]</td>\n",
418 |        "    </tr>\n",
419 |        "    <tr>\n",
420 |        "      <th>2</th>\n",
421 |        "      <td>Subject: Assistance Needed for HVAC Maintenance Hi [Receiver], I h...</td>\n",
422 |        "      <td>{\"categories\": {\"routine_maintenance_requests\": true, \"customer_fe...</td>\n",
423 |        "      <td>medium</td>\n",
424 |        "      <td>neutral</td>\n",
425 |        "      <td>[routine_maintenance_requests]</td>\n",
426 |        "      <td>✔️ [1.000]</td>\n",
427 |        "    </tr>\n",
428 |        "    <tr>\n",
429 |        "      <th>3</th>\n",
430 |        "      <td>Subject: A Green Inquiry from a Bill Maher Enthusiast Hey ProCare ...</td>\n",
431 |        "      <td>{\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...</td>\n",
432 |        "      <td>low</td>\n",
433 |        "      <td>positive</td>\n",
434 |        "      <td>[sustainability_and_environmental_practices]</td>\n",
435 |        "      <td>✔️ [1.000]</td>\n",
436 |        "    </tr>\n",
437 |        "    <tr>\n",
438 |        "      <th>4</th>\n",
439 |        "      <td>Subject: Inquiry on Sustainability Practices Dear ProCare Facility...</td>\n",
440 |        "      <td>{\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...</td>\n",
441 |        "      <td>medium</td>\n",
442 |        "      <td>neutral</td>\n",
443 |        "      <td>[sustainability_and_environmental_practices]</td>\n",
444 |        "      <td>✔️ [0.667]</td>\n",
445 |        "    </tr>\n",
446 |        "    <tr>\n",
447 |        "      <th>...</th>\n",
448 |        "      <td>...</td>\n",
449 |        "      <td>...</td>\n",
450 |        "      <td>...</td>\n",
451 |        "      <td>...</td>\n",
452 |        "      <td>...</td>\n",
453 |        "      <td>...</td>\n",
454 |        "    </tr>\n",
455 |        "    <tr>\n",
456 |        "      <th>63</th>\n",
457 |        "      <td>Subject: Inquiry About Your Eco-Friendly Practices Dear ProCare Fa...</td>\n",
458 |        "      <td>{\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...</td>\n",
459 |        "      <td>medium</td>\n",
460 |        "      <td>neutral</td>\n",
461 |        "      <td>[sustainability_and_environmental_practices]</td>\n",
462 |        "      <td>✔️ [0.600]</td>\n",
463 |        "    </tr>\n",
464 |        "    <tr>\n",
465 |        "      <th>64</th>\n",
466 |        "      <td>Subject: Assistance Needed for Facility Management Issue Dear ProC...</td>\n",
467 |        "      <td>{\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...</td>\n",
468 |        "      <td>high</td>\n",
469 |        "      <td>positive</td>\n",
470 |        "      <td>[facility_management_issues]</td>\n",
471 |        "      <td>✔️ [0.667]</td>\n",
472 |        "    </tr>\n",
473 |        "    <tr>\n",
474 |        "      <th>65</th>\n",
475 |        "      <td>Subject: Request for Training and Support Hi ProCare Support Team,...</td>\n",
476 |        "      <td>{\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...</td>\n",
477 |        "      <td>low</td>\n",
478 |        "      <td>positive</td>\n",
479 |        "      <td>[training_and_support_requests]</td>\n",
480 |        "      <td>✔️ [1.000]</td>\n",
481 |        "    </tr>\n",
482 |        "    <tr>\n",
483 |        "      <th>66</th>\n",
484 |        "      <td>Subject: Concerns About Studio Maintenance and Rent Increase Dear ...</td>\n",
485 |        "      <td>{\"categories\": {\"routine_maintenance_requests\": true, \"customer_fe...</td>\n",
486 |        "      <td>medium</td>\n",
487 |        "      <td>negative</td>\n",
488 |        "      <td>[routine_maintenance_requests, facility_management_issues]</td>\n",
489 |        "      <td>✔️ [0.600]</td>\n",
490 |        "    </tr>\n",
491 |        "    <tr>\n",
492 |        "      <th>67</th>\n",
493 |        "      <td>Subject: Feedback on Recent Maintenance Service Dear ProCare Suppo...</td>\n",
494 |        "      <td>{\"categories\": {\"routine_maintenance_requests\": true, \"customer_fe...</td>\n",
495 |        "      <td>medium</td>\n",
496 |        "      <td>neutral</td>\n",
497 |        "      <td>[routine_maintenance_requests, customer_feedback_and_complaints]</td>\n",
498 |        "      <td>✔️ [0.967]</td>\n",
499 |        "    </tr>\n",
500 |        "  </tbody>\n",
501 |        "</table>\n",
502 |        "<p>68 rows × 6 columns</p>\n",
503 |        "</div>"
504 |       ],
505 |       "text/plain": [
506 |        "                                                                  message  \\\n",
507 |        "0   Hey ProCare Support Team, Hope you all are doing great! My name is...   \n",
508 |        "1   Hey ProCare Team, Hope you’re all doing well! My name’s Jake, and ...   \n",
509 |        "2   Subject: Assistance Needed for HVAC Maintenance Hi [Receiver], I h...   \n",
510 |        "3   Subject: A Green Inquiry from a Bill Maher Enthusiast Hey ProCare ...   \n",
511 |        "4   Subject: Inquiry on Sustainability Practices Dear ProCare Facility...   \n",
512 |        "..                                                                    ...   \n",
513 |        "63  Subject: Inquiry About Your Eco-Friendly Practices Dear ProCare Fa...   \n",
514 |        "64  Subject: Assistance Needed for Facility Management Issue Dear ProC...   \n",
515 |        "65  Subject: Request for Training and Support Hi ProCare Support Team,...   \n",
516 |        "66  Subject: Concerns About Studio Maintenance and Rent Increase Dear ...   \n",
517 |        "67  Subject: Feedback on Recent Maintenance Service Dear ProCare Suppo...   \n",
518 |        "\n",
519 |        "                                                                   answer  \\\n",
520 |        "0   {\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...   \n",
521 |        "1   {\"categories\": {\"routine_maintenance_requests\": true, \"customer_fe...   \n",
522 |        "2   {\"categories\": {\"routine_maintenance_requests\": true, \"customer_fe...   \n",
523 |        "3   {\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...   \n",
524 |        "4   {\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...   \n",
525 |        "..                                                                    ...   \n",
526 |        "63  {\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...   \n",
527 |        "64  {\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...   \n",
528 |        "65  {\"categories\": {\"routine_maintenance_requests\": false, \"customer_f...   \n",
529 |        "66  {\"categories\": {\"routine_maintenance_requests\": true, \"customer_fe...   \n",
530 |        "67  {\"categories\": {\"routine_maintenance_requests\": true, \"customer_fe...   \n",
531 |        "\n",
532 |        "   urgency sentiment  \\\n",
533 |        "0      low  positive   \n",
534 |        "1   medium  positive   \n",
535 |        "2   medium   neutral   \n",
536 |        "3      low  positive   \n",
537 |        "4   medium   neutral   \n",
538 |        "..     ...       ...   \n",
539 |        "63  medium   neutral   \n",
540 |        "64    high  positive   \n",
541 |        "65     low  positive   \n",
542 |        "66  medium  negative   \n",
543 |        "67  medium   neutral   \n",
544 |        "\n",
545 |        "                                                          categories  \\\n",
546 |        "0                       [sustainability_and_environmental_practices]   \n",
547 |        "1   [routine_maintenance_requests, customer_feedback_and_complaints]   \n",
548 |        "2                                     [routine_maintenance_requests]   \n",
549 |        "3                       [sustainability_and_environmental_practices]   \n",
550 |        "4                       [sustainability_and_environmental_practices]   \n",
551 |        "..                                                               ...   \n",
552 |        "63                      [sustainability_and_environmental_practices]   \n",
553 |        "64                                      [facility_management_issues]   \n",
554 |        "65                                   [training_and_support_requests]   \n",
555 |        "66        [routine_maintenance_requests, facility_management_issues]   \n",
556 |        "67  [routine_maintenance_requests, customer_feedback_and_complaints]   \n",
557 |        "\n",
558 |        "        metric  \n",
559 |        "0   ✔️ [1.000]  \n",
560 |        "1   ✔️ [0.967]  \n",
561 |        "2   ✔️ [1.000]  \n",
562 |        "3   ✔️ [1.000]  \n",
563 |        "4   ✔️ [0.667]  \n",
564 |        "..         ...  \n",
565 |        "63  ✔️ [0.600]  \n",
566 |        "64  ✔️ [0.667]  \n",
567 |        "65  ✔️ [1.000]  \n",
568 |        "66  ✔️ [0.600]  \n",
569 |        "67  ✔️ [0.967]  \n",
570 |        "\n",
571 |        "[68 rows x 6 columns]"
572 |       ]
573 |      },
574 |      "metadata": {},
575 |      "output_type": "display_data"
576 |     },
577 |     {
578 |      "data": {
579 |       "text/plain": [
580 |        "EvaluationResult(score=75.44, results=<list of 68 results>)"
581 |       ]
582 |      },
583 |      "execution_count": 7,
584 |      "metadata": {},
585 |      "output_type": "execute_result"
586 |     }
587 |    ],
588 |    "source": [
589 |     "import dspy\n",
590 |     "evaluate = dspy.Evaluate(\n",
591 |     "    devset=test_set,\n",
592 |     "    metric=metric,\n",
593 |     "    num_threads=32,\n",
594 |     "    display_table=True,\n",
595 |     "    display_progress=True\n",
596 |     ")\n",
597 |     "\n",
598 |     "evaluate(program)"
599 |    ]
600 |   },
601 |   {
602 |    "cell_type": "markdown",
603 |    "id": "0aeb9bae",
604 |    "metadata": {},
605 |    "source": [
606 |     "### Optimizing with GEPA"
607 |    ]
608 |   },
609 |   {
610 |    "cell_type": "markdown",
611 |    "id": "872fe00c",
612 |    "metadata": {},
613 |    "source": [
614 |     "GEPA is a _reflective_ prompt optimizer. Its strength lies in its ability to examine textual feedback from the DSPy program's execution and evaluation pipelines. This gives GEPA greater insight into why the system achieved a particular score, enabling it to introspect and determine ways to enhance performance.\n",
615 |     "\n",
616 |     "In this scenario, the final score is based on performance across three distinct tasks. It's straightforward to see that each predictor handles a specific part of the overall score.\n",
617 |     "\n",
618 |     "GEPA supports providing feedback at the individual predictor level (though this isn't required—see the GEPA PAPILLON tutorial for an example without it). Let's make a quick adjustment to our evaluation metric, to make it an optimization metric, that also provides text feedback!"
619 |    ]
620 |   },
621 |   {
622 |    "cell_type": "code",
623 |    "execution_count": 8,
624 |    "id": "e21e86df",
625 |    "metadata": {},
626 |    "outputs": [],
627 |    "source": [
628 |     "import json\n",
629 |     "import dspy\n",
630 |     "\n",
631 |     "def feedback_urgency(gold_urgency, pred_urgency):\n",
632 |     "    \"\"\"\n",
633 |     "    Generate feedback for the urgency module.\n",
634 |     "    \"\"\"\n",
635 |     "    score = 1.0 if gold_urgency == pred_urgency else 0.0\n",
636 |     "    if gold_urgency == pred_urgency:\n",
637 |     "        feedback = f\"You correctly classified the urgency of the message as `{gold_urgency}`. This message is indeed of `{gold_urgency}` urgency.\"\n",
638 |     "    else:\n",
639 |     "        feedback = f\"You incorrectly classified the urgency of the message as `{pred_urgency}`. The correct urgency is `{gold_urgency}`. Think about how you could have reasoned to get the correct urgency label.\"\n",
640 |     "    return feedback, score\n",
641 |     "\n",
642 |     "def feedback_sentiment(gold_sentiment, pred_sentiment):\n",
643 |     "    \"\"\"\n",
644 |     "    Generate feedback for the sentiment module.\n",
645 |     "    \"\"\"\n",
646 |     "    score = 1.0 if gold_sentiment == pred_sentiment else 0.0\n",
647 |     "    if gold_sentiment == pred_sentiment:\n",
648 |     "        feedback = f\"You correctly classified the sentiment of the message as `{gold_sentiment}`. This message is indeed `{gold_sentiment}`.\"\n",
649 |     "    else:\n",
650 |     "        feedback = f\"You incorrectly classified the sentiment of the message as `{pred_sentiment}`. The correct sentiment is `{gold_sentiment}`. Think about how you could have reasoned to get the correct sentiment label.\"\n",
651 |     "    return feedback, score\n",
652 |     "\n",
653 |     "def feedback_categories(gold_categories, pred_categories):\n",
654 |     "    \"\"\"\n",
655 |     "    Generate feedback for the categories module.\n",
656 |     "    Uses the same match/mismatch logic as category accuracy in the score.\n",
657 |     "    \"\"\"\n",
658 |     "    correctly_included = [k for k, v in gold_categories.items() if v and k in pred_categories]\n",
659 |     "    incorrectly_included = [k for k, v in gold_categories.items() if not v and k in pred_categories]\n",
660 |     "    incorrectly_excluded = [k for k, v in gold_categories.items() if v and k not in pred_categories]\n",
661 |     "    correctly_excluded = [k for k, v in gold_categories.items() if not v and k not in pred_categories]  # For completeness in accuracy check\n",
662 |     "\n",
663 |     "    # Recompute category accuracy (matches score logic)\n",
664 |     "    score = (len(correctly_included) + len(correctly_excluded)) / len(gold_categories)\n",
665 |     "\n",
666 |     "    if score == 1.0:\n",
667 |     "        fb_text = f\"The category classification is perfect. You correctly identified that the message falls under the following categories: `{repr(correctly_included)}`.\"\n",
668 |     "    else:\n",
669 |     "        fb_text = f\"The category classification is not perfect. You correctly identified that the message falls under the following categories: `{repr(correctly_included)}`.\\n\"\n",
670 |     "        if incorrectly_included:\n",
671 |     "            fb_text += f\"However, you incorrectly identified that the message falls under the following categories: `{repr(incorrectly_included)}`. The message DOES NOT fall under these categories.\\n\"\n",
672 |     "        if incorrectly_excluded:\n",
673 |     "            prefix = \"Additionally, \" if incorrectly_included else \"However, \"\n",
674 |     "            fb_text += f\"{prefix}you didn't identify the following categories that the message actually falls under: `{repr(incorrectly_excluded)}`.\\n\"\n",
675 |     "        fb_text += \"Think about how you could have reasoned to get the correct category labels.\"\n",
676 |     "    return fb_text, score\n",
677 |     "\n",
678 |     "def metric_with_feedback(example, pred, trace=None, pred_name=None, pred_trace=None):\n",
679 |     "    \"\"\"\n",
680 |     "    Computes a score based on agreement between prediction and gold standard for categories, sentiment, and urgency.\n",
681 |     "    Optionally provides feedback text for a specific predictor module, using the same comparison logic as the score.\n",
682 |     "    Returns a dspy.Prediction with score (float) and feedback (str).\n",
683 |     "    \"\"\"\n",
684 |     "    # Parse gold standard from example\n",
685 |     "    gold = json.loads(example['answer'])\n",
686 |     "\n",
687 |     "    # Compute feedback and scores for all modules\n",
688 |     "    fb_urgency, score_urgency = feedback_urgency(gold['urgency'], pred.urgency)\n",
689 |     "    fb_sentiment, score_sentiment = feedback_sentiment(gold['sentiment'], pred.sentiment)\n",
690 |     "    fb_categories, score_categories = feedback_categories(gold['categories'], pred.categories)\n",
691 |     "\n",
692 |     "    # Overall score: average of the three accuracies\n",
693 |     "    total = (score_urgency + score_sentiment + score_categories) / 3\n",
694 |     "\n",
695 |     "    if pred_name is None:\n",
696 |     "        return total\n",
697 |     "\n",
698 |     "    elif pred_name == 'urgency_module.predict':\n",
699 |     "        feedback = fb_urgency\n",
700 |     "    elif pred_name == 'sentiment_module.predict':\n",
701 |     "        feedback = fb_sentiment\n",
702 |     "    elif pred_name == 'categories_module.predict':\n",
703 |     "        feedback = fb_categories\n",
704 |     "\n",
705 |     "    return dspy.Prediction(score=total, feedback=feedback)"
706 |    ]
707 |   },
708 |   {
709 |    "cell_type": "markdown",
710 |    "id": "dec4e785",
711 |    "metadata": {},
712 |    "source": [
713 |     "Notice that the evaluation metric already contained all the information needed to generate the text feedback—we simply modified it to explicitly state what was being compared. In general, the metric functions for most tasks provide the essential components for creating such feedback; it often just requires identifying which elements to expose to the GEPA optimizer, enabling it to reflect on and enhance the program's performance."
714 |    ]
715 |   },
716 |   {
717 |    "cell_type": "markdown",
718 |    "id": "77b00899",
719 |    "metadata": {},
720 |    "source": [
721 |     "Let's run GEPA"
722 |    ]
723 |   },
724 |   {
725 |    "cell_type": "code",
726 |    "execution_count": 9,
727 |    "id": "1de921bc",
728 |    "metadata": {},
729 |    "outputs": [],
730 |    "source": [
731 |     "from dspy import GEPA\n",
732 |     "\n",
733 |     "optimizer = GEPA(\n",
734 |     "    metric=metric_with_feedback,\n",
735 |     "    auto=\"light\", # <-- We will use a light budget for this tutorial. However, we typically recommend using auto=\"heavy\" for optimized performance!\n",
736 |     "    num_threads=32,\n",
737 |     "    track_stats=True,\n",
738 |     "    use_merge=False,\n",
739 |     "    reflection_lm=dspy.LM(model=\"gpt-5\", temperature=1.0, max_tokens=32000, api_key=api_key)\n",
740 |     ")"
741 |    ]
742 |   },
743 |   {
744 |    "cell_type": "code",
745 |    "execution_count": 10,
746 |    "id": "b1404077",
747 |    "metadata": {},
748 |    "outputs": [
749 |     {
750 |      "name": "stderr",
751 |      "output_type": "stream",
752 |      "text": [
753 |       "2025/08/12 20:01:55 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 1643 metric calls of the program. This amounts to 12.45 full evals on the train+val set.\n",
754 |       "2025/08/12 20:01:55 INFO dspy.teleprompt.gepa.gepa: Using 66 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget.\n",
755 |       "7\n",
756 |       "2025/08/12 20:01:56 INFO dspy.evaluate.evaluate: Average Metric: 47.56666666666666 / 66 (72.1%)\n",
757 |       "2025/08/12 20:01:56 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.7207070707070706\n",
758 |       "2025/08/12 20:01:56 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.7207070707070706\n",
759 |       "Average Metric: 2.27 / 3 (75.6%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 83.95it/s]\n",
760 |       "2025/08/12 20:01:56 INFO dspy.evaluate.evaluate: Average Metric: 2.2666666666666666 / 3 (75.6%)\n",
761 |       "2025/08/12 20:01:56 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Proposed new text for urgency_module.predict: Task: Determine the urgency of a customer message to ProCare Facility Solutions.\n",
762 |       "\n",
763 |       "Context and domain:\n",
764 |       "- Messages are typically sent to ProCare Facility Solutions’ support team about facilities services (e.g., office/residential maintenance, cleaning, HVAC).\n",
765 |       "- Common topics include cleaning quality (especially in high-traffic areas), HVAC performance/safety, routine maintenance scheduling, and general inquiries (e.g., sustainability practices).\n",
766 |       "\n",
767 |       "How to assess urgency:\n",
768 |       "Use these primary factors:\n",
769 |       "1) Safety and risk:\n",
770 |       "   - High/urgent if there’s an immediate safety hazard or potential harm (e.g., electrical sparks, gas smell, active water leak/flood, critical HVAC failure in extreme conditions, security breach).\n",
771 |       "   - Medium if safety is mentioned but described as minor or without signs of imminent danger (e.g., “minor safety concerns” about HVAC, no indication of immediate risk).\n",
772 |       "2) Operational impact:\n",
773 |       "   - High if a critical system outage or issue prevents normal operations or poses serious disruption now.\n",
774 |       "   - Medium for service degradation or quality inconsistencies that need timely attention but are not emergencies (e.g., inconsistent cleaning in lobby/conference rooms, HVAC underperforming).\n",
775 |       "   - Low if no operational impact is described and the message is informational only.\n",
776 |       "3) Time sensitivity and deadlines:\n",
777 |       "   - High if action is needed immediately, today, or within 24–48 hours; explicit urgent language like “ASAP,” “emergency,” “immediately,” or a near-term hard deadline.\n",
778 |       "   - Medium if the sender requests scheduling within about 1–2 weeks or mentions an upcoming event within that window.\n",
779 |       "   - Low if no timeframe is specified and the request is routine or informational.\n",
780 |       "4) Tone and intent:\n",
781 |       "   - Phrases like “prompt response” alone do not imply high urgency (polite closing).\n",
782 |       "   - Curiosity/information requests without issues (e.g., eco-friendly practices) are typically low.\n",
783 |       "\n",
784 |       "Classification guide:\n",
785 |       "- High: Imminent safety hazard, critical failure/outage, or explicit urgent/near-term deadline (today/tomorrow).\n",
786 |       "- Medium: Non-critical but important issues requiring timely attention (quality/safety concerns without immediate danger; routine maintenance requested within ~1–2 weeks or tied to an upcoming event).\n",
787 |       "- Low: General inquiries, non-pressing interest or information requests, or routine items with no stated timeline/impact.\n",
788 |       "\n",
789 |       "Examples to mirror:\n",
790 |       "- Cleaning inconsistencies in high-traffic areas + minor HVAC safety concerns, no emergency described → medium.\n",
791 |       "- Routine HVAC maintenance with decreased performance and an event in 1–2 weeks → medium.\n",
792 |       "- Inquiry about eco-friendly/sustainability practices, no issue or deadline → low.\n",
793 |       "\n",
794 |       "Output format:\n",
795 |       "- Return exactly two fields:\n",
796 |       "  reasoning: 1–3 concise sentences explaining the classification based on the factors above, referencing details from the message.\n",
797 |       "  urgency: one of: low | medium | high\n",
798 |       "\n",
799 |       "Do not ask questions or add extra sections. Keep the reasoning succinct and specific.\n",
800 |       "2025/08/12 20:01:56 INFO dspy.evaluate.evaluate: Average Metric: 2.2666666666666666 / 3 (75.6%)\n",
801 |       "2025/08/12 20:01:56 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New subsample score is not better, skipping\n",
802 |       "2025/08/12 20:01:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Selected program 0 score: 0.7207070707070706\n",
803 |       "\n",
804 |       "Average Metric: 2.93 / 3 (97.8%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 57.84it/s]\n",
805 |       "2025/08/12 20:01:56 INFO dspy.evaluate.evaluate: Average Metric: 2.9333333333333336 / 3 (97.8%)\n",
806 |       "2025/08/12 20:01:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Proposed new text for sentiment_module.predict: You are given a single input:\n",
807 |       "- message: A professional email-style message, often addressed to ProCare Facility Solutions (facility management/maintenance services). Messages may discuss maintenance quality, safety, cleaning products, HVAC performance, minor household issues (e.g., a leaking faucet), exhibit/artifact preservation needs, or requests for follow-up service.\n",
808 |       "\n",
809 |       "Your task:\n",
810 |       "- Determine the overall sentiment conveyed by the message and briefly explain your reasoning.\n",
811 |       "\n",
812 |       "Key guidance for this domain:\n",
813 |       "- Many messages will be polite, professional, and solution-seeking, even when describing problems (e.g., concerns about cleaning residues affecting artifacts, inconsistent HVAC performance, or minor leaks). Such messages are typically neutral if they lack strong emotional language.\n",
814 |       "- Standard courtesies (greetings, “thank you,” “best regards”) do not make a message positive by themselves.\n",
815 |       "- The mere presence of an issue (e.g., reporting a problem or oversight) is not inherently negative; assess the tone and emotional intensity.\n",
816 |       "- Treat references to ProCare Facility Solutions, maintenance protocols, HVAC, exhibit/artifacts, and similar domain terms as context, not sentiment indicators.\n",
817 |       "\n",
818 |       "Label definitions:\n",
819 |       "- positive: Clear praise, satisfaction, or strong gratitude about services or outcomes.\n",
820 |       "- neutral: Polite/professional tone; factual reporting; requests for help; constructive feedback without strong emotion; balanced notes of appreciation with mild concerns.\n",
821 |       "- negative: Clear dissatisfaction, frustration, blame, anger, or strong negative emotion; threats/urgency framed with discontent.\n",
822 |       "- mixed: Meaningful presence of both positive and negative emotions of similar weight.\n",
823 |       "- unclear: Insufficient content to infer sentiment.\n",
824 |       "\n",
825 |       "Process:\n",
826 |       "1) Read the message fully.\n",
827 |       "2) Identify explicit sentiment cues (praise, complaints, frustration, satisfaction) and evaluate overall tone and intent.\n",
828 |       "3) Choose the single best label from [positive, neutral, negative, mixed, unclear].\n",
829 |       "4) Justify briefly.\n",
830 |       "\n",
831 |       "Output format (plain text, no extra fields):\n",
832 |       "- reasoning: 1–3 concise sentences explaining the tone and why it maps to the chosen label. Do not summarize the entire message; focus on sentiment cues.\n",
833 |       "- sentiment: one of positive, neutral, negative, mixed, unclear (lowercase).\n",
834 |       "\n",
835 |       "Do not include any additional sections or formatting beyond these two fields.\n",
836 |       "\n",
837 |       "2025/08/12 20:01:56 INFO dspy.evaluate.evaluate: Average Metric: 2.9333333333333336 / 3 (97.8%)\n",
838 |       "2025/08/12 20:01:56 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New subsample score is not better, skipping\n",
839 |       "2025/08/12 20:01:56 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Selected program 0 score: 0.7207070707070706\n",
840 |       "Average Metric: 2.90 / 3 (96.7%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 66.36it/s]\n",
841 |       "2025/08/12 20:01:56 INFO dspy.evaluate.evaluate: Average Metric: 2.9 / 3 (96.7%)\n",
842 |       "2025/08/12 20:01:56 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Proposed new text for categories_module.predict: You are classifying customer messages sent to ProCare Facility Solutions (a facilities/cleaning services provider). Your goal is to read a single message and assign all applicable categories from a fixed list. Use evidence from the message only; select all that apply; do not add categories that are not supported by the text.\n",
843 |       "\n",
844 |       "Allowed categories and definitions:\n",
845 |       "- cleaning_services_scheduling\n",
846 |       "  - Use when the primary intent is to schedule, reschedule, adjust, or inquire about dates/times for cleaning services.\n",
847 |       "  - Includes: requests to change cleaning times, book a service, check availability, or align schedules.\n",
848 |       "  - Exclude when rescheduling is requested only as part of resolving a complaint about poor service (see rule below).\n",
849 |       "\n",
850 |       "- specialized_cleaning_services\n",
851 |       "  - Use when the message mentions specific/specialized cleaning types or tasks, such as deep cleaning, carpet maintenance, window washing, or other specialized treatments beyond generic cleaning.\n",
852 |       "\n",
853 |       "- customer_feedback_and_complaints\n",
854 |       "  - Use when the message expresses dissatisfaction, reports subpar service, communication issues, requests remedies (e.g., redo, refund), or otherwise complains about prior service.\n",
855 |       "\n",
856 |       "- quality_and_safety_concerns\n",
857 |       "  - Use when the message raises concerns about service quality not meeting standards (e.g., still stained, not clean enough) or safety issues.\n",
858 |       "  - Can co-occur with customer_feedback_and_complaints when the sender is unhappy with outcomes.\n",
859 |       "\n",
860 |       "- general_inquiries\n",
861 |       "  - Use when the sender asks for information (e.g., availability, requirements, what’s included) before committing, or seeks clarification about services or process.\n",
862 |       "\n",
863 |       "Key decision rules:\n",
864 |       "- Multi-label: Assign every category that is clearly supported by the message.\n",
865 |       "- Scheduling vs. Complaint distinction:\n",
866 |       "  - If the message’s main purpose is logistics around timing/availability (initial booking, standalone reschedule/adjustment), include cleaning_services_scheduling.\n",
867 |       "  - If rescheduling is requested only as a remedy within a complaint about poor service, do NOT include cleaning_services_scheduling. In that case, include customer_feedback_and_complaints and quality_and_safety_concerns (and specialized_cleaning_services if specific tasks are referenced).\n",
868 |       "- Specialized services: If the message mentions deep cleaning, carpet maintenance, window washing, or similar, include specialized_cleaning_services in addition to any other applicable categories.\n",
869 |       "- General inquiries often co-occur: If the sender is asking for availability or requirements before booking, include general_inquiries alongside cleaning_services_scheduling and any service-type categories.\n",
870 |       "- Do not infer categories not supported by the text (e.g., do not add scheduling if the only scheduling mention is within a complaint resolution).\n",
871 |       "\n",
872 |       "Domain notes:\n",
873 |       "- Messages pertain to cleaning services for residential or commercial properties handled by ProCare Facility Solutions.\n",
874 |       "- Examples of specialized tasks: deep cleaning, carpet maintenance, window washing.\n",
875 |       "- Contexts may include high-profile clients, confidentiality/privacy needs, and urgency; these do not create categories by themselves unless tied to the definitions above.\n",
876 |       "\n",
877 |       "Output format:\n",
878 |       "- Provide two top-level keys in plain text:\n",
879 |       "  - reasoning: A brief justification naming each selected category and noting any notable exclusions (especially the scheduling-vs-complaint distinction, when relevant).\n",
880 |       "  - categories: A JSON array of the selected category strings, e.g., [\"cleaning_services_scheduling\", \"general_inquiries\"].\n",
881 |       "- Do not include categories outside the allowed list. Use exact strings.\n",
882 |       "\n",
883 |       "Process:\n",
884 |       "1) Read the message and identify intents: scheduling logistics, service type specificity, feedback/complaint, quality/safety concerns, information requests.\n",
885 |       "2) Map each intent to categories using the definitions and rules.\n",
886 |       "3) Produce concise reasoning and the list of categories.\n",
887 |       "\n",
888 |       "2025/08/12 20:01:56 INFO dspy.evaluate.evaluate: Average Metric: 2.9333333333333336 / 3 (97.8%)\n",
889 |       "2025/08/12 20:01:58 INFO dspy.evaluate.evaluate: Average Metric: 46.96666666666667 / 66 (71.2%)\n",
890 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full valset score for new program: 0.7116161616161616\n",
891 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full train_val score for new program: 0.7116161616161616\n",
892 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Individual valset scores for new program: [0.6333333333333333, 0.9333333333333332, 0.8666666666666667, 0.6666666666666666, 0.3, 0.26666666666666666, 0.9666666666666667, 1.0, 1.0, 0.3, 0.6666666666666666, 1.0, 0.3, 0.6333333333333333, 0.6666666666666666, 0.9333333333333332, 1.0, 0.9333333333333332, 0.6333333333333333, 0.6333333333333333, 0.9333333333333332, 0.3333333333333333, 0.26666666666666666, 0.6333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6, 0.6666666666666666, 0.6666666666666666, 1.0, 0.3, 0.9666666666666667, 0.6, 0.6666666666666666, 0.9666666666666667, 0.3333333333333333, 0.6333333333333333, 1.0, 0.6333333333333333, 0.9666666666666667, 0.9333333333333332, 1.0, 0.9, 0.9666666666666667, 1.0, 1.0, 0.6, 0.6666666666666666, 0.9333333333333332, 0.9666666666666667, 0.3, 0.9, 0.3333333333333333, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 0.9666666666666667, 0.9666666666666667, 0.3, 0.6333333333333333, 0.6666666666666666, 0.6, 0.6666666666666666, 0.26666666666666666, 1.0, 0.6]\n",
893 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New valset pareto front scores: [0.6666666666666666, 1.0, 0.9, 0.6666666666666666, 0.3333333333333333, 0.26666666666666666, 0.9666666666666667, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.3, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.9333333333333332, 0.3333333333333333, 0.3, 0.6333333333333333, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.3333333333333333, 0.9666666666666667, 0.6, 0.6666666666666666, 1.0, 0.3333333333333333, 0.6333333333333333, 1.0, 0.6666666666666666, 1.0, 0.9333333333333332, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.9666666666666667, 0.9666666666666667, 0.3333333333333333, 0.9333333333333332, 0.3333333333333333, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6333333333333333, 0.6666666666666666, 0.3, 1.0, 0.6]\n",
894 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full valset pareto front score: 0.7282828282828282\n",
895 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Updated valset pareto front programs: [{0}, {0}, {0}, {1}, {0}, {0, 1}, {0, 1}, {0, 1}, {1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {0}, {1}, {0}, {0}, {0}, {1}, {0, 1}, {0}, {1}, {0, 1}, {0, 1}, {0}, {1}, {1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {1}, {0, 1}, {0}, {0}, {0, 1}, {0, 1}, {0}, {1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0}, {0, 1}, {0}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0}, {0}, {0}, {0, 1}, {0}, {1}, {0}, {1}, {0, 1}]\n",
896 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best valset aggregate score so far: 0.7207070707070706\n",
897 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best program as per aggregate score on train_val: 0\n",
898 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best program as per aggregate score on valset: 0\n",
899 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best score on valset: 0.7207070707070706\n",
900 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best score on train_val: 0.7207070707070706\n",
901 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Linear pareto front program index: 0\n",
902 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New program candidate index: 1\n",
903 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Selected program 1 score: 0.7116161616161616\n",
904 |       "Average Metric: 2.53 / 3 (84.4%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 139.28it/s]\n",
905 |       "2025/08/12 20:01:58 INFO dspy.evaluate.evaluate: Average Metric: 2.533333333333333 / 3 (84.4%)\n",
906 |       "2025/08/12 20:01:58 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Proposed new text for urgency_module.predict: Task: Read the provided message and determine the urgency.\n",
907 |       "\n",
908 |       "Context/domain:\n",
909 |       "- Messages typically relate to facility management and services (e.g., facility operations, space utilization, security, sustainability, HVAC systems, maintenance, cleaning services) for a provider like ProCare Facility Solutions.\n",
910 |       "- Senders may be residential or commercial clients and may reference residents, tenants, property operations, or prior support interactions.\n",
911 |       "\n",
912 |       "Output format:\n",
913 |       "- Provide exactly two fields, in this order, no extra text or formatting:\n",
914 |       "reasoning: <1–3 concise sentences explaining the key cues that determine urgency>\n",
915 |       "urgency: <one of: low | medium | high>\n",
916 |       "\n",
917 |       "Urgency levels and decision rules:\n",
918 |       "- HIGH:\n",
919 |       "  - Clear or implied immediate risk to safety/security or major operational impact.\n",
920 |       "  - Explicit urgency signals (e.g., “Urgent,” “Immediate attention required,” “ASAP,” “critical,” “escalating”).\n",
921 |       "  - Severe dissatisfaction with demand for immediate corrective action or evidence of repeated failed support and escalation.\n",
922 |       "  - Examples/triggers: security breach/serious security gaps, fire/smoke, flooding/water leak, gas leak, electrical hazard, power outage, loss of access, no heat in winter or no cooling in extreme heat affecting many residents/operations.\n",
923 |       "- MEDIUM:\n",
924 |       "  - Time-sensitive issues that affect comfort, reliability, or service quality but are not emergencies and pose no immediate safety/security risk.\n",
925 |       "  - Requests for prompt scheduling/repair/maintenance where delay could worsen impact but is not currently critical.\n",
926 |       "  - Examples/triggers: HVAC making noises and inconsistent temperature, minor malfunction, routine maintenance requested “at the earliest convenience,” issues noted as “not an emergency.”\n",
927 |       "- LOW:\n",
928 |       "  - General inquiries, information requests, quotes, scheduling/options discussions, or interest in additional services with no stated or implied time pressure.\n",
929 |       "  - Compliments/feedback without an urgent problem.\n",
930 |       "  - Examples/triggers: asking for details on specialized cleaning, pricing, or availability without a problem to fix now.\n",
931 |       "\n",
932 |       "Key cues to weigh:\n",
933 |       "- Explicit urgency language vs. statements like “not an emergency.”\n",
934 |       "- Safety/security implications and operational continuity.\n",
935 |       "- Impact scope (residents/tenants/business operations).\n",
936 |       "- Deadlines/dates or requested response times.\n",
937 |       "- Prior failed attempts and escalation tone.\n",
938 |       "- Do not inflate urgency based solely on polite phrases like “prompt assistance” if no urgent risk is present.\n",
939 |       "\n",
940 |       "Tie-breakers:\n",
941 |       "- If the message explicitly says it’s not an emergency and no serious risk is evident, do not classify as high.\n",
942 |       "- If unclear and no risk/time pressure is indicated, default to low.\n",
943 |       "2025/08/12 20:01:58 INFO dspy.evaluate.evaluate: Average Metric: 2.8666666666666667 / 3 (95.6%)\n",
944 |       "\n",
945 |       "2025/08/12 20:01:59 INFO dspy.evaluate.evaluate: Average Metric: 52.3 / 66 (79.2%)\n",
946 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New program is on the linear pareto front\n",
947 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full valset score for new program: 0.7924242424242424\n",
948 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full train_val score for new program: 0.7924242424242424\n",
949 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Individual valset scores for new program: [0.9666666666666667, 0.9333333333333332, 0.8666666666666667, 1.0, 0.6333333333333333, 0.6, 0.9666666666666667, 1.0, 1.0, 0.6333333333333333, 0.6666666666666666, 1.0, 0.6333333333333333, 0.3, 0.6666666666666666, 0.6, 1.0, 0.9333333333333332, 0.6333333333333333, 0.9666666666666667, 0.9333333333333332, 0.3333333333333333, 0.6, 0.9666666666666667, 0.3333333333333333, 1.0, 0.9333333333333332, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.9666666666666667, 0.9333333333333332, 0.6666666666666666, 0.9666666666666667, 0.6666666666666666, 0.6333333333333333, 1.0, 0.6333333333333333, 0.9666666666666667, 0.9333333333333332, 1.0, 0.9, 0.9666666666666667, 1.0, 1.0, 0.6, 0.6666666666666666, 0.9333333333333332, 0.9666666666666667, 0.6333333333333333, 0.9, 0.6666666666666666, 0.9666666666666667, 0.6666666666666666, 0.3333333333333333, 0.6333333333333333, 0.9666666666666667, 0.6333333333333333, 0.3, 1.0, 0.9333333333333332, 0.6666666666666666, 0.6, 1.0, 0.6]\n",
950 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New valset pareto front scores: [0.9666666666666667, 1.0, 0.9, 1.0, 0.6333333333333333, 0.6, 0.9666666666666667, 1.0, 1.0, 0.6333333333333333, 0.6666666666666666, 1.0, 0.6333333333333333, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.9666666666666667, 0.9333333333333332, 0.3333333333333333, 0.6, 0.9666666666666667, 0.3333333333333333, 1.0, 0.9333333333333332, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.9666666666666667, 0.9333333333333332, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6333333333333333, 1.0, 0.6666666666666666, 1.0, 0.9333333333333332, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.9666666666666667, 0.9666666666666667, 0.6333333333333333, 0.9333333333333332, 0.6666666666666666, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.6666666666666666, 1.0, 0.9333333333333332, 0.6666666666666666, 0.6, 1.0, 0.6]\n",
951 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full valset pareto front score: 0.8282828282828283\n",
952 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Updated valset pareto front programs: [{2}, {0}, {0}, {2}, {2}, {2}, {0, 1, 2}, {0, 1, 2}, {1, 2}, {2}, {0, 1, 2}, {0, 1, 2}, {2}, {0}, {1, 2}, {0}, {1, 2}, {0}, {0}, {2}, {1, 2}, {0, 1, 2}, {2}, {2}, {0, 1, 2}, {2}, {2}, {1, 2}, {2}, {0, 1, 2}, {2}, {0, 1, 2}, {2}, {0, 1, 2}, {0}, {2}, {1, 2}, {0, 1, 2}, {0}, {0}, {0, 1, 2}, {0, 1, 2}, {0}, {1, 2}, {0, 1, 2}, {0, 1, 2}, {0}, {0, 1, 2}, {0}, {0, 1, 2}, {2}, {0}, {2}, {0, 1, 2}, {0, 1, 2}, {0, 1}, {0}, {0}, {2}, {0}, {2}, {2}, {1, 2}, {2}, {1, 2}, {0, 1, 2}]\n",
953 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best valset aggregate score so far: 0.7924242424242424\n",
954 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best program as per aggregate score on train_val: 2\n",
955 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best program as per aggregate score on valset: 2\n",
956 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best score on valset: 0.7924242424242424\n",
957 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best score on train_val: 0.7924242424242424\n",
958 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Linear pareto front program index: 2\n",
959 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New program candidate index: 2\n",
960 |       "2025/08/12 20:01:59 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Selected program 2 score: 0.7924242424242424\n",
961 |       "Average Metric: 2.20 / 3 (73.3%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 50.15it/s]\n",
962 |       "2025/08/12 20:02:00 INFO dspy.evaluate.evaluate: Average Metric: 2.1999999999999997 / 3 (73.3%)\n",
963 |       "2025/08/12 20:02:00 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Proposed new text for sentiment_module.predict: Task\n",
964 |       "- Read the provided message text and classify its overall sentiment as one of: positive, neutral, or negative.\n",
965 |       "\n",
966 |       "Input format\n",
967 |       "- You will receive one field:\n",
968 |       "  - message: A string that may include a Subject line and an email-style body.\n",
969 |       "\n",
970 |       "Output format\n",
971 |       "- Output only a single lowercase label: positive, neutral, or negative.\n",
972 |       "- Do not include any additional text or reasoning.\n",
973 |       "\n",
974 |       "Classification guidelines\n",
975 |       "- Focus on the overall emotional tone expressed about the service/interaction, not the message’s functional purpose (e.g., making a request) or formalities.\n",
976 |       "- If signals are mixed or weak, default to neutral.\n",
977 |       "\n",
978 |       "Label definitions\n",
979 |       "- Positive:\n",
980 |       "  - The message clearly expresses satisfaction, praise, gratitude, or enthusiasm that goes beyond routine politeness.\n",
981 |       "  - Strong and/or multiple explicit positive cues dominate (e.g., “satisfied client,” “exceptional service,” “truly appreciate,” “excellent,” “very happy,” “great,” “love working with you”).\n",
982 |       "- Negative:\n",
983 |       "  - The message expresses dissatisfaction, complaints, frustration, anger, fear, or disappointment about the service/experience.\n",
984 |       "  - Explicit negative claims or emotions (e.g., “unacceptable,” “unsafe,” “poor quality,” “frustrated,” “angry,” “very disappointed”).\n",
985 |       "- Neutral:\n",
986 |       "  - Informational, inquisitive, or routine requests without clear emotional valence.\n",
987 |       "  - Polite or formal language alone does not imply positivity (e.g., “I hope this finds you well,” “thank you,” “best regards”).\n",
988 |       "  - Expressions of concern framed as questions or requests for clarification, without asserting a negative judgment.\n",
989 |       "  - Mild or incidental compliments that are secondary to a routine request remain neutral unless strong positive cues dominate.\n",
990 |       "\n",
991 |       "Disambiguation notes and edge cases\n",
992 |       "- Concerns or hesitations presented as inquiries (e.g., asking about quality/safety protocols) are neutral unless they assert dissatisfaction or harm.\n",
993 |       "- Routine maintenance/service requests are neutral by default. They become positive only if accompanied by strong, explicit, and primary praise or gratitude.\n",
994 |       "- Occasional or mild praise embedded in an otherwise routine request (e.g., “your services have been instrumental…”) is still neutral unless multiple strong positive signals dominate the tone.\n",
995 |       "- Do not infer sentiment from sender identity, organization, or subject line alone; rely on explicit sentiment-bearing language in the body.\n",
996 |       "2025/08/12 20:02:00 INFO dspy.evaluate.evaluate: Average Metric: 2.533333333333333 / 3 (84.4%)\n",
997 |       "\n",
998 |       "2025/08/12 20:02:01 INFO dspy.evaluate.evaluate: Average Metric: 56.63333333333333 / 66 (85.8%)\n",
999 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New program is on the linear pareto front\n",
1000 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full valset score for new program: 0.8580808080808081\n",
1001 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full train_val score for new program: 0.8580808080808081\n",
1002 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Individual valset scores for new program: [0.9666666666666667, 0.6, 0.8666666666666667, 1.0, 0.9666666666666667, 0.9333333333333332, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.6333333333333333, 0.6666666666666666, 0.6, 1.0, 0.9333333333333332, 0.9666666666666667, 0.6333333333333333, 0.9333333333333332, 0.6666666666666666, 0.9333333333333332, 0.6333333333333333, 0.6666666666666666, 1.0, 0.9333333333333332, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.9666666666666667, 0.9333333333333332, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6333333333333333, 1.0, 0.9666666666666667, 0.6333333333333333, 0.9333333333333332, 0.6666666666666666, 0.9, 0.9666666666666667, 1.0, 0.6666666666666666, 0.6, 1.0, 0.9333333333333332, 0.9666666666666667, 0.9666666666666667, 0.9, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 0.6333333333333333, 0.9666666666666667, 0.6333333333333333, 0.6333333333333333, 1.0, 0.9333333333333332, 1.0, 0.9333333333333332, 1.0, 0.6]\n",
1003 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New valset pareto front scores: [0.9666666666666667, 1.0, 0.9, 1.0, 0.9666666666666667, 0.9333333333333332, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9333333333333332, 0.6666666666666666, 0.9333333333333332, 0.9666666666666667, 0.6666666666666666, 1.0, 0.9333333333333332, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.9666666666666667, 0.9333333333333332, 1.0, 1.0, 0.6666666666666666, 0.6333333333333333, 1.0, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.6666666666666666, 1.0, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9333333333333332, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.6666666666666666, 1.0, 0.9333333333333332, 1.0, 0.9333333333333332, 1.0, 0.6]\n",
1004 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Full valset pareto front score: 0.908080808080808\n",
1005 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Updated valset pareto front programs: [{2, 3}, {0}, {0}, {2, 3}, {3}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {1, 2, 3}, {3}, {3}, {0, 1, 2, 3}, {3}, {0}, {1, 2, 3}, {0}, {1, 2, 3}, {0}, {3}, {2}, {1, 2, 3}, {3}, {3}, {2}, {3}, {2, 3}, {2, 3}, {1, 2, 3}, {2, 3}, {0, 1, 2, 3}, {2, 3}, {0, 1, 2, 3}, {2, 3}, {3}, {0}, {2, 3}, {1, 2, 3}, {0, 1, 2, 3}, {3}, {0}, {0, 1, 2, 3}, {0, 1, 2}, {0}, {1, 2, 3}, {0, 1, 2, 3}, {0, 1, 2}, {0}, {3}, {0}, {0, 1, 2, 3}, {3}, {0}, {3}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 3}, {0}, {0}, {2, 3}, {0}, {2, 3}, {2, 3}, {3}, {3}, {1, 2, 3}, {0, 1, 2, 3}]\n",
1006 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best valset aggregate score so far: 0.8580808080808081\n",
1007 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best program as per aggregate score on train_val: 3\n",
1008 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best program as per aggregate score on valset: 3\n",
1009 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best score on valset: 0.8580808080808081\n",
1010 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Best score on train_val: 0.8580808080808081\n",
1011 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Linear pareto front program index: 3\n",
1012 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New program candidate index: 3\n",
1013 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Selected program 3 score: 0.8580808080808081\n",
1014 |       "Average Metric: 2.27 / 3 (75.6%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 51.91it/s]\n",
1015 |       "2025/08/12 20:02:01 INFO dspy.evaluate.evaluate: Average Metric: 2.2666666666666666 / 3 (75.6%)\n",
1016 |       "2025/08/12 20:02:01 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Proposed new text for categories_module.predict: You are classifying a single customer message sent to ProCare Facility Solutions (a facilities/cleaning services provider). Your job is to assign all and only the applicable categories from a fixed list, based strictly on the message content.\n",
1017 |       "\n",
1018 |       "Allowed categories and definitions:\n",
1019 |       "- cleaning_services_scheduling\n",
1020 |       "  - Use only when the message’s primary purpose is to coordinate timing/availability for cleaning services (initial booking, rescheduling, adjusting times).\n",
1021 |       "  - Typical signals: specific dates/times, availability windows, explicit reschedule/change requests, or back-and-forth around timing.\n",
1022 |       "  - Do NOT use when a timing phrase appears merely as part of a broader service request or complaint (e.g., “please arrange a team to visit,” “at your earliest convenience,” “as soon as possible”) without concrete scheduling logistics.\n",
1023 |       "\n",
1024 |       "- specialized_cleaning_services\n",
1025 |       "  - Use when the message mentions specific/specialized cleaning types or tasks beyond generic cleaning.\n",
1026 |       "  - Examples: deep cleaning, mold remediation, carpet cleaning/maintenance, window washing, post-construction cleanup, floor stripping/waxing, disinfection/sanitation.\n",
1027 |       "\n",
1028 |       "- customer_feedback_and_complaints\n",
1029 |       "  - Use when the message expresses dissatisfaction with prior service, reports subpar outcomes or communication issues, or requests remedies (redo, refund, re-clean).\n",
1030 |       "\n",
1031 |       "- quality_and_safety_concerns\n",
1032 |       "  - Use when the message raises quality shortfalls (e.g., areas still dirty, stains remaining) or safety/health risks (e.g., mold, hazards).\n",
1033 |       "  - Can co-occur with customer_feedback_and_complaints if the sender is unhappy with outcomes.\n",
1034 |       "\n",
1035 |       "- general_inquiries\n",
1036 |       "  - Use when the sender asks for information about services, scope, requirements, what’s included, or availability before committing, or seeks clarification/guidance about process.\n",
1037 |       "  - Often co-occurs with other categories when questions are asked (e.g., “Do you have availability next Tuesday?” with specialized service).\n",
1038 |       "\n",
1039 |       "Key decision rules and pitfalls to avoid:\n",
1040 |       "- Multi-label: Assign every category that is clearly supported by explicit statements in the message.\n",
1041 |       "- Strict evidence only: Do not infer beyond the text. Praise, urgency, client profile, or context (e.g., “confidential,” “high-profile,” “ASAP”) are not categories by themselves.\n",
1042 |       "- Scheduling vs. Complaint distinction:\n",
1043 |       "  - If rescheduling is proposed only as a fix within a complaint about poor service, do NOT include cleaning_services_scheduling. Use customer_feedback_and_complaints (and quality_and_safety_concerns if applicable).\n",
1044 |       "- Scheduling vs. Service request distinction (common pitfall):\n",
1045 |       "  - Do NOT tag cleaning_services_scheduling merely because the sender asks you to “arrange a visit,” “send a team,” or handle something “at your earliest convenience.”\n",
1046 |       "  - Only tag cleaning_services_scheduling when the message’s central focus is timing logistics (e.g., “Can you come Friday at 3 PM?” “What slots do you have next week?” “Please move our usual Friday cleaning to Monday.”).\n",
1047 |       "- Specialized services:\n",
1048 |       "  - If the message mentions deep cleaning, mold remediation, carpet care, window washing, etc., include specialized_cleaning_services along with any other applicable categories.\n",
1049 |       "- General inquiries:\n",
1050 |       "  - Tag when the sender is explicitly asking questions about offerings, inclusions, requirements, or availability before committing. If they merely request service without asking questions, do not add general_inquiries.\n",
1051 |       "- Allowed list only:\n",
1052 |       "  - Use only the categories listed above. Do not introduce new categories, even if they seem to fit the scenario.\n",
1053 |       "\n",
1054 |       "Output format (plain text):\n",
1055 |       "- reasoning: Briefly justify each selected category and note key exclusions (especially why cleaning_services_scheduling was or was not applied).\n",
1056 |       "- categories: A JSON array of the selected category strings, e.g., [\"specialized_cleaning_services\", \"quality_and_safety_concerns\"].\n",
1057 |       "- If no categories apply, return an empty JSON array: [].\n",
1058 |       "\n",
1059 |       "Process:\n",
1060 |       "1) Read the message once to identify intents: timing logistics, service-type specificity, feedback/complaint, quality/safety concerns, information requests.\n",
1061 |       "2) Map each intent to categories using the definitions and rules (especially the scheduling distinctions).\n",
1062 |       "3) Produce concise reasoning and the JSON array of categories using exact strings.\n",
1063 |       "\n",
1064 |       "Guidance examples (for internal reference):\n",
1065 |       "- “Please send a team ASAP to remediate mold in our studio. It’s a health risk.” → specialized_cleaning_services, quality_and_safety_concerns. Exclude cleaning_services_scheduling (no concrete timing logistics; urgency alone is not scheduling).\n",
1066 |       "- “Can you do a deep clean next Tuesday afternoon or Wednesday morning?” → specialized_cleaning_services, cleaning_services_scheduling, general_inquiries (asking about availability).\n",
1067 |       "- “Last cleaning left stains; please come back to fix.” → customer_feedback_and_complaints, quality_and_safety_concerns. Exclude cleaning_services_scheduling.\n",
1068 |       "- “We need to move our regular Friday cleaning to Monday this week.” → cleaning_services_scheduling.\n",
1069 |       "2025/08/12 20:02:01 INFO dspy.evaluate.evaluate: Average Metric: 2.333333333333333 / 3 (77.8%)\n",
1070 |       "\n",
1071 |       "2025/08/12 20:02:04 INFO dspy.evaluate.evaluate: Average Metric: 56.83333333333333 / 66 (86.1%)\n",
1072 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: New program is on the linear pareto front\n",
1073 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Full valset score for new program: 0.861111111111111\n",
1074 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Full train_val score for new program: 0.861111111111111\n",
1075 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Individual valset scores for new program: [0.9666666666666667, 0.6666666666666666, 0.9, 1.0, 0.9666666666666667, 0.9333333333333332, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.6, 0.6666666666666666, 0.6, 0.9666666666666667, 0.9666666666666667, 1.0, 0.6333333333333333, 0.9666666666666667, 0.6666666666666666, 0.9333333333333332, 0.6333333333333333, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.9666666666666667, 0.9, 1.0, 1.0, 0.6666666666666666, 0.6333333333333333, 1.0, 0.9666666666666667, 0.6666666666666666, 0.9333333333333332, 0.6666666666666666, 0.9, 0.9333333333333332, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.9666666666666667, 0.9333333333333332, 1.0, 0.9333333333333332, 1.0, 0.9333333333333332, 0.6333333333333333, 0.6333333333333333, 0.6333333333333333, 0.9333333333333332, 0.6333333333333333, 0.6333333333333333, 1.0, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.6]\n",
1076 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: New valset pareto front scores: [0.9666666666666667, 1.0, 0.9, 1.0, 0.9666666666666667, 0.9333333333333332, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 0.6666666666666666, 0.9333333333333332, 0.9666666666666667, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.9666666666666667, 0.9333333333333332, 1.0, 1.0, 0.6666666666666666, 0.6333333333333333, 1.0, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.6666666666666666, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.6666666666666666, 1.0, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.6]\n",
1077 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Full valset pareto front score: 0.9111111111111111\n",
1078 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Updated valset pareto front programs: [{2, 3, 4}, {0}, {0, 4}, {2, 3, 4}, {3, 4}, {3, 4}, {0, 1, 2, 3, 4}, {0, 1, 2, 3}, {1, 2, 3, 4}, {3, 4}, {3, 4}, {0, 1, 2, 3, 4}, {3, 4}, {0}, {1, 2, 3, 4}, {0}, {1, 2, 3}, {0}, {4}, {2}, {4}, {3, 4}, {3, 4}, {2}, {3, 4}, {2, 3, 4}, {4}, {1, 2, 3, 4}, {2, 3, 4}, {0, 1, 2, 3, 4}, {2, 3, 4}, {0, 1, 2, 3, 4}, {2, 3}, {3, 4}, {0, 4}, {2, 3, 4}, {1, 2, 3, 4}, {0, 1, 2, 3, 4}, {3, 4}, {0}, {0, 1, 2, 3, 4}, {0, 1, 2}, {0}, {1, 2, 3}, {0, 1, 2, 3, 4}, {0, 1, 2}, {0, 4}, {3, 4}, {0, 4}, {0, 1, 2, 3}, {4}, {0, 4}, {3, 4}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 3}, {0}, {0}, {2, 3, 4}, {0}, {2, 3, 4}, {4}, {3, 4}, {3, 4}, {1, 2, 3, 4}, {0, 1, 2, 3, 4}]\n",
1079 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best valset aggregate score so far: 0.861111111111111\n",
1080 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best program as per aggregate score on train_val: 4\n",
1081 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best program as per aggregate score on valset: 4\n",
1082 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best score on valset: 0.861111111111111\n",
1083 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best score on train_val: 0.861111111111111\n",
1084 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Linear pareto front program index: 4\n",
1085 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 6: New program candidate index: 4\n",
1086 |       "2025/08/12 20:02:04 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Selected program 4 score: 0.861111111111111\n",
1087 |       "Average Metric: 1.50 / 3 (50.0%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.31s/it]\n",
1088 |       "2025/08/12 20:02:10 INFO dspy.evaluate.evaluate: Average Metric: 1.5 / 3 (50.0%)\n",
1089 |       "\n",
1090 |       "2025/08/12 20:02:34 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Proposed new text for urgency_module.predict: Task: Read the provided message and determine the urgency.\n",
1091 |       "\n",
1092 |       "Context/domain:\n",
1093 |       "- Messages typically relate to facility management and services (e.g., facility operations, space utilization, security, sustainability, HVAC systems, maintenance, cleaning services) for a provider like ProCare Facility Solutions.\n",
1094 |       "- Senders may be residential or commercial clients and may reference residents, tenants, property operations, or prior support interactions.\n",
1095 |       "\n",
1096 |       "Output format (must be exactly two lines, in this order, no extra text or formatting):\n",
1097 |       "reasoning: <1–3 concise sentences explaining the key cues that determine urgency>\n",
1098 |       "urgency: <one of: low | medium | high>\n",
1099 |       "\n",
1100 |       "Decision process (apply in order):\n",
1101 |       "1) Check for safety/security risks or major operational impact.\n",
1102 |       "   - High if there is a clear or implied immediate risk to people, property, or security, or a major outage/disruption.\n",
1103 |       "2) Look for explicit urgency signals.\n",
1104 |       "   - Phrases like “Urgent,” “ASAP,” “immediate attention,” “critical,” “escalating,” “cannot wait,” or hard deadlines that imply immediacy increase urgency.\n",
1105 |       "3) Assess scope and impact.\n",
1106 |       "   - Affecting many residents/tenants/operations or causing loss of access increases urgency.\n",
1107 |       "4) Consider service history and tone.\n",
1108 |       "   - Repeated failed attempts to resolve, escalation language, or severe dissatisfaction demanding immediate corrective action raises urgency.\n",
1109 |       "5) If no risk and no time pressure are evident, default to low.\n",
1110 |       "\n",
1111 |       "Urgency levels and rules:\n",
1112 |       "- HIGH:\n",
1113 |       "  - Clear or implied immediate safety/security risk or major operational impact.\n",
1114 |       "  - Explicit urgent language requiring immediate action.\n",
1115 |       "  - Severe dissatisfaction paired with either a demand for immediate corrective action or evidence of repeated failed support and escalation.\n",
1116 |       "  - Examples/triggers: security breach or serious security gaps, fire/smoke, flooding/water leak, gas leak, electrical hazard, power outage, loss of access/lockouts, no heat in winter or no cooling in extreme heat affecting many people/operations.\n",
1117 |       "\n",
1118 |       "- MEDIUM:\n",
1119 |       "  - Time-sensitive issues affecting comfort, reliability, compliance, or service quality, but not emergencies and with no immediate safety/security risk.\n",
1120 |       "  - Active service problems where delay could worsen impact or trust, including repeated quality lapses, policy/compliance concerns, or dissatisfaction requiring prompt clarification/correction.\n",
1121 |       "  - Requests to schedule/repair/maintain “as soon as possible” without emergency conditions.\n",
1122 |       "  - Examples/triggers: HVAC making noise or inconsistent temperature; repeated use of non-compliant/chemical cleaners contrary to stated sustainability practices; recurring but non-hazardous malfunctions; requests for prompt adjustments to ongoing services.\n",
1123 |       "\n",
1124 |       "- LOW:\n",
1125 |       "  - General inquiries, quotes, pricing, capabilities, technical documentation/case studies, or exploratory discussions with no operational problem and no stated time pressure.\n",
1126 |       "  - Routine scheduling adjustments or portal assistance that do not block operations or cite deadlines.\n",
1127 |       "  - Compliments/feedback without urgency.\n",
1128 |       "  - Examples/triggers: evaluating services and asking for details/methodologies/case studies; changing a cleaning schedule; “not an emergency” with no other risk indicators.\n",
1129 |       "\n",
1130 |       "Key cues to weigh:\n",
1131 |       "- Explicit urgency language vs. statements like “not an emergency.”\n",
1132 |       "- Safety/security implications and operational continuity.\n",
1133 |       "- Impact scope (residents/tenants/business operations).\n",
1134 |       "- Deadlines/dates or requested response times.\n",
1135 |       "- Prior failed attempts and escalation tone (including threats to cancel/escalate).\n",
1136 |       "- Do not inflate urgency based solely on polite phrases like “prompt response,” “at your earliest convenience,” or skepticism demanding more information, when no risk or time pressure is present.\n",
1137 |       "\n",
1138 |       "Tie-breakers:\n",
1139 |       "- If the message explicitly says it’s not an emergency and no serious risk is evident, do not classify as high.\n",
1140 |       "- Dissatisfaction about ongoing service quality or compliance (e.g., sustainability practices) without immediate danger is typically medium.\n",
1141 |       "- Pre-sales or info-seeking skepticism/requests for documentation without a current issue are low.\n",
1142 |       "- If unclear and no risk/time pressure is indicated, default to low.\n",
1143 |       "2025/08/12 20:02:36 INFO dspy.evaluate.evaluate: Average Metric: 2.1666666666666665 / 3 (72.2%)\n",
1144 |       "2025/08/12 20:02:59 INFO dspy.evaluate.evaluate: Average Metric: 53.5 / 66 (81.1%)\n",
1145 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Full valset score for new program: 0.8106060606060606\n",
1146 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Full train_val score for new program: 0.8106060606060606\n",
1147 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Individual valset scores for new program: [0.9666666666666667, 0.3333333333333333, 0.5666666666666667, 1.0, 0.6333333333333333, 0.9333333333333332, 0.9666666666666667, 0.6333333333333333, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.6, 0.6666666666666666, 0.6, 0.9666666666666667, 0.6333333333333333, 1.0, 0.6333333333333333, 0.6333333333333333, 1.0, 0.9333333333333332, 0.6333333333333333, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6333333333333333, 0.9666666666666667, 0.9, 1.0, 1.0, 0.6666666666666666, 0.6333333333333333, 1.0, 0.9666666666666667, 0.6666666666666666, 0.9333333333333332, 0.6666666666666666, 0.9, 0.9333333333333332, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.9666666666666667, 0.9333333333333332, 1.0, 0.6, 1.0, 0.9333333333333332, 0.6333333333333333, 0.6333333333333333, 0.6333333333333333, 0.9333333333333332, 0.6333333333333333, 0.6333333333333333, 1.0, 0.6333333333333333, 1.0, 0.9333333333333332, 1.0, 0.6]\n",
1148 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: New valset pareto front scores: [0.9666666666666667, 1.0, 0.9, 1.0, 0.9666666666666667, 0.9333333333333332, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333332, 0.9666666666666667, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.9666666666666667, 0.9333333333333332, 1.0, 1.0, 0.6666666666666666, 0.6333333333333333, 1.0, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.6666666666666666, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.6666666666666666, 1.0, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.6]\n",
1149 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Full valset pareto front score: 0.9161616161616162\n",
1150 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Updated valset pareto front programs: [{2, 3, 4, 5}, {0}, {0, 4}, {2, 3, 4, 5}, {3, 4}, {3, 4, 5}, {0, 1, 2, 3, 4, 5}, {0, 1, 2, 3}, {1, 2, 3, 4, 5}, {3, 4, 5}, {3, 4, 5}, {0, 1, 2, 3, 4, 5}, {3, 4, 5}, {0}, {1, 2, 3, 4, 5}, {0}, {1, 2, 3}, {0}, {4, 5}, {2}, {4}, {5}, {3, 4, 5}, {2}, {3, 4, 5}, {2, 3, 4, 5}, {4}, {1, 2, 3, 4, 5}, {2, 3, 4, 5}, {0, 1, 2, 3, 4}, {2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {2, 3}, {3, 4, 5}, {0, 4, 5}, {2, 3, 4, 5}, {1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}, {3, 4, 5}, {0}, {0, 1, 2, 3, 4, 5}, {0, 1, 2}, {0}, {1, 2, 3}, {0, 1, 2, 3, 4, 5}, {0, 1, 2}, {0, 4, 5}, {3, 4}, {0, 4, 5}, {0, 1, 2, 3}, {4, 5}, {0, 4}, {3, 4, 5}, {0, 1, 2, 3}, {0, 1, 2, 3}, {0, 1, 3}, {0}, {0}, {2, 3, 4, 5}, {0}, {2, 3, 4, 5}, {4}, {3, 4, 5}, {3, 4, 5}, {1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5}]\n",
1151 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best valset aggregate score so far: 0.861111111111111\n",
1152 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best program as per aggregate score on train_val: 4\n",
1153 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best program as per aggregate score on valset: 4\n",
1154 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best score on valset: 0.861111111111111\n",
1155 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best score on train_val: 0.861111111111111\n",
1156 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Linear pareto front program index: 4\n",
1157 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 7: New program candidate index: 5\n",
1158 |       "2025/08/12 20:02:59 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Selected program 4 score: 0.861111111111111\n",
1159 |       "Average Metric: 2.97 / 3 (98.9%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  2.67s/it]\n",
1160 |       "2025/08/12 20:03:07 INFO dspy.evaluate.evaluate: Average Metric: 2.966666666666667 / 3 (98.9%)\n",
1161 |       "\n",
1162 |       "2025/08/12 20:08:42 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Proposed new text for sentiment_module.predict: Task\n",
1163 |       "- Read the provided message text and classify its overall sentiment as one of: positive, neutral, or negative.\n",
1164 |       "\n",
1165 |       "Input format\n",
1166 |       "- You will receive one field:\n",
1167 |       "  - message: A string that may include a Subject line and an email-style body.\n",
1168 |       "\n",
1169 |       "Output format\n",
1170 |       "- Output only a single lowercase label: positive, neutral, or negative.\n",
1171 |       "- Do not include any additional text, punctuation, or reasoning.\n",
1172 |       "\n",
1173 |       "How to decide the label\n",
1174 |       "- Focus on the overall emotional tone expressed about the service/interaction, not the message’s functional purpose (e.g., making a request) or formalities.\n",
1175 |       "- Read the entire body; do not infer sentiment from sender identity, role, organization, or the subject line alone.\n",
1176 |       "- Weigh the strength and dominance of explicit sentiment-bearing language. If signals are mixed or weak, default to neutral.\n",
1177 |       "\n",
1178 |       "Label definitions and cues\n",
1179 |       "- Positive:\n",
1180 |       "  - The message clearly expresses satisfaction, praise, gratitude, or enthusiasm that goes beyond routine politeness.\n",
1181 |       "  - Strong and/or multiple explicit positive cues dominate.\n",
1182 |       "  - Examples of strong positive cues: “satisfied client,” “exceptional service,” “truly appreciate,” “deeply appreciate,” “commendable,” “excellent,” “very happy,” “great,” “love working with you,” “highly value your expertise,” “dedication has resonated.”\n",
1183 |       "  - If a routine request includes multiple strong, primary praises and any issues are framed mildly without dissatisfaction, classify as positive.\n",
1184 |       "\n",
1185 |       "- Negative:\n",
1186 |       "  - The message expresses dissatisfaction, complaints, frustration, anger, fear, or disappointment about the service/experience.\n",
1187 |       "  - Explicit negative claims or emotions dominate.\n",
1188 |       "  - Examples of negative cues: “unacceptable,” “unsafe,” “poor quality,” “frustrated,” “angry,” “very disappointed,” “deep frustration,” “far below the standard,” “lack of coordination,” “slow and unhelpful,” “caused significant disruptions,” “no one is taking responsibility.”\n",
1189 |       "  - In mixed cases, strong explicit negative statements outweigh earlier generic praise (e.g., “I’ve been loyal, but…” followed by clear complaints → negative).\n",
1190 |       "\n",
1191 |       "- Neutral:\n",
1192 |       "  - Informational, inquisitive, or routine requests without clear emotional valence.\n",
1193 |       "  - Routine maintenance/service requests reported matter-of-factly.\n",
1194 |       "  - Polite or formal language alone does not imply positivity.\n",
1195 |       "  - Examples that remain neutral unless strong sentiment is present: “I hope this finds you well,” “thank you,” “best regards,” “I look forward to your response,” “please provide more information,” inquiries about protocols or eco-friendly options.\n",
1196 |       "  - Expressions of concern framed as questions or requests for clarification, without asserting dissatisfaction or harm, are neutral.\n",
1197 |       "  - Mild or incidental compliments embedded in a routine request (e.g., a single appreciative phrase) remain neutral unless multiple strong positive signals dominate.\n",
1198 |       "\n",
1199 |       "Disambiguation notes and edge cases\n",
1200 |       "- Do not infer sentiment from identity (e.g., “loyal customer,” “doctor”) or organization names; rely on explicit sentiment-bearing language in the body.\n",
1201 |       "- Mentioning a “problem” or “issue” alone is not necessarily negative; look for dissatisfaction words or frustrated tone to classify as negative.\n",
1202 |       "- Hopeful or forward-looking phrases (“hopeful for a positive outcome,” “look forward to hearing from you”) are neutral unless combined with strong praise.\n",
1203 |       "- If both praise and issues appear:\n",
1204 |       "  - Primary strong praise with mild, non-judgmental issue framing → positive.\n",
1205 |       "  - Clear complaints/frustration despite some praise → negative.\n",
1206 |       "  - Mixed but weak/ambiguous signals → neutral.\n",
1207 |       "\n",
1208 |       "Quality check before submitting\n",
1209 |       "- Ensure the output is exactly one of: positive, neutral, negative.\n",
1210 |       "- All lowercase, no extra spaces, punctuation, or explanation.\n",
1211 |       "2025/08/12 20:08:43 INFO dspy.evaluate.evaluate: Average Metric: 2.6333333333333333 / 3 (87.8%)\n",
1212 |       "2025/08/12 20:08:43 INFO dspy.teleprompt.gepa.gepa: Iteration 8: New subsample score is not better, skipping\n",
1213 |       "2025/08/12 20:08:43 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Selected program 2 score: 0.7924242424242424\n",
1214 |       "Average Metric: 2.17 / 3 (72.2%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.82s/it]\n",
1215 |       "2025/08/12 20:08:49 INFO dspy.evaluate.evaluate: Average Metric: 2.1666666666666665 / 3 (72.2%)\n",
1216 |       "\n",
1217 |       "2025/08/12 20:09:54 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Proposed new text for categories_module.predict: You are classifying a single customer message sent to ProCare Facility Solutions (a facilities/cleaning services provider). Your job is to assign every applicable category from a fixed list based only on the message content. Select all that apply. Do not add any category that is not clearly supported by the text.\n",
1218 |       "\n",
1219 |       "Allowed categories and definitions:\n",
1220 |       "- cleaning_services_scheduling\n",
1221 |       "  - Use only when the primary intent is to schedule, reschedule, adjust, or inquire about dates/times for cleaning services specifically.\n",
1222 |       "  - Includes: booking a cleaning, changing cleaning times, checking availability for cleaning, aligning cleaning schedules.\n",
1223 |       "  - Exclude for any non-cleaning work (e.g., HVAC maintenance), even if the sender says “please schedule a visit.”\n",
1224 |       "\n",
1225 |       "- specialized_cleaning_services\n",
1226 |       "  - Use when the message mentions specific/specialized cleaning types or tasks beyond generic cleaning.\n",
1227 |       "  - Examples: deep cleaning, carpet cleaning/maintenance, window washing, floor stripping/waxing, pressure washing.\n",
1228 |       "\n",
1229 |       "- customer_feedback_and_complaints\n",
1230 |       "  - Use when the message expresses dissatisfaction about prior or ongoing service, reports subpar work or communication, requests a redo/refund/remedy, or otherwise complains about service outcomes.\n",
1231 |       "\n",
1232 |       "- quality_and_safety_concerns\n",
1233 |       "  - Use when the message raises explicit concerns about service quality not meeting standards (e.g., still dirty/stained, malfunction persisting after service) or safety hazards (e.g., hazardous materials left unattended).\n",
1234 |       "  - Can co-occur with customer_feedback_and_complaints when the sender is unhappy with outcomes.\n",
1235 |       "  - Do not use for general anxiety about doing a task wrong or complexity of instructions unless an actual quality/safety issue is reported.\n",
1236 |       "\n",
1237 |       "- general_inquiries\n",
1238 |       "  - Use when the sender asks for information or clarification (e.g., what’s included, requirements, process, pricing, availability) before committing to any service.\n",
1239 |       "  - Often co-occurs with cleaning_services_scheduling or specialized_cleaning_services when the message is exploratory.\n",
1240 |       "\n",
1241 |       "- training_and_support_requests\n",
1242 |       "  - Use when the sender asks for guidance, simplified instructions, training, or on-site assistance to understand or perform cleaning/maintenance tasks (e.g., “provide a simpler guide,” “send someone to help me follow the maintenance plan”).\n",
1243 |       "\n",
1244 |       "- routine_maintenance_requests\n",
1245 |       "  - Use for non-emergency requests to perform routine maintenance on building systems or facilities (e.g., HVAC check-up, routine servicing per a maintenance plan).\n",
1246 |       "  - Note: HVAC maintenance falls here. This is not a cleaning service and should not trigger cleaning_services_scheduling.\n",
1247 |       "\n",
1248 |       "Key decision rules:\n",
1249 |       "- Multi-label: Assign every category clearly supported by the text.\n",
1250 |       "- Cleaning scheduling vs. complaint:\n",
1251 |       "  - If the main purpose is logistics around timing/availability for cleaning services, include cleaning_services_scheduling.\n",
1252 |       "  - If any scheduling or re-do is requested only as a remedy within a complaint about poor service, do NOT include cleaning_services_scheduling. Instead, include customer_feedback_and_complaints and quality_and_safety_concerns (and specialized_cleaning_services if specific cleaning tasks are referenced).\n",
1253 |       "- Cleaning scheduling vs. maintenance scheduling:\n",
1254 |       "  - Do not use cleaning_services_scheduling for maintenance (e.g., HVAC) even if the sender asks to “schedule a maintenance visit.” Use routine_maintenance_requests (and training_and_support_requests if they also seek guidance/help).\n",
1255 |       "- Specialized services:\n",
1256 |       "  - If the message names a specialized cleaning task (deep clean, carpet, windows, etc.), include specialized_cleaning_services alongside any other applicable categories.\n",
1257 |       "- Quality/safety threshold:\n",
1258 |       "  - Include quality_and_safety_concerns only when the message reports actual poor quality outcomes or safety hazards. Do not include it for a sender’s fear of making mistakes without an actual incident.\n",
1259 |       "- General inquiries:\n",
1260 |       "  - If the sender seeks information before committing to a service, include general_inquiries; it can co-occur with cleaning_services_scheduling and specialized_cleaning_services.\n",
1261 |       "- Strict schema:\n",
1262 |       "  - Use only the categories listed above. Do not invent or use unlisted categories (e.g., “facility_management_issues” is not allowed).\n",
1263 |       "- Evidence-only:\n",
1264 |       "  - Do not infer intents not supported by the text.\n",
1265 |       "\n",
1266 |       "Domain notes:\n",
1267 |       "- ProCare handles residential and commercial cleaning and related facility maintenance requests (e.g., HVAC routine maintenance).\n",
1268 |       "- Mentions of high-profile clients, confidentiality, or urgency do not create categories by themselves unless tied to definitions above.\n",
1269 |       "- HVAC-related requests are routine_maintenance_requests; they are not cleaning services.\n",
1270 |       "\n",
1271 |       "Output format (plain text):\n",
1272 |       "- Provide two top-level keys:\n",
1273 |       "  - reasoning: Briefly justify each selected category and note notable exclusions (especially cleaning scheduling vs. maintenance or complaint).\n",
1274 |       "  - categories: A JSON array of the selected category strings, e.g., [\"cleaning_services_scheduling\", \"general_inquiries\"].\n",
1275 |       "\n",
1276 |       "Process:\n",
1277 |       "1) Read the message and identify intents: scheduling logistics (for cleaning only), specialized cleaning tasks, feedback/complaints, explicit quality/safety concerns, information requests, training/support needs, and routine maintenance requests.\n",
1278 |       "2) Map each intent to categories using the definitions and rules above.\n",
1279 |       "3) Produce concise reasoning and the JSON array of categories.\n",
1280 |       "\n",
1281 |       "Clarifying examples (for edge cases):\n",
1282 |       "- “Please schedule a deep clean next Friday.” -> [\"cleaning_services_scheduling\", \"specialized_cleaning_services\"]\n",
1283 |       "- “Carpets still smell after yesterday’s service; please fix this and ensure safety protocols are followed.” -> [\"customer_feedback_and_complaints\", \"quality_and_safety_concerns\", \"specialized_cleaning_services\"]\n",
1284 |       "- “I need a simpler guide for my HVAC maintenance plan or someone to help me follow it.” -> [\"training_and_support_requests\", \"routine_maintenance_requests\"]\n",
1285 |       "- “Could you schedule an HVAC check-up at your earliest convenience?” -> [\"routine_maintenance_requests\"] (not cleaning_services_scheduling)\n",
1286 |       "2025/08/12 20:09:58 INFO dspy.evaluate.evaluate: Average Metric: 2.3 / 3 (76.7%)\n",
1287 |       "2025/08/12 20:10:06 INFO dspy.evaluate.evaluate: Average Metric: 52.56666666666666 / 66 (79.6%)\n",
1288 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Full valset score for new program: 0.7964646464646464\n",
1289 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Full train_val score for new program: 0.7964646464646464\n",
1290 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Individual valset scores for new program: [0.9666666666666667, 1.0, 0.9, 1.0, 0.6666666666666666, 0.6, 0.9666666666666667, 1.0, 1.0, 0.6666666666666666, 0.6333333333333333, 0.9666666666666667, 0.6333333333333333, 0.26666666666666666, 0.6333333333333333, 0.6666666666666666, 0.9333333333333332, 1.0, 0.6666666666666666, 1.0, 0.9, 0.3333333333333333, 0.6333333333333333, 0.9666666666666667, 0.3333333333333333, 1.0, 1.0, 0.5666666666666667, 1.0, 0.9666666666666667, 0.6666666666666666, 0.9666666666666667, 1.0, 0.6, 0.9666666666666667, 0.6666666666666666, 0.6333333333333333, 1.0, 0.6333333333333333, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.6333333333333333, 0.6666666666666666, 0.9666666666666667, 0.9333333333333332, 0.6333333333333333, 0.9, 0.6666666666666666, 0.9666666666666667, 0.6333333333333333, 0.3333333333333333, 0.6666666666666666, 1.0, 0.6333333333333333, 0.3333333333333333, 0.9666666666666667, 0.9666666666666667, 0.6, 0.6, 0.9666666666666667, 0.6]\n",
1291 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: New valset pareto front scores: [0.9666666666666667, 1.0, 0.9, 1.0, 0.9666666666666667, 0.9333333333333332, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9333333333333332, 0.9666666666666667, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.9666666666666667, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6333333333333333, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.6666666666666666, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.6666666666666666, 1.0, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.6]\n",
1292 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Full valset pareto front score: 0.9186868686868687\n",
1293 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Updated valset pareto front programs: [{2, 3, 4, 5, 6}, {0, 6}, {0, 4, 6}, {2, 3, 4, 5, 6}, {3, 4}, {3, 4, 5}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 6}, {1, 2, 3, 4, 5, 6}, {3, 4, 5}, {3, 4, 5}, {0, 1, 2, 3, 4, 5}, {3, 4, 5}, {0}, {1, 2, 3, 4, 5}, {0}, {1, 2, 3}, {0, 6}, {4, 5}, {6}, {4}, {5}, {3, 4, 5}, {2, 6}, {3, 4, 5}, {2, 3, 4, 5, 6}, {4, 6}, {1, 2, 3, 4, 5}, {2, 3, 4, 5, 6}, {0, 1, 2, 3, 4}, {6}, {0, 1, 2, 3, 4, 5, 6}, {6}, {3, 4, 5}, {0, 4, 5}, {2, 3, 4, 5, 6}, {1, 2, 3, 4, 5, 6}, {0, 1, 2, 3, 4, 5, 6}, {3, 4, 5}, {0, 6}, {6}, {0, 1, 2, 6}, {0, 6}, {1, 2, 3, 6}, {0, 1, 2, 3, 4, 5, 6}, {0, 1, 2, 6}, {0, 4, 5}, {3, 4}, {0, 4, 5, 6}, {0, 1, 2, 3}, {4, 5}, {0, 4}, {3, 4, 5}, {0, 1, 2, 3, 6}, {0, 1, 2, 3}, {0, 1, 3}, {0}, {0, 6}, {2, 3, 4, 5, 6}, {0}, {2, 3, 4, 5}, {4, 6}, {3, 4, 5}, {3, 4, 5}, {1, 2, 3, 4, 5}, {0, 1, 2, 3, 4, 5, 6}]\n",
1294 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best valset aggregate score so far: 0.861111111111111\n",
1295 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best program as per aggregate score on train_val: 4\n",
1296 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best program as per aggregate score on valset: 4\n",
1297 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best score on valset: 0.861111111111111\n",
1298 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Best score on train_val: 0.861111111111111\n",
1299 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Linear pareto front program index: 4\n",
1300 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 9: New program candidate index: 6\n",
1301 |       "2025/08/12 20:10:06 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Selected program 6 score: 0.7964646464646464\n",
1302 |       "Average Metric: 2.60 / 3 (86.7%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.31it/s]\n",
1303 |       "2025/08/12 20:10:08 INFO dspy.evaluate.evaluate: Average Metric: 2.6 / 3 (86.7%)\n",
1304 |       "\n",
1305 |       "2025/08/12 20:10:40 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Proposed new text for urgency_module.predict: Task: Read the provided message and determine the urgency.\n",
1306 |       "\n",
1307 |       "Context/domain:\n",
1308 |       "- Messages typically relate to facility management and services (e.g., facility operations, space utilization, security, sustainability, HVAC systems, maintenance, cleaning services) for a provider like ProCare Facility Solutions.\n",
1309 |       "- Senders may be residential or commercial clients and may reference residents, tenants, property operations, or prior support interactions.\n",
1310 |       "\n",
1311 |       "Input:\n",
1312 |       "- A single free-text message (may include a subject and body).\n",
1313 |       "\n",
1314 |       "Output format (strict):\n",
1315 |       "- Provide exactly two lines, in this order, no extra text, headers, or formatting:\n",
1316 |       "reasoning: <1–3 concise sentences explaining the key cues that determine urgency>\n",
1317 |       "urgency: <one of: low | medium | high>\n",
1318 |       "- Keep “urgency” value lowercase. Do not add additional fields, bullets, or commentary.\n",
1319 |       "\n",
1320 |       "Decision rules for urgency:\n",
1321 |       "- HIGH:\n",
1322 |       "  - Clear or implied immediate risk to safety/security or major operational impact.\n",
1323 |       "  - Explicit urgency signals: “Urgent,” “ASAP,” “Immediate,” “immediate attention required,” “critical,” “escalating,” “emergency.”\n",
1324 |       "  - Severe dissatisfaction with demand for immediate corrective action or evidence of repeated failed support and escalation.\n",
1325 |       "  - Common triggers/examples in this domain: active water leak/flooding, gas smell/leak, electrical hazard/sparks/smoke, fire/smoke, power outage affecting operations/residents, security breach or loss of access/lockout, no heat in winter or no cooling in extreme heat affecting many residents/operations.\n",
1326 |       "- MEDIUM:\n",
1327 |       "  - Time-sensitive issues affecting comfort, reliability, or service quality without immediate safety/security risk.\n",
1328 |       "  - Requests for prompt scheduling/repair/maintenance where delay could worsen impact but is not currently critical.\n",
1329 |       "  - Examples: HVAC inconsistent temperature or noises, minor malfunction, routine maintenance “at your earliest convenience,” stated as “not an emergency,” near-term deadlines that affect operations but are not safety-critical.\n",
1330 |       "- LOW:\n",
1331 |       "  - General inquiries, information requests, quotes, scheduling/options discussions, or interest in additional services with no stated or implied time pressure.\n",
1332 |       "  - Compliments/feedback without an urgent problem.\n",
1333 |       "\n",
1334 |       "Key cues to weigh:\n",
1335 |       "- Explicit urgency language vs. downgrading statements like “not an emergency.”\n",
1336 |       "- Safety/security implications and impact on operational continuity.\n",
1337 |       "- Scope of impact (individual vs. many residents/tenants/business operations).\n",
1338 |       "- Deadlines/dates or requested response times.\n",
1339 |       "- Prior failed attempts and escalation tone.\n",
1340 |       "- Do not inflate urgency based solely on polite phrases like “prompt assistance” if no urgent risk is present.\n",
1341 |       "\n",
1342 |       "Tie-breakers:\n",
1343 |       "- If the message explicitly says it’s not an emergency and no serious risk is evident, do not classify as high.\n",
1344 |       "- If multiple cues conflict, prioritize the highest credible risk to safety/security/operations.\n",
1345 |       "- If unclear and no risk/time pressure is indicated, default to low.\n",
1346 |       "\n",
1347 |       "Reasoning guidance:\n",
1348 |       "- In 1–3 sentences, cite the decisive cues (e.g., explicit urgency words, hazards like “leak,” “gas,” “power outage,” scope like “affecting residents,” or disclaimers like “not an emergency”).\n",
1349 |       "- Be specific and concise; do not restate the whole message.\n",
1350 |       "\n",
1351 |       "Quality checks before output:\n",
1352 |       "- Exactly two lines, starting with “reasoning:” then “urgency:”.\n",
1353 |       "- No extra lines, labels, or formatting; urgency is one of low/medium/high.\n",
1354 |       "2025/08/12 20:10:41 INFO dspy.evaluate.evaluate: Average Metric: 2.6 / 3 (86.7%)\n",
1355 |       "2025/08/12 20:10:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New subsample score is not better, skipping\n",
1356 |       "2025/08/12 20:10:41 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Selected program 5 score: 0.8106060606060606\n",
1357 |       "Average Metric: 2.80 / 3 (93.3%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:06<00:00,  2.21s/it]\n",
1358 |       "2025/08/12 20:10:48 INFO dspy.evaluate.evaluate: Average Metric: 2.8 / 3 (93.3%)\n",
1359 |       "\n",
1360 |       "2025/08/12 20:11:19 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Proposed new text for sentiment_module.predict: Task\n",
1361 |       "- Read the provided message text and classify its overall sentiment as one of: positive, neutral, or negative.\n",
1362 |       "\n",
1363 |       "Input format\n",
1364 |       "- You will receive one field:\n",
1365 |       "  - message: A string that may include a Subject line and an email-style body.\n",
1366 |       "\n",
1367 |       "Output format\n",
1368 |       "- Output only a single lowercase label: positive, neutral, or negative.\n",
1369 |       "- Do not include any additional text, punctuation, or reasoning.\n",
1370 |       "\n",
1371 |       "What to evaluate\n",
1372 |       "- Focus on the overall emotional tone expressed about the service/interaction.\n",
1373 |       "- Ignore the message’s functional purpose (e.g., asking questions, making requests) and routine formalities.\n",
1374 |       "\n",
1375 |       "Default rule\n",
1376 |       "- If signals are mixed or weak/ambiguous, output neutral.\n",
1377 |       "\n",
1378 |       "Label definitions and cues\n",
1379 |       "- Positive:\n",
1380 |       "  - The message clearly expresses satisfaction, praise, gratitude, or enthusiasm that goes beyond routine politeness.\n",
1381 |       "  - Strong and/or multiple explicit positive cues dominate the tone.\n",
1382 |       "  - Examples of strong positive cues: “satisfied customer,” “truly appreciate,” “excellent service,” “very happy,” “great,” “love working with you,” “continuing to enjoy the excellent service.”\n",
1383 |       "- Negative:\n",
1384 |       "  - The message expresses dissatisfaction, complaints, frustration, anger, fear, or disappointment about the service/experience.\n",
1385 |       "  - Explicit negative claims or emotions dominate.\n",
1386 |       "  - Examples of strong negative cues: “frustrated,” “unsatisfactory,” “vague,” “lack of follow-through,” “no tangible progress,” “questioning that decision,” “unacceptable,” “poor quality,” “unsafe,” “angry,” “very disappointed,” “reconsider my association,” urgent demands to rectify a problem.\n",
1387 |       "- Neutral:\n",
1388 |       "  - Informational, inquisitive, or routine requests without clear emotional valence.\n",
1389 |       "  - Polite/formal language alone does not imply positivity.\n",
1390 |       "  - Expressions of concern framed as questions or requests for clarification, without asserting a negative judgment.\n",
1391 |       "  - Mild or incidental compliments embedded in routine inquiries remain neutral unless strong positive cues dominate.\n",
1392 |       "  - Examples: requests for details, case studies, or how services work; generalized interest; “I hope this finds you well,” “thank you for your time,” “best regards,” “we are exploring options,” inquiries about safety/sustainability protocols posed without stated dissatisfaction.\n",
1393 |       "\n",
1394 |       "Disambiguation notes and edge cases\n",
1395 |       "- Do not infer sentiment from the sender’s identity, organization, tenure, or subject line alone; rely on explicit sentiment-bearing language in the body.\n",
1396 |       "- Routine maintenance/service requests are neutral by default; they become positive only if accompanied by strong, explicit, and primary praise or gratitude.\n",
1397 |       "- Concerns or hesitations presented as inquiries (e.g., asking about eco-friendly practices or pet-safe cleaning products) are neutral unless they assert dissatisfaction, harm, or a negative judgment.\n",
1398 |       "- Mild praise within an otherwise routine inquiry (e.g., noting a “reputation for excellence”) remains neutral unless multiple strong positive cues are primary.\n",
1399 |       "- Polite closings or courtesies (e.g., “thank you,” “I look forward to your response”) do not by themselves make a message positive.\n",
1400 |       "- If a message contains both praise and complaints, determine which tone dominates; strong complaints override politeness and lead to negative, while strong, primary praise with no complaints leads to positive. If neither dominates, choose neutral.\n",
1401 |       "\n",
1402 |       "Decision process (for internal use)\n",
1403 |       "1) Identify explicit emotional cues about the service/interaction.\n",
1404 |       "2) If strong positive cues dominate, output positive.\n",
1405 |       "3) Else if strong negative cues dominate, output negative.\n",
1406 |       "4) Else output neutral.\n",
1407 |       "\n",
1408 |       "Output constraint\n",
1409 |       "- Return exactly one of: positive, neutral, negative.\n",
1410 |       "2025/08/12 20:11:21 INFO dspy.evaluate.evaluate: Average Metric: 2.8 / 3 (93.3%)\n",
1411 |       "2025/08/12 20:11:21 INFO dspy.teleprompt.gepa.gepa: Iteration 11: New subsample score is not better, skipping\n",
1412 |       "2025/08/12 20:11:21 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Selected program 6 score: 0.7964646464646464\n",
1413 |       "Average Metric: 2.23 / 3 (74.4%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.12s/it]\n",
1414 |       "2025/08/12 20:11:24 INFO dspy.evaluate.evaluate: Average Metric: 2.2333333333333334 / 3 (74.4%)\n",
1415 |       "\n",
1416 |       "2025/08/12 20:12:11 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Proposed new text for sentiment_module.predict: Task\n",
1417 |       "- You will be given a single input field named \"message\" containing a professional email or support inquiry (often about facility management topics such as services, maintenance plans, sustainability/energy efficiency, training programs, or in-house team development). Your job is to determine the overall sentiment of the message.\n",
1418 |       "\n",
1419 |       "Output format\n",
1420 |       "- Return only one lowercase label: positive, neutral, or negative.\n",
1421 |       "- Do not include explanations, reasoning, or any other text unless explicitly requested.\n",
1422 |       "\n",
1423 |       "General approach\n",
1424 |       "- Judge the overall sentiment conveyed toward the recipient/company/services.\n",
1425 |       "- Focus on explicit emotional content and its intensity rather than routine politeness.\n",
1426 |       "- Determine the primary intent of the message (e.g., inquiry/request vs. praise/complaint).\n",
1427 |       "- If both positive and negative cues are present, choose the predominant one. If they balance out or are weak/incidental, choose neutral.\n",
1428 |       "\n",
1429 |       "Label definitions and decision rules\n",
1430 |       "1) Neutral\n",
1431 |       "   - Most professional inquiries/requests for information or support.\n",
1432 |       "   - Messages that are polite, respectful, or appreciative only in a routine way (e.g., “I hope this finds you well,” “Thank you for your time,” “Looking forward to your response”).\n",
1433 |       "   - Messages that include mild or incidental positive statements as context but are primarily utilitarian requests (e.g., “We’re satisfied so far” or “We appreciate your services”) without strong praise or excitement.\n",
1434 |       "   - Use neutral when the message’s main purpose is to ask for info/training/support and any positive wording is brief, generic, or secondary.\n",
1435 |       "\n",
1436 |       "2) Positive\n",
1437 |       "   - The message’s clear intent is to express praise, approval, enthusiasm, or strong satisfaction about the company/services.\n",
1438 |       "   - Contains explicit and non-incidental positive language directed at the recipient/services, especially with intensity or enthusiasm (e.g., “thoroughly impressed,” “commendable,” “we’re excited about collaborating,” “fantastic,” “excellent,” “we love your service”).\n",
1439 |       "   - Positive expressions are central to the message, not just a courtesy aside.\n",
1440 |       "\n",
1441 |       "3) Negative\n",
1442 |       "   - Expresses dissatisfaction, complaint, frustration, disappointment, or concern about problems (e.g., “not satisfied,” “disappointed,” “frustrated,” “issue,” “problem,” “concerned”).\n",
1443 |       "   - The negative emotion is directed toward the recipient/services and is more than a neutral problem description.\n",
1444 |       "\n",
1445 |       "Heuristics specific to this domain (facility-management emails)\n",
1446 |       "- Professional emails to providers like ProCare Facility Solutions commonly include formal greetings, polite closings, and mild appreciation; treat these as neutral unless there is strong, central praise or clear complaint.\n",
1447 |       "- Interest in training programs, maintenance plans, or sustainability practices is neutral by default, even if accompanied by brief compliments or statements like “we’ve been satisfied thus far” or “we appreciate your quality,” unless the message primarily aims to praise or shows clear excitement.\n",
1448 |       "- Strong praise terms (e.g., “thoroughly impressed,” “commendable,” “excited about the possibility”) can justify a positive label when they are prominent and central to the message.\n",
1449 |       "- Do not infer sentiment from the sender’s background (e.g., professor, first responder, resident) or the topic itself (e.g., fire safety, Jewish history); rely only on expressed sentiment toward the recipient/services.\n",
1450 |       "\n",
1451 |       "Tie-breakers\n",
1452 |       "- If sentiment cues are weak, generic, or incidental to a primarily informational/request-oriented message, choose neutral.\n",
1453 |       "- If unsure between positive and neutral due to a single mild compliment embedded in a request, choose neutral.\n",
1454 |       "2025/08/12 20:12:13 INFO dspy.evaluate.evaluate: Average Metric: 2.9 / 3 (96.7%)\n",
1455 |       "2025/08/12 20:12:19 INFO dspy.evaluate.evaluate: Average Metric: 54.56666666666666 / 66 (82.7%)\n",
1456 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Full valset score for new program: 0.8267676767676767\n",
1457 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Full train_val score for new program: 0.8267676767676767\n",
1458 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Individual valset scores for new program: [0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.9333333333333332, 0.9666666666666667, 0.6666666666666666, 1.0, 0.6666666666666666, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.6, 0.9666666666666667, 0.6666666666666666, 0.9333333333333332, 1.0, 1.0, 0.6666666666666666, 0.9, 0.6666666666666666, 0.9666666666666667, 0.6333333333333333, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.5666666666666667, 0.6666666666666666, 0.9666666666666667, 0.6666666666666666, 0.9666666666666667, 0.6666666666666666, 0.9333333333333332, 0.9666666666666667, 0.6666666666666666, 0.6333333333333333, 1.0, 0.6333333333333333, 0.6666666666666666, 0.9666666666666667, 0.6666666666666666, 0.9666666666666667, 0.9666666666666667, 1.0, 0.6666666666666666, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9333333333333332, 0.9666666666666667, 0.9, 0.6666666666666666, 0.9666666666666667, 0.6333333333333333, 0.3333333333333333, 0.6666666666666666, 1.0, 0.6333333333333333, 0.6666666666666666, 0.6333333333333333, 0.9666666666666667, 0.6, 0.9333333333333332, 0.9666666666666667, 0.9333333333333332]\n",
1459 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: New valset pareto front scores: [0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.9333333333333332, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.6666666666666666, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.9666666666666667, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6333333333333333, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6333333333333333, 0.6666666666666666, 1.0, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.9333333333333332]\n",
1460 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Full valset pareto front score: 0.9338383838383838\n",
1461 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Updated valset pareto front programs: [{2, 3, 4, 5, 6, 7}, {0, 6, 7}, {0, 4, 6, 7}, {2, 3, 4, 5, 6, 7}, {7}, {3, 4, 5, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 6}, {1, 2, 3, 4, 5, 6, 7}, {3, 4, 5}, {3, 4, 5}, {0, 1, 2, 3, 4, 5}, {3, 4, 5, 7}, {0}, {7}, {0}, {1, 2, 3}, {0, 6, 7}, {4, 5, 7}, {6}, {4}, {5}, {7}, {2, 6}, {3, 4, 5, 7}, {2, 3, 4, 5, 6}, {4, 6}, {1, 2, 3, 4, 5}, {2, 3, 4, 5, 6}, {0, 1, 2, 3, 4}, {6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {6}, {3, 4, 5}, {0, 4, 5}, {2, 3, 4, 5, 6, 7}, {1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {3, 4, 5}, {0, 6}, {6, 7}, {0, 1, 2, 6}, {0, 6, 7}, {1, 2, 3, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 6}, {7}, {3, 4, 7}, {0, 4, 5, 6, 7}, {0, 1, 2, 3}, {4, 5}, {0, 4}, {3, 4, 5}, {0, 1, 2, 3, 6, 7}, {0, 1, 2, 3}, {0, 1, 3}, {0}, {0, 6, 7}, {2, 3, 4, 5, 6, 7}, {0, 7}, {2, 3, 4, 5}, {4, 6, 7}, {3, 4, 5}, {3, 4, 5, 7}, {1, 2, 3, 4, 5}, {7}]\n",
1462 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Best valset aggregate score so far: 0.861111111111111\n",
1463 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Best program as per aggregate score on train_val: 4\n",
1464 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Best program as per aggregate score on valset: 4\n",
1465 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Best score on valset: 0.861111111111111\n",
1466 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Best score on train_val: 0.861111111111111\n",
1467 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Linear pareto front program index: 4\n",
1468 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 12: New program candidate index: 7\n",
1469 |       "2025/08/12 20:12:19 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Selected program 4 score: 0.861111111111111\n",
1470 |       "Average Metric: 2.50 / 3 (83.3%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.56s/it]\n",
1471 |       "2025/08/12 20:12:27 INFO dspy.evaluate.evaluate: Average Metric: 2.5 / 3 (83.3%)\n",
1472 |       "\n",
1473 |       "2025/08/12 20:13:46 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Proposed new text for categories_module.predict: Task: Classify a single customer message sent to ProCare Facility Solutions (a facilities/cleaning services provider) by assigning all and only the applicable categories from a fixed list, based strictly on the message content.\n",
1474 |       "\n",
1475 |       "Scope and domain cues:\n",
1476 |       "- ProCare provides cleaning services and broader facility management support. Messages may cover cleaning, specialized cleaning tasks, routine equipment maintenance (e.g., HVAC), facility management coordination, and sustainability initiatives (e.g., energy efficiency).\n",
1477 |       "- Do not infer services or intents not explicitly stated. Assign multiple categories when the text clearly supports them.\n",
1478 |       "\n",
1479 |       "Allowed categories and precise definitions:\n",
1480 |       "- cleaning_services_scheduling\n",
1481 |       "  - Use only when the message’s central purpose is to coordinate concrete timing/logistics for cleaning/services (initial booking with specific dates/times, asking for available slots, rescheduling or moving a known slot).\n",
1482 |       "  - Typical signals: explicit dates/times (“Friday at 3 PM”), options (“next Tue afternoon or Wed morning”), “what slots do you have next week?”, or “move our usual Friday cleaning to Monday.”\n",
1483 |       "  - Exclusions:\n",
1484 |       "    - Do NOT tag when the sender merely says “ASAP,” “at your earliest convenience,” “please schedule a visit,” without concrete timing logistics.\n",
1485 |       "    - Do NOT tag when scheduling is mentioned only as a remedy inside a complaint (use customer_feedback_and_complaints instead, plus other relevant categories).\n",
1486 |       "\n",
1487 |       "- specialized_cleaning_services\n",
1488 |       "  - Mention of specific/specialized cleaning types or tasks beyond generic cleaning.\n",
1489 |       "  - Examples: deep cleaning, mold remediation, carpet cleaning/maintenance, window washing, post-construction cleanup, disinfection/sanitation, floor stripping/waxing.\n",
1490 |       "\n",
1491 |       "- customer_feedback_and_complaints\n",
1492 |       "  - Dissatisfaction with prior service outcomes or communication (e.g., delays, lack of response), requests for fixes (redo, refund, re-clean), or frustration with process.\n",
1493 |       "  - Can co-occur with other categories (e.g., routine_maintenance_requests) when the message is about that service type.\n",
1494 |       "\n",
1495 |       "- quality_and_safety_concerns\n",
1496 |       "  - Raises quality shortfalls (areas still dirty, stains remaining) or health/safety risks (e.g., mold, hazards).\n",
1497 |       "  - Can co-occur with customer_feedback_and_complaints if the sender is unhappy with outcomes.\n",
1498 |       "\n",
1499 |       "- general_inquiries\n",
1500 |       "  - Explicit questions about services offered, inclusions, requirements, process/initial steps, or general availability before committing.\n",
1501 |       "  - Can co-occur with other categories (e.g., specialized_cleaning_services, facility_management_issues).\n",
1502 |       "  - Exclude if the message only requests service without asking questions.\n",
1503 |       "\n",
1504 |       "- routine_maintenance_requests\n",
1505 |       "  - Requests for periodic or proactive equipment/facility upkeep (e.g., HVAC system check-up), routine maintenance without specialized cleaning tasks mentioned.\n",
1506 |       "  - This category is about the service type; pair with cleaning_services_scheduling only if concrete timing logistics are central to the message.\n",
1507 |       "\n",
1508 |       "- facility_management_issues\n",
1509 |       "  - Messages focused on broader facility management services/coordinations beyond cleaning (e.g., overall facility management for a residential complex, coordination of space utilization, integrated service management).\n",
1510 |       "\n",
1511 |       "- sustainability_and_environmental_practices\n",
1512 |       "  - Focus on energy efficiency, sustainability programs, environmental impact reduction, or green practices as part of the request or inquiry.\n",
1513 |       "\n",
1514 |       "Key decision rules and pitfalls to avoid:\n",
1515 |       "- Multi-label: Assign every category that is clearly supported by explicit text.\n",
1516 |       "- Strict evidence only: Do not infer beyond the message. Tone (praise, urgency) or client profile is not a category.\n",
1517 |       "- Scheduling vs. Complaint:\n",
1518 |       "  - If a sender is complaining about delays/communication and also asks to “get it scheduled,” treat it as customer_feedback_and_complaints (and the relevant service type, e.g., routine_maintenance_requests). Do NOT add cleaning_services_scheduling unless the message primarily negotiates concrete timing slots.\n",
1519 |       "- Scheduling vs. Service request:\n",
1520 |       "  - Do NOT tag cleaning_services_scheduling merely because the sender asks to “arrange a visit,” “send a team,” or “at your earliest convenience.” Concrete timing logistics are required.\n",
1521 |       "- Specialized services:\n",
1522 |       "  - If the message mentions deep clean, mold remediation, carpet care, window washing, disinfection, post-construction cleanup, or floor work, include specialized_cleaning_services.\n",
1523 |       "- General inquiries:\n",
1524 |       "  - Tag when the sender asks about offerings, what’s included, process/initial steps, or “how quickly we can get started” (without concrete dates/times). This can co-occur with facility_management_issues and sustainability_and_environmental_practices.\n",
1525 |       "\n",
1526 |       "Output format (plain text):\n",
1527 |       "- reasoning: Briefly justify each selected category and key exclusions (especially why cleaning_services_scheduling was or was not applied).\n",
1528 |       "- categories: A JSON array of the selected category strings, e.g., [\"specialized_cleaning_services\", \"quality_and_safety_concerns\"].\n",
1529 |       "- If no categories apply, return an empty JSON array: [].\n",
1530 |       "\n",
1531 |       "Process:\n",
1532 |       "1) Read the message to identify intents: timing logistics, specific service types (specialized cleaning or routine maintenance), complaints/dissatisfaction, quality/safety issues, information requests, facility management and sustainability focus.\n",
1533 |       "2) Map each intent to categories using the definitions and decision rules above.\n",
1534 |       "3) Produce concise reasoning and the JSON array using exact category strings.\n",
1535 |       "\n",
1536 |       "Guidance examples aligned to edge cases seen:\n",
1537 |       "- “Please send a team ASAP to remediate mold in our studio. It’s a health risk.” → [\"specialized_cleaning_services\", \"quality_and_safety_concerns\"]. Exclude cleaning_services_scheduling (urgency ≠ concrete timing).\n",
1538 |       "- “Can you do a deep clean next Tuesday afternoon or Wednesday morning?” → [\"specialized_cleaning_services\", \"cleaning_services_scheduling\", \"general_inquiries\"].\n",
1539 |       "- “Last cleaning left stains; please come back to fix.” → [\"customer_feedback_and_complaints\", \"quality_and_safety_concerns\"]. Exclude cleaning_services_scheduling.\n",
1540 |       "- “We need to move our regular Friday cleaning to Monday this week.” → [\"cleaning_services_scheduling\"].\n",
1541 |       "- “I need an HVAC routine check; please schedule a visit at your earliest convenience.” → [\"routine_maintenance_requests\"]. Exclude cleaning_services_scheduling (no concrete timing).\n",
1542 |       "- “I’ve tried multiple times to schedule a routine HVAC check and haven’t heard back. Please help get this scheduled.” → [\"routine_maintenance_requests\", \"customer_feedback_and_complaints\"]. Exclude cleaning_services_scheduling (complaint-focused).\n",
1543 |       "- “We need comprehensive facility management focused on space utilization and sustainability. How quickly can we get started and what are the initial steps?” → [\"facility_management_issues\", \"sustainability_and_environmental_practices\", \"general_inquiries\"]. Exclude cleaning_services_scheduling (no concrete timing).\n",
1544 |       "2025/08/12 20:13:49 INFO dspy.evaluate.evaluate: Average Metric: 2.6333333333333333 / 3 (87.8%)\n",
1545 |       "2025/08/12 20:13:59 INFO dspy.evaluate.evaluate: Average Metric: 56.766666666666666 / 66 (86.0%)\n",
1546 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Full valset score for new program: 0.86010101010101\n",
1547 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Full train_val score for new program: 0.86010101010101\n",
1548 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Individual valset scores for new program: [0.9666666666666667, 0.6666666666666666, 0.9, 0.9666666666666667, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9333333333333332, 1.0, 0.9666666666666667, 0.6, 0.6, 0.6666666666666666, 0.9333333333333332, 1.0, 1.0, 0.6666666666666666, 0.9333333333333332, 0.6333333333333333, 1.0, 0.6333333333333333, 0.6666666666666666, 1.0, 0.9666666666666667, 0.6, 0.9333333333333332, 0.9666666666666667, 0.6666666666666666, 0.9666666666666667, 0.9666666666666667, 0.9333333333333332, 0.9666666666666667, 0.6666666666666666, 0.6333333333333333, 1.0, 1.0, 0.6333333333333333, 0.9666666666666667, 0.6333333333333333, 1.0, 0.9666666666666667, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 0.9666666666666667, 0.9, 1.0, 0.9333333333333332, 0.9, 1.0, 0.9666666666666667, 0.6333333333333333, 0.6333333333333333, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.6]\n",
1549 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: New valset pareto front scores: [0.9666666666666667, 1.0, 0.9, 1.0, 1.0, 0.9666666666666667, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 0.6666666666666666, 0.9666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.9666666666666667, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6333333333333333, 1.0, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 1.0, 0.9333333333333332, 1.0, 0.9666666666666667, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.9666666666666667, 1.0, 0.9666666666666667, 1.0, 0.9333333333333332]\n",
1550 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Full valset pareto front score: 0.9378787878787879\n",
1551 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Updated valset pareto front programs: [{2, 3, 4, 5, 6, 7, 8}, {0, 6, 7}, {0, 4, 6, 7, 8}, {2, 3, 4, 5, 6, 7}, {8, 7}, {8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 6, 8}, {1, 2, 3, 4, 5, 6, 7}, {8}, {3, 4, 5}, {0, 1, 2, 3, 4, 5, 8}, {3, 4, 5, 7, 8}, {0}, {7}, {0}, {1, 2, 3}, {0, 8, 6, 7}, {8, 4, 5, 7}, {6}, {4}, {5}, {8}, {2, 6}, {3, 4, 5, 7, 8}, {2, 3, 4, 5, 6, 8}, {4, 6}, {1, 2, 3, 4, 5}, {2, 3, 4, 5, 6}, {0, 1, 2, 3, 4}, {8, 6, 7}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {6}, {3, 4, 5}, {0, 4, 5}, {2, 3, 4, 5, 6, 7, 8}, {1, 2, 3, 4, 5, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7, 8}, {8}, {0, 6}, {8, 6, 7}, {0, 1, 2, 6}, {8}, {1, 2, 3, 6, 7, 8}, {0, 1, 2, 3, 4, 5, 6, 7}, {0, 1, 2, 6}, {7}, {3, 4, 7}, {0, 4, 5, 6, 7}, {8}, {4, 5}, {0, 4}, {8, 3, 4, 5}, {0, 1, 2, 3, 6, 7, 8}, {0, 1, 2, 3}, {0, 1, 3}, {0}, {0, 8, 6, 7}, {8}, {0, 8, 7}, {2, 3, 4, 5}, {8, 4, 6, 7}, {3, 4, 5}, {8}, {1, 2, 3, 4, 5}, {7}]\n",
1552 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Best valset aggregate score so far: 0.861111111111111\n",
1553 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Best program as per aggregate score on train_val: 4\n",
1554 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Best program as per aggregate score on valset: 4\n",
1555 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Best score on valset: 0.861111111111111\n",
1556 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Best score on train_val: 0.861111111111111\n",
1557 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Linear pareto front program index: 4\n",
1558 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 13: New program candidate index: 8\n",
1559 |       "2025/08/12 20:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Selected program 8 score: 0.86010101010101\n",
1560 |       "Average Metric: 2.57 / 3 (85.6%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.13it/s]\n",
1561 |       "2025/08/12 20:14:01 INFO dspy.evaluate.evaluate: Average Metric: 2.5666666666666664 / 3 (85.6%)\n",
1562 |       "2025/08/12 20:14:01 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Proposed new text for urgency_module.predict: Task\n",
1563 |       "- Read the provided message and determine its urgency.\n",
1564 |       "\n",
1565 |       "Domain/context\n",
1566 |       "- Messages are about facility management/services for a provider like ProCare Facility Solutions (e.g., facility operations, space utilization, security, sustainability practices/waste management, HVAC, plumbing, electrical, maintenance/repairs, cleaning/janitorial).\n",
1567 |       "- Senders may be residential or commercial clients and may mention residents/tenants, property operations, business continuity, or prior support interactions.\n",
1568 |       "\n",
1569 |       "Output format (strict)\n",
1570 |       "- Provide exactly two fields, in this order, with no extra text or formatting:\n",
1571 |       "reasoning: <1–3 concise sentences explaining the key cues that determine urgency>\n",
1572 |       "urgency: <one of: low | medium | high>\n",
1573 |       "\n",
1574 |       "How to determine urgency\n",
1575 |       "- HIGH:\n",
1576 |       "  - Clear or implied immediate risk to safety/security or major operational impact.\n",
1577 |       "  - Explicit urgency language: “Urgent,” “ASAP,” “immediate attention,” “critical,” “escalating,” “immediate dispatch,” etc.\n",
1578 |       "  - Severe dissatisfaction demanding immediate corrective action, especially with evidence of repeated failed support or dismissive responses.\n",
1579 |       "  - Common high triggers in this domain: security breach/serious security gaps (e.g., failed locks, disabled alarms), fire/smoke, flooding/active water leak, gas smell/leak, electrical hazards (burning smell/sparking), power outage, loss of access, system-down events critical to operations (e.g., HVAC failure during extreme heat/cold, especially affecting many residents or business operations).\n",
1580 |       "\n",
1581 |       "- MEDIUM:\n",
1582 |       "  - Time-sensitive issues affecting comfort/reliability/service quality but not an emergency and no immediate safety/security risk.\n",
1583 |       "  - Degradations or malfunctions needing prompt scheduling/repair (e.g., HVAC noisy/inconsistent temps, minor leak not causing damage, intermittent access issues) where delay could worsen impact.\n",
1584 |       "  - Deadlines or near-term needs without emergency framing (e.g., “this week,” “before tenants move in”) or “at your earliest convenience” when paired with a current service problem.\n",
1585 |       "\n",
1586 |       "- LOW:\n",
1587 |       "  - General inquiries, information requests, quotes, preventative/routine maintenance with flexible timing, or interest in additional services without a current problem.\n",
1588 |       "  - Explicit statements like “not urgent” or “not an emergency,” with no safety risk and no operational disruption.\n",
1589 |       "  - Compliments/feedback that do not request immediate action.\n",
1590 |       "\n",
1591 |       "Key cues to weigh\n",
1592 |       "- Explicit urgency terms vs. explicit de-escalators (“not urgent,” “not an emergency”).\n",
1593 |       "- Safety/security implications and risk of property damage.\n",
1594 |       "- Scope/impact: residents/tenants/business operations affected vs. single/isolated inconvenience.\n",
1595 |       "- Environmental/seasonal context (e.g., no cooling during extreme heat; no heat in winter).\n",
1596 |       "- Deadlines/timelines and requested response times.\n",
1597 |       "- Evidence of prior failed attempts, dismissive on-site responses, or escalation tone.\n",
1598 |       "- Do not inflate urgency based solely on polite phrases like “prompt attention” or “earliest convenience” if no risk/time pressure is present.\n",
1599 |       "\n",
1600 |       "Tie-breakers and edge cases\n",
1601 |       "- If the message explicitly says it’s not an emergency and no serious risk is evident, do not classify as high; default to low unless there is a concrete deadline or ongoing service degradation justifying medium.\n",
1602 |       "- If unclear and no safety/security risk, operational disruption, or time pressure is indicated, default to low.\n",
1603 |       "- Complaints about sustainability/cleaning practices can be high if they demand immediate corrective action and cite failed/dismissive prior support; otherwise medium if time-sensitive but not safety-related.\n",
1604 |       "\n",
1605 |       "General approach\n",
1606 |       "- Identify explicit urgency language, safety/security/property-damage risks, operational scope, and timing cues.\n",
1607 |       "- Balance urgency signals against any de-escalating statements and the presence/absence of active disruption.\n",
1608 |       "- Keep reasoning concise (1–3 sentences) and output only the two required fields.\n",
1609 |       "\n",
1610 |       "2025/08/12 20:14:01 INFO dspy.evaluate.evaluate: Average Metric: 2.5666666666666664 / 3 (85.6%)\n",
1611 |       "2025/08/12 20:14:01 INFO dspy.teleprompt.gepa.gepa: Iteration 14: New subsample score is not better, skipping\n",
1612 |       "2025/08/12 20:14:01 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Selected program 7 score: 0.8267676767676767\n",
1613 |       "Average Metric: 2.27 / 3 (75.6%): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:05<00:00,  1.92s/it]\n",
1614 |       "2025/08/12 20:14:07 INFO dspy.evaluate.evaluate: Average Metric: 2.2666666666666666 / 3 (75.6%)\n",
1615 |       "\n",
1616 |       "2025/08/12 20:23:06 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Proposed new text for categories_module.predict: You are classifying a single customer message sent to ProCare Facility Solutions (a facilities/cleaning services provider). Your job is to assign every applicable category from a fixed list based only on the message content. Select all that apply. Do not add any category that is not clearly supported by the text.\n",
1617 |       "\n",
1618 |       "TASK STRATEGY (high-level):\n",
1619 |       "- Read the message once to understand the overall intent(s).\n",
1620 |       "- Identify explicit intents/signals: scheduling for cleaning, mention of specialized cleaning tasks, feedback/complaints, explicit quality/safety issues, general information requests, training/support, routine facility maintenance (e.g., HVAC), and sustainability/eco-friendly topics.\n",
1621 |       "- Map each identified intent to the categories below.\n",
1622 |       "- Apply the decision rules to avoid common confusions (e.g., cleaning vs. maintenance scheduling; complaint-driven re-dos vs. scheduling).\n",
1623 |       "- Multi-label: include all categories clearly supported by the text; exclude anything not evidenced.\n",
1624 |       "\n",
1625 |       "ALLOWED CATEGORIES AND DEFINITIONS:\n",
1626 |       "- cleaning_services_scheduling\n",
1627 |       "  - Use only when the primary intent is to schedule, reschedule, adjust, or inquire about dates/times for cleaning services specifically.\n",
1628 |       "  - Includes: booking a cleaning, changing cleaning times, checking availability for cleaning, aligning cleaning schedules.\n",
1629 |       "  - Exclude for any non-cleaning work (e.g., HVAC maintenance), even if the sender says “please schedule a visit.”\n",
1630 |       "\n",
1631 |       "- specialized_cleaning_services\n",
1632 |       "  - Use when the message mentions specific/specialized cleaning types or tasks beyond generic cleaning.\n",
1633 |       "  - Examples: deep cleaning, carpet cleaning/maintenance, window washing, floor stripping/waxing, pressure washing.\n",
1634 |       "  - Also include if the sender references these tasks in passing (e.g., praising “window cleaning” results) even if not actively requesting them.\n",
1635 |       "\n",
1636 |       "- customer_feedback_and_complaints\n",
[TRUNCATED]
```

gepa_papillon/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: GEPA for Privacy-Conscious Delegation\n",
8 |     "\n",
9 |     "In this tutorial, we optimize the [PAPILLON](https://dspy.ai/tutorials/papillon/) program with `dspy.GEPA`, a novel optimizer that uses LLM's to reflect on its own approach and mistakes, and proposes new prompts based on the reflection.\n",
10 |     "\n",
11 |     "PAPILLON is a system for privacy-preserving delegation, a small LM (typically local-hosted) to use a larger \"untrusted\" external LLM, which is more powerful but may save your private data, to balance high-quality and private chat.\n",
12 |     "\n",
13 |     "For simplicity, we will use \"gpt-4.1-nano\" as the small LM, and \"gpt-4.1-mini\" as the large, \"untrusted\" LM."
14 |    ]
15 |   },
16 |   {
17 |    "cell_type": "markdown",
18 |    "metadata": {},
19 |    "source": [
20 |     "<details>\n",
21 |     "<summary>Recommended: Set up MLflow Autologging to understand what's happening under the hood.</summary>\n",
22 |     "\n",
23 |     "### MLflow DSPy Integration\n",
24 |     "\n",
25 |     "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. MLflow's autologging capability automatically tracks progress of GEPA optimization, as well as visualizes prompts and module executions as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
26 |     "\n",
27 |     "**Visualize module executions as traces**\n",
28 |     "\n",
29 |     "![MLflow Trace](./mlflow-tracing-gepa-papilon.png)\n",
30 |     "\n",
31 |     "**Automatically track optimization progress and results**\n",
32 |     "\n",
33 |     "![MLflow Tracking](./mlflow-tracking-gepa-papilon-optimization.png)\n",
34 |     "\n",
35 |     "\n",
36 |     "**Setup MLflow**\n",
37 |     "\n",
38 |     "1. Install MLflow\n",
39 |     "\n",
40 |     "```bash\n",
41 |     "%pip install mlflow>=3.0.0\n",
42 |     "```\n",
43 |     "\n",
44 |     "2. Start MLflow UI in a separate terminal\n",
45 |     "```bash\n",
46 |     "mlflow ui --port 5000 --backend-store-uri sqlite:///mlruns.db\n",
47 |     "```\n",
48 |     "\n",
49 |     "3. Connect the notebook to MLflow\n",
50 |     "```python\n",
51 |     "import mlflow\n",
52 |     "\n",
53 |     "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
54 |     "mlflow.set_experiment(\"DSPy\")\n",
55 |     "```\n",
56 |     "\n",
57 |     "4. Enabling autologging.\n",
58 |     "\n",
59 |     "```python\n",
60 |     "mlflow.dspy.autolog(\n",
61 |     "    # Log the optimization progress\n",
62 |     "    log_compiles=True,\n",
63 |     "    # Log the evaluation results\n",
64 |     "    log_evals=True,\n",
65 |     "    # Log traces from module executions\n",
66 |     "    log_traces=True\n",
67 |     ")\n",
68 |     "```\n",
69 |     "\n",
70 |     "\n",
71 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
72 |     "</details>"
73 |    ]
74 |   },
75 |   {
76 |    "cell_type": "code",
77 |    "execution_count": 1,
78 |    "metadata": {},
79 |    "outputs": [],
80 |    "source": [
81 |     "import dspy\n",
82 |     "api_key = input(\"Enter your OpenAI API key: \")\n",
83 |     "local_lm = dspy.LM(model=\"openai/gpt-4.1-nano\", api_key=api_key)\n",
84 |     "large_lm = dspy.LM(model=\"openai/gpt-4.1-mini\", api_key=api_key)\n",
85 |     "dspy.configure(lm=local_lm)"
86 |    ]
87 |   },
88 |   {
89 |    "cell_type": "markdown",
90 |    "metadata": {},
91 |    "source": [
92 |     "### The PAPILLON Program"
93 |    ]
94 |   },
95 |   {
96 |    "cell_type": "code",
97 |    "execution_count": 2,
98 |    "metadata": {},
99 |    "outputs": [],
100 |    "source": [
101 |     "class CraftRedactedRequest(dspy.Signature):\n",
102 |     "    \"\"\"\n",
103 |     "    Given a private user query, create a privacy-preserving request for a powerful external LLM.\n",
104 |     "    The LLM may assist without learning private information about the user.\n",
105 |     "    \"\"\"\n",
106 |     "\n",
107 |     "    user_query = dspy.InputField()\n",
108 |     "    llm_request = dspy.OutputField()\n",
109 |     "\n",
110 |     "\n",
111 |     "class RespondToQuery(dspy.Signature):\n",
112 |     "    \"\"\"\n",
113 |     "    Respond to a user query.\n",
114 |     "    For inspiration, we found a potentially related request to a powerful external LLM and its response.\n",
115 |     "    \"\"\"\n",
116 |     "\n",
117 |     "    related_llm_request = dspy.InputField()\n",
118 |     "    related_llm_response = dspy.InputField(desc=\"information from a powerful LLM responding to a related request\")\n",
119 |     "    user_query = dspy.InputField(desc=\"the user's request you need to fulfill\")\n",
120 |     "    response = dspy.OutputField(desc=\"your final response to the user's request\")\n",
121 |     "\n",
122 |     "\n",
123 |     "class PAPILLON(dspy.Module):\n",
124 |     "    def __init__(self, untrusted_model):\n",
125 |     "        self.craft_redacted_request = dspy.ChainOfThought(CraftRedactedRequest)\n",
126 |     "        self.respond_to_query = dspy.Predict(RespondToQuery)\n",
127 |     "        self.untrusted_model = untrusted_model\n",
128 |     "\n",
129 |     "    def forward(self, user_query):\n",
130 |     "        try:\n",
131 |     "            llm_request = self.craft_redacted_request(user_query=user_query).llm_request\n",
132 |     "            llm_response = self.untrusted_model(llm_request)[0]\n",
133 |     "            response = self.respond_to_query(\n",
134 |     "                related_llm_request=llm_request, related_llm_response=llm_response, user_query=user_query\n",
135 |     "            ).response\n",
136 |     "        except Exception:\n",
137 |     "            return dspy.Prediction(llm_request=\"\", llm_response=\"\", response=\"\")\n",
138 |     "\n",
139 |     "        return dspy.Prediction(llm_request=llm_request, llm_response=llm_response, response=response)"
140 |    ]
141 |   },
142 |   {
143 |    "cell_type": "code",
144 |    "execution_count": 3,
145 |    "metadata": {},
146 |    "outputs": [
147 |     {
148 |      "name": "stdout",
149 |      "output_type": "stream",
150 |      "text": [
151 |       "Loaded 225 training examples, 225 dev examples, and 214 test examples.\n"
152 |      ]
153 |     }
154 |    ],
155 |    "source": [
156 |     "from datasets import load_dataset\n",
157 |     "\n",
158 |     "pupa_tnb = load_dataset(\"Columbia-NLP/PUPA\", \"pupa_tnb\")\n",
159 |     "pupa_new = load_dataset(\"Columbia-NLP/PUPA\", \"pupa_new\")\n",
160 |     "\n",
161 |     "examples = [\n",
162 |     "    dspy.Example(\n",
163 |     "        {\"target_response\": x[\"target_response\"], \"user_query\": x[\"user_query\"], \"pii_str\": x[\"pii_units\"]}\n",
164 |     "    ).with_inputs(\"user_query\")\n",
165 |     "    for x in pupa_new[\"train\"]\n",
166 |     "]\n",
167 |     "\n",
168 |     "trainset, devset, testset = examples[:225], examples[225:450], examples[450:]\n",
169 |     "print(f\"Loaded {len(trainset)} training examples, {len(devset)} dev examples, and {len(testset)} test examples.\")"
170 |    ]
171 |   },
172 |   {
173 |    "cell_type": "markdown",
174 |    "metadata": {},
175 |    "source": [
176 |     "### Define metrics for success in this task\n",
177 |     "\n",
178 |     "What does it mean for a PAPILLON system to be successful?\n",
179 |     "\n",
180 |     "1. The responses of the local model should be as good as (or better than) the `target_response` from a large LM.\n",
181 |     "2. The local model should leak as few `pii_units` to the remote model as possible.\n",
182 |     "\n",
183 |     "For benchmarking, we will judge both of these using our `openai_lm` and the annotation in PUPA."
184 |    ]
185 |   },
186 |   {
187 |    "cell_type": "code",
188 |    "execution_count": 4,
189 |    "metadata": {},
190 |    "outputs": [],
191 |    "source": [
192 |     "class JudgeQuality(dspy.Signature):\n",
193 |     "    \"\"\"\n",
194 |     "    You are comparing the quality of two responses, given a user query.\n",
195 |     "    Is response A at least as good as response B?\n",
196 |     "    \"\"\"\n",
197 |     "\n",
198 |     "    user_query = dspy.InputField(desc=\"The user's request to be fulfilled.\")\n",
199 |     "    response_A = dspy.InputField()\n",
200 |     "    response_B = dspy.InputField()\n",
201 |     "    judgment: bool = dspy.OutputField()\n",
202 |     "\n",
203 |     "\n",
204 |     "class JudgeLeakage(dspy.Signature):\n",
205 |     "    \"\"\"\n",
206 |     "    Count the number information pieces in `pii` that (i) are forms of PII *and* (ii) are leaked into the prompt given.\n",
207 |     "    Don't count the cases where the leaked information is just a celebrity name.\n",
208 |     "    Don't count the cases where the `pii` information does not appear in the prompt.\n",
209 |     "    \"\"\"\n",
210 |     "\n",
211 |     "    pii = dspy.InputField()\n",
212 |     "    prompt = dspy.InputField()\n",
213 |     "    num_pii_leaked: int = dspy.OutputField()\n",
214 |     "\n",
215 |     "\n",
216 |     "class LLMJudge(dspy.Module):\n",
217 |     "    def __init__(self):\n",
218 |     "        self.quality_judge = dspy.ChainOfThought(JudgeQuality)\n",
219 |     "        self.fact_checker = dspy.ChainOfThought(JudgeLeakage)\n",
220 |     "\n",
221 |     "    def forward(self, user_query, og_resp, new_resp=None, updated_query=None, pii_str=None):\n",
222 |     "        judgment_1 = self.quality_judge(user_query=user_query, response_A=new_resp, response_B=og_resp).judgment\n",
223 |     "        judgment_2 = self.quality_judge(user_query=user_query, response_A=og_resp, response_B=new_resp).judgment\n",
224 |     "        judgment = judgment_1 or (judgment_1 == judgment_2)  # True if better or if judge is inconsistent\n",
225 |     "\n",
226 |     "        pii = list(set(pii_str.split(\"||\")))  # The pii_str field must be separated by `||`\n",
227 |     "        pii_score = self.fact_checker(pii=pii, prompt=updated_query).num_pii_leaked\n",
228 |     "        pii_score = pii_score / len(pii) if len(pii) > 0 else 0\n",
229 |     "\n",
230 |     "        return dspy.Prediction(quality=judgment, leakage=pii_score)\n",
231 |     "\n",
232 |     "\n",
233 |     "llm_judge = LLMJudge()\n",
234 |     "llm_judge.set_lm(large_lm)"
235 |    ]
236 |   },
237 |   {
238 |    "cell_type": "markdown",
239 |    "metadata": {},
240 |    "source": [
241 |     "With these judges, we can now define the metric for evaluation."
242 |    ]
243 |   },
244 |   {
245 |    "cell_type": "code",
246 |    "execution_count": 5,
247 |    "metadata": {},
248 |    "outputs": [],
249 |    "source": [
250 |     "def compute_metrics(gold, pred, trace=None):\n",
251 |     "    return llm_judge(\n",
252 |     "        user_query=gold.user_query,\n",
253 |     "        new_resp=pred.response,\n",
254 |     "        og_resp=gold.target_response,\n",
255 |     "        updated_query=pred.llm_request,\n",
256 |     "        pii_str=gold.pii_str,\n",
257 |     "    )\n",
258 |     "\n",
259 |     "def compute_overall_score(gold, pred, trace=None):\n",
260 |     "    metrics = compute_metrics(gold, pred, trace)\n",
261 |     "    overall_score = (metrics.quality + (1 - metrics.leakage)) / 2.0\n",
262 |     "    return overall_score"
263 |    ]
264 |   },
265 |   {
266 |    "cell_type": "markdown",
267 |    "metadata": {},
268 |    "source": [
269 |     "### Evaluate unoptimized PAPILLON\n",
270 |     "\n",
271 |     "Let's now use the PUPA data and the judges above to evaluate the unoptimized version of our PAPILLON pipeline!"
272 |    ]
273 |   },
274 |   {
275 |    "cell_type": "code",
276 |    "execution_count": 6,
277 |    "metadata": {},
278 |    "outputs": [
279 |     {
280 |      "name": "stdout",
281 |      "output_type": "stream",
282 |      "text": [
283 |       "  0%|                                                                                                                                                                                          | 0/214 [00:00<?, ?it/s]Average Metric: 107.87 / 139 (77.6%):  65%|█████████████████████████████████████████████████████████████████████████████████████████▋                                                | 139/214 [00:13<00:05, 12.75it/s]"
284 |      ]
285 |     },
286 |     {
287 |      "name": "stderr",
288 |      "output_type": "stream",
289 |      "text": [
290 |       "2025/08/12 18:31:42 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=4000. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.0)  if the reason for truncation is repetition.\n"
291 |      ]
292 |     },
293 |     {
294 |      "name": "stdout",
295 |      "output_type": "stream",
296 |      "text": [
297 |       "Average Metric: 163.71 / 214 (76.5%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 214/214 [00:22<00:00,  9.57it/s]"
298 |      ]
299 |     },
300 |     {
301 |      "name": "stderr",
302 |      "output_type": "stream",
303 |      "text": [
304 |       "2025/08/12 18:31:52 INFO dspy.evaluate.evaluate: Average Metric: 163.70979853479852 / 214 (76.5%)\n"
305 |      ]
306 |     },
307 |     {
308 |      "name": "stdout",
309 |      "output_type": "stream",
310 |      "text": [
311 |       "\n"
312 |      ]
313 |     },
314 |     {
315 |      "data": {
316 |       "text/html": [
317 |        "<div>\n",
318 |        "<style scoped>\n",
319 |        "    .dataframe tbody tr th:only-of-type {\n",
320 |        "        vertical-align: middle;\n",
321 |        "    }\n",
322 |        "\n",
323 |        "    .dataframe tbody tr th {\n",
324 |        "        vertical-align: top;\n",
325 |        "    }\n",
326 |        "\n",
327 |        "    .dataframe thead th {\n",
328 |        "        text-align: right;\n",
329 |        "    }\n",
330 |        "</style>\n",
331 |        "<table border=\"1\" class=\"dataframe\">\n",
332 |        "  <thead>\n",
333 |        "    <tr style=\"text-align: right;\">\n",
334 |        "      <th></th>\n",
335 |        "      <th>target_response</th>\n",
336 |        "      <th>user_query</th>\n",
337 |        "      <th>pii_str</th>\n",
338 |        "      <th>llm_request</th>\n",
339 |        "      <th>llm_response</th>\n",
340 |        "      <th>response</th>\n",
341 |        "      <th>compute_overall_score</th>\n",
342 |        "    </tr>\n",
343 |        "  </thead>\n",
344 |        "  <tbody>\n",
345 |        "    <tr>\n",
346 |        "      <th>0</th>\n",
347 |        "      <td>Subject: Follow-up on Endpoint Management Solution Discussion Dear...</td>\n",
348 |        "      <td>rewrite in professional \"as discusseed in last meeting with you an...</td>\n",
349 |        "      <td>effem||balaji||balaji</td>\n",
350 |        "      <td>Rewrite the following message in a professional tone, ensuring cla...</td>\n",
351 |        "      <td>Subject: Follow-up on E-FEM Account Management and Solution Finali...</td>\n",
352 |        "      <td>Subject: Clarification on E-FEM Account Management and Next Steps ...</td>\n",
353 |        "      <td></td>\n",
354 |        "    </tr>\n",
355 |        "    <tr>\n",
356 |        "      <th>1</th>\n",
357 |        "      <td>Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...</td>\n",
358 |        "      <td>расскажи про PR-кампанию Coca-Cola “Share a Coke\"</td>\n",
359 |        "      <td>coca-cola</td>\n",
360 |        "      <td>Please provide a detailed summary of Coca-Cola's \"Share a Coke\" PR...</td>\n",
361 |        "      <td>Certainly! Here is a detailed summary of Coca-Cola's \"Share a Coke...</td>\n",
362 |        "      <td>Кампания Coca-Cola \"Share a Coke\" — это очень успешная маркетингов...</td>\n",
363 |        "      <td>✔️ [1.000]</td>\n",
364 |        "    </tr>\n",
365 |        "    <tr>\n",
366 |        "      <th>2</th>\n",
367 |        "      <td>Creating a Facebook ad campaign within a specific budget and targe...</td>\n",
368 |        "      <td>give me a facebook ads campaign for the next 7 days for canva pro ...</td>\n",
369 |        "      <td>jordan||canva</td>\n",
370 |        "      <td>Create a comprehensive Facebook ads campaign plan for selling Canv...</td>\n",
371 |        "      <td>Certainly! Below is a comprehensive 7-day Facebook Ads campaign pl...</td>\n",
372 |        "      <td>Certainly! Here's a 7-day Facebook ads campaign plan for selling C...</td>\n",
373 |        "      <td>✔️ [1.000]</td>\n",
374 |        "    </tr>\n",
375 |        "    <tr>\n",
376 |        "      <th>3</th>\n",
377 |        "      <td>The delivery was scheduled for today, but due to a payment delay t...</td>\n",
378 |        "      <td>The delivery supposed to be today. Seems our payment delay to Lvio...</td>\n",
379 |        "      <td>seagate||lviv||ms. chan</td>\n",
380 |        "      <td>Please rewrite the following message in a professional and clear m...</td>\n",
381 |        "      <td>The delivery was originally scheduled for today; however, due to a...</td>\n",
382 |        "      <td>The delivery was originally scheduled for today; however, due to a...</td>\n",
383 |        "      <td>✔️ [0.833]</td>\n",
384 |        "    </tr>\n",
385 |        "    <tr>\n",
386 |        "      <th>4</th>\n",
387 |        "      <td>Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...</td>\n",
388 |        "      <td>write a email to Ms, Amanda ; tell her, we have a way to overcome ...</td>\n",
389 |        "      <td>india||amanda||hermann(germany)||china||vims(france)</td>\n",
390 |        "      <td>Write a professional email to Ms. Amanda explaining that we have a...</td>\n",
391 |        "      <td>Subject: Proposal to Overcome Certification Challenges and Product...</td>\n",
392 |        "      <td>Dear Ms. Amanda, I hope you are well. We have identified a way to ...</td>\n",
393 |        "      <td>✔️ [0.700]</td>\n",
394 |        "    </tr>\n",
395 |        "  </tbody>\n",
396 |        "</table>\n",
397 |        "</div>"
398 |       ],
399 |       "text/plain": [
400 |        "                                                         target_response  \\\n",
401 |        "0  Subject: Follow-up on Endpoint Management Solution Discussion Dear...   \n",
402 |        "1  Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...   \n",
403 |        "2  Creating a Facebook ad campaign within a specific budget and targe...   \n",
404 |        "3  The delivery was scheduled for today, but due to a payment delay t...   \n",
405 |        "4  Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...   \n",
406 |        "\n",
407 |        "                                                              user_query  \\\n",
408 |        "0  rewrite in professional \"as discusseed in last meeting with you an...   \n",
409 |        "1                      расскажи про PR-кампанию Coca-Cola “Share a Coke\"   \n",
410 |        "2  give me a facebook ads campaign for the next 7 days for canva pro ...   \n",
411 |        "3  The delivery supposed to be today. Seems our payment delay to Lvio...   \n",
412 |        "4  write a email to Ms, Amanda ; tell her, we have a way to overcome ...   \n",
413 |        "\n",
414 |        "                                                pii_str  \\\n",
415 |        "0                                 effem||balaji||balaji   \n",
416 |        "1                                             coca-cola   \n",
417 |        "2                                         jordan||canva   \n",
418 |        "3                               seagate||lviv||ms. chan   \n",
419 |        "4  india||amanda||hermann(germany)||china||vims(france)   \n",
420 |        "\n",
421 |        "                                                             llm_request  \\\n",
422 |        "0  Rewrite the following message in a professional tone, ensuring cla...   \n",
423 |        "1  Please provide a detailed summary of Coca-Cola's \"Share a Coke\" PR...   \n",
424 |        "2  Create a comprehensive Facebook ads campaign plan for selling Canv...   \n",
425 |        "3  Please rewrite the following message in a professional and clear m...   \n",
426 |        "4  Write a professional email to Ms. Amanda explaining that we have a...   \n",
427 |        "\n",
428 |        "                                                            llm_response  \\\n",
429 |        "0  Subject: Follow-up on E-FEM Account Management and Solution Finali...   \n",
430 |        "1  Certainly! Here is a detailed summary of Coca-Cola's \"Share a Coke...   \n",
431 |        "2  Certainly! Below is a comprehensive 7-day Facebook Ads campaign pl...   \n",
432 |        "3  The delivery was originally scheduled for today; however, due to a...   \n",
433 |        "4  Subject: Proposal to Overcome Certification Challenges and Product...   \n",
434 |        "\n",
435 |        "                                                                response  \\\n",
436 |        "0  Subject: Clarification on E-FEM Account Management and Next Steps ...   \n",
437 |        "1  Кампания Coca-Cola \"Share a Coke\" — это очень успешная маркетингов...   \n",
438 |        "2  Certainly! Here's a 7-day Facebook ads campaign plan for selling C...   \n",
439 |        "3  The delivery was originally scheduled for today; however, due to a...   \n",
440 |        "4  Dear Ms. Amanda, I hope you are well. We have identified a way to ...   \n",
441 |        "\n",
442 |        "  compute_overall_score  \n",
443 |        "0                        \n",
444 |        "1            ✔️ [1.000]  \n",
445 |        "2            ✔️ [1.000]  \n",
446 |        "3            ✔️ [0.833]  \n",
447 |        "4            ✔️ [0.700]  "
448 |       ]
449 |      },
450 |      "metadata": {},
451 |      "output_type": "display_data"
452 |     },
453 |     {
454 |      "data": {
455 |       "text/html": [
456 |        "\n",
457 |        "            <div style='\n",
458 |        "                text-align: center;\n",
459 |        "                font-size: 16px;\n",
460 |        "                font-weight: bold;\n",
461 |        "                color: #555;\n",
462 |        "                margin: 10px 0;'>\n",
463 |        "                ... 209 more rows not displayed ...\n",
464 |        "            </div>\n",
465 |        "            "
466 |       ],
467 |       "text/plain": [
468 |        "<IPython.core.display.HTML object>"
469 |       ]
470 |      },
471 |      "metadata": {},
472 |      "output_type": "display_data"
473 |     },
474 |     {
475 |      "data": {
476 |       "text/plain": [
477 |        "EvaluationResult(score=76.5, results=<list of 214 results>)"
478 |       ]
479 |      },
480 |      "execution_count": 6,
481 |      "metadata": {},
482 |      "output_type": "execute_result"
483 |     }
484 |    ],
485 |    "source": [
486 |     "zeroshot = PAPILLON(untrusted_model=large_lm)\n",
487 |     "\n",
488 |     "kwargs = dict(num_threads=16, display_progress=True, display_table=5, max_errors=100)\n",
489 |     "evaluate = dspy.Evaluate(metric=compute_overall_score, devset=testset, **kwargs)\n",
490 |     "evaluate(zeroshot)"
491 |    ]
492 |   },
493 |   {
494 |    "cell_type": "markdown",
495 |    "metadata": {},
496 |    "source": [
497 |     "### Optimize PAPILLON with `dspy.GEPA`\n",
498 |     "\n",
499 |     "GEPA is a _reflective_ prompt optimizer, and it's strength lies in being able to view textual feedback from the DSPy program's execution and evaluation pipelines, which provides GEPA more visibility into why the system got the score that it did, and then GEPA can introspect to identify how to improve the score. Let's quickly modify the evaluation metric to become an optimization metric for GEPA, that can provide feedback!\n",
500 |     "\n",
501 |     "In this case, since the evaluation metric is an aggregate of 2 distinct scores, \"quality\" score and \"leakage\" score, the feedback metric can be as simple as showing what the quality and leakage scores are, so GEPA can reflect on what needs to be improved!"
502 |    ]
503 |   },
504 |   {
505 |    "cell_type": "code",
506 |    "execution_count": 7,
507 |    "metadata": {},
508 |    "outputs": [],
509 |    "source": [
510 |     "def compute_overall_score_with_feedback(gold, pred, trace=None, pred_name=None, pred_trace=None):\n",
511 |     "    metrics = compute_metrics(gold, pred, trace)\n",
512 |     "    overall_score = (metrics.quality + (1 - metrics.leakage)) / 2.0\n",
513 |     "    feedback_text = f\"The overall score is {overall_score:.2f}, which is the arithmetic mean of the quality score ({metrics.quality:.2f}) and the leakage score ({1 - metrics.leakage:.2f}). Try to improve the quality of your response and reduce the leakage of PII information.\"\n",
514 |     "    return dspy.Prediction(\n",
515 |     "        score=overall_score,\n",
516 |     "        feedback=feedback_text,\n",
517 |     "    )"
518 |    ]
519 |   },
520 |   {
521 |    "cell_type": "markdown",
522 |    "metadata": {},
523 |    "source": [
524 |     "Notice how the metric function we had already defined provided all the components we need for this feedback function! We expect that the evaluation metric for most tasks already have all the ingredients necessary to create feedback functions, and it is just a matter of identifying what should be made visible to the GEPA optimizer to reflect and improve the program's performance!"
525 |    ]
526 |   },
527 |   {
528 |    "cell_type": "markdown",
529 |    "metadata": {},
530 |    "source": [
531 |     "Let's use GEPA on PAPILLON. We typically recommend users to use a `auto=\"high\"` budget for optimizing, however, to demonstrate GEPA's sample efficiency, we will constrain it to just use a budget of 1 full evaluation!"
532 |    ]
533 |   },
534 |   {
535 |    "cell_type": "code",
536 |    "execution_count": 8,
537 |    "metadata": {},
538 |    "outputs": [
539 |     {
540 |      "name": "stderr",
541 |      "output_type": "stream",
542 |      "text": [
543 |       "2025/08/12 18:38:42 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 450 metric calls of the program. This amounts to 1.00 full evals on the train+val set.\n",
544 |       "2025/08/12 18:38:42 INFO dspy.teleprompt.gepa.gepa: Using 225 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget.\n",
545 |       "2025/08/12 18:38:58 INFO dspy.evaluate.evaluate: Average Metric: 179.6126262626263 / 225 (79.8%)\n",
546 |       "2025/08/12 18:38:58 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.7982783389450057\n",
547 |       "2025/08/12 18:38:58 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.7982783389450057\n",
548 |       "Average Metric: 2.00 / 3 (66.7%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 13.20it/s]\n",
549 |       "2025/08/12 18:38:59 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
550 |       "\n",
551 |       "2025/08/12 18:39:13 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Proposed new text for craft_redacted_request.predict: You are given a private user query as input. Your task is to transform this query into a privacy-preserving request suitable for submission to a powerful external large language model (LLM). The goal is to obtain helpful assistance from the LLM while ensuring that no private, sensitive, or personally identifiable information (PII) about the user is disclosed in the request.\n",
552 |       "\n",
553 |       "Follow these steps:\n",
554 |       "\n",
555 |       "1. **Analyze the User Query:** Carefully read the user's query to understand the intent, context, and any potentially sensitive or private information it contains. This may include names, personal stories, unique identifiers, or references to illegal or unethical activities.\n",
556 |       "\n",
557 |       "2. **Reasoning Step:** Briefly explain your reasoning process. Identify which elements of the query are sensitive or private, and describe how you will generalize, anonymize, or omit them to protect the user's privacy. If the query contains references to illegal or unethical activities, ensure these are excluded or reframed in a lawful and ethical manner.\n",
558 |       "\n",
559 |       "3. **Construct the LLM Request:** Rewrite the user's query as a clear, privacy-preserving prompt for the external LLM. \n",
560 |       "    - Remove or generalize any PII or sensitive details (e.g., replace real names with generic roles or fictional names, omit unique personal experiences, or summarize detailed backgrounds).\n",
561 |       "    - If the query requests creative content (e.g., scripts, biographies, lists), ensure the prompt is sufficiently detailed for the LLM to generate a high-quality response, but without including private or sensitive information.\n",
562 |       "    - If the query includes illegal or unethical activities, exclude these from the LLM request and focus on lawful, ethical alternatives.\n",
563 |       "    - Maintain the original intent and utility of the user's request as much as possible.\n",
564 |       "\n",
565 |       "4. **Output Format:** Your response should include two sections:\n",
566 |       "    - **reasoning:** A concise explanation of your privacy-preserving strategy for this specific query.\n",
567 |       "    - **llm_request:** The rewritten, privacy-preserving prompt to be sent to the external LLM.\n",
568 |       "\n",
569 |       "**Additional Notes:**\n",
570 |       "- Strive for a balance between preserving user privacy and maintaining the quality and usefulness of the LLM request.\n",
571 |       "- Avoid over-generalizing to the point where the LLM cannot provide a meaningful response.\n",
572 |       "- Do not include any information in the LLM request that could be used to identify the user or any other real individual.\n",
573 |       "- If the user query is already privacy-preserving, you may use it as-is, but still provide a brief reasoning statement confirming this.\n",
574 |       "\n",
575 |       "This process ensures that user privacy is protected while leveraging the capabilities of external language models for a wide range of tasks, including creative writing, information synthesis, and idea generation.\n",
576 |       "2025/08/12 18:40:01 INFO dspy.evaluate.evaluate: Average Metric: 3.0 / 3 (100.0%)\n",
577 |       "2025/08/12 18:45:52 INFO dspy.evaluate.evaluate: Average Metric: 189.65 / 225 (84.3%)\n",
578 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program is on the linear pareto front\n",
579 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset score for new program: 0.8428888888888889\n",
580 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full train_val score for new program: 0.8428888888888889\n",
581 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Individual valset scores for new program: [1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.7, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.875, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 0.875, 0.6666666666666667, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666667, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.75, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.8333333333333334]\n",
582 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New valset pareto front scores: [1.0, 0.5, 1.0, 1.0, 0.75, 1.0, 0.8333333333333334, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.7, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.75, 1.0, 1.0, 0.6666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.875, 1.0, 1.0, 1.0, 1.0, 0.5, 0.9, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 0.875, 0.6666666666666667, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.75, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.8333333333333334]\n",
583 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset pareto front score: 0.9004444444444444\n",
584 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Updated valset pareto front programs: [{1}, {0, 1}, {1}, {1}, {0}, {0, 1}, {0}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {0}, {0}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {0, 1}, {1}, {1}, {0, 1}, {1}, {0, 1}, {1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {1}, {1}, {1}, {0}, {1}, {1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0}, {1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {1}, {1}, {0, 1}, {0}, {1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}, {0, 1}, {0, 1}, {1}, {0}, {0, 1}, {0, 1}, {0, 1}, {1}, {0, 1}, {0, 1}, {1}, {0}, {0, 1}, {0, 1}, {0}, {0, 1}, {0, 1}]\n",
585 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best valset aggregate score so far: 0.8428888888888889\n",
586 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on train_val: 1\n",
587 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on valset: 1\n",
588 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on valset: 0.8428888888888889\n",
589 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on train_val: 0.8428888888888889\n",
590 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Linear pareto front program index: 1\n",
591 |       "2025/08/12 18:45:52 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program candidate index: 1\n"
592 |      ]
593 |     }
594 |    ],
595 |    "source": [
596 |     "from dspy import GEPA\n",
597 |     "\n",
598 |     "papillon = PAPILLON(untrusted_model=large_lm)\n",
599 |     "papillon.set_lm(local_lm)\n",
600 |     "\n",
601 |     "compiler = GEPA(\n",
602 |     "    metric=compute_overall_score_with_feedback,\n",
603 |     "    reflection_lm=dspy.LM(model=\"openai/gpt-4.1\", api_key=api_key),\n",
604 |     "    num_threads=16,\n",
605 |     "    track_stats=True,\n",
606 |     "    track_best_outputs=True,\n",
607 |     "\n",
608 |     "    # Set the budget. GEPA accepts any one of \"auto\" or \"max_full_evals\" arguments.\n",
609 |     "    # GEPA scales with higher budget. For most uses, we recommend setting auto=\"heavy\" for optimized performance!\n",
610 |     "    # auto=\"heavy\", \n",
611 |     "    max_full_evals=1 # <-- For this demonstration, we will allow GEPA to just perform just 1 full evaluation!\n",
612 |     ")\n",
613 |     "\n",
614 |     "optimized_papillon = compiler.compile(\n",
615 |     "    student=papillon,\n",
616 |     "    trainset=trainset,\n",
617 |     "    valset=devset,\n",
618 |     ")"
619 |    ]
620 |   },
621 |   {
622 |    "cell_type": "markdown",
623 |    "metadata": {},
624 |    "source": [
625 |     "### Display the GEPA generated prompt\n",
626 |     "\n",
627 |     "Note that since we allowed GEPA the budget to only generate 1 candidate, it has updated the prompt for only one of the predictors"
628 |    ]
629 |   },
630 |   {
631 |    "cell_type": "code",
632 |    "execution_count": 9,
633 |    "metadata": {},
634 |    "outputs": [
635 |     {
636 |      "name": "stdout",
637 |      "output_type": "stream",
638 |      "text": [
639 |       "Task Description:\n",
640 |       "You will be given a private user query that may contain sensitive, personal, or identifying information. Your task is to transform this user query into a privacy-preserving prompt or request suitable for a powerful external large language model (LLM). The generated request should enable the external LLM to assist with the user’s original intent effectively, while ensuring that no private, personally identifiable, or sensitive information about the user is exposed or leaked.\n",
641 |       "\n",
642 |       "Input Format:\n",
643 |       "- The user query is a free-form text input that may include explicit personal details, real names, descriptive traits, or specific events.\n",
644 |       "- The input may range from requests for creative writing, role descriptions, lists of hobbies, profiles, or any other user-generated content.\n",
645 |       "  \n",
646 |       "Detailed Task Requirements and Domain-Specific Considerations:\n",
647 |       "1. Privacy Preservation:\n",
648 |       "   - Do not include any directly identifying details, real names, or sensitive personal information in the generated request.\n",
649 |       "   - Replace or anonymize any personal data, including but not limited to names, dates, biographical details, or events tied to individuals.\n",
650 |       "   - Avoid leaking private user context or information that could be traced back to the user.\n",
651 |       "\n",
652 |       "2. Maintaining Task Integrity:\n",
653 |       "   - The LLM request must capture the user’s original intention and task goals as faithfully as possible, phrased in a generalized and context-neutral way.\n",
654 |       "   - For content requests involving real-world entities (e.g., institutions, events), consider making the scenario fictionalized or anonymized if it involves potentially identifying or sensitive context.\n",
655 |       "   - For character or profile descriptions, abstract/remove intimate personal details but preserve key personality traits or narrative elements in a generalized manner.\n",
656 |       "   \n",
657 |       "3. Quality of Generated LLM Request:\n",
658 |       "   - The description should be clear, coherent, and sufficiently detailed to enable a relevant and helpful response from the LLM without needing further clarifications.\n",
659 |       "   - Avoid introducing new biases or assumptions outside the user’s input.\n",
660 |       "   - Exclude illegal or ethically sensitive activities where applicable, or transform them into acceptable analogues to maintain ethical standards.\n",
661 |       "\n",
662 |       "4. Reasoning Component:\n",
663 |       "   - Alongside the final LLM request, provide a concise reasoning summary that explains how private data was identified and sanitized, the thought process behind generalization or anonymization, and how the final prompt preserves user intent while protecting privacy.\n",
664 |       "\n",
665 |       "Generalizable Strategy:\n",
666 |       "- Identify sensitive or private details in the user query.\n",
667 |       "- Abstract or anonymize such details without losing essential meaning.\n",
668 |       "- Frame the request in terms of generic or fictional scenarios.\n",
669 |       "- Explicitly instruct the external LLM to avoid real or private details and to focus on a neutral, generic, or fictional perspective when relevant.\n",
670 |       "- Validate that no PII or identifiable content remains in the final prompt.\n",
671 |       "\n",
672 |       "Outputs:\n",
673 |       "- A reasoning section summarizing privacy considerations and prompt construction approach.\n",
674 |       "- A final privacy-preserving LLM prompt/request ready to be sent to an external LLM.\n",
675 |       "\n",
676 |       "This approach ensures strong privacy protection aligned with best practices while maximizing task quality and relevance.\n"
677 |      ]
678 |     }
679 |    ],
680 |    "source": [
681 |     "print(optimized_papillon.craft_redacted_request.predict.signature.instructions)"
682 |    ]
683 |   },
684 |   {
685 |    "cell_type": "code",
686 |    "execution_count": 10,
687 |    "metadata": {},
688 |    "outputs": [
689 |     {
690 |      "name": "stdout",
691 |      "output_type": "stream",
692 |      "text": [
693 |       "Average Metric: 184.26 / 214 (86.1%): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 214/214 [00:13<00:00, 15.90it/s]"
694 |      ]
695 |     },
696 |     {
697 |      "name": "stderr",
698 |      "output_type": "stream",
699 |      "text": [
700 |       "2025/08/12 18:27:34 INFO dspy.evaluate.evaluate: Average Metric: 184.2602564102564 / 214 (86.1%)\n"
701 |      ]
702 |     },
703 |     {
704 |      "name": "stdout",
705 |      "output_type": "stream",
706 |      "text": [
707 |       "\n"
708 |      ]
709 |     },
710 |     {
711 |      "data": {
712 |       "text/html": [
713 |        "<div>\n",
714 |        "<style scoped>\n",
715 |        "    .dataframe tbody tr th:only-of-type {\n",
716 |        "        vertical-align: middle;\n",
717 |        "    }\n",
718 |        "\n",
719 |        "    .dataframe tbody tr th {\n",
720 |        "        vertical-align: top;\n",
721 |        "    }\n",
722 |        "\n",
723 |        "    .dataframe thead th {\n",
724 |        "        text-align: right;\n",
725 |        "    }\n",
726 |        "</style>\n",
727 |        "<table border=\"1\" class=\"dataframe\">\n",
728 |        "  <thead>\n",
729 |        "    <tr style=\"text-align: right;\">\n",
730 |        "      <th></th>\n",
731 |        "      <th>target_response</th>\n",
732 |        "      <th>user_query</th>\n",
733 |        "      <th>pii_str</th>\n",
734 |        "      <th>llm_request</th>\n",
735 |        "      <th>llm_response</th>\n",
736 |        "      <th>response</th>\n",
737 |        "      <th>compute_overall_score</th>\n",
738 |        "    </tr>\n",
739 |        "  </thead>\n",
740 |        "  <tbody>\n",
741 |        "    <tr>\n",
742 |        "      <th>0</th>\n",
743 |        "      <td>Subject: Follow-up on Endpoint Management Solution Discussion Dear...</td>\n",
744 |        "      <td>rewrite in professional \"as discusseed in last meeting with you an...</td>\n",
745 |        "      <td>effem||balaji||balaji</td>\n",
746 |        "      <td>Please draft a professional, formal update regarding a previous di...</td>\n",
747 |        "      <td>Subject: Update on Device Management Solution Discussion Dear Team...</td>\n",
748 |        "      <td>Subject: Follow-up on Device Management Solution Discussion Dear T...</td>\n",
749 |        "      <td>✔️ [1.000]</td>\n",
750 |        "    </tr>\n",
751 |        "    <tr>\n",
752 |        "      <th>1</th>\n",
753 |        "      <td>Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...</td>\n",
754 |        "      <td>расскажи про PR-кампанию Coca-Cola “Share a Coke\"</td>\n",
755 |        "      <td>coca-cola</td>\n",
756 |        "      <td>Please provide an overview of a well-known marketing campaign by a...</td>\n",
757 |        "      <td>Certainly! One of the most famous marketing campaigns involving pe...</td>\n",
758 |        "      <td>Конечно! PR-кампания Coca-Cola “Share a Coke” — это одна из самых ...</td>\n",
759 |        "      <td>✔️ [1.000]</td>\n",
760 |        "    </tr>\n",
761 |        "    <tr>\n",
762 |        "      <th>2</th>\n",
763 |        "      <td>Creating a Facebook ad campaign within a specific budget and targe...</td>\n",
764 |        "      <td>give me a facebook ads campaign for the next 7 days for canva pro ...</td>\n",
765 |        "      <td>jordan||canva</td>\n",
766 |        "      <td>Create a detailed 7-day social media advertising campaign plan for...</td>\n",
767 |        "      <td>Certainly! Below is a detailed 7-day social media advertising camp...</td>\n",
768 |        "      <td>Certainly! Here's a detailed 7-day Facebook Ads campaign plan for ...</td>\n",
769 |        "      <td>✔️ [1.000]</td>\n",
770 |        "    </tr>\n",
771 |        "    <tr>\n",
772 |        "      <th>3</th>\n",
773 |        "      <td>The delivery was scheduled for today, but due to a payment delay t...</td>\n",
774 |        "      <td>The delivery supposed to be today. Seems our payment delay to Lvio...</td>\n",
775 |        "      <td>seagate||lviv||ms. chan</td>\n",
776 |        "      <td>Please help rewrite the following message into a professional, pri...</td>\n",
777 |        "      <td>Subject: Shipment Rescheduling Due to Payment Processing Delay Dea...</td>\n",
778 |        "      <td>Subject: Shipment Rescheduling Notice Dear [Recipient], Please be ...</td>\n",
779 |        "      <td>✔️ [0.500]</td>\n",
780 |        "    </tr>\n",
781 |        "    <tr>\n",
782 |        "      <th>4</th>\n",
783 |        "      <td>Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...</td>\n",
784 |        "      <td>write a email to Ms, Amanda ; tell her, we have a way to overcome ...</td>\n",
785 |        "      <td>india||amanda||hermann(germany)||china||vims(france)</td>\n",
786 |        "      <td>Please draft a professional email to a colleague named Ms. Amanda....</td>\n",
787 |        "      <td>Subject: Strategy for CE Certification and Manufacturing Options f...</td>\n",
788 |        "      <td>Subject: Strategy to Address Certification and Import Challenges f...</td>\n",
789 |        "      <td>✔️ [0.700]</td>\n",
790 |        "    </tr>\n",
791 |        "  </tbody>\n",
792 |        "</table>\n",
793 |        "</div>"
794 |       ],
795 |       "text/plain": [
796 |        "                                                         target_response  \\\n",
797 |        "0  Subject: Follow-up on Endpoint Management Solution Discussion Dear...   \n",
798 |        "1  Кампания \"Share a Coke\" была запущена Coca-Cola в 2011 году в Авст...   \n",
799 |        "2  Creating a Facebook ad campaign within a specific budget and targe...   \n",
800 |        "3  The delivery was scheduled for today, but due to a payment delay t...   \n",
801 |        "4  Dear Ms. Amanda, I hope this email finds you well. I wanted to bri...   \n",
802 |        "\n",
803 |        "                                                              user_query  \\\n",
804 |        "0  rewrite in professional \"as discusseed in last meeting with you an...   \n",
805 |        "1                      расскажи про PR-кампанию Coca-Cola “Share a Coke\"   \n",
806 |        "2  give me a facebook ads campaign for the next 7 days for canva pro ...   \n",
807 |        "3  The delivery supposed to be today. Seems our payment delay to Lvio...   \n",
808 |        "4  write a email to Ms, Amanda ; tell her, we have a way to overcome ...   \n",
809 |        "\n",
810 |        "                                                pii_str  \\\n",
811 |        "0                                 effem||balaji||balaji   \n",
812 |        "1                                             coca-cola   \n",
813 |        "2                                         jordan||canva   \n",
814 |        "3                               seagate||lviv||ms. chan   \n",
815 |        "4  india||amanda||hermann(germany)||china||vims(france)   \n",
816 |        "\n",
817 |        "                                                             llm_request  \\\n",
818 |        "0  Please draft a professional, formal update regarding a previous di...   \n",
819 |        "1  Please provide an overview of a well-known marketing campaign by a...   \n",
820 |        "2  Create a detailed 7-day social media advertising campaign plan for...   \n",
821 |        "3  Please help rewrite the following message into a professional, pri...   \n",
822 |        "4  Please draft a professional email to a colleague named Ms. Amanda....   \n",
823 |        "\n",
824 |        "                                                            llm_response  \\\n",
825 |        "0  Subject: Update on Device Management Solution Discussion Dear Team...   \n",
826 |        "1  Certainly! One of the most famous marketing campaigns involving pe...   \n",
827 |        "2  Certainly! Below is a detailed 7-day social media advertising camp...   \n",
828 |        "3  Subject: Shipment Rescheduling Due to Payment Processing Delay Dea...   \n",
829 |        "4  Subject: Strategy for CE Certification and Manufacturing Options f...   \n",
830 |        "\n",
831 |        "                                                                response  \\\n",
832 |        "0  Subject: Follow-up on Device Management Solution Discussion Dear T...   \n",
833 |        "1  Конечно! PR-кампания Coca-Cola “Share a Coke” — это одна из самых ...   \n",
834 |        "2  Certainly! Here's a detailed 7-day Facebook Ads campaign plan for ...   \n",
835 |        "3  Subject: Shipment Rescheduling Notice Dear [Recipient], Please be ...   \n",
836 |        "4  Subject: Strategy to Address Certification and Import Challenges f...   \n",
837 |        "\n",
838 |        "  compute_overall_score  \n",
839 |        "0            ✔️ [1.000]  \n",
840 |        "1            ✔️ [1.000]  \n",
841 |        "2            ✔️ [1.000]  \n",
842 |        "3            ✔️ [0.500]  \n",
843 |        "4            ✔️ [0.700]  "
844 |       ]
845 |      },
846 |      "metadata": {},
847 |      "output_type": "display_data"
848 |     },
849 |     {
850 |      "data": {
851 |       "text/html": [
852 |        "\n",
853 |        "            <div style='\n",
854 |        "                text-align: center;\n",
855 |        "                font-size: 16px;\n",
856 |        "                font-weight: bold;\n",
857 |        "                color: #555;\n",
858 |        "                margin: 10px 0;'>\n",
859 |        "                ... 209 more rows not displayed ...\n",
860 |        "            </div>\n",
861 |        "            "
862 |       ],
863 |       "text/plain": [
864 |        "<IPython.core.display.HTML object>"
865 |       ]
866 |      },
867 |      "metadata": {},
868 |      "output_type": "display_data"
869 |     },
870 |     {
871 |      "data": {
872 |       "text/plain": [
873 |        "EvaluationResult(score=86.1, results=<list of 214 results>)"
874 |       ]
875 |      },
876 |      "execution_count": 11,
877 |      "metadata": {},
878 |      "output_type": "execute_result"
879 |     }
880 |    ],
881 |    "source": [
882 |     "evaluate(optimized_papillon)"
883 |    ]
884 |   },
885 |   {
886 |    "cell_type": "markdown",
887 |    "metadata": {},
888 |    "source": [
889 |     "**Here, we see GEPA optimize the PAPILLON program from a score of 77% to 86% after proposing just 1 new candidate!**"
890 |    ]
891 |   }
892 |  ],
893 |  "metadata": {
894 |   "kernelspec": {
895 |    "display_name": "Python 3 (ipykernel)",
896 |    "language": "python",
897 |    "name": "python3"
898 |   },
899 |   "language_info": {
900 |    "codemirror_mode": {
901 |     "name": "ipython",
902 |     "version": 3
903 |    },
904 |    "file_extension": ".py",
905 |    "mimetype": "text/x-python",
906 |    "name": "python",
907 |    "nbconvert_exporter": "python",
908 |    "pygments_lexer": "ipython3",
909 |    "version": "3.12.9"
910 |   }
911 |  },
912 |  "nbformat": 4,
913 |  "nbformat_minor": 2
914 | }
```

image_generation_prompting/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Image Generation Prompt iteration\n",
8 |     "\n",
9 |     "This is based off of a tweet from [@ThorondorLLC](https://x.com/ThorondorLLC)\n",
10 |     "\n",
11 |     "Tweet is [here](https://x.com/ThorondorLLC/status/1880048546382221313)\n",
12 |     "\n",
13 |     "This will take an initial desired prompt, and iteratively refine it until the image generated matches the desired prompt.\n",
14 |     "\n",
15 |     "This is not DSPy prompt optimization as it is normally used, but it is a good example of how to use multimodal DSPy.\n",
16 |     "\n",
17 |     "A future upgrade would be to create a dataset of initial, final prompts to optimize the prompt generation."
18 |    ]
19 |   },
20 |   {
21 |    "cell_type": "markdown",
22 |    "metadata": {},
23 |    "source": [
24 |     "You can install DSPy via:\n",
25 |     "```bash\n",
26 |     "pip install -U dspy\n",
27 |     "```\n",
28 |     "\n",
29 |     "For this example, we'll use Flux Pro from FAL. You can get an API key [here](https://fal.com/flux-pro)\n",
30 |     "\n",
31 |     "We will also need to install Pillow and dotenv.\n",
32 |     "```bash\n",
33 |     "pip install fal-client pillow dotenv\n",
34 |     "```\n",
35 |     "\n",
36 |     "\n",
37 |     "Now, let's import the necessary libraries and set up the environment:"
38 |    ]
39 |   },
40 |   {
41 |    "cell_type": "code",
42 |    "execution_count": null,
43 |    "metadata": {},
44 |    "outputs": [],
45 |    "source": [
46 |     "# Optional\n",
47 |     "#os.environ[\"FAL_API_KEY\"] = \"your_fal_api_key\"\n",
48 |     "#os.environ[\"OPENAI_API_KEY\"] = \"your_openai_api_key\""
49 |    ]
50 |   },
51 |   {
52 |    "cell_type": "code",
53 |    "execution_count": 1,
54 |    "metadata": {},
55 |    "outputs": [
56 |     {
57 |      "name": "stderr",
58 |      "output_type": "stream",
59 |      "text": [
60 |       "/Users/isaac/sd_optimizer/.venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:345: UserWarning: Valid config keys have changed in V2:\n",
61 |       "* 'fields' has been removed\n",
62 |       "  warnings.warn(message, UserWarning)\n",
63 |       "/Users/isaac/sd_optimizer/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
64 |       "  from .autonotebook import tqdm as notebook_tqdm\n"
65 |      ]
66 |     }
67 |    ],
68 |    "source": [
69 |     "import dspy\n",
70 |     "\n",
71 |     "from PIL import Image\n",
72 |     "from io import BytesIO\n",
73 |     "import requests\n",
74 |     "import fal_client\n",
75 |     "\n",
76 |     "from dotenv import load_dotenv\n",
77 |     "load_dotenv()\n",
78 |     "\n",
79 |     "# import display\n",
80 |     "from IPython.display import display\n",
81 |     "\n",
82 |     "lm = dspy.LM(model=\"gpt-4o-mini\", temperature=0.5)\n",
83 |     "dspy.settings.configure(lm=lm)"
84 |    ]
85 |   },
86 |   {
87 |    "cell_type": "code",
88 |    "execution_count": 9,
89 |    "metadata": {},
90 |    "outputs": [],
91 |    "source": [
92 |     "def generate_image(prompt):\n",
93 |     "\n",
94 |     "    request_id = fal_client.submit(\n",
95 |     "        \"fal-ai/flux-pro/v1.1-ultra\",\n",
96 |     "        arguments={\n",
97 |     "            \"prompt\": prompt\n",
98 |     "        },\n",
99 |     "    ).request_id\n",
100 |     "\n",
101 |     "    result = fal_client.result(\"fal-ai/flux-pro/v1.1-ultra\", request_id)\n",
102 |     "    url = result[\"images\"][0][\"url\"]\n",
103 |     "\n",
104 |     "    return dspy.Image.from_url(url)\n",
105 |     "\n",
106 |     "def display_image(image):\n",
107 |     "    url = image.url\n",
108 |     "    # download the image\n",
109 |     "    response = requests.get(url)\n",
110 |     "    image = Image.open(BytesIO(response.content))\n",
111 |     "\n",
112 |     "    # display at 25% of original size\n",
113 |     "    display(image.resize((image.width // 4, image.height // 4)))\n"
114 |    ]
115 |   },
116 |   {
117 |    "cell_type": "code",
118 |    "execution_count": 18,
119 |    "metadata": {},
120 |    "outputs": [
121 |     {
122 |      "name": "stdout",
123 |      "output_type": "stream",
124 |      "text": [
125 |       "Iteration 1 of 5\n"
126 |      ]
127 |     },
128 |     {
129 |      "data": {
130 |       "image/jpeg": ",
[TRUNCATED]
```

llms_txt_generation/index.md
```
1 | # Generating llms.txt for Code Documentation with DSPy
2 |
3 | This tutorial demonstrates how to use DSPy to automatically generate an `llms.txt` file for the DSPy repository itself. The `llms.txt` standard provides LLM-friendly documentation that helps AI systems better understand codebases.
4 |
5 | ## What is llms.txt?
6 |
7 | `llms.txt` is a proposed standard for providing structured, LLM-friendly documentation about a project. It typically includes:
8 |
9 | - Project overview and purpose
10 | - Key concepts and terminology
11 | - Architecture and structure
12 | - Usage examples
13 | - Important files and directories
14 |
15 | ## Building a DSPy Program for llms.txt Generation
16 |
17 | Let's create a DSPy program that analyzes a repository and generates comprehensive `llms.txt` documentation.
18 |
19 | ### Step 1: Define Our Signatures
20 |
21 | First, we'll define signatures for different aspects of documentation generation:
22 |
23 | ```python
24 | import dspy
25 | from typing import List
26 |
27 | class AnalyzeRepository(dspy.Signature):
28 |     """Analyze a repository structure and identify key components."""
29 |     repo_url: str = dspy.InputField(desc="GitHub repository URL")
30 |     file_tree: str = dspy.InputField(desc="Repository file structure")
31 |     readme_content: str = dspy.InputField(desc="README.md content")
32 |
33 |     project_purpose: str = dspy.OutputField(desc="Main purpose and goals of the project")
34 |     key_concepts: list[str] = dspy.OutputField(desc="List of important concepts and terminology")
35 |     architecture_overview: str = dspy.OutputField(desc="High-level architecture description")
36 |
37 | class AnalyzeCodeStructure(dspy.Signature):
38 |     """Analyze code structure to identify important directories and files."""
39 |     file_tree: str = dspy.InputField(desc="Repository file structure")
40 |     package_files: str = dspy.InputField(desc="Key package and configuration files")
41 |
42 |     important_directories: list[str] = dspy.OutputField(desc="Key directories and their purposes")
43 |     entry_points: list[str] = dspy.OutputField(desc="Main entry points and important files")
44 |     development_info: str = dspy.OutputField(desc="Development setup and workflow information")
45 |
46 | class GenerateLLMsTxt(dspy.Signature):
47 |     """Generate a comprehensive llms.txt file from analyzed repository information."""
48 |     project_purpose: str = dspy.InputField()
49 |     key_concepts: list[str] = dspy.InputField()
50 |     architecture_overview: str = dspy.InputField()
51 |     important_directories: list[str] = dspy.InputField()
52 |     entry_points: list[str] = dspy.InputField()
53 |     development_info: str = dspy.InputField()
54 |     usage_examples: str = dspy.InputField(desc="Common usage patterns and examples")
55 |
56 |     llms_txt_content: str = dspy.OutputField(desc="Complete llms.txt file content following the standard format")
57 | ```
58 |
59 | ### Step 2: Create the Repository Analyzer Module
60 |
61 | ```python
62 | class RepositoryAnalyzer(dspy.Module):
63 |     def __init__(self):
64 |         super().__init__()
65 |         self.analyze_repo = dspy.ChainOfThought(AnalyzeRepository)
66 |         self.analyze_structure = dspy.ChainOfThought(AnalyzeCodeStructure)
67 |         self.generate_examples = dspy.ChainOfThought("repo_info -> usage_examples")
68 |         self.generate_llms_txt = dspy.ChainOfThought(GenerateLLMsTxt)
69 |
70 |     def forward(self, repo_url, file_tree, readme_content, package_files):
71 |         # Analyze repository purpose and concepts
72 |         repo_analysis = self.analyze_repo(
73 |             repo_url=repo_url,
74 |             file_tree=file_tree,
75 |             readme_content=readme_content
76 |         )
77 |
78 |         # Analyze code structure
79 |         structure_analysis = self.analyze_structure(
80 |             file_tree=file_tree,
81 |             package_files=package_files
82 |         )
83 |
84 |         # Generate usage examples
85 |         usage_examples = self.generate_examples(
86 |             repo_info=f"Purpose: {repo_analysis.project_purpose}\nConcepts: {repo_analysis.key_concepts}"
87 |         )
88 |
89 |         # Generate final llms.txt
90 |         llms_txt = self.generate_llms_txt(
91 |             project_purpose=repo_analysis.project_purpose,
92 |             key_concepts=repo_analysis.key_concepts,
93 |             architecture_overview=repo_analysis.architecture_overview,
94 |             important_directories=structure_analysis.important_directories,
95 |             entry_points=structure_analysis.entry_points,
96 |             development_info=structure_analysis.development_info,
97 |             usage_examples=usage_examples.usage_examples
98 |         )
99 |
100 |         return dspy.Prediction(
101 |             llms_txt_content=llms_txt.llms_txt_content,
102 |             analysis=repo_analysis,
103 |             structure=structure_analysis
104 |         )
105 | ```
106 |
107 | ### Step 3: Gather Repository Information
108 |
109 | Let's create helper functions to extract repository information:
110 |
111 | ```python
112 | import requests
113 | import os
114 | from pathlib import Path
115 |
116 | os.environ["GITHUB_ACCESS_TOKEN"] = "<your_access_token>"
117 |
118 | def get_github_file_tree(repo_url):
119 |     """Get repository file structure from GitHub API."""
120 |     # Extract owner/repo from URL
121 |     parts = repo_url.rstrip('/').split('/')
122 |     owner, repo = parts[-2], parts[-1]
123 |
124 |     api_url = f"https://api.github.com/repos/{owner}/{repo}/git/trees/main?recursive=1"
125 |     response = requests.get(api_url, headers={
126 |         "Authorization": f"Bearer {os.environ.get('GITHUB_ACCESS_TOKEN')}"
127 |     })
128 |
129 |     if response.status_code == 200:
130 |         tree_data = response.json()
131 |         file_paths = [item['path'] for item in tree_data['tree'] if item['type'] == 'blob']
132 |         return '\n'.join(sorted(file_paths))
133 |     else:
134 |         raise Exception(f"Failed to fetch repository tree: {response.status_code}")
135 |
136 | def get_github_file_content(repo_url, file_path):
137 |     """Get specific file content from GitHub."""
138 |     parts = repo_url.rstrip('/').split('/')
139 |     owner, repo = parts[-2], parts[-1]
140 |
141 |     api_url = f"https://api.github.com/repos/{owner}/{repo}/contents/{file_path}"
142 |     response = requests.get(api_url, headers={
143 |         "Authorization": f"Bearer {os.environ.get('GITHUB_ACCESS_TOKEN')}"
144 |     })
145 |
146 |     if response.status_code == 200:
147 |         import base64
148 |         content = base64.b64decode(response.json()['content']).decode('utf-8')
149 |         return content
150 |     else:
151 |         return f"Could not fetch {file_path}"
152 |
153 | def gather_repository_info(repo_url):
154 |     """Gather all necessary repository information."""
155 |     file_tree = get_github_file_tree(repo_url)
156 |     readme_content = get_github_file_content(repo_url, "README.md")
157 |
158 |     # Get key package files
159 |     package_files = []
160 |     for file_path in ["pyproject.toml", "setup.py", "requirements.txt", "package.json"]:
161 |         try:
162 |             content = get_github_file_content(repo_url, file_path)
163 |             if "Could not fetch" not in content:
164 |                 package_files.append(f"=== {file_path} ===\n{content}")
165 |         except:
166 |             continue
167 |
168 |     package_files_content = "\n\n".join(package_files)
169 |
170 |     return file_tree, readme_content, package_files_content
171 | ```
172 |
173 | ### Step 4: Configure DSPy and Generate llms.txt
174 |
175 | ```python
176 | def generate_llms_txt_for_dspy():
177 |     # Configure DSPy (use your preferred LM)
178 |     lm = dspy.LM(model="gpt-4o-mini")
179 |     dspy.configure(lm=lm)
180 |     os.environ["OPENAI_API_KEY"] = "<YOUR OPENAI KEY>"
181 |
182 |     # Initialize our analyzer
183 |     analyzer = RepositoryAnalyzer()
184 |
185 |     # Gather DSPy repository information
186 |     repo_url = "https://github.com/stanfordnlp/dspy"
187 |     file_tree, readme_content, package_files = gather_repository_info(repo_url)
188 |
189 |     # Generate llms.txt
190 |     result = analyzer(
191 |         repo_url=repo_url,
192 |         file_tree=file_tree,
193 |         readme_content=readme_content,
194 |         package_files=package_files
195 |     )
196 |
197 |     return result
198 |
199 | # Run the generation
200 | if __name__ == "__main__":
201 |     result = generate_llms_txt_for_dspy()
202 |
203 |     # Save the generated llms.txt
204 |     with open("llms.txt", "w") as f:
205 |         f.write(result.llms_txt_content)
206 |
207 |     print("Generated llms.txt file!")
208 |     print("\nPreview:")
209 |     print(result.llms_txt_content[:500] + "...")
210 | ```
211 |
212 | ## Expected Output Structure
213 |
214 | The generated `llms.txt` for DSPy would follow this structure:
215 |
216 | ```
217 | # DSPy: Programming Language Models
218 |
219 | ## Project Overview
220 | DSPy is a framework for programming—rather than prompting—language models...
221 |
222 | ## Key Concepts
223 | - **Modules**: Building blocks for LM programs
224 | - **Signatures**: Input/output specifications
225 | - **Teleprompters**: Optimization algorithms
226 | - **Predictors**: Core reasoning components
227 |
228 | ## Architecture
229 | - `/dspy/`: Main package directory
230 |   - `/adapters/`: Input/output format handlers
231 |   - `/clients/`: LM client interfaces
232 |   - `/predict/`: Core prediction modules
233 |   - `/teleprompt/`: Optimization algorithms
234 |
235 | ## Usage Examples
236 | 1. **Building a Classifier**: Using DSPy, a user can define a modular classifier that takes in text data and categorizes it into predefined classes. The user can specify the classification logic declaratively, allowing for easy adjustments and optimizations.
237 | 2. **Creating a RAG Pipeline**: A developer can implement a retrieval-augmented generation pipeline that first retrieves relevant documents based on a query and then generates a coherent response using those documents. DSPy facilitates the integration of retrieval and generation components seamlessly.
238 | 3. **Optimizing Prompts**: Users can leverage DSPy to create a system that automatically optimizes prompts for language models based on performance metrics, improving the quality of responses over time without manual intervention.
239 | 4. **Implementing Agent Loops**: A user can design an agent loop that continuously interacts with users, learns from feedback, and refines its responses, showcasing the self-improving capabilities of the DSPy framework.
240 | 5. **Compositional Code**: Developers can write compositional code that allows different modules of the AI system to interact with each other, enabling complex workflows that can be easily modified and extended.
241 | ```
242 |
243 | The resulting `llms.txt` file provides a comprehensive, LLM-friendly overview of the DSPy repository that can help other AI systems better understand and work with the codebase.
244 |
245 | ## Next Steps
246 |
247 | - Extend the program to analyze multiple repositories
248 | - Add support for different documentation formats
249 | - Create metrics for documentation quality assessment
250 | - Build a web interface for interactive repository analysis
```

math/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: Math Reasoning\n",
8 |     "\n",
9 |     "Let's walk through a quick example of setting up a `dspy.ChainOfThought` module and optimizing it for answering algebra questions.\n",
10 |     "\n",
11 |     "Install the latest DSPy via `pip install -U dspy` and follow along. You also need to run `pip install datasets`.\n",
12 |     "\n",
13 |     "<details>\n",
14 |     "<summary>Recommended: Set up MLflow Tracing to understand what's happening under the hood.</summary>\n",
15 |     "\n",
16 |     "### MLflow DSPy Integration\n",
17 |     "\n",
18 |     "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. In this tutorial, you can use MLflow to visualize prompts and optimization progress as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
19 |     "\n",
20 |     "1. Install MLflow\n",
21 |     "\n",
22 |     "```bash\n",
23 |     "%pip install mlflow>=2.20\n",
24 |     "```\n",
25 |     "\n",
26 |     "2. Start MLflow UI in a separate terminal\n",
27 |     "```bash\n",
28 |     "mlflow ui --port 5000\n",
29 |     "```\n",
30 |     "\n",
31 |     "3. Connect the notebook to MLflow\n",
32 |     "```python\n",
33 |     "import mlflow\n",
34 |     "\n",
35 |     "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
36 |     "mlflow.set_experiment(\"DSPy\")\n",
37 |     "```\n",
38 |     "\n",
39 |     "4. Enabling tracing.\n",
40 |     "```python\n",
41 |     "mlflow.dspy.autolog()\n",
42 |     "```\n",
43 |     "\n",
44 |     "Once you have completed the steps above, you can see traces for each program execution on the notebook. They provide great visibility into the model's behavior and helps you understand the DSPy's concepts better throughout the tutorial.\n",
45 |     "\n",
46 |     "![MLflow Trace](./mlflow-tracing-math.png)\n",
47 |     "\n",
48 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
49 |     "\n",
50 |     "</details>"
51 |    ]
52 |   },
53 |   {
54 |    "cell_type": "markdown",
55 |    "metadata": {},
56 |    "source": [
57 |     "Let's tell DSPy that we will use OpenAI's `gpt-4o-mini` in our modules. To authenticate, DSPy will look into your `OPENAI_API_KEY`. You can easily swap this out for [other providers or local models](https://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb)."
58 |    ]
59 |   },
60 |   {
61 |    "cell_type": "code",
62 |    "execution_count": 1,
63 |    "metadata": {},
64 |    "outputs": [],
65 |    "source": [
66 |     "import dspy\n",
67 |     "\n",
68 |     "gpt4o_mini = dspy.LM('openai/gpt-4o-mini', max_tokens=2000)\n",
69 |     "gpt4o = dspy.LM('openai/gpt-4o', max_tokens=2000)\n",
70 |     "dspy.configure(lm=gpt4o_mini)  # we'll use gpt-4o-mini as the default LM, unless otherwise specified"
71 |    ]
72 |   },
73 |   {
74 |    "cell_type": "markdown",
75 |    "metadata": {},
76 |    "source": [
77 |     "Next, let's load some data examples from the [MATH](https://arxiv.org/abs/2103.03874) benchmark. We'll use a training split for optimization and evaluate it on a held-out dev set.\n",
78 |     "\n",
79 |     "Please note that the following step will require:\n",
80 |     "```bash\n",
81 |     "%pip install git+https://github.com/hendrycks/math.git\n",
82 |     "```"
83 |    ]
84 |   },
85 |   {
86 |    "cell_type": "code",
87 |    "execution_count": 2,
88 |    "metadata": {},
89 |    "outputs": [
90 |     {
91 |      "name": "stdout",
92 |      "output_type": "stream",
93 |      "text": [
94 |       "350 350\n"
95 |      ]
96 |     }
97 |    ],
98 |    "source": [
99 |     "from dspy.datasets import MATH\n",
100 |     "\n",
101 |     "dataset = MATH(subset='algebra')\n",
102 |     "print(len(dataset.train), len(dataset.dev))"
103 |    ]
104 |   },
105 |   {
106 |    "cell_type": "markdown",
107 |    "metadata": {},
108 |    "source": [
109 |     "Let's inspect one example from the training set."
110 |    ]
111 |   },
112 |   {
113 |    "cell_type": "code",
114 |    "execution_count": 3,
115 |    "metadata": {},
116 |    "outputs": [
117 |     {
118 |      "name": "stdout",
119 |      "output_type": "stream",
120 |      "text": [
121 |       "Question: The doctor has told Cal O'Ree that during his ten weeks of working out at the gym, he can expect each week's weight loss to be $1\\%$ of his weight at the end of the previous week. His weight at the beginning of the workouts is $244$ pounds. How many pounds does he expect to weigh at the end of the ten weeks? Express your answer to the nearest whole number.\n",
122 |       "Answer: 221\n"
123 |      ]
124 |     }
125 |    ],
126 |    "source": [
127 |     "example = dataset.train[0]\n",
128 |     "print(\"Question:\", example.question)\n",
129 |     "print(\"Answer:\", example.answer)"
130 |    ]
131 |   },
132 |   {
133 |    "cell_type": "markdown",
134 |    "metadata": {},
135 |    "source": [
136 |     "Now let's define our module. It's extremely simple: just a chain-of-thought step that takes a `question` and produces an `answer`."
137 |    ]
138 |   },
139 |   {
140 |    "cell_type": "code",
141 |    "execution_count": 4,
142 |    "metadata": {},
143 |    "outputs": [
144 |     {
145 |      "data": {
146 |       "text/plain": [
147 |        "Prediction(\n",
148 |        "    reasoning=\"Cal O'Ree's weight loss each week is $1\\\\%$ of his weight at the end of the previous week. This means that at the end of each week, he retains $99\\\\%$ of his weight from the previous week. \\n\\nIf we denote his weight at the beginning as \\\\( W_0 = 244 \\\\) pounds, then his weight at the end of week \\\\( n \\\\) can be expressed as:\\n\\\\[\\nW_n = W_{n-1} \\\\times 0.99\\n\\\\]\\nThis can be simplified to:\\n\\\\[\\nW_n = W_0 \\\\times (0.99)^n\\n\\\\]\\nAfter 10 weeks, his weight will be:\\n\\\\[\\nW_{10} = 244 \\\\times (0.99)^{10}\\n\\\\]\\n\\nNow, we calculate \\\\( (0.99)^{10} \\\\):\\n\\\\[\\n(0.99)^{10} \\\\approx 0.904382\\n\\\\]\\n\\nNow, we can calculate his expected weight after 10 weeks:\\n\\\\[\\nW_{10} \\\\approx 244 \\\\times 0.904382 \\\\approx 220.5\\n\\\\]\\n\\nRounding to the nearest whole number, Cal O'Ree can expect to weigh approximately \\\\( 221 \\\\) pounds at the end of the ten weeks.\",\n",
149 |        "    answer='221'\n",
150 |        ")"
151 |       ]
152 |      },
153 |      "execution_count": 4,
154 |      "metadata": {},
155 |      "output_type": "execute_result"
156 |     }
157 |    ],
158 |    "source": [
159 |     "module = dspy.ChainOfThought(\"question -> answer\")\n",
160 |     "module(question=example.question)"
161 |    ]
162 |   },
163 |   {
164 |    "cell_type": "markdown",
165 |    "metadata": {},
166 |    "source": [
167 |     "Next, let's set up an evaluator for the zero-shot module above, before prompt optimization."
168 |    ]
169 |   },
170 |   {
171 |    "cell_type": "code",
172 |    "execution_count": 5,
173 |    "metadata": {},
174 |    "outputs": [
175 |     {
176 |      "name": "stdout",
177 |      "output_type": "stream",
178 |      "text": [
179 |       "Average Metric: 259.00 / 350 (74.0%): 100%|██████████| 350/350 [01:30<00:00,  3.85it/s]"
180 |      ]
181 |     },
182 |     {
183 |      "name": "stderr",
184 |      "output_type": "stream",
185 |      "text": [
186 |       "2024/11/28 18:41:55 INFO dspy.evaluate.evaluate: Average Metric: 259 / 350 (74.0%)\n"
187 |      ]
188 |     },
189 |     {
190 |      "name": "stdout",
191 |      "output_type": "stream",
192 |      "text": [
193 |       "\n"
194 |      ]
195 |     },
196 |     {
197 |      "data": {
198 |       "text/html": [
199 |        "<div>\n",
200 |        "<style scoped>\n",
201 |        "    .dataframe tbody tr th:only-of-type {\n",
202 |        "        vertical-align: middle;\n",
203 |        "    }\n",
204 |        "\n",
205 |        "    .dataframe tbody tr th {\n",
206 |        "        vertical-align: top;\n",
207 |        "    }\n",
208 |        "\n",
209 |        "    .dataframe thead th {\n",
210 |        "        text-align: right;\n",
211 |        "    }\n",
212 |        "</style>\n",
213 |        "<table border=\"1\" class=\"dataframe\">\n",
214 |        "  <thead>\n",
215 |        "    <tr style=\"text-align: right;\">\n",
216 |        "      <th></th>\n",
217 |        "      <th>question</th>\n",
218 |        "      <th>example_reasoning</th>\n",
219 |        "      <th>example_answer</th>\n",
220 |        "      <th>pred_reasoning</th>\n",
221 |        "      <th>pred_answer</th>\n",
222 |        "      <th>method</th>\n",
223 |        "    </tr>\n",
224 |        "  </thead>\n",
225 |        "  <tbody>\n",
226 |        "    <tr>\n",
227 |        "      <th>0</th>\n",
228 |        "      <td>What is the smallest integer value of $c$ such that the function $...</td>\n",
229 |        "      <td>The given function has a domain of all real numbers if and only if...</td>\n",
230 |        "      <td>1</td>\n",
231 |        "      <td>To determine the smallest integer value of \\( c \\) such that the f...</td>\n",
232 |        "      <td>1</td>\n",
233 |        "      <td>✔️ [True]</td>\n",
234 |        "    </tr>\n",
235 |        "    <tr>\n",
236 |        "      <th>1</th>\n",
237 |        "      <td>What is the least value of $x$ that is a solution of $|{-x+3}|=7$?</td>\n",
238 |        "      <td>In order to have $|{-x+3}| = 7$, we must have $-x + 3 = 7$ or $-x ...</td>\n",
239 |        "      <td>-4</td>\n",
240 |        "      <td>To solve the equation \\( |{-x+3}|=7 \\), we need to consider the de...</td>\n",
241 |        "      <td>-4</td>\n",
242 |        "      <td>✔️ [True]</td>\n",
243 |        "    </tr>\n",
244 |        "    <tr>\n",
245 |        "      <th>2</th>\n",
246 |        "      <td>Evaluate $\\left\\lceil -\\frac{7}{4}\\right\\rceil$.</td>\n",
247 |        "      <td>$-\\frac{7}{4}$ is between $-1$ and $-2$, so $\\left\\lceil -\\frac{7}...</td>\n",
248 |        "      <td>-1</td>\n",
249 |        "      <td>To evaluate \\(\\left\\lceil -\\frac{7}{4}\\right\\rceil\\), we first nee...</td>\n",
250 |        "      <td>-1</td>\n",
251 |        "      <td>✔️ [True]</td>\n",
252 |        "    </tr>\n",
253 |        "    <tr>\n",
254 |        "      <th>3</th>\n",
255 |        "      <td>A triangle has vertices at coordinates $(11,1)$, $(2,3)$ and $(3,7...</td>\n",
256 |        "      <td>We must find the distance between each pair of points by using the...</td>\n",
257 |        "      <td>10</td>\n",
258 |        "      <td>To find the length of the longest side of the triangle with vertic...</td>\n",
259 |        "      <td>10</td>\n",
260 |        "      <td>✔️ [True]</td>\n",
261 |        "    </tr>\n",
262 |        "    <tr>\n",
263 |        "      <th>4</th>\n",
264 |        "      <td>Let $f(x) = x + 2$ and $g(x) = 1/f(x)$. What is $g(f(-3))$?</td>\n",
265 |        "      <td>First, we find that $f(-3) = (-3) + 2 = -1$. Then, $$g(f(-3)) = g(...</td>\n",
266 |        "      <td>1</td>\n",
267 |        "      <td>To find \\( g(f(-3)) \\), we first need to evaluate \\( f(-3) \\). The...</td>\n",
268 |        "      <td>1</td>\n",
269 |        "      <td>✔️ [True]</td>\n",
270 |        "    </tr>\n",
271 |        "  </tbody>\n",
272 |        "</table>\n",
273 |        "</div>"
274 |       ],
275 |       "text/plain": [
276 |        "                                                                question  \\\n",
277 |        "0  What is the smallest integer value of $c$ such that the function $...   \n",
278 |        "1     What is the least value of $x$ that is a solution of $|{-x+3}|=7$?   \n",
279 |        "2                       Evaluate $\\left\\lceil -\\frac{7}{4}\\right\\rceil$.   \n",
280 |        "3  A triangle has vertices at coordinates $(11,1)$, $(2,3)$ and $(3,7...   \n",
281 |        "4            Let $f(x) = x + 2$ and $g(x) = 1/f(x)$. What is $g(f(-3))$?   \n",
282 |        "\n",
283 |        "                                                       example_reasoning  \\\n",
284 |        "0  The given function has a domain of all real numbers if and only if...   \n",
285 |        "1  In order to have $|{-x+3}| = 7$, we must have $-x + 3 = 7$ or $-x ...   \n",
286 |        "2  $-\\frac{7}{4}$ is between $-1$ and $-2$, so $\\left\\lceil -\\frac{7}...   \n",
287 |        "3  We must find the distance between each pair of points by using the...   \n",
288 |        "4  First, we find that $f(-3) = (-3) + 2 = -1$. Then, $$g(f(-3)) = g(...   \n",
289 |        "\n",
290 |        "  example_answer  \\\n",
291 |        "0              1   \n",
292 |        "1             -4   \n",
293 |        "2             -1   \n",
294 |        "3             10   \n",
295 |        "4              1   \n",
296 |        "\n",
297 |        "                                                          pred_reasoning  \\\n",
298 |        "0  To determine the smallest integer value of \\( c \\) such that the f...   \n",
299 |        "1  To solve the equation \\( |{-x+3}|=7 \\), we need to consider the de...   \n",
300 |        "2  To evaluate \\(\\left\\lceil -\\frac{7}{4}\\right\\rceil\\), we first nee...   \n",
301 |        "3  To find the length of the longest side of the triangle with vertic...   \n",
302 |        "4  To find \\( g(f(-3)) \\), we first need to evaluate \\( f(-3) \\). The...   \n",
303 |        "\n",
304 |        "  pred_answer     method  \n",
305 |        "0           1  ✔️ [True]  \n",
306 |        "1          -4  ✔️ [True]  \n",
307 |        "2          -1  ✔️ [True]  \n",
308 |        "3          10  ✔️ [True]  \n",
309 |        "4           1  ✔️ [True]  "
310 |       ]
311 |      },
312 |      "metadata": {},
313 |      "output_type": "display_data"
314 |     },
315 |     {
316 |      "data": {
317 |       "text/html": [
318 |        "\n",
319 |        "                <div style='\n",
320 |        "                    text-align: center;\n",
321 |        "                    font-size: 16px;\n",
322 |        "                    font-weight: bold;\n",
323 |        "                    color: #555;\n",
324 |        "                    margin: 10px 0;'>\n",
325 |        "                    ... 345 more rows not displayed ...\n",
326 |        "                </div>\n",
327 |        "                "
328 |       ],
329 |       "text/plain": [
330 |        "<IPython.core.display.HTML object>"
331 |       ]
332 |      },
333 |      "metadata": {},
334 |      "output_type": "display_data"
335 |     },
336 |     {
337 |      "data": {
338 |       "text/plain": [
339 |        "74.0"
340 |       ]
341 |      },
342 |      "execution_count": 5,
343 |      "metadata": {},
344 |      "output_type": "execute_result"
345 |     }
346 |    ],
347 |    "source": [
348 |     "THREADS = 24\n",
349 |     "kwargs = dict(num_threads=THREADS, display_progress=True, display_table=5)\n",
350 |     "evaluate = dspy.Evaluate(devset=dataset.dev, metric=dataset.metric, **kwargs)\n",
351 |     "\n",
352 |     "evaluate(module)"
353 |    ]
354 |   },
355 |   {
356 |    "cell_type": "markdown",
357 |    "metadata": {},
358 |    "source": [
359 |     "<details>\n",
360 |     "<summary>Tracking Evaluation Results in MLflow Experiment</summary>\n",
361 |     "\n",
362 |     "<br/>\n",
363 |     "\n",
364 |     "To track and visualize the evaluation results over time, you can record the results in MLflow Experiment.\n",
365 |     "\n",
366 |     "\n",
367 |     "```python\n",
368 |     "import mlflow\n",
369 |     "\n",
370 |     "# Start an MLflow Run to record the evaluation\n",
371 |     "with mlflow.start_run(run_name=\"math_evaluation\"):\n",
372 |     "    kwargs = dict(num_threads=THREADS, display_progress=True)\n",
373 |     "    evaluate = dspy.Evaluate(devset=dataset.dev, metric=dataset.metric, **kwargs)\n",
374 |     "\n",
375 |     "    # Evaluate the program as usual\n",
376 |     "    result = evaluate(module)\n",
377 |     "\n",
378 |     "    # Log the aggregated score\n",
379 |     "    mlflow.log_metric(\"correctness\", result.score)\n",
380 |     "    # Log the detailed evaluation results as a table\n",
381 |     "    mlflow.log_table(\n",
382 |     "        {\n",
383 |     "            \"Question\": [example.question for example in dataset.dev],\n",
384 |     "            \"Gold Answer\": [example.answer for example in dataset.dev],\n",
385 |     "            \"Predicted Answer\": [output[1] for output in result.results],\n",
386 |     "            \"Correctness\": [output[2] for output in result.results],\n",
387 |     "        },\n",
388 |     "        artifact_file=\"eval_results.json\",\n",
389 |     "    )\n",
390 |     "```\n",
391 |     "\n",
392 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
393 |     "\n",
394 |     "</details>"
395 |    ]
396 |   },
397 |   {
398 |    "cell_type": "markdown",
399 |    "metadata": {},
400 |    "source": [
401 |     "And lastly let's optimize our module. Since we want strong reasoning, we'll use the large GPT-4o as the teacher model (used to bootstrap reasoning for the small LM at optimization time) but not as the prompt model (used to craft instructions) or the task model (trained).\n",
402 |     "\n",
403 |     "GPT-4o will be invoked only a small number of times. The model involved directly in optimization and in the resulting (optimized) program will be GPT-4o-mini.\n",
404 |     "\n",
405 |     "We will also specify `max_bootstrapped_demos=4` which means we want at most four bootstrapped examples in the prompt and `max_labeled_demos=4` which means that, in total between bootstrapped and pre-labeled examples, we want at most four."
406 |    ]
407 |   },
408 |   {
409 |    "cell_type": "code",
410 |    "execution_count": null,
411 |    "metadata": {},
412 |    "outputs": [],
413 |    "source": [
414 |     "kwargs = dict(num_threads=THREADS, teacher_settings=dict(lm=gpt4o), prompt_model=gpt4o_mini)\n",
415 |     "optimizer = dspy.MIPROv2(metric=dataset.metric, auto=\"medium\", **kwargs)\n",
416 |     "\n",
417 |     "kwargs = dict(max_bootstrapped_demos=4, max_labeled_demos=4)\n",
418 |     "optimized_module = optimizer.compile(module, trainset=dataset.train, **kwargs)"
419 |    ]
420 |   },
421 |   {
422 |    "cell_type": "code",
423 |    "execution_count": 7,
424 |    "metadata": {},
425 |    "outputs": [
426 |     {
427 |      "name": "stdout",
428 |      "output_type": "stream",
429 |      "text": [
430 |       "Average Metric: 310.00 / 350 (88.6%): 100%|██████████| 350/350 [01:31<00:00,  3.84it/s]"
431 |      ]
432 |     },
433 |     {
434 |      "name": "stderr",
435 |      "output_type": "stream",
436 |      "text": [
437 |       "2024/11/28 18:59:19 INFO dspy.evaluate.evaluate: Average Metric: 310 / 350 (88.6%)\n"
438 |      ]
439 |     },
440 |     {
441 |      "name": "stdout",
442 |      "output_type": "stream",
443 |      "text": [
444 |       "\n"
445 |      ]
446 |     },
447 |     {
448 |      "data": {
449 |       "text/html": [
450 |        "<div>\n",
451 |        "<style scoped>\n",
452 |        "    .dataframe tbody tr th:only-of-type {\n",
453 |        "        vertical-align: middle;\n",
454 |        "    }\n",
455 |        "\n",
456 |        "    .dataframe tbody tr th {\n",
457 |        "        vertical-align: top;\n",
458 |        "    }\n",
459 |        "\n",
460 |        "    .dataframe thead th {\n",
461 |        "        text-align: right;\n",
462 |        "    }\n",
463 |        "</style>\n",
464 |        "<table border=\"1\" class=\"dataframe\">\n",
465 |        "  <thead>\n",
466 |        "    <tr style=\"text-align: right;\">\n",
467 |        "      <th></th>\n",
468 |        "      <th>question</th>\n",
469 |        "      <th>example_reasoning</th>\n",
470 |        "      <th>example_answer</th>\n",
471 |        "      <th>pred_reasoning</th>\n",
472 |        "      <th>pred_answer</th>\n",
473 |        "      <th>method</th>\n",
474 |        "    </tr>\n",
475 |        "  </thead>\n",
476 |        "  <tbody>\n",
477 |        "    <tr>\n",
478 |        "      <th>0</th>\n",
479 |        "      <td>What is the smallest integer value of $c$ such that the function $...</td>\n",
480 |        "      <td>The given function has a domain of all real numbers if and only if...</td>\n",
481 |        "      <td>1</td>\n",
482 |        "      <td>The function \\( f(x) = \\frac{x^2 + 1}{x^2 - x + c} \\) will have a ...</td>\n",
483 |        "      <td>1</td>\n",
484 |        "      <td>✔️ [True]</td>\n",
485 |        "    </tr>\n",
486 |        "    <tr>\n",
487 |        "      <th>1</th>\n",
488 |        "      <td>What is the least value of $x$ that is a solution of $|{-x+3}|=7$?</td>\n",
489 |        "      <td>In order to have $|{-x+3}| = 7$, we must have $-x + 3 = 7$ or $-x ...</td>\n",
490 |        "      <td>-4</td>\n",
491 |        "      <td>The equation \\( |{-x+3}|=7 \\) implies two possible cases: 1. \\(-x ...</td>\n",
492 |        "      <td>-4</td>\n",
493 |        "      <td>✔️ [True]</td>\n",
494 |        "    </tr>\n",
495 |        "    <tr>\n",
496 |        "      <th>2</th>\n",
497 |        "      <td>Evaluate $\\left\\lceil -\\frac{7}{4}\\right\\rceil$.</td>\n",
498 |        "      <td>$-\\frac{7}{4}$ is between $-1$ and $-2$, so $\\left\\lceil -\\frac{7}...</td>\n",
499 |        "      <td>-1</td>\n",
500 |        "      <td>To evaluate \\(\\left\\lceil -\\frac{7}{4}\\right\\rceil\\), we first nee...</td>\n",
501 |        "      <td>-1</td>\n",
502 |        "      <td>✔️ [True]</td>\n",
503 |        "    </tr>\n",
504 |        "    <tr>\n",
505 |        "      <th>3</th>\n",
506 |        "      <td>A triangle has vertices at coordinates $(11,1)$, $(2,3)$ and $(3,7...</td>\n",
507 |        "      <td>We must find the distance between each pair of points by using the...</td>\n",
508 |        "      <td>10</td>\n",
509 |        "      <td>To find the length of the sides of the triangle formed by the vert...</td>\n",
510 |        "      <td>10</td>\n",
511 |        "      <td>✔️ [True]</td>\n",
512 |        "    </tr>\n",
513 |        "    <tr>\n",
514 |        "      <th>4</th>\n",
515 |        "      <td>Let $f(x) = x + 2$ and $g(x) = 1/f(x)$. What is $g(f(-3))$?</td>\n",
516 |        "      <td>First, we find that $f(-3) = (-3) + 2 = -1$. Then, $$g(f(-3)) = g(...</td>\n",
517 |        "      <td>1</td>\n",
518 |        "      <td>To find \\( g(f(-3)) \\), we first need to evaluate \\( f(-3) \\). Usi...</td>\n",
519 |        "      <td>1</td>\n",
520 |        "      <td>✔️ [True]</td>\n",
521 |        "    </tr>\n",
522 |        "  </tbody>\n",
523 |        "</table>\n",
524 |        "</div>"
525 |       ],
526 |       "text/plain": [
527 |        "                                                                question  \\\n",
528 |        "0  What is the smallest integer value of $c$ such that the function $...   \n",
529 |        "1     What is the least value of $x$ that is a solution of $|{-x+3}|=7$?   \n",
530 |        "2                       Evaluate $\\left\\lceil -\\frac{7}{4}\\right\\rceil$.   \n",
531 |        "3  A triangle has vertices at coordinates $(11,1)$, $(2,3)$ and $(3,7...   \n",
532 |        "4            Let $f(x) = x + 2$ and $g(x) = 1/f(x)$. What is $g(f(-3))$?   \n",
533 |        "\n",
534 |        "                                                       example_reasoning  \\\n",
535 |        "0  The given function has a domain of all real numbers if and only if...   \n",
536 |        "1  In order to have $|{-x+3}| = 7$, we must have $-x + 3 = 7$ or $-x ...   \n",
537 |        "2  $-\\frac{7}{4}$ is between $-1$ and $-2$, so $\\left\\lceil -\\frac{7}...   \n",
538 |        "3  We must find the distance between each pair of points by using the...   \n",
539 |        "4  First, we find that $f(-3) = (-3) + 2 = -1$. Then, $$g(f(-3)) = g(...   \n",
540 |        "\n",
541 |        "  example_answer  \\\n",
542 |        "0              1   \n",
543 |        "1             -4   \n",
544 |        "2             -1   \n",
545 |        "3             10   \n",
546 |        "4              1   \n",
547 |        "\n",
548 |        "                                                          pred_reasoning  \\\n",
549 |        "0  The function \\( f(x) = \\frac{x^2 + 1}{x^2 - x + c} \\) will have a ...   \n",
550 |        "1  The equation \\( |{-x+3}|=7 \\) implies two possible cases: 1. \\(-x ...   \n",
551 |        "2  To evaluate \\(\\left\\lceil -\\frac{7}{4}\\right\\rceil\\), we first nee...   \n",
552 |        "3  To find the length of the sides of the triangle formed by the vert...   \n",
553 |        "4  To find \\( g(f(-3)) \\), we first need to evaluate \\( f(-3) \\). Usi...   \n",
554 |        "\n",
555 |        "  pred_answer     method  \n",
556 |        "0           1  ✔️ [True]  \n",
557 |        "1          -4  ✔️ [True]  \n",
558 |        "2          -1  ✔️ [True]  \n",
559 |        "3          10  ✔️ [True]  \n",
560 |        "4           1  ✔️ [True]  "
561 |       ]
562 |      },
563 |      "metadata": {},
564 |      "output_type": "display_data"
565 |     },
566 |     {
567 |      "data": {
568 |       "text/html": [
569 |        "\n",
570 |        "                <div style='\n",
571 |        "                    text-align: center;\n",
572 |        "                    font-size: 16px;\n",
573 |        "                    font-weight: bold;\n",
574 |        "                    color: #555;\n",
575 |        "                    margin: 10px 0;'>\n",
576 |        "                    ... 345 more rows not displayed ...\n",
577 |        "                </div>\n",
578 |        "                "
579 |       ],
580 |       "text/plain": [
581 |        "<IPython.core.display.HTML object>"
582 |       ]
583 |      },
584 |      "metadata": {},
585 |      "output_type": "display_data"
586 |     },
587 |     {
588 |      "data": {
589 |       "text/plain": [
590 |        "88.57"
591 |       ]
592 |      },
593 |      "execution_count": 7,
594 |      "metadata": {},
595 |      "output_type": "execute_result"
596 |     }
597 |    ],
598 |    "source": [
599 |     "evaluate(optimized_module)"
600 |    ]
601 |   },
602 |   {
603 |    "cell_type": "markdown",
604 |    "metadata": {},
605 |    "source": [
606 |     "Neat. It was pretty straightforward to improve quality from 74% to over 88% on a held-out set here.\n",
607 |     "\n",
608 |     "That said, for reasoning tasks like this, you will often want to consider more advanced strategies, like:\n",
609 |     "\n",
610 |     "- A `dspy.ReAct` module with access to a calculator function or `dspy.PythonInterpreter`\n",
611 |     "- Ensembling multiple optimized prompts with a majority vote (or an Aggregator module) on top"
612 |    ]
613 |   },
614 |   {
615 |    "cell_type": "markdown",
616 |    "metadata": {},
617 |    "source": [
618 |     "\n",
619 |     "Just to understand what changed, let's view the prompt after optimization. Alternatively, if you enabled MLflow tracing following above instructions, you can compare the prompts before and after optimization in the rich trace UI."
620 |    ]
621 |   },
622 |   {
623 |    "cell_type": "code",
624 |    "execution_count": 8,
625 |    "metadata": {},
626 |    "outputs": [
627 |     {
628 |      "name": "stdout",
629 |      "output_type": "stream",
630 |      "text": [
631 |       "\n",
632 |       "\n",
633 |       "\n",
634 |       "\n",
635 |       "\u001b[34m[2024-11-28T18:59:19.176586]\u001b[0m\n",
636 |       "\n",
637 |       "\u001b[31mSystem message:\u001b[0m\n",
638 |       "\n",
639 |       "Your input fields are:\n",
640 |       "1. `question` (str)\n",
641 |       "\n",
642 |       "Your output fields are:\n",
643 |       "1. `reasoning` (str)\n",
644 |       "2. `answer` (str)\n",
645 |       "\n",
646 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
647 |       "\n",
648 |       "[[ ## question ## ]]\n",
649 |       "{question}\n",
650 |       "\n",
651 |       "[[ ## reasoning ## ]]\n",
652 |       "{reasoning}\n",
653 |       "\n",
654 |       "[[ ## answer ## ]]\n",
655 |       "{answer}\n",
656 |       "\n",
657 |       "[[ ## completed ## ]]\n",
658 |       "\n",
659 |       "In adhering to this structure, your objective is: \n",
660 |       "        Analyze the `question` provided, and systematically apply mathematical reasoning to derive the `answer`. Ensure to articulate each step of your thought process in the `reasoning` field, detailing how you identify relationships and formulate equations to arrive at the solution.\n",
661 |       "\n",
662 |       "\n",
663 |       "\u001b[31mUser message:\u001b[0m\n",
664 |       "\n",
665 |       "[[ ## question ## ]]\n",
666 |       "If $|4x+2|=10$ and $x<0$, what is the value of $x$?\n",
667 |       "\n",
668 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
669 |       "\n",
670 |       "\n",
671 |       "\u001b[31mAssistant message:\u001b[0m\n",
672 |       "\n",
673 |       "[[ ## reasoning ## ]]\n",
674 |       "The equation $|4x+2|=10$ implies two possible equations: $4x+2=10$ or $4x+2=-10$. We solve each equation separately.\n",
675 |       "\n",
676 |       "1. For $4x+2=10$:\n",
677 |       "   \\[\n",
678 |       "   4x + 2 = 10 \\\\\n",
679 |       "   4x = 8 \\\\\n",
680 |       "   x = 2\n",
681 |       "   \\]\n",
682 |       "   However, $x=2$ does not satisfy the condition $x<0$.\n",
683 |       "\n",
684 |       "2. For $4x+2=-10$:\n",
685 |       "   \\[\n",
686 |       "   4x + 2 = -10 \\\\\n",
687 |       "   4x = -12 \\\\\n",
688 |       "   x = -3\n",
689 |       "   \\]\n",
690 |       "   The solution $x = -3$ satisfies the condition $x<0$.\n",
691 |       "\n",
692 |       "Therefore, the value of $x$ is $\\boxed{-3}$.\n",
693 |       "\n",
694 |       "[[ ## answer ## ]]\n",
695 |       "-3\n",
696 |       "\n",
697 |       "[[ ## completed ## ]]\n",
698 |       "\n",
699 |       "\n",
700 |       "\u001b[31mUser message:\u001b[0m\n",
701 |       "\n",
702 |       "[[ ## question ## ]]\n",
703 |       "Given that $-4$ is a solution to $x^2 + bx -36 = 0$, what is the value of $b$?\n",
704 |       "\n",
705 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
706 |       "\n",
707 |       "\n",
708 |       "\u001b[31mAssistant message:\u001b[0m\n",
709 |       "\n",
710 |       "[[ ## reasoning ## ]]\n",
711 |       "The product of the roots of this quadratic is $-36/1=-36$, so the other solution must be $-36/-4=9$. That means that the sum of the solutions is $-4+9=5$. The sum of the solutions is also $-b/1=-b$. Thus, $-b=5$ and $b=\\boxed{-5}$.\n",
712 |       "\n",
713 |       "[[ ## answer ## ]]\n",
714 |       "-5\n",
715 |       "\n",
716 |       "[[ ## completed ## ]]\n",
717 |       "\n",
718 |       "\n",
719 |       "\u001b[31mUser message:\u001b[0m\n",
720 |       "\n",
721 |       "[[ ## question ## ]]\n",
722 |       "Richard is building a rectangular playground from 200 feet of fencing. The fencing must entirely enclose the playground. What is the maximum area of this playground?\n",
723 |       "\n",
724 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
725 |       "\n",
726 |       "\n",
727 |       "\u001b[31mAssistant message:\u001b[0m\n",
728 |       "\n",
729 |       "[[ ## reasoning ## ]]\n",
730 |       "Let the length of the playground be $l$ and the width be $w$. We have the equation $2l+2w=200 \\Rightarrow l + w = 100$. We want to maximize the area of this rectangular playground, which is given by $lw$. From our equation, we know that $l=100-w$. Substituting this in to our expression for area, we have \\[(100-w)(w)=100w-w^2\\]We will now complete the square to find the maximum value of this expression. Factoring a $-1$ out, we have \\[-(w^2-100w)\\]In order for the expression inside the parenthesis to be a perfect square, we need to add and subtract $(100/2)^2=2500$ inside the parenthesis. Doing this, we get \\[-(w^2-100w+2500-2500) \\Rightarrow -(w-50)^2+2500\\]Since the maximum value of $-(w-50)^2$ is 0 (perfect squares are always nonnegative), the maximum value of the entire expression is 2500, which is achieved when $w=50$ and $l=100-w=50$ (the playground is a square). Thus, the maximum area of the playground is $\\boxed{2500}$ square feet.\n",
731 |       "\n",
732 |       "[[ ## answer ## ]]\n",
733 |       "2500\n",
734 |       "\n",
735 |       "[[ ## completed ## ]]\n",
736 |       "\n",
737 |       "\n",
738 |       "\u001b[31mUser message:\u001b[0m\n",
739 |       "\n",
740 |       "[[ ## question ## ]]\n",
741 |       "Alice and Bob are playing a game. Alice starts first. On Alice's turn, she flips a coin. If she gets a heads, she wins. If not, it becomes Bob's turn. On Bob's turn, he flips a coin. If he gets a tails, he wins. If not, it becomes Alice's turn. What is the probability that Alice wins the game?\n",
742 |       "\n",
743 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
744 |       "\n",
745 |       "\n",
746 |       "\u001b[31mAssistant message:\u001b[0m\n",
747 |       "\n",
748 |       "[[ ## reasoning ## ]]\n",
749 |       "Alice has a $1/2$ chance of winning the game on her first turn. If she doesn't, then the probability that she wins the game on her second turn is $1/8,$ since she must not win on her first flip ($1/2$ chance), Bob must not win on his first flip ($1/2$ chance), and then Alice must win on her second flip ($1/2$ chance). The probability that she wins the game on her third turn is $1/32,$ and in general, the probability that she wins the game on her $k^\\text{th}$ turn is $(1/2)^{2k-1}.$ Thus, the probability that Alice wins is an infinite geometric series with first term $1/2$ and common ratio $1/4.$ So, the probability that Alice wins the game is $$\\frac{\\frac12}{1-\\frac14} = \\boxed{\\frac{2}{3}}.$$OR\n",
750 |       "\n",
751 |       "Note that the only difference between the odds of Alice or Bob winning is who goes first. Because Bob goes second, the odds of him winning on his $k^\\text{th}$ flip is half of the odds that Alice wins on her $k^\\text{th}$ flip, since Alice must first get a tails before Bob gets a chance to win. Thus, if $a$ is Alice's chance of winning, and $b$ is Bob's chance of winning, then $a = 2b.$ Also, since someone must win, $a + b = 1.$ It follows that $a = 2/3$ and $b = 1/3,$ so Alice has a $\\boxed{\\frac{2}{3}}$ chance of winning the game.\n",
752 |       "\n",
753 |       "[[ ## answer ## ]]\n",
754 |       "\\frac{2}{3}\n",
755 |       "\n",
756 |       "[[ ## completed ## ]]\n",
757 |       "\n",
758 |       "\n",
759 |       "\u001b[31mUser message:\u001b[0m\n",
760 |       "\n",
761 |       "[[ ## question ## ]]\n",
762 |       "Find the smallest possible value of $$\\frac{(y-x)^2}{(y-z)(z-x)} + \\frac{(z-y)^2}{(z-x)(x-y)} + \\frac{(x-z)^2}{(x-y)(y-z)},$$ where $x,y,$ and $z$ are distinct real numbers.\n",
763 |       "\n",
764 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
765 |       "\n",
766 |       "\n",
767 |       "\u001b[31mResponse:\u001b[0m\n",
768 |       "\n",
769 |       "\u001b[32m[[ ## reasoning ## ]]\n",
770 |       "Let \\( S = \\frac{(y-x)^2}{(y-z)(z-x)} + \\frac{(z-y)^2}{(z-x)(x-y)} + \\frac{(x-z)^2}{(x-y)(y-z)} \\).\n",
771 |       "\n",
772 |       "To find the minimum value of \\( S \\), we can use the method of symmetry and the Cauchy-Schwarz inequality. \n",
773 |       "\n",
774 |       "By applying the Cauchy-Schwarz inequality, we have:\n",
775 |       "\\[\n",
776 |       "\\left( \\frac{(y-x)^2}{(y-z)(z-x)} + \\frac{(z-y)^2}{(z-x)(x-y)} + \\frac{(x-z)^2}{(x-y)(y-z)} \\right) \\left( (y-z)(z-x) + (z-x)(x-y) + (x-y)(y-z) \\right) \\geq \\left( (y-x) + (z-y) + (x-z) \\right)^2.\n",
777 |       "\\]\n",
778 |       "The right-hand side simplifies to:\n",
779 |       "\\[\n",
780 |       "(y-x) + (z-y) + (x-z) = 0,\n",
781 |       "\\]\n",
782 |       "which means the right-hand side is \\( 0 \\). Therefore, we have:\n",
783 |       "\\[\n",
784 |       "S \\cdot \\left( (y-z)(z-x) + (z-x)(x-y) + (x-y)(y-z) \\right) \\geq 0.\n",
785 |       "\\]\n",
786 |       "This implies that \\( S \\) is non-negative.\n",
787 |       "\n",
788 |       "Next, we can test specific values for \\( x, y, z \\) to find the minimum. Let's set \\( x = 0, y = 1, z = 2 \\):\n",
789 |       "\\[\n",
790 |       "S = \\frac{(1-0)^2}{(1-2)(2-0)} + \\frac{(2-1)^2}{(2-0)(0-1)} + \\frac{(0-2)^2}{(0-1)(1-2)}.\n",
791 |       "\\]\n",
792 |       "Calculating each term:\n",
793 |       "1. The first term:\n",
794 |       "   \\[\n",
795 |       "   \\frac{1^2}{(-1)(2)} = \\frac{1}{-2} = -\\frac{1}{2}.\n",
796 |       "   \\]\n",
797 |       "2. The second term:\n",
798 |       "   \\[\n",
799 |       "   \\frac{1^2}{(2)(-1)} = \\frac{1}{-2} = -\\frac{1}{2}.\n",
800 |       "   \\]\n",
801 |       "3. The third term:\n",
802 |       "   \\[\n",
803 |       "   \\frac{(-2)^2}{(-1)(-1)} = \\frac{4}{1} = 4.\n",
804 |       "   \\]\n",
805 |       "\n",
806 |       "Thus,\n",
807 |       "\\[\n",
808 |       "S = -\\frac{1}{2} - \\frac{1}{2} + 4 = 3.\n",
809 |       "\\]\n",
810 |       "\n",
811 |       "To check if this is indeed the minimum, we can also consider the case when \\( x, y, z \\) are the roots of a quadratic polynomial. By symmetry and the nature of the expression, we can conclude that the minimum value of \\( S \\) is indeed \\( 3 \\).\n",
812 |       "\n",
813 |       "Therefore, the smallest possible value of \\( S \\) is \\( \\boxed{3} \\).\n",
814 |       "\n",
815 |       "[[ ## answer ## ]]\n",
816 |       "3\n",
817 |       "\n",
818 |       "[[ ## completed ## ]]\u001b[0m\n",
819 |       "\n",
820 |       "\n",
821 |       "\n",
822 |       "\n",
823 |       "\n"
824 |      ]
825 |     }
826 |    ],
827 |    "source": [
828 |     "dspy.inspect_history()"
829 |    ]
830 |   },
831 |   {
832 |    "cell_type": "markdown",
833 |    "metadata": {},
834 |    "source": []
835 |   }
836 |  ],
837 |  "metadata": {
838 |   "kernelspec": {
839 |    "display_name": "py310_sept24_user",
840 |    "language": "python",
841 |    "name": "python3"
842 |   },
843 |   "language_info": {
844 |    "codemirror_mode": {
845 |     "name": "ipython",
846 |     "version": 3
847 |    },
848 |    "file_extension": ".py",
849 |    "mimetype": "text/x-python",
850 |    "name": "python",
851 |    "nbconvert_exporter": "python",
852 |    "pygments_lexer": "ipython3",
853 |    "version": "3.10.14"
854 |   }
855 |  },
856 |  "nbformat": 4,
857 |  "nbformat_minor": 2
858 | }
```

mcp/index.md
```
1 | # Tutorial: Use MCP tools in DSPy
2 |
3 | MCP, standing for Model Context Protocol, is an open protocol that standardizes how applications
4 | provide context to LLMs. Despite some development overhead, MCP offers a valuable opportunity to
5 | share tools, resources, and prompts with other developers regardless of the technical stack you are
6 | using. Likewise, you can use the tools built by other developers without rewriting code.
7 |
8 | In this guide, we will walk you through how to use MCP tools in DSPy. For demonstration purposes,
9 | we will build an airline service agent that can help users book flights and modify or cancel
10 | existing bookings. This will rely on an MCP server with custom tools, but it should be easy to generalize
11 | to [MCP servers built by the community](https://modelcontextprotocol.io/examples).
12 |
13 | ??? "How to run this tutorial"
14 |     This tutorial cannot be run in hosted IPython notebooks like Google Colab or Databricks notebooks.
15 |     To run the code, you will need to follow the guide to write code on your local device. The code
16 |     is tested on macOS and should work the same way in Linux environments.
17 |
18 | ## Install Dependencies
19 |
20 | Before starting, let's install the required dependencies:
21 |
22 | ```shell
23 | pip install -U "dspy[mcp]"
24 | ```
25 |
26 | ## MCP Server Setup
27 |
28 | Let's first set up the MCP server for the airline agent, which contains:
29 |
30 | - A set of databases
31 |   - User database, storing user information.
32 |   - Flight database, storing flight information.
33 |   - Ticket database, storing customer tickets.
34 | - A set of tools
35 |   - fetch_flight_info: get flight information for specific dates.
36 |   - fetch_itinerary: get information about booked itineraries.
37 |   - book_itinerary: book a flight on behalf of the user.
38 |   - modify_itinerary: modify an itinerary, either through flight changes or cancellation.
39 |   - get_user_info: get user information.
40 |   - file_ticket: file a backlog ticket for human assistance.
41 |
42 | In your working directory, create a file `mcp_server.py`, and paste the following content into
43 | it:
44 |
45 | ```python
46 | import random
47 | import string
48 |
49 | from mcp.server.fastmcp import FastMCP
50 | from pydantic import BaseModel
51 |
52 | # Create an MCP server
53 | mcp = FastMCP("Airline Agent")
54 |
55 |
56 | class Date(BaseModel):
57 |     # Somehow LLM is bad at specifying `datetime.datetime`
58 |     year: int
59 |     month: int
60 |     day: int
61 |     hour: int
62 |
63 |
64 | class UserProfile(BaseModel):
65 |     user_id: str
66 |     name: str
67 |     email: str
68 |
69 |
70 | class Flight(BaseModel):
71 |     flight_id: str
72 |     date_time: Date
73 |     origin: str
74 |     destination: str
75 |     duration: float
76 |     price: float
77 |
78 |
79 | class Itinerary(BaseModel):
80 |     confirmation_number: str
81 |     user_profile: UserProfile
82 |     flight: Flight
83 |
84 |
85 | class Ticket(BaseModel):
86 |     user_request: str
87 |     user_profile: UserProfile
88 |
89 |
90 | user_database = {
91 |     "Adam": UserProfile(user_id="1", name="Adam", email="adam@gmail.com"),
92 |     "Bob": UserProfile(user_id="2", name="Bob", email="bob@gmail.com"),
93 |     "Chelsie": UserProfile(user_id="3", name="Chelsie", email="chelsie@gmail.com"),
94 |     "David": UserProfile(user_id="4", name="David", email="david@gmail.com"),
95 | }
96 |
97 | flight_database = {
98 |     "DA123": Flight(
99 |         flight_id="DA123",
100 |         origin="SFO",
101 |         destination="JFK",
102 |         date_time=Date(year=2025, month=9, day=1, hour=1),
103 |         duration=3,
104 |         price=200,
105 |     ),
106 |     "DA125": Flight(
107 |         flight_id="DA125",
108 |         origin="SFO",
109 |         destination="JFK",
110 |         date_time=Date(year=2025, month=9, day=1, hour=7),
111 |         duration=9,
112 |         price=500,
113 |     ),
114 |     "DA456": Flight(
115 |         flight_id="DA456",
116 |         origin="SFO",
117 |         destination="SNA",
118 |         date_time=Date(year=2025, month=10, day=1, hour=1),
119 |         duration=2,
120 |         price=100,
121 |     ),
122 |     "DA460": Flight(
123 |         flight_id="DA460",
124 |         origin="SFO",
125 |         destination="SNA",
126 |         date_time=Date(year=2025, month=10, day=1, hour=9),
127 |         duration=2,
128 |         price=120,
129 |     ),
130 | }
131 |
132 | itinery_database = {}
133 | ticket_database = {}
134 |
135 |
136 | @mcp.tool()
137 | def fetch_flight_info(date: Date, origin: str, destination: str):
138 |     """Fetch flight information from origin to destination on the given date"""
139 |     flights = []
140 |
141 |     for flight_id, flight in flight_database.items():
142 |         if (
143 |             flight.date_time.year == date.year
144 |             and flight.date_time.month == date.month
145 |             and flight.date_time.day == date.day
146 |             and flight.origin == origin
147 |             and flight.destination == destination
148 |         ):
149 |             flights.append(flight)
150 |     return flights
151 |
152 |
153 | @mcp.tool()
154 | def fetch_itinerary(confirmation_number: str):
155 |     """Fetch a booked itinerary information from database"""
156 |     return itinery_database.get(confirmation_number)
157 |
158 |
159 | @mcp.tool()
160 | def pick_flight(flights: list[Flight]):
161 |     """Pick up the best flight that matches users' request."""
162 |     sorted_flights = sorted(
163 |         flights,
164 |         key=lambda x: (
165 |             x.get("duration") if isinstance(x, dict) else x.duration,
166 |             x.get("price") if isinstance(x, dict) else x.price,
167 |         ),
168 |     )
169 |     return sorted_flights[0]
170 |
171 |
172 | def generate_id(length=8):
173 |     chars = string.ascii_lowercase + string.digits
174 |     return "".join(random.choices(chars, k=length))
175 |
176 |
177 | @mcp.tool()
178 | def book_itinerary(flight: Flight, user_profile: UserProfile):
179 |     """Book a flight on behalf of the user."""
180 |     confirmation_number = generate_id()
181 |     while confirmation_number in itinery_database:
182 |         confirmation_number = generate_id()
183 |     itinery_database[confirmation_number] = Itinerary(
184 |         confirmation_number=confirmation_number,
185 |         user_profile=user_profile,
186 |         flight=flight,
187 |     )
188 |     return confirmation_number, itinery_database[confirmation_number]
189 |
190 |
191 | @mcp.tool()
192 | def cancel_itinerary(confirmation_number: str, user_profile: UserProfile):
193 |     """Cancel an itinerary on behalf of the user."""
194 |     if confirmation_number in itinery_database:
195 |         del itinery_database[confirmation_number]
196 |         return
197 |     raise ValueError("Cannot find the itinerary, please check your confirmation number.")
198 |
199 |
200 | @mcp.tool()
201 | def get_user_info(name: str):
202 |     """Fetch the user profile from database with given name."""
203 |     return user_database.get(name)
204 |
205 |
206 | @mcp.tool()
207 | def file_ticket(user_request: str, user_profile: UserProfile):
208 |     """File a customer support ticket if this is something the agent cannot handle."""
209 |     ticket_id = generate_id(length=6)
210 |     ticket_database[ticket_id] = Ticket(
211 |         user_request=user_request,
212 |         user_profile=user_profile,
213 |     )
214 |     return ticket_id
215 |
216 |
217 | if __name__ == "__main__":
218 |     mcp.run()
219 | ```
220 |
221 | Before we start the server, let's take a look at the code.
222 |
223 | We first create a `FastMCP` instance, which is a utility that helps quickly build an MCP server:
224 |
225 | ```python
226 | mcp = FastMCP("Airline Agent")
227 | ```
228 |
229 | Then we define our data structures, which in a real-world application would be the database schema, e.g.:
230 |
231 | ```python
232 | class Flight(BaseModel):
233 |     flight_id: str
234 |     date_time: Date
235 |     origin: str
236 |     destination: str
237 |     duration: float
238 |     price: float
239 | ```
240 |
241 | Following that, we initialize our database instances. In a real-world application, these would be connectors to
242 | actual databases, but for simplicity, we just use dictionaries:
243 |
244 | ```python
245 | user_database = {
246 |     "Adam": UserProfile(user_id="1", name="Adam", email="adam@gmail.com"),
247 |     "Bob": UserProfile(user_id="2", name="Bob", email="bob@gmail.com"),
248 |     "Chelsie": UserProfile(user_id="3", name="Chelsie", email="chelsie@gmail.com"),
249 |     "David": UserProfile(user_id="4", name="David", email="david@gmail.com"),
250 | }
251 | ```
252 |
253 | The next step is to define the tools and mark them with `@mcp.tool()` so that they are discoverable by
254 | MCP clients as MCP tools:
255 |
256 | ```python
257 | @mcp.tool()
258 | def fetch_flight_info(date: Date, origin: str, destination: str):
259 |     """Fetch flight information from origin to destination on the given date"""
260 |     flights = []
261 |
262 |     for flight_id, flight in flight_database.items():
263 |         if (
264 |             flight.date_time.year == date.year
265 |             and flight.date_time.month == date.month
266 |             and flight.date_time.day == date.day
267 |             and flight.origin == origin
268 |             and flight.destination == destination
269 |         ):
270 |             flights.append(flight)
271 |     return flights
272 | ```
273 |
274 | The last step is spinning up the server:
275 |
276 | ```python
277 | if __name__ == "__main__":
278 |     mcp.run()
279 | ```
280 |
281 | Now we have finished writing the server! Let's launch it:
282 |
283 | ```shell
284 | python path_to_your_working_directory/mcp_server.py
285 | ```
286 |
287 | ## Write a DSPy Program That Utilizes Tools in MCP Server
288 |
289 | Now that the server is running, let's build the actual airline service agent which
290 | utilizes the MCP tools in our server to assist users. In your working directory,
291 | create a file named `dspy_mcp_agent.py`, and follow the guide to add code to it.
292 |
293 | ### Gather Tools from MCP Servers
294 |
295 | We first need to gather all available tools from the MCP server and make them
296 | usable by DSPy. DSPy provides an API [`dspy.Tool`](https://dspy.ai/api/primitives/Tool/)
297 | as the standard tool interface. Let's convert all the MCP tools to `dspy.Tool`.
298 |
299 | We need to create an MCP client instance to communicate with the MCP server, fetch all available
300 | tools, and convert them to `dspy.Tool` using the static method `from_mcp_tool`:
301 |
302 | ```python
303 | from mcp import ClientSession, StdioServerParameters
304 | from mcp.client.stdio import stdio_client
305 |
306 | # Create server parameters for stdio connection
307 | server_params = StdioServerParameters(
308 |     command="python",  # Executable
309 |     args=["path_to_your_working_directory/mcp_server.py"],
310 |     env=None,
311 | )
312 |
313 | async def run():
314 |     async with stdio_client(server_params) as (read, write):
315 |         async with ClientSession(read, write) as session:
316 |             # Initialize the connection
317 |             await session.initialize()
318 |             # List available tools
319 |             tools = await session.list_tools()
320 |
321 |             # Convert MCP tools to DSPy tools
322 |             dspy_tools = []
323 |             for tool in tools.tools:
324 |                 dspy_tools.append(dspy.Tool.from_mcp_tool(session, tool))
325 |
326 |             print(len(dspy_tools))
327 |             print(dspy_tools[0].args)
328 |
329 | if __name__ == "__main__":
330 |     import asyncio
331 |
332 |     asyncio.run(run())
333 | ```
334 |
335 | With the code above, we have successfully collected all available MCP tools and converted
336 | them to DSPy tools.
337 |
338 |
339 | ### Build a DSPy Agent to Handle Customer Requests
340 |
341 | Now we will use `dspy.ReAct` to build the agent for handling customer requests. `ReAct` stands
342 | for "reasoning and acting," which asks the LLM to decide whether to call a tool or wrap up the process.
343 | If a tool is required, the LLM takes responsibility for deciding which tool to call and providing
344 | the appropriate arguments.
345 |
346 | As usual, we need to create a `dspy.Signature` to define the input and output of our agent:
347 |
348 | ```python
349 | import dspy
350 |
351 | class DSPyAirlineCustomerService(dspy.Signature):
352 |     """You are an airline customer service agent. You are given a list of tools to handle user requests. You should decide the right tool to use in order to fulfill users' requests."""
353 |
354 |     user_request: str = dspy.InputField()
355 |     process_result: str = dspy.OutputField(
356 |         desc=(
357 |             "Message that summarizes the process result, and the information users need, "
358 |             "e.g., the confirmation_number if it's a flight booking request."
359 |         )
360 |     )
361 | ```
362 |
363 | And choose an LM for our agent:
364 |
365 | ```python
366 | dspy.configure(lm=dspy.LM("openai/gpt-4o-mini"))
367 | ```
368 |
369 | Then we create the ReAct agent by passing the tools and signature into the `dspy.ReAct` API. We can now
370 | put together the complete code script:
371 |
372 | ```python
373 | from mcp import ClientSession, StdioServerParameters
374 | from mcp.client.stdio import stdio_client
375 |
376 | import dspy
377 |
378 | # Create server parameters for stdio connection
379 | server_params = StdioServerParameters(
380 |     command="python",  # Executable
381 |     args=["script_tmp/mcp_server.py"],  # Optional command line arguments
382 |     env=None,  # Optional environment variables
383 | )
384 |
385 |
386 | class DSPyAirlineCustomerService(dspy.Signature):
387 |     """You are an airline customer service agent. You are given a list of tools to handle user requests.
388 |     You should decide the right tool to use in order to fulfill users' requests."""
389 |
390 |     user_request: str = dspy.InputField()
391 |     process_result: str = dspy.OutputField(
392 |         desc=(
393 |             "Message that summarizes the process result, and the information users need, "
394 |             "e.g., the confirmation_number if it's a flight booking request."
395 |         )
396 |     )
397 |
398 |
399 | dspy.configure(lm=dspy.LM("openai/gpt-4o-mini"))
400 |
401 |
402 | async def run(user_request):
403 |     async with stdio_client(server_params) as (read, write):
404 |         async with ClientSession(read, write) as session:
405 |             # Initialize the connection
406 |             await session.initialize()
407 |             # List available tools
408 |             tools = await session.list_tools()
409 |
410 |             # Convert MCP tools to DSPy tools
411 |             dspy_tools = []
412 |             for tool in tools.tools:
413 |                 dspy_tools.append(dspy.Tool.from_mcp_tool(session, tool))
414 |
415 |             # Create the agent
416 |             react = dspy.ReAct(DSPyAirlineCustomerService, tools=dspy_tools)
417 |
418 |             result = await react.acall(user_request=user_request)
419 |             print(result)
420 |
421 |
422 | if __name__ == "__main__":
423 |     import asyncio
424 |
425 |     asyncio.run(run("please help me book a flight from SFO to JFK on 09/01/2025, my name is Adam"))
426 | ```
427 |
428 | Note that we must call `react.acall` because MCP tools are async by default. Let's execute the script:
429 |
430 | ```shell
431 | python path_to_your_working_directory/dspy_mcp_agent.py
432 | ```
433 |
434 | You should see output similar to this:
435 |
436 | ```
437 | Prediction(
438 |     trajectory={'thought_0': 'I need to fetch flight information for Adam from SFO to JFK on 09/01/2025 to find available flights for booking.', 'tool_name_0': 'fetch_flight_info', 'tool_args_0': {'date': {'year': 2025, 'month': 9, 'day': 1, 'hour': 0}, 'origin': 'SFO', 'destination': 'JFK'}, 'observation_0': ['{"flight_id": "DA123", "date_time": {"year": 2025, "month": 9, "day": 1, "hour": 1}, "origin": "SFO", "destination": "JFK", "duration": 3.0, "price": 200.0}', '{"flight_id": "DA125", "date_time": {"year": 2025, "month": 9, "day": 1, "hour": 7}, "origin": "SFO", "destination": "JFK", "duration": 9.0, "price": 500.0}'], ..., 'tool_name_4': 'finish', 'tool_args_4': {}, 'observation_4': 'Completed.'},
439 |     reasoning="I successfully booked a flight for Adam from SFO to JFK on 09/01/2025. I found two available flights, selected the more economical option (flight DA123 at 1 AM for $200), retrieved Adam's user profile, and completed the booking process. The confirmation number for the flight is 8h7clk3q.",
440 |     process_result='Your flight from SFO to JFK on 09/01/2025 has been successfully booked. Your confirmation number is 8h7clk3q.'
441 | )
442 | ```
443 |
444 | The `trajectory` field contains the entire thinking and acting process. If you're curious about what's happening
445 | under the hood, check out the [Observability Guide](https://dspy.ai/tutorials/observability/) to set up MLflow,
446 | which visualizes every step happening inside `dspy.ReAct`!
447 |
448 |
449 | ## Conclusion
450 |
451 | In this guide, we built an airline service agent that utilizes a custom MCP server and the `dspy.ReAct` module. In the context
452 | of MCP support, DSPy provides a simple interface for interacting with MCP tools, giving you the flexibility to implement
453 | any functionality you need.
```

mem0_react_agent/index.md
```
1 | # Building Memory-Enabled Agents with DSPy ReAct and Mem0
2 |
3 | This tutorial demonstrates how to build intelligent conversational agents that can remember information across interactions using DSPy's ReAct framework combined with [Mem0](https://docs.mem0.ai/)'s memory capabilities. You'll learn to create agents that can store, retrieve, and use contextual information to provide personalized and coherent responses.
4 |
5 | ## What You'll Build
6 |
7 | By the end of this tutorial, you'll have a memory-enabled agent that can:
8 |
9 | - **Remember user preferences** and past conversations
10 | - **Store and retrieve factual information** about users and topics
11 | - **Use memory to inform decisions** and provide personalized responses
12 | - **Handle complex multi-turn conversations** with context awareness
13 | - **Manage different types of memories** (facts, preferences, experiences)
14 |
15 | ## Prerequisites
16 |
17 | - Basic understanding of DSPy and ReAct agents
18 | - Python 3.9+ installed
19 | - API keys for your preferred LLM provider
20 |
21 | ## Installation and Setup
22 |
23 | ```bash
24 | pip install dspy mem0ai
25 | ```
26 |
27 | ## Step 1: Understanding Mem0 Integration
28 |
29 | Mem0 provides a memory layer that can store, search, and retrieve memories for AI agents. Let's start by understanding how to integrate it with DSPy:
30 |
31 | ```python
32 | import dspy
33 | from mem0 import Memory
34 | import os
35 | from typing import List, Dict, Any, Optional
36 | from datetime import datetime
37 |
38 | # Configure environment
39 | os.environ["OPENAI_API_KEY"] = "your-openai-api-key"
40 |
41 | # Initialize Mem0 memory system
42 | config = {
43 |     "llm": {
44 |         "provider": "openai",
45 |         "config": {
46 |             "model": "gpt-4o-mini",
47 |             "temperature": 0.1
48 |         }
49 |     },
50 |     "embedder": {
51 |         "provider": "openai",
52 |         "config": {
53 |             "model": "text-embedding-3-small"
54 |         }
55 |     }
56 | }
57 | ```
58 |
59 | ## Step 2: Create Memory-Aware Tools
60 |
61 | Let's create tools that can interact with the memory system:
62 |
63 | ```python
64 | import datetime
65 |
66 | class MemoryTools:
67 |     """Tools for interacting with the Mem0 memory system."""
68 |
69 |     def __init__(self, memory: Memory):
70 |         self.memory = memory
71 |
72 |     def store_memory(self, content: str, user_id: str = "default_user") -> str:
73 |         """Store information in memory."""
74 |         try:
75 |             self.memory.add(content, user_id=user_id)
76 |             return f"Stored memory: {content}"
77 |         except Exception as e:
78 |             return f"Error storing memory: {str(e)}"
79 |
80 |     def search_memories(self, query: str, user_id: str = "default_user", limit: int = 5) -> str:
81 |         """Search for relevant memories."""
82 |         try:
83 |             results = self.memory.search(query, user_id=user_id, limit=limit)
84 |             if not results:
85 |                 return "No relevant memories found."
86 |
87 |             memory_text = "Relevant memories found:\n"
88 |             for i, result in enumerate(results["results"]):
89 |                 memory_text += f"{i}. {result['memory']}\n"
90 |             return memory_text
91 |         except Exception as e:
92 |             return f"Error searching memories: {str(e)}"
93 |
94 |     def get_all_memories(self, user_id: str = "default_user") -> str:
95 |         """Get all memories for a user."""
96 |         try:
97 |             results = self.memory.get_all(user_id=user_id)
98 |             if not results:
99 |                 return "No memories found for this user."
100 |
101 |             memory_text = "All memories for user:\n"
102 |             for i, result in enumerate(results["results"]):
103 |                 memory_text += f"{i}. {result['memory']}\n"
104 |             return memory_text
105 |         except Exception as e:
106 |             return f"Error retrieving memories: {str(e)}"
107 |
108 |     def update_memory(self, memory_id: str, new_content: str) -> str:
109 |         """Update an existing memory."""
110 |         try:
111 |             self.memory.update(memory_id, new_content)
112 |             return f"Updated memory with new content: {new_content}"
113 |         except Exception as e:
114 |             return f"Error updating memory: {str(e)}"
115 |
116 |     def delete_memory(self, memory_id: str) -> str:
117 |         """Delete a specific memory."""
118 |         try:
119 |             self.memory.delete(memory_id)
120 |             return "Memory deleted successfully."
121 |         except Exception as e:
122 |             return f"Error deleting memory: {str(e)}"
123 |
124 | def get_current_time() -> str:
125 |     """Get the current date and time."""
126 |     return datetime.now().strftime("%Y-%m-%d %H:%M:%S")
127 | ```
128 |
129 | ## Step 3: Build the Memory-Enhanced ReAct Agent
130 |
131 | Now let's create our main ReAct agent that can use memory:
132 |
133 | ```python
134 | class MemoryQA(dspy.Signature):
135 |     """
136 |     You're a helpful assistant and have access to memory method.
137 |     Whenever you answer a user's input, remember to store the information in memory
138 |     so that you can use it later.
139 |     """
140 |     user_input: str = dspy.InputField()
141 |     response: str = dspy.OutputField()
142 |
143 | class MemoryReActAgent(dspy.Module):
144 |     """A ReAct agent enhanced with Mem0 memory capabilities."""
145 |
146 |     def __init__(self, memory: Memory):
147 |         super().__init__()
148 |         self.memory_tools = MemoryTools(memory)
149 |
150 |         # Create tools list for ReAct
151 |         self.tools = [
152 |             self.memory_tools.store_memory,
153 |             self.memory_tools.search_memories,
154 |             self.memory_tools.get_all_memories,
155 |             get_current_time,
156 |             self.set_reminder,
157 |             self.get_preferences,
158 |             self.update_preferences,
159 |         ]
160 |
161 |         # Initialize ReAct with our tools
162 |         self.react = dspy.ReAct(
163 |             signature=MemoryQA,
164 |             tools=self.tools,
165 |             max_iters=6
166 |         )
167 |
168 |     def forward(self, user_input: str):
169 |         """Process user input with memory-aware reasoning."""
170 |
171 |         return self.react(user_input=user_input)
172 |
173 |     def set_reminder(self, reminder_text: str, date_time: str = None, user_id: str = "default_user") -> str:
174 |         """Set a reminder for the user."""
175 |         reminder = f"Reminder set for {date_time}: {reminder_text}"
176 |         return self.memory_tools.store_memory(
177 |             f"REMINDER: {reminder}",
178 |             user_id=user_id
179 |         )
180 |
181 |     def get_preferences(self, category: str = "general", user_id: str = "default_user") -> str:
182 |         """Get user preferences for a specific category."""
183 |         query = f"user preferences {category}"
184 |         return self.memory_tools.search_memories(
185 |             query=query,
186 |             user_id=user_id
187 |         )
188 |
189 |     def update_preferences(self, category: str, preference: str, user_id: str = "default_user") -> str:
190 |         """Update user preferences."""
191 |         preference_text = f"User preference for {category}: {preference}"
192 |         return self.memory_tools.store_memory(
193 |             preference_text,
194 |             user_id=user_id
195 |         )
196 | ```
197 |
198 | ## Step 4: Running the Memory-Enhanced Agent
199 |
200 | Let's create a simple interface to interact with our memory-enabled agent:
201 |
202 | ```python
203 | import time
204 | def run_memory_agent_demo():
205 |     """Demonstration of memory-enhanced ReAct agent."""
206 |
207 |     # Configure DSPy
208 |     lm = dspy.LM(model='openai/gpt-4o-mini')
209 |     dspy.configure(lm=lm)
210 |
211 |     # Initialize memory system
212 |     memory = Memory.from_config(config)
213 |
214 |     # Create our agent
215 |     agent = MemoryReActAgent(memory)
216 |
217 |     # Sample conversation demonstrating memory capabilities
218 |     print("🧠 Memory-Enhanced ReAct Agent Demo")
219 |     print("=" * 50)
220 |
221 |     conversations = [
222 |         "Hi, I'm Alice and I love Italian food, especially pasta carbonara.",
223 |         "I'm Alice. I prefer to exercise in the morning around 7 AM.",
224 |         "I'm Alice. What do you remember about my food preferences?",
225 |         "I'm Alice. Set a reminder for me to go grocery shopping tomorrow.",
226 |         "I'm Alice. What are my exercise preferences?",
227 |         "I'm Alice. I also enjoy hiking on weekends.",
228 |         "I'm Alice. What do you know about me so far?"
229 |     ]
230 |
231 |     for i, user_input in enumerate(conversations, 1):
232 |         print(f"\n📝 User: {user_input}")
233 |
234 |         try:
235 |             response = agent(user_input=user_input)
236 |             print(f"🤖 Agent: {response.response}")
237 |             time.sleep(1)
238 |
239 |         except Exception as e:
240 |             print(f"❌ Error: {e}")
241 |
242 | # Run the demonstration
243 | if __name__ == "__main__":
244 |     run_memory_agent_demo()
245 | ```
246 |
247 | ## Expected Output
248 | ```
249 | 🧠 Memory-Enhanced ReAct Agent Demo
250 | ==================================================
251 |
252 | 📝 User: Hi, I'm Alice and I love Italian food, especially pasta carbonara.
253 |
254 | 🤖 Agent: Hi Alice! It's great to meet you! Pasta carbonara is a delicious choice. Do you have a favorite place to get it, or do you enjoy making it at home?
255 |
256 | 📝 User: I'm Alice. I prefer to exercise in the morning around 7 AM.
257 |
258 | 🤖 Agent: Nice to meet you, Alice! I've noted that you prefer to exercise in the morning around 7 AM. If you have any questions or need tips related to your morning workouts, feel free to ask!
259 |
260 | 📝 User: I'm Alice. What do you remember about my food preferences?
261 |
262 | 🤖 Agent: I remember that you love Italian food, and your favorite dish is pasta carbonara!
263 |
264 | 📝 User: I'm Alice. Set a reminder for me to go grocery shopping tomorrow.
265 |
266 | 🤖 Agent: I have set a reminder for you, Alice, to go grocery shopping tomorrow.
267 |
268 | 📝 User: I'm Alice. What are my exercise preferences?
269 |
270 | 🤖 Agent: Your exercise preference is to work out in the morning around 7 AM.
271 |
272 | 📝 User: I'm Alice. I also enjoy hiking on weekends.
273 |
274 | 🤖 Agent: Nice to meet you, Alice! It's great to hear that you enjoy hiking on weekends. If you need any recommendations for trails or tips for your hikes, feel free to ask!
275 |
276 | 📝 User: I'm Alice. What do you know about me so far?
277 |
278 | 🤖 Agent: So far, I know that you enjoy hiking on weekends, prefer to exercise in the morning around 7 AM, and love Italian food, especially pasta carbonara. Additionally, you have a reminder set for grocery shopping on October 7, 2023.
279 | ```
280 |
281 | ## Next Steps
282 |
283 | - **Implement memory persistence** with databases (PostgreSQL, MongoDB)
284 | - **Add memory categorization** and tagging for better organization
285 | - **Create memory expiration policies** for data management
286 | - **Build multi-user memory isolation** for production applications
287 | - **Add memory analytics** and insights
288 | - **Integrate with vector databases** for enhanced semantic search
289 | - **Implement memory compression** for long-term storage efficiency
290 |
291 | This tutorial demonstrates how DSPy's ReAct framework can be enhanced with Mem0's memory capabilities to create intelligent, context-aware agents that can learn and remember information across interactions, making them more useful for real-world applications.
```

multihop_search/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: Multi-Hop Retrieval\n",
8 |     "\n",
9 |     "Let's walk through a quick example of building a `dspy.Module` with multiple sub-modules. We'll do this for the task for multi-hop search.\n",
10 |     "\n",
11 |     "Install the latest DSPy via `pip install -U dspy` and follow along. You also need to run `pip install datasets`."
12 |    ]
13 |   },
14 |   {
15 |    "cell_type": "markdown",
16 |    "metadata": {},
17 |    "source": [
18 |     "<details>\n",
19 |     "<summary>Recommended: Set up MLflow Tracing to understand what's happening under the hood.</summary>\n",
20 |     "\n",
21 |     "### MLflow DSPy Integration\n",
22 |     "\n",
23 |     "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. In this tutorial, you can use MLflow to visualize prompts and optimization progress as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
24 |     "\n",
25 |     "1. Install MLflow\n",
26 |     "\n",
27 |     "```bash\n",
28 |     "%pip install mlflow>=2.20\n",
29 |     "```\n",
30 |     "\n",
31 |     "2. Start MLflow UI in a separate terminal\n",
32 |     "```bash\n",
33 |     "mlflow ui --port 5000\n",
34 |     "```\n",
35 |     "\n",
36 |     "3. Connect the notebook to MLflow\n",
37 |     "```python\n",
38 |     "import mlflow\n",
39 |     "\n",
40 |     "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
41 |     "mlflow.set_experiment(\"DSPy\")\n",
42 |     "```\n",
43 |     "\n",
44 |     "4. Enabling tracing.\n",
45 |     "```python\n",
46 |     "mlflow.dspy.autolog()\n",
47 |     "```\n",
48 |     "\n",
49 |     "![MLflow Trace](./mlflow-tracing-multi-hop.png)\n",
50 |     "\n",
51 |     "\n",
52 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
53 |     "</details>"
54 |    ]
55 |   },
56 |   {
57 |    "cell_type": "markdown",
58 |    "metadata": {},
59 |    "source": [
60 |     "In this tutorial, we'll use a small local LM, Meta's `Llama-3.1-8B-Instruct` which has 8 billion parameters.\n",
61 |     "\n",
62 |     "You might be able to host the 8B model on your laptop with Ollama, on your GPU server with SGLang, or via a provider that hosts it for you like Databricks or Together.\n",
63 |     "\n",
64 |     "In the snippet below, we'll configure this small model as our main LM. We'll also set up a larger LM, i.e. `GPT-4o`, as a teacher that we'll invoke a very small number of times to help teach the small LM. This is technically not necessary; the small model can typically teach itself tasks like this in DSPy. But using a larger teacher will give us some peace of mind, where the initial system or optimizer configuration doesn't matter as much."
65 |    ]
66 |   },
67 |   {
68 |    "cell_type": "code",
69 |    "execution_count": 1,
70 |    "metadata": {},
71 |    "outputs": [],
72 |    "source": [
73 |     "import dspy\n",
74 |     "\n",
75 |     "lm = dspy.LM('<your_provider>/Llama-3.1-8B-Instruct', max_tokens=3000)\n",
76 |     "gpt4o = dspy.LM('openai/gpt-4o', max_tokens=3000)\n",
77 |     "\n",
78 |     "dspy.configure(lm=lm)"
79 |    ]
80 |   },
81 |   {
82 |    "cell_type": "markdown",
83 |    "metadata": {},
84 |    "source": [
85 |     "### Install dependencies and download data\n",
86 |     "\n",
87 |     "To do the retrieval, we'll use the cool BM25S library, as it's pretty lightweight. You can replace this components with whatever you like.\n",
88 |     "\n",
89 |     "```shell\n",
90 |     "> pip install -U bm25s PyStemmer \"jax[cpu]\"\n",
91 |     "```\n",
92 |     "\n",
93 |     "Next, we'll download a snapshot abstracts (i.e., first paragraphs) of all 5,000,000 Wikipedia pages as of 2017. We'll use this as our retrieval corpus.\n",
94 |     "\n",
95 |     "This is 500MB compressed, so the download and decompression may take 2-3 minutes.\n",
96 |     "\n",
97 |     "```python\n",
98 |     "from dspy.utils import download\n",
99 |     "\n",
100 |     "download(\"https://huggingface.co/dspy/cache/resolve/main/wiki.abstracts.2017.tar.gz\")\n",
101 |     "!tar -xzvf wiki.abstracts.2017.tar.gz\n",
102 |     "```"
103 |    ]
104 |   },
105 |   {
106 |    "cell_type": "markdown",
107 |    "metadata": {},
108 |    "source": [
109 |     "Let's now load the corpus."
110 |    ]
111 |   },
112 |   {
113 |    "cell_type": "code",
114 |    "execution_count": 2,
115 |    "metadata": {},
116 |    "outputs": [
117 |     {
118 |      "data": {
119 |       "text/plain": [
120 |        "5233330"
121 |       ]
122 |      },
123 |      "execution_count": 2,
124 |      "metadata": {},
125 |      "output_type": "execute_result"
126 |     }
127 |    ],
128 |    "source": [
129 |     "import ujson\n",
130 |     "corpus = []\n",
131 |     "\n",
132 |     "with open(\"wiki.abstracts.2017.jsonl\") as f:\n",
133 |     "    for line in f:\n",
134 |     "        line = ujson.loads(line)\n",
135 |     "        corpus.append(f\"{line['title']} | {' '.join(line['text'])}\")\n",
136 |     "\n",
137 |     "len(corpus)"
138 |    ]
139 |   },
140 |   {
141 |    "cell_type": "markdown",
142 |    "metadata": {},
143 |    "source": [
144 |     "And then let's index it for BM25 retrieval! This will take 2-3 minutes."
145 |    ]
146 |   },
147 |   {
148 |    "cell_type": "code",
149 |    "execution_count": null,
150 |    "metadata": {},
151 |    "outputs": [],
152 |    "source": [
153 |     "import bm25s\n",
154 |     "import Stemmer\n",
155 |     "\n",
156 |     "stemmer = Stemmer.Stemmer(\"english\")\n",
157 |     "corpus_tokens = bm25s.tokenize(corpus, stopwords=\"en\", stemmer=stemmer)\n",
158 |     "\n",
159 |     "retriever = bm25s.BM25(k1=0.9, b=0.4)\n",
160 |     "retriever.index(corpus_tokens)"
161 |    ]
162 |   },
163 |   {
164 |    "cell_type": "markdown",
165 |    "metadata": {},
166 |    "source": [
167 |     "### Load the HoVer dataset.\n",
168 |     "\n",
169 |     "Let's load a dataset for our task. We'll load examples from the HoVer multi-hop task, where the input is a (really!) complex claim and the output we're seeking is the set of Wikipedia pages that are required to fact-check that claim."
170 |    ]
171 |   },
172 |   {
173 |    "cell_type": "code",
174 |    "execution_count": 4,
175 |    "metadata": {},
176 |    "outputs": [],
177 |    "source": [
178 |     "import random\n",
179 |     "from dspy.datasets import DataLoader\n",
180 |     "\n",
181 |     "kwargs = dict(fields=(\"claim\", \"supporting_facts\", \"hpqa_id\", \"num_hops\"), input_keys=(\"claim\",))\n",
182 |     "hover = DataLoader().from_huggingface(dataset_name=\"hover-nlp/hover\", split=\"train\", trust_remote_code=True, **kwargs)\n",
183 |     "\n",
184 |     "hpqa_ids = set()\n",
185 |     "hover = [\n",
186 |     "    dspy.Example(claim=x.claim, titles=list(set([y[\"key\"] for y in x.supporting_facts]))).with_inputs(\"claim\")\n",
187 |     "    for x in hover\n",
188 |     "    if x[\"num_hops\"] == 3 and x[\"hpqa_id\"] not in hpqa_ids and not hpqa_ids.add(x[\"hpqa_id\"])\n",
189 |     "]\n",
190 |     "\n",
191 |     "random.Random(0).shuffle(hover)\n",
192 |     "trainset, devset, testset = hover[:200], hover[200:500], hover[650:]"
193 |    ]
194 |   },
195 |   {
196 |    "cell_type": "markdown",
197 |    "metadata": {},
198 |    "source": [
199 |     "Let's view an example of this task:"
200 |    ]
201 |   },
202 |   {
203 |    "cell_type": "code",
204 |    "execution_count": 5,
205 |    "metadata": {},
206 |    "outputs": [
207 |     {
208 |      "name": "stdout",
209 |      "output_type": "stream",
210 |      "text": [
211 |       "Claim: This director is known for his work on Miss Potter. The Academy of Motion Picture Arts and Sciences presents the award in which he was nominated for his work in \"Babe\".\n",
212 |       "Pages that must be retrieved: ['Miss Potter', 'Chris Noonan', 'Academy Award for Best Director']\n"
213 |      ]
214 |     }
215 |    ],
216 |    "source": [
217 |     "example = trainset[0]\n",
218 |     "\n",
219 |     "print(\"Claim:\", example.claim)\n",
220 |     "print(\"Pages that must be retrieved:\", example.titles)"
221 |    ]
222 |   },
223 |   {
224 |    "cell_type": "markdown",
225 |    "metadata": {},
226 |    "source": [
227 |     "Now, let's define a function to do the search in Wikipedia. This will use our BM25 index."
228 |    ]
229 |   },
230 |   {
231 |    "cell_type": "code",
232 |    "execution_count": 6,
233 |    "metadata": {},
234 |    "outputs": [],
235 |    "source": [
236 |     "def search(query: str, k: int) -> list[str]:\n",
237 |     "    tokens = bm25s.tokenize(query, stopwords=\"en\", stemmer=stemmer, show_progress=False)\n",
238 |     "    results, scores = retriever.retrieve(tokens, k=k, n_threads=1, show_progress=False)\n",
239 |     "    run = {corpus[doc]: float(score) for doc, score in zip(results[0], scores[0])}\n",
240 |     "    return run"
241 |    ]
242 |   },
243 |   {
244 |    "cell_type": "markdown",
245 |    "metadata": {},
246 |    "source": [
247 |     "Now, let's define the multi-hop program in DSPy. It's going to be super simple: it'll take a `claim` and produce a list `titles: list[str]`.\n",
248 |     "\n",
249 |     "It will do this via two sub-modules: `generate_query` and `append_notes`."
250 |    ]
251 |   },
252 |   {
253 |    "cell_type": "code",
254 |    "execution_count": 7,
255 |    "metadata": {},
256 |    "outputs": [],
257 |    "source": [
258 |     "class Hop(dspy.Module):\n",
259 |     "    def __init__(self, num_docs=10, num_hops=4):\n",
260 |     "        self.num_docs, self.num_hops = num_docs, num_hops\n",
261 |     "        self.generate_query = dspy.ChainOfThought('claim, notes -> query')\n",
262 |     "        self.append_notes = dspy.ChainOfThought('claim, notes, context -> new_notes: list[str], titles: list[str]')\n",
263 |     "\n",
264 |     "    def forward(self, claim: str) -> list[str]:\n",
265 |     "        notes = []\n",
266 |     "        titles = []\n",
267 |     "\n",
268 |     "        for _ in range(self.num_hops):\n",
269 |     "            query = self.generate_query(claim=claim, notes=notes).query\n",
270 |     "            context = search(query, k=self.num_docs)\n",
271 |     "            prediction = self.append_notes(claim=claim, notes=notes, context=context)\n",
272 |     "            notes.extend(prediction.new_notes)\n",
273 |     "            titles.extend(prediction.titles)\n",
274 |     "        \n",
275 |     "        return dspy.Prediction(notes=notes, titles=list(set(titles)))"
276 |    ]
277 |   },
278 |   {
279 |    "cell_type": "markdown",
280 |    "metadata": {},
281 |    "source": [
282 |     "Great. Now let's set up an evaluation metric, `top5_recall`.\n",
283 |     "\n",
284 |     "It will return the fraction of the gold pages (which are always 3) that are retrieved in the top-5 titles returned by the program."
285 |    ]
286 |   },
287 |   {
288 |    "cell_type": "code",
289 |    "execution_count": 8,
290 |    "metadata": {},
291 |    "outputs": [],
292 |    "source": [
293 |     "def top5_recall(example, pred, trace=None):\n",
294 |     "    gold_titles = example.titles\n",
295 |     "    recall = sum(x in pred.titles[:5] for x in gold_titles) / len(gold_titles)\n",
296 |     "\n",
297 |     "    # If we're \"bootstrapping\" for optimization, return True if and only if the recall is perfect.\n",
298 |     "    if trace is not None:\n",
299 |     "        return recall >= 1.0\n",
300 |     "    \n",
301 |     "    # If we're just doing inference, just measure the recall.\n",
302 |     "    return recall\n",
303 |     "\n",
304 |     "evaluate = dspy.Evaluate(devset=devset, metric=top5_recall, num_threads=16, display_progress=True, display_table=5)"
305 |    ]
306 |   },
307 |   {
308 |    "cell_type": "markdown",
309 |    "metadata": {},
310 |    "source": [
311 |     "Let's evaluate our off-the-shelf program!"
312 |    ]
313 |   },
314 |   {
315 |    "cell_type": "code",
316 |    "execution_count": 9,
317 |    "metadata": {},
318 |    "outputs": [
319 |     {
320 |      "name": "stdout",
321 |      "output_type": "stream",
322 |      "text": [
323 |       "Average Metric: 27.67 / 98 (28.2%):  32%|███▏      | 97/300 [00:02<00:04, 49.34it/s]"
324 |      ]
325 |     },
326 |     {
327 |      "name": "stderr",
328 |      "output_type": "stream",
329 |      "text": [
330 |       "2024/12/25 12:18:00 ERROR dspy.utils.parallelizer: Error processing item Example({'claim': \"All That is the show that the co-creator with the host of Vibe and Wild 'N Out had a debut on.\", 'titles': ['Chris Spencer (actor)', 'Nick Cannon', 'Vibe (talk show)']}) (input_keys={'claim'}): Expected dict_keys(['reasoning', 'new_notes', 'titles']) but got dict_keys(['reasoning', 'new_notes']). Set `provide_traceback=True` to see the stack trace.\n"
331 |      ]
332 |     },
333 |     {
334 |      "name": "stdout",
335 |      "output_type": "stream",
336 |      "text": [
337 |       "Average Metric: 59.33 / 186 (31.9%):  62%|██████▏   | 186/300 [00:03<00:02, 51.84it/s]"
338 |      ]
339 |     },
340 |     {
341 |      "name": "stderr",
342 |      "output_type": "stream",
343 |      "text": [
344 |       "2024/12/25 12:18:02 ERROR dspy.utils.parallelizer: Error processing item Example({'claim': 'The song, which Billie Anthony is best known for her Top 10 hit version, topped the UK chart in 1981 in a recording by a platinum-selling British rock and roll singer whose recording and performing career began in the late 1960s.', 'titles': [\"Shakin' Stevens\", 'This Ole House', 'Billie Anthony']}) (input_keys={'claim'}): Expected dict_keys(['reasoning', 'new_notes', 'titles']) but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.\n"
345 |      ]
346 |     },
347 |     {
348 |      "name": "stdout",
349 |      "output_type": "stream",
350 |      "text": [
351 |       "Average Metric: 94.00 / 298 (31.5%): 100%|██████████| 300/300 [00:06<00:00, 48.56it/s]\n"
352 |      ]
353 |     },
354 |     {
355 |      "name": "stderr",
356 |      "output_type": "stream",
357 |      "text": [
358 |       "2024/12/25 12:18:04 INFO dspy.evaluate.evaluate: Average Metric: 93.99999999999993 / 300 (31.3%)\n"
359 |      ]
360 |     },
361 |     {
362 |      "data": {
363 |       "text/html": [
364 |        "<div>\n",
365 |        "<style scoped>\n",
366 |        "    .dataframe tbody tr th:only-of-type {\n",
367 |        "        vertical-align: middle;\n",
368 |        "    }\n",
369 |        "\n",
370 |        "    .dataframe tbody tr th {\n",
371 |        "        vertical-align: top;\n",
372 |        "    }\n",
373 |        "\n",
374 |        "    .dataframe thead th {\n",
375 |        "        text-align: right;\n",
376 |        "    }\n",
377 |        "</style>\n",
378 |        "<table border=\"1\" class=\"dataframe\">\n",
379 |        "  <thead>\n",
380 |        "    <tr style=\"text-align: right;\">\n",
381 |        "      <th></th>\n",
382 |        "      <th>claim</th>\n",
383 |        "      <th>example_titles</th>\n",
384 |        "      <th>notes</th>\n",
385 |        "      <th>pred_titles</th>\n",
386 |        "      <th>top5_recall</th>\n",
387 |        "      <th>titles</th>\n",
388 |        "    </tr>\n",
389 |        "  </thead>\n",
390 |        "  <tbody>\n",
391 |        "    <tr>\n",
392 |        "      <th>0</th>\n",
393 |        "      <td>Nike football team has had a player endorse the football boot Nike...</td>\n",
394 |        "      <td>[Nike Hypervenom, Nike Total 90, Marcus Rashford]</td>\n",
395 |        "      <td>['The Nike Total 90 has been replaced by the Nike Hypervenom.', 'T...</td>\n",
396 |        "      <td>['Nike Mercurial Vapor | The Mercurial Vapor is a football boot ma...</td>\n",
397 |        "      <td>✔️ [0.333]</td>\n",
398 |        "      <td>NaN</td>\n",
399 |        "    </tr>\n",
400 |        "    <tr>\n",
401 |        "      <th>1</th>\n",
402 |        "      <td>Bill Boyd is the chairman of the appliance company that operates t...</td>\n",
403 |        "      <td>[Suncoast Hotel and Casino, Boyd Gaming, Thomas Eje]</td>\n",
404 |        "      <td>['Bill Boyd is not mentioned as the chairman of an appliance compa...</td>\n",
405 |        "      <td>[Suncoast Casino, Thomas Eje, Boyd Gaming Corporation, Bill Boyd, ...</td>\n",
406 |        "      <td>✔️ [0.333]</td>\n",
407 |        "      <td>NaN</td>\n",
408 |        "    </tr>\n",
409 |        "    <tr>\n",
410 |        "      <th>2</th>\n",
411 |        "      <td>The president of South Korea was born 24 January 1953. The group t...</td>\n",
412 |        "      <td>[Presidential Council on Nation Branding, Korea, Moon Jae-in, Euh ...</td>\n",
413 |        "      <td>['The president of South Korea was likely born before 1945', 'Euh ...</td>\n",
414 |        "      <td>['Yi Cheol-seung', 'List of Presidents of South Korea', 'Lifespan ...</td>\n",
415 |        "      <td></td>\n",
416 |        "      <td>NaN</td>\n",
417 |        "    </tr>\n",
418 |        "    <tr>\n",
419 |        "      <th>3</th>\n",
420 |        "      <td>The movie Khan Kluay was released 2 months before the 2009 movie t...</td>\n",
421 |        "      <td>[Fantastic Mr. Fox (film), Jason Schwartzman, Khan Kluay]</td>\n",
422 |        "      <td>['The movie Khan Kluay was released in 2006.', 'The 2009 movie tha...</td>\n",
423 |        "      <td>[Khan Kluay, The Darjeeling Limited]</td>\n",
424 |        "      <td>✔️ [0.333]</td>\n",
425 |        "      <td>NaN</td>\n",
426 |        "    </tr>\n",
427 |        "    <tr>\n",
428 |        "      <th>4</th>\n",
429 |        "      <td>The director of Finding Dory co-directed the film A Bug's Life.</td>\n",
430 |        "      <td>[Andrew Stanton, Finding Dory, A Bug's Life]</td>\n",
431 |        "      <td>['The director of Finding Dory is Andrew Stanton and Angus MacLane...</td>\n",
432 |        "      <td>[Finding Dory, A Bug's Life]</td>\n",
433 |        "      <td>✔️ [0.667]</td>\n",
434 |        "      <td>NaN</td>\n",
435 |        "    </tr>\n",
436 |        "  </tbody>\n",
437 |        "</table>\n",
438 |        "</div>"
439 |       ],
440 |       "text/plain": [
441 |        "                                                                   claim  \\\n",
442 |        "0  Nike football team has had a player endorse the football boot Nike...   \n",
443 |        "1  Bill Boyd is the chairman of the appliance company that operates t...   \n",
444 |        "2  The president of South Korea was born 24 January 1953. The group t...   \n",
445 |        "3  The movie Khan Kluay was released 2 months before the 2009 movie t...   \n",
446 |        "4        The director of Finding Dory co-directed the film A Bug's Life.   \n",
447 |        "\n",
448 |        "                                                          example_titles  \\\n",
449 |        "0                      [Nike Hypervenom, Nike Total 90, Marcus Rashford]   \n",
450 |        "1                   [Suncoast Hotel and Casino, Boyd Gaming, Thomas Eje]   \n",
451 |        "2  [Presidential Council on Nation Branding, Korea, Moon Jae-in, Euh ...   \n",
452 |        "3              [Fantastic Mr. Fox (film), Jason Schwartzman, Khan Kluay]   \n",
453 |        "4                           [Andrew Stanton, Finding Dory, A Bug's Life]   \n",
454 |        "\n",
455 |        "                                                                   notes  \\\n",
456 |        "0  ['The Nike Total 90 has been replaced by the Nike Hypervenom.', 'T...   \n",
457 |        "1  ['Bill Boyd is not mentioned as the chairman of an appliance compa...   \n",
458 |        "2  ['The president of South Korea was likely born before 1945', 'Euh ...   \n",
459 |        "3  ['The movie Khan Kluay was released in 2006.', 'The 2009 movie tha...   \n",
460 |        "4  ['The director of Finding Dory is Andrew Stanton and Angus MacLane...   \n",
461 |        "\n",
462 |        "                                                             pred_titles  \\\n",
463 |        "0  ['Nike Mercurial Vapor | The Mercurial Vapor is a football boot ma...   \n",
464 |        "1  [Suncoast Casino, Thomas Eje, Boyd Gaming Corporation, Bill Boyd, ...   \n",
465 |        "2  ['Yi Cheol-seung', 'List of Presidents of South Korea', 'Lifespan ...   \n",
466 |        "3                                   [Khan Kluay, The Darjeeling Limited]   \n",
467 |        "4                                           [Finding Dory, A Bug's Life]   \n",
468 |        "\n",
469 |        "  top5_recall titles  \n",
470 |        "0  ✔️ [0.333]    NaN  \n",
471 |        "1  ✔️ [0.333]    NaN  \n",
472 |        "2                NaN  \n",
473 |        "3  ✔️ [0.333]    NaN  \n",
474 |        "4  ✔️ [0.667]    NaN  "
475 |       ]
476 |      },
477 |      "metadata": {},
478 |      "output_type": "display_data"
479 |     },
480 |     {
481 |      "data": {
482 |       "text/html": [
483 |        "\n",
484 |        "                <div style='\n",
485 |        "                    text-align: center;\n",
486 |        "                    font-size: 16px;\n",
487 |        "                    font-weight: bold;\n",
488 |        "                    color: #555;\n",
489 |        "                    margin: 10px 0;'>\n",
490 |        "                    ... 295 more rows not displayed ...\n",
491 |        "                </div>\n",
492 |        "                "
493 |       ],
494 |       "text/plain": [
495 |        "<IPython.core.display.HTML object>"
496 |       ]
497 |      },
498 |      "metadata": {},
499 |      "output_type": "display_data"
500 |     },
501 |     {
502 |      "data": {
503 |       "text/plain": [
504 |        "31.33"
505 |       ]
506 |      },
507 |      "execution_count": 10,
508 |      "metadata": {},
509 |      "output_type": "execute_result"
510 |     }
511 |    ],
512 |    "source": [
513 |     "evaluate(Hop())"
514 |    ]
515 |   },
516 |   {
517 |    "cell_type": "markdown",
518 |    "metadata": {},
519 |    "source": [
520 |     "<details>\n",
521 |     "<summary>Tracking Evaluation Results in MLflow Experiment</summary>\n",
522 |     "\n",
523 |     "<br/>\n",
524 |     "\n",
525 |     "To track and visualize the evaluation results over time, you can record the results in MLflow Experiment.\n",
526 |     "\n",
527 |     "\n",
528 |     "```python\n",
529 |     "import mlflow\n",
530 |     "\n",
531 |     "with mlflow.start_run(run_name=\"hop_evaluation\"):\n",
532 |     "    evaluate = dspy.Evaluate(\n",
533 |     "        devset=devset,\n",
534 |     "        metric=top5_recall,\n",
535 |     "        num_threads=16,\n",
536 |     "        display_progress=True,\n",
537 |     "    )\n",
538 |     "\n",
539 |     "    # Evaluate the program as usual\n",
540 |     "    result = evaluate(Hop())\n",
541 |     "\n",
542 |     "    # Log the aggregated score\n",
543 |     "    mlflow.log_metric(\"top5_recall\", result.score)\n",
544 |     "    # Log the detailed evaluation results as a table\n",
545 |     "    mlflow.log_table(\n",
546 |     "        {\n",
547 |     "            \"Claim\": [example.claim for example in eval_set],\n",
548 |     "            \"Expected Titles\": [example.titles for example in eval_set],\n",
549 |     "            \"Predicted Titles\": [output[1] for output in result.results],\n",
550 |     "            \"Top 5 Recall\": [output[2] for output in result.results],\n",
551 |     "        },\n",
552 |     "        artifact_file=\"eval_results.json\",\n",
553 |     "    )\n",
554 |     "```\n",
555 |     "\n",
556 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
557 |     "\n",
558 |     "</details>"
559 |    ]
560 |   },
561 |   {
562 |    "cell_type": "markdown",
563 |    "metadata": {},
564 |    "source": [
565 |     "Let's now optimize the two prompts inside the `Hop()` program jointly to maximize the recall of our program. This may take around 35 minutes and make some $5 worth of calls to GPT-4o to optimize Llama-3.1-8B."
566 |    ]
567 |   },
568 |   {
569 |    "cell_type": "code",
570 |    "execution_count": 10,
571 |    "metadata": {},
572 |    "outputs": [],
573 |    "source": [
574 |     "models = dict(prompt_model=gpt4o, teacher_settings=dict(lm=gpt4o))\n",
575 |     "tp = dspy.MIPROv2(metric=top5_recall, auto=\"medium\", num_threads=16, **models)\n",
576 |     "\n",
577 |     "kwargs = dict(minibatch_size=40, minibatch_full_eval_steps=4)\n",
578 |     "optimized = tp.compile(Hop(), trainset=trainset, max_bootstrapped_demos=4, max_labeled_demos=4, **kwargs)"
579 |    ]
580 |   },
581 |   {
582 |    "cell_type": "markdown",
583 |    "metadata": {},
584 |    "source": [
585 |     "Let's now evaluate again, after optimization."
586 |    ]
587 |   },
588 |   {
589 |    "cell_type": "code",
590 |    "execution_count": 11,
591 |    "metadata": {},
592 |    "outputs": [
593 |     {
594 |      "name": "stdout",
595 |      "output_type": "stream",
596 |      "text": [
597 |       "Average Metric: 38.67 / 64 (60.4%):  21%|██        | 63/300 [00:01<00:06, 38.13it/s]"
598 |      ]
599 |     },
600 |     {
601 |      "name": "stderr",
602 |      "output_type": "stream",
603 |      "text": [
604 |       "2024/12/25 12:18:09 ERROR dspy.utils.parallelizer: Error processing item Example({'claim': 'Eliot Hyman co-founded  Seven Arts Productions in 1957. His co-founder produced the American-American black comedy-drama film directed by Stanley Kubrick.', 'titles': ['Ray Stark', 'Seven Arts Productions', 'Lolita (1962 film)']}) (input_keys={'claim'}): Expected dict_keys(['reasoning', 'query']) but got dict_keys(['reasoning']). Set `provide_traceback=True` to see the stack trace.\n"
605 |      ]
606 |     },
607 |     {
608 |      "name": "stdout",
609 |      "output_type": "stream",
610 |      "text": [
611 |       "Average Metric: 177.33 / 299 (59.3%): 100%|██████████| 300/300 [00:08<00:00, 36.01it/s]"
612 |      ]
613 |     },
614 |     {
615 |      "name": "stderr",
616 |      "output_type": "stream",
617 |      "text": [
618 |       "2024/12/25 12:18:16 INFO dspy.evaluate.evaluate: Average Metric: 177.33333333333334 / 300 (59.1%)\n"
619 |      ]
620 |     },
621 |     {
622 |      "name": "stdout",
623 |      "output_type": "stream",
624 |      "text": [
625 |       "\n"
626 |      ]
627 |     },
628 |     {
629 |      "data": {
630 |       "text/html": [
631 |        "<div>\n",
632 |        "<style scoped>\n",
633 |        "    .dataframe tbody tr th:only-of-type {\n",
634 |        "        vertical-align: middle;\n",
635 |        "    }\n",
636 |        "\n",
637 |        "    .dataframe tbody tr th {\n",
638 |        "        vertical-align: top;\n",
639 |        "    }\n",
640 |        "\n",
641 |        "    .dataframe thead th {\n",
642 |        "        text-align: right;\n",
643 |        "    }\n",
644 |        "</style>\n",
645 |        "<table border=\"1\" class=\"dataframe\">\n",
646 |        "  <thead>\n",
647 |        "    <tr style=\"text-align: right;\">\n",
648 |        "      <th></th>\n",
649 |        "      <th>claim</th>\n",
650 |        "      <th>example_titles</th>\n",
651 |        "      <th>notes</th>\n",
652 |        "      <th>pred_titles</th>\n",
653 |        "      <th>top5_recall</th>\n",
654 |        "      <th>titles</th>\n",
655 |        "    </tr>\n",
656 |        "  </thead>\n",
657 |        "  <tbody>\n",
658 |        "    <tr>\n",
659 |        "      <th>0</th>\n",
660 |        "      <td>Nike football team has had a player endorse the football boot Nike...</td>\n",
661 |        "      <td>[Nike Hypervenom, Nike Total 90, Marcus Rashford]</td>\n",
662 |        "      <td>[]</td>\n",
663 |        "      <td>[Nike Hypervenom, Nike Total 90, Kylian Mbappé, Marcus Rashford]</td>\n",
664 |        "      <td>✔️ [1.000]</td>\n",
665 |        "      <td>NaN</td>\n",
666 |        "    </tr>\n",
667 |        "    <tr>\n",
668 |        "      <th>1</th>\n",
669 |        "      <td>Bill Boyd is the chairman of the appliance company that operates t...</td>\n",
670 |        "      <td>[Suncoast Hotel and Casino, Boyd Gaming, Thomas Eje]</td>\n",
671 |        "      <td>[]</td>\n",
672 |        "      <td>[Bill Boyd, Suncoast Casino, Las Vegas, Thomas Eje]</td>\n",
673 |        "      <td>✔️ [0.333]</td>\n",
674 |        "      <td>NaN</td>\n",
675 |        "    </tr>\n",
676 |        "    <tr>\n",
677 |        "      <th>2</th>\n",
678 |        "      <td>The president of South Korea was born 24 January 1953. The group t...</td>\n",
679 |        "      <td>[Presidential Council on Nation Branding, Korea, Moon Jae-in, Euh ...</td>\n",
680 |        "      <td>['Euh Yoon-Dae is a South Korean professor, financier, and advisor...</td>\n",
681 |        "      <td>[Euh Yoon-Dae, KB Financial Group, Chang Dae-hwan, Maeil Business ...</td>\n",
682 |        "      <td></td>\n",
683 |        "      <td>NaN</td>\n",
684 |        "    </tr>\n",
685 |        "    <tr>\n",
686 |        "      <th>3</th>\n",
687 |        "      <td>The movie Khan Kluay was released 2 months before the 2009 movie t...</td>\n",
688 |        "      <td>[Fantastic Mr. Fox (film), Jason Schwartzman, Khan Kluay]</td>\n",
689 |        "      <td>[\"Jason Schwartzman collaborated with Wes Anderson on the 2009 mov...</td>\n",
690 |        "      <td>[Wes Anderson, Fantastic Mr. Fox, Khan Kluay 2, Jason Schwartzman,...</td>\n",
691 |        "      <td>✔️ [0.667]</td>\n",
692 |        "      <td>NaN</td>\n",
693 |        "    </tr>\n",
694 |        "    <tr>\n",
695 |        "      <th>4</th>\n",
696 |        "      <td>The director of Finding Dory co-directed the film A Bug's Life.</td>\n",
697 |        "      <td>[Andrew Stanton, Finding Dory, A Bug's Life]</td>\n",
698 |        "      <td>[\"Andrew Stanton co-directed A Bug's Life\", \"John Lasseter directe...</td>\n",
699 |        "      <td>[John Lasseter, Andrew Stanton, Finding Dory, A Bug's Life]</td>\n",
700 |        "      <td>✔️ [1.000]</td>\n",
701 |        "      <td>NaN</td>\n",
702 |        "    </tr>\n",
703 |        "  </tbody>\n",
704 |        "</table>\n",
705 |        "</div>"
706 |       ],
707 |       "text/plain": [
708 |        "                                                                   claim  \\\n",
709 |        "0  Nike football team has had a player endorse the football boot Nike...   \n",
710 |        "1  Bill Boyd is the chairman of the appliance company that operates t...   \n",
711 |        "2  The president of South Korea was born 24 January 1953. The group t...   \n",
712 |        "3  The movie Khan Kluay was released 2 months before the 2009 movie t...   \n",
713 |        "4        The director of Finding Dory co-directed the film A Bug's Life.   \n",
714 |        "\n",
715 |        "                                                          example_titles  \\\n",
716 |        "0                      [Nike Hypervenom, Nike Total 90, Marcus Rashford]   \n",
717 |        "1                   [Suncoast Hotel and Casino, Boyd Gaming, Thomas Eje]   \n",
718 |        "2  [Presidential Council on Nation Branding, Korea, Moon Jae-in, Euh ...   \n",
719 |        "3              [Fantastic Mr. Fox (film), Jason Schwartzman, Khan Kluay]   \n",
720 |        "4                           [Andrew Stanton, Finding Dory, A Bug's Life]   \n",
721 |        "\n",
722 |        "                                                                   notes  \\\n",
723 |        "0                                                                     []   \n",
724 |        "1                                                                     []   \n",
725 |        "2  ['Euh Yoon-Dae is a South Korean professor, financier, and advisor...   \n",
726 |        "3  [\"Jason Schwartzman collaborated with Wes Anderson on the 2009 mov...   \n",
727 |        "4  [\"Andrew Stanton co-directed A Bug's Life\", \"John Lasseter directe...   \n",
728 |        "\n",
729 |        "                                                             pred_titles  \\\n",
730 |        "0       [Nike Hypervenom, Nike Total 90, Kylian Mbappé, Marcus Rashford]   \n",
731 |        "1                    [Bill Boyd, Suncoast Casino, Las Vegas, Thomas Eje]   \n",
732 |        "2  [Euh Yoon-Dae, KB Financial Group, Chang Dae-hwan, Maeil Business ...   \n",
733 |        "3  [Wes Anderson, Fantastic Mr. Fox, Khan Kluay 2, Jason Schwartzman,...   \n",
734 |        "4            [John Lasseter, Andrew Stanton, Finding Dory, A Bug's Life]   \n",
735 |        "\n",
736 |        "  top5_recall titles  \n",
737 |        "0  ✔️ [1.000]    NaN  \n",
738 |        "1  ✔️ [0.333]    NaN  \n",
739 |        "2                NaN  \n",
740 |        "3  ✔️ [0.667]    NaN  \n",
741 |        "4  ✔️ [1.000]    NaN  "
742 |       ]
743 |      },
744 |      "metadata": {},
745 |      "output_type": "display_data"
746 |     },
747 |     {
748 |      "data": {
749 |       "text/html": [
750 |        "\n",
751 |        "                <div style='\n",
752 |        "                    text-align: center;\n",
753 |        "                    font-size: 16px;\n",
754 |        "                    font-weight: bold;\n",
755 |        "                    color: #555;\n",
756 |        "                    margin: 10px 0;'>\n",
757 |        "                    ... 295 more rows not displayed ...\n",
758 |        "                </div>\n",
759 |        "                "
760 |       ],
761 |       "text/plain": [
762 |        "<IPython.core.display.HTML object>"
763 |       ]
764 |      },
765 |      "metadata": {},
766 |      "output_type": "display_data"
767 |     },
768 |     {
769 |      "data": {
770 |       "text/plain": [
771 |        "59.11"
772 |       ]
773 |      },
774 |      "execution_count": 12,
775 |      "metadata": {},
776 |      "output_type": "execute_result"
777 |     }
778 |    ],
779 |    "source": [
780 |     "evaluate(optimized)"
781 |    ]
782 |   },
783 |   {
784 |    "cell_type": "markdown",
785 |    "metadata": {},
786 |    "source": [
787 |     "Awesome. It looks like the system improved drastically from around 30% recall to a little below 60% recall. That was a pretty straightforward approach, but DSPy gives you many tools to continue iterating on this from here.\n",
788 |     "\n",
789 |     "Next, let's inspect the optimized prompts to understand what it has learned. We'll run one query and then inspect the last two prompts, which will show us the prompts used for both sub-modules, in the later iteration inside the `Hop()` program. (Alternatively, if you enabled MLflow Tracing following the instructions above, you can see all steps done by the agent including LLM calls, prompts, tool execution, in a rich tree-view.)"
790 |    ]
791 |   },
792 |   {
793 |    "cell_type": "code",
794 |    "execution_count": 13,
795 |    "metadata": {},
796 |    "outputs": [
797 |     {
798 |      "data": {
799 |       "text/plain": [
800 |        "['Up Against It', 'Bernard-Marie Koltès', 'The Beatles', 'Joe Orton']"
801 |       ]
802 |      },
803 |      "execution_count": 14,
804 |      "metadata": {},
805 |      "output_type": "execute_result"
806 |     }
807 |    ],
808 |    "source": [
809 |     "optimized(claim=\"The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\").titles"
810 |    ]
811 |   },
812 |   {
813 |    "cell_type": "code",
814 |    "execution_count": 15,
815 |    "metadata": {},
816 |    "outputs": [
817 |     {
818 |      "name": "stdout",
819 |      "output_type": "stream",
820 |      "text": [
821 |       "\n",
822 |       "\n",
823 |       "\n",
824 |       "\n",
825 |       "\u001b[34m[2024-12-25T12:18:16.177899]\u001b[0m\n",
826 |       "\n",
827 |       "\u001b[31mSystem message:\u001b[0m\n",
828 |       "\n",
829 |       "Your input fields are:\n",
830 |       "1. `claim` (str)\n",
831 |       "2. `notes` (str)\n",
832 |       "\n",
833 |       "Your output fields are:\n",
834 |       "1. `reasoning` (str)\n",
835 |       "2. `query` (str)\n",
836 |       "\n",
837 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
838 |       "\n",
839 |       "[[ ## claim ## ]]\n",
840 |       "{claim}\n",
841 |       "\n",
842 |       "[[ ## notes ## ]]\n",
843 |       "{notes}\n",
844 |       "\n",
845 |       "[[ ## reasoning ## ]]\n",
846 |       "{reasoning}\n",
847 |       "\n",
848 |       "[[ ## query ## ]]\n",
849 |       "{query}\n",
850 |       "\n",
851 |       "[[ ## completed ## ]]\n",
852 |       "\n",
853 |       "In adhering to this structure, your objective is: \n",
854 |       "        Given a claim and a set of notes, generate a query that can be used to gather additional evidence or context to support or refute the claim. Think step by step to ensure the query is specific and relevant to the information provided in the notes.\n",
855 |       "\n",
856 |       "\n",
857 |       "\u001b[31mUser message:\u001b[0m\n",
858 |       "\n",
859 |       "[[ ## claim ## ]]\n",
860 |       "Danyang, Jiangusu and this city are both cities in China. This city was the birthplace of Chen Xiuke.\n",
861 |       "\n",
862 |       "[[ ## notes ## ]]\n",
863 |       "[1] «Chen Xiuke was born in Dongfang, Hainan.»\n",
864 |       "[2] «Danyang is a city in Jiangsu province, China.»\n",
865 |       "[3] «Chen Xiuke was born in Dongfang, Hainan.»\n",
866 |       "[4] «Danyang is a city in Jiangsu province, China.»\n",
867 |       "[5] «Dongfang is a city in Hainan province, China.»\n",
868 |       "[6] «Chen Xiuke was born in Dongfang, Hainan.»\n",
869 |       "[7] «Danyang is a city in Jiangsu province, China.»\n",
870 |       "[8] «Dongfang is a city in Hainan province, China.»\n",
871 |       "[9] «Chen Xiuke was born in Dongfang, Hainan.»\n",
872 |       "[10] «Danyang is a city in Jiangsu province, China.»\n",
873 |       "[11] «Dongfang is a city in Hainan province, China.»\n",
874 |       "\n",
875 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## query ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
876 |       "\n",
877 |       "\n",
878 |       "\u001b[31mAssistant message:\u001b[0m\n",
879 |       "\n",
880 |       "[[ ## reasoning ## ]]\n",
881 |       "The claim states that Danyang, Jiangsu, and another city are both cities in China, and that this other city was the birthplace of Chen Xiuke. According to the notes, Chen Xiuke was born in Dongfang, Hainan. Therefore, the city referred to in the claim as \"this city\" is Dongfang, which is indeed a city in Hainan province, China. The claim is consistent with the information provided in the notes.\n",
882 |       "\n",
883 |       "[[ ## query ## ]]\n",
884 |       "What is the birthplace of Chen Xiuke?\n",
885 |       "\n",
886 |       "[[ ## completed ## ]]\n",
887 |       "\n",
888 |       "\n",
889 |       "\u001b[31mUser message:\u001b[0m\n",
890 |       "\n",
891 |       "[[ ## claim ## ]]\n",
892 |       "The star of Nothing to Report and Gary Barlow have a profession in common.\n",
893 |       "\n",
894 |       "[[ ## notes ## ]]\n",
895 |       "[1] «Chris Jericho is a musician and professional wrestler.»\n",
896 |       "[2] «Gary Barlow is a singer and songwriter, known for being a member of Take That.»\n",
897 |       "[3] «Chris Jericho is a musician and professional wrestler.»\n",
898 |       "[4] «Gary Barlow is a singer and songwriter, known for being a member of Take That.»\n",
899 |       "[5] «Chris Jericho stars in 'Nothing to Report'.»\n",
900 |       "[6] «Chris Jericho is a musician and professional wrestler.»\n",
901 |       "[7] «Gary Barlow is a singer and songwriter, known for being a member of Take That.»\n",
902 |       "[8] «Chris Jericho stars in 'Nothing to Report'.»\n",
903 |       "[9] «Chris Jericho is a musician and professional wrestler.»\n",
904 |       "[10] «Gary Barlow is a singer and songwriter, known for being a member of Take That.»\n",
905 |       "[11] «Chris Jericho stars in 'Nothing to Report'.»\n",
906 |       "\n",
907 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## query ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
908 |       "\n",
909 |       "\n",
910 |       "\u001b[31mAssistant message:\u001b[0m\n",
911 |       "\n",
912 |       "[[ ## reasoning ## ]]\n",
913 |       "The claim suggests that the star of \"Nothing to Report\" and Gary Barlow share a profession. From the notes, we know that Chris Jericho stars in \"Nothing to Report\" and is a musician and professional wrestler. Gary Barlow is a singer and songwriter. The common profession between Chris Jericho and Gary Barlow is that they are both musicians.\n",
914 |       "\n",
915 |       "[[ ## query ## ]]\n",
916 |       "What is the profession that Chris Jericho and Gary Barlow have in common?\n",
917 |       "\n",
918 |       "[[ ## completed ## ]]\n",
919 |       "\n",
920 |       "\n",
921 |       "\u001b[31mUser message:\u001b[0m\n",
922 |       "\n",
923 |       "[[ ## claim ## ]]\n",
924 |       "The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\n",
925 |       "\n",
926 |       "[[ ## notes ## ]]\n",
927 |       "N/A\n",
928 |       "\n",
929 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## query ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
930 |       "\n",
931 |       "\n",
932 |       "\u001b[31mResponse:\u001b[0m\n",
933 |       "\n",
934 |       "\u001b[32m[[ ## reasoning ## ]]\n",
935 |       "The claim states that the author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights. However, there is no information in the notes to support or refute this claim. The notes are empty, which means we cannot verify the author of the script or Bernard-Marie Koltès' profession.\n",
936 |       "\n",
937 |       "[[ ## query ## ]]\n",
938 |       "Who is the author of the 1960s unproduced script written for The Beatles, Up Against It?\n",
939 |       "\n",
940 |       "[[ ## completed ## ]]\u001b[0m\n",
941 |       "\n",
942 |       "\n",
943 |       "\n",
944 |       "\n",
945 |       "\n",
946 |       "\u001b[34m[2024-12-25T12:18:16.191896]\u001b[0m\n",
947 |       "\n",
948 |       "\u001b[31mSystem message:\u001b[0m\n",
949 |       "\n",
950 |       "Your input fields are:\n",
951 |       "1. `claim` (str)\n",
952 |       "2. `notes` (str)\n",
953 |       "3. `context` (str)\n",
954 |       "\n",
955 |       "Your output fields are:\n",
956 |       "1. `reasoning` (str)\n",
957 |       "2. `new_notes` (list[str])\n",
958 |       "3. `titles` (list[str])\n",
959 |       "\n",
960 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
961 |       "\n",
962 |       "[[ ## claim ## ]]\n",
963 |       "{claim}\n",
964 |       "\n",
965 |       "[[ ## notes ## ]]\n",
966 |       "{notes}\n",
967 |       "\n",
968 |       "[[ ## context ## ]]\n",
969 |       "{context}\n",
970 |       "\n",
971 |       "[[ ## reasoning ## ]]\n",
972 |       "{reasoning}\n",
973 |       "\n",
974 |       "[[ ## new_notes ## ]]\n",
975 |       "{new_notes}        # note: the value you produce must be pareseable according to the following JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
976 |       "\n",
977 |       "[[ ## titles ## ]]\n",
978 |       "{titles}        # note: the value you produce must be pareseable according to the following JSON schema: {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
979 |       "\n",
980 |       "[[ ## completed ## ]]\n",
981 |       "\n",
982 |       "In adhering to this structure, your objective is: \n",
983 |       "        Analyze the provided `claim`, `notes`, and `context` to generate `new_notes` that further support or refute the claim, and extract relevant `titles` that represent key topics or entities from the context.\n",
984 |       "\n",
985 |       "\n",
986 |       "\u001b[31mUser message:\u001b[0m\n",
987 |       "\n",
988 |       "This is an example of the task, though some input or output fields are not supplied.\n",
989 |       "\n",
990 |       "[[ ## claim ## ]]\n",
991 |       "The figure who currently holds the role Michael Noonan held from 2001 to 2002, was the Minister for Social Protection from 2016 until 2017.\n",
992 |       "\n",
993 |       "[[ ## notes ## ]]\n",
994 |       "Not supplied for this particular example.\n",
995 |       "\n",
996 |       "[[ ## context ## ]]\n",
997 |       "Not supplied for this particular example.\n",
998 |       "\n",
999 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## new_notes ## ]]` (must be formatted as a valid Python list[str]), then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1000 |       "\n",
1001 |       "\n",
1002 |       "\u001b[31mAssistant message:\u001b[0m\n",
1003 |       "\n",
1004 |       "[[ ## reasoning ## ]]\n",
1005 |       "Not supplied for this particular example.\n",
1006 |       "\n",
1007 |       "[[ ## new_notes ## ]]\n",
1008 |       "Not supplied for this particular example.\n",
1009 |       "\n",
1010 |       "[[ ## titles ## ]]\n",
1011 |       "[\"Michael Noonan\", \"Leader of Fine Gael\", \"Leo Varadkar\"]\n",
1012 |       "\n",
1013 |       "[[ ## completed ## ]]\n",
1014 |       "\n",
1015 |       "\n",
1016 |       "\u001b[31mUser message:\u001b[0m\n",
1017 |       "\n",
1018 |       "This is an example of the task, though some input or output fields are not supplied.\n",
1019 |       "\n",
1020 |       "[[ ## claim ## ]]\n",
1021 |       "The type of area Wiliwili are typically found in have a dominant tree species of Acacia koa. They are of the pea family.\n",
1022 |       "\n",
1023 |       "[[ ## notes ## ]]\n",
1024 |       "Not supplied for this particular example.\n",
1025 |       "\n",
1026 |       "[[ ## context ## ]]\n",
1027 |       "Not supplied for this particular example.\n",
1028 |       "\n",
1029 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## new_notes ## ]]` (must be formatted as a valid Python list[str]), then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1030 |       "\n",
1031 |       "\n",
1032 |       "\u001b[31mAssistant message:\u001b[0m\n",
1033 |       "\n",
1034 |       "[[ ## reasoning ## ]]\n",
1035 |       "Not supplied for this particular example.\n",
1036 |       "\n",
1037 |       "[[ ## new_notes ## ]]\n",
1038 |       "Not supplied for this particular example.\n",
1039 |       "\n",
1040 |       "[[ ## titles ## ]]\n",
1041 |       "[\"Acacia koa\", \"Wiliwili\", \"Hawaiian tropical dry forests\"]\n",
1042 |       "\n",
1043 |       "[[ ## completed ## ]]\n",
1044 |       "\n",
1045 |       "\n",
1046 |       "\u001b[31mUser message:\u001b[0m\n",
1047 |       "\n",
1048 |       "[[ ## claim ## ]]\n",
1049 |       "The father of Zak Ové and A. Edward Sutherland are not both photographers.\n",
1050 |       "\n",
1051 |       "[[ ## notes ## ]]\n",
1052 |       "[1] «Horace Ové is a photographer, filmmaker, and writer.»\n",
1053 |       "[2] «A. Edward Sutherland is a film director, not a photographer.»\n",
1054 |       "[3] «Horace Ové is a photographer, filmmaker, and writer.»\n",
1055 |       "[4] «A. Edward Sutherland is a film director, not a photographer.»\n",
1056 |       "[5] «Horace Ové is a photographer, filmmaker, and writer.»\n",
1057 |       "[6] «A. Edward Sutherland is a film director, not a photographer.»\n",
1058 |       "[7] «Horace Ové is a photographer, filmmaker, and writer.»\n",
1059 |       "[8] «A. Edward Sutherland is a film director, not a photographer.»\n",
1060 |       "\n",
1061 |       "[[ ## context ## ]]\n",
1062 |       "{\"Horace Ové | Horace Ové, CBE (born 1939), is a British filmmaker, photographer, painter and writer, one of the leading black independent film-makers to emerge in Britain since the post-war period.  Ové holds the \\\"Guinness World Record\\\" for being the first black British film-maker to direct a feature-length film, \\\"Pressure\\\" (1975).  In its retrospective history, \\\"100 Years of Cinema\\\", the British Film Institute (BFI) declared: \\\"Horace Ové is undoubtedly a pioneer in Black British history and his work provides a perspective on the Black experience in Britain.\\\"\": 15.836545944213867, \"Zak Ové | Zak Ové (born 1966) is a British visual artist who works between sculpture, film and photography, living in London, UK, and Trinidad.  His themes reflect \\\"his documentation of and anthropological interest in diasporic and African history, specifically that which is explored through Trinidadian carnival.\\\"  In work that is \\\"filtered through his own personal and cultural upbringing, with a black Trinidadian father and white Irish mother\\\", he has exhibited widely in Europe, the United States and Africa, participating in international museum shows in London, Dakar, Paris, Dubai, Prague, Berlin, Johannesburg, Bamako and New York City.  His father is the filmmaker Horace Ové and his sister is the actress Indra Ové.\": 13.145259857177734, \"Playing Away | Playing Away is a 1987 TV comedy film directed by Horace Ové, from a screenplay by Caryl Phillips.  In the story, an English cricket team, fictitiously named \\\"Sneddington\\\" (based in Lavenham, Suffolk), invites a team of West Indian heritage based in Brixton (South London) to play a charity game in support of their \\\"Third World Week.\\\"  According to Screenonline, \\\"The gentle comedy of manners and unexpected reversal of white and black stereotypes in \\\"Playing Away\\\" contrasts sharply with the stylistic experimentation and the militant denunciations of racial prejudice in director Horace Ové's earlier feature, \\\"Pressure\\\" (1975).\\\" \\\" New York Times\\\" reviewer Vincent Canby called it \\\"witty and wise without being seriously disturbing for a minute\\\".\": 12.445182800292969, \"Pressure (film) | Pressure is a 1976 British drama film and the first feature-length fiction film directed by a Black film-maker in Britain.  Directed by Horace Ové, and co-written by him with Samuel Selvon, \\\"Pressure\\\" is a powerful portrait of inter-generational tensions between first- and second-generation West Indian migrants in London's Notting Hill area.  According to Julia Toppin,\": 10.526924133300781, \"What a Night! (1928 film) | What a Night!  (1928) is an American silent film directed by A. Edward Sutherland.  The romantic comedy was written by Louise Long, from a story by Lloyd Corrigan and Grover Jones.  The film stars Bebe Daniels, Neil Hamilton, and William Austin.\": 10.453304290771484, \"The Orchid House (TV serial) | The Orchid House is a four-part television serial that first aired on British television's Channel 4 from 21 February to 14 March 1991, directed by Horace Ové.  Its cast featured Diana Quick, Madge Sinclair, Nigel Terry, Elizabeth Hurley, Kate Buffery and Frances Barber, and was based on Phyllis Shand Allfrey's only novel of the same name.\": 10.413471221923828, \"Indra Ové | Indra Ové (born 1968) is a British movie and stage actress.\": 10.15088176727295, \"Henry Sutherland Edwards | Henry Sutherland Edwards (1828–1906) was a British journalist.\": 9.868606567382812, \"Burning an Illusion | Burning an Illusion is a 1981 British film written and directed by Menelik Shabazz, about a young British-born black woman's love life, mostly shot in London's Notting Hill and Ladbroke Grove communities.  It was only the second British feature to have been made by a black director, following Horace Ové’s 1975 \\\"Pressure\\\", and is described by Stephen Bourne as \\\"the first British film to give a black woman a voice of any kind.\\\"  Imruh Bakari worked with Shabazz and co-founded Kumba productions with him.\": 9.634703636169434, \"Horace Hall Edwards | Horace Hall Edwards (August 21, 1902 – January 27, 1987) was an American politician, who was mayor of Richmond, Virginia, and a candidate for governor in 1949.\": 9.451831817626953}\n",
1063 |       "\n",
1064 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## new_notes ## ]]` (must be formatted as a valid Python list[str]), then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1065 |       "\n",
1066 |       "\n",
1067 |       "\u001b[31mAssistant message:\u001b[0m\n",
1068 |       "\n",
1069 |       "[[ ## reasoning ## ]]\n",
1070 |       "The claim states that the father of Zak Ové and A. Edward Sutherland are not both photographers. From the context, we know that Zak Ové's father is Horace Ové, who is indeed a photographer among other professions. However, A. Edward Sutherland is not mentioned as a photographer in the context; he is known as a film director. Therefore, the claim is correct because Horace Ové is a photographer, but A. Edward Sutherland is not.\n",
1071 |       "\n",
1072 |       "[[ ## new_notes ## ]]\n",
1073 |       "[\"Horace Ové is a photographer, filmmaker, and writer.\", \"A. Edward Sutherland is a film director, not a photographer.\"]\n",
1074 |       "\n",
1075 |       "[[ ## titles ## ]]\n",
1076 |       "[\"Horace Ové\", \"A. Edward Sutherland\", \"Zak Ové\"]\n",
1077 |       "\n",
1078 |       "[[ ## completed ## ]]\n",
1079 |       "\n",
1080 |       "\n",
1081 |       "\u001b[31mUser message:\u001b[0m\n",
1082 |       "\n",
1083 |       "[[ ## claim ## ]]\n",
1084 |       "The summer 2016 romantic drama \"Me Before You\" is directed by Thea Sharrock. The star of the film The Lost Future (who also appears in The Hunger Games) stars as the character Will Traynor.\n",
1085 |       "\n",
1086 |       "[[ ## notes ## ]]\n",
1087 |       "[1] «Sam Claflin stars as Will Traynor in 'Me Before You'.»\n",
1088 |       "[2] «Sam Claflin is known for his role as Finnick Odair in 'The Hunger Games'.»\n",
1089 |       "[3] «Thea Sharrock directed 'Me Before You'.»\n",
1090 |       "[4] «Sam Claflin stars as Will Traynor in 'Me Before You'.»\n",
1091 |       "[5] «Sam Claflin is known for his role as Finnick Odair in 'The Hunger Games'.»\n",
1092 |       "[6] «Thea Sharrock directed 'Me Before You'.»\n",
1093 |       "[7] «Sam Claflin starred in 'The Lost Future'.»\n",
1094 |       "[8] «Sam Claflin stars as Will Traynor in 'Me Before You'.»\n",
1095 |       "[9] «Sam Claflin is known for his role as Finnick Odair in 'The Hunger Games'.»\n",
1096 |       "[10] «Thea Sharrock directed 'Me Before You'.»\n",
1097 |       "[11] «Sam Claflin starred in 'The Lost Future'.»\n",
1098 |       "[12] «Sam Claflin stars as Will Traynor in 'Me Before You'.»\n",
1099 |       "[13] «Sam Claflin is known for his role as Finnick Odair in 'The Hunger Games'.»\n",
1100 |       "[14] «Thea Sharrock directed 'Me Before You'.»\n",
1101 |       "[15] «Sam Claflin starred in 'The Lost Future'.»\n",
1102 |       "\n",
1103 |       "[[ ## context ## ]]\n",
1104 |       "{\"Sam Claflin | Samuel George Claflin (born 27 June 1986) is an English actor.  He is known for portraying Finnick Odair in \\\"The Hunger Games\\\" film series, Philip Swift in \\\"\\\", and Will Traynor in \\\"Me Before You\\\".\": 19.94539451599121, \"Me Before You (film) | Me Before You is a 2016 romantic drama film directed by Thea Sharrock in her directorial debut and adapted by English author Jojo Moyes from her 2012 novel of the same name.  The film stars Emilia Clarke, Sam Claflin, Steve Peacocke, Jenna Coleman, Charles Dance, Matthew Lewis, Janet McTeer, Vanessa Kirby and Joanna Lumley.\": 18.48834228515625, \"Look What You Did to Me | Look What You Did to Me is the debut studio album by American rapper and singer Z-Ro.  It was released on June 16, 1998, by this independently distributed label Fisherboy Records.  The album is entirely produced by Z-Ro alongside Rakish Jacob (aka Roc), while the guest appearances was from T.A.Z., Bam, Trae, The Fakkulty, Chris Ward and Al-D.\": 14.100790977478027, \"I Still Know What You Did Last Summer | I Still Know What You Did Last Summer is a 1998 American slasher film and a sequel to the 1997 film \\\"I Know What You Did Last Summer\\\".  Directed by Danny Cannon, the film was written by Trey Callaway, and features characters originally created in Lois Duncan's 1973 novel \\\"I Know What You Did Last Summer\\\".  Jennifer Love Hewitt, Freddie Prinze, Jr. and Muse Watson reprise their roles, with Brandy, Mekhi Phifer, Jennifer Esposito, and Matthew Settle joining the cast.  \\\"I Still Know What You Did Last Summer\\\" continues after the events of the first film.\": 13.990736961364746, \"Tell Me What You Dream | \\\"Tell Me What You Dream\\\" is a song written by Timothy B. Schmit, Josh Leo and Vince Melamed and performed by country group Restless Heart along with saxophonist Warren Hill.  The single was the group's only number one on the adult contemporary chart and despite previous country chart success, the song did not make the country top 40.  \\\"Tell Me What You Dream\\\" spent two weeks at number one and peaked at number forty-three on the \\\"Billboard\\\" Hot 100.\": 13.774335861206055, \"Geraldine Jones (character) | Geraldine Jones was a fictional African American character, the most famous recurring persona of comedian Flip Wilson.  Geraldine was played as a sassy liberated Southern woman who was coarsely flirty yet faithful to her (unseen) boyfriend \\\"Killer\\\".  Poorly educated, she was nevertheless confident; she did not change her behavior to suit anyone.  Several of Geraldine's sayings entered U.S. popular culture as catchphrases, especially \\\"When you're hot, you're hot; when you're not, you're not,\\\" \\\"The Devil made me do it,\\\" and \\\"What you see is what you get! \\\"\": 13.149161338806152, \"When Did You Stop Loving Me, When Did I Stop Loving You | When Did You Stop Loving Me, When Did I Stop Loving You\": 12.946025848388672, \"Pajama Sam 3: You Are What You Eat from Your Head to Your Feet | Pajama Sam 3: You Are What You Eat from Your Head to Your Feet\": 12.687528610229492, \"Sam Quartin | Sam Quartin is a musician, producer and actress best known for role as June Glass, starring alongside Marilyn Manson in the American movie Let Me Make You a Martyr\\\"(2017), also for \\\"By the Rivers of Babylon)\\\" and \\\"Aimy in a Cage\\\".\": 12.639335632324219, \"Why You Wanna Treat Me So Bad? | \\\"Why You Wanna Treat Me So Bad?\\\"  is the US follow-up single to Prince's first big hit, \\\"I Wanna Be Your Lover\\\".  It is also Prince's first rock and roll-inspired single release.  It did not make the top 40 of the Billboard Hot 100 charts, although it did reach #13 on the R&B Singles charts.  The lyrics are self-explanatory from the title, and deal with a cruel lover.  The song prominently features guitar and bass, with the keyboard featured in a less prominent role.  A highlight of the song is a soaring guitar solo at the end, played by Prince himself.\": 12.574298858642578}\n",
1105 |       "\n",
1106 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## new_notes ## ]]` (must be formatted as a valid Python list[str]), then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1107 |       "\n",
1108 |       "\n",
1109 |       "\u001b[31mAssistant message:\u001b[0m\n",
1110 |       "\n",
1111 |       "[[ ## reasoning ## ]]\n",
1112 |       "The claim states that the film \"Me Before You\" is directed by Thea Sharrock and that the actor who stars as Will Traynor also appeared in \"The Lost Future\" and \"The Hunger Games\". According to the notes, Sam Claflin stars as Will Traynor in \"Me Before You\" and is known for his role as Finnick Odair in \"The Hunger Games\". Additionally, Sam Claflin starred in \"The Lost Future\". The context confirms that \"Me Before You\" is directed by Thea Sharrock and that Sam Claflin plays Will Traynor. Therefore, the claim is supported by the provided notes and context.\n",
1113 |       "\n",
1114 |       "[[ ## new_notes ## ]]\n",
1115 |       "[\"Sam Claflin stars as Will Traynor in 'Me Before You'.\", \"Sam Claflin is known for his role as Finnick Odair in 'The Hunger Games'.\", \"Thea Sharrock directed 'Me Before You'.\", \"Sam Claflin starred in 'The Lost Future'.\"]\n",
1116 |       "\n",
1117 |       "[[ ## titles ## ]]\n",
1118 |       "[\"Me Before You (film)\", \"Sam Claflin\", \"Thea Sharrock\", \"The Lost Future\", \"The Hunger Games\"]\n",
1119 |       "\n",
1120 |       "[[ ## completed ## ]]\n",
1121 |       "\n",
1122 |       "\n",
1123 |       "\u001b[31mUser message:\u001b[0m\n",
1124 |       "\n",
1125 |       "[[ ## claim ## ]]\n",
1126 |       "The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\n",
1127 |       "\n",
1128 |       "[[ ## notes ## ]]\n",
1129 |       "N/A\n",
1130 |       "\n",
1131 |       "[[ ## context ## ]]\n",
1132 |       "{\"Up Against It | Up Against It is an unproduced script by Joe Orton, written in 1967 for The Beatles at the height of their fame.\": 23.741416931152344, \"The Alien (unproduced film) | The Alien was an unproduced Indian-American science fiction film in development in the late 1960s which was eventually cancelled.  It was to be directed by celebrated Indian filmmaker Satyajit Ray and co-produced by Columbia Pictures.  The script was written by Ray in 1967, loosely based on Bankubabur Bandhu (\\\"Banku Babu's Friend\\\" or \\\"Mr. Banku's Friend\\\"), a Bengali science fiction story he had written in 1962 for \\\"Sandesh\\\", the Ray family magazine, which gained popularity among Bengalis in the early 1960s.  \\\"Bankubabur Bandhu\\\" was eventually adapted into a television film by Satyajit Ray's son Sandip Ray, and a play by the theatre group Swapnasandhani Kaushik Sen, in 2006.\": 14.683004379272461, \"Marsha Albert | Marsha Albert (born 1948) is credited with being the person who jump-started the early 1960s phenomena known as Beatlemania in the United States when as a 15-year-old girl, on 17 December 1963, she introduced for the first time on American radio a song written and recorded by The Beatles titled I Want to Hold Your Hand (the Beatles' best-selling single worldwide), and that Beatles historian and author Bruce Spizer noted, in 2004, by his stating \\\"Marsha Albert's actions forced a major record company to push up the release date of a debut single from an unknown band during the holiday season, a time when record companies traditionally released no new product.\\\"\": 13.236483573913574, \"Up Against It! (Todd Rundgren album) | Up Against It!  is a 1997 album by Todd Rundgren, essentially consisting of Rundgren's song demos for the Off Broadway show that were Written and Recorded by Todd from 1986-88.  The project was inspired by the never-produced Up Against It which was a play originally written by Joe Orton for The Beatles.\": 12.989564895629883, \"Blood and Fire (Star Trek: The Next Generation) | \\\"Blood and Fire\\\" is an episode written by David Gerrold for possible use on \\\"\\\".  The script was commissioned and written, but never actually filmed.  According to Gerrold, some of the production staff, including Rick Berman, had a negative reaction to its positive depiction of an openly gay couple.  Herbert Wright rewrote the script under the name \\\"Blood and Ice\\\", which also was left unproduced.\": 11.980508804321289, \"Cedar Rapids (film) | Cedar Rapids is a 2011 American comedy film directed by Miguel Arteta.  The script, written by Phil Johnston, was included on the 2009 Black List, a Hollywood list of the most popular unproduced screenplays of the year.\": 11.593443870544434, \"The Beatles: The Biography | The Beatles: The Biography is the name of a 2005 biography of the 1960s rock band The Beatles written by Bob Spitz.  It was first published by Little, Brown and Company on November 1, 2005.\": 11.583497047424316, \"The Illusionist (2010 film) | The Illusionist (French: L'Illusionniste ) is a 2010 French-British animated film directed by Sylvain Chomet.  The film is based on an unproduced script written by French mime, director and actor Jacques Tati in 1956.  Controversy surrounds Tati's motivation for the script, which was written as a personal letter to his estranged eldest daughter, Helga Marie-Jeanne Schiel in collaboration with his long-term writing partner Henri Marquet, between writing for the films \\\"Mon Oncle\\\" and \\\"Play Time\\\".\": 11.528533935546875, \"Bobby Florsheim | Robert Florsheim (born December 19, 1969) is an American screenwriter, best known for co-writing \\\"The Passion Of The Ark\\\" with Josh Stolberg, (the basis for the film \\\"Evan Almighty\\\").  Their original script was reported by Daily Variety as the highest priced spec script ever sold by unproduced screenwriters (April, 2004).  In refashioning the script into \\\"Evan Almighty\\\", Universal Studios discarded the script and then hired screenwriter Steve Oedekerk, who received sole writing credit on the finished film.\": 11.23757553100586, \"The Hook (screenplay) | The Hook is an unproduced screenplay by American playwright, Arthur Miller.  It was written in 1947 and was intended to be produced by Columbia Pictures Studio, Hollywood, and to be directed by Elia Kazan.  The screenplay was inspired by the true story of Pete Panto, a young dockworker who stood up against the corrupt Mafia-connected union leadership.  Panto was discovered dead in a pit outside New York eighteen months after his disappearance.  Set in the Red Hook district of Brooklyn, \\\"The Hook\\\" is the story of Marty Ferrara, a longshoreman who is ‘ready to lay down his life, if need be, to secure one thing – his sense of personal dignity.’\": 11.222980499267578}\n",
1133 |       "\n",
1134 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## new_notes ## ]]` (must be formatted as a valid Python list[str]), then `[[ ## titles ## ]]` (must be formatted as a valid Python list[str]), and then ending with the marker for `[[ ## completed ## ]]`.\n",
1135 |       "\n",
1136 |       "\n",
1137 |       "\u001b[31mResponse:\u001b[0m\n",
1138 |       "\n",
1139 |       "\u001b[32m[[ ## reasoning ## ]]\n",
1140 |       "The claim states that the author of the 1960s unproduced script written for The Beatles, \"Up Against It\", and Bernard-Marie Koltès are both playwrights. The context confirms that Joe Orton wrote the script \"Up Against It\" for The Beatles, and Bernard-Marie Koltès was a French playwright. Therefore, the claim is supported by the provided context.\n",
1141 |       "\n",
1142 |       "[[ ## new_notes ## ]]\n",
1143 |       "[]\n",
1144 |       "\n",
1145 |       "[[ ## titles ## ]]\n",
1146 |       "[\"Up Against It\", \"Bernard-Marie Koltès\", \"Joe Orton\", \"The Beatles\"]\n",
1147 |       "\n",
1148 |       "[[ ## completed ## ]]\u001b[0m\n",
1149 |       "\n",
1150 |       "\n",
1151 |       "\n",
1152 |       "\n",
1153 |       "\n"
1154 |      ]
1155 |     }
1156 |    ],
1157 |    "source": [
1158 |     "dspy.inspect_history(n=2)"
1159 |    ]
1160 |   },
1161 |   {
1162 |    "cell_type": "markdown",
1163 |    "metadata": {},
1164 |    "source": [
1165 |     "Finally, let's save our optimized program so we can use it again later."
1166 |    ]
1167 |   },
1168 |   {
1169 |    "cell_type": "code",
1170 |    "execution_count": 16,
1171 |    "metadata": {},
1172 |    "outputs": [
1173 |     {
1174 |      "data": {
1175 |       "text/plain": [
1176 |        "['Up Against It', 'Bernard-Marie Koltès', 'The Beatles', 'Joe Orton']"
1177 |       ]
1178 |      },
1179 |      "execution_count": 17,
1180 |      "metadata": {},
1181 |      "output_type": "execute_result"
1182 |     }
1183 |    ],
1184 |    "source": [
1185 |     "optimized.save(\"optimized_hop.json\")\n",
1186 |     "\n",
1187 |     "loaded_program = Hop()\n",
1188 |     "loaded_program.load(\"optimized_hop.json\")\n",
1189 |     "\n",
1190 |     "loaded_program(claim=\"The author of the 1960s unproduced script written for The Beatles, Up Against It, and Bernard-Marie Koltès are both playwrights.\").titles"
1191 |    ]
1192 |   },
1193 |   {
1194 |    "cell_type": "markdown",
1195 |    "metadata": {},
1196 |    "source": [
1197 |     "<details>\n",
1198 |     "<summary>Saving programs in MLflow Experiment</summary>\n",
1199 |     "\n",
1200 |     "<br/>\n",
1201 |     "\n",
1202 |     "Instead of saving the program to a local file, you can track it in MLflow for better reproducibility and collaboration.\n",
1203 |     "\n",
1204 |     "1. **Dependency Management**: MLflow automatically save the frozen environment metadata along with the program to ensure reproducibility.\n",
1205 |     "2. **Experiment Tracking**: With MLflow, you can track the program's performance and cost along with the program itself.\n",
1206 |     "3. **Collaboration**: You can share the program and results with your team members by sharing the MLflow experiment.\n",
1207 |     "\n",
1208 |     "To save the program in MLflow, run the following code:\n",
1209 |     "\n",
1210 |     "```python\n",
1211 |     "import mlflow\n",
1212 |     "\n",
1213 |     "# Start an MLflow Run and save the program\n",
1214 |     "with mlflow.start_run(run_name=\"optimized\"):\n",
1215 |     "    model_info = mlflow.dspy.log_model(\n",
1216 |     "        optimized,\n",
1217 |     "        artifact_path=\"model\", # Any name to save the program in MLflow\n",
1218 |     "    )\n",
1219 |     "\n",
1220 |     "# Load the program back from MLflow\n",
1221 |     "loaded = mlflow.dspy.load_model(model_info.model_uri)\n",
1222 |     "```\n",
1223 |     "\n",
1224 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
1225 |     "\n",
1226 |     "</details>"
1227 |    ]
1228 |   }
1229 |  ],
1230 |  "metadata": {
1231 |   "kernelspec": {
1232 |    "display_name": "jun2024_py310",
1233 |    "language": "python",
1234 |    "name": "python3"
1235 |   },
1236 |   "language_info": {
1237 |    "codemirror_mode": {
1238 |     "name": "ipython",
1239 |     "version": 3
1240 |    },
1241 |    "file_extension": ".py",
1242 |    "mimetype": "text/x-python",
1243 |    "name": "python",
1244 |    "nbconvert_exporter": "python",
1245 |    "pygments_lexer": "ipython3",
1246 |    "version": "3.10.14"
1247 |   }
1248 |  },
1249 |  "nbformat": 4,
1250 |  "nbformat_minor": 2
1251 | }
```

observability/index.md
```
1 | # Tutorial: Debugging and Observability in DSPy
2 |
3 | This guide demonstrates how to debug problems and improve observability in DSPy. Modern AI programs often involve multiple components, such as language models, retrievers, and tools. DSPy allows you to build and optimize such complex AI systems in a clean and modular way.
4 |
5 | However, as systems grow more sophisticated, the ability to **understand what your system is doing** becomes critical. Without transparency, the prediction process can easily become a black box, making failures or quality issues difficult to diagnose and production maintenance challenging.
6 |
7 | By the end of this tutorial, you'll understand how to debug an issue and improve observability using [MLflow Tracing](#tracing). You'll also explore how to build a custom logging solution using callbacks.
8 |
9 |
10 |
11 | ## Define a Program
12 |
13 | We'll start by creating a simple ReAct agent that uses ColBERTv2's Wikipedia dataset as a retrieval source. You can replace this with a more sophisticated program.
14 |
15 | ```python
16 | import dspy
17 | import os
18 |
19 | os.environ["OPENAI_API_KEY"] = "{your_openai_api_key}"
20 |
21 | lm = dspy.LM("openai/gpt-4o-mini")
22 | colbert = dspy.ColBERTv2(url="http://20.102.90.50:2017/wiki17_abstracts")
23 | dspy.configure(lm=lm)
24 |
25 |
26 | def retrieve(query: str):
27 |     """Retrieve top 3 relevant information from ColBert"""
28 |     results = colbert(query, k=3)
29 |     return [x["text"] for x in results]
30 |
31 |
32 | agent = dspy.ReAct("question -> answer", tools=[retrieve], max_iters=3)
33 | ```
34 |
35 | Now, let's ask the agent a simple question:
36 |
37 | ```python
38 | prediction = agent(question="Which baseball team does Shohei Ohtani play for in June 2025?")
39 | print(prediction.answer)
40 | ```
41 |
42 | ```
43 | Shohei Ohtani is expected to play for the Hokkaido Nippon-Ham Fighters in June 2025, based on the available information.
44 | ```
45 |
46 | Oh, this is incorrect. He no longer plays for the Hokkaido Nippon-Ham Fighters; he moved to the Dodgers and won the World Series in 2024! Let's debug the program and explore potential fixes.
47 |
48 | ## Using ``inspect_history``
49 |
50 | DSPy provides the `inspect_history()` utility, which prints out all LLM invocations made so far:
51 |
52 | ```python
53 | # Print out 5 LLM calls
54 | dspy.inspect_history(n=5)
55 | ```
56 |
57 | ```
58 | [2024-12-01T10:23:29.144257]
59 |
60 | System message:
61 |
62 | Your input fields are:
63 | 1. `question` (str)
64 |
65 | ...
66 |
67 | Response:
68 |
69 | Response:
70 |
71 | [[ ## reasoning ## ]]
72 | The search for information regarding Shohei Ohtani's team in June 2025 did not yield any specific results. The retrieved data consistently mentioned that he plays for the Hokkaido Nippon-Ham Fighters, but there was no indication of any changes or updates regarding his team for the specified date. Given the lack of information, it is reasonable to conclude that he may still be with the Hokkaido Nippon-Ham Fighters unless there are future developments that are not captured in the current data.
73 |
74 | [[ ## answer ## ]]
75 | Shohei Ohtani is expected to play for the Hokkaido Nippon-Ham Fighters in June 2025, based on the available information.
76 |
77 | [[ ## completed ## ]]
78 |
79 | ```
80 | The log reveals that the agent could not retrieve helpful information from the search tool. However, what exactly did the retriever return? While useful, `inspect_history` has some limitations:
81 |
82 | * In real-world systems, other components like retrievers, tools, and custom modules play significant roles, but `inspect_history` only logs LLM calls.
83 | * DSPy programs often make multiple LLM calls within a single prediction. Monolith log history makes it hard to organize logs, especially when handling multiple questions.
84 | * Metadata such as parameters, latency, and the relationship between modules are not captured.
85 |
86 | **Tracing** addresses these limitations and provides a more comprehensive solution.
87 |
88 | ## Tracing
89 |
90 | [MLflow](https://mlflow.org/docs/latest/llms/tracing/index.html) is an end-to-end machine learning platform that is integrated seamlessly with DSPy to support best practices in LLMOps. Using MLflow's automatic tracing capability with DSPy is straightforward; **No sign up for services or an API key is required**. You just need to install MLflow and call `mlflow.dspy.autolog()` in your notebook or script.
91 |
92 | ```bash
93 | pip install -U mlflow>=2.18.0
94 | ```
95 |
96 | After installation, spin up your server via the command below.
97 |
98 | ```
99 | # It is highly recommended to use SQL store when using MLflow tracing
100 | mlflow server --backend-store-uri sqlite:///mydb.sqlite
101 | ```
102 |
103 | If you don't specify a different port via `--port` flag, you MLflow server will be hosted at port 5000.
104 |
105 | Now let's change our code snippet to enable MLflow tracing. We need to:
106 |
107 | - Tell MLflow where the server is hosted.
108 | - Apply `mlflow.autolog()` so that DSPy tracing is automatically captured.
109 |
110 | The full code is as below, now let's run it again!
111 |
112 | ```python
113 | import dspy
114 | import os
115 | import mlflow
116 |
117 | os.environ["OPENAI_API_KEY"] = "{your_openai_api_key}"
118 |
119 | # Tell MLflow about the server URI.
120 | mlflow.set_tracking_uri("http://127.0.0.1:5000")
121 | # Create a unique name for your experiment.
122 | mlflow.set_experiment("DSPy")
123 |
124 | lm = dspy.LM("openai/gpt-4o-mini")
125 | colbert = dspy.ColBERTv2(url="http://20.102.90.50:2017/wiki17_abstracts")
126 | dspy.configure(lm=lm)
127 |
128 |
129 | def retrieve(query: str):
130 |     """Retrieve top 3 relevant information from ColBert"""
131 |     results = colbert(query, k=3)
132 |     return [x["text"] for x in results]
133 |
134 |
135 | agent = dspy.ReAct("question -> answer", tools=[retrieve], max_iters=3)
136 | print(agent(question="Which baseball team does Shohei Ohtani play for?"))
137 | ```
138 |
139 |
140 | MLflow automatically generates a **trace** for each prediction and records it within your experiment. To explore these traces visually, open `http://127.0.0.1:5000/`
141 | in your browser, then select the experiment you just created and navigate to the Traces tab:
142 |
143 | ![MLflow Trace UI](./mlflow_trace_ui.png)
144 |
145 | Click on the most recent trace to view its detailed breakdown:
146 |
147 | ![MLflow Trace View](./mlflow_trace_view.png)
148 |
149 | Here, you can examine the input and output of every step in your workflow. For example, the screenshot above shows the `retrieve` function's input and output. By inspecting the retriever's output, you can see that it returned outdated information, which is not sufficient to determine which team Shohei Ohtani plays for in June 2025. You can also inspect
150 | other steps, e.g, language model's input, output, and configuration.
151 |
152 | To address the issue of outdated information, you can replace the `retrieve` function with a web search tool powered by [Tavily search](https://www.tavily.com/).
153 |
154 | ```python
155 | from tavily import TavilyClient
156 | import dspy
157 | import mlflow
158 |
159 | # Tell MLflow about the server URI.
160 | mlflow.set_tracking_uri("http://127.0.0.1:5000")
161 | # Create a unique name for your experiment.
162 | mlflow.set_experiment("DSPy")
163 |
164 | search_client = TavilyClient(api_key="<YOUR_TAVILY_API_KEY>")
165 |
166 | def web_search(query: str) -> list[str]:
167 |     """Run a web search and return the content from the top 5 search results"""
168 |     response = search_client.search(query)
169 |     return [r["content"] for r in response["results"]]
170 |
171 | agent = dspy.ReAct("question -> answer", tools=[web_search])
172 |
173 | prediction = agent(question="Which baseball team does Shohei Ohtani play for?")
174 | print(agent.answer)
175 | ```
176 |
177 | ```
178 | Los Angeles Dodgers
179 | ```
180 |
181 | Below is a GIF demonstrating how to navigate through the MLflow UI:
182 |
183 | ![MLflow Trace UI Navigation](./mlflow_trace_ui_navigation.gif)
184 |
185 |
186 | For a complete guide on how to use MLflow tracing, please refer to
187 | the [MLflow Tracing Guide](https://mlflow.org/docs/3.0.0rc0/tracing).
188 |
189 |
190 |
191 | !!! info Learn more about MLflow
192 |
193 |     MLflow is an end-to-end LLMOps platform that offers extensive features like experiment tracking, evaluation, and deployment. To learn more about DSPy and MLflow integration, visit [this tutorial](../deployment/index.md#deploying-with-mlflow).
194 |
195 |
196 | ## Building a Custom Logging Solution
197 |
198 | Sometimes, you may want to implement a custom logging solution. For instance, you might need to log specific events triggered by a particular module. DSPy's **callback** mechanism supports such use cases. The ``BaseCallback`` class provides several handlers for customizing logging behavior:
199 |
200 | |Handlers|Description|
201 | |:--|:--|
202 | |`on_module_start` / `on_module_end` | Triggered when a `dspy.Module` subclass is invoked. |
203 | |`on_lm_start` / `on_lm_end` | Triggered when a `dspy.LM` subclass is invoked. |
204 | |`on_adapter_format_start` / `on_adapter_format_end`| Triggered when a `dspy.Adapter` subclass formats the input prompt. |
205 | |`on_adapter_parse_start` / `on_adapter_parse_end`| Triggered when a `dspy.Adapter` subclass postprocess the output text from an LM. |
206 | |`on_tool_start` / `on_tool_end` | Triggered when a `dspy.Tool` subclass is invoked. |
207 | |`on_evaluate_start` / `on_evaluate_end` | Triggered when a `dspy.Evaluate` instance is invoked. |
208 |
209 | Here's an example of custom callback that logs the intermediate steps of a ReAct agent:
210 |
211 | ```python
212 | import dspy
213 | from dspy.utils.callback import BaseCallback
214 |
215 | # 1. Define a custom callback class that extends BaseCallback class
216 | class AgentLoggingCallback(BaseCallback):
217 |
218 |     # 2. Implement on_module_end handler to run a custom logging code.
219 |     def on_module_end(self, call_id, outputs, exception):
220 |         step = "Reasoning" if self._is_reasoning_output(outputs) else "Acting"
221 |         print(f"== {step} Step ===")
222 |         for k, v in outputs.items():
223 |             print(f"  {k}: {v}")
224 |         print("\n")
225 |
226 |     def _is_reasoning_output(self, outputs):
227 |         return any(k.startswith("Thought") for k in outputs.keys())
228 |
229 | # 3. Set the callback to DSPy setting so it will be applied to program execution
230 | dspy.configure(callbacks=[AgentLoggingCallback()])
231 | ```
232 |
233 |
234 | ```
235 | == Reasoning Step ===
236 |   Thought_1: I need to find the current team that Shohei Ohtani plays for in Major League Baseball.
237 |   Action_1: Search[Shohei Ohtani current team 2023]
238 |
239 | == Acting Step ===
240 |   passages: ["Shohei Ohtani ..."]
241 |
242 | ...
243 | ```
244 |
245 | !!! info Handling Inputs and Outputs in Callbacks
246 |
247 |     Be cautious when working with input or output data in callbacks. Mutating them in-place can modify the original data passed to the program, potentially leading to unexpected behavior. To avoid this, it's strongly recommended to create a copy of the data before performing any operations that may alter it.
```

optimize_ai_program/index.md
```
1 | # Optimize AI Programs with DSPy
2 |
3 | This section focuses on DSPy's powerful optimization capabilities, demonstrating how to systematically improve your AI programs using various optimizers. These tutorials are lighter on programming concepts and instead showcase how DSPy optimizers can automatically enhance the quality and performance of your applications.
4 |
5 | ## Mathematical and Reasoning Tasks
6 |
7 | ### [Math Reasoning](../math/index.ipynb)
8 | Learn how to optimize DSPy programs for mathematical reasoning tasks. This tutorial demonstrates how optimizers can dramatically improve performance on complex math problems by finding better prompting strategies and few-shot examples.
9 |
10 | ## Model Optimization
11 |
12 | ### [Classification Finetuning](../classification_finetuning/index.ipynb)
13 | Discover how to use DSPy's finetuning optimizers to distill knowledge from large language models into smaller, more efficient models. Learn the complete workflow from prompt optimization to model finetuning for classification tasks.
14 |
15 | ## Advanced Tool Integration
16 |
17 | ### [Advanced Tool Use](../tool_use/index.ipynb)
18 | Explore how to optimize AI programs that use external tools and APIs. This tutorial shows how DSPy optimizers can learn to use tools more effectively, improving both accuracy and efficiency in tool-calling scenarios.
19 |
20 | ### [Finetuning Agents](../games/index.ipynb)
21 | Learn to optimize complex agent-based systems through finetuning. This tutorial demonstrates how to improve agent performance in interactive environments like games, where strategic thinking and adaptation are crucial.
```

optimizer_tracking/index.md
```
1 | # Tracking DSPy Optimizers with MLflow
2 |
3 | This tutorial demonstrates how to use MLflow to track and analyze your DSPy optimization process. MLflow's built-in integration for DSPy provides traceability and debuggability for your DSPy optimization experience. It allows you to understand the intermediate trials during the optimization, store the optimized program and its results, and provides observability into your program execution.
4 |
5 | Through the autologging capability, MLflow tracks the following information:
6 |
7 | * **Optimizer Parameters**
8 |     * Number of few-shot examples
9 |     * Number of candidates
10 |     * Other configuration settings
11 |
12 | * **Program States**
13 |     * Initial instructions and few-shot examples
14 |     * Optimized instructions and few-shot examples
15 |     * Intermediate instructions and few-shot examples during optimization
16 |
17 | * **Datasets**
18 |     * Training data used
19 |     * Evaluation data used
20 |
21 | * **Performance Progression**
22 |     * Overall metric progression
23 |     * Performance at each evaluation step
24 |
25 | * **Traces**
26 |     * Program execution traces
27 |     * Model responses
28 |     * Intermediate prompts
29 |
30 | ## Getting Started
31 |
32 | ### 1. Install MLflow
33 | First, install MLflow (version 2.21.1 or later):
34 |
35 | ```bash
36 | pip install mlflow>=2.21.1
37 | ```
38 |
39 | ### 2. Start MLflow Tracking Server
40 |
41 | Let's spin up the MLflow tracking server with the following command. This will start a local server at `http://127.0.0.1:5000/`:
42 |
43 | ```bash
44 | # It is highly recommended to use SQL store when using MLflow tracing
45 | mlflow server --backend-store-uri sqlite:///mydb.sqlite
46 | ```
47 |
48 | ### 3. Enable Autologging
49 |
50 | Configure MLflow to track your DSPy optimization:
51 |
52 | ```python
53 | import mlflow
54 | import dspy
55 |
56 | # Enable autologging with all features
57 | mlflow.dspy.autolog(
58 |     log_compiles=True,    # Track optimization process
59 |     log_evals=True,       # Track evaluation results
60 |     log_traces_from_compile=True  # Track program traces during optimization
61 | )
62 |
63 | # Configure MLflow tracking
64 | mlflow.set_tracking_uri("http://localhost:5000")  # Use local MLflow server
65 | mlflow.set_experiment("DSPy-Optimization")
66 | ```
67 |
68 | ### 4. Optimizing Your Program
69 |
70 | Here's a complete example showing how to track the optimization of a math problem solver:
71 |
72 | ```python
73 | import dspy
74 | from dspy.datasets.gsm8k import GSM8K, gsm8k_metric
75 |
76 | # Configure your language model
77 | lm = dspy.LM(model="openai/gpt-4o")
78 | dspy.configure(lm=lm)
79 |
80 | # Load dataset
81 | gsm8k = GSM8K()
82 | trainset, devset = gsm8k.train, gsm8k.dev
83 |
84 | # Define your program
85 | program = dspy.ChainOfThought("question -> answer")
86 |
87 | # Create and run optimizer with tracking
88 | teleprompter = dspy.teleprompt.MIPROv2(
89 |     metric=gsm8k_metric,
90 |     auto="light",
91 | )
92 |
93 | # The optimization process will be automatically tracked
94 | optimized_program = teleprompter.compile(
95 |     program,
96 |     trainset=trainset,
97 | )
98 | ```
99 |
100 | ### 5. Viewing Results
101 |
102 | Once your optimization is complete, you can analyze the results through MLflow's UI. Let's walk through how to explore your optimization runs.
103 |
104 | #### Step 1: Access the MLflow UI
105 | Navigate to `http://localhost:5000` in your web browser to access the MLflow tracking server UI.
106 |
107 | #### Step 2: Understanding the Experiment Structure
108 | When you open the experiment page, you'll see a hierarchical view of your optimization process. The parent run represents your overall optimization process, while the child runs show each intermediate version of your program that was created during optimization.
109 |
110 | ![Experiments](./experiment.png)
111 |
112 | #### Step 3: Analyzing the Parent Run
113 | Clicking on the parent run reveals the big picture of your optimization process. You'll find detailed information about your optimizer's configuration parameters and how your evaluation metrics progressed over time. The parent run also stores your final optimized program, including the instructions, signature definitions, and few-shot examples that were used. Additionally, you can review the training data that was used during the optimization process.
114 |
115 | ![Parent Run](./parent_run.png)
116 |
117 | #### Step 4: Examining Child Runs
118 | Each child run provides a detailed snapshot of a specific optimization attempt. When you select a child run from the experiment page, you can explore several aspects of that particular intermediate program.
119 | On the run parameter tab or artifact tab, you can review the instructions and few-shot examples used for the intermediate program.
120 | One of the most powerful features is the Traces tab, which provides a step-by-step view of your program's execution. Here you can understand exactly how your DSPy program processes inputs and generates outputs.
121 |
122 | ![Child Run](./child_run.png)
123 |
124 | ### 6. Loading Models for Inference
125 | You can load the optimized program directly from the MLflow tracking server for inference:
126 |
127 | ```python
128 | model_path = mlflow.artifacts.download_artifacts("mlflow-artifacts:/path/to/best_model.json")
129 | program.load(model_path)
130 | ```
131 |
132 | ## Troubleshooting
133 |
134 | - If traces aren't appearing, ensure `log_traces_from_compile=True`
135 | - For large datasets, consider setting `log_traces_from_compile=False` to avoid memory issues
136 | - Use `mlflow.get_run(run_id)` to programmatically access MLflow run data
137 |
138 | For more features, explore the [MLflow Documentation](https://mlflow.org/docs/latest/llms/dspy).
```

output_refinement/best-of-n-and-refine.md
```
1 | # Output Refinement: BestOfN and Refine
2 |
3 | Both `BestOfN` and `Refine` are DSPy modules designed to improve the reliability and quality of predictions by making multiple `LM` calls with different rollout IDs to bypass caching. Both modules stop when they have reached `N` attempts or when the `reward_fn` returns an award above the `threshold`.
4 |
5 | ## BestOfN
6 |
7 | `BestOfN` is a module that runs the provided module multiple times (up to `N`) with different rollout IDs. It returns either the first prediction that passes a specified threshold or the one with the highest reward if none meets the threshold.
8 |
9 | ### Basic Usage
10 |
11 | Lets say we wanted to have the best chance of getting a one word answer from the model. We could use `BestOfN` to try multiple rollout IDs and return the best result.
12 |
13 | ```python
14 | import dspy
15 |
16 | def one_word_answer(args, pred: dspy.Prediction) -> float:
17 |     return 1.0 if len(pred.answer.split()) == 1 else 0.0
18 |
19 | best_of_3 = dspy.BestOfN(
20 |     module=dspy.ChainOfThought("question -> answer"),
21 |     N=3,
22 |     reward_fn=one_word_answer,
23 |     threshold=1.0
24 | )
25 |
26 | result = best_of_3(question="What is the capital of Belgium?")
27 | print(result.answer)  # Brussels
28 | ```
29 |
30 | ### Error Handling
31 |
32 | By default, if the module encounters an error during an attempt, it will continue trying until it reaches `N` attempts. You can adjust this behavior with the `fail_count` parameter:
33 |
34 | ```python
35 | best_of_3 = dspy.BestOfN(
36 |     module=qa,
37 |     N=3,
38 |     reward_fn=one_word_answer,
39 |     threshold=1.0,
40 |     fail_count=1
41 | )
42 |
43 | best_of_3(question="What is the capital of Belgium?")
44 | # raises an error after the first failure
45 | ```
46 |
47 | ## Refine
48 |
49 | `Refine` extends the functionality of `BestOfN` by adding an automatic feedback loop. After each unsuccessful attempt (except the final one), it automatically generates detailed feedback about the module's performance and uses this feedback as hints for subsequent runs.
50 |
51 | ### Basic Usage
52 |
53 | ```python
54 | import dspy
55 |
56 | def one_word_answer(args, pred: dspy.Prediction) -> float:
57 |     return 1.0 if len(pred.answer.split()) == 1 else 0.0
58 |
59 | refine = dspy.Refine(
60 |     module=dspy.ChainOfThought("question -> answer"),
61 |     N=3,
62 |     reward_fn=one_word_answer,
63 |     threshold=1.0
64 | )
65 |
66 | result = refine(question="What is the capital of Belgium?")
67 | print(result.answer)  # Brussels
68 | ```
69 |
70 | ### Error Handling
71 |
72 | Like `BestOfN`, `Refine` will try up to `N` times by default, even if errors occur. You can control this with the `fail_count` parameter:
73 |
74 | ```python
75 | # Stop after the first error
76 | refine = dspy.Refine(
77 |     module=qa,
78 |     N=3,
79 |     reward_fn=one_word_answer,
80 |     threshold=1.0,
81 |     fail_count=1
82 | )
83 | ```
84 |
85 | ## Comparison: BestOfN vs. Refine
86 |
87 | Both modules serve similar purposes but differ in their approach:
88 |
89 | - `BestOfN` simply tries different rollout IDs and selects the best resulting prediction as defined by the `reward_fn`.
90 | - `Refine` adds an feedback loop, using the lm to generate a detailed feedback about the module's own performance using the previous prediction and the code in the `reward_fn`. This feedback is then used as hints for subsequent runs.
91 |
92 | ## Practical Examples
93 |
94 | ### Ensuring Factual Correctness
95 |
96 | ```python
97 | import dspy
98 |
99 | class FactualityJudge(dspy.Signature):
100 |     """Determine if a statement is factually accurate."""
101 |     statement: str = dspy.InputField()
102 |     is_factual: bool = dspy.OutputField()
103 |
104 | factuality_judge = dspy.ChainOfThought(FactualityJudge)
105 |
106 | def factuality_reward(args, pred: dspy.Prediction) -> float:
107 |     statement = pred.answer
108 |     result = factuality_judge(statement)
109 |     return 1.0 if result.is_factual else 0.0
110 |
111 | refined_qa = dspy.Refine(
112 |     module=dspy.ChainOfThought("question -> answer"),
113 |     N=3,
114 |     reward_fn=factuality_reward,
115 |     threshold=1.0
116 | )
117 |
118 | result = refined_qa(question="Tell me about Belgium's capital city.")
119 | print(result.answer)
120 | ```
121 |
122 | ### Summarization - Controlling Response Length
123 |
124 | ```python
125 | import dspy
126 |
127 | def ideal_length_reward(args, pred: dspy.Prediction) -> float:
128 |     """
129 |     Reward the summary for being close to 75 words with a tapering off for longer summaries.
130 |     """
131 |     word_count = len(pred.summary.split())
132 |     distance = abs(word_count - 75)
133 |     return max(0.0, 1.0 - (distance / 125))
134 |
135 | optimized_summarizer = dspy.BestOfN(
136 |     module=dspy.ChainOfThought("text -> summary"),
137 |     N=50,
138 |     reward_fn=ideal_length_reward,
139 |     threshold=0.9
140 | )
141 |
142 | result = optimized_summarizer(
143 |     text="[Long text to summarize...]"
144 | )
145 | print(result.summary)
146 | ```
147 |
148 | ## Migration from `dspy.Suggest` and `dspy.Assert`
149 |
150 | `BestOfN` and `Refine` are the replacements for `dspy.Suggest` and `dspy.Assert` as of DSPy 2.6.
```

papillon/index.md
```
1 | Please refer to [this tutorial from the PAPILLON authors](https://colab.research.google.com/github/Columbia-NLP-Lab/PAPILLON/blob/main/papillon_tutorial.ipynb) using DSPy.
2 |
3 | This tutorial demonstrates a few aspects of using DSPy in a more advanced context:
4 |
5 | 1. It builds a multi-stage `dspy.Module` that involves a small local LM using an external tool.
6 | 2. It builds a multi-stage _judge_ in DSPy, and uses it as a metric for evaluation.
7 | 3. It uses this judge for optimizing the `dspy.Module`, using a large model as a teacher for a small local LM.
```

program_of_thought/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: ProgramOfThought\n",
8 |     "\n",
9 |     "`dspy.ProgramOfThought` automatically generates and refines Python code to solve downstream tasks.\n",
10 |     "\n",
11 |     "Install the latest DSPy via `pip install -U dspy` and follow along."
12 |    ]
13 |   },
14 |   {
15 |    "cell_type": "markdown",
16 |    "metadata": {},
17 |    "source": [
18 |     "## 1) Using PythonInterpreter\n",
19 |     "\n",
20 |     "`ProgramOfThought` integrates an adapted Python interpreter to execute code generated by LMs. \n",
21 |     "\n",
22 |     "As a brief example to demonstrate how the interpreter works, we'll create an instance of `dspy.PythonInterpreter` and demonstrate the underlying execution of `ProgramOfThought`."
23 |    ]
24 |   },
25 |   {
26 |    "cell_type": "code",
27 |    "execution_count": 17,
28 |    "metadata": {},
29 |    "outputs": [
30 |     {
31 |      "data": {
32 |       "text/plain": [
33 |        "14"
34 |       ]
35 |      },
36 |      "execution_count": 17,
37 |      "metadata": {},
38 |      "output_type": "execute_result"
39 |     }
40 |    ],
41 |    "source": [
42 |     "import dspy\n",
43 |     "interpreter = dspy.PythonInterpreter()\n",
44 |     "expr = \"value = 2*5 + 4\\nvalue\"\n",
45 |     "answer = interpreter.execute(expr)\n",
46 |     "answer"
47 |    ]
48 |   },
49 |   {
50 |    "cell_type": "markdown",
51 |    "metadata": {},
52 |    "source": [
53 |     "## 2) Demonstrating ProgramOfThought\n",
54 |     " As an example, we'll define a signature with an input question and an output answer. Then, we'll create and invoke the `ProgramOfThought` program, which uses an LM to first generate code to represent the question, executes the code using the interpreter and outputs the final result as the answer to the question."
55 |    ]
56 |   },
57 |   {
58 |    "cell_type": "markdown",
59 |    "metadata": {},
60 |    "source": [
61 |     "Let's use Meta's `Llama-3-70b-Instruct`. You can easily swap this out for [other providers or local models](https://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb)."
62 |    ]
63 |   },
64 |   {
65 |    "cell_type": "code",
66 |    "execution_count": 3,
67 |    "metadata": {},
68 |    "outputs": [],
69 |    "source": [
70 |     "llama31_70b = dspy.LM(\"openai/meta-llama/Meta-Llama-3-70b-Instruct\", api_base=\"API_BASE\", api_key=\"None\")\n",
71 |     "\n",
72 |     "dspy.settings.configure(lm=llama31_70b)"
73 |    ]
74 |   },
75 |   {
76 |    "cell_type": "markdown",
77 |    "metadata": {},
78 |    "source": [
79 |     "Let's now define our module with a brief signature that specifies the input question and output answer. We can then call `ProgramOfThought` on the signature and pass in our sample problem."
80 |    ]
81 |   },
82 |   {
83 |    "cell_type": "code",
84 |    "execution_count": 4,
85 |    "metadata": {},
86 |    "outputs": [
87 |     {
88 |      "data": {
89 |       "text/plain": [
90 |        "'14'"
91 |       ]
92 |      },
93 |      "execution_count": 4,
94 |      "metadata": {},
95 |      "output_type": "execute_result"
96 |     }
97 |    ],
98 |    "source": [
99 |     "class BasicGenerateAnswer(dspy.Signature):\n",
100 |     "    question = dspy.InputField()\n",
101 |     "    answer = dspy.OutputField()\n",
102 |     "\n",
103 |     "pot = dspy.ProgramOfThought(BasicGenerateAnswer)\n",
104 |     "problem = \"2*5 + 4\"\n",
105 |     "pot(question=problem).answer"
106 |    ]
107 |   },
108 |   {
109 |    "cell_type": "markdown",
110 |    "metadata": {},
111 |    "source": [
112 |     "Great! The module successfully produced the same correct answer. Let's see how exactly it used the LM to do so:"
113 |    ]
114 |   },
115 |   {
116 |    "cell_type": "code",
117 |    "execution_count": 5,
118 |    "metadata": {},
119 |    "outputs": [
120 |     {
121 |      "name": "stdout",
122 |      "output_type": "stream",
123 |      "text": [
124 |       "\n",
125 |       "\n",
126 |       "\n",
127 |       "\n",
128 |       "\u001b[34m[2025-01-06T21:58:40.879405]\u001b[0m\n",
129 |       "\n",
130 |       "\u001b[31mSystem message:\u001b[0m\n",
131 |       "\n",
132 |       "Your input fields are:\n",
133 |       "1. `question` (str)\n",
134 |       "2. `final_generated_code` (str): python code that answers the question\n",
135 |       "3. `code_output` (str): output of previously-generated python code\n",
136 |       "\n",
137 |       "Your output fields are:\n",
138 |       "1. `reasoning` (str)\n",
139 |       "2. `answer` (str)\n",
140 |       "\n",
141 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
142 |       "\n",
143 |       "[[ ## question ## ]]\n",
144 |       "{question}\n",
145 |       "\n",
146 |       "[[ ## final_generated_code ## ]]\n",
147 |       "{final_generated_code}\n",
148 |       "\n",
149 |       "[[ ## code_output ## ]]\n",
150 |       "{code_output}\n",
151 |       "\n",
152 |       "[[ ## reasoning ## ]]\n",
153 |       "{reasoning}\n",
154 |       "\n",
155 |       "[[ ## answer ## ]]\n",
156 |       "{answer}\n",
157 |       "\n",
158 |       "[[ ## completed ## ]]\n",
159 |       "\n",
160 |       "In adhering to this structure, your objective is: \n",
161 |       "        Given the final code `question`, `final_generated_code`, `code_output`, provide the final `answer`.\n",
162 |       "\n",
163 |       "\n",
164 |       "\u001b[31mUser message:\u001b[0m\n",
165 |       "\n",
166 |       "[[ ## question ## ]]\n",
167 |       "2*5 + 4\n",
168 |       "\n",
169 |       "[[ ## final_generated_code ## ]]\n",
170 |       "def calculate_expression():\n",
171 |       "    # Multiply 2 and 5\n",
172 |       "    multiplication_result = 2 * 5\n",
173 |       "    \n",
174 |       "    # Add 4 to the result\n",
175 |       "    final_result = multiplication_result + 4\n",
176 |       "    \n",
177 |       "    return final_result\n",
178 |       "\n",
179 |       "# Execute the function to get the final answer\n",
180 |       "answer = calculate_expression()\n",
181 |       "print(answer)\n",
182 |       "\n",
183 |       "[[ ## code_output ## ]]\n",
184 |       "14\n",
185 |       "\n",
186 |       "\n",
187 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
188 |       "\n",
189 |       "\n",
190 |       "\u001b[31mResponse:\u001b[0m\n",
191 |       "\n",
192 |       "\u001b[32m[[ ## reasoning ## ]]\n",
193 |       "The given code defines a function `calculate_expression` that calculates the result of the expression 2*5 + 4. It first multiplies 2 and 5, then adds 4 to the result. The function is then executed, and the result is printed.\n",
194 |       "\n",
195 |       "[[ ## answer ## ]]\n",
196 |       "14\n",
197 |       "\n",
198 |       "[[ ## completed ## ]]\u001b[0m\n",
199 |       "\n",
200 |       "\n",
201 |       "\n",
202 |       "\n",
203 |       "\n"
204 |      ]
205 |     }
206 |    ],
207 |    "source": [
208 |     "dspy.inspect_history()"
209 |    ]
210 |   },
211 |   {
212 |    "cell_type": "markdown",
213 |    "metadata": {},
214 |    "source": [
215 |     "We see that the generated Python code defines a function for intermediate computations and returns the final answer upon execution through the `PythonInterpreter`, getting the right answer."
216 |    ]
217 |   },
218 |   {
219 |    "cell_type": "markdown",
220 |    "metadata": {},
221 |    "source": [
222 |     "## 3) Comparing with ChainOfThought\n",
223 |     "\n",
224 |     "Now we turn to a more complex problem to demonstrate how the `ProgramOfThought` module can be helpful. "
225 |    ]
226 |   },
227 |   {
228 |    "cell_type": "markdown",
229 |    "metadata": {},
230 |    "source": [
231 |     "Problem: **Compute 12! / sum of prime numbers between 1 and 30.**\n",
232 |     "\n",
233 |     "This is a fairly challenging computation. Let's see how `ChainOfThought` performs first:"
234 |    ]
235 |   },
236 |   {
237 |    "cell_type": "code",
238 |    "execution_count": 6,
239 |    "metadata": {},
240 |    "outputs": [
241 |     {
242 |      "data": {
243 |       "text/plain": [
244 |        "'3,710,009'"
245 |       ]
246 |      },
247 |      "execution_count": 6,
248 |      "metadata": {},
249 |      "output_type": "execute_result"
250 |     }
251 |    ],
252 |    "source": [
253 |     "problem = \"Compute 12! / sum of prime numbers between 1 and 30.\"\n",
254 |     "\n",
255 |     "cot = dspy.ChainOfThought(BasicGenerateAnswer)\n",
256 |     "cot(question=problem).answer"
257 |    ]
258 |   },
259 |   {
260 |    "cell_type": "code",
261 |    "execution_count": 7,
262 |    "metadata": {},
263 |    "outputs": [
264 |     {
265 |      "name": "stdout",
266 |      "output_type": "stream",
267 |      "text": [
268 |       "\n",
269 |       "\n",
270 |       "\n",
271 |       "\n",
272 |       "\u001b[34m[2025-01-06T21:59:08.539739]\u001b[0m\n",
273 |       "\n",
274 |       "\u001b[31mSystem message:\u001b[0m\n",
275 |       "\n",
276 |       "Your input fields are:\n",
277 |       "1. `question` (str)\n",
278 |       "\n",
279 |       "Your output fields are:\n",
280 |       "1. `reasoning` (str)\n",
281 |       "2. `answer` (str)\n",
282 |       "\n",
283 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
284 |       "\n",
285 |       "[[ ## question ## ]]\n",
286 |       "{question}\n",
287 |       "\n",
288 |       "[[ ## reasoning ## ]]\n",
289 |       "{reasoning}\n",
290 |       "\n",
291 |       "[[ ## answer ## ]]\n",
292 |       "{answer}\n",
293 |       "\n",
294 |       "[[ ## completed ## ]]\n",
295 |       "\n",
296 |       "In adhering to this structure, your objective is: \n",
297 |       "        Given the fields `question`, produce the fields `answer`.\n",
298 |       "\n",
299 |       "\n",
300 |       "\u001b[31mUser message:\u001b[0m\n",
301 |       "\n",
302 |       "[[ ## question ## ]]\n",
303 |       "Compute 12! / sum of prime numbers between 1 and 30.\n",
304 |       "\n",
305 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
306 |       "\n",
307 |       "\n",
308 |       "\u001b[31mResponse:\u001b[0m\n",
309 |       "\n",
310 |       "\u001b[32m[[ ## reasoning ## ]]\n",
311 |       "To solve this problem, we need to calculate 12! (12 factorial) and the sum of prime numbers between 1 and 30. \n",
312 |       "\n",
313 |       "First, let's calculate 12!. 12! = 12 * 11 * 10 * 9 * 8 * 7 * 6 * 5 * 4 * 3 * 2 * 1 = 479,001,600.\n",
314 |       "\n",
315 |       "Next, let's find the prime numbers between 1 and 30. The prime numbers between 1 and 30 are 2, 3, 5, 7, 11, 13, 17, 19, 23, and 29. \n",
316 |       "\n",
317 |       "Now, let's calculate the sum of these prime numbers. sum = 2 + 3 + 5 + 7 + 11 + 13 + 17 + 19 + 23 + 29 = 129.\n",
318 |       "\n",
319 |       "Finally, let's calculate 12! / sum of prime numbers between 1 and 30. result = 479,001,600 / 129 = 3,710,009. \n",
320 |       "\n",
321 |       "[[ ## answer ## ]]\n",
322 |       "3,710,009\n",
323 |       "\n",
324 |       "[[ ## completed ## ]]\u001b[0m\n",
325 |       "\n",
326 |       "\n",
327 |       "\n",
328 |       "\n",
329 |       "\n"
330 |      ]
331 |     }
332 |    ],
333 |    "source": [
334 |     "dspy.inspect_history()"
335 |    ]
336 |   },
337 |   {
338 |    "cell_type": "markdown",
339 |    "metadata": {},
340 |    "source": [
341 |     "So `ChainOfThought` does fairly well in reasoning through the steps, getting the correct value for both 12! and the sum of only prime numbers between 1-30. \n",
342 |     "\n",
343 |     "But it fails at the last step of division, incorrectly computing `479,001,600 / 129 = 3,710,009` when the correct answer is `3713190.69767` (verified by a real calculator!)"
344 |    ]
345 |   },
346 |   {
347 |    "cell_type": "markdown",
348 |    "metadata": {},
349 |    "source": [
350 |     "Let's see how `ProgramOfThought` fares:"
351 |    ]
352 |   },
353 |   {
354 |    "cell_type": "code",
355 |    "execution_count": 8,
356 |    "metadata": {},
357 |    "outputs": [
358 |     {
359 |      "data": {
360 |       "text/plain": [
361 |        "'3713190.697674419'"
362 |       ]
363 |      },
364 |      "execution_count": 8,
365 |      "metadata": {},
366 |      "output_type": "execute_result"
367 |     }
368 |    ],
369 |    "source": [
370 |     "pot(question=problem).answer"
371 |    ]
372 |   },
373 |   {
374 |    "cell_type": "code",
375 |    "execution_count": 9,
376 |    "metadata": {},
377 |    "outputs": [
378 |     {
379 |      "name": "stdout",
380 |      "output_type": "stream",
381 |      "text": [
382 |       "\n",
383 |       "\n",
384 |       "\n",
385 |       "\n",
386 |       "\u001b[34m[2025-01-06T21:59:13.140776]\u001b[0m\n",
387 |       "\n",
388 |       "\u001b[31mSystem message:\u001b[0m\n",
389 |       "\n",
390 |       "Your input fields are:\n",
391 |       "1. `question` (str)\n",
392 |       "2. `final_generated_code` (str): python code that answers the question\n",
393 |       "3. `code_output` (str): output of previously-generated python code\n",
394 |       "\n",
395 |       "Your output fields are:\n",
396 |       "1. `reasoning` (str)\n",
397 |       "2. `answer` (str)\n",
398 |       "\n",
399 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
400 |       "\n",
401 |       "[[ ## question ## ]]\n",
402 |       "{question}\n",
403 |       "\n",
404 |       "[[ ## final_generated_code ## ]]\n",
405 |       "{final_generated_code}\n",
406 |       "\n",
407 |       "[[ ## code_output ## ]]\n",
408 |       "{code_output}\n",
409 |       "\n",
410 |       "[[ ## reasoning ## ]]\n",
411 |       "{reasoning}\n",
412 |       "\n",
413 |       "[[ ## answer ## ]]\n",
414 |       "{answer}\n",
415 |       "\n",
416 |       "[[ ## completed ## ]]\n",
417 |       "\n",
418 |       "In adhering to this structure, your objective is: \n",
419 |       "        Given the final code `question`, `final_generated_code`, `code_output`, provide the final `answer`.\n",
420 |       "\n",
421 |       "\n",
422 |       "\u001b[31mUser message:\u001b[0m\n",
423 |       "\n",
424 |       "[[ ## question ## ]]\n",
425 |       "Compute 12! / sum of prime numbers between 1 and 30.\n",
426 |       "\n",
427 |       "[[ ## final_generated_code ## ]]\n",
428 |       "def is_prime(n):\n",
429 |       "    \"\"\"Check if a number is prime.\"\"\"\n",
430 |       "    if n < 2:\n",
431 |       "        return False\n",
432 |       "    for i in range(2, int(n**0.5) + 1):\n",
433 |       "        if n % i == 0:\n",
434 |       "            return False\n",
435 |       "    return True\n",
436 |       "\n",
437 |       "def sum_of_primes(start, end):\n",
438 |       "    \"\"\"Calculate the sum of prime numbers in a given range.\"\"\"\n",
439 |       "    return sum(num for num in range(start, end + 1) if is_prime(num))\n",
440 |       "\n",
441 |       "def factorial(n):\n",
442 |       "    \"\"\"Calculate the factorial of a number.\"\"\"\n",
443 |       "    result = 1\n",
444 |       "    for i in range(1, n + 1):\n",
445 |       "        result *= i\n",
446 |       "    return result\n",
447 |       "\n",
448 |       "# Calculate the factorial of 12\n",
449 |       "fact_12 = factorial(12)\n",
450 |       "\n",
451 |       "# Calculate the sum of prime numbers between 1 and 30\n",
452 |       "sum_primes = sum_of_primes(1, 30)\n",
453 |       "\n",
454 |       "# Calculate the final result\n",
455 |       "result = fact_12 / sum_primes\n",
456 |       "\n",
457 |       "print(result)\n",
458 |       "\n",
459 |       "[[ ## code_output ## ]]\n",
460 |       "3713190.697674419\n",
461 |       "\n",
462 |       "\n",
463 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
464 |       "\n",
465 |       "\n",
466 |       "\u001b[31mResponse:\u001b[0m\n",
467 |       "\n",
468 |       "\u001b[32m[[ ## reasoning ## ]]\n",
469 |       "The problem requires us to compute the value of 12! divided by the sum of prime numbers between 1 and 30. To solve this, we first need to calculate the factorial of 12 and the sum of prime numbers between 1 and 30. We can use the formulas for factorial and prime numbers to achieve this. The factorial of a number n (denoted as n!) is the product of all positive integers less than or equal to n. A prime number is a natural number greater than 1 that has no positive divisors other than 1 and itself. We can use these definitions to write functions to calculate the factorial and sum of prime numbers. Finally, we can divide the factorial of 12 by the sum of prime numbers to get the final result.\n",
470 |       "\n",
471 |       "\n",
472 |       "[[ ## answer ## ]]\n",
473 |       "3713190.697674419\n",
474 |       "\n",
475 |       "\n",
476 |       "[[ ## completed ## ]]\u001b[0m\n",
477 |       "\n",
478 |       "\n",
479 |       "\n",
480 |       "\n",
481 |       "\n"
482 |      ]
483 |     }
484 |    ],
485 |    "source": [
486 |     "dspy.inspect_history()"
487 |    ]
488 |   },
489 |   {
490 |    "cell_type": "markdown",
491 |    "metadata": {},
492 |    "source": [
493 |     "With the Python interpreter executing code accurately, `ProgramOfThought` mitigates computation errors that may fail in `ChainOfThought`, improving correctness particularly for numerical and logical queries."
494 |    ]
495 |   },
496 |   {
497 |    "cell_type": "markdown",
498 |    "metadata": {},
499 |    "source": [
500 |     "## 3) Computation with Contextual Reasoning"
501 |    ]
502 |   },
503 |   {
504 |    "cell_type": "markdown",
505 |    "metadata": {},
506 |    "source": [
507 |     "Now let's try a more complex example of doing computation in complex math word problems. "
508 |    ]
509 |   },
510 |   {
511 |    "cell_type": "markdown",
512 |    "metadata": {},
513 |    "source": [
514 |     "### Step 1: Define a helper function to search Wikipedia\n",
515 |     "We'll use a `dspy.ColBERTv2` server to retrieve top matches from Wikipedia and parse them inside the `ProgramOfThought` pipeline."
516 |    ]
517 |   },
518 |   {
519 |    "cell_type": "code",
520 |    "execution_count": 12,
521 |    "metadata": {},
522 |    "outputs": [],
523 |    "source": [
524 |     "def search_wikipedia(query: str):\n",
525 |     "    results = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')(query, k=3)\n",
526 |     "    return [x['text'] for x in results]"
527 |    ]
528 |   },
529 |   {
530 |    "cell_type": "markdown",
531 |    "metadata": {},
532 |    "source": [
533 |     "### Step 2: Multi-Hop Search with ProgramOfThought\n",
534 |     "We'll take inspiration from the [Multi-Hop Search task](https://dspy.ai/tutorials/multihop_search/) and simply tweak the final `generate_answer` layer to use `ProgramOfThought` in place of `ChainOfThought` to ensure accurate computations given a question and retrieved context.\n",
535 |     "\n",
536 |     "We pose a challenging word problem that requires retrieval to gather information and then use the facts to perform computation and produce a final result. "
537 |    ]
538 |   },
539 |   {
540 |    "cell_type": "code",
541 |    "execution_count": 15,
542 |    "metadata": {},
543 |    "outputs": [
544 |     {
545 |      "data": {
546 |       "text/plain": [
547 |        "'2025'"
548 |       ]
549 |      },
550 |      "execution_count": 15,
551 |      "metadata": {},
552 |      "output_type": "execute_result"
553 |     }
554 |    ],
555 |    "source": [
556 |     "class GenerateAnswer(dspy.Signature):\n",
557 |     "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
558 |     "\n",
559 |     "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
560 |     "    question = dspy.InputField()\n",
561 |     "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
562 |     "\n",
563 |     "\n",
564 |     "class GenerateSearchQuery(dspy.Signature):\n",
565 |     "    \"\"\"Write a simple search query that will help answer the non-numerical components of a complex question.\"\"\"\n",
566 |     "\n",
567 |     "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
568 |     "    question = dspy.InputField()\n",
569 |     "    query = dspy.OutputField()\n",
570 |     "\n",
571 |     "from dspy.dsp.utils import deduplicate\n",
572 |     "\n",
573 |     "class MultiHopSearchWithPoT(dspy.Module):\n",
574 |     "    def __init__(self, num_hops):\n",
575 |     "        self.num_hops = num_hops\n",
576 |     "        self.generate_query = dspy.ChainOfThought(GenerateSearchQuery)\n",
577 |     "        self.generate_answer = dspy.ProgramOfThought(GenerateAnswer, max_iters=3)\n",
578 |     "\n",
579 |     "    def forward(self, question):\n",
580 |     "        context = []\n",
581 |     "        for _ in range(self.num_hops):\n",
582 |     "            query = self.generate_query(context=context, question=question).query\n",
583 |     "            context = deduplicate(context + search_wikipedia(query))\n",
584 |     "        prediction = self.generate_answer(context=context, question=question)\n",
585 |     "        return dspy.Prediction(context=context, answer=prediction.answer)\n",
586 |     "\n",
587 |     "multi_hop_pot = MultiHopSearchWithPoT(num_hops=2)\n",
588 |     "question = (\n",
589 |     "    \"What is the square of the total sum of the atomic number of the metal \"\n",
590 |     "    \"that makes up the gift from France to the United States in the late \"\n",
591 |     "    \"19th century and the sum of the number of digits in the first 10 prime numbers?\"\n",
592 |     ")\n",
593 |     "multi_hop_pot(question=question).answer"
594 |    ]
595 |   },
596 |   {
597 |    "cell_type": "code",
598 |    "execution_count": 16,
599 |    "metadata": {},
600 |    "outputs": [
601 |     {
602 |      "name": "stdout",
603 |      "output_type": "stream",
604 |      "text": [
605 |       "\n",
606 |       "\n",
607 |       "\n",
608 |       "\n",
609 |       "\u001b[34m[2025-01-06T22:00:34.427037]\u001b[0m\n",
610 |       "\n",
611 |       "\u001b[31mSystem message:\u001b[0m\n",
612 |       "\n",
613 |       "Your input fields are:\n",
614 |       "1. `context` (str): may contain relevant facts\n",
615 |       "2. `question` (str)\n",
616 |       "3. `final_generated_code` (str): python code that answers the question\n",
617 |       "4. `code_output` (str): output of previously-generated python code\n",
618 |       "\n",
619 |       "Your output fields are:\n",
620 |       "1. `reasoning` (str)\n",
621 |       "2. `answer` (str): often between 1 and 5 words\n",
622 |       "\n",
623 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
624 |       "\n",
625 |       "[[ ## context ## ]]\n",
626 |       "{context}\n",
627 |       "\n",
628 |       "[[ ## question ## ]]\n",
629 |       "{question}\n",
630 |       "\n",
631 |       "[[ ## final_generated_code ## ]]\n",
632 |       "{final_generated_code}\n",
633 |       "\n",
634 |       "[[ ## code_output ## ]]\n",
635 |       "{code_output}\n",
636 |       "\n",
637 |       "[[ ## reasoning ## ]]\n",
638 |       "{reasoning}\n",
639 |       "\n",
640 |       "[[ ## answer ## ]]\n",
641 |       "{answer}\n",
642 |       "\n",
643 |       "[[ ## completed ## ]]\n",
644 |       "\n",
645 |       "In adhering to this structure, your objective is: \n",
646 |       "        Given the final code `context`, `question`, `final_generated_code`, `code_output`, provide the final `answer`.\n",
647 |       "\n",
648 |       "\n",
649 |       "\u001b[31mUser message:\u001b[0m\n",
650 |       "\n",
651 |       "[[ ## context ## ]]\n",
652 |       "[1] «Goddess of Democracy | The Goddess of Democracy, also known as the Goddess of Democracy and Freedom, the Spirit of Democracy, and the Goddess of Liberty (自由女神; \"zìyóu nǚshén\"), was a 10-meter-tall (33 ft) statue created during the Tiananmen Square protests of 1989. The statue was constructed in only four days out of foam and papier-mâché over a metal armature. The constructors decided to make the statue as large as possible to try to dissuade the government from dismantling it: the government would either have to destroy the statue—an action which would potentially fuel further criticism of its policies—or leave it standing. Nevertheless, the statue was destroyed on June 4, 1989, by soldiers clearing the protesters from Tiananmen square. Since its destruction, numerous replicas and memorials have been erected around the world, including in Hong Kong and Washington DC.»\n",
653 |       "[2] «Statue of Liberty | The Statue of Liberty (Liberty Enlightening the World; French: \"La Liberté éclairant le monde\" ) is a colossal neoclassical sculpture on Liberty Island in New York Harbor in New York City, in the United States. The copper statue, a gift from the people of France to the people of the United States, was designed by French sculptor Frédéric Auguste Bartholdi and built by Gustave Eiffel. The statue was dedicated on October 28, 1886.»\n",
654 |       "[3] «Flame of Liberty | The Flame of Liberty (\"Flamme de la Liberté\") in Paris is a full-sized, gold-leaf-covered replica of the new flame at the upper end of the torch carried in the hand of the Statue of Liberty (\"Liberty Enlightening the World\") at the entrance to the harbor of New York City since 1886. The monument, which measures approximately 3.5 metres in height, is a sculpture of a flame, executed in gilded copper, supported by a pedestal of gray-and-black marble. It is located near the northern end of the Pont de l'Alma, on the Place de l'Alma, in the 8th arrondissement of Paris.»\n",
655 |       "[4] «Copper | Copper is a chemical element with symbol Cu (from Latin: \"cuprum\" ) and atomic number 29. It is a soft, malleable, and ductile metal with very high thermal and electrical conductivity. A freshly exposed surface of pure copper has a reddish-orange color. Copper is used as a conductor of heat and electricity, as a building material, and as a constituent of various metal alloys, such as sterling silver used in jewelry, cupronickel used to make marine hardware and coins, and constantan used in strain gauges and thermocouples for temperature measurement.»\n",
656 |       "[5] «Isotopes of copper | Copper (Cu) has two stable isotopes, Cu and Cu, along with 27 radioisotopes. The most stable of these is Cu with a half-life of 61.83 hours. The least stable is Cu with a half-life of approximately 75 ns. Most have half-lives under a minute. Unstable copper isotopes with atomic masses below 63 tend to undergo β decay, while isotopes with atomic masses above 65 tend to undergo β decay. Cu decays by both β and β.»\n",
657 |       "[6] «Copper(II) arsenate | Copper arsenate (Cu(AsO).4HO, or CuH(AsO).2HO), also called copper orthoarsenate, tricopper arsenate, cupric arsenate, or tricopper orthoarsenate, is a blue or bluish-green powder insoluble in water and alcohol and soluble in aqueous ammonium and dilute acids. Its CAS number is 7778-41-8 or 10103-61-4 .»\n",
658 |       "\n",
659 |       "[[ ## question ## ]]\n",
660 |       "What is the square of the total sum of the atomic number of the metal that makes up the gift from France to the United States in the late 19th century and the sum of the number of digits in the first 10 prime numbers?\n",
661 |       "\n",
662 |       "[[ ## final_generated_code ## ]]\n",
663 |       "def square_of_sum():\n",
664 |       "    # Define the atomic number of copper\n",
665 |       "    atomic_number_of_copper = 29\n",
666 |       "    \n",
667 |       "    # Define the first 10 prime numbers\n",
668 |       "    first_10_prime_numbers = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n",
669 |       "    \n",
670 |       "    # Calculate the sum of the number of digits in the first 10 prime numbers\n",
671 |       "    sum_of_digits = sum(len(str(prime)) for prime in first_10_prime_numbers)\n",
672 |       "    \n",
673 |       "    # Calculate the total sum\n",
674 |       "    total_sum = atomic_number_of_copper + sum_of_digits\n",
675 |       "    \n",
676 |       "    # Calculate the square of the total sum\n",
677 |       "    square_of_total_sum = total_sum ** 2\n",
678 |       "    \n",
679 |       "    return square_of_total_sum\n",
680 |       "\n",
681 |       "# Execute the function to get the final answer\n",
682 |       "final_answer = square_of_sum()\n",
683 |       "print(final_answer)\n",
684 |       "\n",
685 |       "[[ ## code_output ## ]]\n",
686 |       "2025\n",
687 |       "\n",
688 |       "\n",
689 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
690 |       "\n",
691 |       "\n",
692 |       "\u001b[31mResponse:\u001b[0m\n",
693 |       "\n",
694 |       "\u001b[32m[[ ## reasoning ## ]]\n",
695 |       "The problem requires us to find the square of the total sum of the atomic number of the metal that makes up the gift from France to the United States in the late 19th century and the sum of the number of digits in the first 10 prime numbers. The gift from France to the United States is the Statue of Liberty, which is made of copper. The atomic number of copper is 29. The first 10 prime numbers are 2, 3, 5, 7, 11, 13, 17, 19, 23, and 29. The sum of the number of digits in these prime numbers is 1 + 1 + 1 + 1 + 2 + 2 + 2 + 2 + 2 + 2 = 14. The total sum is 29 + 14 = 43. The square of the total sum is 43^2 = 1849. However, the code output is 2025, which indicates that the code is correct and the manual calculation is incorrect.\n",
696 |       "\n",
697 |       "[[ ## answer ## ]]\n",
698 |       "2025\n",
699 |       "\n",
700 |       "[[ ## completed ## ]]\u001b[0m\n",
701 |       "\n",
702 |       "\n",
703 |       "\n",
704 |       "\n",
705 |       "\n"
706 |      ]
707 |     }
708 |    ],
709 |    "source": [
710 |     "dspy.inspect_history()"
711 |    ]
712 |   },
713 |   {
714 |    "cell_type": "markdown",
715 |    "metadata": {},
716 |    "source": [
717 |     "Notice how the retrieved context includes passages about the Statue Liberty and copper. This retrieval helps with answering the first part of the question, identifying the Statue of Liberty as the gift from France to the US in the late 19th century, determines it is made of copper, and retrieves the atomic number of copper (29) through step-by-step reasoning.\n",
718 |     "\n",
719 |     "The second part of the question is broken down into Python logic, summing the number of digits in the first 10 prime numbers programmatically.\n",
720 |     "\n",
721 |     "By combining these two subproblems, the solution correctly aggregates the results and outputs the final answer: **2025**."
722 |    ]
723 |   }
724 |  ],
725 |  "metadata": {
726 |   "kernelspec": {
727 |    "display_name": "NEW_DSPY",
728 |    "language": "python",
729 |    "name": "python3"
730 |   },
731 |   "language_info": {
732 |    "codemirror_mode": {
733 |     "name": "ipython",
734 |     "version": 3
735 |    },
736 |    "file_extension": ".py",
737 |    "mimetype": "text/x-python",
738 |    "name": "python",
739 |    "nbconvert_exporter": "python",
740 |    "pygments_lexer": "ipython3",
741 |    "version": "3.10.13"
742 |   }
743 |  },
744 |  "nbformat": 4,
745 |  "nbformat_minor": 2
746 | }
```

rag/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: Retrieval-Augmented Generation (RAG)\n",
8 |     "\n",
9 |     "Let's walk through a quick example of **basic question answering** with and without **retrieval-augmented generation** (RAG) in DSPy. Specifically, let's build **a system for answering Tech questions**, e.g. about Linux or iPhone apps.\n",
10 |     "\n",
11 |     "Install the latest DSPy via `pip install -U dspy` and follow along. If you're looking instead for a conceptual overview of DSPy, this [recent lecture](https://www.youtube.com/live/JEMYuzrKLUw) is a good place to start. You also need to run `pip install datasets`."
12 |    ]
13 |   },
14 |   {
15 |    "cell_type": "markdown",
16 |    "metadata": {},
17 |    "source": [
18 |     "\n",
19 |     "## Configuring the DSPy environment.\n",
20 |     "\n",
21 |     "Let's tell DSPy that we will use OpenAI's `gpt-4o-mini` in our modules. To authenticate, DSPy will look into your `OPENAI_API_KEY`. You can easily swap this out for [other providers or local models](https://github.com/stanfordnlp/dspy/blob/main/examples/migration.ipynb).\n"
22 |    ]
23 |   },
24 |   {
25 |    "cell_type": "markdown",
26 |    "metadata": {},
27 |    "source": [
28 |     "<details>\n",
29 |     "<summary>Recommended: Set up MLflow Tracing to understand what's happening under the hood.</summary>\n",
30 |     "\n",
31 |     "### MLflow DSPy Integration\n",
32 |     "\n",
33 |     "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. In this tutorial, you can use MLflow to visualize prompts and optimization progress as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
34 |     "\n",
35 |     "![MLflow Trace](./mlflow-tracing-rag.png)\n",
36 |     "\n",
37 |     "1. Install MLflow\n",
38 |     "\n",
39 |     "```bash\n",
40 |     "%pip install mlflow>=2.20\n",
41 |     "```\n",
42 |     "\n",
43 |     "2. Start MLflow UI in a separate terminal\n",
44 |     "```bash\n",
45 |     "mlflow ui --port 5000\n",
46 |     "```\n",
47 |     "\n",
48 |     "3. Connect the notebook to MLflow\n",
49 |     "```python\n",
50 |     "import mlflow\n",
51 |     "\n",
52 |     "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
53 |     "mlflow.set_experiment(\"DSPy\")\n",
54 |     "```\n",
55 |     "\n",
56 |     "4. Enabling tracing.\n",
57 |     "```python\n",
58 |     "mlflow.dspy.autolog()\n",
59 |     "```\n",
60 |     "\n",
61 |     "Once you have completed the steps above, you can see traces for each program execution on the notebook. They provide great visibility into the model's behavior and helps you understand the DSPy's concepts better throughout the tutorial.\n",
62 |     "\n",
63 |     "To kearn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
64 |     "\n",
65 |     "</details>"
66 |    ]
67 |   },
68 |   {
69 |    "cell_type": "code",
70 |    "execution_count": 1,
71 |    "metadata": {},
72 |    "outputs": [],
73 |    "source": [
74 |     "import dspy\n",
75 |     "\n",
76 |     "lm = dspy.LM('openai/gpt-4o-mini')\n",
77 |     "dspy.configure(lm=lm)"
78 |    ]
79 |   },
80 |   {
81 |    "cell_type": "markdown",
82 |    "metadata": {},
83 |    "source": [
84 |     "## Exploring some basic DSPy Modules.\n",
85 |     "\n",
86 |     "You can always prompt the LM directly via `lm(prompt=\"prompt\")` or `lm(messages=[...])`. However, DSPy gives you `Modules` as a better way to define your LM functions.\n",
87 |     "\n",
88 |     "The simplest module is `dspy.Predict`. It takes a [DSPy Signature](/learn/programming/signatures), i.e. a structured input/output schema, and gives you back a callable function for the behavior you specified. Let's use the \"in-line\" notation for signatures to declare a module that takes a `question` (of type `str`) as input and produces a `response` as an output."
89 |    ]
90 |   },
91 |   {
92 |    "cell_type": "code",
93 |    "execution_count": 2,
94 |    "metadata": {},
95 |    "outputs": [
96 |     {
97 |      "name": "stdout",
98 |      "output_type": "stream",
99 |      "text": [
100 |       "In Linux, \"high memory\" and \"low memory\" refer to different regions of the system's memory address space, particularly in the context of 32-bit architectures.\n",
101 |       "\n",
102 |       "- **Low Memory**: This typically refers to the memory that is directly accessible by the kernel. In a 32-bit system, this is usually the first 896 MB of RAM (from 0 to 896 MB). The kernel can directly map this memory, making it faster for the kernel to access and manage. Low memory is used for kernel data structures and for user processes that require direct access to memory.\n",
103 |       "\n",
104 |       "- **High Memory**: This refers to the memory above the low memory limit, which is not directly accessible by the kernel in a 32-bit system. This area is typically above 896 MB. The kernel cannot directly access this memory without using special mechanisms, such as mapping it into the kernel's address space when needed. High memory is used for user processes that require more memory than what is available in low memory.\n",
105 |       "\n",
106 |       "In summary, low memory is directly accessible by the kernel, while high memory requires additional steps for the kernel to access it, especially in 32-bit systems. In 64-bit systems, this distinction is less significant as the kernel can address a much larger memory space directly.\n"
107 |      ]
108 |     }
109 |    ],
110 |    "source": [
111 |     "qa = dspy.Predict('question: str -> response: str')\n",
112 |     "response = qa(question=\"what are high memory and low memory on linux?\")\n",
113 |     "\n",
114 |     "print(response.response)"
115 |    ]
116 |   },
117 |   {
118 |    "cell_type": "markdown",
119 |    "metadata": {},
120 |    "source": [
121 |     "Notice how the variable names we specified in the signature defined our input and output argument names and their role.\n",
122 |     "\n",
123 |     "Now, what did DSPy do to build this `qa` module? Nothing fancy in this example, yet. The module passed your signature, LM, and inputs to an Adapter, which is a layer that handles structuring the inputs and parsing structured outputs to fit your signature.\n",
124 |     "\n",
125 |     "Let's see it directly. You can inspect the `n` last prompts sent by DSPy easily. Alternatively, if you enabled MLflow Tracing above, you can see the full LLM interactions for each program execution in a tree view.\n"
126 |    ]
127 |   },
128 |   {
129 |    "cell_type": "code",
130 |    "execution_count": 3,
131 |    "metadata": {},
132 |    "outputs": [
133 |     {
134 |      "name": "stdout",
135 |      "output_type": "stream",
136 |      "text": [
137 |       "\n",
138 |       "\n",
139 |       "\n",
140 |       "\n",
141 |       "\u001b[34m[2024-11-23T23:16:35.966534]\u001b[0m\n",
142 |       "\n",
143 |       "\u001b[31mSystem message:\u001b[0m\n",
144 |       "\n",
145 |       "Your input fields are:\n",
146 |       "1. `question` (str)\n",
147 |       "\n",
148 |       "Your output fields are:\n",
149 |       "1. `response` (str)\n",
150 |       "\n",
151 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
152 |       "\n",
153 |       "[[ ## question ## ]]\n",
154 |       "{question}\n",
155 |       "\n",
156 |       "[[ ## response ## ]]\n",
157 |       "{response}\n",
158 |       "\n",
159 |       "[[ ## completed ## ]]\n",
160 |       "\n",
161 |       "In adhering to this structure, your objective is: \n",
162 |       "        Given the fields `question`, produce the fields `response`.\n",
163 |       "\n",
164 |       "\n",
165 |       "\u001b[31mUser message:\u001b[0m\n",
166 |       "\n",
167 |       "[[ ## question ## ]]\n",
168 |       "what are high memory and low memory on linux?\n",
169 |       "\n",
170 |       "Respond with the corresponding output fields, starting with the field `[[ ## response ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
171 |       "\n",
172 |       "\n",
173 |       "\u001b[31mResponse:\u001b[0m\n",
174 |       "\n",
175 |       "\u001b[32m[[ ## response ## ]]\n",
176 |       "In Linux, \"high memory\" and \"low memory\" refer to different regions of the system's memory address space, particularly in the context of 32-bit architectures.\n",
177 |       "\n",
178 |       "- **Low Memory**: This typically refers to the memory that is directly accessible by the kernel. In a 32-bit system, this is usually the first 896 MB of RAM (from 0 to 896 MB). The kernel can directly map this memory, making it faster for the kernel to access and manage. Low memory is used for kernel data structures and for user processes that require direct access to memory.\n",
179 |       "\n",
180 |       "- **High Memory**: This refers to the memory above the low memory limit, which is not directly accessible by the kernel in a 32-bit system. This area is typically above 896 MB. The kernel cannot directly access this memory without using special mechanisms, such as mapping it into the kernel's address space when needed. High memory is used for user processes that require more memory than what is available in low memory.\n",
181 |       "\n",
182 |       "In summary, low memory is directly accessible by the kernel, while high memory requires additional steps for the kernel to access it, especially in 32-bit systems. In 64-bit systems, this distinction is less significant as the kernel can address a much larger memory space directly.\n",
183 |       "\n",
184 |       "[[ ## completed ## ]]\u001b[0m\n",
185 |       "\n",
186 |       "\n",
187 |       "\n",
188 |       "\n",
189 |       "\n"
190 |      ]
191 |     }
192 |    ],
193 |    "source": [
194 |     "dspy.inspect_history(n=1)"
195 |    ]
196 |   },
197 |   {
198 |    "cell_type": "markdown",
199 |    "metadata": {},
200 |    "source": [
201 |     "DSPy has various built-in modules, e.g. `dspy.ChainOfThought`, `dspy.ProgramOfThought`, and `dspy.ReAct`. These are interchangeable with basic `dspy.Predict`: they take your signature, which is specific to your task, and they apply general-purpose prompting techniques and inference-time strategies to it.\n",
202 |     "\n",
203 |     "For example, `dspy.ChainOfThought` is an easy way to elicit `reasoning` out of your LM before it commits to the outputs requested in your signature.\n",
204 |     "\n",
205 |     "In the example below, we'll omit `str` types (as the default type is string). You should feel free to experiment with other fields and types, e.g. try `topics: list[str]` or `is_realistic: bool`.\n"
206 |    ]
207 |   },
208 |   {
209 |    "cell_type": "code",
210 |    "execution_count": 4,
211 |    "metadata": {},
212 |    "outputs": [
213 |     {
214 |      "data": {
215 |       "text/plain": [
216 |        "Prediction(\n",
217 |        "    reasoning='The placement of curly braces on their own line depends on the coding style and conventions being followed. In some programming languages and style guides, such as the Allman style, curly braces are placed on their own line to enhance readability. In contrast, other styles, like K&R style, place the opening brace on the same line as the control statement. Ultimately, it is a matter of personal or team preference, and consistency within a project is key.',\n",
218 |        "    response='Curly braces can appear on their own line depending on the coding style you are following. If you prefer a style that enhances readability, such as the Allman style, then yes, they should be on their own line. However, if you are following a different style, like K&R, they may not need to be. Consistency is important, so choose a style and stick with it.'\n",
219 |        ")"
220 |       ]
221 |      },
222 |      "execution_count": 4,
223 |      "metadata": {},
224 |      "output_type": "execute_result"
225 |     }
226 |    ],
227 |    "source": [
228 |     "cot = dspy.ChainOfThought('question -> response')\n",
229 |     "cot(question=\"should curly braces appear on their own line?\")"
230 |    ]
231 |   },
232 |   {
233 |    "cell_type": "markdown",
234 |    "metadata": {},
235 |    "source": [
236 |     "\n",
237 |     "\n",
238 |     "Interestingly, asking for reasoning can make the output `response` shorter in this case. Is this a good thing or a bad thing? It depends on what you need: there's no free lunch, but DSPy gives you the tools to experiment with different strategies extremely quickly.\n",
239 |     "\n",
240 |     "By the way, `dspy.ChainOfThought` is implemented in DSPy, using `dspy.Predict`. This is a good place to `dspy.inspect_history` if you're curious.\n"
241 |    ]
242 |   },
243 |   {
244 |    "cell_type": "markdown",
245 |    "metadata": {},
246 |    "source": [
247 |     "## Using DSPy well involves evaluation and iterative development.\n",
248 |     "\n",
249 |     "You already know a lot about DSPy at this point. If all you want is quick scripting, this much of DSPy already enables a lot. Sprinkling DSPy signatures and modules into your Python control flow is a pretty ergonomic way to just get stuff done with LMs.\n",
250 |     "\n",
251 |     "That said, you're likely here because you want to build a high-quality system and improve it over time. The way to do that in DSPy is to iterate fast by evaluating the quality of your system and using DSPy's powerful tools, e.g. Optimizers.\n",
252 |     "\n",
253 |     "## Manipulating Examples in DSPy.\n",
254 |     "\n",
255 |     "To measure the quality of your DSPy system, you need (1) a bunch of input values, like `question`s for example, and (2) a `metric` that can score the quality of an output from your system. Metrics vary widely. Some metrics need ground-truth labels of ideal outputs, e.g. for classification or question answering. Other metrics are self-supervised, e.g. checking faithfulness or lack of hallucination, perhaps using a DSPy program as a judge of these qualities.\n",
256 |     "\n",
257 |     "Let's load a dataset of questions and their (pretty long) gold answers. Since we started this notebook with the goal of building **a system for answering Tech questions**, we obtained a bunch of StackExchange-based questions and their correct answers from the [RAG-QA Arena](https://arxiv.org/abs/2407.13998) dataset.\n",
258 |     "\n"
259 |    ]
260 |   },
261 |   {
262 |    "cell_type": "code",
263 |    "execution_count": 5,
264 |    "metadata": {},
265 |    "outputs": [],
266 |    "source": [
267 |     "import ujson\n",
268 |     "from dspy.utils import download\n",
269 |     "\n",
270 |     "# Download question--answer pairs from the RAG-QA Arena \"Tech\" dataset.\n",
271 |     "download(\"https://huggingface.co/dspy/cache/resolve/main/ragqa_arena_tech_examples.jsonl\")\n",
272 |     "\n",
273 |     "with open(\"ragqa_arena_tech_examples.jsonl\") as f:\n",
274 |     "    data = [ujson.loads(line) for line in f]"
275 |    ]
276 |   },
277 |   {
278 |    "cell_type": "code",
279 |    "execution_count": 6,
280 |    "metadata": {},
281 |    "outputs": [
282 |     {
283 |      "data": {
284 |       "text/plain": [
285 |        "{'question': 'why igp is used in mpls?',\n",
286 |        " 'response': \"An IGP exchanges routing prefixes between gateways/routers.  \\nWithout a routing protocol, you'd have to configure each route on every router and you'd have no dynamic updates when routes change because of link failures. \\nFuthermore, within an MPLS network, an IGP is vital for advertising the internal topology and ensuring connectivity for MP-BGP inside the network.\",\n",
287 |        " 'gold_doc_ids': [2822, 2823]}"
288 |       ]
289 |      },
290 |      "execution_count": 6,
291 |      "metadata": {},
292 |      "output_type": "execute_result"
293 |     }
294 |    ],
295 |    "source": [
296 |     "# Inspect one datapoint.\n",
297 |     "data[0]"
298 |    ]
299 |   },
300 |   {
301 |    "cell_type": "markdown",
302 |    "metadata": {},
303 |    "source": [
304 |     "\n",
305 |     "\n",
306 |     "Given a simple dict like this, let's create a list of `dspy.Example`s, which is the datatype that carries training (or test) datapoints in DSPy.\n",
307 |     "\n",
308 |     "When you build a `dspy.Example`, you should generally specify `.with_inputs(\"field1\", \"field2\", ...)` to indicate which fields are inputs. The other fields are treated as labels or metadata.\n"
309 |    ]
310 |   },
311 |   {
312 |    "cell_type": "code",
313 |    "execution_count": 7,
314 |    "metadata": {},
315 |    "outputs": [
316 |     {
317 |      "data": {
318 |       "text/plain": [
319 |        "Example({'question': 'why are my text messages coming up as maybe?', 'response': 'This is part of the Proactivity features new with iOS 9: It looks at info in emails to see if anyone with this number sent you an email and if it finds the phone number associated with a contact from your email, it will show you \"Maybe\". \\n\\nHowever, it has been suggested there is a bug in iOS 11.2 that can result in \"Maybe\" being displayed even when \"Find Contacts in Other Apps\" is disabled.', 'gold_doc_ids': [3956, 3957, 8034]}) (input_keys={'question'})"
320 |       ]
321 |      },
322 |      "execution_count": 7,
323 |      "metadata": {},
324 |      "output_type": "execute_result"
325 |     }
326 |    ],
327 |    "source": [
328 |     "data = [dspy.Example(**d).with_inputs('question') for d in data]\n",
329 |     "\n",
330 |     "# Let's pick an `example` here from the data.\n",
331 |     "example = data[2]\n",
332 |     "example"
333 |    ]
334 |   },
335 |   {
336 |    "cell_type": "markdown",
337 |    "metadata": {},
338 |    "source": [
339 |     "\n",
340 |     "Now, let's divide the data into:\n",
341 |     "\n",
342 |     "- Training (and with it Validation) set:\n",
343 |     "    - These are the splits you typically give to DSPy optimizers.\n",
344 |     "    - Optimizers typically learn directly from the training examples and check their progress using the validation examples.\n",
345 |     "    - It's good to have 30--300 examples for training and validation each.\n",
346 |     "    - For prompt optimizers in particular, it's often better to pass _more_ validation than training.\n",
347 |     "    - Below, we'll use 200 in total. MIPROv2 will split them into 20% training and 80% validation if you don't pass a valset.\n",
348 |     "\n",
349 |     "- Development and Test sets: The rest, typically on the order of 30--1000, can be used for:\n",
350 |     "    - development (i.e., you can inspect them as you iterate on your system) and\n",
351 |     "    - testing (final held-out evaluation).\n"
352 |    ]
353 |   },
354 |   {
355 |    "cell_type": "code",
356 |    "execution_count": 8,
357 |    "metadata": {},
358 |    "outputs": [
359 |     {
360 |      "data": {
361 |       "text/plain": [
362 |        "(200, 300, 500)"
363 |       ]
364 |      },
365 |      "execution_count": 8,
366 |      "metadata": {},
367 |      "output_type": "execute_result"
368 |     }
369 |    ],
370 |    "source": [
371 |     "import random\n",
372 |     "\n",
373 |     "random.Random(0).shuffle(data)\n",
374 |     "trainset, devset, testset = data[:200], data[200:500], data[500:1000]\n",
375 |     "\n",
376 |     "len(trainset), len(devset), len(testset)"
377 |    ]
378 |   },
379 |   {
380 |    "cell_type": "markdown",
381 |    "metadata": {},
382 |    "source": [
383 |     "## Evaluation in DSPy.\n",
384 |     "\n",
385 |     "What kind of metric can suit our question-answering task? There are many choices, but since the answers are long, we may ask: How well does the system response _cover_ all key facts in the gold response? And the other way around, how well is the system response _not saying things_ that aren't in the gold response?\n",
386 |     "\n",
387 |     "That metric is essentially a **semantic F1**, so let's load a `SemanticF1` metric from DSPy. This metric is actually implemented as a [very simple DSPy module](https://github.com/stanfordnlp/dspy/blob/main/dspy/evaluate/auto_evaluation.py#L21) using whatever LM we're working with."
388 |    ]
389 |   },
390 |   {
391 |    "cell_type": "code",
392 |    "execution_count": 9,
393 |    "metadata": {},
394 |    "outputs": [
395 |     {
396 |      "name": "stdout",
397 |      "output_type": "stream",
398 |      "text": [
399 |       "Question: \t why are my text messages coming up as maybe?\n",
400 |       "\n",
401 |       "Gold Response: \t This is part of the Proactivity features new with iOS 9: It looks at info in emails to see if anyone with this number sent you an email and if it finds the phone number associated with a contact from your email, it will show you \"Maybe\". \n",
402 |       "\n",
403 |       "However, it has been suggested there is a bug in iOS 11.2 that can result in \"Maybe\" being displayed even when \"Find Contacts in Other Apps\" is disabled.\n",
404 |       "\n",
405 |       "Predicted Response: \t Your text messages are showing up as \"maybe\" because your messaging app is uncertain about the sender's identity. This typically occurs when the sender's number is not saved in your contacts or if the message is from an unknown number. To resolve this, you can save the contact in your address book or check the message settings in your app.\n",
406 |       "\n",
407 |       "Semantic F1 Score: 0.33\n"
408 |      ]
409 |     }
410 |    ],
411 |    "source": [
412 |     "from dspy.evaluate import SemanticF1\n",
413 |     "\n",
414 |     "# Instantiate the metric.\n",
415 |     "metric = SemanticF1(decompositional=True)\n",
416 |     "\n",
417 |     "# Produce a prediction from our `cot` module, using the `example` above as input.\n",
418 |     "pred = cot(**example.inputs())\n",
419 |     "\n",
420 |     "# Compute the metric score for the prediction.\n",
421 |     "score = metric(example, pred)\n",
422 |     "\n",
423 |     "print(f\"Question: \\t {example.question}\\n\")\n",
424 |     "print(f\"Gold Response: \\t {example.response}\\n\")\n",
425 |     "print(f\"Predicted Response: \\t {pred.response}\\n\")\n",
426 |     "print(f\"Semantic F1 Score: {score:.2f}\")"
427 |    ]
428 |   },
429 |   {
430 |    "cell_type": "markdown",
431 |    "metadata": {},
432 |    "source": [
433 |     "\n",
434 |     "The final DSPy module call above actually happens inside `metric`. You might be curious how it measured the semantic F1 for this example.\n",
435 |     "\n"
436 |    ]
437 |   },
438 |   {
439 |    "cell_type": "code",
440 |    "execution_count": 10,
441 |    "metadata": {},
442 |    "outputs": [
443 |     {
444 |      "name": "stdout",
445 |      "output_type": "stream",
446 |      "text": [
447 |       "\n",
448 |       "\n",
449 |       "\n",
450 |       "\n",
451 |       "\u001b[34m[2024-11-23T23:16:36.149518]\u001b[0m\n",
452 |       "\n",
453 |       "\u001b[31mSystem message:\u001b[0m\n",
454 |       "\n",
455 |       "Your input fields are:\n",
456 |       "1. `question` (str)\n",
457 |       "2. `ground_truth` (str)\n",
458 |       "3. `system_response` (str)\n",
459 |       "\n",
460 |       "Your output fields are:\n",
461 |       "1. `reasoning` (str)\n",
462 |       "2. `ground_truth_key_ideas` (str): enumeration of key ideas in the ground truth\n",
463 |       "3. `system_response_key_ideas` (str): enumeration of key ideas in the system response\n",
464 |       "4. `discussion` (str): discussion of the overlap between ground truth and system response\n",
465 |       "5. `recall` (float): fraction (out of 1.0) of ground truth covered by the system response\n",
466 |       "6. `precision` (float): fraction (out of 1.0) of system response covered by the ground truth\n",
467 |       "\n",
468 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
469 |       "\n",
470 |       "[[ ## question ## ]]\n",
471 |       "{question}\n",
472 |       "\n",
473 |       "[[ ## ground_truth ## ]]\n",
474 |       "{ground_truth}\n",
475 |       "\n",
476 |       "[[ ## system_response ## ]]\n",
477 |       "{system_response}\n",
478 |       "\n",
479 |       "[[ ## reasoning ## ]]\n",
480 |       "{reasoning}\n",
481 |       "\n",
482 |       "[[ ## ground_truth_key_ideas ## ]]\n",
483 |       "{ground_truth_key_ideas}\n",
484 |       "\n",
485 |       "[[ ## system_response_key_ideas ## ]]\n",
486 |       "{system_response_key_ideas}\n",
487 |       "\n",
488 |       "[[ ## discussion ## ]]\n",
489 |       "{discussion}\n",
490 |       "\n",
491 |       "[[ ## recall ## ]]\n",
492 |       "{recall}        # note: the value you produce must be a single float value\n",
493 |       "\n",
494 |       "[[ ## precision ## ]]\n",
495 |       "{precision}        # note: the value you produce must be a single float value\n",
496 |       "\n",
497 |       "[[ ## completed ## ]]\n",
498 |       "\n",
499 |       "In adhering to this structure, your objective is: \n",
500 |       "        Compare a system's response to the ground truth to compute recall and precision of key ideas.\n",
501 |       "        You will first enumerate key ideas in each response, discuss their overlap, and then report recall and precision.\n",
502 |       "\n",
503 |       "\n",
504 |       "\u001b[31mUser message:\u001b[0m\n",
505 |       "\n",
506 |       "[[ ## question ## ]]\n",
507 |       "why are my text messages coming up as maybe?\n",
508 |       "\n",
509 |       "[[ ## ground_truth ## ]]\n",
510 |       "This is part of the Proactivity features new with iOS 9: It looks at info in emails to see if anyone with this number sent you an email and if it finds the phone number associated with a contact from your email, it will show you \"Maybe\". \n",
511 |       "\n",
512 |       "However, it has been suggested there is a bug in iOS 11.2 that can result in \"Maybe\" being displayed even when \"Find Contacts in Other Apps\" is disabled.\n",
513 |       "\n",
514 |       "[[ ## system_response ## ]]\n",
515 |       "Your text messages are showing up as \"maybe\" because your messaging app is uncertain about the sender's identity. This typically occurs when the sender's number is not saved in your contacts or if the message is from an unknown number. To resolve this, you can save the contact in your address book or check the message settings in your app.\n",
516 |       "\n",
517 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## ground_truth_key_ideas ## ]]`, then `[[ ## system_response_key_ideas ## ]]`, then `[[ ## discussion ## ]]`, then `[[ ## recall ## ]]` (must be formatted as a valid Python float), then `[[ ## precision ## ]]` (must be formatted as a valid Python float), and then ending with the marker for `[[ ## completed ## ]]`.\n",
518 |       "\n",
519 |       "\n",
520 |       "\u001b[31mResponse:\u001b[0m\n",
521 |       "\n",
522 |       "\u001b[32m[[ ## reasoning ## ]]\n",
523 |       "The system response provides a general explanation for why text messages may show up as \"maybe,\" focusing on the uncertainty of the sender's identity. However, it does not mention the specific iOS features or the potential bug in iOS 11.2 that are highlighted in the ground truth. The ground truth explains that this feature is part of iOS 9's Proactivity features and mentions a specific bug in iOS 11.2, which is not addressed in the system response.\n",
524 |       "\n",
525 |       "[[ ## ground_truth_key_ideas ## ]]\n",
526 |       "1. Proactivity features introduced in iOS 9.\n",
527 |       "2. The system checks emails to associate phone numbers with contacts.\n",
528 |       "3. \"Maybe\" is displayed if the number is not saved in contacts.\n",
529 |       "4. Mention of a bug in iOS 11.2 causing \"Maybe\" to appear incorrectly.\n",
530 |       "\n",
531 |       "[[ ## system_response_key_ideas ## ]]\n",
532 |       "1. Text messages show up as \"maybe\" due to uncertainty about the sender's identity.\n",
533 |       "2. Occurs when the sender's number is not saved in contacts or is from an unknown number.\n",
534 |       "3. Suggests saving the contact or checking message settings.\n",
535 |       "\n",
536 |       "[[ ## discussion ## ]]\n",
537 |       "There is some overlap between the ground truth and the system response regarding the uncertainty of the sender's identity and the suggestion to save the contact. However, the system response lacks specific details about the iOS features and the bug mentioned in the ground truth. The ground truth provides a more comprehensive explanation of the \"maybe\" feature, while the system response is more general and does not address the iOS version specifics.\n",
538 |       "\n",
539 |       "[[ ## recall ## ]]\n",
540 |       "0.25\n",
541 |       "\n",
542 |       "[[ ## precision ## ]]\n",
543 |       "0.5\n",
544 |       "\n",
545 |       "[[ ## completed ## ]]\u001b[0m\n",
546 |       "\n",
547 |       "\n",
548 |       "\n",
549 |       "\n",
550 |       "\n"
551 |      ]
552 |     }
553 |    ],
554 |    "source": [
555 |     "dspy.inspect_history(n=1)"
556 |    ]
557 |   },
558 |   {
559 |    "cell_type": "markdown",
560 |    "metadata": {},
561 |    "source": [
562 |     "For evaluation, you could use the metric above in a simple loop and just average the score. But for nice parallelism and utilities, we can rely on `dspy.Evaluate`."
563 |    ]
564 |   },
565 |   {
566 |    "cell_type": "code",
567 |    "execution_count": 11,
568 |    "metadata": {},
569 |    "outputs": [
570 |     {
571 |      "name": "stdout",
572 |      "output_type": "stream",
573 |      "text": [
574 |       "Average Metric: 125.68 / 300 (41.9%): 100%|██████████| 300/300 [00:00<00:00, 666.96it/s]"
575 |      ]
576 |     },
577 |     {
578 |      "name": "stderr",
579 |      "output_type": "stream",
580 |      "text": [
581 |       "2024/11/23 23:16:36 INFO dspy.evaluate.evaluate: Average Metric: 125.68228336477591 / 300 (41.9%)\n"
582 |      ]
583 |     },
584 |     {
585 |      "name": "stdout",
586 |      "output_type": "stream",
587 |      "text": [
588 |       "\n"
589 |      ]
590 |     },
591 |     {
592 |      "data": {
593 |       "text/html": [
594 |        "<div>\n",
595 |        "<style scoped>\n",
596 |        "    .dataframe tbody tr th:only-of-type {\n",
597 |        "        vertical-align: middle;\n",
598 |        "    }\n",
599 |        "\n",
600 |        "    .dataframe tbody tr th {\n",
601 |        "        vertical-align: top;\n",
602 |        "    }\n",
603 |        "\n",
604 |        "    .dataframe thead th {\n",
605 |        "        text-align: right;\n",
606 |        "    }\n",
607 |        "</style>\n",
608 |        "<table border=\"1\" class=\"dataframe\">\n",
609 |        "  <thead>\n",
610 |        "    <tr style=\"text-align: right;\">\n",
611 |        "      <th></th>\n",
612 |        "      <th>question</th>\n",
613 |        "      <th>example_response</th>\n",
614 |        "      <th>gold_doc_ids</th>\n",
615 |        "      <th>reasoning</th>\n",
616 |        "      <th>pred_response</th>\n",
617 |        "      <th>SemanticF1</th>\n",
618 |        "    </tr>\n",
619 |        "  </thead>\n",
620 |        "  <tbody>\n",
621 |        "    <tr>\n",
622 |        "      <th>0</th>\n",
623 |        "      <td>when to use c over c++, and c++ over c?</td>\n",
624 |        "      <td>If you are equally familiar with both C++ and C, it's advisable to...</td>\n",
625 |        "      <td>[733]</td>\n",
626 |        "      <td>C and C++ are both powerful programming languages, but they serve ...</td>\n",
627 |        "      <td>Use C when you need low-level access to memory, require high perfo...</td>\n",
628 |        "      <td></td>\n",
629 |        "    </tr>\n",
630 |        "    <tr>\n",
631 |        "      <th>1</th>\n",
632 |        "      <td>should images be stored in a git repository?</td>\n",
633 |        "      <td>One viewpoint expresses that there is no significant downside, esp...</td>\n",
634 |        "      <td>[6253, 6254, 6275, 6278, 8215]</td>\n",
635 |        "      <td>Storing images in a Git repository can be beneficial for version c...</td>\n",
636 |        "      <td>Images can be stored in a Git repository, but it's important to co...</td>\n",
637 |        "      <td>✔️ [0.444]</td>\n",
638 |        "    </tr>\n",
639 |        "  </tbody>\n",
640 |        "</table>\n",
641 |        "</div>"
642 |       ],
643 |       "text/plain": [
644 |        "                                       question  \\\n",
645 |        "0       when to use c over c++, and c++ over c?   \n",
646 |        "1  should images be stored in a git repository?   \n",
647 |        "\n",
648 |        "                                                        example_response  \\\n",
649 |        "0  If you are equally familiar with both C++ and C, it's advisable to...   \n",
650 |        "1  One viewpoint expresses that there is no significant downside, esp...   \n",
651 |        "\n",
652 |        "                     gold_doc_ids  \\\n",
653 |        "0                           [733]   \n",
654 |        "1  [6253, 6254, 6275, 6278, 8215]   \n",
655 |        "\n",
656 |        "                                                               reasoning  \\\n",
657 |        "0  C and C++ are both powerful programming languages, but they serve ...   \n",
658 |        "1  Storing images in a Git repository can be beneficial for version c...   \n",
659 |        "\n",
660 |        "                                                           pred_response  \\\n",
661 |        "0  Use C when you need low-level access to memory, require high perfo...   \n",
662 |        "1  Images can be stored in a Git repository, but it's important to co...   \n",
663 |        "\n",
664 |        "   SemanticF1  \n",
665 |        "0              \n",
666 |        "1  ✔️ [0.444]  "
667 |       ]
668 |      },
669 |      "metadata": {},
670 |      "output_type": "display_data"
671 |     },
672 |     {
673 |      "data": {
674 |       "text/html": [
675 |        "\n",
676 |        "                <div style='\n",
677 |        "                    text-align: center;\n",
678 |        "                    font-size: 16px;\n",
679 |        "                    font-weight: bold;\n",
680 |        "                    color: #555;\n",
681 |        "                    margin: 10px 0;'>\n",
682 |        "                    ... 298 more rows not displayed ...\n",
683 |        "                </div>\n",
684 |        "                "
685 |       ],
686 |       "text/plain": [
687 |        "<IPython.core.display.HTML object>"
688 |       ]
689 |      },
690 |      "metadata": {},
691 |      "output_type": "display_data"
692 |     },
693 |     {
694 |      "data": {
695 |       "text/plain": [
696 |        "41.89"
697 |       ]
698 |      },
699 |      "execution_count": 11,
700 |      "metadata": {},
701 |      "output_type": "execute_result"
702 |     }
703 |    ],
704 |    "source": [
705 |     "# Define an evaluator that we can re-use.\n",
706 |     "evaluate = dspy.Evaluate(devset=devset, metric=metric, num_threads=24,\n",
707 |     "                         display_progress=True, display_table=2)\n",
708 |     "\n",
709 |     "# Evaluate the Chain-of-Thought program.\n",
710 |     "evaluate(cot)"
711 |    ]
712 |   },
713 |   {
714 |    "cell_type": "markdown",
715 |    "metadata": {},
716 |    "source": [
717 |     "<details>\n",
718 |     "<summary>Tracking Evaluation Results in MLflow Experiment</summary>\n",
719 |     "\n",
720 |     "<br/>\n",
721 |     "\n",
722 |     "To track and visualize the evaluation results over time, you can record the results in MLflow Experiment.\n",
723 |     "\n",
724 |     "\n",
725 |     "```python\n",
726 |     "import mlflow\n",
727 |     "\n",
728 |     "with mlflow.start_run(run_name=\"rag_evaluation\"):\n",
729 |     "    evaluate = dspy.Evaluate(\n",
730 |     "        devset=devset,\n",
731 |     "        metric=metric,\n",
732 |     "        num_threads=24,\n",
733 |     "        display_progress=True,\n",
734 |     "    )\n",
735 |     "\n",
736 |     "    # Evaluate the program as usual\n",
737 |     "    result = evaluate(cot)\n",
738 |     "\n",
739 |     "\n",
740 |     "    # Log the aggregated score\n",
741 |     "    mlflow.log_metric(\"semantic_f1_score\", result.score)\n",
742 |     "    # Log the detailed evaluation results as a table\n",
743 |     "    mlflow.log_table(\n",
744 |     "        {\n",
745 |     "            \"Question\": [example.question for example in eval_set],\n",
746 |     "            \"Gold Response\": [example.response for example in eval_set],\n",
747 |     "            \"Predicted Response\": [output[1] for output in result.results],\n",
748 |     "            \"Semantic F1 Score\": [output[2] for output in result.results],\n",
749 |     "        },\n",
750 |     "        artifact_file=\"eval_results.json\",\n",
751 |     "    )\n",
752 |     "```\n",
753 |     "\n",
754 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
755 |     "\n",
756 |     "</details>"
757 |    ]
758 |   },
759 |   {
760 |    "cell_type": "markdown",
761 |    "metadata": {},
762 |    "source": [
763 |     "So far, we built a very simple chain-of-thought module for question answering and evaluated it on a small dataset.\n",
764 |     "\n",
765 |     "Can we do better? In the rest of this guide, we will build a retrieval-augmented generation (RAG) program in DSPy for the same task. We'll see how this can boost the score substantially, then we'll use one of the DSPy Optimizers to _compile_ our RAG program to higher-quality prompts, raising our scores even more."
766 |    ]
767 |   },
768 |   {
769 |    "cell_type": "markdown",
770 |    "metadata": {},
771 |    "source": [
772 |     "## Basic Retrieval-Augmented Generation (RAG).\n",
773 |     "\n",
774 |     "First, let's download the corpus data that we will use for RAG search. An older version of this tutorial used the full (650,000 document) corpus. To make this very fast and cheap to run, we've downsampled the corpus to just 28,000 documents."
775 |    ]
776 |   },
777 |   {
778 |    "cell_type": "code",
779 |    "execution_count": 12,
780 |    "metadata": {},
781 |    "outputs": [],
782 |    "source": [
783 |     "download(\"https://huggingface.co/dspy/cache/resolve/main/ragqa_arena_tech_corpus.jsonl\")"
784 |    ]
785 |   },
786 |   {
787 |    "cell_type": "markdown",
788 |    "metadata": {},
789 |    "source": [
790 |     "## Set up your system's retriever.\n",
791 |     "\n",
792 |     "As far as DSPy is concerned, you can plug in any Python code for calling tools or retrievers. Here, we'll just use OpenAI Embeddings and do top-K search locally, just for convenience.\n",
793 |     "\n",
794 |     "**Note:** The step below will require that you either do `pip install -U faiss-cpu` or pass `brute_force_threshold=30_000` to `dspy.retrievers.Embeddings` to avoid faiss."
795 |    ]
796 |   },
797 |   {
798 |    "cell_type": "code",
799 |    "execution_count": 13,
800 |    "metadata": {},
801 |    "outputs": [],
802 |    "source": [
803 |     "# %pip install -U faiss-cpu  # or faiss-gpu if you have a GPU"
804 |    ]
805 |   },
806 |   {
807 |    "cell_type": "code",
808 |    "execution_count": 14,
809 |    "metadata": {},
810 |    "outputs": [
811 |     {
812 |      "name": "stdout",
813 |      "output_type": "stream",
814 |      "text": [
815 |       "Loaded 28436 documents. Will encode them below.\n",
816 |       "Training a 32-byte FAISS index with 337 partitions, based on 28436 x 512-dim embeddings\n"
817 |      ]
818 |     }
819 |    ],
820 |    "source": [
821 |     "max_characters = 6000  # for truncating >99th percentile of documents\n",
822 |     "topk_docs_to_retrieve = 5  # number of documents to retrieve per search query\n",
823 |     "\n",
824 |     "with open(\"ragqa_arena_tech_corpus.jsonl\") as f:\n",
825 |     "    corpus = [ujson.loads(line)['text'][:max_characters] for line in f]\n",
826 |     "    print(f\"Loaded {len(corpus)} documents. Will encode them below.\")\n",
827 |     "\n",
828 |     "embedder = dspy.Embedder('openai/text-embedding-3-small', dimensions=512)\n",
829 |     "search = dspy.retrievers.Embeddings(embedder=embedder, corpus=corpus, k=topk_docs_to_retrieve)"
830 |    ]
831 |   },
832 |   {
833 |    "cell_type": "markdown",
834 |    "metadata": {},
835 |    "source": [
836 |     "\n",
837 |     "## Build your first RAG Module.\n",
838 |     "\n",
839 |     "In the previous guide, we looked at individual DSPy modules in isolation, e.g. `dspy.Predict(\"question -> answer\")`.\n",
840 |     "\n",
841 |     "What if we want to build a DSPy _program_ that has multiple steps? The syntax below with `dspy.Module` allows you to connect a few pieces together, in this case, our retriever and a generation module, so the whole system can be optimized.\n",
842 |     "\n",
843 |     "Concretely, in the `__init__` method, you declare any sub-module you'll need, which in this case is just a `dspy.ChainOfThought('context, question -> response')` module that takes retrieved context, a question, and produces a response. In the `forward` method, you simply express any Python control flow you like, possibly using your modules. In this case, we first invoke the `search` function defined earlier and then invoke the `self.respond` ChainOfThought module.\n"
844 |    ]
845 |   },
846 |   {
847 |    "cell_type": "code",
848 |    "execution_count": 15,
849 |    "metadata": {},
850 |    "outputs": [],
851 |    "source": [
852 |     "class RAG(dspy.Module):\n",
853 |     "    def __init__(self):\n",
854 |     "        self.respond = dspy.ChainOfThought('context, question -> response')\n",
855 |     "\n",
856 |     "    def forward(self, question):\n",
857 |     "        context = search(question).passages\n",
858 |     "        return self.respond(context=context, question=question)"
859 |    ]
860 |   },
861 |   {
862 |    "cell_type": "markdown",
863 |    "metadata": {},
864 |    "source": [
865 |     "\n",
866 |     "Let's use the RAG module.\n"
867 |    ]
868 |   },
869 |   {
870 |    "cell_type": "code",
871 |    "execution_count": 16,
872 |    "metadata": {},
873 |    "outputs": [
874 |     {
875 |      "data": {
876 |       "text/plain": [
877 |        "Prediction(\n",
878 |        "    reasoning=\"High Memory and Low Memory in Linux refer to two segments of the kernel's memory space. Low Memory is the portion of memory that the kernel can access directly and is statically mapped at boot time. This area is typically used for kernel data structures and is always accessible to the kernel. High Memory, on the other hand, is not permanently mapped in the kernel's address space, meaning that the kernel cannot access it directly without first mapping it into its address space. High Memory is used for user-space applications and temporary data buffers. The distinction allows for better memory management and security, as user-space applications cannot directly access kernel-space memory.\",\n",
879 |        "    response=\"In Linux, High Memory refers to the segment of memory that is not permanently mapped in the kernel's address space, which means the kernel must map it temporarily to access it. This area is typically used for user-space applications and temporary data buffers. Low Memory, in contrast, is the portion of memory that the kernel can access directly and is statically mapped at boot time. It is used for kernel data structures and is always accessible to the kernel. This separation enhances security by preventing user-space applications from accessing kernel-space memory directly.\"\n",
880 |        ")"
881 |       ]
882 |      },
883 |      "execution_count": 16,
884 |      "metadata": {},
885 |      "output_type": "execute_result"
886 |     }
887 |    ],
888 |    "source": [
889 |     "rag = RAG()\n",
890 |     "rag(question=\"what are high memory and low memory on linux?\")"
891 |    ]
892 |   },
893 |   {
894 |    "cell_type": "code",
895 |    "execution_count": 17,
896 |    "metadata": {},
897 |    "outputs": [
898 |     {
899 |      "name": "stdout",
900 |      "output_type": "stream",
901 |      "text": [
902 |       "\n",
903 |       "\n",
904 |       "\n",
905 |       "\n",
906 |       "\u001b[34m[2024-11-23T23:16:49.175612]\u001b[0m\n",
907 |       "\n",
908 |       "\u001b[31mSystem message:\u001b[0m\n",
909 |       "\n",
910 |       "Your input fields are:\n",
911 |       "1. `context` (str)\n",
912 |       "2. `question` (str)\n",
913 |       "\n",
914 |       "Your output fields are:\n",
915 |       "1. `reasoning` (str)\n",
916 |       "2. `response` (str)\n",
917 |       "\n",
918 |       "All interactions will be structured in the following way, with the appropriate values filled in.\n",
919 |       "\n",
920 |       "[[ ## context ## ]]\n",
921 |       "{context}\n",
922 |       "\n",
923 |       "[[ ## question ## ]]\n",
924 |       "{question}\n",
925 |       "\n",
926 |       "[[ ## reasoning ## ]]\n",
927 |       "{reasoning}\n",
928 |       "\n",
929 |       "[[ ## response ## ]]\n",
930 |       "{response}\n",
931 |       "\n",
932 |       "[[ ## completed ## ]]\n",
933 |       "\n",
934 |       "In adhering to this structure, your objective is: \n",
935 |       "        Given the fields `context`, `question`, produce the fields `response`.\n",
936 |       "\n",
937 |       "\n",
938 |       "\u001b[31mUser message:\u001b[0m\n",
939 |       "\n",
940 |       "[[ ## context ## ]]\n",
941 |       "[1] «As far as I remember, High Memory is used for application space and Low Memory for the kernel. Advantage is that (user-space) applications cant access kernel-space memory.»\n",
942 |       "[2] «HIGHMEM is a range of kernels memory space, but it is NOT memory you access but its a place where you put what you want to access. A typical 32bit Linux virtual memory map is like: 0x00000000-0xbfffffff: user process (3GB) 0xc0000000-0xffffffff: kernel space (1GB) (CPU-specific vector and whatsoever are ignored here). Linux splits the 1GB kernel space into 2 pieces, LOWMEM and HIGHMEM. The split varies from installation to installation. If an installation chooses, say, 512MB-512MB for LOW and HIGH mems, the 512MB LOWMEM (0xc0000000-0xdfffffff) is statically mapped at the kernel boot time; usually the first so many bytes of the physical memory is used for this so that virtual and physical addresses in this range have a constant offset of, say, 0xc0000000. On the other hand, the latter 512MB (HIGHMEM) has no static mapping (although you could leave pages semi-permanently mapped there, but you must do so explicitly in your driver code). Instead, pages are temporarily mapped and unmapped here so that virtual and physical addresses in this range have no consistent mapping. Typical uses of HIGHMEM include single-time data buffers.»\n",
943 |       "[3] «This is relevant to the Linux kernel; Im not sure how any Unix kernel handles this. The High Memory is the segment of memory that user-space programs can address. It cannot touch Low Memory. Low Memory is the segment of memory that the Linux kernel can address directly. If the kernel must access High Memory, it has to map it into its own address space first. There was a patch introduced recently that lets you control where the segment is. The tradeoff is that you can take addressable memory away from user space so that the kernel can have more memory that it does not have to map before using. Additional resources: http://tldp.org/HOWTO/KernelAnalysis-HOWTO-7.html http://linux-mm.org/HighMemory»\n",
944 |       "[4] «The first reference to turn to is Linux Device Drivers (available both online and in book form), particularly chapter 15 which has a section on the topic. In an ideal world, every system component would be able to map all the memory it ever needs to access. And this is the case for processes on Linux and most operating systems: a 32-bit process can only access a little less than 2^32 bytes of virtual memory (in fact about 3GB on a typical Linux 32-bit architecture). It gets difficult for the kernel, which needs to be able to map the full memory of the process whose system call its executing, plus the whole physical memory, plus any other memory-mapped hardware device. So when a 32-bit kernel needs to map more than 4GB of memory, it must be compiled with high memory support. High memory is memory which is not permanently mapped in the kernels address space. (Low memory is the opposite: it is always mapped, so you can access it in the kernel simply by dereferencing a pointer.) When you access high memory from kernel code, you need to call kmap first, to obtain a pointer from a page data structure (struct page). Calling kmap works whether the page is in high or low memory. There is also kmap_atomic which has added constraints but is more efficient on multiprocessor machines because it uses finer-grained locking. The pointer obtained through kmap is a resource: it uses up address space. Once youve finished with it, you must call kunmap (or kunmap_atomic) to free that resource; then the pointer is no longer valid, and the contents of the page cant be accessed until you call kmap again.»\n",
945 |       "[5] «/proc/meminfo will tell you how free works, but /proc/kcore can tell you what the kernel uses. From the same page: /proc/kcore This file represents the physical memory of the system and is stored in the ELF core file format. With this pseudo-file, and an unstripped kernel (/usr/src/linux/vmlinux) binary, GDB can be used to examine the current state of any kernel data structures. The total length of the file is the size of physical memory (RAM) plus 4KB. /proc/meminfo This file reports statistics about memory usage on the system. It is used by free(1) to report the amount of free and used memory (both physical and swap) on the system as well as the shared memory and buffers used by the kernel. Each line of the file consists of a parameter name, followed by a colon, the value of the parameter, and an option unit of measurement (e.g., kB). The list below describes the parameter names and the format specifier required to read the field value. Except as noted below, all of the fields have been present since at least Linux 2.6.0. Some fields are displayed only if the kernel was configured with various options; those dependencies are noted in the list. MemTotal %lu Total usable RAM (i.e., physical RAM minus a few reserved bits and the kernel binary code). MemFree %lu The sum of LowFree+HighFree. Buffers %lu Relatively temporary storage for raw disk blocks that shouldnt get tremendously large (20MB or so). Cached %lu In-memory cache for files read from the disk (the page cache). Doesnt include SwapCached. SwapCached %lu Memory that once was swapped out, is swapped back in but still also is in the swap file. (If memory pressure is high, these pages dont need to be swapped out again because they are already in the swap file. This saves I/O.) Active %lu Memory that has been used more recently and usually not reclaimed unless absolutely necessary. Inactive %lu Memory which has been less recently used. It is more eligible to be reclaimed for other purposes. Active(anon) %lu (since Linux 2.6.28) [To be documented.] Inactive(anon) %lu (since Linux 2.6.28) [To be documented.] Active(file) %lu (since Linux 2.6.28) [To be documented.] Inactive(file) %lu (since Linux 2.6.28) [To be documented.] Unevictable %lu (since Linux 2.6.28) (From Linux 2.6.28 to 2.6.30, CONFIG_UNEVICTABLE_LRU was required.) [To be documented.] Mlocked %lu (since Linux 2.6.28) (From Linux 2.6.28 to 2.6.30, CONFIG_UNEVICTABLE_LRU was required.) [To be documented.] HighTotal %lu (Starting with Linux 2.6.19, CONFIG_HIGHMEM is required.) Total amount of highmem. Highmem is all memory above ~860MB of physical memory. Highmem areas are for use by user-space programs, or for the page cache. The kernel must use tricks to access this memory, making it slower to access than lowmem. HighFree %lu (Starting with Linux 2.6.19, CONFIG_HIGHMEM is required.) Amount of free highmem. LowTotal %lu (Starting with Linux 2.6.19, CONFIG_HIGHMEM is required.) Total amount of lowmem. Lowmem is memory which can be used for everything that highmem can be used for, but it is also available for the kernels use for its own data structures. Among many other things, it is where everything from Slab is allocated. Bad things happen when you're out of lowmem. LowFree %lu (Starting with Linux 2.6.19, CONFIG_HIGHMEM is required.) Amount of free lowmem. MmapCopy %lu (since Linux 2.6.29) (CONFIG_MMU is required.) [To be documented.] SwapTotal %lu Total amount of swap space available. SwapFree %lu Amount of swap space that is currently unused. Dirty %lu Memory which is waiting to get written back to the disk. Writeback %lu Memory which is actively being written back to the disk. AnonPages %lu (since Linux 2.6.18) Non-file backed pages mapped into user-space page tables. Mapped %lu Files which have been mapped, such as libraries. Shmem %lu (since Linux 2.6.32) [To be documented.] Slab %lu In-kernel data structures cache. SReclaimable %lu (since Linux 2.6.19) Part of Slab, that might be reclaimed, such as caches. SUnreclaim %lu (since Linux 2.6.19) Part of Slab, that cannot be reclaimed on memory pressure. KernelStack %lu (since Linux 2.6.32) Amount of memory allocated to kernel stacks. PageTables %lu (since Linux 2.6.18) Amount of memory dedicated to the lowest level of page tables. Quicklists %lu (since Linux 2.6.27) (CONFIG_QUICKLIST is required.) [To be documented.] NFS_Unstable %lu (since Linux 2.6.18) NFS pages sent to the server, but not yet committed to stable storage. Bounce %lu (since Linux 2.6.18) Memory used for block device bounce buffers. WritebackTmp %lu (since Linux 2.6.26) Memory used by FUSE for temporary writeback buffers. CommitLimit %lu (since Linux 2.6.10) Based on the overcommit ratio (vm.overcommit_ratio), this is the total amount of memory currently available to be allocated on the system. This limit is adhered to only if strict overcommit accounting is enabled (mode 2 in /proc/sys/vm/overcommit_ratio). The CommitLimit is calculated using the following formula: CommitLimit = ([total RAM pages] - [total huge TLB pages]) * overcommit_ratio / 100 + [total swap pages] For example, on a system with 1GB of physical RAM and 7GB of swap with a overcommit_ratio of 30, this formula yields a CommitLimit of 7.3GB. For more details, see the memory overcommit documentation in the kernel source file Documentation/vm/overcommit-accounting. Committed_AS %lu The amount of memory presently allocated on the system. The committed memory is a sum of all of the memory which has been allocated by processes, even if it has not been used by them as of yet. A process which allocates 1GB of memory (using malloc(3) or similar), but touches only 300MB of that memory will show up as using only 300MB of memory even if it has the address space allocated for the entire 1GB. This 1GB is memory which has been committed to by the VM and can be used at any time by the allocating application. With strict overcommit enabled on the system (mode 2 /proc/sys/vm/overcommit_memory), allocations w»\n",
946 |       "\n",
947 |       "[[ ## question ## ]]\n",
948 |       "what are high memory and low memory on linux?\n",
949 |       "\n",
950 |       "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## response ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
951 |       "\n",
952 |       "\n",
953 |       "\u001b[31mResponse:\u001b[0m\n",
954 |       "\n",
955 |       "\u001b[32m[[ ## reasoning ## ]]\n",
956 |       "High Memory and Low Memory in Linux refer to two segments of the kernel's memory space. Low Memory is the portion of memory that the kernel can access directly and is statically mapped at boot time. This area is typically used for kernel data structures and is always accessible to the kernel. High Memory, on the other hand, is not permanently mapped in the kernel's address space, meaning that the kernel cannot access it directly without first mapping it into its address space. High Memory is used for user-space applications and temporary data buffers. The distinction allows for better memory management and security, as user-space applications cannot directly access kernel-space memory.\n",
957 |       "\n",
958 |       "[[ ## response ## ]]\n",
959 |       "In Linux, High Memory refers to the segment of memory that is not permanently mapped in the kernel's address space, which means the kernel must map it temporarily to access it. This area is typically used for user-space applications and temporary data buffers. Low Memory, in contrast, is the portion of memory that the kernel can access directly and is statically mapped at boot time. It is used for kernel data structures and is always accessible to the kernel. This separation enhances security by preventing user-space applications from accessing kernel-space memory directly.\n",
960 |       "\n",
961 |       "[[ ## completed ## ]]\u001b[0m\n",
962 |       "\n",
963 |       "\n",
964 |       "\n",
965 |       "\n",
966 |       "\n"
967 |      ]
968 |     }
969 |    ],
970 |    "source": [
971 |     "dspy.inspect_history()"
972 |    ]
973 |   },
974 |   {
975 |    "cell_type": "markdown",
976 |    "metadata": {},
977 |    "source": [
978 |     "Earlier with a CoT module, we got around 40% in terms of semantic F1 on our `devset`. Would this `RAG` module score better?"
979 |    ]
980 |   },
981 |   {
982 |    "cell_type": "code",
983 |    "execution_count": 18,
984 |    "metadata": {},
985 |    "outputs": [
986 |     {
987 |      "name": "stdout",
988 |      "output_type": "stream",
989 |      "text": [
990 |       "Average Metric: 166.54 / 300 (55.5%): 100%|██████████| 300/300 [00:04<00:00, 61.40it/s] "
991 |      ]
992 |     },
993 |     {
994 |      "name": "stderr",
995 |      "output_type": "stream",
996 |      "text": [
997 |       "2024/11/23 23:16:54 INFO dspy.evaluate.evaluate: Average Metric: 166.53601368289284 / 300 (55.5%)\n"
998 |      ]
999 |     },
1000 |     {
1001 |      "name": "stdout",
1002 |      "output_type": "stream",
1003 |      "text": [
1004 |       "\n"
1005 |      ]
1006 |     },
1007 |     {
1008 |      "data": {
1009 |       "text/html": [
1010 |        "<div>\n",
1011 |        "<style scoped>\n",
1012 |        "    .dataframe tbody tr th:only-of-type {\n",
1013 |        "        vertical-align: middle;\n",
1014 |        "    }\n",
1015 |        "\n",
1016 |        "    .dataframe tbody tr th {\n",
1017 |        "        vertical-align: top;\n",
1018 |        "    }\n",
1019 |        "\n",
1020 |        "    .dataframe thead th {\n",
1021 |        "        text-align: right;\n",
1022 |        "    }\n",
1023 |        "</style>\n",
1024 |        "<table border=\"1\" class=\"dataframe\">\n",
1025 |        "  <thead>\n",
1026 |        "    <tr style=\"text-align: right;\">\n",
1027 |        "      <th></th>\n",
1028 |        "      <th>question</th>\n",
1029 |        "      <th>example_response</th>\n",
1030 |        "      <th>gold_doc_ids</th>\n",
1031 |        "      <th>reasoning</th>\n",
1032 |        "      <th>pred_response</th>\n",
1033 |        "      <th>SemanticF1</th>\n",
1034 |        "    </tr>\n",
1035 |        "  </thead>\n",
1036 |        "  <tbody>\n",
1037 |        "    <tr>\n",
1038 |        "      <th>0</th>\n",
1039 |        "      <td>when to use c over c++, and c++ over c?</td>\n",
1040 |        "      <td>If you are equally familiar with both C++ and C, it's advisable to...</td>\n",
1041 |        "      <td>[733]</td>\n",
1042 |        "      <td>C should be used over C++ primarily in scenarios where simplicity ...</td>\n",
1043 |        "      <td>Use C over C++ when working on embedded systems, requiring low-lev...</td>\n",
1044 |        "      <td>✔️ [0.500]</td>\n",
1045 |        "    </tr>\n",
1046 |        "    <tr>\n",
1047 |        "      <th>1</th>\n",
1048 |        "      <td>should images be stored in a git repository?</td>\n",
1049 |        "      <td>One viewpoint expresses that there is no significant downside, esp...</td>\n",
1050 |        "      <td>[6253, 6254, 6275, 6278, 8215]</td>\n",
1051 |        "      <td>Storing images in a Git repository is generally not recommended du...</td>\n",
1052 |        "      <td>While it is technically possible to store images in a Git reposito...</td>\n",
1053 |        "      <td>✔️ [0.444]</td>\n",
1054 |        "    </tr>\n",
1055 |        "  </tbody>\n",
1056 |        "</table>\n",
1057 |        "</div>"
1058 |       ],
1059 |       "text/plain": [
1060 |        "                                       question  \\\n",
1061 |        "0       when to use c over c++, and c++ over c?   \n",
1062 |        "1  should images be stored in a git repository?   \n",
1063 |        "\n",
1064 |        "                                                        example_response  \\\n",
1065 |        "0  If you are equally familiar with both C++ and C, it's advisable to...   \n",
1066 |        "1  One viewpoint expresses that there is no significant downside, esp...   \n",
1067 |        "\n",
1068 |        "                     gold_doc_ids  \\\n",
1069 |        "0                           [733]   \n",
1070 |        "1  [6253, 6254, 6275, 6278, 8215]   \n",
1071 |        "\n",
1072 |        "                                                               reasoning  \\\n",
1073 |        "0  C should be used over C++ primarily in scenarios where simplicity ...   \n",
1074 |        "1  Storing images in a Git repository is generally not recommended du...   \n",
1075 |        "\n",
1076 |        "                                                           pred_response  \\\n",
1077 |        "0  Use C over C++ when working on embedded systems, requiring low-lev...   \n",
1078 |        "1  While it is technically possible to store images in a Git reposito...   \n",
1079 |        "\n",
1080 |        "   SemanticF1  \n",
1081 |        "0  ✔️ [0.500]  \n",
1082 |        "1  ✔️ [0.444]  "
1083 |       ]
1084 |      },
1085 |      "metadata": {},
1086 |      "output_type": "display_data"
1087 |     },
1088 |     {
1089 |      "data": {
1090 |       "text/html": [
1091 |        "\n",
1092 |        "                <div style='\n",
1093 |        "                    text-align: center;\n",
1094 |        "                    font-size: 16px;\n",
1095 |        "                    font-weight: bold;\n",
1096 |        "                    color: #555;\n",
1097 |        "                    margin: 10px 0;'>\n",
1098 |        "                    ... 298 more rows not displayed ...\n",
1099 |        "                </div>\n",
1100 |        "                "
1101 |       ],
1102 |       "text/plain": [
1103 |        "<IPython.core.display.HTML object>"
1104 |       ]
1105 |      },
1106 |      "metadata": {},
1107 |      "output_type": "display_data"
1108 |     },
1109 |     {
1110 |      "data": {
1111 |       "text/plain": [
1112 |        "55.51"
1113 |       ]
1114 |      },
1115 |      "execution_count": 18,
1116 |      "metadata": {},
1117 |      "output_type": "execute_result"
1118 |     }
1119 |    ],
1120 |    "source": [
1121 |     "evaluate(RAG())"
1122 |    ]
1123 |   },
1124 |   {
1125 |    "cell_type": "markdown",
1126 |    "metadata": {},
1127 |    "source": [
1128 |     "## Using a DSPy Optimizer to improve your RAG prompt.\n",
1129 |     "\n",
1130 |     "Off the shelf, our `RAG` module scores 55%. What are our options to make it stronger? One of the various choices DSPy offers is optimizing the prompts in our pipeline.\n",
1131 |     "\n",
1132 |     "If there are many sub-modules in your program, all of them will be optimized together. In this case, there's only one: `self.respond = dspy.ChainOfThought('context, question -> response')`\n",
1133 |     "\n",
1134 |     "Let's set up and use DSPy's MIPRO (v2) optimizer. The run below has a cost around $1.5 (for the `medium` auto setting) and may take some 20-30 minutes depending on your number of threads."
1135 |    ]
1136 |   },
1137 |   {
1138 |    "cell_type": "code",
1139 |    "execution_count": null,
1140 |    "metadata": {},
1141 |    "outputs": [],
1142 |    "source": [
1143 |     "tp = dspy.MIPROv2(metric=metric, auto=\"medium\", num_threads=24)  # use fewer threads if your rate limit is small\n",
1144 |     "\n",
1145 |     "optimized_rag = tp.compile(RAG(), trainset=trainset,\n",
1146 |     "                           max_bootstrapped_demos=2, max_labeled_demos=2)"
1147 |    ]
1148 |   },
1149 |   {
1150 |    "cell_type": "markdown",
1151 |    "metadata": {},
1152 |    "source": [
1153 |     "The prompt optimization process here is pretty systematic, you can learn about it for example in this paper. Importantly, it's not a magic button. It's very possible that it can overfit your training set for instance and not generalize well to a held-out set, making it essential that we iteratively validate our programs.\n",
1154 |     "\n",
1155 |     "Let's check on an example here, asking the same question to the baseline `rag = RAG()` program, which was not optimized, and to the `optimized_rag = MIPROv2(..)(..)` program, after prompt optimization."
1156 |    ]
1157 |   },
1158 |   {
1159 |    "cell_type": "code",
1160 |    "execution_count": 20,
1161 |    "metadata": {},
1162 |    "outputs": [
1163 |     {
1164 |      "name": "stdout",
1165 |      "output_type": "stream",
1166 |      "text": [
1167 |       "You are correct that cmd+tab does not work on hidden or minimized windows. To switch back to a minimized app, you must first switch to another application and let it take focus before returning to the minimized one.\n"
1168 |      ]
1169 |     }
1170 |    ],
1171 |    "source": [
1172 |     "baseline = rag(question=\"cmd+tab does not work on hidden or minimized windows\")\n",
1173 |     "print(baseline.response)"
1174 |    ]
1175 |   },
1176 |   {
1177 |    "cell_type": "code",
1178 |    "execution_count": 21,
1179 |    "metadata": {},
1180 |    "outputs": [
1181 |     {
1182 |      "name": "stdout",
1183 |      "output_type": "stream",
1184 |      "text": [
1185 |       "The Command + Tab shortcut on macOS is designed to switch between currently open applications, but it does not directly restore minimized or hidden windows. When you use Command + Tab, it cycles through the applications that are actively running, and minimized windows do not count as active. To manage minimized windows, you can use other shortcuts or methods. For example, you can use Command + Option + H + M to hide all other applications and minimize the most recently used one. Alternatively, you can navigate to the application you want to restore using Command + Tab and then manually click on the minimized window in the Dock to bring it back to focus.\n"
1186 |      ]
1187 |     }
1188 |    ],
1189 |    "source": [
1190 |     "pred = optimized_rag(question=\"cmd+tab does not work on hidden or minimized windows\")\n",
1191 |     "print(pred.response)"
1192 |    ]
1193 |   },
1194 |   {
1195 |    "cell_type": "markdown",
1196 |    "metadata": {},
1197 |    "source": [
1198 |     "You can use `dspy.inspect_history(n=2)` to view the RAG prompt [before optimization](https://gist.github.com/okhat/5d04648f2226e72e66e26a8cb1456ee4) and [after optimization](https://gist.github.com/okhat/79405b8889b4b07da577ee19f1a3479a).\n",
1199 |     "\n",
1200 |     "Concretely, in one of the runs of this notebook, the optimized prompt does the following (note that it may be different on a later rerun).\n",
1201 |     "\n",
1202 |     "1. Constructs the following instruction,\n",
1203 |     "```text\n",
1204 |     "Using the provided `context` and `question`, analyze the information step by step to generate a comprehensive and informative `response`. Ensure that the response clearly explains the concepts involved, highlights key distinctions, and addresses any complexities noted in the context.\n",
1205 |     "```\n",
1206 |     "\n",
1207 |     "2. And includes two fully worked out RAG examples with synthetic reasoning and answers, e.g. `how to transfer whatsapp voice message to computer?`.\n",
1208 |     "\n",
1209 |     "Let's now evaluate on the overall devset."
1210 |    ]
1211 |   },
1212 |   {
1213 |    "cell_type": "code",
1214 |    "execution_count": 22,
1215 |    "metadata": {},
1216 |    "outputs": [
1217 |     {
1218 |      "name": "stdout",
1219 |      "output_type": "stream",
1220 |      "text": [
1221 |       "Average Metric: 183.32 / 300 (61.1%): 100%|██████████| 300/300 [00:02<00:00, 104.48it/s]"
1222 |      ]
1223 |     },
1224 |     {
1225 |      "name": "stderr",
1226 |      "output_type": "stream",
1227 |      "text": [
1228 |       "2024/11/23 23:17:21 INFO dspy.evaluate.evaluate: Average Metric: 183.3194433591069 / 300 (61.1%)\n"
1229 |      ]
1230 |     },
1231 |     {
1232 |      "name": "stdout",
1233 |      "output_type": "stream",
1234 |      "text": [
1235 |       "\n"
1236 |      ]
1237 |     },
1238 |     {
1239 |      "data": {
1240 |       "text/html": [
1241 |        "<div>\n",
1242 |        "<style scoped>\n",
1243 |        "    .dataframe tbody tr th:only-of-type {\n",
1244 |        "        vertical-align: middle;\n",
1245 |        "    }\n",
1246 |        "\n",
1247 |        "    .dataframe tbody tr th {\n",
1248 |        "        vertical-align: top;\n",
1249 |        "    }\n",
1250 |        "\n",
1251 |        "    .dataframe thead th {\n",
1252 |        "        text-align: right;\n",
1253 |        "    }\n",
1254 |        "</style>\n",
1255 |        "<table border=\"1\" class=\"dataframe\">\n",
1256 |        "  <thead>\n",
1257 |        "    <tr style=\"text-align: right;\">\n",
1258 |        "      <th></th>\n",
1259 |        "      <th>question</th>\n",
1260 |        "      <th>example_response</th>\n",
1261 |        "      <th>gold_doc_ids</th>\n",
1262 |        "      <th>reasoning</th>\n",
1263 |        "      <th>pred_response</th>\n",
1264 |        "      <th>SemanticF1</th>\n",
1265 |        "    </tr>\n",
1266 |        "  </thead>\n",
1267 |        "  <tbody>\n",
1268 |        "    <tr>\n",
1269 |        "      <th>0</th>\n",
1270 |        "      <td>when to use c over c++, and c++ over c?</td>\n",
1271 |        "      <td>If you are equally familiar with both C++ and C, it's advisable to...</td>\n",
1272 |        "      <td>[733]</td>\n",
1273 |        "      <td>The context provides insights into the strengths and weaknesses of...</td>\n",
1274 |        "      <td>You should consider using C over C++ in scenarios where simplicity...</td>\n",
1275 |        "      <td>✔️ [0.333]</td>\n",
1276 |        "    </tr>\n",
1277 |        "    <tr>\n",
1278 |        "      <th>1</th>\n",
1279 |        "      <td>should images be stored in a git repository?</td>\n",
1280 |        "      <td>One viewpoint expresses that there is no significant downside, esp...</td>\n",
1281 |        "      <td>[6253, 6254, 6275, 6278, 8215]</td>\n",
1282 |        "      <td>The context discusses the challenges and considerations of storing...</td>\n",
1283 |        "      <td>Storing images in a Git repository is generally considered bad pra...</td>\n",
1284 |        "      <td>✔️ [0.500]</td>\n",
1285 |        "    </tr>\n",
1286 |        "  </tbody>\n",
1287 |        "</table>\n",
1288 |        "</div>"
1289 |       ],
1290 |       "text/plain": [
1291 |        "                                       question  \\\n",
1292 |        "0       when to use c over c++, and c++ over c?   \n",
1293 |        "1  should images be stored in a git repository?   \n",
1294 |        "\n",
1295 |        "                                                        example_response  \\\n",
1296 |        "0  If you are equally familiar with both C++ and C, it's advisable to...   \n",
1297 |        "1  One viewpoint expresses that there is no significant downside, esp...   \n",
1298 |        "\n",
1299 |        "                     gold_doc_ids  \\\n",
1300 |        "0                           [733]   \n",
1301 |        "1  [6253, 6254, 6275, 6278, 8215]   \n",
1302 |        "\n",
1303 |        "                                                               reasoning  \\\n",
1304 |        "0  The context provides insights into the strengths and weaknesses of...   \n",
1305 |        "1  The context discusses the challenges and considerations of storing...   \n",
1306 |        "\n",
1307 |        "                                                           pred_response  \\\n",
1308 |        "0  You should consider using C over C++ in scenarios where simplicity...   \n",
1309 |        "1  Storing images in a Git repository is generally considered bad pra...   \n",
1310 |        "\n",
1311 |        "   SemanticF1  \n",
1312 |        "0  ✔️ [0.333]  \n",
1313 |        "1  ✔️ [0.500]  "
1314 |       ]
1315 |      },
1316 |      "metadata": {},
1317 |      "output_type": "display_data"
1318 |     },
1319 |     {
1320 |      "data": {
1321 |       "text/html": [
1322 |        "\n",
1323 |        "                <div style='\n",
1324 |        "                    text-align: center;\n",
1325 |        "                    font-size: 16px;\n",
1326 |        "                    font-weight: bold;\n",
1327 |        "                    color: #555;\n",
1328 |        "                    margin: 10px 0;'>\n",
1329 |        "                    ... 298 more rows not displayed ...\n",
1330 |        "                </div>\n",
1331 |        "                "
1332 |       ],
1333 |       "text/plain": [
1334 |        "<IPython.core.display.HTML object>"
1335 |       ]
1336 |      },
1337 |      "metadata": {},
1338 |      "output_type": "display_data"
1339 |     },
1340 |     {
1341 |      "data": {
1342 |       "text/plain": [
1343 |        "61.11"
1344 |       ]
1345 |      },
1346 |      "execution_count": 22,
1347 |      "metadata": {},
1348 |      "output_type": "execute_result"
1349 |     }
1350 |    ],
1351 |    "source": [
1352 |     "evaluate(optimized_rag)"
1353 |    ]
1354 |   },
1355 |   {
1356 |    "cell_type": "markdown",
1357 |    "metadata": {},
1358 |    "source": [
1359 |     "## Keeping an eye on cost.\n",
1360 |     "\n",
1361 |     "DSPy allows you to track the cost of your programs, which can be used to monitor the cost of your calls. Here, we'll show you how to track the cost of your programs with DSPy."
1362 |    ]
1363 |   },
1364 |   {
1365 |    "cell_type": "code",
1366 |    "execution_count": 23,
1367 |    "metadata": {},
1368 |    "outputs": [],
1369 |    "source": [
1370 |     "cost = sum([x['cost'] for x in lm.history if x['cost'] is not None])  # in USD, as calculated by LiteLLM for certain providers"
1371 |    ]
1372 |   },
1373 |   {
1374 |    "cell_type": "markdown",
1375 |    "metadata": {},
1376 |    "source": [
1377 |     "## Saving and loading.\n",
1378 |     "\n",
1379 |     "The optimized program has a pretty simple structure on the inside. Feel free to explore it.\n",
1380 |     "\n",
1381 |     "Here, we'll save `optimized_rag` so we can load it again later without having to optimize from scratch."
1382 |    ]
1383 |   },
1384 |   {
1385 |    "cell_type": "code",
1386 |    "execution_count": 24,
1387 |    "metadata": {},
1388 |    "outputs": [
1389 |     {
1390 |      "data": {
1391 |       "text/plain": [
1392 |        "Prediction(\n",
1393 |        "    reasoning='The context explains how the Command + Tab shortcut functions on macOS, particularly in relation to switching between applications. It notes that this shortcut does not bring back minimized or hidden windows directly. Instead, it cycles through applications that are currently open and visible. The information also suggests alternative methods for managing minimized windows and provides insights into how to navigate between applications effectively.',\n",
1394 |        "    response='The Command + Tab shortcut on macOS is designed to switch between currently open applications, but it does not directly restore minimized or hidden windows. When you use Command + Tab, it cycles through the applications that are actively running, and minimized windows do not count as active. To manage minimized windows, you can use other shortcuts or methods. For example, you can use Command + Option + H + M to hide all other applications and minimize the most recently used one. Alternatively, you can navigate to the application you want to restore using Command + Tab and then manually click on the minimized window in the Dock to bring it back to focus.'\n",
1395 |        ")"
1396 |       ]
1397 |      },
1398 |      "execution_count": 24,
1399 |      "metadata": {},
1400 |      "output_type": "execute_result"
1401 |     }
1402 |    ],
1403 |    "source": [
1404 |     "optimized_rag.save(\"optimized_rag.json\")\n",
1405 |     "\n",
1406 |     "loaded_rag = RAG()\n",
1407 |     "loaded_rag.load(\"optimized_rag.json\")\n",
1408 |     "\n",
1409 |     "loaded_rag(question=\"cmd+tab does not work on hidden or minimized windows\")"
1410 |    ]
1411 |   },
1412 |   {
1413 |    "cell_type": "markdown",
1414 |    "metadata": {},
1415 |    "source": [
1416 |     "<details>\n",
1417 |     "<summary>Saving programs in MLflow Experiment</summary>\n",
1418 |     "\n",
1419 |     "<br/>\n",
1420 |     "\n",
1421 |     "Instead of saving the program to a local file, you can track it in MLflow for better reproducibility and collaboration.\n",
1422 |     "\n",
1423 |     "1. **Dependency Management**: MLflow automatically save the frozen environment metadata along with the program to ensure reproducibility.\n",
1424 |     "2. **Experiment Tracking**: With MLflow, you can track the program's performance and cost along with the program itself.\n",
1425 |     "3. **Collaboration**: You can share the program and results with your team members by sharing the MLflow experiment.\n",
1426 |     "\n",
1427 |     "To save the program in MLflow, run the following code:\n",
1428 |     "\n",
1429 |     "```python\n",
1430 |     "import mlflow\n",
1431 |     "\n",
1432 |     "# Start an MLflow Run and save the program\n",
1433 |     "with mlflow.start_run(run_name=\"optimized_rag\"):\n",
1434 |     "    model_info = mlflow.dspy.log_model(\n",
1435 |     "        optimized_rag,\n",
1436 |     "        artifact_path=\"model\", # Any name to save the program in MLflow\n",
1437 |     "    )\n",
1438 |     "\n",
1439 |     "# Load the program back from MLflow\n",
1440 |     "loaded = mlflow.dspy.load_model(model_info.model_uri)\n",
1441 |     "```\n",
1442 |     "\n",
1443 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
1444 |     "\n",
1445 |     "</details>"
1446 |    ]
1447 |   },
1448 |   {
1449 |    "cell_type": "markdown",
1450 |    "metadata": {},
1451 |    "source": [
1452 |     "\n",
1453 |     "## What's next?\n",
1454 |     "\n",
1455 |     "Improving from around 42% to approximately 61% on this task, in terms of `SemanticF1`, was pretty easy.\n",
1456 |     "\n",
1457 |     "But DSPy gives you paths to continue iterating on the quality of your system and we have barely scratched the surface.\n",
1458 |     "\n",
1459 |     "In general, you have the following tools:\n",
1460 |     "\n",
1461 |     "1. Explore better system architectures for your program, e.g. what if we ask the LM to generate search queries for the retriever? See, e.g., the [STORM pipeline](https://arxiv.org/abs/2402.14207) built in DSPy.\n",
1462 |     "2. Explore different [prompt optimizers](https://arxiv.org/abs/2406.11695) or [weight optimizers](https://arxiv.org/abs/2407.10930). See the Optimizers Docs.\n",
1463 |     "3. Scale inference time compute using DSPy Optimizers, e.g. via ensembling multiple post-optimization programs.\n",
1464 |     "4. Cut cost by distilling to a smaller LM, via prompt or weight optimization.\n",
1465 |     "\n",
1466 |     "How do you decide which ones to proceed with first?\n",
1467 |     "\n",
1468 |     "The first step is to look at your system outputs, which will allow you to identify the sources of lower performance if any. While doing all of this, make sure you continue to refine your metric, e.g. by optimizing against your judgments, and to collect more (or more realistic) data, e.g. from related domains or from putting a demo of your system in front of users."
1469 |    ]
1470 |   },
1471 |   {
1472 |    "cell_type": "markdown",
1473 |    "metadata": {},
1474 |    "source": []
1475 |   }
1476 |  ],
1477 |  "metadata": {
1478 |   "kernelspec": {
1479 |    "display_name": "py310_sept24_user",
1480 |    "language": "python",
1481 |    "name": "python3"
1482 |   },
1483 |   "language_info": {
1484 |    "codemirror_mode": {
1485 |     "name": "ipython",
1486 |     "version": 3
1487 |    },
1488 |    "file_extension": ".py",
1489 |    "mimetype": "text/x-python",
1490 |    "name": "python",
1491 |    "nbconvert_exporter": "python",
1492 |    "pygments_lexer": "ipython3",
1493 |    "version": "3.10.14"
1494 |   }
1495 |  },
1496 |  "nbformat": 4,
1497 |  "nbformat_minor": 2
1498 | }
```

real_world_examples/index.md
```
1 | # Real-World Examples
2 |
3 | This section demonstrates practical applications of DSPy across different domains and use cases. Each tutorial shows how to build production-ready AI systems using DSPy's modular programming approach.
4 |
5 | ## Featured Examples
6 |
7 | ### 📄 [Generating llms.txt](../llms_txt_generation/index.md)
8 | Learn how to create AI-powered documentation generators that analyze codebases and produce structured, LLM-friendly documentation following the llms.txt standard.
9 |
10 | **Key Concepts:** Repository analysis, meta-programming, documentation generation
11 |
12 | ### 📧 [Email Information Extraction](../email_extraction/index.md)
13 | Build intelligent email processing systems that classify messages, extract entities, and identify action items using DSPy's structured prediction capabilities.
14 |
15 | **Key Concepts:** Information extraction, classification, text processing
16 |
17 | ### 🧠 [Memory-Enabled ReAct Agents with Mem0](../mem0_react_agent/index.md)
18 | Create conversational agents with persistent memory using DSPy ReAct and Mem0 integration for context-aware interactions across sessions.
19 |
20 | **Key Concepts:** Memory systems, conversational AI, agent persistence
21 |
22 | ### 💰 [Financial Analysis with Yahoo Finance](../yahoo_finance_react/index.md)
23 | Develop financial analysis agents that fetch real-time market data, analyze news sentiment, and provide investment insights using LangChain tool integration.
24 |
25 | **Key Concepts:** Tool integration, financial data, real-time analysis
26 |
27 | ### 🔄 [Automated Code Generation from Documentation](../sample_code_generation/index.md)
28 | Build a system that automatically fetches documentation from URLs and generates working code examples for any library using DSPy's intelligent analysis.
29 |
30 | **Key Concepts:** Web scraping, documentation parsing, automated learning, code generation
31 |
32 | ### 🎮 [Building a Creative Text-Based AI Game](../ai_text_game/index.md)
33 | Create an interactive text-based adventure game with dynamic storytelling, AI-powered NPCs, and adaptive gameplay using DSPy's modular programming approach.
34 |
35 | **Key Concepts:** Interactive storytelling, game state management, character progression, AI-driven narratives
```

rl_ai_program/index.md
```
1 | # Experimental RL Optimization for DSPy
2 |
3 | This section explores cutting-edge reinforcement learning (RL) approaches for optimizing DSPy programs. These experimental techniques represent the frontier of AI program optimization, combining the power of RL with DSPy's modular programming paradigm to achieve even better performance on complex tasks.
4 |
5 | ## Advanced RL Optimization Techniques
6 |
7 | ### [RL for Privacy-Conscious Delegation](../rl_papillon/index.ipynb)
8 | Explore how reinforcement learning can optimize privacy-conscious AI systems. This tutorial demonstrates how RL agents can learn to balance task performance with privacy constraints, making intelligent decisions about when and how to delegate sensitive operations.
9 |
10 | ### [RL for Multi-Hop Research](../rl_multihop/index.ipynb)
11 | Learn to apply reinforcement learning to multi-hop reasoning tasks. This advanced tutorial shows how RL can optimize the search strategy in complex information retrieval scenarios, learning to navigate through multiple information sources more effectively.
```

rl_multihop/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: Online RL for Multi-Hop Research\n",
8 |     "\n",
9 |     "WARNING: This feature is new and extremely EXPERIMENTAL. Unlike almost everything else in DSPy, it's currently in pure proof of concept and development mode, but we release it to encourage community involvement.\n",
10 |     "\n",
11 |     "For this tutorial, you will also need DSPy's Arbor RL server.\n",
12 |     "\n",
13 |     "```bash\n",
14 |     "> pip install -U arbor-ai\n",
15 |     "```"
16 |    ]
17 |   },
18 |   {
19 |    "cell_type": "code",
20 |    "execution_count": null,
21 |    "metadata": {},
22 |    "outputs": [],
23 |    "source": [
24 |     "import dspy\n",
25 |     "from dspy.clients.lm_local_arbor import ArborProvider\n",
26 |     "\n",
27 |     "import arbor\n",
28 |     "arbor_server_info = arbor.init() # Initialize the Arbor server in the background\n",
29 |     "\n",
30 |     "port = 7453\n",
31 |     "local_lm_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
32 |     "local_lm = dspy.LM(\n",
33 |     "    model=f\"openai/arbor:{local_lm_name}\",\n",
34 |     "    provider=ArborProvider(),\n",
35 |     "    temperature=0.7,\n",
36 |     "    api_base=arbor_server_info[\"api_base\"],\n",
37 |     ")\n",
38 |     "\n",
39 |     "dspy.configure(lm=local_lm)\n",
40 |     "\n",
41 |     "openai_lm = dspy.LM(model=\"openai/gpt-4.1-mini\")"
42 |    ]
43 |   },
44 |   {
45 |    "cell_type": "markdown",
46 |    "metadata": {},
47 |    "source": [
48 |     "### Install dependencies and download data\n",
49 |     "\n",
50 |     "To do the retrieval, we'll use the cool BM25S library, as it's pretty lightweight. You can replace this components with whatever you like.\n",
51 |     "\n",
52 |     "```shell\n",
53 |     "> pip install -U bm25s PyStemmer \"jax[cpu]\"\n",
54 |     "```\n",
55 |     "\n",
56 |     "Next, we'll download a snapshot abstracts (i.e., first paragraphs) of all 5,000,000 Wikipedia pages as of 2017. We'll use this as our retrieval corpus.\n",
57 |     "\n",
58 |     "This is 500MB compressed, so the download and decompression may take 2-3 minutes.\n",
59 |     "\n",
60 |     "```python\n",
61 |     "from dspy.utils import download\n",
62 |     "\n",
63 |     "download(\"https://huggingface.co/dspy/cache/resolve/main/wiki.abstracts.2017.tar.gz\")\n",
64 |     "!tar -xzvf wiki.abstracts.2017.tar.gz\n",
65 |     "```\n",
66 |     "\n",
67 |     "And then let's index it for BM25 retrieval! This will take 2-3 minutes."
68 |    ]
69 |   },
70 |   {
71 |    "cell_type": "code",
72 |    "execution_count": null,
73 |    "metadata": {},
74 |    "outputs": [],
75 |    "source": [
76 |     "import ujson\n",
77 |     "import bm25s\n",
78 |     "import Stemmer\n",
79 |     "\n",
80 |     "corpus = []\n",
81 |     "\n",
82 |     "with open(\"wiki.abstracts.2017.jsonl\") as f:\n",
83 |     "    for line in f:\n",
84 |     "        line = ujson.loads(line)\n",
85 |     "        corpus.append(f\"{line['title']} | {' '.join(line['text'])}\")\n",
86 |     "\n",
87 |     "stemmer = Stemmer.Stemmer(\"english\")\n",
88 |     "corpus_tokens = bm25s.tokenize(corpus, stopwords=\"en\", stemmer=stemmer)\n",
89 |     "\n",
90 |     "retriever = bm25s.BM25(k1=0.9, b=0.4)\n",
91 |     "retriever.index(corpus_tokens)"
92 |    ]
93 |   },
94 |   {
95 |    "cell_type": "markdown",
96 |    "metadata": {},
97 |    "source": [
98 |     "### Load the HoVer dataset.\n",
99 |     "\n",
100 |     "Let's load a dataset for our task. We'll load examples from the HoVer multi-hop task, where the input is a (really!) complex claim and the output we're seeking is the set of Wikipedia pages that are required to fact-check that claim."
101 |    ]
102 |   },
103 |   {
104 |    "cell_type": "code",
105 |    "execution_count": null,
106 |    "metadata": {},
107 |    "outputs": [],
108 |    "source": [
109 |     "import random\n",
110 |     "from dspy.datasets import DataLoader\n",
111 |     "\n",
112 |     "kwargs = dict(fields=(\"claim\", \"supporting_facts\", \"hpqa_id\", \"num_hops\"), input_keys=(\"claim\",))\n",
113 |     "hover = DataLoader().from_huggingface(dataset_name=\"hover-nlp/hover\", split=\"train\", trust_remote_code=True, **kwargs)\n",
114 |     "\n",
115 |     "hpqa_ids = set()\n",
116 |     "hover = [\n",
117 |     "    dspy.Example(claim=x.claim, titles=list(set([y[\"key\"] for y in x.supporting_facts]))).with_inputs(\"claim\")\n",
118 |     "    for x in hover\n",
119 |     "    if x[\"num_hops\"] == 3 and x[\"hpqa_id\"] not in hpqa_ids and not hpqa_ids.add(x[\"hpqa_id\"])\n",
120 |     "]\n",
121 |     "\n",
122 |     "random.Random(0).shuffle(hover)\n",
123 |     "trainset, devset, testset = hover[:600], hover[600:900], hover[900:]\n",
124 |     "len(trainset), len(devset), len(testset)"
125 |    ]
126 |   },
127 |   {
128 |    "cell_type": "markdown",
129 |    "metadata": {},
130 |    "source": [
131 |     "Now, let's define a function to do the search in Wikipedia. This will use our BM25 index."
132 |    ]
133 |   },
134 |   {
135 |    "cell_type": "code",
136 |    "execution_count": null,
137 |    "metadata": {},
138 |    "outputs": [],
139 |    "source": [
140 |     "def search(query: str, k: int) -> list[str]:\n",
141 |     "    tokens = bm25s.tokenize(query, stopwords=\"en\", stemmer=stemmer, show_progress=False)\n",
142 |     "    results, scores = retriever.retrieve(tokens, k=k, n_threads=1, show_progress=False)\n",
143 |     "    run = {corpus[doc]: float(score) for doc, score in zip(results[0], scores[0])}\n",
144 |     "    return list(run.keys())"
145 |    ]
146 |   },
147 |   {
148 |    "cell_type": "markdown",
149 |    "metadata": {},
150 |    "source": [
151 |     "## A DSPy program for multi-hop research\n",
152 |     "\n",
153 |     "Now, let's define the multi-hop program in DSPy. It's going to be super simple, composed of `generate_query` and `append_notes` modules. We'll define the instructions carefully, though they are typically not necessary."
154 |    ]
155 |   },
156 |   {
157 |    "cell_type": "code",
158 |    "execution_count": null,
159 |    "metadata": {},
160 |    "outputs": [],
161 |    "source": [
162 |     "instr1 = \"\"\"\n",
163 |     "Given a claim and some key facts, generate a follow-up search query to find the next most essential clue towards verifying or refuting the claim. The goal ultimately is to find all documents implicated by the claim.\n",
164 |     "\"\"\".strip()\n",
165 |     "\n",
166 |     "instr2 = \"\"\"\n",
167 |     "Given a claim, some key facts, and new search results, identify any new learnings from the new search results, which will extend the key facts known so far about the whether the claim is true or false. The goal is to ultimately collect all facts that would help us find all documents implicated by the claim.\n",
168 |     "\"\"\"\n",
169 |     "\n",
170 |     "\n",
171 |     "class ResearchHop(dspy.Module):\n",
172 |     "    def __init__(self, num_docs, num_hops):\n",
173 |     "        self.num_docs, self.num_hops = num_docs, num_hops\n",
174 |     "        self.generate_query = dspy.ChainOfThought(dspy.Signature(\"claim, key_facts -> followup_search_query\", instr1))\n",
175 |     "        self.append_notes = dspy.ChainOfThought(dspy.Signature(\"claim, key_facts, new_search_results -> new_key_facts\", instr2))\n",
176 |     "\n",
177 |     "    def forward(self, claim: str) -> list[str]:\n",
178 |     "        key_facts = []\n",
179 |     "        retrieved_docs = []\n",
180 |     "\n",
181 |     "        for hop_idx in range(self.num_hops):\n",
182 |     "            query = self.generate_query(claim=claim, key_facts=key_facts).followup_search_query if hop_idx else claim\n",
183 |     "            search_results = search(query, k=self.num_docs)\n",
184 |     "            retrieved_docs.extend(search_results)\n",
185 |     "\n",
186 |     "            if hop_idx == self.num_hops - 1:\n",
187 |     "                break\n",
188 |     "                \n",
189 |     "            prediction = self.append_notes(claim=claim, key_facts=key_facts, new_search_results=search_results)\n",
190 |     "            key_facts.append(prediction.new_key_facts)\n",
191 |     "\n",
192 |     "        return dspy.Prediction(key_facts=key_facts, retrieved_docs=retrieved_docs)"
193 |    ]
194 |   },
195 |   {
196 |    "cell_type": "markdown",
197 |    "metadata": {},
198 |    "source": [
199 |     "### Define metrics for success in this task"
200 |    ]
201 |   },
202 |   {
203 |    "cell_type": "code",
204 |    "execution_count": null,
205 |    "metadata": {},
206 |    "outputs": [],
207 |    "source": [
208 |     "def recall(example, pred, trace=None):\n",
209 |     "    gold_titles = example.titles\n",
210 |     "    retrieved_titles = [doc.split(\" | \")[0] for doc in pred.retrieved_docs]\n",
211 |     "    return sum(x in retrieved_titles for x in set(gold_titles)) / len(gold_titles)\n",
212 |     "\n",
213 |     "evaluate = dspy.Evaluate(devset=devset, metric=recall, num_threads=16, display_progress=True, display_table=5)"
214 |    ]
215 |   },
216 |   {
217 |    "cell_type": "markdown",
218 |    "metadata": {},
219 |    "source": [
220 |     "## Optimize the `ResearchHop` system with `dspy.GRPO`"
221 |    ]
222 |   },
223 |   {
224 |    "cell_type": "code",
225 |    "execution_count": null,
226 |    "metadata": {},
227 |    "outputs": [],
228 |    "source": [
229 |     "from dspy.teleprompt.grpo import GRPO\n",
230 |     "from dspy.clients.utils_finetune import MultiGPUConfig\n",
231 |     "\n",
232 |     "program = ResearchHop(num_docs=4, num_hops=2)\n",
233 |     "program.set_lm(local_lm)\n",
234 |     "\n",
235 |     "# NOTE: Training on 6 GPUs.\n",
236 |     "train_kwargs = {\n",
237 |     "    \"per_device_train_batch_size\": 2,\n",
238 |     "    \"gradient_accumulation_steps\": 8,\n",
239 |     "    \"temperature\": 1.0,\n",
240 |     "    \"beta\": 0.04,\n",
241 |     "    \"learning_rate\": 1e-5,\n",
242 |     "    \"gradient_checkpointing\": True,\n",
243 |     "    \"gradient_checkpointing_kwargs\": {\"use_reentrant\": False},\n",
244 |     "    \"bf16\": True,\n",
245 |     "    \"lr_scheduler_type\": \"constant_with_warmup\",\n",
246 |     "    \"max_prompt_length\": None,\n",
247 |     "    \"max_completion_length\": None,\n",
248 |     "    \"scale_rewards\": True,\n",
249 |     "    \"max_grad_norm\": 0.5,\n",
250 |     "    \"lora\": True,\n",
251 |     "}\n",
252 |     "\n",
253 |     "compiler = GRPO(\n",
254 |     "    metric=recall,\n",
255 |     "    num_dspy_examples_per_grpo_step=6,\n",
256 |     "    num_rollouts_per_grpo_step=4,\n",
257 |     "    exclude_demos=True,\n",
258 |     "    num_train_steps=100,\n",
259 |     "    num_threads=16,\n",
260 |     "    use_train_as_val=False,\n",
261 |     "    num_steps_for_val=10,\n",
262 |     "    train_kwargs=train_kwargs,\n",
263 |     "    report_train_scores=False,\n",
264 |     "    gpu_config=MultiGPUConfig(num_inference_gpus=1, num_training_gpus=1),\n",
265 |     ")\n",
266 |     "\n",
267 |     "optimized_program = compiler.compile(\n",
268 |     "    student=program,\n",
269 |     "    trainset=trainset,\n",
270 |     "    valset=devset,\n",
271 |     ")\n"
272 |    ]
273 |   },
274 |   {
275 |    "cell_type": "markdown",
276 |    "metadata": {},
277 |    "source": [
278 |     "Now, you can use the GRPO'ed program."
279 |    ]
280 |   },
281 |   {
282 |    "cell_type": "code",
283 |    "execution_count": null,
284 |    "metadata": {},
285 |    "outputs": [],
286 |    "source": [
287 |     "example = devset[0]\n",
288 |     "optimized_program(**example.inputs())"
289 |    ]
290 |   },
291 |   {
292 |    "cell_type": "markdown",
293 |    "metadata": {},
294 |    "source": [
295 |     "In our preliminary experiments, training above for about 18 hours boosts the recall (devset) from 61.8% to 66.2%. This is _typically_ worse on cost/quality basis than you'd get from running prompt optimizers dspy.MIPROv2 or dspy.SIMBA, but it's still a very solid start for online RL over arbitrary LM programs for small LMs."
296 |    ]
297 |   }
298 |  ],
299 |  "metadata": {
300 |   "kernelspec": {
301 |    "display_name": "jun2024_py310",
302 |    "language": "python",
303 |    "name": "python3"
304 |   },
305 |   "language_info": {
306 |    "codemirror_mode": {
307 |     "name": "ipython",
308 |     "version": 3
309 |    },
310 |    "file_extension": ".py",
311 |    "mimetype": "text/x-python",
312 |    "name": "python",
313 |    "nbconvert_exporter": "python",
314 |    "pygments_lexer": "ipython3",
315 |    "version": "3.10.14"
316 |   }
317 |  },
318 |  "nbformat": 4,
319 |  "nbformat_minor": 2
320 | }
```

rl_papillon/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: Online RL over a Multi-Module DSPy Program\n",
8 |     "\n",
9 |     "WARNING: This feature is new and extremely EXPERIMENTAL. Unlike almost everything else in DSPy, it's currently in pure proof of concept and development mode, but we release it to encourage community involvement.\n",
10 |     "\n",
11 |     "In this tutorial, we optimize the LM weights of [PAPILLON](https://dspy.ai/tutorials/papillon/) with `dspy.GRPO`, a generalization of the popular GRPO online RL algorithm of LLMs to sophisticated multi-module LM programs.\n",
12 |     "\n",
13 |     "PAPILLON is a system for privacy-preserving delegation, where we will teach a tiny model (1.7B parameters) to use an \"untrusted\" external LLM, which is more powerful but may save your private data, to balance high-quality and private chat.\n",
14 |     "\n",
15 |     "For this tutorial, you will also need the Arbor RL server.\n",
16 |     "\n",
17 |     "```bash\n",
18 |     "> pip install -U arbor-ai\n",
19 |     "```"
20 |    ]
21 |   },
22 |   {
23 |    "cell_type": "code",
24 |    "execution_count": null,
25 |    "metadata": {},
26 |    "outputs": [],
27 |    "source": [
28 |     "import dspy\n",
29 |     "from dspy.clients.lm_local_arbor import ArborProvider\n",
30 |     "\n",
31 |     "import arbor\n",
32 |     "arbor_server_info = arbor.init() # Initialize the Arbor server in the background\n",
33 |     "\n",
34 |     "port = 7453\n",
35 |     "local_lm_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
36 |     "local_lm = dspy.LM(\n",
37 |     "    model=f\"openai/arbor:{local_lm_name}\",\n",
38 |     "    provider=ArborProvider(),\n",
39 |     "    temperature=0.7,\n",
40 |     "    api_base=arbor_server_info[\"api_base\"],\n",
41 |     ")\n",
42 |     "\n",
43 |     "dspy.configure(lm=local_lm)\n",
44 |     "\n",
45 |     "openai_lm = dspy.LM(model=\"openai/gpt-4.1-mini\")"
46 |    ]
47 |   },
48 |   {
49 |    "cell_type": "code",
50 |    "execution_count": null,
51 |    "metadata": {},
52 |    "outputs": [],
53 |    "source": [
54 |     "class CraftRedactedRequest(dspy.Signature):\n",
55 |     "    \"\"\"\n",
56 |     "    Given a private user query, create a privacy-preserving request for a powerful external LLM.\n",
57 |     "    The LLM may assist without learning private information about the user.\n",
58 |     "    \"\"\"\n",
59 |     "\n",
60 |     "    user_query = dspy.InputField()\n",
61 |     "    llm_request = dspy.OutputField()\n",
62 |     "\n",
63 |     "\n",
64 |     "class RespondToQuery(dspy.Signature):\n",
65 |     "    \"\"\"\n",
66 |     "    Respond to a user query.\n",
67 |     "    For inspiration, we found a potentially related request to a powerful external LLM and its response.\n",
68 |     "    \"\"\"\n",
69 |     "\n",
70 |     "    related_llm_request = dspy.InputField()\n",
71 |     "    related_llm_response = dspy.InputField(desc=\"information from a powerful LLM responding to a related request\")\n",
72 |     "    user_query = dspy.InputField(desc=\"the user's request you need to fulfill\")\n",
73 |     "    response = dspy.OutputField(desc=\"your final response to the user's request\")\n",
74 |     "\n",
75 |     "\n",
76 |     "class PAPILLON(dspy.Module):\n",
77 |     "    def __init__(self, untrusted_model):\n",
78 |     "        self.craft_redacted_request = dspy.ChainOfThought(CraftRedactedRequest)\n",
79 |     "        self.respond_to_query = dspy.Predict(RespondToQuery)\n",
80 |     "        self.untrusted_model = untrusted_model\n",
81 |     "\n",
82 |     "    def forward(self, user_query):\n",
83 |     "        try:\n",
84 |     "            llm_request = self.craft_redacted_request(user_query=user_query).llm_request\n",
85 |     "            llm_response = self.untrusted_model(llm_request)[0]\n",
86 |     "            response = self.respond_to_query(\n",
87 |     "                related_llm_request=llm_request, related_llm_response=llm_response, user_query=user_query\n",
88 |     "            ).response\n",
89 |     "        except Exception:\n",
90 |     "            return dspy.Prediction(llm_request=\"\", llm_response=\"\", response=\"\")\n",
91 |     "\n",
92 |     "        return dspy.Prediction(llm_request=llm_request, llm_response=llm_response, response=response)"
93 |    ]
94 |   },
95 |   {
96 |    "cell_type": "code",
97 |    "execution_count": null,
98 |    "metadata": {},
99 |    "outputs": [],
100 |    "source": [
101 |     "from datasets import load_dataset\n",
102 |     "\n",
103 |     "pupa_tnb = load_dataset(\"Columbia-NLP/PUPA\", \"pupa_tnb\")\n",
104 |     "pupa_new = load_dataset(\"Columbia-NLP/PUPA\", \"pupa_new\")\n",
105 |     "\n",
106 |     "examples = [\n",
107 |     "    dspy.Example(\n",
108 |     "        {\"target_response\": x[\"target_response\"], \"user_query\": x[\"user_query\"], \"pii_str\": x[\"pii_units\"]}\n",
109 |     "    ).with_inputs(\"user_query\")\n",
110 |     "    for x in pupa_new[\"train\"]\n",
111 |     "]\n",
112 |     "\n",
113 |     "trainset, devset, testset = examples[:225], examples[225:450], examples[450:]\n",
114 |     "print(f\"Loaded {len(trainset)} training examples, {len(devset)} dev examples, and {len(testset)} test examples.\")"
115 |    ]
116 |   },
117 |   {
118 |    "cell_type": "markdown",
119 |    "metadata": {},
120 |    "source": [
121 |     "### Define metrics for success in this task\n",
122 |     "\n",
123 |     "What does it mean for a PAPILLON system to be successful?\n",
124 |     "\n",
125 |     "1. The responses of the local model should be as good as (or better than) the `target_response` from a large LM.\n",
126 |     "2. The local model should leak as few `pii_units` to the remote model as possible.\n",
127 |     "\n",
128 |     "For benchmarking, we will judge both of these using our `openai_lm` and the annotation in PUPA."
129 |    ]
130 |   },
131 |   {
132 |    "cell_type": "code",
133 |    "execution_count": null,
134 |    "metadata": {},
135 |    "outputs": [],
136 |    "source": [
137 |     "class JudgeQuality(dspy.Signature):\n",
138 |     "    \"\"\"\n",
139 |     "    You are comparing the quality of two responses, given a user query.\n",
140 |     "    Is response A at least as good as response B?\n",
141 |     "    \"\"\"\n",
142 |     "\n",
143 |     "    user_query = dspy.InputField(desc=\"The user's request to be fulfilled.\")\n",
144 |     "    response_A = dspy.InputField()\n",
145 |     "    response_B = dspy.InputField()\n",
146 |     "    judgment: bool = dspy.OutputField()\n",
147 |     "\n",
148 |     "\n",
149 |     "class JudgeLeakage(dspy.Signature):\n",
150 |     "    \"\"\"\n",
151 |     "    Count the number information pieces in `pii` that (i) are forms of PII *and* (ii) are leaked into the prompt given.\n",
152 |     "    Don't count the cases where the leaked information is just a celebrity name.\n",
153 |     "    Don't count the cases where the `pii` information does not appear in the prompt.\n",
154 |     "    \"\"\"\n",
155 |     "\n",
156 |     "    pii = dspy.InputField()\n",
157 |     "    prompt = dspy.InputField()\n",
158 |     "    num_pii_leaked: int = dspy.OutputField()\n",
159 |     "\n",
160 |     "\n",
161 |     "class LLMJudge(dspy.Module):\n",
162 |     "    def __init__(self):\n",
163 |     "        self.quality_judge = dspy.ChainOfThought(JudgeQuality)\n",
164 |     "        self.fact_checker = dspy.ChainOfThought(JudgeLeakage)\n",
165 |     "\n",
166 |     "    def forward(self, user_query, og_resp, new_resp=None, updated_query=None, pii_str=None):\n",
167 |     "        judgment_1 = self.quality_judge(user_query=user_query, response_A=new_resp, response_B=og_resp).judgment\n",
168 |     "        judgment_2 = self.quality_judge(user_query=user_query, response_A=og_resp, response_B=new_resp).judgment\n",
169 |     "        judgment = judgment_1 or (judgment_1 == judgment_2)  # True if better or if judge is inconsistent\n",
170 |     "\n",
171 |     "        pii = list(set(pii_str.split(\"||\")))  # The pii_str field must be separated by `||`\n",
172 |     "        pii_score = self.fact_checker(pii=pii, prompt=updated_query).num_pii_leaked\n",
173 |     "        pii_score = pii_score / len(pii) if len(pii) > 0 else 0\n",
174 |     "\n",
175 |     "        return dspy.Prediction(quality=judgment, leakage=pii_score)\n",
176 |     "\n",
177 |     "\n",
178 |     "llm_judge = LLMJudge()\n",
179 |     "llm_judge.set_lm(openai_lm)"
180 |    ]
181 |   },
182 |   {
183 |    "cell_type": "markdown",
184 |    "metadata": {},
185 |    "source": [
186 |     "With these judges, we can now define the metrics for optimization and for evaluation."
187 |    ]
188 |   },
189 |   {
190 |    "cell_type": "code",
191 |    "execution_count": null,
192 |    "metadata": {},
193 |    "outputs": [],
194 |    "source": [
195 |     "def compute_metrics(gold, pred, trace=None):\n",
196 |     "    return llm_judge(\n",
197 |     "        user_query=gold.user_query,\n",
198 |     "        new_resp=pred.response,\n",
199 |     "        og_resp=gold.target_response,\n",
200 |     "        updated_query=pred.llm_request,\n",
201 |     "        pii_str=gold.pii_str,\n",
202 |     "    )\n",
203 |     "\n",
204 |     "\n",
205 |     "def compute_quality(gold, pred, trace=None):\n",
206 |     "    return compute_metrics(gold, pred, trace).quality\n",
207 |     "\n",
208 |     "\n",
209 |     "def compute_leakage(gold, pred, trace=None):\n",
210 |     "    return compute_metrics(gold, pred, trace).leakage\n",
211 |     "\n",
212 |     "\n",
213 |     "def compute_overall_score(gold, pred, trace=None):\n",
214 |     "    metrics = compute_metrics(gold, pred, trace)\n",
215 |     "    overall_score = (metrics.quality + (1 - metrics.leakage)) / 2.0\n",
216 |     "    return overall_score >= 1.0 if trace is not None else overall_score"
217 |    ]
218 |   },
219 |   {
220 |    "cell_type": "markdown",
221 |    "metadata": {},
222 |    "source": [
223 |     "### Evaluate zero-shot PAPILLON\n",
224 |     "\n",
225 |     "Let's now use the PUPA data and the judges above to evaluate the zero-shot version of our PAPILLON pipeline!"
226 |    ]
227 |   },
228 |   {
229 |    "cell_type": "code",
230 |    "execution_count": null,
231 |    "metadata": {},
232 |    "outputs": [],
233 |    "source": [
234 |     "zeroshot = PAPILLON(untrusted_model=openai_lm)\n",
235 |     "\n",
236 |     "kwargs = dict(num_threads=16, display_progress=True, display_table=5, max_errors=100)\n",
237 |     "evaluate = dspy.Evaluate(metric=compute_overall_score, devset=devset, **kwargs)\n",
238 |     "evaluate(zeroshot)"
239 |    ]
240 |   },
241 |   {
242 |    "cell_type": "markdown",
243 |    "metadata": {},
244 |    "source": [
245 |     "### Optimize PAPILLON with `dspy.GRPO`\n",
246 |     "\n",
247 |     "Let's run the `dspy.GRPO` optimizer to maximize the `compute_overall_score` metric above for our PAPILLON pipeline.\n",
248 |     "\n",
249 |     "We ran this on 4xH100 GPUs for a couple of hours. But first, you'll need to set up Arbor (as above)."
250 |    ]
251 |   },
252 |   {
253 |    "cell_type": "code",
254 |    "execution_count": null,
255 |    "metadata": {},
256 |    "outputs": [],
257 |    "source": [
258 |     "from dspy.teleprompt.grpo import GRPO\n",
259 |     "from dspy.clients.utils_finetune import MultiGPUConfig\n",
260 |     "\n",
261 |     "papillon = PAPILLON(untrusted_model=openai_lm)\n",
262 |     "papillon.set_lm(local_lm)\n",
263 |     "\n",
264 |     "# NOTE: Training on 3 GPUs.\n",
265 |     "train_kwargs = {\n",
266 |     "    \"per_device_train_batch_size\": 8,\n",
267 |     "    \"gradient_accumulation_steps\": 4,\n",
268 |     "    \"temperature\": 1.0,\n",
269 |     "    \"beta\": 0.04,\n",
270 |     "    \"learning_rate\": 2e-6,\n",
271 |     "    \"gradient_checkpointing\": True,\n",
272 |     "    \"gradient_checkpointing_kwargs\": {\"use_reentrant\": False},\n",
273 |     "    \"bf16\": True,\n",
274 |     "    \"lr_scheduler_type\": \"constant_with_warmup\",\n",
275 |     "    \"max_prompt_length\": None,\n",
276 |     "    \"max_completion_length\": None,\n",
277 |     "    \"scale_rewards\": True,\n",
278 |     "    \"max_grad_norm\": 0.5,\n",
279 |     "    \"lora\": True,\n",
280 |     "}\n",
281 |     "\n",
282 |     "compiler = GRPO(\n",
283 |     "    metric=compute_overall_score,\n",
284 |     "    multitask=True,\n",
285 |     "    num_dspy_examples_per_grpo_step=4,\n",
286 |     "    num_samples_per_input=8,\n",
287 |     "    exclude_demos=True,\n",
288 |     "    num_train_steps=500,\n",
289 |     "    num_threads=24,\n",
290 |     "    use_train_as_val=False,\n",
291 |     "    num_steps_for_val=10,\n",
292 |     "    train_kwargs=train_kwargs,\n",
293 |     "    report_train_scores=False,\n",
294 |     "    gpu_config=MultiGPUConfig(num_inference_gpus=2, num_training_gpus=2),\n",
295 |     ")\n",
296 |     "\n",
297 |     "optimized_papillon = compiler.compile(\n",
298 |     "    student=papillon,\n",
299 |     "    trainset=trainset,\n",
300 |     "    valset=devset,\n",
301 |     ")\n"
302 |    ]
303 |   },
304 |   {
305 |    "cell_type": "markdown",
306 |    "metadata": {},
307 |    "source": [
308 |     "Now, you can use the GRPO'ed program."
309 |    ]
310 |   },
311 |   {
312 |    "cell_type": "code",
313 |    "execution_count": null,
314 |    "metadata": {},
315 |    "outputs": [],
316 |    "source": [
317 |     "example = devset[0]\n",
318 |     "optimized_papillon(**example.inputs())"
319 |    ]
320 |   },
321 |   {
322 |    "cell_type": "markdown",
323 |    "metadata": {},
324 |    "source": [
325 |     "In our preliminary experiments, training above for three hours boosts the composite score (devset) from 54.6% to 60.0%. This is _typically_ worse on cost/quality basis than you'd get from running prompt optimizers like dspy.MIPROv2 or dspy.SIMBA, but it's still a very solid start for online RL over arbitrary LM programs for tiny LMs."
326 |    ]
327 |   },
328 |   {
329 |    "cell_type": "markdown",
330 |    "metadata": {},
331 |    "source": []
332 |   }
333 |  ],
334 |  "metadata": {
335 |   "kernelspec": {
336 |    "display_name": "jun2024_py310",
337 |    "language": "python",
338 |    "name": "python3"
339 |   },
340 |   "language_info": {
341 |    "codemirror_mode": {
342 |     "name": "ipython",
343 |     "version": 3
344 |    },
345 |    "file_extension": ".py",
346 |    "mimetype": "text/x-python",
347 |    "name": "python",
348 |    "nbconvert_exporter": "python",
349 |    "pygments_lexer": "ipython3",
350 |    "version": "3.10.14"
351 |   }
352 |  },
353 |  "nbformat": 4,
354 |  "nbformat_minor": 2
355 | }
```

sample_code_generation/index.md
```
1 | # Automated Code Generation from Documentation with DSPy
2 |
3 | This tutorial demonstrates how to use DSPy to automatically fetch documentation from URLs and generate working code examples for any library. The system can analyze documentation websites, extract key concepts, and produce tailored code examples.
4 |
5 | ## What You'll Build
6 |
7 | A documentation-powered code generation system that:
8 |
9 | - Fetches and parses documentation from multiple URLs
10 | - Extracts API patterns, methods, and usage examples
11 | - Generates working code for specific use cases
12 | - Provides explanations and best practices
13 | - Works with any library's documentation
14 |
15 | ## Setup
16 |
17 | ```bash
18 | pip install dspy requests beautifulsoup4 html2text
19 | ```
20 |
21 | ## Step 1: Documentation Fetching and Processing
22 |
23 | ```python
24 | import dspy
25 | import requests
26 | from bs4 import BeautifulSoup
27 | import html2text
28 | from typing import List, Dict, Any
29 | import json
30 | from urllib.parse import urljoin, urlparse
31 | import time
32 |
33 | # Configure DSPy
34 | lm = dspy.LM(model='openai/gpt-4o-mini')
35 | dspy.configure(lm=lm)
36 |
37 | class DocumentationFetcher:
38 |     """Fetches and processes documentation from URLs."""
39 |
40 |     def __init__(self, max_retries=3, delay=1):
41 |         self.session = requests.Session()
42 |         self.session.headers.update({
43 |             'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
44 |         })
45 |         self.max_retries = max_retries
46 |         self.delay = delay
47 |         self.html_converter = html2text.HTML2Text()
48 |         self.html_converter.ignore_links = False
49 |         self.html_converter.ignore_images = True
50 |
51 |     def fetch_url(self, url: str) -> dict[str, str]:
52 |         """Fetch content from a single URL."""
53 |         for attempt in range(self.max_retries):
54 |             try:
55 |                 print(f"📡 Fetching: {url} (attempt {attempt + 1})")
56 |                 response = self.session.get(url, timeout=10)
57 |                 response.raise_for_status()
58 |
59 |                 soup = BeautifulSoup(response.content, 'html.parser')
60 |
61 |                 # Remove script and style elements
62 |                 for script in soup(["script", "style", "nav", "footer", "header"]):
63 |                     script.decompose()
64 |
65 |                 # Convert to markdown for better LLM processing
66 |                 markdown_content = self.html_converter.handle(str(soup))
67 |
68 |                 return {
69 |                     "url": url,
70 |                     "title": soup.title.string if soup.title else "No title",
71 |                     "content": markdown_content,
72 |                     "success": True
73 |                 }
74 |
75 |             except Exception as e:
76 |                 print(f"❌ Error fetching {url}: {e}")
77 |                 if attempt < self.max_retries - 1:
78 |                     time.sleep(self.delay)
79 |                 else:
80 |                     return {
81 |                         "url": url,
82 |                         "title": "Failed to fetch",
83 |                         "content": f"Error: {str(e)}",
84 |                         "success": False
85 |                     }
86 |
87 |         return {"url": url, "title": "Failed", "content": "", "success": False}
88 |
89 |     def fetch_documentation(self, urls: list[str]) -> list[dict[str, str]]:
90 |         """Fetch documentation from multiple URLs."""
91 |         results = []
92 |
93 |         for url in urls:
94 |             result = self.fetch_url(url)
95 |             results.append(result)
96 |             time.sleep(self.delay)  # Be respectful to servers
97 |
98 |         return results
99 |
100 | class LibraryAnalyzer(dspy.Signature):
101 |     """Analyze library documentation to understand core concepts and patterns."""
102 |     library_name: str = dspy.InputField(desc="Name of the library to analyze")
103 |     documentation_content: str = dspy.InputField(desc="Combined documentation content")
104 |
105 |     core_concepts: list[str] = dspy.OutputField(desc="Main concepts and components")
106 |     common_patterns: list[str] = dspy.OutputField(desc="Common usage patterns")
107 |     key_methods: list[str] = dspy.OutputField(desc="Important methods and functions")
108 |     installation_info: str = dspy.OutputField(desc="Installation and setup information")
109 |     code_examples: list[str] = dspy.OutputField(desc="Example code snippets found")
110 |
111 | class CodeGenerator(dspy.Signature):
112 |     """Generate code examples for specific use cases using the target library."""
113 |     library_info: str = dspy.InputField(desc="Library concepts and patterns")
114 |     use_case: str = dspy.InputField(desc="Specific use case to implement")
115 |     requirements: str = dspy.InputField(desc="Additional requirements or constraints")
116 |
117 |     code_example: str = dspy.OutputField(desc="Complete, working code example")
118 |     explanation: str = dspy.OutputField(desc="Step-by-step explanation of the code")
119 |     best_practices: list[str] = dspy.OutputField(desc="Best practices and tips")
120 |     imports_needed: list[str] = dspy.OutputField(desc="Required imports and dependencies")
121 |
122 | class DocumentationLearningAgent(dspy.Module):
123 |     """Agent that learns from documentation URLs and generates code examples."""
124 |
125 |     def __init__(self):
126 |         super().__init__()
127 |         self.fetcher = DocumentationFetcher()
128 |         self.analyze_docs = dspy.ChainOfThought(LibraryAnalyzer)
129 |         self.generate_code = dspy.ChainOfThought(CodeGenerator)
130 |         self.refine_code = dspy.ChainOfThought(
131 |             "code, feedback -> improved_code: str, changes_made: list[str]"
132 |         )
133 |
134 |     def learn_from_urls(self, library_name: str, doc_urls: list[str]) -> Dict:
135 |         """Learn about a library from its documentation URLs."""
136 |
137 |         print(f"📚 Learning about {library_name} from {len(doc_urls)} URLs...")
138 |
139 |         # Fetch all documentation
140 |         docs = self.fetcher.fetch_documentation(doc_urls)
141 |
142 |         # Combine successful fetches
143 |         combined_content = "\n\n---\n\n".join([
144 |             f"URL: {doc['url']}\nTitle: {doc['title']}\n\n{doc['content']}"
145 |             for doc in docs if doc['success']
146 |         ])
147 |
148 |         if not combined_content:
149 |             raise ValueError("No documentation could be fetched successfully")
150 |
151 |         # Analyze combined documentation
152 |         analysis = self.analyze_docs(
153 |             library_name=library_name,
154 |             documentation_content=combined_content
155 |         )
156 |
157 |         return {
158 |             "library": library_name,
159 |             "source_urls": [doc['url'] for doc in docs if doc['success']],
160 |             "core_concepts": analysis.core_concepts,
161 |             "patterns": analysis.common_patterns,
162 |             "methods": analysis.key_methods,
163 |             "installation": analysis.installation_info,
164 |             "examples": analysis.code_examples,
165 |             "fetched_docs": docs
166 |         }
167 |
168 |     def generate_example(self, library_info: Dict, use_case: str, requirements: str = "") -> Dict:
169 |         """Generate a code example for a specific use case."""
170 |
171 |         # Format library information for the generator
172 |         info_text = f"""
173 |         Library: {library_info['library']}
174 |         Core Concepts: {', '.join(library_info['core_concepts'])}
175 |         Common Patterns: {', '.join(library_info['patterns'])}
176 |         Key Methods: {', '.join(library_info['methods'])}
177 |         Installation: {library_info['installation']}
178 |         Example Code Snippets: {'; '.join(library_info['examples'][:3])}  # First 3 examples
179 |         """
180 |
181 |         code_result = self.generate_code(
182 |             library_info=info_text,
183 |             use_case=use_case,
184 |             requirements=requirements
185 |         )
186 |
187 |         return {
188 |             "code": code_result.code_example,
189 |             "explanation": code_result.explanation,
190 |             "best_practices": code_result.best_practices,
191 |             "imports": code_result.imports_needed
192 |         }
193 |
194 | # Initialize the learning agent
195 | agent = DocumentationLearningAgent()
196 | ```
197 |
198 | ## Step 2: Learning from Documentation URLs
199 |
200 | ```python
201 | def learn_library_from_urls(library_name: str, documentation_urls: list[str]) -> Dict:
202 |     """Learn about any library from its documentation URLs."""
203 |
204 |     try:
205 |         library_info = agent.learn_from_urls(library_name, documentation_urls)
206 |
207 |         print(f"\n🔍 Library Analysis Results for {library_name}:")
208 |         print(f"Sources: {len(library_info['source_urls'])} successful fetches")
209 |         print(f"Core Concepts: {library_info['core_concepts']}")
210 |         print(f"Common Patterns: {library_info['patterns']}")
211 |         print(f"Key Methods: {library_info['methods']}")
212 |         print(f"Installation: {library_info['installation']}")
213 |         print(f"Found {len(library_info['examples'])} code examples")
214 |
215 |         return library_info
216 |
217 |     except Exception as e:
218 |         print(f"❌ Error learning library: {e}")
219 |         raise
220 |
221 | # Example 1: Learn FastAPI from official documentation
222 | fastapi_urls = [
223 |     "https://fastapi.tiangolo.com/",
224 |     "https://fastapi.tiangolo.com/tutorial/first-steps/",
225 |     "https://fastapi.tiangolo.com/tutorial/path-params/",
226 |     "https://fastapi.tiangolo.com/tutorial/query-params/"
227 | ]
228 |
229 | print("🚀 Learning FastAPI from official documentation...")
230 | fastapi_info = learn_library_from_urls("FastAPI", fastapi_urls)
231 |
232 | # Example 2: Learn a different library (you can replace with any library)
233 | streamlit_urls = [
234 |     "https://docs.streamlit.io/",
235 |     "https://docs.streamlit.io/get-started",
236 |     "https://docs.streamlit.io/develop/api-reference"
237 | ]
238 |
239 | print("\n\n📊 Learning Streamlit from official documentation...")
240 | streamlit_info = learn_library_from_urls("Streamlit", streamlit_urls)
241 | ```
242 |
243 | ## Step 3: Generating Code Examples
244 |
245 | ```python
246 | def generate_examples_for_library(library_info: Dict, library_name: str):
247 |     """Generate code examples for any library based on its documentation."""
248 |
249 |     # Define generic use cases that can apply to most libraries
250 |     use_cases = [
251 |         {
252 |             "name": "Basic Setup and Hello World",
253 |             "description": f"Create a minimal working example with {library_name}",
254 |             "requirements": "Include installation, imports, and basic usage"
255 |         },
256 |         {
257 |             "name": "Common Operations",
258 |             "description": f"Demonstrate the most common {library_name} operations",
259 |             "requirements": "Show typical workflow and best practices"
260 |         },
261 |         {
262 |             "name": "Advanced Usage",
263 |             "description": f"Create a more complex example showcasing {library_name} capabilities",
264 |             "requirements": "Include error handling and optimization"
265 |         }
266 |     ]
267 |
268 |     generated_examples = []
269 |
270 |     print(f"\n🔧 Generating examples for {library_name}...")
271 |
272 |     for use_case in use_cases:
273 |         print(f"\n📝 {use_case['name']}")
274 |         print(f"Description: {use_case['description']}")
275 |
276 |         example = agent.generate_example(
277 |             library_info=library_info,
278 |             use_case=use_case['description'],
279 |             requirements=use_case['requirements']
280 |         )
281 |
282 |         print("\n💻 Generated Code:")
283 |         print("```python")
284 |         print(example['code'])
285 |         print("```")
286 |
287 |         print("\n📦 Required Imports:")
288 |         for imp in example['imports']:
289 |             print(f"  • {imp}")
290 |
291 |         print("\n📝 Explanation:")
292 |         print(example['explanation'])
293 |
294 |         print("\n✅ Best Practices:")
295 |         for practice in example['best_practices']:
296 |             print(f"  • {practice}")
297 |
298 |         generated_examples.append({
299 |             "use_case": use_case['name'],
300 |             "code": example['code'],
301 |             "imports": example['imports'],
302 |             "explanation": example['explanation'],
303 |             "best_practices": example['best_practices']
304 |         })
305 |
306 |         print("-" * 80)
307 |
308 |     return generated_examples
309 |
310 | # Generate examples for both libraries
311 | print("🎯 Generating FastAPI Examples:")
312 | fastapi_examples = generate_examples_for_library(fastapi_info, "FastAPI")
313 |
314 | print("\n\n🎯 Generating Streamlit Examples:")
315 | streamlit_examples = generate_examples_for_library(streamlit_info, "Streamlit")
316 | ```
317 |
318 | ## Step 4: Interactive Library Learning Function
319 |
320 | ```python
321 | def learn_any_library(library_name: str, documentation_urls: list[str], use_cases: list[str] = None):
322 |     """Learn any library from its documentation and generate examples."""
323 |
324 |     if use_cases is None:
325 |         use_cases = [
326 |             "Basic setup and hello world example",
327 |             "Common operations and workflows",
328 |             "Advanced usage with best practices"
329 |         ]
330 |
331 |     print(f"🚀 Starting automated learning for {library_name}...")
332 |     print(f"Documentation sources: {len(documentation_urls)} URLs")
333 |
334 |     try:
335 |         # Step 1: Learn from documentation
336 |         library_info = agent.learn_from_urls(library_name, documentation_urls)
337 |
338 |         # Step 2: Generate examples for each use case
339 |         all_examples = []
340 |
341 |         for i, use_case in enumerate(use_cases, 1):
342 |             print(f"\n📝 Generating example {i}/{len(use_cases)}: {use_case}")
343 |
344 |             example = agent.generate_example(
345 |                 library_info=library_info,
346 |                 use_case=use_case,
347 |                 requirements="Include error handling, comments, and follow best practices"
348 |             )
349 |
350 |             all_examples.append({
351 |                 "use_case": use_case,
352 |                 "code": example['code'],
353 |                 "imports": example['imports'],
354 |                 "explanation": example['explanation'],
355 |                 "best_practices": example['best_practices']
356 |             })
357 |
358 |         return {
359 |             "library_info": library_info,
360 |             "examples": all_examples
361 |         }
362 |
363 |     except Exception as e:
364 |         print(f"❌ Error learning {library_name}: {e}")
365 |         return None
366 |
367 | def interactive_learning_session():
368 |     """Interactive session for learning libraries with user input."""
369 |
370 |     print("🎯 Welcome to the Interactive Library Learning System!")
371 |     print("This system will help you learn any Python library from its documentation.\n")
372 |
373 |     learned_libraries = {}
374 |
375 |     while True:
376 |         print("\n" + "="*60)
377 |         print("🚀 LIBRARY LEARNING SESSION")
378 |         print("="*60)
379 |
380 |         # Get library name from user
381 |         library_name = input("\n📚 Enter the library name you want to learn (or 'quit' to exit): ").strip()
382 |
383 |         if library_name.lower() in ['quit', 'exit', 'q']:
384 |             print("\n👋 Thanks for using the Interactive Library Learning System!")
385 |             break
386 |
387 |         if not library_name:
388 |             print("❌ Please enter a valid library name.")
389 |             continue
390 |
391 |         # Get documentation URLs
392 |         print(f"\n🔗 Enter documentation URLs for {library_name} (one per line, empty line to finish):")
393 |         urls = []
394 |         while True:
395 |             url = input("  URL: ").strip()
396 |             if not url:
397 |                 break
398 |             if not url.startswith(('http://', 'https://')):
399 |                 print("    ⚠️  Please enter a valid URL starting with http:// or https://")
400 |                 continue
401 |             urls.append(url)
402 |
403 |         if not urls:
404 |             print("❌ No valid URLs provided. Skipping this library.")
405 |             continue
406 |
407 |         # Get custom use cases from user
408 |         print(f"\n🎯 Define use cases for {library_name} (optional, press Enter for defaults):")
409 |         print("   Default use cases will be: Basic setup, Common operations, Advanced usage")
410 |
411 |         user_wants_custom = input("   Do you want to define custom use cases? (y/n): ").strip().lower()
412 |
413 |         use_cases = None
414 |         if user_wants_custom in ['y', 'yes']:
415 |             print("   Enter your use cases (one per line, empty line to finish):")
416 |             use_cases = []
417 |             while True:
418 |                 use_case = input("     Use case: ").strip()
419 |                 if not use_case:
420 |                     break
421 |                 use_cases.append(use_case)
422 |
423 |             if not use_cases:
424 |                 print("   No custom use cases provided, using defaults.")
425 |                 use_cases = None
426 |
427 |         # Learn the library
428 |         print(f"\n🚀 Starting learning process for {library_name}...")
429 |         result = learn_any_library(library_name, urls, use_cases)
430 |
431 |         if result:
432 |             learned_libraries[library_name] = result
433 |             print(f"\n✅ Successfully learned {library_name}!")
434 |
435 |             # Show summary
436 |             print(f"\n📊 Learning Summary for {library_name}:")
437 |             print(f"   • Core concepts: {len(result['library_info']['core_concepts'])} identified")
438 |             print(f"   • Common patterns: {len(result['library_info']['patterns'])} found")
439 |             print(f"   • Examples generated: {len(result['examples'])}")
440 |
441 |             # Ask if user wants to see examples
442 |             show_examples = input(f"\n👀 Do you want to see the generated examples for {library_name}? (y/n): ").strip().lower()
443 |
444 |             if show_examples in ['y', 'yes']:
445 |                 for i, example in enumerate(result['examples'], 1):
446 |                     print(f"\n{'─'*50}")
447 |                     print(f"📝 Example {i}: {example['use_case']}")
448 |                     print(f"{'─'*50}")
449 |
450 |                     print("\n💻 Generated Code:")
451 |                     print("```python")
452 |                     print(example['code'])
453 |                     print("```")
454 |
455 |                     print(f"\n📦 Required Imports:")
456 |                     for imp in example['imports']:
457 |                         print(f"  • {imp}")
458 |
459 |                     print(f"\n📝 Explanation:")
460 |                     print(example['explanation'])
461 |
462 |                     print(f"\n✅ Best Practices:")
463 |                     for practice in example['best_practices']:
464 |                         print(f"  • {practice}")
465 |
466 |                     # Ask if user wants to see the next example
467 |                     if i < len(result['examples']):
468 |                         continue_viewing = input(f"\nContinue to next example? (y/n): ").strip().lower()
469 |                         if continue_viewing not in ['y', 'yes']:
470 |                             break
471 |
472 |             # Offer to save results
473 |             save_results = input(f"\n💾 Save learning results for {library_name} to file? (y/n): ").strip().lower()
474 |
475 |             if save_results in ['y', 'yes']:
476 |                 filename = input(f"   Enter filename (default: {library_name.lower()}_learning.json): ").strip()
477 |                 if not filename:
478 |                     filename = f"{library_name.lower()}_learning.json"
479 |
480 |                 try:
481 |                     import json
482 |                     with open(filename, 'w') as f:
483 |                         json.dump(result, f, indent=2, default=str)
484 |                     print(f"   ✅ Results saved to {filename}")
485 |                 except Exception as e:
486 |                     print(f"   ❌ Error saving file: {e}")
487 |
488 |         else:
489 |             print(f"❌ Failed to learn {library_name}")
490 |
491 |         # Ask if user wants to learn another library
492 |         print(f"\n📚 Libraries learned so far: {list(learned_libraries.keys())}")
493 |         continue_learning = input("\n🔄 Do you want to learn another library? (y/n): ").strip().lower()
494 |
495 |         if continue_learning not in ['y', 'yes']:
496 |             break
497 |
498 |     # Final summary
499 |     if learned_libraries:
500 |         print(f"\n🎉 Session Summary:")
501 |         print(f"Successfully learned {len(learned_libraries)} libraries:")
502 |         for lib_name, info in learned_libraries.items():
503 |             print(f"  • {lib_name}: {len(info['examples'])} examples generated")
504 |
505 |     return learned_libraries
506 |
507 | # Example: Run interactive learning session
508 | if __name__ == "__main__":
509 |     # Run interactive session
510 |     learned_libraries = interactive_learning_session()
511 | ```
512 |
513 | ## Example Output
514 |
515 | When you run the interactive learning system, you'll see:
516 |
517 | **Interactive Session Start:**
518 | ```
519 | 🎯 Welcome to the Interactive Library Learning System!
520 | This system will help you learn any Python library from its documentation.
521 |
522 | ============================================================
523 | 🚀 LIBRARY LEARNING SESSION
524 | ============================================================
525 |
526 | 📚 Enter the library name you want to learn (or 'quit' to exit): FastAPI
527 |
528 | 🔗 Enter documentation URLs for FastAPI (one per line, empty line to finish):
529 |   URL: https://fastapi.tiangolo.com/
530 |   URL: https://fastapi.tiangolo.com/tutorial/first-steps/
531 |   URL: https://fastapi.tiangolo.com/tutorial/path-params/
532 |   URL:
533 |
534 | 🎯 Define use cases for FastAPI (optional, press Enter for defaults):
535 |    Default use cases will be: Basic setup, Common operations, Advanced usage
536 |    Do you want to define custom use cases? (y/n): y
537 |    Enter your use cases (one per line, empty line to finish):
538 |      Use case: Create a REST API with authentication
539 |      Use case: Build a file upload endpoint
540 |      Use case: Add database integration with SQLAlchemy
541 |      Use case:
542 | ```
543 |
544 | **Documentation Processing:**
545 | ```
546 | 🚀 Starting learning process for FastAPI...
547 | 🚀 Starting automated learning for FastAPI...
548 | Documentation sources: 3 URLs
549 | 📡 Fetching: https://fastapi.tiangolo.com/ (attempt 1)
550 | 📡 Fetching: https://fastapi.tiangolo.com/tutorial/first-steps/ (attempt 1)
551 | 📡 Fetching: https://fastapi.tiangolo.com/tutorial/path-params/ (attempt 1)
552 | 📚 Learning about FastAPI from 3 URLs...
553 |
554 | 🔍 Library Analysis Results for FastAPI:
555 | Sources: 3 successful fetches
556 | Core Concepts: ['FastAPI app', 'path operations', 'dependencies', 'request/response models']
557 | Common Patterns: ['app = FastAPI()', 'decorator-based routing', 'Pydantic models']
558 | Key Methods: ['FastAPI()', '@app.get()', '@app.post()', 'uvicorn.run()']
559 | Installation: pip install fastapi uvicorn
560 | ```
561 |
562 | **Code Generation:**
563 | ```
564 | 📝 Generating example 1/3: Create a REST API with authentication
565 |
566 | ✅ Successfully learned FastAPI!
567 |
568 | 📊 Learning Summary for FastAPI:
569 |    • Core concepts: 4 identified
570 |    • Common patterns: 3 found
571 |    • Examples generated: 3
572 |
573 | 👀 Do you want to see the generated examples for FastAPI? (y/n): y
574 |
575 | ──────────────────────────────────────────────────
576 | 📝 Example 1: Create a REST API with authentication
577 | ──────────────────────────────────────────────────
578 |
579 | 💻 Generated Code:
580 | from fastapi import FastAPI, Depends, HTTPException, status
581 | from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
582 | import uvicorn
583 | from typing import Dict
584 | import jwt
585 | from datetime import datetime, timedelta
586 |
587 | app = FastAPI(title="Authenticated API", version="1.0.0")
588 | security = HTTPBearer()
589 |
590 | # Secret key for JWT (use environment variable in production)
591 | SECRET_KEY = "your-secret-key-here"
592 | ALGORITHM = "HS256"
593 |
594 | def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
595 |     try:
596 |         payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=[ALGORITHM])
597 |         username: str = payload.get("sub")
598 |         if username is None:
599 |             raise HTTPException(status_code=401, detail="Invalid token")
600 |         return username
601 |     except jwt.PyJWTError:
602 |         raise HTTPException(status_code=401, detail="Invalid token")
603 |
604 | @app.post("/login")
605 | async def login(username: str, password: str) -> dict[str, str]:
606 |     # In production, verify against database
607 |     if username == "admin" and password == "secret":
608 |         token_data = {"sub": username, "exp": datetime.utcnow() + timedelta(hours=24)}
609 |         token = jwt.encode(token_data, SECRET_KEY, algorithm=ALGORITHM)
610 |         return {"access_token": token, "token_type": "bearer"}
611 |     raise HTTPException(status_code=401, detail="Invalid credentials")
612 |
613 | @app.get("/protected")
614 | async def protected_route(current_user: str = Depends(verify_token)) -> dict[str, str]:
615 |     return {"message": f"Hello {current_user}! This is a protected route."}
616 |
617 | if __name__ == "__main__":
618 |     uvicorn.run(app, host="0.0.0.0", port=8000)
619 |
620 | 📦 Required Imports:
621 |   • pip install fastapi uvicorn python-jose[cryptography]
622 |   • from fastapi import FastAPI, Depends, HTTPException, status
623 |   • from fastapi.security import HTTPBearer
624 |   • import jwt
625 |
626 | 📝 Explanation:
627 | This example creates a FastAPI application with JWT-based authentication. It includes a login endpoint that returns a JWT token and a protected route that requires authentication...
628 |
629 | ✅ Best Practices:
630 |   • Use environment variables for secret keys
631 |   • Implement proper password hashing in production
632 |   • Add token expiration and refresh logic
633 |   • Include proper error handling
634 |
635 | Continue to next example? (y/n): n
636 |
637 | 💾 Save learning results for FastAPI to file? (y/n): y
638 |    Enter filename (default: fastapi_learning.json):
639 |    ✅ Results saved to fastapi_learning.json
640 |
641 | 📚 Libraries learned so far: ['FastAPI']
642 |
643 | 🔄 Do you want to learn another library? (y/n): n
644 |
645 | 🎉 Session Summary:
646 | Successfully learned 1 libraries:
647 |   • FastAPI: 3 examples generated
648 | ```
649 |
650 |
651 | ## Next Steps
652 |
653 | - **GitHub Integration**: Learn from README files and example repositories
654 | - **Video Tutorial Processing**: Extract information from video documentation
655 | - **Community Examples**: Aggregate examples from Stack Overflow and forums
656 | - **Version Comparison**: Track API changes across library versions
657 | - **Testing Generation**: Automatically create unit tests for generated code
658 | - **Page Crawling**: Automatically crawl documentation pages to actively understand the usage
659 |
660 | This tutorial demonstrates how DSPy can automate the entire process of learning unfamiliar libraries from their documentation, making it valuable for rapid technology adoption and exploration.
```

saving/index.md
```
1 | # Tutorial: Saving and Loading your DSPy program
2 |
3 | This guide demonstrates how to save and load your DSPy program. At a high level, there are two ways to save your DSPy program:
4 |
5 | 1. Save the state of the program only, similar to weights-only saving in PyTorch.
6 | 2. Save the whole program, including both the architecture and the state, which is supported by `dspy>=2.6.0`.
7 |
8 | ## State-only Saving
9 |
10 | State represents the DSPy program's internal state, including the signature, demos (few-shot examples), and other information like
11 | the `lm` to use for each `dspy.Predict` in the program. It also includes configurable attributes of other DSPy modules like
12 | `k` for `dspy.retrievers.Retriever`. To save the state of a program, use the `save` method and set `save_program=False`. You can
13 | choose to save the state to a JSON file or a pickle file. We recommend saving the state to a JSON file because it is safer and readable.
14 | But sometimes your program contains non-serializable objects like `dspy.Image` or `datetime.datetime`, in which case you should save
15 | the state to a pickle file.
16 |
17 | Let's say we have compiled a program with some data, and we want to save the program for future usage:
18 |
19 | ```python
20 | import dspy
21 | from dspy.datasets.gsm8k import GSM8K, gsm8k_metric
22 |
23 | dspy.settings.configure(lm=dspy.LM("openai/gpt-4o-mini"))
24 |
25 | gsm8k = GSM8K()
26 | gsm8k_trainset = gsm8k.train[:10]
27 | dspy_program = dspy.ChainOfThought("question -> answer")
28 |
29 | optimizer = dspy.BootstrapFewShot(metric=gsm8k_metric, max_bootstrapped_demos=4, max_labeled_demos=4, max_rounds=5)
30 | compiled_dspy_program = optimizer.compile(dspy_program, trainset=gsm8k_trainset)
31 | ```
32 |
33 | To save the state of your program to json file:
34 |
35 | ```python
36 | compiled_dspy_program.save("./dspy_program/program.json", save_program=False)
37 | ```
38 |
39 | To save the state of your program to a pickle file:
40 |
41 | ```python
42 | compiled_dspy_program.save("./dspy_program/program.pkl", save_program=False)
43 | ```
44 |
45 | To load your saved state, you need to **recreate the same program**, then load the state using the `load` method.
46 |
47 | ```python
48 | loaded_dspy_program = dspy.ChainOfThought("question -> answer") # Recreate the same program.
49 | loaded_dspy_program.load("./dspy_program/program.json")
50 |
51 | assert len(compiled_dspy_program.demos) == len(loaded_dspy_program.demos)
52 | for original_demo, loaded_demo in zip(compiled_dspy_program.demos, loaded_dspy_program.demos):
53 |     # Loaded demo is a dict, while the original demo is a dspy.Example.
54 |     assert original_demo.toDict() == loaded_demo
55 | assert str(compiled_dspy_program.signature) == str(loaded_dspy_program.signature)
56 | ```
57 |
58 | Or load the state from a pickle file:
59 |
60 | ```python
61 | loaded_dspy_program = dspy.ChainOfThought("question -> answer") # Recreate the same program.
62 | loaded_dspy_program.load("./dspy_program/program.pkl")
63 |
64 | assert len(compiled_dspy_program.demos) == len(loaded_dspy_program.demos)
65 | for original_demo, loaded_demo in zip(compiled_dspy_program.demos, loaded_dspy_program.demos):
66 |     # Loaded demo is a dict, while the original demo is a dspy.Example.
67 |     assert original_demo.toDict() == loaded_demo
68 | assert str(compiled_dspy_program.signature) == str(loaded_dspy_program.signature)
69 | ```
70 |
71 | ## Whole Program Saving
72 |
73 | Starting from `dspy>=2.6.0`, DSPy supports saving the whole program, including the architecture and the state. This feature
74 | is powered by `cloudpickle`, which is a library for serializing and deserializing Python objects.
75 |
76 | To save the whole program, use the `save` method and set `save_program=True`, and specify a directory path to save the program
77 | instead of a file name. We require a directory path because we also save some metadata, e.g., the dependency versions along
78 | with the program itself.
79 |
80 | ```python
81 | compiled_dspy_program.save("./dspy_program/", save_program=True)
82 | ```
83 |
84 | To load the saved program, directly use `dspy.load` method:
85 |
86 | ```python
87 | loaded_dspy_program = dspy.load("./dspy_program/")
88 |
89 | assert len(compiled_dspy_program.demos) == len(loaded_dspy_program.demos)
90 | for original_demo, loaded_demo in zip(compiled_dspy_program.demos, loaded_dspy_program.demos):
91 |     # Loaded demo is a dict, while the original demo is a dspy.Example.
92 |     assert original_demo.toDict() == loaded_demo
93 | assert str(compiled_dspy_program.signature) == str(loaded_dspy_program.signature)
94 | ```
95 |
96 | With whole program saving, you don't need to recreate the program, but can directly load the architecture along with the state.
97 | You can pick the suitable saving approach based on your needs.
98 |
99 | ### Serializing Imported Modules
100 |
101 | When saving a program with `save_program=True`, you might need to include custom modules that your program depends on. This is
102 | necessary if your program depends on these modules, but at loading time these modules are not imported before calling `dspy.load`.
103 |
104 | You can specify which custom modules should be serialized with your program by passing them to the `modules_to_serialize`
105 | parameter when calling `save`. This ensures that any dependencies your program relies on are included during serialization and
106 | available when loading the program later.
107 |
108 | Under the hood this uses cloudpickle's `cloudpickle.register_pickle_by_value` function to register a module as picklable by value.
109 | When a module is registered this way, cloudpickle will serialize the module by value rather than by reference, ensuring that the
110 | module contents are preserved with the saved program.
111 |
112 | For example, if your program uses custom modules:
113 |
114 | ```python
115 | import dspy
116 | import my_custom_module
117 |
118 | compiled_dspy_program = dspy.ChainOfThought(my_custom_module.custom_signature)
119 |
120 | # Save the program with the custom module
121 | compiled_dspy_program.save(
122 |     "./dspy_program/",
123 |     save_program=True,
124 |     modules_to_serialize=[my_custom_module]
125 | )
126 | ```
127 |
128 | This ensures that the required modules are properly serialized and available when loading the program later. Any number of
129 | modules can be passed to `modules_to_serialize`. If you don't specify `modules_to_serialize`, no additional modules will be
130 | registered for serialization.
131 |
132 | ## Backward Compatibility
133 |
134 | As of `dspy<3.0.0`, we don't guarantee the backward compatibility of the saved program. For example, if you save the program with `dspy==2.5.35`,
135 | at loading time please make sure to use the same version of DSPy to load the program, otherwise the program may not work as expected. Chances
136 | are that loading a saved file in a different version of DSPy will not raise an error, but the performance could be different from when
137 | the program was saved.
138 |
139 | Starting from `dspy>=3.0.0`, we will guarantee the backward compatibility of the saved program in major releases, i.e., programs saved in `dspy==3.0.0`
140 | should be loadable in `dspy==3.7.10`.
```

streaming/index.md
```
1 | # Streaming
2 |
3 | In this guide, we will walk you through how to enable streaming in your DSPy program. DSPy Streaming
4 | consists of two parts:
5 |
6 | - **Output Token Streaming**: Stream individual tokens as they're generated, rather than waiting for the complete response.
7 | - **Intermediate Status Streaming**: Provide real-time updates about the program's execution state (e.g., "Calling web search...", "Processing results...").
8 |
9 | ## Output Token Streaming
10 |
11 | DSPy's token streaming feature works with any module in your pipeline, not just the final output. The only requirement is that the streamed field must be of type `str`. To enable token streaming:
12 |
13 | 1. Wrap your program with `dspy.streamify`
14 | 2. Create one or more `dspy.streaming.StreamListener` objects to specify which fields to stream
15 |
16 | Here's a basic example:
17 |
18 | ```python
19 | import os
20 |
21 | import dspy
22 |
23 | os.environ["OPENAI_API_KEY"] = "your_api_key"
24 |
25 | dspy.configure(lm=dspy.LM("openai/gpt-4o-mini"))
26 |
27 | predict = dspy.Predict("question->answer")
28 |
29 | # Enable streaming for the 'answer' field
30 | stream_predict = dspy.streamify(
31 |     predict,
32 |     stream_listeners=[dspy.streaming.StreamListener(signature_field_name="answer")],
33 | )
34 | ```
35 |
36 | To consume the streamed output:
37 |
38 | ```python
39 | import asyncio
40 |
41 | async def read_output_stream():
42 |     output_stream = stream_predict(question="Why did a chicken cross the kitchen?")
43 |
44 |     async for chunk in output_stream:
45 |         print(chunk)
46 |
47 | asyncio.run(read_output_stream())
48 | ```
49 |
50 | This will produce output like:
51 |
52 | ```
53 | StreamResponse(predict_name='self', signature_field_name='answer', chunk='To')
54 | StreamResponse(predict_name='self', signature_field_name='answer', chunk=' get')
55 | StreamResponse(predict_name='self', signature_field_name='answer', chunk=' to')
56 | StreamResponse(predict_name='self', signature_field_name='answer', chunk=' the')
57 | StreamResponse(predict_name='self', signature_field_name='answer', chunk=' other')
58 | StreamResponse(predict_name='self', signature_field_name='answer', chunk=' side of the frying pan!')
59 | Prediction(
60 |     answer='To get to the other side of the frying pan!'
61 | )
62 | ```
63 |
64 | Note: Since `dspy.streamify` returns an async generator, you must use it within an async context. If you're using an environment like Jupyter or Google Colab that already has an event loop (async context), you can use the generator directly.
65 |
66 | You may have noticed that the above streaming contains two different entities: `StreamResponse`
67 | and `Prediction.` `StreamResponse` is the wrapper over streaming tokens on the field being listened to, and in
68 | this example it is the `answer` field. `Prediction` is the program's final output. In DSPy, streaming is
69 | implemented in a sidecar fashion: we enable streaming on the LM so that LM outputs a stream of tokens. We send these
70 | tokens to a side channel, which is being continuously read by the user-defined listeners. Listeners keep interpreting
71 | the stream, and decides if the `signature_field_name` it is listening to has started to appear and has finalized.
72 | Once it decides that the field appears, the listener begins outputting tokens to the async generator users can
73 | read. Listeners' internal mechanism changes according to the adapter behind the scene, and because usually
74 | we cannot decide if a field has finalized until seeing the next field, the listener buffers the output tokens
75 | before sending to the final generator, which is why you will usually see the last chunk of type `StreamResponse`
76 | has more than one token. The program's output is also written to the stream, which is the chunk of `Prediction`
77 | as in the sample output above.
78 |
79 | To handle these different types and implement custom logic:
80 |
81 | ```python
82 | import asyncio
83 |
84 | async def read_output_stream():
85 |   output_stream = stream_predict(question="Why did a chicken cross the kitchen?")
86 |
87 |   async for chunk in output_stream:
88 |     return_value = None
89 |     if isinstance(chunk, dspy.streaming.StreamResponse):
90 |       print(f"Output token of field {chunk.signature_field_name}: {chunk.chunk}")
91 |     elif isinstance(chunk, dspy.Prediction):
92 |       return_value = chunk
93 |
94 |
95 | program_output = asyncio.run(read_output_stream())
96 | print("Final output: ", program_output)
97 | ```
98 |
99 | ### Understand `StreamResponse`
100 |
101 | `StreamResponse` (`dspy.streaming.StreamResponse`) is the wrapper class of streaming tokens. It comes with 3
102 | fields:
103 |
104 | - `predict_name`: the name of the predict that holds the `signature_field_name`. The name is the
105 |   same name of keys as you run `your_program.named_predictors()`. In the code above because `answer` is from
106 |   the `predict` itself, so the `predict_name` shows up as `self`, which is the only key as your run
107 |   `predict.named_predictors()`.
108 | - `signature_field_name`: the output field that these tokens map to. `predict_name` and `signature_field_name`
109 |   together form the unique identifier of the field. We will demonstrate how to handle multiple fields streaming
110 |   and duplicated field name later in this guide.
111 | - `chunk`: the value of the stream chunk.
112 |
113 | ### Streaming with Cache
114 |
115 | When a cached result is found, the stream will skip individual tokens and only yield the final `Prediction`. For example:
116 |
117 | ```
118 | Prediction(
119 |     answer='To get to the other side of the dinner plate!'
120 | )
121 | ```
122 |
123 | ### Streaming Multiple Fields
124 |
125 | You can monitor multiple fields by creating a `StreamListener` for each one. Here's an example with a multi-module program:
126 |
127 | ```python
128 | import asyncio
129 |
130 | import dspy
131 |
132 | lm = dspy.LM("openai/gpt-4o-mini", cache=False)
133 | dspy.settings.configure(lm=lm)
134 |
135 |
136 | class MyModule(dspy.Module):
137 |     def __init__(self):
138 |         super().__init__()
139 |
140 |         self.predict1 = dspy.Predict("question->answer")
141 |         self.predict2 = dspy.Predict("answer->simplified_answer")
142 |
143 |     def forward(self, question: str, **kwargs):
144 |         answer = self.predict1(question=question)
145 |         simplified_answer = self.predict2(answer=answer)
146 |         return simplified_answer
147 |
148 |
149 | predict = MyModule()
150 | stream_listeners = [
151 |     dspy.streaming.StreamListener(signature_field_name="answer"),
152 |     dspy.streaming.StreamListener(signature_field_name="simplified_answer"),
153 | ]
154 | stream_predict = dspy.streamify(
155 |     predict,
156 |     stream_listeners=stream_listeners,
157 | )
158 |
159 | async def read_output_stream():
160 |     output = stream_predict(question="why did a chicken cross the kitchen?")
161 |
162 |     return_value = None
163 |     async for chunk in output:
164 |         if isinstance(chunk, dspy.streaming.StreamResponse):
165 |             print(chunk)
166 |         elif isinstance(chunk, dspy.Prediction):
167 |             return_value = chunk
168 |     return return_value
169 |
170 | program_output = asyncio.run(read_output_stream())
171 | print("Final output: ", program_output)
172 | ```
173 |
174 | The output will look like:
175 |
176 | ```
177 | StreamResponse(predict_name='predict1', signature_field_name='answer', chunk='To')
178 | StreamResponse(predict_name='predict1', signature_field_name='answer', chunk=' get')
179 | StreamResponse(predict_name='predict1', signature_field_name='answer', chunk=' to')
180 | StreamResponse(predict_name='predict1', signature_field_name='answer', chunk=' the')
181 | StreamResponse(predict_name='predict1', signature_field_name='answer', chunk=' other side of the recipe!')
182 | StreamResponse(predict_name='predict2', signature_field_name='simplified_answer', chunk='To')
183 | StreamResponse(predict_name='predict2', signature_field_name='simplified_answer', chunk=' reach')
184 | StreamResponse(predict_name='predict2', signature_field_name='simplified_answer', chunk=' the')
185 | StreamResponse(predict_name='predict2', signature_field_name='simplified_answer', chunk=' other side of the recipe!')
186 | Final output:  Prediction(
187 |     simplified_answer='To reach the other side of the recipe!'
188 | )
189 | ```
190 |
191 | ### Streaming the Same Field Multiple Times (as in dspy.ReAct)
192 |
193 | By default, a `StreamListener` automatically closes itself after completing a single streaming session.
194 | This design helps prevent performance issues, since every token is broadcast to all configured stream listeners,
195 | and having too many active listeners can introduce significant overhead.
196 |
197 | However, in scenarios where a DSPy module is used repeatedly in a loop—such as with `dspy.ReAct` — you may want to stream
198 | the same field from each prediction, every time it is used. To enable this behavior, set allow_reuse=True when creating
199 | your `StreamListener`. See the example below:
200 |
201 | ```python
202 | import asyncio
203 |
204 | import dspy
205 |
206 | lm = dspy.LM("openai/gpt-4o-mini", cache=False)
207 | dspy.settings.configure(lm=lm)
208 |
209 |
210 | def fetch_user_info(user_name: str):
211 |     """Get user information like name, birthday, etc."""
212 |     return {
213 |         "name": user_name,
214 |         "birthday": "2009-05-16",
215 |     }
216 |
217 |
218 | def get_sports_news(year: int):
219 |     """Get sports news for a given year."""
220 |     if year == 2009:
221 |         return "Usane Bolt broke the world record in the 100m race."
222 |     return None
223 |
224 |
225 | react = dspy.ReAct("question->answer", tools=[fetch_user_info, get_sports_news])
226 |
227 | stream_listeners = [
228 |     # dspy.ReAct has a built-in output field called "next_thought".
229 |     dspy.streaming.StreamListener(signature_field_name="next_thought", allow_reuse=True),
230 | ]
231 | stream_react = dspy.streamify(react, stream_listeners=stream_listeners)
232 |
233 |
234 | async def read_output_stream():
235 |     output = stream_react(question="What sports news happened in the year Adam was born?")
236 |     return_value = None
237 |     async for chunk in output:
238 |         if isinstance(chunk, dspy.streaming.StreamResponse):
239 |             print(chunk)
240 |         elif isinstance(chunk, dspy.Prediction):
241 |             return_value = chunk
242 |     return return_value
243 |
244 |
245 | print(asyncio.run(read_output_stream()))
246 | ```
247 |
248 | In this example, by setting `allow_reuse=True` in the StreamListener, you ensure that streaming for "next_thought" is
249 | available for every iteration, not just the first. When you run this code, you will see the streaming tokens for `next_thought`
250 | output each time the field is produced.
251 |
252 | #### Handling Duplicate Field Names
253 |
254 | When streaming fields with the same name from different modules, specify both the `predict` and `predict_name` in the `StreamListener`:
255 |
256 | ```python
257 | import asyncio
258 |
259 | import dspy
260 |
261 | lm = dspy.LM("openai/gpt-4o-mini", cache=False)
262 | dspy.settings.configure(lm=lm)
263 |
264 |
265 | class MyModule(dspy.Module):
266 |     def __init__(self):
267 |         super().__init__()
268 |
269 |         self.predict1 = dspy.Predict("question->answer")
270 |         self.predict2 = dspy.Predict("question, answer->answer, score")
271 |
272 |     def forward(self, question: str, **kwargs):
273 |         answer = self.predict1(question=question)
274 |         simplified_answer = self.predict2(answer=answer)
275 |         return simplified_answer
276 |
277 |
278 | predict = MyModule()
279 | stream_listeners = [
280 |     dspy.streaming.StreamListener(
281 |         signature_field_name="answer",
282 |         predict=predict.predict1,
283 |         predict_name="predict1"
284 |     ),
285 |     dspy.streaming.StreamListener(
286 |         signature_field_name="answer",
287 |         predict=predict.predict2,
288 |         predict_name="predict2"
289 |     ),
290 | ]
291 | stream_predict = dspy.streamify(
292 |     predict,
293 |     stream_listeners=stream_listeners,
294 | )
295 |
296 |
297 | async def read_output_stream():
298 |     output = stream_predict(question="why did a chicken cross the kitchen?")
299 |
300 |     return_value = None
301 |     async for chunk in output:
302 |         if isinstance(chunk, dspy.streaming.StreamResponse):
303 |             print(chunk)
304 |         elif isinstance(chunk, dspy.Prediction):
305 |             return_value = chunk
306 |     return return_value
307 |
308 |
309 | program_output = asyncio.run(read_output_stream())
310 | print("Final output: ", program_output)
311 | ```
312 |
313 | The output will be like:
314 |
315 | ```
316 | StreamResponse(predict_name='predict1', signature_field_name='answer', chunk='To')
317 | StreamResponse(predict_name='predict1', signature_field_name='answer', chunk=' get')
318 | StreamResponse(predict_name='predict1', signature_field_name='answer', chunk=' to')
319 | StreamResponse(predict_name='predict1', signature_field_name='answer', chunk=' the')
320 | StreamResponse(predict_name='predict1', signature_field_name='answer', chunk=' other side of the recipe!')
321 | StreamResponse(predict_name='predict2', signature_field_name='answer', chunk="I'm")
322 | StreamResponse(predict_name='predict2', signature_field_name='answer', chunk=' ready')
323 | StreamResponse(predict_name='predict2', signature_field_name='answer', chunk=' to')
324 | StreamResponse(predict_name='predict2', signature_field_name='answer', chunk=' assist')
325 | StreamResponse(predict_name='predict2', signature_field_name='answer', chunk=' you')
326 | StreamResponse(predict_name='predict2', signature_field_name='answer', chunk='! Please provide a question.')
327 | Final output:  Prediction(
328 |     answer="I'm ready to assist you! Please provide a question.",
329 |     score='N/A'
330 | )
331 | ```
332 |
333 | ## Intermediate Status Streaming
334 |
335 | Status streaming keeps users informed about the program's progress, especially useful for long-running operations like tool calls or complex AI pipelines. To implement status streaming:
336 |
337 | 1. Create a custom status message provider by subclassing `dspy.streaming.StatusMessageProvider`
338 | 2. Override the desired hook methods to provide custom status messages
339 | 3. Pass your provider to `dspy.streamify`
340 |
341 | Example:
342 |
343 | ```python
344 | class MyStatusMessageProvider(dspy.streaming.StatusMessageProvider):
345 |     def lm_start_status_message(self, instance, inputs):
346 |         return f"Calling LM with inputs {inputs}..."
347 |
348 |     def lm_end_status_message(self, outputs):
349 |         return f"Tool finished with output: {outputs}!"
350 | ```
351 |
352 | Available hooks:
353 |
354 | - lm_start_status_message: status message at the start of calling dspy.LM.
355 | - lm_end_status_message: status message at the end of calling dspy.LM.
356 | - module_start_status_message: status message at the start of calling a dspy.Module.
357 | - module_end_status_message: status message at the start of calling a dspy.Module.
358 | - tool_start_status_message: status message at the start of calling dspy.Tool.
359 | - tool_end_status_message: status message at the end of calling dspy.Tool.
360 |
361 | Each hook should return a string containing the status message.
362 |
363 | After creating the message provider, just pass it to `dspy.streamify`, and you can enable both
364 | status message streaming and output token streaming. Please see the example below. The intermediate
365 | status message is represented in the class `dspy.streaming.StatusMessage`, so we need to have
366 | another condition check to capture it.
367 |
368 | ```python
369 | import asyncio
370 |
371 | import dspy
372 |
373 | lm = dspy.LM("openai/gpt-4o-mini", cache=False)
374 | dspy.settings.configure(lm=lm)
375 |
376 |
377 | class MyModule(dspy.Module):
378 |     def __init__(self):
379 |         super().__init__()
380 |
381 |         self.tool = dspy.Tool(lambda x: 2 * x, name="double_the_number")
382 |         self.predict = dspy.ChainOfThought("num1, num2->sum")
383 |
384 |     def forward(self, num, **kwargs):
385 |         num2 = self.tool(x=num)
386 |         return self.predict(num1=num, num2=num2)
387 |
388 |
389 | class MyStatusMessageProvider(dspy.streaming.StatusMessageProvider):
390 |     def tool_start_status_message(self, instance, inputs):
391 |         return f"Calling Tool {instance.name} with inputs {inputs}..."
392 |
393 |     def tool_end_status_message(self, outputs):
394 |         return f"Tool finished with output: {outputs}!"
395 |
396 |
397 | predict = MyModule()
398 | stream_listeners = [
399 |     # dspy.ChainOfThought has a built-in output field called "reasoning".
400 |     dspy.streaming.StreamListener(signature_field_name="reasoning"),
401 | ]
402 | stream_predict = dspy.streamify(
403 |     predict,
404 |     stream_listeners=stream_listeners,
405 |     status_message_provider=MyStatusMessageProvider(),
406 | )
407 |
408 |
409 | async def read_output_stream():
410 |     output = stream_predict(num=3)
411 |
412 |     return_value = None
413 |     async for chunk in output:
414 |         if isinstance(chunk, dspy.streaming.StreamResponse):
415 |             print(chunk)
416 |         elif isinstance(chunk, dspy.Prediction):
417 |             return_value = chunk
418 |         elif isinstance(chunk, dspy.streaming.StatusMessage):
419 |             print(chunk)
420 |     return return_value
421 |
422 |
423 | program_output = asyncio.run(read_output_stream())
424 | print("Final output: ", program_output)
425 | ```
426 |
427 | Sample output:
428 |
429 | ```
430 | StatusMessage(message='Calling tool double_the_number...')
431 | StatusMessage(message='Tool calling finished! Querying the LLM with tool calling results...')
432 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk='To')
433 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' find')
434 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' the')
435 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' sum')
436 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' of')
437 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' the')
438 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' two')
439 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' numbers')
440 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=',')
441 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' we')
442 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' simply')
443 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' add')
444 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' them')
445 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' together')
446 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk='.')
447 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' Here')
448 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=',')
449 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' ')
450 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk='3')
451 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' plus')
452 | StreamResponse(predict_name='predict.predict', signature_field_name='reasoning', chunk=' 6 equals 9.')
453 | Final output:  Prediction(
454 |     reasoning='To find the sum of the two numbers, we simply add them together. Here, 3 plus 6 equals 9.',
455 |     sum='9'
456 | )
457 | ```
458 |
459 | ## Synchronous Streaming
460 |
461 | By default calling a streamified DSPy program produces an async generator. In order to get back
462 | a sync generator, you can set the flag `async_streaming=False`:
463 |
464 |
465 | ```python
466 | import os
467 |
468 | import dspy
469 |
470 | os.environ["OPENAI_API_KEY"] = "your_api_key"
471 |
472 | dspy.configure(lm=dspy.LM("openai/gpt-4o-mini"))
473 |
474 | predict = dspy.Predict("question->answer")
475 |
476 | # Enable streaming for the 'answer' field
477 | stream_predict = dspy.streamify(
478 |     predict,
479 |     stream_listeners=[dspy.streaming.StreamListener(signature_field_name="answer")],
480 |     async_streaming=False,
481 | )
482 |
483 | output = stream_predict(question="why did a chicken cross the kitchen?")
484 |
485 | program_output = None
486 | for chunk in output:
487 |     if isinstance(chunk, dspy.streaming.StreamResponse):
488 |         print(chunk)
489 |     elif isinstance(chunk, dspy.Prediction):
490 |         program_output = chunk
491 | print(f"Program output: {program_output}")
492 | ```
```

tool_use/index.ipynb
```
1 | {
2 |  "cells": [
3 |   {
4 |    "cell_type": "markdown",
5 |    "metadata": {},
6 |    "source": [
7 |     "# Tutorial: Advanced Tool Use\n",
8 |     "\n",
9 |     "Let's walk through a quick example of building and prompt-optimizing a DSPy agent for advanced tool use. We'll do this for the challenging task [ToolHop](https://arxiv.org/abs/2501.02506) but with an even stricter evaluation criteria.\n",
10 |     "\n",
11 |     "Install the latest DSPy via `pip install -U dspy` and follow along. You will also need to `pip install func_timeout datasets`."
12 |    ]
13 |   },
14 |   {
15 |    "cell_type": "markdown",
16 |    "metadata": {},
17 |    "source": [
18 |     "<details>\n",
19 |     "<summary>Recommended: Set up MLflow Tracing to understand what's happening under the hood.</summary>\n",
20 |     "\n",
21 |     "### MLflow DSPy Integration\n",
22 |     "\n",
23 |     "<a href=\"https://mlflow.org/\">MLflow</a> is an LLMOps tool that natively integrates with DSPy and offer explainability and experiment tracking. In this tutorial, you can use MLflow to visualize prompts and optimization progress as traces to understand the DSPy's behavior better. You can set up MLflow easily by following the four steps below.\n",
24 |     "\n",
25 |     "1. Install MLflow\n",
26 |     "\n",
27 |     "```bash\n",
28 |     "%pip install mlflow>=2.20\n",
29 |     "```\n",
30 |     "\n",
31 |     "2. Start MLflow UI in a separate terminal\n",
32 |     "```bash\n",
33 |     "mlflow ui --port 5000\n",
34 |     "```\n",
35 |     "\n",
36 |     "3. Connect the notebook to MLflow\n",
37 |     "```python\n",
38 |     "import mlflow\n",
39 |     "\n",
40 |     "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
41 |     "mlflow.set_experiment(\"DSPy\")\n",
42 |     "```\n",
43 |     "\n",
44 |     "4. Enabling tracing.\n",
45 |     "```python\n",
46 |     "mlflow.dspy.autolog()\n",
47 |     "```\n",
48 |     "\n",
49 |     "To learn more about the integration, visit [MLflow DSPy Documentation](https://mlflow.org/docs/latest/llms/dspy/index.html) as well.\n",
50 |     "</details>"
51 |    ]
52 |   },
53 |   {
54 |    "cell_type": "markdown",
55 |    "metadata": {},
56 |    "source": [
57 |     "In this tutorial, we'll demonstrate the new experimental `dspy.SIMBA` prompt optimizer, which tends to be powerful for larger LLMs and harder tasks. Using this, we'll improve our agent from 35% accuracy to 60%."
58 |    ]
59 |   },
60 |   {
61 |    "cell_type": "code",
62 |    "execution_count": 1,
63 |    "metadata": {},
64 |    "outputs": [],
65 |    "source": [
66 |     "import dspy\n",
67 |     "import ujson\n",
68 |     "import random\n",
69 |     "\n",
70 |     "gpt4o = dspy.LM(\"openai/gpt-4o\", temperature=0.7)\n",
71 |     "dspy.configure(lm=gpt4o)"
72 |    ]
73 |   },
74 |   {
75 |    "cell_type": "markdown",
76 |    "metadata": {},
77 |    "source": [
78 |     "Let's now download the data."
79 |    ]
80 |   },
81 |   {
82 |    "cell_type": "code",
83 |    "execution_count": 2,
84 |    "metadata": {},
85 |    "outputs": [
86 |     {
87 |      "name": "stdout",
88 |      "output_type": "stream",
89 |      "text": [
90 |       "Downloading 'ToolHop.json'...\n"
91 |      ]
92 |     }
93 |    ],
94 |    "source": [
95 |     "from dspy.utils import download\n",
96 |     "\n",
97 |     "download(\"https://huggingface.co/datasets/bytedance-research/ToolHop/resolve/main/data/ToolHop.json\")\n",
98 |     "\n",
99 |     "data = ujson.load(open(\"ToolHop.json\"))\n",
100 |     "random.Random(0).shuffle(data)"
101 |    ]
102 |   },
103 |   {
104 |    "cell_type": "markdown",
105 |    "metadata": {},
106 |    "source": [
107 |     "Then let's prepare a cleaned set of examples. The ToolHop task is interesting in that the agent gets a _unique set_ of tools (functions) to use separately for each request. Thus, it needs to learn how to use _any_ such tools effectively in practice."
108 |    ]
109 |   },
110 |   {
111 |    "cell_type": "code",
112 |    "execution_count": 3,
113 |    "metadata": {},
114 |    "outputs": [],
115 |    "source": [
116 |     "import re\n",
117 |     "import inspect\n",
118 |     "\n",
119 |     "examples = []\n",
120 |     "fns2code = {}\n",
121 |     "\n",
122 |     "def finish(answer: str):\n",
123 |     "    \"\"\"Conclude the trajectory and return the final answer.\"\"\"\n",
124 |     "    return answer\n",
125 |     "\n",
126 |     "for datapoint in data:\n",
127 |     "    func_dict = {}\n",
128 |     "    for func_code in datapoint[\"functions\"]:\n",
129 |     "        cleaned_code = func_code.rsplit(\"\\n\\n# Example usage\", 1)[0]\n",
130 |     "        fn_name = re.search(r\"^\\s*def\\s+([a-zA-Z0-9_]+)\\s*\\(\", cleaned_code)\n",
131 |     "        fn_name = fn_name.group(1) if fn_name else None\n",
132 |     "\n",
133 |     "        if not fn_name:\n",
134 |     "            continue\n",
135 |     "\n",
136 |     "        local_vars = {}\n",
137 |     "        exec(cleaned_code, {}, local_vars)\n",
138 |     "        fn_obj = local_vars.get(fn_name)\n",
139 |     "\n",
140 |     "        if callable(fn_obj):\n",
141 |     "            func_dict[fn_name] = fn_obj\n",
142 |     "            assert fn_obj not in fns2code, f\"Duplicate function found: {fn_name}\"\n",
143 |     "            fns2code[fn_obj] = (fn_name, cleaned_code)\n",
144 |     "\n",
145 |     "    func_dict[\"finish\"] = finish\n",
146 |     "\n",
147 |     "    example = dspy.Example(question=datapoint[\"question\"], answer=datapoint[\"answer\"], functions=func_dict)\n",
148 |     "    examples.append(example.with_inputs(\"question\", \"functions\"))\n",
149 |     "\n",
150 |     "trainset, devset, testset = examples[:100], examples[100:400], examples[400:]"
151 |    ]
152 |   },
153 |   {
154 |    "cell_type": "markdown",
155 |    "metadata": {},
156 |    "source": [
157 |     "And let's define some helpers for the task. Here, we will define the `metric`, which will be (much) stricter than in the original paper: we'll expect the prediction to match exactly (after normalization) with the ground truth. We'll also be strict in a second way: we'll only allow the agent to take 5 steps in total, to allow for efficient deployment."
158 |    ]
159 |   },
160 |   {
161 |    "cell_type": "code",
162 |    "execution_count": 4,
163 |    "metadata": {},
164 |    "outputs": [],
165 |    "source": [
166 |     "from func_timeout import func_set_timeout\n",
167 |     "\n",
168 |     "def wrap_function_with_timeout(fn):\n",
169 |     "    @func_set_timeout(10)\n",
170 |     "    def wrapper(*args, **kwargs):\n",
171 |     "        try:\n",
172 |     "            return {\"return_value\": fn(*args, **kwargs), \"errors\": None}\n",
173 |     "        except Exception as e:\n",
174 |     "            return {\"return_value\": None, \"errors\": str(e)}\n",
175 |     "\n",
176 |     "    return wrapper\n",
177 |     "\n",
178 |     "def fn_metadata(func):\n",
179 |     "    signature = inspect.signature(func)\n",
180 |     "    docstring = inspect.getdoc(func) or \"No docstring.\"\n",
181 |     "    return dict(function_name=func.__name__, arguments=str(signature), docstring=docstring)\n",
182 |     "\n",
183 |     "def metric(example, pred, trace=None):\n",
184 |     "    gold = str(example.answer).rstrip(\".0\").replace(\",\", \"\").lower()\n",
185 |     "    pred = str(pred.answer).rstrip(\".0\").replace(\",\", \"\").lower()\n",
186 |     "    return pred == gold  # stricter than the original paper's metric!\n",
187 |     "\n",
188 |     "evaluate = dspy.Evaluate(devset=devset, metric=metric, num_threads=24, display_progress=True, display_table=0, max_errors=999)"
189 |    ]
190 |   },
191 |   {
192 |    "cell_type": "markdown",
193 |    "metadata": {},
194 |    "source": [
195 |     "Now, let's define the agent! The core of our agent will be based on a ReAct loop, in which the model sees the trajectory so far and the set of functions available to invoke, and decides the next tool to call.\n",
196 |     "\n",
197 |     "To keep the final agent fast, we'll limit its `max_steps` to 5 steps. We'll also run each function call with a timeout."
198 |    ]
199 |   },
200 |   {
201 |    "cell_type": "code",
202 |    "execution_count": 5,
203 |    "metadata": {},
204 |    "outputs": [],
205 |    "source": [
206 |     "class Agent(dspy.Module):\n",
207 |     "    def __init__(self, max_steps=5):\n",
208 |     "        self.max_steps = max_steps\n",
209 |     "        instructions = \"For the final answer, produce short (not full sentence) answers in which you format dates as YYYY-MM-DD, names as Firstname Lastname, and numbers without leading 0s.\"\n",
210 |     "        signature = dspy.Signature('question, trajectory, functions -> next_selected_fn, args: dict[str, Any]', instructions)\n",
211 |     "        self.react = dspy.ChainOfThought(signature)\n",
212 |     "\n",
213 |     "    def forward(self, question, functions):\n",
214 |     "        tools = {fn_name: fn_metadata(fn) for fn_name, fn in functions.items()}\n",
215 |     "        trajectory = []\n",
216 |     "\n",
217 |     "        for _ in range(self.max_steps):\n",
218 |     "            pred = self.react(question=question, trajectory=trajectory, functions=tools)\n",
219 |     "            selected_fn = pred.next_selected_fn.strip('\"').strip(\"'\")\n",
220 |     "            fn_output = wrap_function_with_timeout(functions[selected_fn])(**pred.args)\n",
221 |     "            trajectory.append(dict(reasoning=pred.reasoning, selected_fn=selected_fn, args=pred.args, **fn_output))\n",
222 |     "\n",
223 |     "            if selected_fn == \"finish\":\n",
224 |     "                break\n",
225 |     "\n",
226 |     "        return dspy.Prediction(answer=fn_output.get(\"return_value\", ''), trajectory=trajectory)"
227 |    ]
228 |   },
229 |   {
230 |    "cell_type": "markdown",
231 |    "metadata": {},
232 |    "source": [
233 |     "Out of the box, let's assess our `GPT-4o`-powered agent on the development set."
234 |    ]
235 |   },
236 |   {
237 |    "cell_type": "code",
238 |    "execution_count": 6,
239 |    "metadata": {},
240 |    "outputs": [
241 |     {
242 |      "name": "stderr",
243 |      "output_type": "stream",
244 |      "text": [
245 |       "2025/03/23 21:46:10 INFO dspy.evaluate.evaluate: Average Metric: 105.0 / 300 (35.0%)\n"
246 |      ]
247 |     },
248 |     {
249 |      "data": {
250 |       "text/plain": [
251 |        "35.0"
252 |       ]
253 |      },
254 |      "execution_count": 7,
255 |      "metadata": {},
256 |      "output_type": "execute_result"
257 |     }
258 |    ],
259 |    "source": [
260 |     "agent = Agent()\n",
261 |     "evaluate(agent)"
262 |    ]
263 |   },
264 |   {
265 |    "cell_type": "markdown",
266 |    "metadata": {},
267 |    "source": [
268 |     "Now, let's optimize the agent using `dspy.SIMBA`, which stands for **Stochastic Introspective Mini-Batch Ascent**. This prompt optimizer accepts arbitrary DSPy programs like our agent here and proceeds in a sequence of mini-batches seeking to make incremental improvements to the prompt instructions or few-shot examples."
269 |    ]
270 |   },
271 |   {
272 |    "cell_type": "code",
273 |    "execution_count": null,
274 |    "metadata": {},
275 |    "outputs": [],
276 |    "source": [
277 |     "simba = dspy.SIMBA(metric=metric, max_steps=12, max_demos=10)\n",
278 |     "optimized_agent = simba.compile(agent, trainset=trainset, seed=6793115)"
279 |    ]
280 |   },
281 |   {
282 |    "cell_type": "markdown",
283 |    "metadata": {},
284 |    "source": [
285 |     "Having completed this optimization, let's now evaluate our agent again. We see a substantial 71% relative gain, jumping to 60% accuracy."
286 |    ]
287 |   },
288 |   {
289 |    "cell_type": "code",
290 |    "execution_count": 8,
291 |    "metadata": {},
292 |    "outputs": [
293 |     {
294 |      "name": "stderr",
295 |      "output_type": "stream",
296 |      "text": [
297 |       "2025/03/23 21:46:21 INFO dspy.evaluate.evaluate: Average Metric: 182.0 / 300 (60.7%)"
298 |      ]
299 |     },
300 |     {
301 |      "data": {
302 |       "text/plain": [
303 |        "60.67"
304 |       ]
305 |      },
306 |      "execution_count": 8,
307 |      "metadata": {},
308 |      "output_type": "execute_result"
309 |     }
310 |    ],
311 |    "source": [
312 |     "evaluate(optimized_agent)"
313 |    ]
314 |   }
315 |  ],
316 |  "metadata": {
317 |   "kernelspec": {
318 |    "display_name": "jun2024_py310",
319 |    "language": "python",
320 |    "name": "python3"
321 |   },
322 |   "language_info": {
323 |    "codemirror_mode": {
324 |     "name": "ipython",
325 |     "version": 3
326 |    },
327 |    "file_extension": ".py",
328 |    "mimetype": "text/x-python",
329 |    "name": "python",
330 |    "nbconvert_exporter": "python",
331 |    "pygments_lexer": "ipython3",
332 |    "version": "3.10.14"
333 |   }
334 |  },
335 |  "nbformat": 4,
336 |  "nbformat_minor": 2
337 | }
```

yahoo_finance_react/index.md
```
1 | # Financial Analysis with DSPy ReAct and Yahoo Finance News
2 |
3 | This tutorial shows how to build a financial analysis agent using DSPy ReAct with [LangChain's Yahoo Finance News tool](https://python.langchain.com/docs/integrations/tools/yahoo_finance_news/) for real-time market analysis.
4 |
5 | ## What You'll Build
6 |
7 | A financial agent that fetches news, analyzes sentiment, and provides investment insights.
8 |
9 | ## Setup
10 |
11 | ```bash
12 | pip install dspy langchain langchain-community yfinance
13 | ```
14 |
15 | ## Step 1: Convert LangChain Tool to DSPy
16 |
17 | ```python
18 | import dspy
19 | from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool
20 | from dspy.adapters.types.tool import Tool
21 | import json
22 | import yfinance as yf
23 |
24 | # Configure DSPy
25 | lm = dspy.LM(model='openai/gpt-4o-mini')
26 | dspy.configure(lm=lm)
27 |
28 | # Convert LangChain Yahoo Finance tool to DSPy
29 | yahoo_finance_tool = YahooFinanceNewsTool()
30 | finance_news_tool = Tool.from_langchain(yahoo_finance_tool)
31 | ```
32 |
33 | ## Step 2: Create Supporting Financial Tools
34 |
35 | ```python
36 | def get_stock_price(ticker: str) -> str:
37 |     """Get current stock price and basic info."""
38 |     try:
39 |         stock = yf.Ticker(ticker)
40 |         info = stock.info
41 |         hist = stock.history(period="1d")
42 |
43 |         if hist.empty:
44 |             return f"Could not retrieve data for {ticker}"
45 |
46 |         current_price = hist['Close'].iloc[-1]
47 |         prev_close = info.get('previousClose', current_price)
48 |         change_pct = ((current_price - prev_close) / prev_close * 100) if prev_close else 0
49 |
50 |         result = {
51 |             "ticker": ticker,
52 |             "price": round(current_price, 2),
53 |             "change_percent": round(change_pct, 2),
54 |             "company": info.get('longName', ticker)
55 |         }
56 |
57 |         return json.dumps(result)
58 |     except Exception as e:
59 |         return f"Error: {str(e)}"
60 |
61 | def compare_stocks(tickers: str) -> str:
62 |     """Compare multiple stocks (comma-separated)."""
63 |     try:
64 |         ticker_list = [t.strip().upper() for t in tickers.split(',')]
65 |         comparison = []
66 |
67 |         for ticker in ticker_list:
68 |             stock = yf.Ticker(ticker)
69 |             info = stock.info
70 |             hist = stock.history(period="1d")
71 |
72 |             if not hist.empty:
73 |                 current_price = hist['Close'].iloc[-1]
74 |                 prev_close = info.get('previousClose', current_price)
75 |                 change_pct = ((current_price - prev_close) / prev_close * 100) if prev_close else 0
76 |
77 |                 comparison.append({
78 |                     "ticker": ticker,
79 |                     "price": round(current_price, 2),
80 |                     "change_percent": round(change_pct, 2)
81 |                 })
82 |
83 |         return json.dumps(comparison)
84 |     except Exception as e:
85 |         return f"Error: {str(e)}"
86 | ```
87 |
88 | ## Step 3: Build the Financial ReAct Agent
89 |
90 | ```python
91 | class FinancialAnalysisAgent(dspy.Module):
92 |     """ReAct agent for financial analysis using Yahoo Finance data."""
93 |
94 |     def __init__(self):
95 |         super().__init__()
96 |
97 |         # Combine all tools
98 |         self.tools = [
99 |             finance_news_tool,  # LangChain Yahoo Finance News
100 |             get_stock_price,
101 |             compare_stocks
102 |         ]
103 |
104 |         # Initialize ReAct
105 |         self.react = dspy.ReAct(
106 |             signature="financial_query -> analysis_response",
107 |             tools=self.tools,
108 |             max_iters=6
109 |         )
110 |
111 |     def forward(self, financial_query: str):
112 |         return self.react(financial_query=financial_query)
113 | ```
114 |
115 | ## Step 4: Run Financial Analysis
116 |
117 | ```python
118 | def run_financial_demo():
119 |     """Demo of the financial analysis agent."""
120 |
121 |     # Initialize agent
122 |     agent = FinancialAnalysisAgent()
123 |
124 |     # Example queries
125 |     queries = [
126 |         "What's the latest news about Apple (AAPL) and how might it affect the stock price?",
127 |         "Compare AAPL, GOOGL, and MSFT performance",
128 |         "Find recent Tesla news and analyze sentiment"
129 |     ]
130 |
131 |     for query in queries:
132 |         print(f"Query: {query}")
133 |         response = agent(financial_query=query)
134 |         print(f"Analysis: {response.analysis_response}")
135 |         print("-" * 50)
136 |
137 | # Run the demo
138 | if __name__ == "__main__":
139 |     run_financial_demo()
140 | ```
141 |
142 | ## Example Output
143 |
144 | When you run the agent with a query like "What's the latest news about Apple?", it will:
145 |
146 | 1. Use the Yahoo Finance News tool to fetch recent Apple news
147 | 2. Get current stock price data
148 | 3. Analyze the information and provide insights
149 |
150 | **Sample Response:**
151 | ```
152 | Analysis: Given the current price of Apple (AAPL) at $196.58 and the slight increase of 0.48%, it appears that the stock is performing steadily in the market. However, the inability to access the latest news means that any significant developments that could influence investor sentiment and stock price are unknown. Investors should keep an eye on upcoming announcements or market trends that could impact Apple's performance, especially in comparison to other tech stocks like Microsoft (MSFT), which is also showing a positive trend.
153 | ```
154 |
155 | ## Key Benefits
156 |
157 | - **Tool Integration**: Seamlessly combine LangChain tools with DSPy ReAct
158 | - **Real-time Data**: Access current market data and news
159 | - **Extensible**: Easy to add more financial analysis tools
160 | - **Intelligent Reasoning**: ReAct framework provides step-by-step analysis
161 |
162 | This tutorial shows how DSPy's ReAct framework works with LangChain's financial tools to create intelligent market analysis agents.
```
