Project Structure:
├── index.ts
├── package.json
├── src
│   ├── __mocks__
│   │   └── fs
│   │       └── promises.ts
│   ├── agents
│   │   ├── codebase-investigator.ts
│   │   ├── executor.test.ts
│   │   ├── executor.ts
│   │   ├── invocation.test.ts
│   │   ├── invocation.ts
│   │   ├── registry.test.ts
│   │   ├── registry.ts
│   │   ├── schema-utils.test.ts
│   │   ├── schema-utils.ts
│   │   ├── subagent-tool-wrapper.test.ts
│   │   ├── subagent-tool-wrapper.ts
│   │   ├── types.ts
│   │   ├── utils.test.ts
│   │   └── utils.ts
│   ├── code_assist
│   │   ├── codeAssist.ts
│   │   ├── converter.test.ts
│   │   ├── converter.ts
│   │   ├── oauth-credential-storage.test.ts
│   │   ├── oauth-credential-storage.ts
│   │   ├── oauth2.test.ts
│   │   ├── oauth2.ts
│   │   ├── server.test.ts
│   │   ├── server.ts
│   │   ├── setup.test.ts
│   │   ├── setup.ts
│   │   └── types.ts
│   ├── config
│   │   ├── config.test.ts
│   │   ├── config.ts
│   │   ├── constants.ts
│   │   ├── flashFallback.test.ts
│   │   ├── models.test.ts
│   │   ├── models.ts
│   │   ├── storage.test.ts
│   │   └── storage.ts
│   ├── confirmation-bus
│   │   ├── index.ts
│   │   ├── message-bus.test.ts
│   │   ├── message-bus.ts
│   │   └── types.ts
│   ├── core
│   │   ├── __snapshots__
│   │   │   └── prompts.test.ts.snap
│   │   ├── baseLlmClient.test.ts
│   │   ├── baseLlmClient.ts
│   │   ├── client.test.ts
│   │   ├── client.ts
│   │   ├── contentGenerator.test.ts
│   │   ├── contentGenerator.ts
│   │   ├── coreToolScheduler.test.ts
│   │   ├── coreToolScheduler.ts
│   │   ├── geminiChat.test.ts
│   │   ├── geminiChat.ts
│   │   ├── geminiRequest.ts
│   │   ├── logger.test.ts
│   │   ├── logger.ts
│   │   ├── loggingContentGenerator.ts
│   │   ├── nonInteractiveToolExecutor.test.ts
│   │   ├── nonInteractiveToolExecutor.ts
│   │   ├── prompts.test.ts
│   │   ├── prompts.ts
│   │   ├── subagent.test.ts
│   │   ├── subagent.ts
│   │   ├── tokenLimits.ts
│   │   ├── turn.test.ts
│   │   └── turn.ts
│   ├── fallback
│   │   ├── handler.test.ts
│   │   ├── handler.ts
│   │   └── types.ts
│   ├── ide
│   │   ├── constants.ts
│   │   ├── detect-ide.test.ts
│   │   ├── detect-ide.ts
│   │   ├── ide-client.test.ts
│   │   ├── ide-client.ts
│   │   ├── ide-installer.test.ts
│   │   ├── ide-installer.ts
│   │   ├── ideContext.test.ts
│   │   ├── ideContext.ts
│   │   ├── process-utils.test.ts
│   │   ├── process-utils.ts
│   │   └── types.ts
│   ├── index.test.ts
│   ├── index.ts
│   ├── mcp
│   │   ├── google-auth-provider.test.ts
│   │   ├── google-auth-provider.ts
│   │   ├── oauth-provider.test.ts
│   │   ├── oauth-provider.ts
│   │   ├── oauth-token-storage.test.ts
│   │   ├── oauth-token-storage.ts
│   │   ├── oauth-utils.test.ts
│   │   ├── oauth-utils.ts
│   │   ├── sa-impersonation-provider.test.ts
│   │   ├── sa-impersonation-provider.ts
│   │   └── token-storage
│   │       ├── base-token-storage.test.ts
│   │       ├── base-token-storage.ts
│   │       ├── file-token-storage.test.ts
│   │       ├── file-token-storage.ts
│   │       ├── hybrid-token-storage.test.ts
│   │       ├── hybrid-token-storage.ts
│   │       ├── index.ts
│   │       ├── keychain-token-storage.test.ts
│   │       ├── keychain-token-storage.ts
│   │       └── types.ts
│   ├── mocks
│   │   └── msw.ts
│   ├── output
│   │   ├── json-formatter.test.ts
│   │   ├── json-formatter.ts
│   │   └── types.ts
│   ├── policy
│   │   ├── index.ts
│   │   ├── policy-engine.test.ts
│   │   ├── policy-engine.ts
│   │   ├── stable-stringify.ts
│   │   └── types.ts
│   ├── prompts
│   │   ├── mcp-prompts.ts
│   │   └── prompt-registry.ts
│   ├── routing
│   │   ├── modelRouterService.test.ts
│   │   ├── modelRouterService.ts
│   │   ├── routingStrategy.ts
│   │   └── strategies
│   │       ├── classifierStrategy.test.ts
│   │       ├── classifierStrategy.ts
│   │       ├── compositeStrategy.test.ts
│   │       ├── compositeStrategy.ts
│   │       ├── defaultStrategy.test.ts
│   │       ├── defaultStrategy.ts
│   │       ├── fallbackStrategy.test.ts
│   │       ├── fallbackStrategy.ts
│   │       ├── overrideStrategy.test.ts
│   │       └── overrideStrategy.ts
│   ├── services
│   │   ├── chatRecordingService.test.ts
│   │   ├── chatRecordingService.ts
│   │   ├── fileDiscoveryService.test.ts
│   │   ├── fileDiscoveryService.ts
│   │   ├── fileSystemService.test.ts
│   │   ├── fileSystemService.ts
│   │   ├── gitService.test.ts
│   │   ├── gitService.ts
│   │   ├── loopDetectionService.test.ts
│   │   ├── loopDetectionService.ts
│   │   ├── shellExecutionService.test.ts
│   │   └── shellExecutionService.ts
│   ├── telemetry
│   │   ├── activity-detector.test.ts
│   │   ├── activity-detector.ts
│   │   ├── activity-types.ts
│   │   ├── clearcut-logger
│   │   │   ├── clearcut-logger.test.ts
│   │   │   ├── clearcut-logger.ts
│   │   │   └── event-metadata-key.ts
│   │   ├── config.test.ts
│   │   ├── config.ts
│   │   ├── constants.ts
│   │   ├── file-exporters.ts
│   │   ├── gcp-exporters.test.ts
│   │   ├── gcp-exporters.ts
│   │   ├── high-water-mark-tracker.test.ts
│   │   ├── high-water-mark-tracker.ts
│   │   ├── index.ts
│   │   ├── integration.test.circular.ts
│   │   ├── loggers.test.circular.ts
│   │   ├── loggers.test.ts
│   │   ├── loggers.ts
│   │   ├── memory-monitor.test.ts
│   │   ├── memory-monitor.ts
│   │   ├── metrics.test.ts
│   │   ├── metrics.ts
│   │   ├── rate-limiter.test.ts
│   │   ├── rate-limiter.ts
│   │   ├── sdk.test.ts
│   │   ├── sdk.ts
│   │   ├── telemetry-utils.test.ts
│   │   ├── telemetry-utils.ts
│   │   ├── telemetry.test.ts
│   │   ├── telemetryAttributes.ts
│   │   ├── tool-call-decision.ts
│   │   ├── types.ts
│   │   ├── uiTelemetry.test.ts
│   │   └── uiTelemetry.ts
│   ├── test-utils
│   │   ├── config.ts
│   │   ├── index.ts
│   │   ├── mock-tool.ts
│   │   └── mockWorkspaceContext.ts
│   ├── tools
│   │   ├── __snapshots__
│   │   │   └── shell.test.ts.snap
│   │   ├── diffOptions.test.ts
│   │   ├── diffOptions.ts
│   │   ├── edit.test.ts
│   │   ├── edit.ts
│   │   ├── glob.test.ts
│   │   ├── glob.ts
│   │   ├── grep.test.ts
│   │   ├── grep.ts
│   │   ├── ls.test.ts
│   │   ├── ls.ts
│   │   ├── mcp-client-manager.test.ts
│   │   ├── mcp-client-manager.ts
│   │   ├── mcp-client.test.ts
│   │   ├── mcp-client.ts
│   │   ├── mcp-tool.test.ts
│   │   ├── mcp-tool.ts
│   │   ├── memoryTool.test.ts
│   │   ├── memoryTool.ts
│   │   ├── message-bus-integration.test.ts
│   │   ├── modifiable-tool.test.ts
│   │   ├── modifiable-tool.ts
│   │   ├── read-file.test.ts
│   │   ├── read-file.ts
│   │   ├── read-many-files.test.ts
│   │   ├── read-many-files.ts
│   │   ├── ripGrep.test.ts
│   │   ├── ripGrep.ts
│   │   ├── shell.test.ts
│   │   ├── shell.ts
│   │   ├── smart-edit.test.ts
│   │   ├── smart-edit.ts
│   │   ├── tool-error.ts
│   │   ├── tool-names.ts
│   │   ├── tool-registry.test.ts
│   │   ├── tool-registry.ts
│   │   ├── tools.test.ts
│   │   ├── tools.ts
│   │   ├── web-fetch.test.ts
│   │   ├── web-fetch.ts
│   │   ├── web-search.test.ts
│   │   ├── web-search.ts
│   │   ├── write-file.test.ts
│   │   ├── write-file.ts
│   │   ├── write-todos.test.ts
│   │   └── write-todos.ts
│   └── utils
│       ├── LruCache.ts
│       ├── bfsFileSearch.test.ts
│       ├── bfsFileSearch.ts
│       ├── browser.ts
│       ├── editCorrector.test.ts
│       ├── editCorrector.ts
│       ├── editor.test.ts
│       ├── editor.ts
│       ├── environmentContext.test.ts
│       ├── environmentContext.ts
│       ├── errorParsing.test.ts
│       ├── errorParsing.ts
│       ├── errorReporting.test.ts
│       ├── errorReporting.ts
│       ├── errors.ts
│       ├── fetch.ts
│       ├── fileUtils.test.ts
│       ├── fileUtils.ts
│       ├── filesearch
│       │   ├── crawlCache.test.ts
│       │   ├── crawlCache.ts
│       │   ├── crawler.test.ts
│       │   ├── crawler.ts
│       │   ├── fileSearch.test.ts
│       │   ├── fileSearch.ts
│       │   ├── ignore.test.ts
│       │   ├── ignore.ts
│       │   ├── result-cache.test.ts
│       │   └── result-cache.ts
│       ├── flashFallback.test.ts
│       ├── formatters.test.ts
│       ├── formatters.ts
│       ├── geminiIgnoreParser.test.ts
│       ├── geminiIgnoreParser.ts
│       ├── generateContentResponseUtilities.test.ts
│       ├── generateContentResponseUtilities.ts
│       ├── getFolderStructure.test.ts
│       ├── getFolderStructure.ts
│       ├── getPty.ts
│       ├── gitIgnoreParser.test.ts
│       ├── gitIgnoreParser.ts
│       ├── gitUtils.ts
│       ├── googleErrors.test.ts
│       ├── googleErrors.ts
│       ├── googleQuotaErrors.test.ts
│       ├── googleQuotaErrors.ts
│       ├── ignorePatterns.test.ts
│       ├── ignorePatterns.ts
│       ├── installationManager.test.ts
│       ├── installationManager.ts
│       ├── language-detection.ts
│       ├── llm-edit-fixer.test.ts
│       ├── llm-edit-fixer.ts
│       ├── memoryDiscovery.test.ts
│       ├── memoryDiscovery.ts
│       ├── memoryImportProcessor.test.ts
│       ├── memoryImportProcessor.ts
│       ├── messageInspectors.ts
│       ├── nextSpeakerChecker.test.ts
│       ├── nextSpeakerChecker.ts
│       ├── partUtils.test.ts
│       ├── partUtils.ts
│       ├── pathCorrector.test.ts
│       ├── pathCorrector.ts
│       ├── pathReader.test.ts
│       ├── pathReader.ts
│       ├── paths.test.ts
│       ├── paths.ts
│       ├── promptIdContext.ts
│       ├── quotaErrorDetection.ts
│       ├── retry.test.ts
│       ├── retry.ts
│       ├── safeJsonStringify.test.ts
│       ├── safeJsonStringify.ts
│       ├── schemaValidator.test.ts
│       ├── schemaValidator.ts
│       ├── secure-browser-launcher.test.ts
│       ├── secure-browser-launcher.ts
│       ├── session.ts
│       ├── shell-utils.test.ts
│       ├── shell-utils.ts
│       ├── summarizer.test.ts
│       ├── summarizer.ts
│       ├── systemEncoding.test.ts
│       ├── systemEncoding.ts
│       ├── terminalSerializer.test.ts
│       ├── terminalSerializer.ts
│       ├── testUtils.ts
│       ├── textUtils.test.ts
│       ├── textUtils.ts
│       ├── thoughtUtils.test.ts
│       ├── thoughtUtils.ts
│       ├── tool-utils.test.ts
│       ├── tool-utils.ts
│       ├── userAccountManager.test.ts
│       ├── userAccountManager.ts
│       ├── workspaceContext.test.ts
│       └── workspaceContext.ts
├── test-setup.ts
├── tsconfig.json
└── vitest.config.ts


index.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export * from './src/index.js';
8 | export { Storage } from './src/config/storage.js';
9 | export {
10 |   DEFAULT_GEMINI_MODEL,
11 |   DEFAULT_GEMINI_MODEL_AUTO,
12 |   DEFAULT_GEMINI_FLASH_MODEL,
13 |   DEFAULT_GEMINI_FLASH_LITE_MODEL,
14 |   DEFAULT_GEMINI_EMBEDDING_MODEL,
15 | } from './src/config/models.js';
16 | export {
17 |   serializeTerminalToObject,
18 |   type AnsiOutput,
19 |   type AnsiLine,
20 |   type AnsiToken,
21 | } from './src/utils/terminalSerializer.js';
22 | export {
23 |   DEFAULT_TRUNCATE_TOOL_OUTPUT_LINES,
24 |   DEFAULT_TRUNCATE_TOOL_OUTPUT_THRESHOLD,
25 | } from './src/config/config.js';
26 | export { detectIdeFromEnv } from './src/ide/detect-ide.js';
27 | export {
28 |   logExtensionEnable,
29 |   logIdeConnection,
30 |   logExtensionDisable,
31 | } from './src/telemetry/loggers.js';
32 | 
33 | export {
34 |   IdeConnectionEvent,
35 |   IdeConnectionType,
36 |   ExtensionInstallEvent,
37 |   ExtensionDisableEvent,
38 |   ExtensionEnableEvent,
39 |   ExtensionUninstallEvent,
40 |   ExtensionUpdateEvent,
41 |   ModelSlashCommandEvent,
42 | } from './src/telemetry/types.js';
43 | export { makeFakeConfig } from './src/test-utils/config.js';
44 | export * from './src/utils/pathReader.js';
45 | export { ClearcutLogger } from './src/telemetry/clearcut-logger/clearcut-logger.js';
46 | export { logModelSlashCommand } from './src/telemetry/loggers.js';
47 | export * from './src/utils/googleQuotaErrors.js';
48 | export type { GoogleApiError } from './src/utils/googleErrors.js';
```

package.json
```
1 | {
2 |   "name": "@google/gemini-cli-core",
3 |   "version": "0.10.0-nightly.20251007.c195a9aa",
4 |   "description": "Gemini CLI Core",
5 |   "repository": {
6 |     "type": "git",
7 |     "url": "git+https://github.com/google-gemini/gemini-cli.git"
8 |   },
9 |   "type": "module",
10 |   "main": "dist/index.js",
11 |   "scripts": {
12 |     "build": "node ../../scripts/build_package.js",
13 |     "lint": "eslint . --ext .ts,.tsx",
14 |     "format": "prettier --write .",
15 |     "test": "vitest run",
16 |     "test:ci": "vitest run",
17 |     "typecheck": "tsc --noEmit"
18 |   },
19 |   "files": [
20 |     "dist"
21 |   ],
22 |   "dependencies": {
23 |     "@google/genai": "1.16.0",
24 |     "@google-cloud/opentelemetry-cloud-monitoring-exporter": "^0.21.0",
25 |     "@google-cloud/opentelemetry-cloud-trace-exporter": "^3.0.0",
26 |     "@google-cloud/logging": "^11.2.1",
27 |     "@joshua.litt/get-ripgrep": "^0.0.2",
28 |     "@modelcontextprotocol/sdk": "^1.11.0",
29 |     "@opentelemetry/api": "^1.9.0",
30 |     "@opentelemetry/exporter-logs-otlp-grpc": "^0.203.0",
31 |     "@opentelemetry/exporter-logs-otlp-http": "^0.203.0",
32 |     "@opentelemetry/exporter-metrics-otlp-grpc": "^0.203.0",
33 |     "@opentelemetry/exporter-metrics-otlp-http": "^0.203.0",
34 |     "@opentelemetry/exporter-trace-otlp-grpc": "^0.203.0",
35 |     "@opentelemetry/exporter-trace-otlp-http": "^0.203.0",
36 |     "@opentelemetry/instrumentation-http": "^0.203.0",
37 |     "@opentelemetry/resource-detector-gcp": "^0.40.0",
38 |     "@opentelemetry/sdk-node": "^0.203.0",
39 |     "@types/glob": "^8.1.0",
40 |     "@types/html-to-text": "^9.0.4",
41 |     "@xterm/headless": "5.5.0",
42 |     "ajv": "^8.17.1",
43 |     "ajv-formats": "^3.0.0",
44 |     "chardet": "^2.1.0",
45 |     "diff": "^7.0.0",
46 |     "dotenv": "^17.1.0",
47 |     "fast-levenshtein": "^2.0.6",
48 |     "fast-uri": "^3.0.6",
49 |     "fdir": "^6.4.6",
50 |     "fzf": "^0.5.2",
51 |     "glob": "^10.4.5",
52 |     "google-auth-library": "^9.11.0",
53 |     "html-to-text": "^9.0.5",
54 |     "https-proxy-agent": "^7.0.6",
55 |     "ignore": "^7.0.0",
56 |     "marked": "^15.0.12",
57 |     "mime": "4.0.7",
58 |     "mnemonist": "^0.40.3",
59 |     "open": "^10.1.2",
60 |     "picomatch": "^4.0.1",
61 |     "shell-quote": "^1.8.3",
62 |     "simple-git": "^3.28.0",
63 |     "strip-ansi": "^7.1.0",
64 |     "undici": "^7.10.0",
65 |     "ws": "^8.18.0"
66 |   },
67 |   "optionalDependencies": {
68 |     "@lydell/node-pty": "1.1.0",
69 |     "@lydell/node-pty-darwin-arm64": "1.1.0",
70 |     "@lydell/node-pty-darwin-x64": "1.1.0",
71 |     "@lydell/node-pty-linux-x64": "1.1.0",
72 |     "@lydell/node-pty-win32-arm64": "1.1.0",
73 |     "@lydell/node-pty-win32-x64": "1.1.0",
74 |     "node-pty": "^1.0.0"
75 |   },
76 |   "devDependencies": {
77 |     "@google/gemini-cli-test-utils": "file:../test-utils",
78 |     "@types/diff": "^7.0.2",
79 |     "@types/dotenv": "^6.1.1",
80 |     "@types/fast-levenshtein": "^0.0.4",
81 |     "@types/minimatch": "^5.1.2",
82 |     "@types/picomatch": "^4.0.1",
83 |     "@types/ws": "^8.5.10",
84 |     "msw": "^2.3.4",
85 |     "typescript": "^5.3.3",
86 |     "vitest": "^3.1.1"
87 |   },
88 |   "engines": {
89 |     "node": ">=20"
90 |   }
91 | }
```

test-setup.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | // Unset NO_COLOR environment variable to ensure consistent theme behavior between local and CI test runs
8 | if (process.env.NO_COLOR !== undefined) {
9 |   delete process.env.NO_COLOR;
10 | }
11 | 
12 | import { setSimulate429 } from './src/utils/testUtils.js';
13 | 
14 | // Disable 429 simulation globally for all tests
15 | setSimulate429(false);
```

tsconfig.json
```
1 | {
2 |   "extends": "../../tsconfig.json",
3 |   "compilerOptions": {
4 |     "outDir": "dist",
5 |     "lib": ["DOM", "DOM.Iterable", "ES2023"],
6 |     "composite": true,
7 |     "types": ["node", "vitest/globals"]
8 |   },
9 |   "include": ["index.ts", "src/**/*.ts", "src/**/*.json"],
10 |   "exclude": ["node_modules", "dist"]
11 | }
```

vitest.config.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { defineConfig } from 'vitest/config';
8 | 
9 | export default defineConfig({
10 |   test: {
11 |     reporters: ['default', 'junit'],
12 |     silent: true,
13 |     setupFiles: ['./test-setup.ts'],
14 |     outputFile: {
15 |       junit: 'junit.xml',
16 |     },
17 |     coverage: {
18 |       enabled: true,
19 |       provider: 'v8',
20 |       reportsDirectory: './coverage',
21 |       include: ['src/**/*'],
22 |       reporter: [
23 |         ['text', { file: 'full-text-summary.txt' }],
24 |         'html',
25 |         'json',
26 |         'lcov',
27 |         'cobertura',
28 |         ['json-summary', { outputFile: 'coverage-summary.json' }],
29 |       ],
30 |     },
31 |     poolOptions: {
32 |       threads: {
33 |         minThreads: 8,
34 |         maxThreads: 16,
35 |       },
36 |     },
37 |   },
38 | });
```

src/index.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | 
9 | describe('placeholder tests', () => {
10 |   it('should pass', () => {
11 |     expect(true).toBe(true);
12 |   });
13 | });
```

src/index.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | // Export config
8 | export * from './config/config.js';
9 | export * from './output/types.js';
10 | export * from './output/json-formatter.js';
11 | export * from './policy/types.js';
12 | export * from './policy/policy-engine.js';
13 | 
14 | // Export Core Logic
15 | export * from './core/client.js';
16 | export * from './core/contentGenerator.js';
17 | export * from './core/loggingContentGenerator.js';
18 | export * from './core/geminiChat.js';
19 | export * from './core/logger.js';
20 | export * from './core/prompts.js';
21 | export * from './core/tokenLimits.js';
22 | export * from './core/turn.js';
23 | export * from './core/geminiRequest.js';
24 | export * from './core/coreToolScheduler.js';
25 | export * from './core/nonInteractiveToolExecutor.js';
26 | 
27 | export * from './fallback/types.js';
28 | 
29 | export * from './code_assist/codeAssist.js';
30 | export * from './code_assist/oauth2.js';
31 | export * from './code_assist/server.js';
32 | export * from './code_assist/types.js';
33 | 
34 | // Export utilities
35 | export * from './utils/paths.js';
36 | export * from './utils/schemaValidator.js';
37 | export * from './utils/errors.js';
38 | export * from './utils/getFolderStructure.js';
39 | export * from './utils/memoryDiscovery.js';
40 | export * from './utils/gitIgnoreParser.js';
41 | export * from './utils/gitUtils.js';
42 | export * from './utils/editor.js';
43 | export * from './utils/quotaErrorDetection.js';
44 | export * from './utils/fileUtils.js';
45 | export * from './utils/retry.js';
46 | export * from './utils/shell-utils.js';
47 | export * from './utils/terminalSerializer.js';
48 | export * from './utils/systemEncoding.js';
49 | export * from './utils/textUtils.js';
50 | export * from './utils/formatters.js';
51 | export * from './utils/generateContentResponseUtilities.js';
52 | export * from './utils/filesearch/fileSearch.js';
53 | export * from './utils/errorParsing.js';
54 | export * from './utils/workspaceContext.js';
55 | export * from './utils/ignorePatterns.js';
56 | export * from './utils/partUtils.js';
57 | export * from './utils/promptIdContext.js';
58 | export * from './utils/thoughtUtils.js';
59 | 
60 | // Export services
61 | export * from './services/fileDiscoveryService.js';
62 | export * from './services/gitService.js';
63 | export * from './services/chatRecordingService.js';
64 | export * from './services/fileSystemService.js';
65 | 
66 | // Export IDE specific logic
67 | export * from './ide/ide-client.js';
68 | export * from './ide/ideContext.js';
69 | export * from './ide/ide-installer.js';
70 | export { IDE_DEFINITIONS, type IdeInfo } from './ide/detect-ide.js';
71 | export * from './ide/constants.js';
72 | export * from './ide/types.js';
73 | 
74 | // Export Shell Execution Service
75 | export * from './services/shellExecutionService.js';
76 | 
77 | // Export base tool definitions
78 | export * from './tools/tools.js';
79 | export * from './tools/tool-error.js';
80 | export * from './tools/tool-registry.js';
81 | export * from './tools/tool-names.js';
82 | 
83 | // Export prompt logic
84 | export * from './prompts/mcp-prompts.js';
85 | 
86 | // Export specific tool logic
87 | export * from './tools/read-file.js';
88 | export * from './tools/ls.js';
89 | export * from './tools/grep.js';
90 | export * from './tools/ripGrep.js';
91 | export * from './tools/glob.js';
92 | export * from './tools/edit.js';
93 | export * from './tools/write-file.js';
94 | export * from './tools/web-fetch.js';
95 | export * from './tools/memoryTool.js';
96 | export * from './tools/shell.js';
97 | export * from './tools/web-search.js';
98 | export * from './tools/read-many-files.js';
99 | export * from './tools/mcp-client.js';
100 | export * from './tools/mcp-tool.js';
101 | export * from './tools/write-todos.js';
102 | 
103 | // MCP OAuth
104 | export { MCPOAuthProvider } from './mcp/oauth-provider.js';
105 | export type {
106 |   OAuthToken,
107 |   OAuthCredentials,
108 | } from './mcp/token-storage/types.js';
109 | export { MCPOAuthTokenStorage } from './mcp/oauth-token-storage.js';
110 | export type { MCPOAuthConfig } from './mcp/oauth-provider.js';
111 | export type {
112 |   OAuthAuthorizationServerMetadata,
113 |   OAuthProtectedResourceMetadata,
114 | } from './mcp/oauth-utils.js';
115 | export { OAuthUtils } from './mcp/oauth-utils.js';
116 | 
117 | // Export telemetry functions
118 | export * from './telemetry/index.js';
119 | export { sessionId } from './utils/session.js';
120 | export * from './utils/browser.js';
121 | export { Storage } from './config/storage.js';
122 | 
123 | // Export test utils
124 | export * from './test-utils/index.js';
```

src/config/config.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import type { Mock } from 'vitest';
9 | import type { ConfigParameters, SandboxConfig } from './config.js';
10 | import {
11 |   Config,
12 |   ApprovalMode,
13 |   DEFAULT_FILE_FILTERING_OPTIONS,
14 | } from './config.js';
15 | import * as path from 'node:path';
16 | import { setGeminiMdFilename as mockSetGeminiMdFilename } from '../tools/memoryTool.js';
17 | import {
18 |   DEFAULT_TELEMETRY_TARGET,
19 |   DEFAULT_OTLP_ENDPOINT,
20 | } from '../telemetry/index.js';
21 | import type { ContentGeneratorConfig } from '../core/contentGenerator.js';
22 | import {
23 |   AuthType,
24 |   createContentGeneratorConfig,
25 | } from '../core/contentGenerator.js';
26 | import { GeminiClient } from '../core/client.js';
27 | import { GitService } from '../services/gitService.js';
28 | import { ClearcutLogger } from '../telemetry/clearcut-logger/clearcut-logger.js';
29 | 
30 | import { ShellTool } from '../tools/shell.js';
31 | import { ReadFileTool } from '../tools/read-file.js';
32 | import { GrepTool } from '../tools/grep.js';
33 | import { RipGrepTool, canUseRipgrep } from '../tools/ripGrep.js';
34 | import { logRipgrepFallback } from '../telemetry/loggers.js';
35 | import { RipgrepFallbackEvent } from '../telemetry/types.js';
36 | import { ToolRegistry } from '../tools/tool-registry.js';
37 | 
38 | vi.mock('fs', async (importOriginal) => {
39 |   const actual = await importOriginal<typeof import('fs')>();
40 |   return {
41 |     ...actual,
42 |     existsSync: vi.fn().mockReturnValue(true),
43 |     statSync: vi.fn().mockReturnValue({
44 |       isDirectory: vi.fn().mockReturnValue(true),
45 |     }),
46 |     realpathSync: vi.fn((path) => path),
47 |   };
48 | });
49 | 
50 | // Mock dependencies that might be called during Config construction or createServerConfig
51 | vi.mock('../tools/tool-registry', () => {
52 |   const ToolRegistryMock = vi.fn();
53 |   ToolRegistryMock.prototype.registerTool = vi.fn();
54 |   ToolRegistryMock.prototype.discoverAllTools = vi.fn();
55 |   ToolRegistryMock.prototype.getAllTools = vi.fn(() => []); // Mock methods if needed
56 |   ToolRegistryMock.prototype.getTool = vi.fn();
57 |   ToolRegistryMock.prototype.getFunctionDeclarations = vi.fn(() => []);
58 |   return { ToolRegistry: ToolRegistryMock };
59 | });
60 | 
61 | vi.mock('../utils/memoryDiscovery.js', () => ({
62 |   loadServerHierarchicalMemory: vi.fn(),
63 | }));
64 | 
65 | // Mock individual tools if their constructors are complex or have side effects
66 | vi.mock('../tools/ls');
67 | vi.mock('../tools/read-file');
68 | vi.mock('../tools/grep.js');
69 | vi.mock('../tools/ripGrep.js', () => ({
70 |   canUseRipgrep: vi.fn(),
71 |   RipGrepTool: class MockRipGrepTool {},
72 | }));
73 | vi.mock('../tools/glob');
74 | vi.mock('../tools/edit');
75 | vi.mock('../tools/shell');
76 | vi.mock('../tools/write-file');
77 | vi.mock('../tools/web-fetch');
78 | vi.mock('../tools/read-many-files');
79 | vi.mock('../tools/memoryTool', () => ({
80 |   MemoryTool: vi.fn(),
81 |   setGeminiMdFilename: vi.fn(),
82 |   getCurrentGeminiMdFilename: vi.fn(() => 'GEMINI.md'), // Mock the original filename
83 |   DEFAULT_CONTEXT_FILENAME: 'GEMINI.md',
84 |   GEMINI_CONFIG_DIR: '.gemini',
85 | }));
86 | 
87 | vi.mock('../core/contentGenerator.js');
88 | 
89 | vi.mock('../core/client.js', () => ({
90 |   GeminiClient: vi.fn().mockImplementation(() => ({
91 |     initialize: vi.fn().mockResolvedValue(undefined),
92 |     stripThoughtsFromHistory: vi.fn(),
93 |   })),
94 | }));
95 | 
96 | vi.mock('../telemetry/index.js', async (importOriginal) => {
97 |   const actual = await importOriginal<typeof import('../telemetry/index.js')>();
98 |   return {
99 |     ...actual,
100 |     initializeTelemetry: vi.fn(),
101 |     uiTelemetryService: {
102 |       getLastPromptTokenCount: vi.fn(),
103 |     },
104 |   };
105 | });
106 | 
107 | vi.mock('../telemetry/loggers.js', async (importOriginal) => {
108 |   const actual =
109 |     await importOriginal<typeof import('../telemetry/loggers.js')>();
110 |   return {
111 |     ...actual,
112 |     logRipgrepFallback: vi.fn(),
113 |   };
114 | });
115 | 
116 | vi.mock('../services/gitService.js', () => {
117 |   const GitServiceMock = vi.fn();
118 |   GitServiceMock.prototype.initialize = vi.fn();
119 |   return { GitService: GitServiceMock };
120 | });
121 | 
122 | vi.mock('../ide/ide-client.js', () => ({
123 |   IdeClient: {
124 |     getInstance: vi.fn().mockResolvedValue({
125 |       getConnectionStatus: vi.fn(),
126 |       initialize: vi.fn(),
127 |       shutdown: vi.fn(),
128 |     }),
129 |   },
130 | }));
131 | 
132 | vi.mock('../agents/registry.js', () => {
133 |   const AgentRegistryMock = vi.fn();
134 |   AgentRegistryMock.prototype.initialize = vi.fn();
135 |   AgentRegistryMock.prototype.getAllDefinitions = vi.fn(() => []);
136 |   return { AgentRegistry: AgentRegistryMock };
137 | });
138 | 
139 | vi.mock('../agents/subagent-tool-wrapper.js', () => ({
140 |   SubagentToolWrapper: vi.fn(),
141 | }));
142 | 
143 | import { BaseLlmClient } from '../core/baseLlmClient.js';
144 | import { tokenLimit } from '../core/tokenLimits.js';
145 | import { uiTelemetryService } from '../telemetry/index.js';
146 | 
147 | vi.mock('../core/baseLlmClient.js');
148 | vi.mock('../core/tokenLimits.js', () => ({
149 |   tokenLimit: vi.fn(),
150 | }));
151 | 
152 | describe('Server Config (config.ts)', () => {
153 |   const MODEL = 'gemini-pro';
154 |   const SANDBOX: SandboxConfig = {
155 |     command: 'docker',
156 |     image: 'gemini-cli-sandbox',
157 |   };
158 |   const TARGET_DIR = '/path/to/target';
159 |   const DEBUG_MODE = false;
160 |   const QUESTION = 'test question';
161 |   const FULL_CONTEXT = false;
162 |   const USER_MEMORY = 'Test User Memory';
163 |   const TELEMETRY_SETTINGS = { enabled: false };
164 |   const EMBEDDING_MODEL = 'gemini-embedding';
165 |   const SESSION_ID = 'test-session-id';
166 |   const baseParams: ConfigParameters = {
167 |     cwd: '/tmp',
168 |     embeddingModel: EMBEDDING_MODEL,
169 |     sandbox: SANDBOX,
170 |     targetDir: TARGET_DIR,
171 |     debugMode: DEBUG_MODE,
172 |     question: QUESTION,
173 |     fullContext: FULL_CONTEXT,
174 |     userMemory: USER_MEMORY,
175 |     telemetry: TELEMETRY_SETTINGS,
176 |     sessionId: SESSION_ID,
177 |     model: MODEL,
178 |     usageStatisticsEnabled: false,
179 |   };
180 | 
181 |   beforeEach(() => {
182 |     // Reset mocks if necessary
183 |     vi.clearAllMocks();
184 |     vi.spyOn(
185 |       ClearcutLogger.prototype,
186 |       'logStartSessionEvent',
187 |     ).mockImplementation(() => undefined);
188 |   });
189 | 
190 |   describe('initialize', () => {
191 |     it('should throw an error if checkpointing is enabled and GitService fails', async () => {
192 |       const gitError = new Error('Git is not installed');
193 |       (GitService.prototype.initialize as Mock).mockRejectedValue(gitError);
194 | 
195 |       const config = new Config({
196 |         ...baseParams,
197 |         checkpointing: true,
198 |       });
199 | 
200 |       await expect(config.initialize()).rejects.toThrow(gitError);
201 |     });
202 | 
203 |     it('should not throw an error if checkpointing is disabled and GitService fails', async () => {
204 |       const gitError = new Error('Git is not installed');
205 |       (GitService.prototype.initialize as Mock).mockRejectedValue(gitError);
206 | 
207 |       const config = new Config({
208 |         ...baseParams,
209 |         checkpointing: false,
210 |       });
211 | 
212 |       await expect(config.initialize()).resolves.toBeUndefined();
213 |     });
214 | 
215 |     it('should throw an error if initialized more than once', async () => {
216 |       const config = new Config({
217 |         ...baseParams,
218 |         checkpointing: false,
219 |       });
220 | 
221 |       await expect(config.initialize()).resolves.toBeUndefined();
222 |       await expect(config.initialize()).rejects.toThrow(
223 |         'Config was already initialized',
224 |       );
225 |     });
226 |   });
227 | 
228 |   describe('refreshAuth', () => {
229 |     it('should refresh auth and update config', async () => {
230 |       const config = new Config(baseParams);
231 |       const authType = AuthType.USE_GEMINI;
232 |       const mockContentConfig = {
233 |         apiKey: 'test-key',
234 |       };
235 | 
236 |       vi.mocked(createContentGeneratorConfig).mockReturnValue(
237 |         mockContentConfig,
238 |       );
239 | 
240 |       // Set fallback mode to true to ensure it gets reset
241 |       config.setFallbackMode(true);
242 |       expect(config.isInFallbackMode()).toBe(true);
243 | 
244 |       await config.refreshAuth(authType);
245 | 
246 |       expect(createContentGeneratorConfig).toHaveBeenCalledWith(
247 |         config,
248 |         authType,
249 |       );
250 |       // Verify that contentGeneratorConfig is updated
251 |       expect(config.getContentGeneratorConfig()).toEqual(mockContentConfig);
252 |       expect(GeminiClient).toHaveBeenCalledWith(config);
253 |       // Verify that fallback mode is reset
254 |       expect(config.isInFallbackMode()).toBe(false);
255 |     });
256 | 
257 |     it('should strip thoughts when switching from GenAI to Vertex', async () => {
258 |       const config = new Config(baseParams);
259 | 
260 |       vi.mocked(createContentGeneratorConfig).mockImplementation(
261 |         (_: Config, authType: AuthType | undefined) =>
262 |           ({ authType }) as unknown as ContentGeneratorConfig,
263 |       );
264 | 
265 |       await config.refreshAuth(AuthType.USE_GEMINI);
266 | 
267 |       await config.refreshAuth(AuthType.LOGIN_WITH_GOOGLE);
268 | 
269 |       expect(
270 |         config.getGeminiClient().stripThoughtsFromHistory,
271 |       ).toHaveBeenCalledWith();
272 |     });
273 | 
274 |     it('should not strip thoughts when switching from Vertex to GenAI', async () => {
275 |       const config = new Config(baseParams);
276 | 
277 |       vi.mocked(createContentGeneratorConfig).mockImplementation(
278 |         (_: Config, authType: AuthType | undefined) =>
279 |           ({ authType }) as unknown as ContentGeneratorConfig,
280 |       );
281 | 
282 |       await config.refreshAuth(AuthType.USE_VERTEX_AI);
283 | 
284 |       await config.refreshAuth(AuthType.USE_GEMINI);
285 | 
286 |       expect(
287 |         config.getGeminiClient().stripThoughtsFromHistory,
288 |       ).not.toHaveBeenCalledWith();
289 |     });
290 |   });
291 | 
292 |   it('Config constructor should store userMemory correctly', () => {
293 |     const config = new Config(baseParams);
294 | 
295 |     expect(config.getUserMemory()).toBe(USER_MEMORY);
296 |     // Verify other getters if needed
297 |     expect(config.getTargetDir()).toBe(path.resolve(TARGET_DIR)); // Check resolved path
298 |   });
299 | 
300 |   it('Config constructor should default userMemory to empty string if not provided', () => {
301 |     const paramsWithoutMemory: ConfigParameters = { ...baseParams };
302 |     delete paramsWithoutMemory.userMemory;
303 |     const config = new Config(paramsWithoutMemory);
304 | 
305 |     expect(config.getUserMemory()).toBe('');
306 |   });
307 | 
308 |   it('Config constructor should call setGeminiMdFilename with contextFileName if provided', () => {
309 |     const contextFileName = 'CUSTOM_AGENTS.md';
310 |     const paramsWithContextFile: ConfigParameters = {
311 |       ...baseParams,
312 |       contextFileName,
313 |     };
314 |     new Config(paramsWithContextFile);
315 |     expect(mockSetGeminiMdFilename).toHaveBeenCalledWith(contextFileName);
316 |   });
317 | 
318 |   it('Config constructor should not call setGeminiMdFilename if contextFileName is not provided', () => {
319 |     new Config(baseParams); // baseParams does not have contextFileName
320 |     expect(mockSetGeminiMdFilename).not.toHaveBeenCalled();
321 |   });
322 | 
323 |   it('should set default file filtering settings when not provided', () => {
324 |     const config = new Config(baseParams);
325 |     expect(config.getFileFilteringRespectGitIgnore()).toBe(
326 |       DEFAULT_FILE_FILTERING_OPTIONS.respectGitIgnore,
327 |     );
328 |   });
329 | 
330 |   it('should set custom file filtering settings when provided', () => {
331 |     const paramsWithFileFiltering: ConfigParameters = {
332 |       ...baseParams,
333 |       fileFiltering: {
334 |         respectGitIgnore: false,
335 |       },
336 |     };
337 |     const config = new Config(paramsWithFileFiltering);
338 |     expect(config.getFileFilteringRespectGitIgnore()).toBe(false);
339 |   });
340 | 
341 |   it('should initialize WorkspaceContext with includeDirectories', () => {
342 |     const includeDirectories = ['/path/to/dir1', '/path/to/dir2'];
343 |     const paramsWithIncludeDirs: ConfigParameters = {
344 |       ...baseParams,
345 |       includeDirectories,
346 |     };
347 |     const config = new Config(paramsWithIncludeDirs);
348 |     const workspaceContext = config.getWorkspaceContext();
349 |     const directories = workspaceContext.getDirectories();
350 | 
351 |     // Should include the target directory plus the included directories
352 |     expect(directories).toHaveLength(3);
353 |     expect(directories).toContain(path.resolve(baseParams.targetDir));
354 |     expect(directories).toContain('/path/to/dir1');
355 |     expect(directories).toContain('/path/to/dir2');
356 |   });
357 | 
358 |   it('Config constructor should set telemetry to true when provided as true', () => {
359 |     const paramsWithTelemetry: ConfigParameters = {
360 |       ...baseParams,
361 |       telemetry: { enabled: true },
362 |     };
363 |     const config = new Config(paramsWithTelemetry);
364 |     expect(config.getTelemetryEnabled()).toBe(true);
365 |   });
366 | 
367 |   it('Config constructor should set telemetry to false when provided as false', () => {
368 |     const paramsWithTelemetry: ConfigParameters = {
369 |       ...baseParams,
370 |       telemetry: { enabled: false },
371 |     };
372 |     const config = new Config(paramsWithTelemetry);
373 |     expect(config.getTelemetryEnabled()).toBe(false);
374 |   });
375 | 
376 |   it('Config constructor should default telemetry to default value if not provided', () => {
377 |     const paramsWithoutTelemetry: ConfigParameters = { ...baseParams };
378 |     delete paramsWithoutTelemetry.telemetry;
379 |     const config = new Config(paramsWithoutTelemetry);
380 |     expect(config.getTelemetryEnabled()).toBe(TELEMETRY_SETTINGS.enabled);
381 |   });
382 | 
383 |   it('Config constructor should set telemetry useCollector to true when provided', () => {
384 |     const paramsWithTelemetry: ConfigParameters = {
385 |       ...baseParams,
386 |       telemetry: { enabled: true, useCollector: true },
387 |     };
388 |     const config = new Config(paramsWithTelemetry);
389 |     expect(config.getTelemetryUseCollector()).toBe(true);
390 |   });
391 | 
392 |   it('Config constructor should set telemetry useCollector to false when provided', () => {
393 |     const paramsWithTelemetry: ConfigParameters = {
394 |       ...baseParams,
395 |       telemetry: { enabled: true, useCollector: false },
396 |     };
397 |     const config = new Config(paramsWithTelemetry);
398 |     expect(config.getTelemetryUseCollector()).toBe(false);
399 |   });
400 | 
401 |   it('Config constructor should default telemetry useCollector to false if not provided', () => {
402 |     const paramsWithTelemetry: ConfigParameters = {
403 |       ...baseParams,
404 |       telemetry: { enabled: true },
405 |     };
406 |     const config = new Config(paramsWithTelemetry);
407 |     expect(config.getTelemetryUseCollector()).toBe(false);
408 |   });
409 | 
410 |   it('should have a getFileService method that returns FileDiscoveryService', () => {
411 |     const config = new Config(baseParams);
412 |     const fileService = config.getFileService();
413 |     expect(fileService).toBeDefined();
414 |   });
415 | 
416 |   describe('Usage Statistics', () => {
417 |     it('defaults usage statistics to enabled if not specified', () => {
418 |       const config = new Config({
419 |         ...baseParams,
420 |         usageStatisticsEnabled: undefined,
421 |       });
422 | 
423 |       expect(config.getUsageStatisticsEnabled()).toBe(true);
424 |     });
425 | 
426 |     it.each([{ enabled: true }, { enabled: false }])(
427 |       'sets usage statistics based on the provided value (enabled: $enabled)',
428 |       ({ enabled }) => {
429 |         const config = new Config({
430 |           ...baseParams,
431 |           usageStatisticsEnabled: enabled,
432 |         });
433 |         expect(config.getUsageStatisticsEnabled()).toBe(enabled);
434 |       },
435 |     );
436 | 
437 |     it('logs the session start event', async () => {
438 |       const config = new Config({
439 |         ...baseParams,
440 |         usageStatisticsEnabled: true,
441 |       });
442 |       await config.refreshAuth(AuthType.USE_GEMINI);
443 | 
444 |       expect(
445 |         ClearcutLogger.prototype.logStartSessionEvent,
446 |       ).toHaveBeenCalledOnce();
447 |     });
448 |   });
449 | 
450 |   describe('Telemetry Settings', () => {
451 |     it('should return default telemetry target if not provided', () => {
452 |       const params: ConfigParameters = {
453 |         ...baseParams,
454 |         telemetry: { enabled: true },
455 |       };
456 |       const config = new Config(params);
457 |       expect(config.getTelemetryTarget()).toBe(DEFAULT_TELEMETRY_TARGET);
458 |     });
459 | 
460 |     it('should return provided OTLP endpoint', () => {
461 |       const endpoint = 'http://custom.otel.collector:4317';
462 |       const params: ConfigParameters = {
463 |         ...baseParams,
464 |         telemetry: { enabled: true, otlpEndpoint: endpoint },
465 |       };
466 |       const config = new Config(params);
467 |       expect(config.getTelemetryOtlpEndpoint()).toBe(endpoint);
468 |     });
469 | 
470 |     it('should return default OTLP endpoint if not provided', () => {
471 |       const params: ConfigParameters = {
472 |         ...baseParams,
473 |         telemetry: { enabled: true },
474 |       };
475 |       const config = new Config(params);
476 |       expect(config.getTelemetryOtlpEndpoint()).toBe(DEFAULT_OTLP_ENDPOINT);
477 |     });
478 | 
479 |     it('should return provided logPrompts setting', () => {
480 |       const params: ConfigParameters = {
481 |         ...baseParams,
482 |         telemetry: { enabled: true, logPrompts: false },
483 |       };
484 |       const config = new Config(params);
485 |       expect(config.getTelemetryLogPromptsEnabled()).toBe(false);
486 |     });
487 | 
488 |     it('should return default logPrompts setting (true) if not provided', () => {
489 |       const params: ConfigParameters = {
490 |         ...baseParams,
491 |         telemetry: { enabled: true },
492 |       };
493 |       const config = new Config(params);
494 |       expect(config.getTelemetryLogPromptsEnabled()).toBe(true);
495 |     });
496 | 
497 |     it('should return default logPrompts setting (true) if telemetry object is not provided', () => {
498 |       const paramsWithoutTelemetry: ConfigParameters = { ...baseParams };
499 |       delete paramsWithoutTelemetry.telemetry;
500 |       const config = new Config(paramsWithoutTelemetry);
501 |       expect(config.getTelemetryLogPromptsEnabled()).toBe(true);
502 |     });
503 | 
504 |     it('should return default telemetry target if telemetry object is not provided', () => {
505 |       const paramsWithoutTelemetry: ConfigParameters = { ...baseParams };
506 |       delete paramsWithoutTelemetry.telemetry;
507 |       const config = new Config(paramsWithoutTelemetry);
508 |       expect(config.getTelemetryTarget()).toBe(DEFAULT_TELEMETRY_TARGET);
509 |     });
510 | 
511 |     it('should return default OTLP endpoint if telemetry object is not provided', () => {
512 |       const paramsWithoutTelemetry: ConfigParameters = { ...baseParams };
513 |       delete paramsWithoutTelemetry.telemetry;
514 |       const config = new Config(paramsWithoutTelemetry);
515 |       expect(config.getTelemetryOtlpEndpoint()).toBe(DEFAULT_OTLP_ENDPOINT);
516 |     });
517 | 
518 |     it('should return provided OTLP protocol', () => {
519 |       const params: ConfigParameters = {
520 |         ...baseParams,
521 |         telemetry: { enabled: true, otlpProtocol: 'http' },
522 |       };
523 |       const config = new Config(params);
524 |       expect(config.getTelemetryOtlpProtocol()).toBe('http');
525 |     });
526 | 
527 |     it('should return default OTLP protocol if not provided', () => {
528 |       const params: ConfigParameters = {
529 |         ...baseParams,
530 |         telemetry: { enabled: true },
531 |       };
532 |       const config = new Config(params);
533 |       expect(config.getTelemetryOtlpProtocol()).toBe('grpc');
534 |     });
535 | 
536 |     it('should return default OTLP protocol if telemetry object is not provided', () => {
537 |       const paramsWithoutTelemetry: ConfigParameters = { ...baseParams };
538 |       delete paramsWithoutTelemetry.telemetry;
539 |       const config = new Config(paramsWithoutTelemetry);
540 |       expect(config.getTelemetryOtlpProtocol()).toBe('grpc');
541 |     });
542 |   });
543 | 
544 |   describe('UseRipgrep Configuration', () => {
545 |     it('should default useRipgrep to true when not provided', () => {
546 |       const config = new Config(baseParams);
547 |       expect(config.getUseRipgrep()).toBe(true);
548 |     });
549 | 
550 |     it('should set useRipgrep to false when provided as false', () => {
551 |       const paramsWithRipgrep: ConfigParameters = {
552 |         ...baseParams,
553 |         useRipgrep: false,
554 |       };
555 |       const config = new Config(paramsWithRipgrep);
556 |       expect(config.getUseRipgrep()).toBe(false);
557 |     });
558 | 
559 |     it('should set useRipgrep to true when explicitly provided as true', () => {
560 |       const paramsWithRipgrep: ConfigParameters = {
561 |         ...baseParams,
562 |         useRipgrep: true,
563 |       };
564 |       const config = new Config(paramsWithRipgrep);
565 |       expect(config.getUseRipgrep()).toBe(true);
566 |     });
567 | 
568 |     it('should default useRipgrep to true when undefined', () => {
569 |       const paramsWithUndefinedRipgrep: ConfigParameters = {
570 |         ...baseParams,
571 |         useRipgrep: undefined,
572 |       };
573 |       const config = new Config(paramsWithUndefinedRipgrep);
574 |       expect(config.getUseRipgrep()).toBe(true);
575 |     });
576 |   });
577 | 
578 |   describe('UseModelRouter Configuration', () => {
579 |     it('should default useModelRouter to false when not provided', () => {
580 |       const config = new Config(baseParams);
581 |       expect(config.getUseModelRouter()).toBe(false);
582 |     });
583 | 
584 |     it('should set useModelRouter to true when provided as true', () => {
585 |       const paramsWithModelRouter: ConfigParameters = {
586 |         ...baseParams,
587 |         useModelRouter: true,
588 |       };
589 |       const config = new Config(paramsWithModelRouter);
590 |       expect(config.getUseModelRouter()).toBe(true);
591 |     });
592 | 
[TRUNCATED]
```

src/config/config.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as path from 'node:path';
8 | import process from 'node:process';
9 | import type {
10 |   ContentGenerator,
11 |   ContentGeneratorConfig,
12 | } from '../core/contentGenerator.js';
13 | import {
14 |   AuthType,
15 |   createContentGenerator,
16 |   createContentGeneratorConfig,
17 | } from '../core/contentGenerator.js';
18 | import { PromptRegistry } from '../prompts/prompt-registry.js';
19 | import { ToolRegistry } from '../tools/tool-registry.js';
20 | import { LSTool } from '../tools/ls.js';
21 | import { ReadFileTool } from '../tools/read-file.js';
22 | import { GrepTool } from '../tools/grep.js';
23 | import { canUseRipgrep, RipGrepTool } from '../tools/ripGrep.js';
24 | import { GlobTool } from '../tools/glob.js';
25 | import { EditTool } from '../tools/edit.js';
26 | import { SmartEditTool } from '../tools/smart-edit.js';
27 | import { ShellTool } from '../tools/shell.js';
28 | import { WriteFileTool } from '../tools/write-file.js';
29 | import { WebFetchTool } from '../tools/web-fetch.js';
30 | import { ReadManyFilesTool } from '../tools/read-many-files.js';
31 | import { MemoryTool, setGeminiMdFilename } from '../tools/memoryTool.js';
32 | import { WebSearchTool } from '../tools/web-search.js';
33 | import { GeminiClient } from '../core/client.js';
34 | import { BaseLlmClient } from '../core/baseLlmClient.js';
35 | import { FileDiscoveryService } from '../services/fileDiscoveryService.js';
36 | import { GitService } from '../services/gitService.js';
37 | import type { TelemetryTarget } from '../telemetry/index.js';
38 | import {
39 |   initializeTelemetry,
40 |   DEFAULT_TELEMETRY_TARGET,
41 |   DEFAULT_OTLP_ENDPOINT,
42 |   uiTelemetryService,
43 | } from '../telemetry/index.js';
44 | import { tokenLimit } from '../core/tokenLimits.js';
45 | import { StartSessionEvent } from '../telemetry/index.js';
46 | import {
47 |   DEFAULT_GEMINI_EMBEDDING_MODEL,
48 |   DEFAULT_GEMINI_FLASH_MODEL,
49 | } from './models.js';
50 | import { shouldAttemptBrowserLaunch } from '../utils/browser.js';
51 | import type { MCPOAuthConfig } from '../mcp/oauth-provider.js';
52 | import { ideContextStore } from '../ide/ideContext.js';
53 | import { WriteTodosTool } from '../tools/write-todos.js';
54 | import type { FileSystemService } from '../services/fileSystemService.js';
55 | import { StandardFileSystemService } from '../services/fileSystemService.js';
56 | import {
57 |   logCliConfiguration,
58 |   logRipgrepFallback,
59 | } from '../telemetry/loggers.js';
60 | import { RipgrepFallbackEvent } from '../telemetry/types.js';
61 | import type { FallbackModelHandler } from '../fallback/types.js';
62 | import { ModelRouterService } from '../routing/modelRouterService.js';
63 | import { OutputFormat } from '../output/types.js';
64 | 
65 | // Re-export OAuth config type
66 | export type { MCPOAuthConfig, AnyToolInvocation };
67 | import type { AnyToolInvocation } from '../tools/tools.js';
68 | import { WorkspaceContext } from '../utils/workspaceContext.js';
69 | import { Storage } from './storage.js';
70 | import type { ShellExecutionConfig } from '../services/shellExecutionService.js';
71 | import { FileExclusions } from '../utils/ignorePatterns.js';
72 | import type { EventEmitter } from 'node:events';
73 | import { MessageBus } from '../confirmation-bus/message-bus.js';
74 | import { PolicyEngine } from '../policy/policy-engine.js';
75 | import type { PolicyEngineConfig } from '../policy/types.js';
76 | import type { UserTierId } from '../code_assist/types.js';
77 | import { ProxyAgent, setGlobalDispatcher } from 'undici';
78 | 
79 | import { AgentRegistry } from '../agents/registry.js';
80 | import { SubagentToolWrapper } from '../agents/subagent-tool-wrapper.js';
81 | 
82 | export enum ApprovalMode {
83 |   DEFAULT = 'default',
84 |   AUTO_EDIT = 'autoEdit',
85 |   YOLO = 'yolo',
86 | }
87 | 
88 | export interface AccessibilitySettings {
89 |   disableLoadingPhrases?: boolean;
90 |   screenReader?: boolean;
91 | }
92 | 
93 | export interface BugCommandSettings {
94 |   urlTemplate: string;
95 | }
96 | 
97 | export interface ChatCompressionSettings {
98 |   contextPercentageThreshold?: number;
99 | }
100 | 
101 | export interface SummarizeToolOutputSettings {
102 |   tokenBudget?: number;
103 | }
104 | 
105 | export interface TelemetrySettings {
106 |   enabled?: boolean;
107 |   target?: TelemetryTarget;
108 |   otlpEndpoint?: string;
109 |   otlpProtocol?: 'grpc' | 'http';
110 |   logPrompts?: boolean;
111 |   outfile?: string;
112 |   useCollector?: boolean;
113 | }
114 | 
115 | export interface OutputSettings {
116 |   format?: OutputFormat;
117 | }
118 | 
119 | /**
120 |  * All information required in CLI to handle an extension. Defined in Core so
121 |  * that the collection of loaded, active, and inactive extensions can be passed
122 |  * around on the config object though Core does not use this information
123 |  * directly.
124 |  */
125 | export interface GeminiCLIExtension {
126 |   name: string;
127 |   version: string;
128 |   isActive: boolean;
129 |   path: string;
130 |   installMetadata?: ExtensionInstallMetadata;
131 |   mcpServers?: Record<string, MCPServerConfig>;
132 |   contextFiles: string[];
133 |   excludeTools?: string[];
134 | }
135 | 
136 | export interface ExtensionInstallMetadata {
137 |   source: string;
138 |   type: 'git' | 'local' | 'link' | 'github-release';
139 |   releaseTag?: string; // Only present for github-release installs.
140 |   ref?: string;
141 |   autoUpdate?: boolean;
142 |   allowPreRelease?: boolean;
143 | }
144 | 
145 | import type { FileFilteringOptions } from './constants.js';
146 | import {
147 |   DEFAULT_FILE_FILTERING_OPTIONS,
148 |   DEFAULT_MEMORY_FILE_FILTERING_OPTIONS,
149 | } from './constants.js';
150 | 
151 | export type { FileFilteringOptions };
152 | export {
153 |   DEFAULT_FILE_FILTERING_OPTIONS,
154 |   DEFAULT_MEMORY_FILE_FILTERING_OPTIONS,
155 | };
156 | 
157 | export const DEFAULT_TRUNCATE_TOOL_OUTPUT_THRESHOLD = 4_000_000;
158 | export const DEFAULT_TRUNCATE_TOOL_OUTPUT_LINES = 1000;
159 | 
160 | export class MCPServerConfig {
161 |   constructor(
162 |     // For stdio transport
163 |     readonly command?: string,
164 |     readonly args?: string[],
165 |     readonly env?: Record<string, string>,
166 |     readonly cwd?: string,
167 |     // For sse transport
168 |     readonly url?: string,
169 |     // For streamable http transport
170 |     readonly httpUrl?: string,
171 |     readonly headers?: Record<string, string>,
172 |     // For websocket transport
173 |     readonly tcp?: string,
174 |     // Common
175 |     readonly timeout?: number,
176 |     readonly trust?: boolean,
177 |     // Metadata
178 |     readonly description?: string,
179 |     readonly includeTools?: string[],
180 |     readonly excludeTools?: string[],
181 |     readonly extensionName?: string,
182 |     // OAuth configuration
183 |     readonly oauth?: MCPOAuthConfig,
184 |     readonly authProviderType?: AuthProviderType,
185 |     // Service Account Configuration
186 |     /* targetAudience format: CLIENT_ID.apps.googleusercontent.com */
187 |     readonly targetAudience?: string,
188 |     /* targetServiceAccount format: <service-account-name>@<project-num>.iam.gserviceaccount.com */
189 |     readonly targetServiceAccount?: string,
190 |   ) {}
191 | }
192 | 
193 | export enum AuthProviderType {
194 |   DYNAMIC_DISCOVERY = 'dynamic_discovery',
195 |   GOOGLE_CREDENTIALS = 'google_credentials',
196 |   SERVICE_ACCOUNT_IMPERSONATION = 'service_account_impersonation',
197 | }
198 | 
199 | export interface SandboxConfig {
200 |   command: 'docker' | 'podman' | 'sandbox-exec';
201 |   image: string;
202 | }
203 | 
204 | export interface ConfigParameters {
205 |   sessionId: string;
206 |   embeddingModel?: string;
207 |   sandbox?: SandboxConfig;
208 |   targetDir: string;
209 |   debugMode: boolean;
210 |   question?: string;
211 |   fullContext?: boolean;
212 |   coreTools?: string[];
213 |   allowedTools?: string[];
214 |   excludeTools?: string[];
215 |   toolDiscoveryCommand?: string;
216 |   toolCallCommand?: string;
217 |   mcpServerCommand?: string;
218 |   mcpServers?: Record<string, MCPServerConfig>;
219 |   userMemory?: string;
220 |   geminiMdFileCount?: number;
221 |   geminiMdFilePaths?: string[];
222 |   approvalMode?: ApprovalMode;
223 |   showMemoryUsage?: boolean;
224 |   contextFileName?: string | string[];
225 |   accessibility?: AccessibilitySettings;
226 |   telemetry?: TelemetrySettings;
227 |   usageStatisticsEnabled?: boolean;
228 |   fileFiltering?: {
229 |     respectGitIgnore?: boolean;
230 |     respectGeminiIgnore?: boolean;
231 |     enableRecursiveFileSearch?: boolean;
232 |     disableFuzzySearch?: boolean;
233 |   };
234 |   checkpointing?: boolean;
235 |   proxy?: string;
236 |   cwd: string;
237 |   fileDiscoveryService?: FileDiscoveryService;
238 |   includeDirectories?: string[];
239 |   bugCommand?: BugCommandSettings;
240 |   model: string;
241 |   extensionContextFilePaths?: string[];
242 |   maxSessionTurns?: number;
243 |   experimentalZedIntegration?: boolean;
244 |   listExtensions?: boolean;
245 |   extensions?: GeminiCLIExtension[];
246 |   blockedMcpServers?: Array<{ name: string; extensionName: string }>;
247 |   noBrowser?: boolean;
248 |   summarizeToolOutput?: Record<string, SummarizeToolOutputSettings>;
249 |   folderTrust?: boolean;
250 |   ideMode?: boolean;
251 |   loadMemoryFromIncludeDirectories?: boolean;
252 |   chatCompression?: ChatCompressionSettings;
253 |   interactive?: boolean;
254 |   trustedFolder?: boolean;
255 |   useRipgrep?: boolean;
256 |   enableInteractiveShell?: boolean;
257 |   skipNextSpeakerCheck?: boolean;
258 |   shellExecutionConfig?: ShellExecutionConfig;
259 |   extensionManagement?: boolean;
260 |   enablePromptCompletion?: boolean;
261 |   truncateToolOutputThreshold?: number;
262 |   truncateToolOutputLines?: number;
263 |   enableToolOutputTruncation?: boolean;
264 |   eventEmitter?: EventEmitter;
265 |   useSmartEdit?: boolean;
266 |   useWriteTodos?: boolean;
267 |   policyEngineConfig?: PolicyEngineConfig;
268 |   output?: OutputSettings;
269 |   useModelRouter?: boolean;
270 |   enableMessageBusIntegration?: boolean;
271 |   enableSubagents?: boolean;
272 |   continueOnFailedApiCall?: boolean;
273 | }
274 | 
275 | export class Config {
276 |   private toolRegistry!: ToolRegistry;
277 |   private promptRegistry!: PromptRegistry;
278 |   private agentRegistry!: AgentRegistry;
279 |   private readonly sessionId: string;
280 |   private fileSystemService: FileSystemService;
281 |   private contentGeneratorConfig!: ContentGeneratorConfig;
282 |   private contentGenerator!: ContentGenerator;
283 |   private readonly embeddingModel: string;
284 |   private readonly sandbox: SandboxConfig | undefined;
285 |   private readonly targetDir: string;
286 |   private workspaceContext: WorkspaceContext;
287 |   private readonly debugMode: boolean;
288 |   private readonly question: string | undefined;
289 |   private readonly fullContext: boolean;
290 |   private readonly coreTools: string[] | undefined;
291 |   private readonly allowedTools: string[] | undefined;
292 |   private readonly excludeTools: string[] | undefined;
293 |   private readonly toolDiscoveryCommand: string | undefined;
294 |   private readonly toolCallCommand: string | undefined;
295 |   private readonly mcpServerCommand: string | undefined;
296 |   private readonly mcpServers: Record<string, MCPServerConfig> | undefined;
297 |   private userMemory: string;
298 |   private geminiMdFileCount: number;
299 |   private geminiMdFilePaths: string[];
300 |   private approvalMode: ApprovalMode;
301 |   private readonly showMemoryUsage: boolean;
302 |   private readonly accessibility: AccessibilitySettings;
303 |   private readonly telemetrySettings: TelemetrySettings;
304 |   private readonly usageStatisticsEnabled: boolean;
305 |   private geminiClient!: GeminiClient;
306 |   private baseLlmClient!: BaseLlmClient;
307 |   private modelRouterService: ModelRouterService;
308 |   private readonly fileFiltering: {
309 |     respectGitIgnore: boolean;
310 |     respectGeminiIgnore: boolean;
311 |     enableRecursiveFileSearch: boolean;
312 |     disableFuzzySearch: boolean;
313 |   };
314 |   private fileDiscoveryService: FileDiscoveryService | null = null;
315 |   private gitService: GitService | undefined = undefined;
316 |   private readonly checkpointing: boolean;
317 |   private readonly proxy: string | undefined;
318 |   private readonly cwd: string;
319 |   private readonly bugCommand: BugCommandSettings | undefined;
320 |   private model: string;
321 |   private readonly extensionContextFilePaths: string[];
322 |   private readonly noBrowser: boolean;
323 |   private readonly folderTrust: boolean;
324 |   private ideMode: boolean;
325 | 
326 |   private inFallbackMode = false;
327 |   private readonly maxSessionTurns: number;
328 |   private readonly listExtensions: boolean;
329 |   private readonly _extensions: GeminiCLIExtension[];
330 |   private readonly _blockedMcpServers: Array<{
331 |     name: string;
332 |     extensionName: string;
333 |   }>;
334 |   fallbackModelHandler?: FallbackModelHandler;
335 |   private quotaErrorOccurred: boolean = false;
336 |   private readonly summarizeToolOutput:
337 |     | Record<string, SummarizeToolOutputSettings>
338 |     | undefined;
339 |   private readonly experimentalZedIntegration: boolean = false;
340 |   private readonly loadMemoryFromIncludeDirectories: boolean = false;
341 |   private readonly chatCompression: ChatCompressionSettings | undefined;
342 |   private readonly interactive: boolean;
343 |   private readonly trustedFolder: boolean | undefined;
344 |   private readonly useRipgrep: boolean;
345 |   private readonly enableInteractiveShell: boolean;
346 |   private readonly skipNextSpeakerCheck: boolean;
347 |   private shellExecutionConfig: ShellExecutionConfig;
348 |   private readonly extensionManagement: boolean = true;
349 |   private readonly enablePromptCompletion: boolean = false;
350 |   private readonly truncateToolOutputThreshold: number;
351 |   private readonly truncateToolOutputLines: number;
352 |   private readonly enableToolOutputTruncation: boolean;
353 |   private initialized: boolean = false;
354 |   readonly storage: Storage;
355 |   private readonly fileExclusions: FileExclusions;
356 |   private readonly eventEmitter?: EventEmitter;
357 |   private readonly useSmartEdit: boolean;
358 |   private readonly useWriteTodos: boolean;
359 |   private readonly messageBus: MessageBus;
360 |   private readonly policyEngine: PolicyEngine;
361 |   private readonly outputSettings: OutputSettings;
362 |   private readonly useModelRouter: boolean;
363 |   private readonly enableMessageBusIntegration: boolean;
364 |   private readonly enableSubagents: boolean;
365 |   private readonly continueOnFailedApiCall: boolean;
366 | 
367 |   constructor(params: ConfigParameters) {
368 |     this.sessionId = params.sessionId;
369 |     this.embeddingModel =
370 |       params.embeddingModel ?? DEFAULT_GEMINI_EMBEDDING_MODEL;
371 |     this.fileSystemService = new StandardFileSystemService();
372 |     this.sandbox = params.sandbox;
373 |     this.targetDir = path.resolve(params.targetDir);
374 |     this.workspaceContext = new WorkspaceContext(
375 |       this.targetDir,
376 |       params.includeDirectories ?? [],
377 |     );
378 |     this.debugMode = params.debugMode;
379 |     this.question = params.question;
380 |     this.fullContext = params.fullContext ?? false;
381 |     this.coreTools = params.coreTools;
382 |     this.allowedTools = params.allowedTools;
383 |     this.excludeTools = params.excludeTools;
384 |     this.toolDiscoveryCommand = params.toolDiscoveryCommand;
385 |     this.toolCallCommand = params.toolCallCommand;
386 |     this.mcpServerCommand = params.mcpServerCommand;
387 |     this.mcpServers = params.mcpServers;
388 |     this.userMemory = params.userMemory ?? '';
389 |     this.geminiMdFileCount = params.geminiMdFileCount ?? 0;
390 |     this.geminiMdFilePaths = params.geminiMdFilePaths ?? [];
391 |     this.approvalMode = params.approvalMode ?? ApprovalMode.DEFAULT;
392 |     this.showMemoryUsage = params.showMemoryUsage ?? false;
393 |     this.accessibility = params.accessibility ?? {};
394 |     this.telemetrySettings = {
395 |       enabled: params.telemetry?.enabled ?? false,
396 |       target: params.telemetry?.target ?? DEFAULT_TELEMETRY_TARGET,
397 |       otlpEndpoint: params.telemetry?.otlpEndpoint ?? DEFAULT_OTLP_ENDPOINT,
398 |       otlpProtocol: params.telemetry?.otlpProtocol,
399 |       logPrompts: params.telemetry?.logPrompts ?? true,
400 |       outfile: params.telemetry?.outfile,
401 |       useCollector: params.telemetry?.useCollector,
402 |     };
403 |     this.usageStatisticsEnabled = params.usageStatisticsEnabled ?? true;
404 | 
405 |     this.fileFiltering = {
406 |       respectGitIgnore:
407 |         params.fileFiltering?.respectGitIgnore ??
408 |         DEFAULT_FILE_FILTERING_OPTIONS.respectGitIgnore,
409 |       respectGeminiIgnore:
410 |         params.fileFiltering?.respectGeminiIgnore ??
411 |         DEFAULT_FILE_FILTERING_OPTIONS.respectGeminiIgnore,
412 |       enableRecursiveFileSearch:
413 |         params.fileFiltering?.enableRecursiveFileSearch ?? true,
414 |       disableFuzzySearch: params.fileFiltering?.disableFuzzySearch ?? false,
415 |     };
416 |     this.checkpointing = params.checkpointing ?? false;
417 |     this.proxy = params.proxy;
418 |     this.cwd = params.cwd ?? process.cwd();
419 |     this.fileDiscoveryService = params.fileDiscoveryService ?? null;
420 |     this.bugCommand = params.bugCommand;
421 |     this.model = params.model;
422 |     this.extensionContextFilePaths = params.extensionContextFilePaths ?? [];
423 |     this.maxSessionTurns = params.maxSessionTurns ?? -1;
424 |     this.experimentalZedIntegration =
425 |       params.experimentalZedIntegration ?? false;
426 |     this.listExtensions = params.listExtensions ?? false;
427 |     this._extensions = params.extensions ?? [];
428 |     this._blockedMcpServers = params.blockedMcpServers ?? [];
429 |     this.noBrowser = params.noBrowser ?? false;
430 |     this.summarizeToolOutput = params.summarizeToolOutput;
431 |     this.folderTrust = params.folderTrust ?? false;
432 |     this.ideMode = params.ideMode ?? false;
433 |     this.loadMemoryFromIncludeDirectories =
434 |       params.loadMemoryFromIncludeDirectories ?? false;
435 |     this.chatCompression = params.chatCompression;
436 |     this.interactive = params.interactive ?? false;
437 |     this.trustedFolder = params.trustedFolder;
438 |     this.useRipgrep = params.useRipgrep ?? true;
439 |     this.enableInteractiveShell = params.enableInteractiveShell ?? false;
440 |     this.skipNextSpeakerCheck = params.skipNextSpeakerCheck ?? true;
441 |     this.shellExecutionConfig = {
442 |       terminalWidth: params.shellExecutionConfig?.terminalWidth ?? 80,
443 |       terminalHeight: params.shellExecutionConfig?.terminalHeight ?? 24,
444 |       showColor: params.shellExecutionConfig?.showColor ?? false,
445 |       pager: params.shellExecutionConfig?.pager ?? 'cat',
446 |     };
447 |     this.truncateToolOutputThreshold =
448 |       params.truncateToolOutputThreshold ??
449 |       DEFAULT_TRUNCATE_TOOL_OUTPUT_THRESHOLD;
450 |     this.truncateToolOutputLines =
451 |       params.truncateToolOutputLines ?? DEFAULT_TRUNCATE_TOOL_OUTPUT_LINES;
452 |     this.enableToolOutputTruncation = params.enableToolOutputTruncation ?? true;
453 |     this.useSmartEdit = params.useSmartEdit ?? true;
454 |     this.useWriteTodos = params.useWriteTodos ?? false;
455 |     this.useModelRouter = params.useModelRouter ?? false;
456 |     this.enableMessageBusIntegration =
457 |       params.enableMessageBusIntegration ?? false;
458 |     this.enableSubagents = params.enableSubagents ?? false;
459 |     this.continueOnFailedApiCall = params.continueOnFailedApiCall ?? true;
460 |     this.extensionManagement = params.extensionManagement ?? true;
461 |     this.storage = new Storage(this.targetDir);
462 |     this.enablePromptCompletion = params.enablePromptCompletion ?? false;
463 |     this.fileExclusions = new FileExclusions(this);
464 |     this.eventEmitter = params.eventEmitter;
465 |     this.policyEngine = new PolicyEngine(params.policyEngineConfig);
466 |     this.messageBus = new MessageBus(this.policyEngine);
467 |     this.outputSettings = {
468 |       format: params.output?.format ?? OutputFormat.TEXT,
469 |     };
470 | 
471 |     if (params.contextFileName) {
472 |       setGeminiMdFilename(params.contextFileName);
473 |     }
474 | 
475 |     if (this.telemetrySettings.enabled) {
476 |       initializeTelemetry(this);
477 |     }
478 | 
479 |     if (this.getProxy()) {
480 |       setGlobalDispatcher(new ProxyAgent(this.getProxy() as string));
481 |     }
482 |     this.geminiClient = new GeminiClient(this);
483 |     this.modelRouterService = new ModelRouterService(this);
484 |   }
485 | 
486 |   /**
487 |    * Must only be called once, throws if called again.
488 |    */
489 |   async initialize(): Promise<void> {
490 |     if (this.initialized) {
491 |       throw Error('Config was already initialized');
492 |     }
493 |     this.initialized = true;
494 | 
495 |     // Initialize centralized FileDiscoveryService
496 |     this.getFileService();
497 |     if (this.getCheckpointingEnabled()) {
498 |       await this.getGitService();
499 |     }
500 |     this.promptRegistry = new PromptRegistry();
501 | 
502 |     this.agentRegistry = new AgentRegistry(this);
503 |     await this.agentRegistry.initialize();
504 | 
505 |     this.toolRegistry = await this.createToolRegistry();
506 | 
507 |     await this.geminiClient.initialize();
508 |   }
509 | 
510 |   getContentGenerator(): ContentGenerator {
511 |     return this.contentGenerator;
512 |   }
513 | 
514 |   async refreshAuth(authMethod: AuthType) {
515 |     // Vertex and Genai have incompatible encryption and sending history with
516 |     // throughtSignature from Genai to Vertex will fail, we need to strip them
517 |     if (
518 |       this.contentGeneratorConfig?.authType === AuthType.USE_GEMINI &&
519 |       authMethod === AuthType.LOGIN_WITH_GOOGLE
520 |     ) {
521 |       // Restore the conversation history to the new client
522 |       this.geminiClient.stripThoughtsFromHistory();
523 |     }
524 | 
525 |     const newContentGeneratorConfig = createContentGeneratorConfig(
526 |       this,
527 |       authMethod,
528 |     );
529 |     this.contentGenerator = await createContentGenerator(
530 |       newContentGeneratorConfig,
531 |       this,
532 |       this.getSessionId(),
533 |     );
534 |     // Only assign to instance properties after successful initialization
535 |     this.contentGeneratorConfig = newContentGeneratorConfig;
536 | 
537 |     // Initialize BaseLlmClient now that the ContentGenerator is available
538 |     this.baseLlmClient = new BaseLlmClient(this.contentGenerator, this);
539 | 
540 |     // Reset the session flag since we're explicitly changing auth and using default model
541 |     this.inFallbackMode = false;
542 | 
543 |     // Logging the cli configuration here as the auth related configuration params would have been loaded by this point
544 |     logCliConfiguration(this, new StartSessionEvent(this, this.toolRegistry));
545 |   }
546 | 
547 |   getUserTier(): UserTierId | undefined {
548 |     return this.contentGenerator?.userTier;
549 |   }
550 | 
551 |   /**
552 |    * Provides access to the BaseLlmClient for stateless LLM operations.
553 |    */
554 |   getBaseLlmClient(): BaseLlmClient {
555 |     if (!this.baseLlmClient) {
556 |       // Handle cases where initialization might be deferred or authentication failed
557 |       if (this.contentGenerator) {
558 |         this.baseLlmClient = new BaseLlmClient(
559 |           this.getContentGenerator(),
560 |           this,
561 |         );
562 |       } else {
563 |         throw new Error(
564 |           'BaseLlmClient not initialized. Ensure authentication has occurred and ContentGenerator is ready.',
565 |         );
566 |       }
567 |     }
568 |     return this.baseLlmClient;
569 |   }
570 | 
571 |   getSessionId(): string {
572 |     return this.sessionId;
573 |   }
574 | 
575 |   shouldLoadMemoryFromIncludeDirectories(): boolean {
576 |     return this.loadMemoryFromIncludeDirectories;
577 |   }
578 | 
579 |   getContentGeneratorConfig(): ContentGeneratorConfig {
580 |     return this.contentGeneratorConfig;
581 |   }
582 | 
583 |   getModel(): string {
584 |     return this.model;
585 |   }
586 | 
587 |   setModel(newModel: string): void {
588 |     // Do not allow Pro usage if the user is in fallback mode.
589 |     if (newModel.includes('pro') && this.isInFallbackMode()) {
590 |       return;
591 |     }
592 | 
593 |     this.model = newModel;
594 |   }
595 | 
596 |   isInFallbackMode(): boolean {
597 |     return this.inFallbackMode;
598 |   }
599 | 
600 |   setFallbackMode(active: boolean): void {
[TRUNCATED]
```

src/config/constants.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export interface FileFilteringOptions {
8 |   respectGitIgnore: boolean;
9 |   respectGeminiIgnore: boolean;
10 | }
11 | 
12 | // For memory files
13 | export const DEFAULT_MEMORY_FILE_FILTERING_OPTIONS: FileFilteringOptions = {
14 |   respectGitIgnore: false,
15 |   respectGeminiIgnore: true,
16 | };
17 | 
18 | // For all other files
19 | export const DEFAULT_FILE_FILTERING_OPTIONS: FileFilteringOptions = {
20 |   respectGitIgnore: true,
21 |   respectGeminiIgnore: true,
22 | };
```

src/config/flashFallback.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, vi } from 'vitest';
8 | import { Config } from './config.js';
9 | import { DEFAULT_GEMINI_MODEL, DEFAULT_GEMINI_FLASH_MODEL } from './models.js';
10 | 
11 | import fs from 'node:fs';
12 | 
13 | vi.mock('node:fs');
14 | 
15 | describe('Flash Model Fallback Configuration', () => {
16 |   let config: Config;
17 | 
18 |   beforeEach(() => {
19 |     vi.mocked(fs.existsSync).mockReturnValue(true);
20 |     vi.mocked(fs.statSync).mockReturnValue({
21 |       isDirectory: () => true,
22 |     } as fs.Stats);
23 |     config = new Config({
24 |       sessionId: 'test-session',
25 |       targetDir: '/test',
26 |       debugMode: false,
27 |       cwd: '/test',
28 |       model: DEFAULT_GEMINI_MODEL,
29 |     });
30 | 
31 |     // Initialize contentGeneratorConfig for testing
32 |     (
33 |       config as unknown as { contentGeneratorConfig: unknown }
34 |     ).contentGeneratorConfig = {
35 |       model: DEFAULT_GEMINI_MODEL,
36 |       authType: 'oauth-personal',
37 |     };
38 |   });
39 | 
40 |   // These tests do not actually test fallback. isInFallbackMode() only returns true,
41 |   // when setFallbackMode is marked as true. This is to decouple setting a model
42 |   // with the fallback mechanism. This will be necessary we introduce more
43 |   // intelligent model routing.
44 |   describe('setModel', () => {
45 |     it('should only mark as switched if contentGeneratorConfig exists', () => {
46 |       // Create config without initializing contentGeneratorConfig
47 |       const newConfig = new Config({
48 |         sessionId: 'test-session-2',
49 |         targetDir: '/test',
50 |         debugMode: false,
51 |         cwd: '/test',
52 |         model: DEFAULT_GEMINI_MODEL,
53 |       });
54 | 
55 |       // Should not crash when contentGeneratorConfig is undefined
56 |       newConfig.setModel(DEFAULT_GEMINI_FLASH_MODEL);
57 |       expect(newConfig.isInFallbackMode()).toBe(false);
58 |     });
59 |   });
60 | 
61 |   describe('getModel', () => {
62 |     it('should return contentGeneratorConfig model if available', () => {
63 |       // Simulate initialized content generator config
64 |       config.setModel(DEFAULT_GEMINI_FLASH_MODEL);
65 |       expect(config.getModel()).toBe(DEFAULT_GEMINI_FLASH_MODEL);
66 |     });
67 | 
68 |     it('should fall back to initial model if contentGeneratorConfig is not available', () => {
69 |       // Test with fresh config where contentGeneratorConfig might not be set
70 |       const newConfig = new Config({
71 |         sessionId: 'test-session-2',
72 |         targetDir: '/test',
73 |         debugMode: false,
74 |         cwd: '/test',
75 |         model: 'custom-model',
76 |       });
77 | 
78 |       expect(newConfig.getModel()).toBe('custom-model');
79 |     });
80 |   });
81 | 
82 |   describe('isInFallbackMode', () => {
83 |     it('should start as false for new session', () => {
84 |       expect(config.isInFallbackMode()).toBe(false);
85 |     });
86 | 
87 |     it('should remain false if no model switch occurs', () => {
88 |       // Perform other operations that don't involve model switching
89 |       expect(config.isInFallbackMode()).toBe(false);
90 |     });
91 | 
92 |     it('should persist switched state throughout session', () => {
93 |       config.setModel(DEFAULT_GEMINI_FLASH_MODEL);
94 |       // Setting state for fallback mode as is expected of clients
95 |       config.setFallbackMode(true);
96 |       expect(config.isInFallbackMode()).toBe(true);
97 | 
98 |       // Should remain true even after getting model
99 |       config.getModel();
100 |       expect(config.isInFallbackMode()).toBe(true);
101 |     });
102 |   });
103 | });
```

src/config/models.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import {
9 |   getEffectiveModel,
10 |   DEFAULT_GEMINI_MODEL,
11 |   DEFAULT_GEMINI_FLASH_MODEL,
12 |   DEFAULT_GEMINI_FLASH_LITE_MODEL,
13 | } from './models.js';
14 | 
15 | describe('getEffectiveModel', () => {
16 |   describe('When NOT in fallback mode', () => {
17 |     const isInFallbackMode = false;
18 | 
19 |     it('should return the Pro model when Pro is requested', () => {
20 |       const model = getEffectiveModel(isInFallbackMode, DEFAULT_GEMINI_MODEL);
21 |       expect(model).toBe(DEFAULT_GEMINI_MODEL);
22 |     });
23 | 
24 |     it('should return the Flash model when Flash is requested', () => {
25 |       const model = getEffectiveModel(
26 |         isInFallbackMode,
27 |         DEFAULT_GEMINI_FLASH_MODEL,
28 |       );
29 |       expect(model).toBe(DEFAULT_GEMINI_FLASH_MODEL);
30 |     });
31 | 
32 |     it('should return the Lite model when Lite is requested', () => {
33 |       const model = getEffectiveModel(
34 |         isInFallbackMode,
35 |         DEFAULT_GEMINI_FLASH_LITE_MODEL,
36 |       );
37 |       expect(model).toBe(DEFAULT_GEMINI_FLASH_LITE_MODEL);
38 |     });
39 | 
40 |     it('should return a custom model name when requested', () => {
41 |       const customModel = 'custom-model-v1';
42 |       const model = getEffectiveModel(isInFallbackMode, customModel);
43 |       expect(model).toBe(customModel);
44 |     });
45 |   });
46 | 
47 |   describe('When IN fallback mode', () => {
48 |     const isInFallbackMode = true;
49 | 
50 |     it('should downgrade the Pro model to the Flash model', () => {
51 |       const model = getEffectiveModel(isInFallbackMode, DEFAULT_GEMINI_MODEL);
52 |       expect(model).toBe(DEFAULT_GEMINI_FLASH_MODEL);
53 |     });
54 | 
55 |     it('should return the Flash model when Flash is requested', () => {
56 |       const model = getEffectiveModel(
57 |         isInFallbackMode,
58 |         DEFAULT_GEMINI_FLASH_MODEL,
59 |       );
60 |       expect(model).toBe(DEFAULT_GEMINI_FLASH_MODEL);
61 |     });
62 | 
63 |     it('should HONOR the Lite model when Lite is requested', () => {
64 |       const model = getEffectiveModel(
65 |         isInFallbackMode,
66 |         DEFAULT_GEMINI_FLASH_LITE_MODEL,
67 |       );
68 |       expect(model).toBe(DEFAULT_GEMINI_FLASH_LITE_MODEL);
69 |     });
70 | 
71 |     it('should HONOR any model with "lite" in its name', () => {
72 |       const customLiteModel = 'gemini-2.5-custom-lite-vNext';
73 |       const model = getEffectiveModel(isInFallbackMode, customLiteModel);
74 |       expect(model).toBe(customLiteModel);
75 |     });
76 | 
77 |     it('should downgrade any other custom model to the Flash model', () => {
78 |       const customModel = 'custom-model-v1-unlisted';
79 |       const model = getEffectiveModel(isInFallbackMode, customModel);
80 |       expect(model).toBe(DEFAULT_GEMINI_FLASH_MODEL);
81 |     });
82 |   });
83 | });
```

src/config/models.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export const DEFAULT_GEMINI_MODEL = 'gemini-2.5-pro';
8 | export const DEFAULT_GEMINI_FLASH_MODEL = 'gemini-2.5-flash';
9 | export const DEFAULT_GEMINI_FLASH_LITE_MODEL = 'gemini-2.5-flash-lite';
10 | 
11 | export const DEFAULT_GEMINI_MODEL_AUTO = 'auto';
12 | 
13 | export const DEFAULT_GEMINI_EMBEDDING_MODEL = 'gemini-embedding-001';
14 | 
15 | // Some thinking models do not default to dynamic thinking which is done by a value of -1
16 | export const DEFAULT_THINKING_MODE = -1;
17 | 
18 | /**
19 |  * Determines the effective model to use, applying fallback logic if necessary.
20 |  *
21 |  * When fallback mode is active, this function enforces the use of the standard
22 |  * fallback model. However, it makes an exception for "lite" models (any model
23 |  * with "lite" in its name), allowing them to be used to preserve cost savings.
24 |  * This ensures that "pro" models are always downgraded, while "lite" model
25 |  * requests are honored.
26 |  *
27 |  * @param isInFallbackMode Whether the application is in fallback mode.
28 |  * @param requestedModel The model that was originally requested.
29 |  * @returns The effective model name.
30 |  */
31 | export function getEffectiveModel(
32 |   isInFallbackMode: boolean,
33 |   requestedModel: string,
34 | ): string {
35 |   // If we are not in fallback mode, simply use the requested model.
36 |   if (!isInFallbackMode) {
37 |     return requestedModel;
38 |   }
39 | 
40 |   // If a "lite" model is requested, honor it. This allows for variations of
41 |   // lite models without needing to list them all as constants.
42 |   if (requestedModel.includes('lite')) {
43 |     return requestedModel;
44 |   }
45 | 
46 |   // Default fallback for Gemini CLI.
47 |   return DEFAULT_GEMINI_FLASH_MODEL;
48 | }
```

src/config/storage.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi } from 'vitest';
8 | import * as os from 'node:os';
9 | import * as path from 'node:path';
10 | 
11 | vi.mock('fs', async (importOriginal) => {
12 |   const actual = await importOriginal<typeof import('fs')>();
13 |   return {
14 |     ...actual,
15 |     mkdirSync: vi.fn(),
16 |   };
17 | });
18 | 
19 | import { Storage } from './storage.js';
20 | 
21 | describe('Storage – getGlobalSettingsPath', () => {
22 |   it('returns path to ~/.gemini/settings.json', () => {
23 |     const expected = path.join(os.homedir(), '.gemini', 'settings.json');
24 |     expect(Storage.getGlobalSettingsPath()).toBe(expected);
25 |   });
26 | });
27 | 
28 | describe('Storage – additional helpers', () => {
29 |   const projectRoot = '/tmp/project';
30 |   const storage = new Storage(projectRoot);
31 | 
32 |   it('getWorkspaceSettingsPath returns project/.gemini/settings.json', () => {
33 |     const expected = path.join(projectRoot, '.gemini', 'settings.json');
34 |     expect(storage.getWorkspaceSettingsPath()).toBe(expected);
35 |   });
36 | 
37 |   it('getUserCommandsDir returns ~/.gemini/commands', () => {
38 |     const expected = path.join(os.homedir(), '.gemini', 'commands');
39 |     expect(Storage.getUserCommandsDir()).toBe(expected);
40 |   });
41 | 
42 |   it('getProjectCommandsDir returns project/.gemini/commands', () => {
43 |     const expected = path.join(projectRoot, '.gemini', 'commands');
44 |     expect(storage.getProjectCommandsDir()).toBe(expected);
45 |   });
46 | 
47 |   it('getMcpOAuthTokensPath returns ~/.gemini/mcp-oauth-tokens.json', () => {
48 |     const expected = path.join(
49 |       os.homedir(),
50 |       '.gemini',
51 |       'mcp-oauth-tokens.json',
52 |     );
53 |     expect(Storage.getMcpOAuthTokensPath()).toBe(expected);
54 |   });
55 | 
56 |   it('getGlobalBinDir returns ~/.gemini/tmp/bin', () => {
57 |     const expected = path.join(os.homedir(), '.gemini', 'tmp', 'bin');
58 |     expect(Storage.getGlobalBinDir()).toBe(expected);
59 |   });
60 | });
```

src/config/storage.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as path from 'node:path';
8 | import * as os from 'node:os';
9 | import * as crypto from 'node:crypto';
10 | import * as fs from 'node:fs';
11 | 
12 | export const GEMINI_DIR = '.gemini';
13 | export const GOOGLE_ACCOUNTS_FILENAME = 'google_accounts.json';
14 | export const OAUTH_FILE = 'oauth_creds.json';
15 | const TMP_DIR_NAME = 'tmp';
16 | const BIN_DIR_NAME = 'bin';
17 | 
18 | export class Storage {
19 |   private readonly targetDir: string;
20 | 
21 |   constructor(targetDir: string) {
22 |     this.targetDir = targetDir;
23 |   }
24 | 
25 |   static getGlobalGeminiDir(): string {
26 |     const homeDir = os.homedir();
27 |     if (!homeDir) {
28 |       return path.join(os.tmpdir(), '.gemini');
29 |     }
30 |     return path.join(homeDir, GEMINI_DIR);
31 |   }
32 | 
33 |   static getMcpOAuthTokensPath(): string {
34 |     return path.join(Storage.getGlobalGeminiDir(), 'mcp-oauth-tokens.json');
35 |   }
36 | 
37 |   static getGlobalSettingsPath(): string {
38 |     return path.join(Storage.getGlobalGeminiDir(), 'settings.json');
39 |   }
40 | 
41 |   static getInstallationIdPath(): string {
42 |     return path.join(Storage.getGlobalGeminiDir(), 'installation_id');
43 |   }
44 | 
45 |   static getGoogleAccountsPath(): string {
46 |     return path.join(Storage.getGlobalGeminiDir(), GOOGLE_ACCOUNTS_FILENAME);
47 |   }
48 | 
49 |   static getUserCommandsDir(): string {
50 |     return path.join(Storage.getGlobalGeminiDir(), 'commands');
51 |   }
52 | 
53 |   static getGlobalMemoryFilePath(): string {
54 |     return path.join(Storage.getGlobalGeminiDir(), 'memory.md');
55 |   }
56 | 
57 |   static getGlobalTempDir(): string {
58 |     return path.join(Storage.getGlobalGeminiDir(), TMP_DIR_NAME);
59 |   }
60 | 
61 |   static getGlobalBinDir(): string {
62 |     return path.join(Storage.getGlobalTempDir(), BIN_DIR_NAME);
63 |   }
64 | 
65 |   getGeminiDir(): string {
66 |     return path.join(this.targetDir, GEMINI_DIR);
67 |   }
68 | 
69 |   getProjectTempDir(): string {
70 |     const hash = this.getFilePathHash(this.getProjectRoot());
71 |     const tempDir = Storage.getGlobalTempDir();
72 |     return path.join(tempDir, hash);
73 |   }
74 | 
75 |   ensureProjectTempDirExists(): void {
76 |     fs.mkdirSync(this.getProjectTempDir(), { recursive: true });
77 |   }
78 | 
79 |   static getOAuthCredsPath(): string {
80 |     return path.join(Storage.getGlobalGeminiDir(), OAUTH_FILE);
81 |   }
82 | 
83 |   getProjectRoot(): string {
84 |     return this.targetDir;
85 |   }
86 | 
87 |   private getFilePathHash(filePath: string): string {
88 |     return crypto.createHash('sha256').update(filePath).digest('hex');
89 |   }
90 | 
91 |   getHistoryDir(): string {
92 |     const hash = this.getFilePathHash(this.getProjectRoot());
93 |     const historyDir = path.join(Storage.getGlobalGeminiDir(), 'history');
94 |     return path.join(historyDir, hash);
95 |   }
96 | 
97 |   getWorkspaceSettingsPath(): string {
98 |     return path.join(this.getGeminiDir(), 'settings.json');
99 |   }
100 | 
101 |   getProjectCommandsDir(): string {
102 |     return path.join(this.getGeminiDir(), 'commands');
103 |   }
104 | 
105 |   getProjectTempCheckpointsDir(): string {
106 |     return path.join(this.getProjectTempDir(), 'checkpoints');
107 |   }
108 | 
109 |   getExtensionsDir(): string {
110 |     return path.join(this.getGeminiDir(), 'extensions');
111 |   }
112 | 
113 |   getExtensionsConfigPath(): string {
114 |     return path.join(this.getExtensionsDir(), 'gemini-extension.json');
115 |   }
116 | 
117 |   getHistoryFilePath(): string {
118 |     return path.join(this.getProjectTempDir(), 'shell_history');
119 |   }
120 | }
```

src/agents/codebase-investigator.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { AgentDefinition } from './types.js';
8 | import { LSTool } from '../tools/ls.js';
9 | import { ReadFileTool } from '../tools/read-file.js';
10 | import { GLOB_TOOL_NAME } from '../tools/tool-names.js';
11 | import { GrepTool } from '../tools/grep.js';
12 | import { DEFAULT_GEMINI_MODEL } from '../config/models.js';
13 | import { z } from 'zod';
14 | 
15 | // Define a type that matches the outputConfig schema for type safety.
16 | const CodebaseInvestigationReportSchema = z.object({
17 |   SummaryOfFindings: z
18 |     .string()
19 |     .describe(
20 |       "A summary of the investigation's conclusions and insights for the main agent.",
21 |     ),
22 |   ExplorationTrace: z
23 |     .array(z.string())
24 |     .describe(
25 |       'A step-by-step list of actions and tools used during the investigation.',
26 |     ),
27 |   RelevantLocations: z
28 |     .array(
29 |       z.object({
30 |         FilePath: z.string(),
31 |         Reasoning: z.string(),
32 |         KeySymbols: z.array(z.string()),
33 |       }),
34 |     )
35 |     .describe('A list of relevant files and the key symbols within them.'),
36 | });
37 | 
38 | /**
39 |  * A Proof-of-Concept subagent specialized in analyzing codebase structure,
40 |  * dependencies, and technologies.
41 |  */
42 | export const CodebaseInvestigatorAgent: AgentDefinition<
43 |   typeof CodebaseInvestigationReportSchema
44 | > = {
45 |   name: 'codebase_investigator',
46 |   displayName: 'Codebase Investigator Agent',
47 |   description: `Your primary tool for multifile search tasks and codebase exploration. 
48 |     Invoke this tool to delegate search tasks to an autonomous subagent. 
49 |     Use this to find features, understand context, or locate specific files, functions, or symbols. 
50 |     Returns a structured Json report with key file paths, symbols, architectural map and insights to solve a task or answer questions`,
51 |   inputConfig: {
52 |     inputs: {
53 |       objective: {
54 |         description: `A comprehensive and detailed description of the user's ultimate goal. 
55 |           You must include original user's objective as well as questions and any extra context and questions you may have.`,
56 |         type: 'string',
57 |         required: true,
58 |       },
59 |     },
60 |   },
61 |   outputConfig: {
62 |     outputName: 'report',
63 |     description: 'The final investigation report as a JSON object.',
64 |     schema: CodebaseInvestigationReportSchema,
65 |   },
66 | 
67 |   // The 'output' parameter is now strongly typed as CodebaseInvestigationReportSchema
68 |   processOutput: (output) => JSON.stringify(output, null, 2),
69 | 
70 |   modelConfig: {
71 |     model: DEFAULT_GEMINI_MODEL,
72 |     temp: 0.1,
73 |     top_p: 0.95,
74 |     thinkingBudget: -1,
75 |   },
76 | 
77 |   runConfig: {
78 |     max_time_minutes: 5,
79 |     max_turns: 15,
80 |   },
81 | 
82 |   toolConfig: {
83 |     // Grant access only to read-only tools.
84 |     tools: [LSTool.Name, ReadFileTool.Name, GLOB_TOOL_NAME, GrepTool.Name],
85 |   },
86 | 
87 |   promptConfig: {
88 |     query: `Your task is to do a deep investigation of the codebase to find all relevant files, code locations, architectural mental map and insights to solve  for the following user objective:
89 | <objective>
90 | \${objective}
91 | </objective>`,
92 |     systemPrompt: `You are **Codebase Investigator**, a hyper-specialized AI agent and an expert in reverse-engineering complex software projects. You are a sub-agent within a larger development system.
93 | Your **SOLE PURPOSE** is to build a complete mental model of the code relevant to a given investigation. You must identify all relevant files, understand their roles, and foresee the direct architectural consequences of potential changes.
94 | You are a sub-agent in a larger system. Your only responsibility is to provide deep, actionable context.
95 | - **DO:** Find the key modules, classes, and functions that are part of the problem and its solution.
96 | - **DO:** Understand *why* the code is written the way it is. Question everything.
97 | - **DO:** Foresee the ripple effects of a change. If \`function A\` is modified, you must check its callers. If a data structure is altered, you must identify where its type definitions need to be updated.
98 | - **DO:** provide a conclusion and insights to the main agent that invoked you. If the agent is trying to solve a bug, you should provide the root cause of the bug, its impacts, how to fix it etc. If it's a new feature, you should provide insights on where to implement it, what chagnes are necessary etc. 
99 | - **DO NOT:** Write the final implementation code yourself.
100 | - **DO NOT:** Stop at the first relevant file. Your goal is a comprehensive understanding of the entire relevant subsystem.
101 | You operate in a non-interactive loop and must reason based on the information provided and the output of your tools.
102 | ---
103 | ## Core Directives
104 | <RULES>
105 | 1.  **DEEP ANALYSIS, NOT JUST FILE FINDING:** Your goal is to understand the *why* behind the code. Don't just list files; explain their purpose and the role of their key components. Your final report should empower another agent to make a correct and complete fix.
106 | 2.  **SYSTEMATIC & CURIOUS EXPLORATION:** Start with high-value clues (like tracebacks or ticket numbers) and broaden your search as needed. Think like a senior engineer doing a code review. An initial file contains clues (imports, function calls, puzzling logic). **If you find something you don't understand, you MUST prioritize investigating it until it is clear.** Treat confusion as a signal to dig deeper.
107 | 3.  **HOLISTIC & PRECISE:** Your goal is to find the complete and minimal set of locations that need to be understood or changed. Do not stop until you are confident you have considered the side effects of a potential fix (e.g., type errors, breaking changes to callers, opportunities for code reuse).
108 | 4.  **Web Search:** You are allowed to use the \`web_fetch\` tool to research libraries, language features, or concepts you don't understand (e.g., "what does gettext.translation do with localedir=None?").
109 | </RULES>
110 | ---
111 | ## Scratchpad Management
112 | **This is your most critical function. Your scratchpad is your memory and your plan.**
113 | 1.  **Initialization:** On your very first turn, you **MUST** create the \`<scratchpad>\` section. Analyze the \`task\` and create an initial \`Checklist\` of investigation goals and a \`Questions to Resolve\` section for any initial uncertainties.
114 | 2.  **Constant Updates:** After **every** \`<OBSERVATION>\`, you **MUST** update the scratchpad.
115 |     * Mark checklist items as complete: \`[x]\`.
116 |     * Add new checklist items as you trace the architecture.
117 |     * **Explicitly log questions in \`Questions to Resolve\`** (e.g., \`[ ] What is the purpose of the 'None' element in this list?\`). Do not consider your investigation complete until this list is empty.
118 |     * Record \`Key Findings\` with file paths and notes about their purpose and relevance.
119 |     * Update \`Irrelevant Paths to Ignore\` to avoid re-investigating dead ends.
120 | 3.  **Thinking on Paper:** The scratchpad must show your reasoning process, including how you resolve your questions.
121 | ---
122 | ## Termination
123 | Your mission is complete **ONLY** when your \`Questions to Resolve\` list is empty and you have identified all files and necessary change *considerations*.
124 | When you are finished, you **MUST** call the \`complete_task\` tool. The \`report\` argument for this tool **MUST** be a valid JSON object containing your findings.
125 | 
126 | **Example of the final report**
127 | \`\`\`json
128 | {
129 |   "SummaryOfFindings": "The core issue is a race condition in the \`updateUser\` function. The function reads the user's state, performs an asynchronous operation, and then writes the state back. If another request modifies the user state during the async operation, that change will be overwritten. The fix requires implementing a transactional read-modify-write pattern, potentially using a database lock or a versioning system.",
130 |   "ExplorationTrace": [
131 |     "Used \`grep\` to search for \`updateUser\` to locate the primary function.",
132 |     "Read the file \`src/controllers/userController.js\` to understand the function's logic.",
133 |     "Used \`ls -R\` to look for related files, such as services or database models.",
134 |     "Read \`src/services/userService.js\` and \`src/models/User.js\` to understand the data flow and how state is managed."
135 |   ],
136 |   "RelevantLocations": [
137 |     {
138 |       "FilePath": "src/controllers/userController.js",
139 |       "Reasoning": "This file contains the \`updateUser\` function which has the race condition. It's the entry point for the problematic logic.",
140 |       "KeySymbols": ["updateUser", "getUser", "saveUser"]
141 |     },
142 |     {
143 |       "FilePath": "src/services/userService.js",
144 |       "Reasoning": "This service is called by the controller and handles the direct interaction with the data layer. Any locking mechanism would likely be implemented here.",
145 |       "KeySymbols": ["updateUserData"]
146 |     }
147 |   ]
148 | }
149 | \`\`\`
150 | `,
151 |   },
152 | };
```

src/agents/executor.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import { AgentExecutor, type ActivityCallback } from './executor.js';
9 | import { makeFakeConfig } from '../test-utils/config.js';
10 | import { ToolRegistry } from '../tools/tool-registry.js';
11 | import { LSTool } from '../tools/ls.js';
12 | import { ReadFileTool } from '../tools/read-file.js';
13 | import {
14 |   GeminiChat,
15 |   StreamEventType,
16 |   type StreamEvent,
17 | } from '../core/geminiChat.js';
18 | import {
19 |   type FunctionCall,
20 |   type Part,
21 |   type GenerateContentResponse,
22 |   type GenerateContentConfig,
23 | } from '@google/genai';
24 | import type { Config } from '../config/config.js';
25 | import { MockTool } from '../test-utils/mock-tool.js';
26 | import { getDirectoryContextString } from '../utils/environmentContext.js';
27 | import { z } from 'zod';
28 | import { promptIdContext } from '../utils/promptIdContext.js';
29 | import { logAgentStart, logAgentFinish } from '../telemetry/loggers.js';
30 | import { AgentStartEvent, AgentFinishEvent } from '../telemetry/types.js';
31 | import type {
32 |   AgentDefinition,
33 |   AgentInputs,
34 |   SubagentActivityEvent,
35 |   OutputConfig,
36 | } from './types.js';
37 | import { AgentTerminateMode } from './types.js';
38 | 
39 | const { mockSendMessageStream, mockExecuteToolCall } = vi.hoisted(() => ({
40 |   mockSendMessageStream: vi.fn(),
41 |   mockExecuteToolCall: vi.fn(),
42 | }));
43 | 
44 | vi.mock('../core/geminiChat.js', async (importOriginal) => {
45 |   const actual = await importOriginal<typeof import('../core/geminiChat.js')>();
46 |   return {
47 |     ...actual,
48 |     GeminiChat: vi.fn().mockImplementation(() => ({
49 |       sendMessageStream: mockSendMessageStream,
50 |     })),
51 |   };
52 | });
53 | 
54 | vi.mock('../core/nonInteractiveToolExecutor.js', () => ({
55 |   executeToolCall: mockExecuteToolCall,
56 | }));
57 | 
58 | vi.mock('../utils/environmentContext.js');
59 | 
60 | vi.mock('../telemetry/loggers.js', () => ({
61 |   logAgentStart: vi.fn(),
62 |   logAgentFinish: vi.fn(),
63 | }));
64 | 
65 | vi.mock('../utils/promptIdContext.js', async (importOriginal) => {
66 |   const actual =
67 |     await importOriginal<typeof import('../utils/promptIdContext.js')>();
68 |   return {
69 |     ...actual,
70 |     promptIdContext: {
71 |       ...actual.promptIdContext,
72 |       getStore: vi.fn(),
73 |       run: vi.fn((_id, fn) => fn()),
74 |     },
75 |   };
76 | });
77 | 
78 | const MockedGeminiChat = vi.mocked(GeminiChat);
79 | const mockedGetDirectoryContextString = vi.mocked(getDirectoryContextString);
80 | const mockedPromptIdContext = vi.mocked(promptIdContext);
81 | const mockedLogAgentStart = vi.mocked(logAgentStart);
82 | const mockedLogAgentFinish = vi.mocked(logAgentFinish);
83 | 
84 | // Constants for testing
85 | const TASK_COMPLETE_TOOL_NAME = 'complete_task';
86 | const MOCK_TOOL_NOT_ALLOWED = new MockTool({ name: 'write_file_interactive' });
87 | 
88 | /**
89 |  * Helper to create a mock API response chunk.
90 |  * Uses conditional spread to handle readonly functionCalls property safely.
91 |  */
92 | const createMockResponseChunk = (
93 |   parts: Part[],
94 |   functionCalls?: FunctionCall[],
95 | ): GenerateContentResponse =>
96 |   ({
97 |     candidates: [{ index: 0, content: { role: 'model', parts } }],
98 |     ...(functionCalls && functionCalls.length > 0 ? { functionCalls } : {}),
99 |   }) as unknown as GenerateContentResponse;
100 | 
101 | /**
102 |  * Helper to mock a single turn of model response in the stream.
103 |  */
104 | const mockModelResponse = (
105 |   functionCalls: FunctionCall[],
106 |   thought?: string,
107 |   text?: string,
108 | ) => {
109 |   const parts: Part[] = [];
110 |   if (thought) {
111 |     parts.push({
112 |       text: `**${thought}** This is the reasoning part.`,
113 |       thought: true,
114 |     });
115 |   }
116 |   if (text) parts.push({ text });
117 | 
118 |   const responseChunk = createMockResponseChunk(parts, functionCalls);
119 | 
120 |   mockSendMessageStream.mockImplementationOnce(async () =>
121 |     (async function* () {
122 |       yield {
123 |         type: StreamEventType.CHUNK,
124 |         value: responseChunk,
125 |       } as StreamEvent;
126 |     })(),
127 |   );
128 | };
129 | 
130 | /**
131 |  * Helper to extract the message parameters sent to sendMessageStream.
132 |  * Provides type safety for inspecting mock calls.
133 |  */
134 | const getMockMessageParams = (callIndex: number) => {
135 |   const call = mockSendMessageStream.mock.calls[callIndex];
136 |   expect(call).toBeDefined();
137 |   // Arg 1 of sendMessageStream is the message parameters
138 |   return call[1] as { message?: Part[]; config?: GenerateContentConfig };
139 | };
140 | 
141 | let mockConfig: Config;
142 | let parentToolRegistry: ToolRegistry;
143 | 
144 | /**
145 |  * Type-safe helper to create agent definitions for tests.
146 |  */
147 | const createTestDefinition = <TOutput extends z.ZodTypeAny>(
148 |   tools: Array<string | MockTool> = [LSTool.Name],
149 |   runConfigOverrides: Partial<AgentDefinition<TOutput>['runConfig']> = {},
150 |   outputConfigMode: 'default' | 'none' = 'default',
151 |   schema: TOutput = z.string() as unknown as TOutput,
152 | ): AgentDefinition<TOutput> => {
153 |   let outputConfig: OutputConfig<TOutput> | undefined;
154 | 
155 |   if (outputConfigMode === 'default') {
156 |     outputConfig = {
157 |       outputName: 'finalResult',
158 |       description: 'The final result.',
159 |       schema,
160 |     };
161 |   }
162 | 
163 |   return {
164 |     name: 'TestAgent',
165 |     description: 'An agent for testing.',
166 |     inputConfig: {
167 |       inputs: { goal: { type: 'string', required: true, description: 'goal' } },
168 |     },
169 |     modelConfig: { model: 'gemini-test-model', temp: 0, top_p: 1 },
170 |     runConfig: { max_time_minutes: 5, max_turns: 5, ...runConfigOverrides },
171 |     promptConfig: { systemPrompt: 'Achieve the goal: ${goal}.' },
172 |     toolConfig: { tools },
173 |     outputConfig,
174 |   };
175 | };
176 | 
177 | describe('AgentExecutor', () => {
178 |   let activities: SubagentActivityEvent[];
179 |   let onActivity: ActivityCallback;
180 |   let abortController: AbortController;
181 |   let signal: AbortSignal;
182 | 
183 |   beforeEach(async () => {
184 |     vi.resetAllMocks();
185 |     mockSendMessageStream.mockReset();
186 |     mockExecuteToolCall.mockReset();
187 |     mockedLogAgentStart.mockReset();
188 |     mockedLogAgentFinish.mockReset();
189 |     mockedPromptIdContext.getStore.mockReset();
190 |     mockedPromptIdContext.run.mockImplementation((_id, fn) => fn());
191 | 
192 |     MockedGeminiChat.mockImplementation(
193 |       () =>
194 |         ({
195 |           sendMessageStream: mockSendMessageStream,
196 |         }) as unknown as GeminiChat,
197 |     );
198 | 
199 |     vi.useFakeTimers();
200 | 
201 |     mockConfig = makeFakeConfig();
202 |     parentToolRegistry = new ToolRegistry(mockConfig);
203 |     parentToolRegistry.registerTool(new LSTool(mockConfig));
204 |     parentToolRegistry.registerTool(new ReadFileTool(mockConfig));
205 |     parentToolRegistry.registerTool(MOCK_TOOL_NOT_ALLOWED);
206 | 
207 |     vi.spyOn(mockConfig, 'getToolRegistry').mockResolvedValue(
208 |       parentToolRegistry,
209 |     );
210 | 
211 |     mockedGetDirectoryContextString.mockResolvedValue(
212 |       'Mocked Environment Context',
213 |     );
214 | 
215 |     activities = [];
216 |     onActivity = (activity) => activities.push(activity);
217 |     abortController = new AbortController();
218 |     signal = abortController.signal;
219 |   });
220 | 
221 |   afterEach(() => {
222 |     vi.useRealTimers();
223 |   });
224 | 
225 |   describe('create (Initialization and Validation)', () => {
226 |     it('should create successfully with allowed tools', async () => {
227 |       const definition = createTestDefinition([LSTool.Name]);
228 |       const executor = await AgentExecutor.create(
229 |         definition,
230 |         mockConfig,
231 |         onActivity,
232 |       );
233 |       expect(executor).toBeInstanceOf(AgentExecutor);
234 |     });
235 | 
236 |     it('SECURITY: should throw if a tool is not on the non-interactive allowlist', async () => {
237 |       const definition = createTestDefinition([MOCK_TOOL_NOT_ALLOWED.name]);
238 |       await expect(
239 |         AgentExecutor.create(definition, mockConfig, onActivity),
240 |       ).rejects.toThrow(/not on the allow-list for non-interactive execution/);
241 |     });
242 | 
243 |     it('should create an isolated ToolRegistry for the agent', async () => {
244 |       const definition = createTestDefinition([LSTool.Name, ReadFileTool.Name]);
245 |       const executor = await AgentExecutor.create(
246 |         definition,
247 |         mockConfig,
248 |         onActivity,
249 |       );
250 | 
251 |       const agentRegistry = executor['toolRegistry'] as ToolRegistry;
252 | 
253 |       expect(agentRegistry).not.toBe(parentToolRegistry);
254 |       expect(agentRegistry.getAllToolNames()).toEqual(
255 |         expect.arrayContaining([LSTool.Name, ReadFileTool.Name]),
256 |       );
257 |       expect(agentRegistry.getAllToolNames()).toHaveLength(2);
258 |       expect(agentRegistry.getTool(MOCK_TOOL_NOT_ALLOWED.name)).toBeUndefined();
259 |     });
260 | 
261 |     it('should use parentPromptId from context to create agentId', async () => {
262 |       const parentId = 'parent-id';
263 |       mockedPromptIdContext.getStore.mockReturnValue(parentId);
264 | 
265 |       const definition = createTestDefinition();
266 |       const executor = await AgentExecutor.create(
267 |         definition,
268 |         mockConfig,
269 |         onActivity,
270 |       );
271 | 
272 |       expect(executor['agentId']).toMatch(
273 |         new RegExp(`^${parentId}-${definition.name}-`),
274 |       );
275 |     });
276 |   });
277 | 
278 |   describe('run (Execution Loop and Logic)', () => {
279 |     it('should log AgentFinish with error if run throws', async () => {
280 |       const definition = createTestDefinition();
281 |       // Make the definition invalid to cause an error during run
282 |       definition.inputConfig.inputs = {
283 |         goal: { type: 'string', required: true, description: 'goal' },
284 |       };
285 |       const executor = await AgentExecutor.create(
286 |         definition,
287 |         mockConfig,
288 |         onActivity,
289 |       );
290 | 
291 |       // Run without inputs to trigger validation error
292 |       await expect(executor.run({}, signal)).rejects.toThrow(
293 |         /Missing required input parameters/,
294 |       );
295 | 
296 |       expect(mockedLogAgentStart).toHaveBeenCalledTimes(1);
297 |       expect(mockedLogAgentFinish).toHaveBeenCalledTimes(1);
298 |       expect(mockedLogAgentFinish).toHaveBeenCalledWith(
299 |         mockConfig,
300 |         expect.objectContaining({
301 |           terminate_reason: AgentTerminateMode.ERROR,
302 |         }),
303 |       );
304 |     });
305 | 
306 |     it('should execute successfully when model calls complete_task with output (Happy Path with Output)', async () => {
307 |       const definition = createTestDefinition();
308 |       const executor = await AgentExecutor.create(
309 |         definition,
310 |         mockConfig,
311 |         onActivity,
312 |       );
313 |       const inputs: AgentInputs = { goal: 'Find files' };
314 | 
315 |       // Turn 1: Model calls ls
316 |       mockModelResponse(
317 |         [{ name: LSTool.Name, args: { path: '.' }, id: 'call1' }],
318 |         'T1: Listing',
319 |       );
320 |       mockExecuteToolCall.mockResolvedValueOnce({
321 |         callId: 'call1',
322 |         resultDisplay: 'file1.txt',
323 |         responseParts: [
324 |           {
325 |             functionResponse: {
326 |               name: LSTool.Name,
327 |               response: { result: 'file1.txt' },
328 |               id: 'call1',
329 |             },
330 |           },
331 |         ],
332 |         error: undefined,
333 |       });
334 | 
335 |       // Turn 2: Model calls complete_task with required output
336 |       mockModelResponse(
337 |         [
338 |           {
339 |             name: TASK_COMPLETE_TOOL_NAME,
340 |             args: { finalResult: 'Found file1.txt' },
341 |             id: 'call2',
342 |           },
343 |         ],
344 |         'T2: Done',
345 |       );
346 | 
347 |       const output = await executor.run(inputs, signal);
348 | 
349 |       expect(mockSendMessageStream).toHaveBeenCalledTimes(2);
350 | 
351 |       const chatConstructorArgs = MockedGeminiChat.mock.calls[0];
352 |       const chatConfig = chatConstructorArgs[1];
353 |       expect(chatConfig?.systemInstruction).toContain(
354 |         `MUST call the \`${TASK_COMPLETE_TOOL_NAME}\` tool`,
355 |       );
356 | 
357 |       const turn1Params = getMockMessageParams(0);
358 | 
359 |       const firstToolGroup = turn1Params.config?.tools?.[0];
360 |       expect(firstToolGroup).toBeDefined();
361 | 
362 |       if (!firstToolGroup || !('functionDeclarations' in firstToolGroup)) {
363 |         throw new Error(
364 |           'Test expectation failed: Config does not contain functionDeclarations.',
365 |         );
366 |       }
367 | 
368 |       const sentTools = firstToolGroup.functionDeclarations;
369 |       expect(sentTools).toBeDefined();
370 | 
371 |       expect(sentTools).toEqual(
372 |         expect.arrayContaining([
373 |           expect.objectContaining({ name: LSTool.Name }),
374 |           expect.objectContaining({ name: TASK_COMPLETE_TOOL_NAME }),
375 |         ]),
376 |       );
377 | 
378 |       const completeToolDef = sentTools!.find(
379 |         (t) => t.name === TASK_COMPLETE_TOOL_NAME,
380 |       );
381 |       expect(completeToolDef?.parameters?.required).toContain('finalResult');
382 | 
383 |       expect(output.result).toBe('Found file1.txt');
384 |       expect(output.terminate_reason).toBe(AgentTerminateMode.GOAL);
385 | 
386 |       // Telemetry checks
387 |       expect(mockedLogAgentStart).toHaveBeenCalledTimes(1);
388 |       expect(mockedLogAgentStart).toHaveBeenCalledWith(
389 |         mockConfig,
390 |         expect.any(AgentStartEvent),
391 |       );
392 |       expect(mockedLogAgentFinish).toHaveBeenCalledTimes(1);
393 |       expect(mockedLogAgentFinish).toHaveBeenCalledWith(
394 |         mockConfig,
395 |         expect.any(AgentFinishEvent),
396 |       );
397 |       const finishEvent = mockedLogAgentFinish.mock.calls[0][1];
398 |       expect(finishEvent.terminate_reason).toBe(AgentTerminateMode.GOAL);
399 | 
400 |       // Context checks
401 |       expect(mockedPromptIdContext.run).toHaveBeenCalledTimes(2); // Two turns
402 |       const agentId = executor['agentId'];
403 |       expect(mockedPromptIdContext.run).toHaveBeenNthCalledWith(
404 |         1,
405 |         `${agentId}#0`,
406 |         expect.any(Function),
407 |       );
408 |       expect(mockedPromptIdContext.run).toHaveBeenNthCalledWith(
409 |         2,
410 |         `${agentId}#1`,
411 |         expect.any(Function),
412 |       );
413 | 
414 |       expect(activities).toEqual(
415 |         expect.arrayContaining([
416 |           expect.objectContaining({
417 |             type: 'THOUGHT_CHUNK',
418 |             data: { text: 'T1: Listing' },
419 |           }),
420 |           expect.objectContaining({
421 |             type: 'TOOL_CALL_END',
422 |             data: { name: LSTool.Name, output: 'file1.txt' },
423 |           }),
424 |           expect.objectContaining({
425 |             type: 'TOOL_CALL_START',
426 |             data: {
427 |               name: TASK_COMPLETE_TOOL_NAME,
428 |               args: { finalResult: 'Found file1.txt' },
429 |             },
430 |           }),
431 |           expect.objectContaining({
432 |             type: 'TOOL_CALL_END',
433 |             data: {
434 |               name: TASK_COMPLETE_TOOL_NAME,
435 |               output: expect.stringContaining('Output submitted'),
436 |             },
437 |           }),
438 |         ]),
439 |       );
440 |     });
441 | 
442 |     it('should execute successfully when model calls complete_task without output (Happy Path No Output)', async () => {
443 |       const definition = createTestDefinition([LSTool.Name], {}, 'none');
444 |       const executor = await AgentExecutor.create(
445 |         definition,
446 |         mockConfig,
447 |         onActivity,
448 |       );
449 | 
450 |       mockModelResponse([
451 |         { name: LSTool.Name, args: { path: '.' }, id: 'call1' },
452 |       ]);
453 |       mockExecuteToolCall.mockResolvedValueOnce({
454 |         callId: 'call1',
455 |         resultDisplay: 'ok',
456 |         responseParts: [
457 |           {
458 |             functionResponse: { name: LSTool.Name, response: {}, id: 'call1' },
459 |           },
460 |         ],
461 |       });
462 | 
463 |       mockModelResponse(
464 |         [{ name: TASK_COMPLETE_TOOL_NAME, args: {}, id: 'call2' }],
465 |         'Task finished.',
466 |       );
467 | 
468 |       const output = await executor.run({ goal: 'Do work' }, signal);
469 | 
470 |       const turn1Params = getMockMessageParams(0);
471 |       const firstToolGroup = turn1Params.config?.tools?.[0];
472 | 
473 |       expect(firstToolGroup).toBeDefined();
474 |       if (!firstToolGroup || !('functionDeclarations' in firstToolGroup)) {
475 |         throw new Error(
476 |           'Test expectation failed: Config does not contain functionDeclarations.',
477 |         );
478 |       }
479 | 
480 |       const sentTools = firstToolGroup.functionDeclarations;
481 |       expect(sentTools).toBeDefined();
482 | 
483 |       const completeToolDef = sentTools!.find(
484 |         (t) => t.name === TASK_COMPLETE_TOOL_NAME,
485 |       );
486 |       expect(completeToolDef?.parameters?.required).toEqual([]);
487 |       expect(completeToolDef?.description).toContain(
488 |         'signal that you have completed',
489 |       );
490 | 
491 |       expect(output.result).toBe('Task completed successfully.');
492 |       expect(output.terminate_reason).toBe(AgentTerminateMode.GOAL);
493 |     });
494 | 
495 |     it('should error immediately if the model stops tools without calling complete_task (Protocol Violation)', async () => {
496 |       const definition = createTestDefinition();
497 |       const executor = await AgentExecutor.create(
498 |         definition,
499 |         mockConfig,
500 |         onActivity,
501 |       );
502 | 
503 |       mockModelResponse([
504 |         { name: LSTool.Name, args: { path: '.' }, id: 'call1' },
505 |       ]);
506 |       mockExecuteToolCall.mockResolvedValueOnce({
507 |         callId: 'call1',
508 |         resultDisplay: 'ok',
509 |         responseParts: [
510 |           {
511 |             functionResponse: { name: LSTool.Name, response: {}, id: 'call1' },
512 |           },
513 |         ],
514 |       });
515 | 
516 |       mockModelResponse([], 'I think I am done.');
517 | 
518 |       const output = await executor.run({ goal: 'Strict test' }, signal);
519 | 
520 |       expect(mockSendMessageStream).toHaveBeenCalledTimes(2);
521 | 
522 |       const expectedError = `Agent stopped calling tools but did not call '${TASK_COMPLETE_TOOL_NAME}' to finalize the session.`;
523 | 
524 |       expect(output.terminate_reason).toBe(AgentTerminateMode.ERROR);
525 |       expect(output.result).toBe(expectedError);
526 | 
527 |       // Telemetry check for error
528 |       expect(mockedLogAgentFinish).toHaveBeenCalledWith(
529 |         mockConfig,
530 |         expect.objectContaining({
531 |           terminate_reason: AgentTerminateMode.ERROR,
532 |         }),
533 |       );
534 | 
535 |       expect(activities).toContainEqual(
536 |         expect.objectContaining({
537 |           type: 'ERROR',
538 |           data: expect.objectContaining({
539 |             context: 'protocol_violation',
540 |             error: expectedError,
541 |           }),
542 |         }),
543 |       );
544 |     });
545 | 
546 |     it('should report an error if complete_task is called with missing required arguments', async () => {
547 |       const definition = createTestDefinition();
548 |       const executor = await AgentExecutor.create(
549 |         definition,
550 |         mockConfig,
551 |         onActivity,
552 |       );
553 | 
554 |       // Turn 1: Missing arg
555 |       mockModelResponse([
556 |         {
557 |           name: TASK_COMPLETE_TOOL_NAME,
558 |           args: { wrongArg: 'oops' },
559 |           id: 'call1',
560 |         },
561 |       ]);
562 | 
563 |       // Turn 2: Corrected
564 |       mockModelResponse([
565 |         {
566 |           name: TASK_COMPLETE_TOOL_NAME,
567 |           args: { finalResult: 'Corrected result' },
568 |           id: 'call2',
569 |         },
570 |       ]);
571 | 
572 |       const output = await executor.run({ goal: 'Error test' }, signal);
573 | 
574 |       expect(mockSendMessageStream).toHaveBeenCalledTimes(2);
575 | 
576 |       const expectedError =
577 |         "Missing required argument 'finalResult' for completion.";
578 | 
579 |       expect(activities).toContainEqual(
580 |         expect.objectContaining({
581 |           type: 'ERROR',
582 |           data: {
583 |             context: 'tool_call',
584 |             name: TASK_COMPLETE_TOOL_NAME,
585 |             error: expectedError,
586 |           },
587 |         }),
588 |       );
589 | 
590 |       const turn2Params = getMockMessageParams(1);
591 |       const turn2Parts = turn2Params.message;
592 |       expect(turn2Parts).toBeDefined();
593 |       expect(turn2Parts).toHaveLength(1);
594 | 
595 |       expect(turn2Parts![0]).toEqual(
596 |         expect.objectContaining({
597 |           functionResponse: expect.objectContaining({
598 |             name: TASK_COMPLETE_TOOL_NAME,
599 |             response: { error: expectedError },
600 |             id: 'call1',
601 |           }),
602 |         }),
603 |       );
604 | 
605 |       expect(output.result).toBe('Corrected result');
606 |       expect(output.terminate_reason).toBe(AgentTerminateMode.GOAL);
607 |     });
608 | 
609 |     it('should handle multiple calls to complete_task in the same turn (accept first, block rest)', async () => {
610 |       const definition = createTestDefinition([], {}, 'none');
611 |       const executor = await AgentExecutor.create(
612 |         definition,
613 |         mockConfig,
614 |         onActivity,
615 |       );
616 | 
617 |       // Turn 1: Duplicate calls
618 |       mockModelResponse([
619 |         { name: TASK_COMPLETE_TOOL_NAME, args: {}, id: 'call1' },
620 |         { name: TASK_COMPLETE_TOOL_NAME, args: {}, id: 'call2' },
621 |       ]);
622 | 
623 |       const output = await executor.run({ goal: 'Dup test' }, signal);
624 | 
625 |       expect(mockSendMessageStream).toHaveBeenCalledTimes(1);
626 |       expect(output.terminate_reason).toBe(AgentTerminateMode.GOAL);
627 | 
628 |       const completions = activities.filter(
629 |         (a) =>
630 |           a.type === 'TOOL_CALL_END' &&
631 |           a.data['name'] === TASK_COMPLETE_TOOL_NAME,
632 |       );
633 |       const errors = activities.filter(
634 |         (a) => a.type === 'ERROR' && a.data['name'] === TASK_COMPLETE_TOOL_NAME,
635 |       );
636 | 
637 |       expect(completions).toHaveLength(1);
638 |       expect(errors).toHaveLength(1);
639 |       expect(errors[0].data['error']).toContain(
640 |         'Task already marked complete in this turn',
641 |       );
642 |     });
643 | 
644 |     it('should execute parallel tool calls and then complete', async () => {
645 |       const definition = createTestDefinition([LSTool.Name]);
646 |       const executor = await AgentExecutor.create(
647 |         definition,
648 |         mockConfig,
649 |         onActivity,
650 |       );
651 | 
652 |       const call1: FunctionCall = {
653 |         name: LSTool.Name,
654 |         args: { path: '/a' },
655 |         id: 'c1',
656 |       };
[TRUNCATED]
```

src/agents/executor.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Config } from '../config/config.js';
8 | import { reportError } from '../utils/errorReporting.js';
9 | import { GeminiChat, StreamEventType } from '../core/geminiChat.js';
10 | import { Type } from '@google/genai';
11 | import type {
12 |   Content,
13 |   Part,
14 |   FunctionCall,
15 |   GenerateContentConfig,
16 |   FunctionDeclaration,
17 |   Schema,
18 | } from '@google/genai';
19 | import { executeToolCall } from '../core/nonInteractiveToolExecutor.js';
20 | import { ToolRegistry } from '../tools/tool-registry.js';
21 | import type { ToolCallRequestInfo } from '../core/turn.js';
22 | import { getDirectoryContextString } from '../utils/environmentContext.js';
23 | import { GrepTool } from '../tools/grep.js';
24 | import { RipGrepTool } from '../tools/ripGrep.js';
25 | import { LSTool } from '../tools/ls.js';
26 | import { MemoryTool } from '../tools/memoryTool.js';
27 | import { ReadFileTool } from '../tools/read-file.js';
28 | import { ReadManyFilesTool } from '../tools/read-many-files.js';
29 | import { GLOB_TOOL_NAME, WEB_SEARCH_TOOL_NAME } from '../tools/tool-names.js';
30 | import { promptIdContext } from '../utils/promptIdContext.js';
31 | import { logAgentStart, logAgentFinish } from '../telemetry/loggers.js';
32 | import { AgentStartEvent, AgentFinishEvent } from '../telemetry/types.js';
33 | import type {
34 |   AgentDefinition,
35 |   AgentInputs,
36 |   OutputObject,
37 |   SubagentActivityEvent,
38 | } from './types.js';
39 | import { AgentTerminateMode } from './types.js';
40 | import { templateString } from './utils.js';
41 | import { parseThought } from '../utils/thoughtUtils.js';
42 | import { type z } from 'zod';
43 | import { zodToJsonSchema } from 'zod-to-json-schema';
44 | 
45 | /** A callback function to report on agent activity. */
46 | export type ActivityCallback = (activity: SubagentActivityEvent) => void;
47 | 
48 | const TASK_COMPLETE_TOOL_NAME = 'complete_task';
49 | 
50 | /**
51 |  * Executes an agent loop based on an {@link AgentDefinition}.
52 |  *
53 |  * This executor runs the agent in a loop, calling tools until it calls the
54 |  * mandatory `complete_task` tool to signal completion.
55 |  */
56 | export class AgentExecutor<TOutput extends z.ZodTypeAny> {
57 |   readonly definition: AgentDefinition<TOutput>;
58 | 
59 |   private readonly agentId: string;
60 |   private readonly toolRegistry: ToolRegistry;
61 |   private readonly runtimeContext: Config;
62 |   private readonly onActivity?: ActivityCallback;
63 | 
64 |   /**
65 |    * Creates and validates a new `AgentExecutor` instance.
66 |    *
67 |    * This method ensures that all tools specified in the agent's definition are
68 |    * safe for non-interactive use before creating the executor.
69 |    *
70 |    * @param definition The definition object for the agent.
71 |    * @param runtimeContext The global runtime configuration.
72 |    * @param onActivity An optional callback to receive activity events.
73 |    * @returns A promise that resolves to a new `AgentExecutor` instance.
74 |    */
75 |   static async create<TOutput extends z.ZodTypeAny>(
76 |     definition: AgentDefinition<TOutput>,
77 |     runtimeContext: Config,
78 |     onActivity?: ActivityCallback,
79 |   ): Promise<AgentExecutor<TOutput>> {
80 |     // Create an isolated tool registry for this agent instance.
81 |     const agentToolRegistry = new ToolRegistry(runtimeContext);
82 |     const parentToolRegistry = await runtimeContext.getToolRegistry();
83 | 
84 |     if (definition.toolConfig) {
85 |       for (const toolRef of definition.toolConfig.tools) {
86 |         if (typeof toolRef === 'string') {
87 |           // If the tool is referenced by name, retrieve it from the parent
88 |           // registry and register it with the agent's isolated registry.
89 |           const toolFromParent = parentToolRegistry.getTool(toolRef);
90 |           if (toolFromParent) {
91 |             agentToolRegistry.registerTool(toolFromParent);
92 |           }
93 |         } else if (
94 |           typeof toolRef === 'object' &&
95 |           'name' in toolRef &&
96 |           'build' in toolRef
97 |         ) {
98 |           agentToolRegistry.registerTool(toolRef);
99 |         }
100 |         // Note: Raw `FunctionDeclaration` objects in the config don't need to be
101 |         // registered; their schemas are passed directly to the model later.
102 |       }
103 | 
104 |       // Validate that all registered tools are safe for non-interactive
105 |       // execution.
106 |       await AgentExecutor.validateTools(agentToolRegistry, definition.name);
107 |     }
108 | 
109 |     // Get the parent prompt ID from context
110 |     const parentPromptId = promptIdContext.getStore();
111 | 
112 |     return new AgentExecutor(
113 |       definition,
114 |       runtimeContext,
115 |       agentToolRegistry,
116 |       parentPromptId,
117 |       onActivity,
118 |     );
119 |   }
120 | 
121 |   /**
122 |    * Constructs a new AgentExecutor instance.
123 |    *
124 |    * @private This constructor is private. Use the static `create` method to
125 |    * instantiate the class.
126 |    */
127 |   private constructor(
128 |     definition: AgentDefinition<TOutput>,
129 |     runtimeContext: Config,
130 |     toolRegistry: ToolRegistry,
131 |     parentPromptId: string | undefined,
132 |     onActivity?: ActivityCallback,
133 |   ) {
134 |     this.definition = definition;
135 |     this.runtimeContext = runtimeContext;
136 |     this.toolRegistry = toolRegistry;
137 |     this.onActivity = onActivity;
138 | 
139 |     const randomIdPart = Math.random().toString(36).slice(2, 8);
140 |     // parentPromptId will be undefined if this agent is invoked directly
141 |     // (top-level), rather than as a sub-agent.
142 |     const parentPrefix = parentPromptId ? `${parentPromptId}-` : '';
143 |     this.agentId = `${parentPrefix}${this.definition.name}-${randomIdPart}`;
144 |   }
145 | 
146 |   /**
147 |    * Runs the agent.
148 |    *
149 |    * @param inputs The validated input parameters for this invocation.
150 |    * @param signal An `AbortSignal` for cancellation.
151 |    * @returns A promise that resolves to the agent's final output.
152 |    */
153 |   async run(inputs: AgentInputs, signal: AbortSignal): Promise<OutputObject> {
154 |     const startTime = Date.now();
155 |     let turnCounter = 0;
156 |     let terminateReason: AgentTerminateMode = AgentTerminateMode.ERROR;
157 |     let finalResult: string | null = null;
158 | 
159 |     logAgentStart(
160 |       this.runtimeContext,
161 |       new AgentStartEvent(this.agentId, this.definition.name),
162 |     );
163 | 
164 |     try {
165 |       const chat = await this.createChatObject(inputs);
166 |       const tools = this.prepareToolsList();
167 | 
168 |       const query = this.definition.promptConfig.query
169 |         ? templateString(this.definition.promptConfig.query, inputs)
170 |         : 'Get Started!';
171 |       let currentMessage: Content = { role: 'user', parts: [{ text: query }] };
172 | 
173 |       while (true) {
174 |         // Check for termination conditions like max turns or timeout.
175 |         const reason = this.checkTermination(startTime, turnCounter);
176 |         if (reason) {
177 |           terminateReason = reason;
178 |           break;
179 |         }
180 |         if (signal.aborted) {
181 |           terminateReason = AgentTerminateMode.ABORTED;
182 |           break;
183 |         }
184 | 
185 |         const promptId = `${this.agentId}#${turnCounter++}`;
186 | 
187 |         const { functionCalls } = await promptIdContext.run(
188 |           promptId,
189 |           async () =>
190 |             this.callModel(chat, currentMessage, tools, signal, promptId),
191 |         );
192 | 
193 |         if (signal.aborted) {
194 |           terminateReason = AgentTerminateMode.ABORTED;
195 |           break;
196 |         }
197 | 
198 |         // If the model stops calling tools without calling complete_task, it's an error.
199 |         if (functionCalls.length === 0) {
200 |           terminateReason = AgentTerminateMode.ERROR;
201 |           finalResult = `Agent stopped calling tools but did not call '${TASK_COMPLETE_TOOL_NAME}' to finalize the session.`;
202 |           this.emitActivity('ERROR', {
203 |             error: finalResult,
204 |             context: 'protocol_violation',
205 |           });
206 |           break;
207 |         }
208 | 
209 |         const { nextMessage, submittedOutput, taskCompleted } =
210 |           await this.processFunctionCalls(functionCalls, signal, promptId);
211 | 
212 |         if (taskCompleted) {
213 |           finalResult = submittedOutput ?? 'Task completed successfully.';
214 |           terminateReason = AgentTerminateMode.GOAL;
215 |           break;
216 |         }
217 | 
218 |         currentMessage = nextMessage;
219 |       }
220 | 
221 |       if (terminateReason === AgentTerminateMode.GOAL) {
222 |         return {
223 |           result: finalResult || 'Task completed.',
224 |           terminate_reason: terminateReason,
225 |         };
226 |       }
227 | 
228 |       return {
229 |         result:
230 |           finalResult || 'Agent execution was terminated before completion.',
231 |         terminate_reason: terminateReason,
232 |       };
233 |     } catch (error) {
234 |       this.emitActivity('ERROR', { error: String(error) });
235 |       throw error; // Re-throw the error for the parent context to handle.
236 |     } finally {
237 |       logAgentFinish(
238 |         this.runtimeContext,
239 |         new AgentFinishEvent(
240 |           this.agentId,
241 |           this.definition.name,
242 |           Date.now() - startTime,
243 |           turnCounter,
244 |           terminateReason,
245 |         ),
246 |       );
247 |     }
248 |   }
249 | 
250 |   /**
251 |    * Calls the generative model with the current context and tools.
252 |    *
253 |    * @returns The model's response, including any tool calls or text.
254 |    */
255 |   private async callModel(
256 |     chat: GeminiChat,
257 |     message: Content,
258 |     tools: FunctionDeclaration[],
259 |     signal: AbortSignal,
260 |     promptId: string,
261 |   ): Promise<{ functionCalls: FunctionCall[]; textResponse: string }> {
262 |     const messageParams = {
263 |       message: message.parts || [],
264 |       config: {
265 |         abortSignal: signal,
266 |         tools: tools.length > 0 ? [{ functionDeclarations: tools }] : undefined,
267 |       },
268 |     };
269 | 
270 |     const responseStream = await chat.sendMessageStream(
271 |       this.definition.modelConfig.model,
272 |       messageParams,
273 |       promptId,
274 |     );
275 | 
276 |     const functionCalls: FunctionCall[] = [];
277 |     let textResponse = '';
278 | 
279 |     for await (const resp of responseStream) {
280 |       if (signal.aborted) break;
281 | 
282 |       if (resp.type === StreamEventType.CHUNK) {
283 |         const chunk = resp.value;
284 |         const parts = chunk.candidates?.[0]?.content?.parts;
285 | 
286 |         // Extract and emit any subject "thought" content from the model.
287 |         const { subject } = parseThought(
288 |           parts?.find((p) => p.thought)?.text || '',
289 |         );
290 |         if (subject) {
291 |           this.emitActivity('THOUGHT_CHUNK', { text: subject });
292 |         }
293 | 
294 |         // Collect any function calls requested by the model.
295 |         if (chunk.functionCalls) {
296 |           functionCalls.push(...chunk.functionCalls);
297 |         }
298 | 
299 |         // Handle text response (non-thought text)
300 |         const text =
301 |           parts
302 |             ?.filter((p) => !p.thought && p.text)
303 |             .map((p) => p.text)
304 |             .join('') || '';
305 | 
306 |         if (text) {
307 |           textResponse += text;
308 |         }
309 |       }
310 |     }
311 | 
312 |     return { functionCalls, textResponse };
313 |   }
314 | 
315 |   /** Initializes a `GeminiChat` instance for the agent run. */
316 |   private async createChatObject(inputs: AgentInputs): Promise<GeminiChat> {
317 |     const { promptConfig, modelConfig } = this.definition;
318 | 
319 |     if (!promptConfig.systemPrompt && !promptConfig.initialMessages) {
320 |       throw new Error(
321 |         'PromptConfig must define either `systemPrompt` or `initialMessages`.',
322 |       );
323 |     }
324 | 
325 |     const startHistory = this.applyTemplateToInitialMessages(
326 |       promptConfig.initialMessages ?? [],
327 |       inputs,
328 |     );
329 | 
330 |     // Build system instruction from the templated prompt string.
331 |     const systemInstruction = promptConfig.systemPrompt
332 |       ? await this.buildSystemPrompt(inputs)
333 |       : undefined;
334 | 
335 |     try {
336 |       const generationConfig: GenerateContentConfig = {
337 |         temperature: modelConfig.temp,
338 |         topP: modelConfig.top_p,
339 |         thinkingConfig: {
340 |           includeThoughts: true,
341 |           thinkingBudget: modelConfig.thinkingBudget ?? -1,
342 |         },
343 |       };
344 | 
345 |       if (systemInstruction) {
346 |         generationConfig.systemInstruction = systemInstruction;
347 |       }
348 | 
349 |       return new GeminiChat(
350 |         this.runtimeContext,
351 |         generationConfig,
352 |         startHistory,
353 |       );
354 |     } catch (error) {
355 |       await reportError(
356 |         error,
357 |         `Error initializing Gemini chat for agent ${this.definition.name}.`,
358 |         startHistory,
359 |         'startChat',
360 |       );
361 |       // Re-throw as a more specific error after reporting.
362 |       throw new Error(`Failed to create chat object: ${error}`);
363 |     }
364 |   }
365 | 
366 |   /**
367 |    * Executes function calls requested by the model and returns the results.
368 |    *
369 |    * @returns A new `Content` object for history, any submitted output, and completion status.
370 |    */
371 |   private async processFunctionCalls(
372 |     functionCalls: FunctionCall[],
373 |     signal: AbortSignal,
374 |     promptId: string,
375 |   ): Promise<{
376 |     nextMessage: Content;
377 |     submittedOutput: string | null;
378 |     taskCompleted: boolean;
379 |   }> {
380 |     const allowedToolNames = new Set(this.toolRegistry.getAllToolNames());
381 |     // Always allow the completion tool
382 |     allowedToolNames.add(TASK_COMPLETE_TOOL_NAME);
383 | 
384 |     let submittedOutput: string | null = null;
385 |     let taskCompleted = false;
386 | 
387 |     // We'll collect promises for the tool executions
388 |     const toolExecutionPromises: Array<Promise<Part[] | void>> = [];
389 |     // And we'll need a place to store the synchronous results (like complete_task or blocked calls)
390 |     const syncResponseParts: Part[] = [];
391 | 
392 |     for (const [index, functionCall] of functionCalls.entries()) {
393 |       const callId = functionCall.id ?? `${promptId}-${index}`;
394 |       const args = (functionCall.args ?? {}) as Record<string, unknown>;
395 | 
396 |       this.emitActivity('TOOL_CALL_START', {
397 |         name: functionCall.name,
398 |         args,
399 |       });
400 | 
401 |       if (functionCall.name === TASK_COMPLETE_TOOL_NAME) {
402 |         if (taskCompleted) {
403 |           // We already have a completion from this turn. Ignore subsequent ones.
404 |           const error =
405 |             'Task already marked complete in this turn. Ignoring duplicate call.';
406 |           syncResponseParts.push({
407 |             functionResponse: {
408 |               name: TASK_COMPLETE_TOOL_NAME,
409 |               response: { error },
410 |               id: callId,
411 |             },
412 |           });
413 |           this.emitActivity('ERROR', {
414 |             context: 'tool_call',
415 |             name: functionCall.name,
416 |             error,
417 |           });
418 |           continue;
419 |         }
420 | 
421 |         const { outputConfig } = this.definition;
422 |         taskCompleted = true; // Signal completion regardless of output presence
423 | 
424 |         if (outputConfig) {
425 |           const outputName = outputConfig.outputName;
426 |           if (args[outputName] !== undefined) {
427 |             const outputValue = args[outputName];
428 |             const validationResult = outputConfig.schema.safeParse(outputValue);
429 | 
430 |             if (!validationResult.success) {
431 |               taskCompleted = false; // Validation failed, revoke completion
432 |               const error = `Output validation failed: ${JSON.stringify(validationResult.error.flatten())}`;
433 |               syncResponseParts.push({
434 |                 functionResponse: {
435 |                   name: TASK_COMPLETE_TOOL_NAME,
436 |                   response: { error },
437 |                   id: callId,
438 |                 },
439 |               });
440 |               this.emitActivity('ERROR', {
441 |                 context: 'tool_call',
442 |                 name: functionCall.name,
443 |                 error,
444 |               });
445 |               continue;
446 |             }
447 | 
448 |             const validatedOutput = validationResult.data;
449 |             if (this.definition.processOutput) {
450 |               submittedOutput = this.definition.processOutput(validatedOutput);
451 |             } else {
452 |               submittedOutput =
453 |                 typeof outputValue === 'string'
454 |                   ? outputValue
455 |                   : JSON.stringify(outputValue, null, 2);
456 |             }
457 |             syncResponseParts.push({
458 |               functionResponse: {
459 |                 name: TASK_COMPLETE_TOOL_NAME,
460 |                 response: { result: 'Output submitted and task completed.' },
461 |                 id: callId,
462 |               },
463 |             });
464 |             this.emitActivity('TOOL_CALL_END', {
465 |               name: functionCall.name,
466 |               output: 'Output submitted and task completed.',
467 |             });
468 |           } else {
469 |             // Failed to provide required output.
470 |             taskCompleted = false; // Revoke completion status
471 |             const error = `Missing required argument '${outputName}' for completion.`;
472 |             syncResponseParts.push({
473 |               functionResponse: {
474 |                 name: TASK_COMPLETE_TOOL_NAME,
475 |                 response: { error },
476 |                 id: callId,
477 |               },
478 |             });
479 |             this.emitActivity('ERROR', {
480 |               context: 'tool_call',
481 |               name: functionCall.name,
482 |               error,
483 |             });
484 |           }
485 |         } else {
486 |           // No output expected. Just signal completion.
487 |           submittedOutput = 'Task completed successfully.';
488 |           syncResponseParts.push({
489 |             functionResponse: {
490 |               name: TASK_COMPLETE_TOOL_NAME,
491 |               response: { status: 'Task marked complete.' },
492 |               id: callId,
493 |             },
494 |           });
495 |           this.emitActivity('TOOL_CALL_END', {
496 |             name: functionCall.name,
497 |             output: 'Task marked complete.',
498 |           });
499 |         }
500 |         continue;
501 |       }
502 | 
503 |       // Handle standard tools
504 |       if (!allowedToolNames.has(functionCall.name as string)) {
505 |         const error = `Unauthorized tool call: '${functionCall.name}' is not available to this agent.`;
506 | 
507 |         console.warn(`[AgentExecutor] Blocked call: ${error}`);
508 | 
509 |         syncResponseParts.push({
510 |           functionResponse: {
511 |             name: functionCall.name as string,
512 |             id: callId,
513 |             response: { error },
514 |           },
515 |         });
516 | 
517 |         this.emitActivity('ERROR', {
518 |           context: 'tool_call_unauthorized',
519 |           name: functionCall.name,
520 |           callId,
521 |           error,
522 |         });
523 | 
524 |         continue;
525 |       }
526 | 
527 |       const requestInfo: ToolCallRequestInfo = {
528 |         callId,
529 |         name: functionCall.name as string,
530 |         args,
531 |         isClientInitiated: true,
532 |         prompt_id: promptId,
533 |       };
534 | 
535 |       // Create a promise for the tool execution
536 |       const executionPromise = (async () => {
537 |         const toolResponse = await executeToolCall(
538 |           this.runtimeContext,
539 |           requestInfo,
540 |           signal,
541 |         );
542 | 
543 |         if (toolResponse.error) {
544 |           this.emitActivity('ERROR', {
545 |             context: 'tool_call',
546 |             name: functionCall.name,
547 |             error: toolResponse.error.message,
548 |           });
549 |         } else {
550 |           this.emitActivity('TOOL_CALL_END', {
551 |             name: functionCall.name,
552 |             output: toolResponse.resultDisplay,
553 |           });
554 |         }
555 | 
556 |         return toolResponse.responseParts;
557 |       })();
558 | 
559 |       toolExecutionPromises.push(executionPromise);
560 |     }
561 | 
562 |     // Wait for all tool executions to complete
563 |     const asyncResults = await Promise.all(toolExecutionPromises);
564 | 
565 |     // Combine all response parts
566 |     const toolResponseParts: Part[] = [...syncResponseParts];
567 |     for (const result of asyncResults) {
568 |       if (result) {
569 |         toolResponseParts.push(...result);
570 |       }
571 |     }
572 | 
573 |     // If all authorized tool calls failed (and task isn't complete), provide a generic error.
574 |     if (
575 |       functionCalls.length > 0 &&
576 |       toolResponseParts.length === 0 &&
577 |       !taskCompleted
578 |     ) {
579 |       toolResponseParts.push({
580 |         text: 'All tool calls failed or were unauthorized. Please analyze the errors and try an alternative approach.',
581 |       });
582 |     }
583 | 
584 |     return {
585 |       nextMessage: { role: 'user', parts: toolResponseParts },
586 |       submittedOutput,
587 |       taskCompleted,
588 |     };
589 |   }
590 | 
591 |   /**
592 |    * Prepares the list of tool function declarations to be sent to the model.
593 |    */
594 |   private prepareToolsList(): FunctionDeclaration[] {
595 |     const toolsList: FunctionDeclaration[] = [];
596 |     const { toolConfig, outputConfig } = this.definition;
597 | 
598 |     if (toolConfig) {
599 |       const toolNamesToLoad: string[] = [];
600 |       for (const toolRef of toolConfig.tools) {
601 |         if (typeof toolRef === 'string') {
602 |           toolNamesToLoad.push(toolRef);
603 |         } else if (typeof toolRef === 'object' && 'schema' in toolRef) {
604 |           // Tool instance with an explicit schema property.
605 |           toolsList.push(toolRef.schema as FunctionDeclaration);
606 |         } else {
607 |           // Raw `FunctionDeclaration` object.
608 |           toolsList.push(toolRef as FunctionDeclaration);
609 |         }
610 |       }
611 |       // Add schemas from tools that were registered by name.
612 |       toolsList.push(
613 |         ...this.toolRegistry.getFunctionDeclarationsFiltered(toolNamesToLoad),
614 |       );
615 |     }
616 | 
617 |     // Always inject complete_task.
618 |     // Configure its schema based on whether output is expected.
619 |     const completeTool: FunctionDeclaration = {
620 |       name: TASK_COMPLETE_TOOL_NAME,
621 |       description: outputConfig
622 |         ? 'Call this tool to submit your final answer and complete the task. This is the ONLY way to finish.'
[TRUNCATED]
```

src/agents/invocation.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, type Mocked } from 'vitest';
8 | import { SubagentInvocation } from './invocation.js';
9 | import { AgentExecutor } from './executor.js';
10 | import type {
11 |   AgentDefinition,
12 |   SubagentActivityEvent,
13 |   AgentInputs,
14 | } from './types.js';
15 | import { AgentTerminateMode } from './types.js';
16 | import { makeFakeConfig } from '../test-utils/config.js';
17 | import { ToolErrorType } from '../tools/tool-error.js';
18 | import type { Config } from '../config/config.js';
19 | import type { MessageBus } from '../confirmation-bus/message-bus.js';
20 | import { type z } from 'zod';
21 | 
22 | vi.mock('./executor.js');
23 | 
24 | const MockAgentExecutor = vi.mocked(AgentExecutor);
25 | 
26 | let mockConfig: Config;
27 | 
28 | const testDefinition: AgentDefinition<z.ZodUnknown> = {
29 |   name: 'MockAgent',
30 |   description: 'A mock agent.',
31 |   inputConfig: {
32 |     inputs: {
33 |       task: { type: 'string', required: true, description: 'task' },
34 |       priority: { type: 'number', required: false, description: 'prio' },
35 |     },
36 |   },
37 |   modelConfig: { model: 'test', temp: 0, top_p: 1 },
38 |   runConfig: { max_time_minutes: 1 },
39 |   promptConfig: { systemPrompt: 'test' },
40 | };
41 | 
42 | describe('SubagentInvocation', () => {
43 |   let mockExecutorInstance: Mocked<AgentExecutor<z.ZodUnknown>>;
44 | 
45 |   beforeEach(() => {
46 |     vi.clearAllMocks();
47 |     mockConfig = makeFakeConfig();
48 | 
49 |     mockExecutorInstance = {
50 |       run: vi.fn(),
51 |       definition: testDefinition,
52 |     } as unknown as Mocked<AgentExecutor<z.ZodUnknown>>;
53 | 
54 |     MockAgentExecutor.create.mockResolvedValue(
55 |       mockExecutorInstance as unknown as AgentExecutor<z.ZodTypeAny>,
56 |     );
57 |   });
58 | 
59 |   it('should pass the messageBus to the parent constructor', () => {
60 |     const mockMessageBus = {} as MessageBus;
61 |     const params = { task: 'Analyze data' };
62 |     const invocation = new SubagentInvocation<z.ZodUnknown>(
63 |       params,
64 |       testDefinition,
65 |       mockConfig,
66 |       mockMessageBus,
67 |     );
68 | 
69 |     // Access the protected messageBus property by casting to any
70 |     // eslint-disable-next-line @typescript-eslint/no-explicit-any
71 |     expect((invocation as any).messageBus).toBe(mockMessageBus);
72 |   });
73 | 
74 |   describe('getDescription', () => {
75 |     it('should format the description with inputs', () => {
76 |       const params = { task: 'Analyze data', priority: 5 };
77 |       const invocation = new SubagentInvocation<z.ZodUnknown>(
78 |         params,
79 |         testDefinition,
80 |         mockConfig,
81 |       );
82 |       const description = invocation.getDescription();
83 |       expect(description).toBe(
84 |         "Running subagent 'MockAgent' with inputs: { task: Analyze data, priority: 5 }",
85 |       );
86 |     });
87 | 
88 |     it('should truncate long input values', () => {
89 |       const longTask = 'A'.repeat(100);
90 |       const params = { task: longTask };
91 |       const invocation = new SubagentInvocation<z.ZodUnknown>(
92 |         params,
93 |         testDefinition,
94 |         mockConfig,
95 |       );
96 |       const description = invocation.getDescription();
97 |       // Default INPUT_PREVIEW_MAX_LENGTH is 50
98 |       expect(description).toBe(
99 |         `Running subagent 'MockAgent' with inputs: { task: ${'A'.repeat(50)} }`,
100 |       );
101 |     });
102 | 
103 |     it('should truncate the overall description if it exceeds the limit', () => {
104 |       // Create a definition and inputs that result in a very long description
105 |       const longNameDef = {
106 |         ...testDefinition,
107 |         name: 'VeryLongAgentNameThatTakesUpSpace',
108 |       };
109 |       const params: AgentInputs = {};
110 |       for (let i = 0; i < 20; i++) {
111 |         params[`input${i}`] = `value${i}`;
112 |       }
113 |       const invocation = new SubagentInvocation<z.ZodUnknown>(
114 |         params,
115 |         longNameDef,
116 |         mockConfig,
117 |       );
118 |       const description = invocation.getDescription();
119 |       // Default DESCRIPTION_MAX_LENGTH is 200
120 |       expect(description.length).toBe(200);
121 |       expect(
122 |         description.startsWith(
123 |           "Running subagent 'VeryLongAgentNameThatTakesUpSpace'",
124 |         ),
125 |       ).toBe(true);
126 |     });
127 |   });
128 | 
129 |   describe('execute', () => {
130 |     let signal: AbortSignal;
131 |     let updateOutput: ReturnType<typeof vi.fn>;
132 |     const params = { task: 'Execute task' };
133 |     let invocation: SubagentInvocation<z.ZodUnknown>;
134 | 
135 |     beforeEach(() => {
136 |       signal = new AbortController().signal;
137 |       updateOutput = vi.fn();
138 |       invocation = new SubagentInvocation<z.ZodUnknown>(
139 |         params,
140 |         testDefinition,
141 |         mockConfig,
142 |       );
143 |     });
144 | 
145 |     it('should initialize and run the executor successfully', async () => {
146 |       const mockOutput = {
147 |         result: 'Analysis complete.',
148 |         terminate_reason: AgentTerminateMode.GOAL,
149 |       };
150 |       mockExecutorInstance.run.mockResolvedValue(mockOutput);
151 | 
152 |       const result = await invocation.execute(signal, updateOutput);
153 | 
154 |       expect(MockAgentExecutor.create).toHaveBeenCalledWith(
155 |         testDefinition,
156 |         mockConfig,
157 |         expect.any(Function),
158 |       );
159 |       expect(updateOutput).toHaveBeenCalledWith('Subagent starting...\n');
160 | 
161 |       expect(mockExecutorInstance.run).toHaveBeenCalledWith(params, signal);
162 | 
163 |       expect(result.llmContent).toEqual([
164 |         {
165 |           text: expect.stringContaining(
166 |             "Subagent 'MockAgent' finished.\nTermination Reason: GOAL\nResult:\nAnalysis complete.",
167 |           ),
168 |         },
169 |       ]);
170 |       expect(result.returnDisplay).toContain('Result:\nAnalysis complete.');
171 |       expect(result.returnDisplay).toContain('Termination Reason:\n GOAL');
172 |     });
173 | 
174 |     it('should stream THOUGHT_CHUNK activities from the executor', async () => {
175 |       mockExecutorInstance.run.mockImplementation(async () => {
176 |         const onActivity = MockAgentExecutor.create.mock.calls[0][2];
177 | 
178 |         if (onActivity) {
179 |           onActivity({
180 |             isSubagentActivityEvent: true,
181 |             agentName: 'MockAgent',
182 |             type: 'THOUGHT_CHUNK',
183 |             data: { text: 'Analyzing...' },
184 |           } as SubagentActivityEvent);
185 |           onActivity({
186 |             isSubagentActivityEvent: true,
187 |             agentName: 'MockAgent',
188 |             type: 'THOUGHT_CHUNK',
189 |             data: { text: ' Still thinking.' },
190 |           } as SubagentActivityEvent);
191 |         }
192 |         return { result: 'Done', terminate_reason: AgentTerminateMode.GOAL };
193 |       });
194 | 
195 |       await invocation.execute(signal, updateOutput);
196 | 
197 |       expect(updateOutput).toHaveBeenCalledWith('Subagent starting...\n');
198 |       expect(updateOutput).toHaveBeenCalledWith('🤖💭 Analyzing...');
199 |       expect(updateOutput).toHaveBeenCalledWith('🤖💭  Still thinking.');
200 |       expect(updateOutput).toHaveBeenCalledTimes(3); // Initial message + 2 thoughts
201 |     });
202 | 
203 |     it('should NOT stream other activities (e.g., TOOL_CALL_START, ERROR)', async () => {
204 |       mockExecutorInstance.run.mockImplementation(async () => {
205 |         const onActivity = MockAgentExecutor.create.mock.calls[0][2];
206 | 
207 |         if (onActivity) {
208 |           onActivity({
209 |             isSubagentActivityEvent: true,
210 |             agentName: 'MockAgent',
211 |             type: 'TOOL_CALL_START',
212 |             data: { name: 'ls' },
213 |           } as SubagentActivityEvent);
214 |           onActivity({
215 |             isSubagentActivityEvent: true,
216 |             agentName: 'MockAgent',
217 |             type: 'ERROR',
218 |             data: { error: 'Failed' },
219 |           } as SubagentActivityEvent);
220 |         }
221 |         return { result: 'Done', terminate_reason: AgentTerminateMode.GOAL };
222 |       });
223 | 
224 |       await invocation.execute(signal, updateOutput);
225 | 
226 |       // Should only contain the initial "Subagent starting..." message
227 |       expect(updateOutput).toHaveBeenCalledTimes(1);
228 |       expect(updateOutput).toHaveBeenCalledWith('Subagent starting...\n');
229 |     });
230 | 
231 |     it('should run successfully without an updateOutput callback', async () => {
232 |       mockExecutorInstance.run.mockImplementation(async () => {
233 |         const onActivity = MockAgentExecutor.create.mock.calls[0][2];
234 |         if (onActivity) {
235 |           // Ensure calling activity doesn't crash when updateOutput is undefined
236 |           onActivity({
237 |             isSubagentActivityEvent: true,
238 |             agentName: 'testAgent',
239 |             type: 'THOUGHT_CHUNK',
240 |             data: { text: 'Thinking silently.' },
241 |           } as SubagentActivityEvent);
242 |         }
243 |         return { result: 'Done', terminate_reason: AgentTerminateMode.GOAL };
244 |       });
245 | 
246 |       // Execute without the optional callback
247 |       const result = await invocation.execute(signal);
248 |       expect(result.error).toBeUndefined();
249 |       expect(result.returnDisplay).toContain('Result:\nDone');
250 |     });
251 | 
252 |     it('should handle executor run failure', async () => {
253 |       const error = new Error('Model failed during execution.');
254 |       mockExecutorInstance.run.mockRejectedValue(error);
255 | 
256 |       const result = await invocation.execute(signal, updateOutput);
257 | 
258 |       expect(result.error).toEqual({
259 |         message: error.message,
260 |         type: ToolErrorType.EXECUTION_FAILED,
261 |       });
262 |       expect(result.returnDisplay).toBe(
263 |         `Subagent Failed: MockAgent\nError: ${error.message}`,
264 |       );
265 |       expect(result.llmContent).toBe(
266 |         `Subagent 'MockAgent' failed. Error: ${error.message}`,
267 |       );
268 |     });
269 | 
270 |     it('should handle executor creation failure', async () => {
271 |       const creationError = new Error('Failed to initialize tools.');
272 |       MockAgentExecutor.create.mockRejectedValue(creationError);
273 | 
274 |       const result = await invocation.execute(signal, updateOutput);
275 | 
276 |       expect(mockExecutorInstance.run).not.toHaveBeenCalled();
277 |       expect(result.error).toEqual({
278 |         message: creationError.message,
279 |         type: ToolErrorType.EXECUTION_FAILED,
280 |       });
281 |       expect(result.returnDisplay).toContain(`Error: ${creationError.message}`);
282 |     });
283 | 
284 |     /**
285 |      * This test verifies that the AbortSignal is correctly propagated and
286 |      * that a rejection from the executor due to abortion is handled gracefully.
287 |      */
288 |     it('should handle abortion signal during execution', async () => {
289 |       const abortError = new Error('Aborted');
290 |       mockExecutorInstance.run.mockRejectedValue(abortError);
291 | 
292 |       const controller = new AbortController();
293 |       const executePromise = invocation.execute(
294 |         controller.signal,
295 |         updateOutput,
296 |       );
297 |       controller.abort();
298 |       const result = await executePromise;
299 | 
300 |       expect(mockExecutorInstance.run).toHaveBeenCalledWith(
301 |         params,
302 |         controller.signal,
303 |       );
304 |       expect(result.error?.message).toBe('Aborted');
305 |       expect(result.error?.type).toBe(ToolErrorType.EXECUTION_FAILED);
306 |     });
307 |   });
308 | });
```

src/agents/invocation.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Config } from '../config/config.js';
8 | import { AgentExecutor } from './executor.js';
9 | import type { AnsiOutput } from '../utils/terminalSerializer.js';
10 | import { BaseToolInvocation, type ToolResult } from '../tools/tools.js';
11 | import { ToolErrorType } from '../tools/tool-error.js';
12 | import type {
13 |   AgentDefinition,
14 |   AgentInputs,
15 |   SubagentActivityEvent,
16 | } from './types.js';
17 | import type { MessageBus } from '../confirmation-bus/message-bus.js';
18 | import { type z } from 'zod';
19 | 
20 | const INPUT_PREVIEW_MAX_LENGTH = 50;
21 | const DESCRIPTION_MAX_LENGTH = 200;
22 | 
23 | /**
24 |  * Represents a validated, executable instance of a subagent tool.
25 |  *
26 |  * This class orchestrates the execution of a defined agent by:
27 |  * 1. Initializing the {@link AgentExecutor}.
28 |  * 2. Running the agent's execution loop.
29 |  * 3. Bridging the agent's streaming activity (e.g., thoughts) to the tool's
30 |  * live output stream.
31 |  * 4. Formatting the final result into a {@link ToolResult}.
32 |  */
33 | export class SubagentInvocation<
34 |   TOutput extends z.ZodTypeAny,
35 | > extends BaseToolInvocation<AgentInputs, ToolResult> {
36 |   /**
37 |    * @param params The validated input parameters for the agent.
38 |    * @param definition The definition object that configures the agent.
39 |    * @param config The global runtime configuration.
40 |    * @param messageBus Optional message bus for policy enforcement.
41 |    */
42 |   constructor(
43 |     params: AgentInputs,
44 |     private readonly definition: AgentDefinition<TOutput>,
45 |     private readonly config: Config,
46 |     messageBus?: MessageBus,
47 |   ) {
48 |     super(params, messageBus);
49 |   }
50 | 
51 |   /**
52 |    * Returns a concise, human-readable description of the invocation.
53 |    * Used for logging and display purposes.
54 |    */
55 |   getDescription(): string {
56 |     const inputSummary = Object.entries(this.params)
57 |       .map(
58 |         ([key, value]) =>
59 |           `${key}: ${String(value).slice(0, INPUT_PREVIEW_MAX_LENGTH)}`,
60 |       )
61 |       .join(', ');
62 | 
63 |     const description = `Running subagent '${this.definition.name}' with inputs: { ${inputSummary} }`;
64 |     return description.slice(0, DESCRIPTION_MAX_LENGTH);
65 |   }
66 | 
67 |   /**
68 |    * Executes the subagent.
69 |    *
70 |    * @param signal An `AbortSignal` to cancel the agent's execution.
71 |    * @param updateOutput A callback to stream intermediate output, such as the
72 |    * agent's thoughts, to the user interface.
73 |    * @returns A `Promise` that resolves with the final `ToolResult`.
74 |    */
75 |   async execute(
76 |     signal: AbortSignal,
77 |     updateOutput?: (output: string | AnsiOutput) => void,
78 |   ): Promise<ToolResult> {
79 |     try {
80 |       if (updateOutput) {
81 |         updateOutput('Subagent starting...\n');
82 |       }
83 | 
84 |       // Create an activity callback to bridge the executor's events to the
85 |       // tool's streaming output.
86 |       const onActivity = (activity: SubagentActivityEvent): void => {
87 |         if (!updateOutput) return;
88 | 
89 |         if (
90 |           activity.type === 'THOUGHT_CHUNK' &&
91 |           typeof activity.data['text'] === 'string'
92 |         ) {
93 |           updateOutput(`🤖💭 ${activity.data['text']}`);
94 |         }
95 |       };
96 | 
97 |       const executor = await AgentExecutor.create(
98 |         this.definition,
99 |         this.config,
100 |         onActivity,
101 |       );
102 | 
103 |       const output = await executor.run(this.params, signal);
104 | 
105 |       const resultContent = `Subagent '${this.definition.name}' finished.
106 | Termination Reason: ${output.terminate_reason}
107 | Result:
108 | ${output.result}`;
109 | 
110 |       const displayContent = `
111 | Subagent ${this.definition.name} Finished
112 | 
113 | Termination Reason:\n ${output.terminate_reason}
114 | 
115 | Result:
116 | ${output.result}
117 | `;
118 | 
119 |       return {
120 |         llmContent: [{ text: resultContent }],
121 |         returnDisplay: displayContent,
122 |       };
123 |     } catch (error) {
124 |       const errorMessage =
125 |         error instanceof Error ? error.message : String(error);
126 | 
127 |       return {
128 |         llmContent: `Subagent '${this.definition.name}' failed. Error: ${errorMessage}`,
129 |         returnDisplay: `Subagent Failed: ${this.definition.name}\nError: ${errorMessage}`,
130 |         error: {
131 |           message: errorMessage,
132 |           type: ToolErrorType.EXECUTION_FAILED,
133 |         },
134 |       };
135 |     }
136 |   }
137 | }
```

src/agents/registry.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import { AgentRegistry } from './registry.js';
9 | import { makeFakeConfig } from '../test-utils/config.js';
10 | import type { AgentDefinition } from './types.js';
11 | import type { Config } from '../config/config.js';
12 | 
13 | // A test-only subclass to expose the protected `registerAgent` method.
14 | class TestableAgentRegistry extends AgentRegistry {
15 |   testRegisterAgent(definition: AgentDefinition): void {
16 |     this.registerAgent(definition);
17 |   }
18 | }
19 | 
20 | // Define mock agent structures for testing registration logic
21 | const MOCK_AGENT_V1: AgentDefinition = {
22 |   name: 'MockAgent',
23 |   description: 'Mock Description V1',
24 |   inputConfig: { inputs: {} },
25 |   modelConfig: { model: 'test', temp: 0, top_p: 1 },
26 |   runConfig: { max_time_minutes: 1 },
27 |   promptConfig: { systemPrompt: 'test' },
28 | };
29 | 
30 | const MOCK_AGENT_V2: AgentDefinition = {
31 |   ...MOCK_AGENT_V1,
32 |   description: 'Mock Description V2 (Updated)',
33 | };
34 | 
35 | describe('AgentRegistry', () => {
36 |   let mockConfig: Config;
37 |   let registry: TestableAgentRegistry;
38 | 
39 |   beforeEach(() => {
40 |     // Default configuration (debugMode: false)
41 |     mockConfig = makeFakeConfig();
42 |     registry = new TestableAgentRegistry(mockConfig);
43 |   });
44 | 
45 |   afterEach(() => {
46 |     vi.restoreAllMocks(); // Restore spies after each test
47 |   });
48 | 
49 |   describe('initialize', () => {
50 |     // TODO: Add this test once we actually have a built-in agent configured.
51 |     // it('should load built-in agents upon initialization', async () => {
52 |     //   expect(registry.getAllDefinitions()).toHaveLength(0);
53 | 
54 |     //   await registry.initialize();
55 | 
56 |     //   // There are currently no built-in agents.
57 |     //   expect(registry.getAllDefinitions()).toEqual([]);
58 |     // });
59 | 
60 |     it('should log the count of loaded agents in debug mode', async () => {
61 |       const debugConfig = makeFakeConfig({ debugMode: true });
62 |       const debugRegistry = new TestableAgentRegistry(debugConfig);
63 |       const consoleLogSpy = vi
64 |         .spyOn(console, 'log')
65 |         .mockImplementation(() => {});
66 | 
67 |       await debugRegistry.initialize();
68 | 
69 |       const agentCount = debugRegistry.getAllDefinitions().length;
70 |       expect(consoleLogSpy).toHaveBeenCalledWith(
71 |         `[AgentRegistry] Initialized with ${agentCount} agents.`,
72 |       );
73 |     });
74 |   });
75 | 
76 |   describe('registration logic', () => {
77 |     it('should register a valid agent definition', () => {
78 |       registry.testRegisterAgent(MOCK_AGENT_V1);
79 |       expect(registry.getDefinition('MockAgent')).toEqual(MOCK_AGENT_V1);
80 |     });
81 | 
82 |     it('should handle special characters in agent names', () => {
83 |       const specialAgent = {
84 |         ...MOCK_AGENT_V1,
85 |         name: 'Agent-123_$pecial.v2',
86 |       };
87 |       registry.testRegisterAgent(specialAgent);
88 |       expect(registry.getDefinition('Agent-123_$pecial.v2')).toEqual(
89 |         specialAgent,
90 |       );
91 |     });
92 | 
93 |     it('should reject an agent definition missing a name', () => {
94 |       const invalidAgent = { ...MOCK_AGENT_V1, name: '' };
95 |       const consoleWarnSpy = vi
96 |         .spyOn(console, 'warn')
97 |         .mockImplementation(() => {});
98 | 
99 |       registry.testRegisterAgent(invalidAgent);
100 | 
101 |       expect(registry.getDefinition('MockAgent')).toBeUndefined();
102 |       expect(consoleWarnSpy).toHaveBeenCalledWith(
103 |         '[AgentRegistry] Skipping invalid agent definition. Missing name or description.',
104 |       );
105 |     });
106 | 
107 |     it('should reject an agent definition missing a description', () => {
108 |       const invalidAgent = { ...MOCK_AGENT_V1, description: '' };
109 |       const consoleWarnSpy = vi
110 |         .spyOn(console, 'warn')
111 |         .mockImplementation(() => {});
112 | 
113 |       registry.testRegisterAgent(invalidAgent as AgentDefinition);
114 | 
115 |       expect(registry.getDefinition('MockAgent')).toBeUndefined();
116 |       expect(consoleWarnSpy).toHaveBeenCalledWith(
117 |         '[AgentRegistry] Skipping invalid agent definition. Missing name or description.',
118 |       );
119 |     });
120 | 
121 |     it('should overwrite an existing agent definition', () => {
122 |       registry.testRegisterAgent(MOCK_AGENT_V1);
123 |       expect(registry.getDefinition('MockAgent')?.description).toBe(
124 |         'Mock Description V1',
125 |       );
126 | 
127 |       registry.testRegisterAgent(MOCK_AGENT_V2);
128 |       expect(registry.getDefinition('MockAgent')?.description).toBe(
129 |         'Mock Description V2 (Updated)',
130 |       );
131 |       expect(registry.getAllDefinitions()).toHaveLength(1);
132 |     });
133 | 
134 |     it('should log overwrites when in debug mode', () => {
135 |       const debugConfig = makeFakeConfig({ debugMode: true });
136 |       const debugRegistry = new TestableAgentRegistry(debugConfig);
137 |       const consoleLogSpy = vi
138 |         .spyOn(console, 'log')
139 |         .mockImplementation(() => {});
140 | 
141 |       debugRegistry.testRegisterAgent(MOCK_AGENT_V1);
142 |       debugRegistry.testRegisterAgent(MOCK_AGENT_V2);
143 | 
144 |       expect(consoleLogSpy).toHaveBeenCalledWith(
145 |         `[AgentRegistry] Overriding agent 'MockAgent'`,
146 |       );
147 |     });
148 | 
149 |     it('should not log overwrites when not in debug mode', () => {
150 |       const consoleLogSpy = vi
151 |         .spyOn(console, 'log')
152 |         .mockImplementation(() => {});
153 | 
154 |       registry.testRegisterAgent(MOCK_AGENT_V1);
155 |       registry.testRegisterAgent(MOCK_AGENT_V2);
156 | 
157 |       expect(consoleLogSpy).not.toHaveBeenCalledWith(
158 |         `[AgentRegistry] Overriding agent 'MockAgent'`,
159 |       );
160 |     });
161 | 
162 |     it('should handle bulk registrations correctly', async () => {
163 |       const promises = Array.from({ length: 100 }, (_, i) =>
164 |         Promise.resolve(
165 |           registry.testRegisterAgent({
166 |             ...MOCK_AGENT_V1,
167 |             name: `Agent${i}`,
168 |           }),
169 |         ),
170 |       );
171 | 
172 |       await Promise.all(promises);
173 |       expect(registry.getAllDefinitions()).toHaveLength(100);
174 |     });
175 |   });
176 | 
177 |   describe('accessors', () => {
178 |     const ANOTHER_AGENT: AgentDefinition = {
179 |       ...MOCK_AGENT_V1,
180 |       name: 'AnotherAgent',
181 |     };
182 | 
183 |     beforeEach(() => {
184 |       registry.testRegisterAgent(MOCK_AGENT_V1);
185 |       registry.testRegisterAgent(ANOTHER_AGENT);
186 |     });
187 | 
188 |     it('getDefinition should return the correct definition', () => {
189 |       expect(registry.getDefinition('MockAgent')).toEqual(MOCK_AGENT_V1);
190 |       expect(registry.getDefinition('AnotherAgent')).toEqual(ANOTHER_AGENT);
191 |     });
192 | 
193 |     it('getDefinition should return undefined for unknown agents', () => {
194 |       expect(registry.getDefinition('NonExistentAgent')).toBeUndefined();
195 |     });
196 | 
197 |     it('getAllDefinitions should return all registered definitions', () => {
198 |       const all = registry.getAllDefinitions();
199 |       expect(all).toHaveLength(2);
200 |       expect(all).toEqual(
201 |         expect.arrayContaining([MOCK_AGENT_V1, ANOTHER_AGENT]),
202 |       );
203 |     });
204 |   });
205 | });
```

src/agents/registry.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Config } from '../config/config.js';
8 | import type { AgentDefinition } from './types.js';
9 | import { CodebaseInvestigatorAgent } from './codebase-investigator.js';
10 | import { type z } from 'zod';
11 | 
12 | /**
13 |  * Manages the discovery, loading, validation, and registration of
14 |  * AgentDefinitions.
15 |  */
16 | export class AgentRegistry {
17 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
18 |   private readonly agents = new Map<string, AgentDefinition<any>>();
19 | 
20 |   constructor(private readonly config: Config) {}
21 | 
22 |   /**
23 |    * Discovers and loads agents.
24 |    */
25 |   async initialize(): Promise<void> {
26 |     this.loadBuiltInAgents();
27 | 
28 |     if (this.config.getDebugMode()) {
29 |       console.log(
30 |         `[AgentRegistry] Initialized with ${this.agents.size} agents.`,
31 |       );
32 |     }
33 |   }
34 | 
35 |   private loadBuiltInAgents(): void {
36 |     this.registerAgent(CodebaseInvestigatorAgent);
37 |   }
38 | 
39 |   /**
40 |    * Registers an agent definition. If an agent with the same name exists,
41 |    * it will be overwritten, respecting the precedence established by the
42 |    * initialization order.
43 |    */
44 |   protected registerAgent<TOutput extends z.ZodTypeAny>(
45 |     definition: AgentDefinition<TOutput>,
46 |   ): void {
47 |     // Basic validation
48 |     if (!definition.name || !definition.description) {
49 |       console.warn(
50 |         `[AgentRegistry] Skipping invalid agent definition. Missing name or description.`,
51 |       );
52 |       return;
53 |     }
54 | 
55 |     if (this.agents.has(definition.name) && this.config.getDebugMode()) {
56 |       console.log(`[AgentRegistry] Overriding agent '${definition.name}'`);
57 |     }
58 | 
59 |     this.agents.set(definition.name, definition);
60 |   }
61 | 
62 |   /**
63 |    * Retrieves an agent definition by name.
64 |    */
65 |   getDefinition(name: string): AgentDefinition | undefined {
66 |     return this.agents.get(name);
67 |   }
68 | 
69 |   /**
70 |    * Returns all active agent definitions.
71 |    */
72 |   getAllDefinitions(): AgentDefinition[] {
73 |     return Array.from(this.agents.values());
74 |   }
75 | }
```

src/agents/schema-utils.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { convertInputConfigToJsonSchema } from './schema-utils.js';
9 | import type { InputConfig } from './types.js';
10 | 
11 | const PRIMITIVE_TYPES_CONFIG: InputConfig = {
12 |   inputs: {
13 |     goal: {
14 |       type: 'string',
15 |       description: 'The primary objective',
16 |       required: true,
17 |     },
18 |     max_retries: {
19 |       type: 'integer',
20 |       description: 'Maximum number of retries',
21 |       required: false,
22 |     },
23 |     temperature: {
24 |       type: 'number',
25 |       description: 'The model temperature',
26 |       required: true,
27 |     },
28 |     verbose: {
29 |       type: 'boolean',
30 |       description: 'Enable verbose logging',
31 |       required: false,
32 |     },
33 |   },
34 | };
35 | 
36 | const ARRAY_TYPES_CONFIG: InputConfig = {
37 |   inputs: {
38 |     filenames: {
39 |       type: 'string[]',
40 |       description: 'A list of file paths',
41 |       required: true,
42 |     },
43 |     scores: {
44 |       type: 'number[]',
45 |       description: 'A list of scores',
46 |       required: false,
47 |     },
48 |   },
49 | };
50 | 
51 | const NO_REQUIRED_FIELDS_CONFIG: InputConfig = {
52 |   inputs: {
53 |     optional_param: {
54 |       type: 'string',
55 |       description: 'An optional parameter',
56 |       required: false,
57 |     },
58 |   },
59 | };
60 | 
61 | const ALL_REQUIRED_FIELDS_CONFIG: InputConfig = {
62 |   inputs: {
63 |     paramA: { type: 'string', description: 'Parameter A', required: true },
64 |     paramB: { type: 'boolean', description: 'Parameter B', required: true },
65 |   },
66 | };
67 | 
68 | const EMPTY_CONFIG: InputConfig = {
69 |   inputs: {},
70 | };
71 | 
72 | const UNSUPPORTED_TYPE_CONFIG: InputConfig = {
73 |   inputs: {
74 |     invalid_param: {
75 |       // @ts-expect-error - Intentionally testing an invalid type
76 |       type: 'date',
77 |       description: 'This type is not supported',
78 |       required: true,
79 |     },
80 |   },
81 | };
82 | 
83 | describe('convertInputConfigToJsonSchema', () => {
84 |   describe('type conversion', () => {
85 |     it('should correctly convert an InputConfig with various primitive types', () => {
86 |       const result = convertInputConfigToJsonSchema(PRIMITIVE_TYPES_CONFIG);
87 | 
88 |       expect(result).toEqual({
89 |         type: 'object',
90 |         properties: {
91 |           goal: { type: 'string', description: 'The primary objective' },
92 |           max_retries: {
93 |             type: 'integer',
94 |             description: 'Maximum number of retries',
95 |           },
96 |           temperature: { type: 'number', description: 'The model temperature' },
97 |           verbose: { type: 'boolean', description: 'Enable verbose logging' },
98 |         },
99 |         required: ['goal', 'temperature'],
100 |       });
101 |     });
102 | 
103 |     it('should correctly handle array types for strings and numbers', () => {
104 |       const result = convertInputConfigToJsonSchema(ARRAY_TYPES_CONFIG);
105 | 
106 |       expect(result).toEqual({
107 |         type: 'object',
108 |         properties: {
109 |           filenames: {
110 |             type: 'array',
111 |             description: 'A list of file paths',
112 |             items: { type: 'string' },
113 |           },
114 |           scores: {
115 |             type: 'array',
116 |             description: 'A list of scores',
117 |             items: { type: 'number' },
118 |           },
119 |         },
120 |         required: ['filenames'],
121 |       });
122 |     });
123 |   });
124 | 
125 |   describe('required field handling', () => {
126 |     it('should produce an undefined `required` field when no inputs are required', () => {
127 |       const result = convertInputConfigToJsonSchema(NO_REQUIRED_FIELDS_CONFIG);
128 | 
129 |       expect(result.properties['optional_param']).toBeDefined();
130 |       // Per the implementation and JSON Schema spec, the `required` field
131 |       // should be omitted if no properties are required.
132 |       expect(result.required).toBeUndefined();
133 |     });
134 | 
135 |     it('should list all properties in `required` when all are marked as required', () => {
136 |       const result = convertInputConfigToJsonSchema(ALL_REQUIRED_FIELDS_CONFIG);
137 |       expect(result.required).toHaveLength(2);
138 |       expect(result.required).toEqual(
139 |         expect.arrayContaining(['paramA', 'paramB']),
140 |       );
141 |     });
142 |   });
143 | 
144 |   describe('edge cases', () => {
145 |     it('should return a valid, empty schema for an empty input config', () => {
146 |       const result = convertInputConfigToJsonSchema(EMPTY_CONFIG);
147 | 
148 |       expect(result).toEqual({
149 |         type: 'object',
150 |         properties: {},
151 |         required: undefined,
152 |       });
153 |     });
154 |   });
155 | 
156 |   describe('error handling', () => {
157 |     it('should throw an informative error for an unsupported input type', () => {
158 |       const action = () =>
159 |         convertInputConfigToJsonSchema(UNSUPPORTED_TYPE_CONFIG);
160 | 
161 |       expect(action).toThrow(/Unsupported input type 'date'/);
162 |       expect(action).toThrow(/parameter 'invalid_param'/);
163 |     });
164 |   });
165 | });
```

src/agents/schema-utils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { InputConfig } from './types.js';
8 | 
9 | /**
10 |  * Defines the structure for a JSON Schema object, used for tool function
11 |  * declarations.
12 |  */
13 | interface JsonSchemaObject {
14 |   type: 'object';
15 |   properties: Record<string, JsonSchemaProperty>;
16 |   required?: string[];
17 | }
18 | 
19 | /**
20 |  * Defines the structure for a property within a {@link JsonSchemaObject}.
21 |  */
22 | interface JsonSchemaProperty {
23 |   type: 'string' | 'number' | 'integer' | 'boolean' | 'array';
24 |   description: string;
25 |   items?: { type: 'string' | 'number' };
26 | }
27 | 
28 | /**
29 |  * Converts an internal `InputConfig` definition into a standard JSON Schema
30 |  * object suitable for a tool's `FunctionDeclaration`.
31 |  *
32 |  * This utility ensures that the configuration for a subagent's inputs is
33 |  * correctly translated into the format expected by the generative model.
34 |  *
35 |  * @param inputConfig The internal `InputConfig` to convert.
36 |  * @returns A JSON Schema object representing the inputs.
37 |  * @throws An `Error` if an unsupported input type is encountered, ensuring
38 |  * configuration errors are caught early.
39 |  */
40 | export function convertInputConfigToJsonSchema(
41 |   inputConfig: InputConfig,
42 | ): JsonSchemaObject {
43 |   const properties: Record<string, JsonSchemaProperty> = {};
44 |   const required: string[] = [];
45 | 
46 |   for (const [name, definition] of Object.entries(inputConfig.inputs)) {
47 |     const schemaProperty: Partial<JsonSchemaProperty> = {
48 |       description: definition.description,
49 |     };
50 | 
51 |     switch (definition.type) {
52 |       case 'string':
53 |       case 'number':
54 |       case 'integer':
55 |       case 'boolean':
56 |         schemaProperty.type = definition.type;
57 |         break;
58 | 
59 |       case 'string[]':
60 |         schemaProperty.type = 'array';
61 |         schemaProperty.items = { type: 'string' };
62 |         break;
63 | 
64 |       case 'number[]':
65 |         schemaProperty.type = 'array';
66 |         schemaProperty.items = { type: 'number' };
67 |         break;
68 | 
69 |       default: {
70 |         const exhaustiveCheck: never = definition.type;
71 |         throw new Error(
72 |           `Unsupported input type '${exhaustiveCheck}' for parameter '${name}'. ` +
73 |             'Supported types: string, number, integer, boolean, string[], number[]',
74 |         );
75 |       }
76 |     }
77 | 
78 |     properties[name] = schemaProperty as JsonSchemaProperty;
79 | 
80 |     if (definition.required) {
81 |       required.push(name);
82 |     }
83 |   }
84 | 
85 |   return {
86 |     type: 'object',
87 |     properties,
88 |     required: required.length > 0 ? required : undefined,
89 |   };
90 | }
```

src/agents/subagent-tool-wrapper.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach } from 'vitest';
8 | import { SubagentToolWrapper } from './subagent-tool-wrapper.js';
9 | import { SubagentInvocation } from './invocation.js';
10 | import { convertInputConfigToJsonSchema } from './schema-utils.js';
11 | import { makeFakeConfig } from '../test-utils/config.js';
12 | import type { AgentDefinition, AgentInputs } from './types.js';
13 | import type { Config } from '../config/config.js';
14 | import { Kind } from '../tools/tools.js';
15 | import type { MessageBus } from '../confirmation-bus/message-bus.js';
16 | 
17 | // Mock dependencies to isolate the SubagentToolWrapper class
18 | vi.mock('./invocation.js');
19 | vi.mock('./schema-utils.js');
20 | 
21 | const MockedSubagentInvocation = vi.mocked(SubagentInvocation);
22 | const mockConvertInputConfigToJsonSchema = vi.mocked(
23 |   convertInputConfigToJsonSchema,
24 | );
25 | 
26 | // Define reusable test data
27 | let mockConfig: Config;
28 | 
29 | const mockDefinition: AgentDefinition = {
30 |   name: 'TestAgent',
31 |   displayName: 'Test Agent Display Name',
32 |   description: 'An agent for testing.',
33 |   inputConfig: {
34 |     inputs: {
35 |       goal: { type: 'string', required: true, description: 'The goal.' },
36 |       priority: {
37 |         type: 'number',
38 |         required: false,
39 |         description: 'The priority.',
40 |       },
41 |     },
42 |   },
43 |   modelConfig: { model: 'gemini-test-model', temp: 0, top_p: 1 },
44 |   runConfig: { max_time_minutes: 5 },
45 |   promptConfig: { systemPrompt: 'You are a test agent.' },
46 | };
47 | 
48 | const mockSchema = {
49 |   type: 'object',
50 |   properties: {
51 |     goal: { type: 'string', description: 'The goal.' },
52 |     priority: { type: 'number', description: 'The priority.' },
53 |   },
54 |   required: ['goal'],
55 | };
56 | 
57 | describe('SubagentToolWrapper', () => {
58 |   beforeEach(() => {
59 |     vi.clearAllMocks();
60 |     mockConfig = makeFakeConfig();
61 |     // Provide a mock implementation for the schema conversion utility
62 |     // eslint-disable-next-line @typescript-eslint/no-explicit-any
63 |     mockConvertInputConfigToJsonSchema.mockReturnValue(mockSchema as any);
64 |   });
65 | 
66 |   describe('constructor', () => {
67 |     it('should call convertInputConfigToJsonSchema with the correct agent inputConfig', () => {
68 |       new SubagentToolWrapper(mockDefinition, mockConfig);
69 | 
70 |       expect(convertInputConfigToJsonSchema).toHaveBeenCalledOnce();
71 |       expect(convertInputConfigToJsonSchema).toHaveBeenCalledWith(
72 |         mockDefinition.inputConfig,
73 |       );
74 |     });
75 | 
76 |     it('should correctly configure the tool properties from the agent definition', () => {
77 |       const wrapper = new SubagentToolWrapper(mockDefinition, mockConfig);
78 | 
79 |       expect(wrapper.name).toBe(mockDefinition.name);
80 |       expect(wrapper.displayName).toBe(mockDefinition.displayName);
81 |       expect(wrapper.description).toBe(mockDefinition.description);
82 |       expect(wrapper.kind).toBe(Kind.Think);
83 |       expect(wrapper.isOutputMarkdown).toBe(true);
84 |       expect(wrapper.canUpdateOutput).toBe(true);
85 |     });
86 | 
87 |     it('should fall back to the agent name for displayName if it is not provided', () => {
88 |       const definitionWithoutDisplayName = {
89 |         ...mockDefinition,
90 |         displayName: undefined,
91 |       };
92 |       const wrapper = new SubagentToolWrapper(
93 |         definitionWithoutDisplayName,
94 |         mockConfig,
95 |       );
96 |       expect(wrapper.displayName).toBe(definitionWithoutDisplayName.name);
97 |     });
98 | 
99 |     it('should generate a valid tool schema using the definition and converted schema', () => {
100 |       const wrapper = new SubagentToolWrapper(mockDefinition, mockConfig);
101 |       const schema = wrapper.schema;
102 | 
103 |       expect(schema.name).toBe(mockDefinition.name);
104 |       expect(schema.description).toBe(mockDefinition.description);
105 |       expect(schema.parametersJsonSchema).toEqual(mockSchema);
106 |     });
107 |   });
108 | 
109 |   describe('createInvocation', () => {
110 |     it('should create a SubagentInvocation with the correct parameters', () => {
111 |       const wrapper = new SubagentToolWrapper(mockDefinition, mockConfig);
112 |       const params: AgentInputs = { goal: 'Test the invocation', priority: 1 };
113 | 
114 |       // The public `build` method calls the protected `createInvocation` after validation
115 |       const invocation = wrapper.build(params);
116 | 
117 |       expect(invocation).toBeInstanceOf(SubagentInvocation);
118 |       expect(MockedSubagentInvocation).toHaveBeenCalledOnce();
119 |       expect(MockedSubagentInvocation).toHaveBeenCalledWith(
120 |         params,
121 |         mockDefinition,
122 |         mockConfig,
123 |         undefined,
124 |       );
125 |     });
126 | 
127 |     it('should pass the messageBus to the SubagentInvocation constructor', () => {
128 |       const mockMessageBus = {} as MessageBus;
129 |       const wrapper = new SubagentToolWrapper(
130 |         mockDefinition,
131 |         mockConfig,
132 |         mockMessageBus,
133 |       );
134 |       const params: AgentInputs = { goal: 'Test the invocation', priority: 1 };
135 | 
136 |       wrapper.build(params);
137 | 
138 |       expect(MockedSubagentInvocation).toHaveBeenCalledWith(
139 |         params,
140 |         mockDefinition,
141 |         mockConfig,
142 |         mockMessageBus,
143 |       );
144 |     });
145 | 
146 |     it('should throw a validation error for invalid parameters before creating an invocation', () => {
147 |       const wrapper = new SubagentToolWrapper(mockDefinition, mockConfig);
148 |       // Missing the required 'goal' parameter
149 |       const invalidParams = { priority: 1 };
150 | 
151 |       // The `build` method in the base class performs JSON schema validation
152 |       // before calling the protected `createInvocation` method.
153 |       expect(() => wrapper.build(invalidParams)).toThrow(
154 |         "params must have required property 'goal'",
155 |       );
156 |       expect(MockedSubagentInvocation).not.toHaveBeenCalled();
157 |     });
158 |   });
159 | });
```

src/agents/subagent-tool-wrapper.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   BaseDeclarativeTool,
9 |   Kind,
10 |   type ToolInvocation,
11 |   type ToolResult,
12 | } from '../tools/tools.js';
13 | import type { Config } from '../config/config.js';
14 | import type { AgentDefinition, AgentInputs } from './types.js';
15 | import { convertInputConfigToJsonSchema } from './schema-utils.js';
16 | import { SubagentInvocation } from './invocation.js';
17 | import type { MessageBus } from '../confirmation-bus/message-bus.js';
18 | 
19 | /**
20 |  * A tool wrapper that dynamically exposes a subagent as a standard,
21 |  * strongly-typed `DeclarativeTool`.
22 |  */
23 | export class SubagentToolWrapper extends BaseDeclarativeTool<
24 |   AgentInputs,
25 |   ToolResult
26 | > {
27 |   /**
28 |    * Constructs the tool wrapper.
29 |    *
30 |    * The constructor dynamically generates the JSON schema for the tool's
31 |    * parameters based on the subagent's input configuration.
32 |    *
33 |    * @param definition The `AgentDefinition` of the subagent to wrap.
34 |    * @param config The runtime configuration, passed down to the subagent.
35 |    * @param messageBus Optional message bus for policy enforcement.
36 |    */
37 |   constructor(
38 |     private readonly definition: AgentDefinition,
39 |     private readonly config: Config,
40 |     messageBus?: MessageBus,
41 |   ) {
42 |     // Dynamically generate the JSON schema required for the tool definition.
43 |     const parameterSchema = convertInputConfigToJsonSchema(
44 |       definition.inputConfig,
45 |     );
46 | 
47 |     super(
48 |       definition.name,
49 |       definition.displayName ?? definition.name,
50 |       definition.description,
51 |       Kind.Think,
52 |       parameterSchema,
53 |       /* isOutputMarkdown */ true,
54 |       /* canUpdateOutput */ true,
55 |       messageBus,
56 |     );
57 |   }
58 | 
59 |   /**
60 |    * Creates an invocation instance for executing the subagent.
61 |    *
62 |    * This method is called by the tool framework when the parent agent decides
63 |    * to use this tool.
64 |    *
65 |    * @param params The validated input parameters from the parent agent's call.
66 |    * @returns A `ToolInvocation` instance ready for execution.
67 |    */
68 |   protected createInvocation(
69 |     params: AgentInputs,
70 |   ): ToolInvocation<AgentInputs, ToolResult> {
71 |     return new SubagentInvocation(
72 |       params,
73 |       this.definition,
74 |       this.config,
75 |       this.messageBus,
76 |     );
77 |   }
78 | }
```

src/agents/types.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * @fileoverview Defines the core configuration interfaces and types for the agent architecture.
9 |  */
10 | 
11 | import type { Content, FunctionDeclaration } from '@google/genai';
12 | import type { AnyDeclarativeTool } from '../tools/tools.js';
13 | import { type z } from 'zod';
14 | 
15 | /**
16 |  * Describes the possible termination modes for an agent.
17 |  */
18 | export enum AgentTerminateMode {
19 |   ERROR = 'ERROR',
20 |   TIMEOUT = 'TIMEOUT',
21 |   GOAL = 'GOAL',
22 |   MAX_TURNS = 'MAX_TURNS',
23 |   ABORTED = 'ABORTED',
24 | }
25 | 
26 | /**
27 |  * Represents the output structure of an agent's execution.
28 |  */
29 | export interface OutputObject {
30 |   result: string;
31 |   terminate_reason: AgentTerminateMode;
32 | }
33 | 
34 | /**
35 |  * Represents the validated input parameters passed to an agent upon invocation.
36 |  * Used primarily for templating the system prompt. (Replaces ContextState)
37 |  */
38 | export type AgentInputs = Record<string, unknown>;
39 | 
40 | /**
41 |  * Structured events emitted during subagent execution for user observability.
42 |  */
43 | export interface SubagentActivityEvent {
44 |   isSubagentActivityEvent: true;
45 |   agentName: string;
46 |   type: 'TOOL_CALL_START' | 'TOOL_CALL_END' | 'THOUGHT_CHUNK' | 'ERROR';
47 |   data: Record<string, unknown>;
48 | }
49 | 
50 | /**
51 |  * The definition for an agent.
52 |  * @template TOutput The specific Zod schema for the agent's final output object.
53 |  */
54 | export interface AgentDefinition<TOutput extends z.ZodTypeAny = z.ZodUnknown> {
55 |   /** Unique identifier for the agent. */
56 |   name: string;
57 |   displayName?: string;
58 |   description: string;
59 |   promptConfig: PromptConfig;
60 |   modelConfig: ModelConfig;
61 |   runConfig: RunConfig;
62 |   toolConfig?: ToolConfig;
63 |   outputConfig?: OutputConfig<TOutput>;
64 |   inputConfig: InputConfig;
65 |   /**
66 |    * An optional function to process the raw output from the agent's final tool
67 |    * call into a string format.
68 |    *
69 |    * @param output The raw output value from the `complete_task` tool, now strongly typed with TOutput.
70 |    * @returns A string representation of the final output.
71 |    */
72 |   processOutput?: (output: z.infer<TOutput>) => string;
73 | }
74 | 
75 | /**
76 |  * Configures the initial prompt for the agent.
77 |  */
78 | export interface PromptConfig {
79 |   /**
80 |    * A single system prompt string. Supports templating using `${input_name}` syntax.
81 |    */
82 |   systemPrompt?: string;
83 |   /**
84 |    * An array of user/model content pairs for few-shot prompting.
85 |    */
86 |   initialMessages?: Content[];
87 | 
88 |   /**
89 |    * The specific task or question to trigger the agent's execution loop.
90 |    * This is sent as the first user message, distinct from the systemPrompt (identity/rules)
91 |    * and initialMessages (history/few-shots). Supports templating.
92 |    * If not provided, a generic "Get Started!" message is used.
93 |    */
94 |   query?: string;
95 | }
96 | 
97 | /**
98 |  * Configures the tools available to the agent during its execution.
99 |  */
100 | export interface ToolConfig {
101 |   tools: Array<string | FunctionDeclaration | AnyDeclarativeTool>;
102 | }
103 | 
104 | /**
105 |  * Configures the expected inputs (parameters) for the agent.
106 |  */
107 | export interface InputConfig {
108 |   /**
109 |    * Defines the parameters the agent accepts.
110 |    * This is vital for generating the tool wrapper schema.
111 |    */
112 |   inputs: Record<
113 |     string,
114 |     {
115 |       description: string;
116 |       type:
117 |         | 'string'
118 |         | 'number'
119 |         | 'boolean'
120 |         | 'integer'
121 |         | 'string[]'
122 |         | 'number[]';
123 |       required: boolean;
124 |     }
125 |   >;
126 | }
127 | 
128 | /**
129 |  * Configures the expected outputs for the agent.
130 |  */
131 | export interface OutputConfig<T extends z.ZodTypeAny> {
132 |   /**
133 |    * The name of the final result parameter. This will be the name of the
134 |    * argument in the `submit_final_output` tool (e.g., "report", "answer").
135 |    */
136 |   outputName: string;
137 |   /**
138 |    * A description of the expected output. This will be used as the description
139 |    * for the tool argument.
140 |    */
141 |   description: string;
142 |   /**
143 |    * Optional JSON schema for the output. If provided, it will be used as the
144 |    * schema for the tool's argument, allowing for structured output enforcement.
145 |    * Defaults to { type: 'string' }.
146 |    */
147 |   schema: T;
148 | }
149 | 
150 | /**
151 |  * Configures the generative model parameters for the agent.
152 |  */
153 | export interface ModelConfig {
154 |   model: string;
155 |   temp: number;
156 |   top_p: number;
157 |   thinkingBudget?: number;
158 | }
159 | 
160 | /**
161 |  * Configures the execution environment and constraints for the agent.
162 |  */
163 | export interface RunConfig {
164 |   /** The maximum execution time for the agent in minutes. */
165 |   max_time_minutes: number;
166 |   /** The maximum number of conversational turns. */
167 |   max_turns?: number;
168 | }
```

src/agents/utils.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { templateString } from './utils.js';
9 | import type { AgentInputs } from './types.js';
10 | 
11 | describe('templateString', () => {
12 |   it('should replace a single placeholder with a string value', () => {
13 |     const template = 'Hello, ${name}!';
14 |     const inputs: AgentInputs = { name: 'World' };
15 |     const result = templateString(template, inputs);
16 |     expect(result).toBe('Hello, World!');
17 |   });
18 | 
19 |   it('should replace multiple unique placeholders', () => {
20 |     const template = 'User: ${user}, Role: ${role}';
21 |     const inputs: AgentInputs = { user: 'Alex', role: 'Admin' };
22 |     const result = templateString(template, inputs);
23 |     expect(result).toBe('User: Alex, Role: Admin');
24 |   });
25 | 
26 |   it('should replace multiple instances of the same placeholder', () => {
27 |     const template = '${greeting}, ${user}. Welcome, ${user}!';
28 |     const inputs: AgentInputs = { greeting: 'Hi', user: 'Sam' };
29 |     const result = templateString(template, inputs);
30 |     expect(result).toBe('Hi, Sam. Welcome, Sam!');
31 |   });
32 | 
33 |   it('should handle various data types for input values', () => {
34 |     const template =
35 |       'Name: ${name}, Age: ${age}, Active: ${isActive}, Plan: ${plan}, Score: ${score}';
36 |     const inputs: AgentInputs = {
37 |       name: 'Jo',
38 |       age: 30,
39 |       isActive: true,
40 |       plan: null,
41 |       score: undefined,
42 |     };
43 |     const result = templateString(template, inputs);
44 |     // All values are converted to their string representations
45 |     expect(result).toBe(
46 |       'Name: Jo, Age: 30, Active: true, Plan: null, Score: undefined',
47 |     );
48 |   });
49 | 
50 |   it('should return the original string if no placeholders are present', () => {
51 |     const template = 'This is a plain string with no placeholders.';
52 |     const inputs: AgentInputs = { key: 'value' };
53 |     const result = templateString(template, inputs);
54 |     expect(result).toBe('This is a plain string with no placeholders.');
55 |   });
56 | 
57 |   it('should correctly handle an empty template string', () => {
58 |     const template = '';
59 |     const inputs: AgentInputs = { key: 'value' };
60 |     const result = templateString(template, inputs);
61 |     expect(result).toBe('');
62 |   });
63 | 
64 |   it('should ignore extra keys in the inputs object that are not in the template', () => {
65 |     const template = 'Hello, ${name}.';
66 |     const inputs: AgentInputs = { name: 'Alice', extra: 'ignored' };
67 |     const result = templateString(template, inputs);
68 |     expect(result).toBe('Hello, Alice.');
69 |   });
70 | 
71 |   it('should throw an error if a required key is missing from the inputs', () => {
72 |     const template = 'The goal is ${goal}.';
73 |     const inputs: AgentInputs = { other_input: 'some value' };
74 | 
75 |     expect(() => templateString(template, inputs)).toThrow(
76 |       'Template validation failed: Missing required input parameters: goal. Available inputs: other_input',
77 |     );
78 |   });
79 | 
80 |   it('should throw an error listing all missing keys if multiple are missing', () => {
81 |     const template = 'Analyze ${file} with ${tool}.';
82 |     const inputs: AgentInputs = { an_available_key: 'foo' };
83 | 
84 |     // Using a regex to allow for any order of missing keys in the error message
85 |     expect(() => templateString(template, inputs)).toThrow(
86 |       /Missing required input parameters: (file, tool|tool, file)/,
87 |     );
88 |   });
89 | 
90 |   it('should be case-sensitive with placeholder keys', () => {
91 |     const template = 'Value: ${Key}';
92 |     const inputs: AgentInputs = { key: 'some value' }; // 'key' is lowercase
93 | 
94 |     expect(() => templateString(template, inputs)).toThrow(
95 |       'Template validation failed: Missing required input parameters: Key. Available inputs: key',
96 |     );
97 |   });
98 | 
99 |   it('should not replace malformed or incomplete placeholders', () => {
100 |     const template =
101 |       'This is {not_a_placeholder} and this is $$escaped. Test: ${valid}';
102 |     const inputs: AgentInputs = { valid: 'works' };
103 |     const result = templateString(template, inputs);
104 |     expect(result).toBe(
105 |       'This is {not_a_placeholder} and this is $$escaped. Test: works',
106 |     );
107 |   });
108 | 
109 |   it('should work correctly with an empty inputs object if the template has no placeholders', () => {
110 |     const template = 'Static text.';
111 |     const inputs: AgentInputs = {};
112 |     const result = templateString(template, inputs);
113 |     expect(result).toBe('Static text.');
114 |   });
115 | });
```

src/agents/utils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { AgentInputs } from './types.js';
8 | 
9 | /**
10 |  * Replaces `${...}` placeholders in a template string with values from AgentInputs.
11 |  *
12 |  * @param template The template string containing placeholders.
13 |  * @param inputs The AgentInputs object providing placeholder values.
14 |  * @returns The populated string with all placeholders replaced.
15 |  * @throws {Error} if any placeholder key is not found in the inputs.
16 |  */
17 | export function templateString(template: string, inputs: AgentInputs): string {
18 |   const placeholderRegex = /\$\{(\w+)\}/g;
19 | 
20 |   // First, find all unique keys required by the template.
21 |   const requiredKeys = new Set(
22 |     Array.from(template.matchAll(placeholderRegex), (match) => match[1]),
23 |   );
24 | 
25 |   // Check if all required keys exist in the inputs.
26 |   const inputKeys = new Set(Object.keys(inputs));
27 |   const missingKeys = Array.from(requiredKeys).filter(
28 |     (key) => !inputKeys.has(key),
29 |   );
30 | 
31 |   if (missingKeys.length > 0) {
32 |     // Enhanced error message showing both missing and available keys
33 |     throw new Error(
34 |       `Template validation failed: Missing required input parameters: ${missingKeys.join(', ')}. ` +
35 |         `Available inputs: ${Object.keys(inputs).join(', ')}`,
36 |     );
37 |   }
38 | 
39 |   // Perform the replacement using a replacer function.
40 |   return template.replace(placeholderRegex, (_match, key) =>
41 |     String(inputs[key]),
42 |   );
43 | }
```

src/code_assist/codeAssist.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { ContentGenerator } from '../core/contentGenerator.js';
8 | import { AuthType } from '../core/contentGenerator.js';
9 | import { getOauthClient } from './oauth2.js';
10 | import { setupUser } from './setup.js';
11 | import type { HttpOptions } from './server.js';
12 | import { CodeAssistServer } from './server.js';
13 | import type { Config } from '../config/config.js';
14 | import { LoggingContentGenerator } from '../core/loggingContentGenerator.js';
15 | 
16 | export async function createCodeAssistContentGenerator(
17 |   httpOptions: HttpOptions,
18 |   authType: AuthType,
19 |   config: Config,
20 |   sessionId?: string,
21 | ): Promise<ContentGenerator> {
22 |   if (
23 |     authType === AuthType.LOGIN_WITH_GOOGLE ||
24 |     authType === AuthType.CLOUD_SHELL
25 |   ) {
26 |     const authClient = await getOauthClient(authType, config);
27 |     const userData = await setupUser(authClient);
28 |     return new CodeAssistServer(
29 |       authClient,
30 |       userData.projectId,
31 |       httpOptions,
32 |       sessionId,
33 |       userData.userTier,
34 |     );
35 |   }
36 | 
37 |   throw new Error(`Unsupported authType: ${authType}`);
38 | }
39 | 
40 | export function getCodeAssistServer(
41 |   config: Config,
42 | ): CodeAssistServer | undefined {
43 |   let server = config.getContentGenerator();
44 | 
45 |   // Unwrap LoggingContentGenerator if present
46 |   if (server instanceof LoggingContentGenerator) {
47 |     server = server.getWrapped();
48 |   }
49 | 
50 |   if (!(server instanceof CodeAssistServer)) {
51 |     return undefined;
52 |   }
53 |   return server;
54 | }
```

src/code_assist/converter.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import type { CaGenerateContentResponse } from './converter.js';
9 | import {
10 |   toGenerateContentRequest,
11 |   fromGenerateContentResponse,
12 |   toContents,
13 | } from './converter.js';
14 | import type {
15 |   ContentListUnion,
16 |   GenerateContentParameters,
17 | } from '@google/genai';
18 | import {
19 |   GenerateContentResponse,
20 |   FinishReason,
21 |   BlockedReason,
22 |   type Part,
23 | } from '@google/genai';
24 | 
25 | describe('converter', () => {
26 |   describe('toCodeAssistRequest', () => {
27 |     it('should convert a simple request with project', () => {
28 |       const genaiReq: GenerateContentParameters = {
29 |         model: 'gemini-pro',
30 |         contents: [{ role: 'user', parts: [{ text: 'Hello' }] }],
31 |       };
32 |       const codeAssistReq = toGenerateContentRequest(
33 |         genaiReq,
34 |         'my-prompt',
35 |         'my-project',
36 |         'my-session',
37 |       );
38 |       expect(codeAssistReq).toEqual({
39 |         model: 'gemini-pro',
40 |         project: 'my-project',
41 |         request: {
42 |           contents: [{ role: 'user', parts: [{ text: 'Hello' }] }],
43 |           systemInstruction: undefined,
44 |           cachedContent: undefined,
45 |           tools: undefined,
46 |           toolConfig: undefined,
47 |           labels: undefined,
48 |           safetySettings: undefined,
49 |           generationConfig: undefined,
50 |           session_id: 'my-session',
51 |         },
52 |         user_prompt_id: 'my-prompt',
53 |       });
54 |     });
55 | 
56 |     it('should convert a request without a project', () => {
57 |       const genaiReq: GenerateContentParameters = {
58 |         model: 'gemini-pro',
59 |         contents: [{ role: 'user', parts: [{ text: 'Hello' }] }],
60 |       };
61 |       const codeAssistReq = toGenerateContentRequest(
62 |         genaiReq,
63 |         'my-prompt',
64 |         undefined,
65 |         'my-session',
66 |       );
67 |       expect(codeAssistReq).toEqual({
68 |         model: 'gemini-pro',
69 |         project: undefined,
70 |         request: {
71 |           contents: [{ role: 'user', parts: [{ text: 'Hello' }] }],
72 |           systemInstruction: undefined,
73 |           cachedContent: undefined,
74 |           tools: undefined,
75 |           toolConfig: undefined,
76 |           labels: undefined,
77 |           safetySettings: undefined,
78 |           generationConfig: undefined,
79 |           session_id: 'my-session',
80 |         },
81 |         user_prompt_id: 'my-prompt',
82 |       });
83 |     });
84 | 
85 |     it('should convert a request with sessionId', () => {
86 |       const genaiReq: GenerateContentParameters = {
87 |         model: 'gemini-pro',
88 |         contents: [{ role: 'user', parts: [{ text: 'Hello' }] }],
89 |       };
90 |       const codeAssistReq = toGenerateContentRequest(
91 |         genaiReq,
92 |         'my-prompt',
93 |         'my-project',
94 |         'session-123',
95 |       );
96 |       expect(codeAssistReq).toEqual({
97 |         model: 'gemini-pro',
98 |         project: 'my-project',
99 |         request: {
100 |           contents: [{ role: 'user', parts: [{ text: 'Hello' }] }],
101 |           systemInstruction: undefined,
102 |           cachedContent: undefined,
103 |           tools: undefined,
104 |           toolConfig: undefined,
105 |           labels: undefined,
106 |           safetySettings: undefined,
107 |           generationConfig: undefined,
108 |           session_id: 'session-123',
109 |         },
110 |         user_prompt_id: 'my-prompt',
111 |       });
112 |     });
113 | 
114 |     it('should handle string content', () => {
115 |       const genaiReq: GenerateContentParameters = {
116 |         model: 'gemini-pro',
117 |         contents: 'Hello',
118 |       };
119 |       const codeAssistReq = toGenerateContentRequest(
120 |         genaiReq,
121 |         'my-prompt',
122 |         'my-project',
123 |         'my-session',
124 |       );
125 |       expect(codeAssistReq.request.contents).toEqual([
126 |         { role: 'user', parts: [{ text: 'Hello' }] },
127 |       ]);
128 |     });
129 | 
130 |     it('should handle Part[] content', () => {
131 |       const genaiReq: GenerateContentParameters = {
132 |         model: 'gemini-pro',
133 |         contents: [{ text: 'Hello' }, { text: 'World' }],
134 |       };
135 |       const codeAssistReq = toGenerateContentRequest(
136 |         genaiReq,
137 |         'my-prompt',
138 |         'my-project',
139 |         'my-session',
140 |       );
141 |       expect(codeAssistReq.request.contents).toEqual([
142 |         { role: 'user', parts: [{ text: 'Hello' }] },
143 |         { role: 'user', parts: [{ text: 'World' }] },
144 |       ]);
145 |     });
146 | 
147 |     it('should handle system instructions', () => {
148 |       const genaiReq: GenerateContentParameters = {
149 |         model: 'gemini-pro',
150 |         contents: 'Hello',
151 |         config: {
152 |           systemInstruction: 'You are a helpful assistant.',
153 |         },
154 |       };
155 |       const codeAssistReq = toGenerateContentRequest(
156 |         genaiReq,
157 |         'my-prompt',
158 |         'my-project',
159 |         'my-session',
160 |       );
161 |       expect(codeAssistReq.request.systemInstruction).toEqual({
162 |         role: 'user',
163 |         parts: [{ text: 'You are a helpful assistant.' }],
164 |       });
165 |     });
166 | 
167 |     it('should handle generation config', () => {
168 |       const genaiReq: GenerateContentParameters = {
169 |         model: 'gemini-pro',
170 |         contents: 'Hello',
171 |         config: {
172 |           temperature: 0.8,
173 |           topK: 40,
174 |         },
175 |       };
176 |       const codeAssistReq = toGenerateContentRequest(
177 |         genaiReq,
178 |         'my-prompt',
179 |         'my-project',
180 |         'my-session',
181 |       );
182 |       expect(codeAssistReq.request.generationConfig).toEqual({
183 |         temperature: 0.8,
184 |         topK: 40,
185 |       });
186 |     });
187 | 
188 |     it('should handle all generation config fields', () => {
189 |       const genaiReq: GenerateContentParameters = {
190 |         model: 'gemini-pro',
191 |         contents: 'Hello',
192 |         config: {
193 |           temperature: 0.1,
194 |           topP: 0.2,
195 |           topK: 3,
196 |           candidateCount: 4,
197 |           maxOutputTokens: 5,
198 |           stopSequences: ['a'],
199 |           responseLogprobs: true,
200 |           logprobs: 6,
201 |           presencePenalty: 0.7,
202 |           frequencyPenalty: 0.8,
203 |           seed: 9,
204 |           responseMimeType: 'application/json',
205 |         },
206 |       };
207 |       const codeAssistReq = toGenerateContentRequest(
208 |         genaiReq,
209 |         'my-prompt',
210 |         'my-project',
211 |         'my-session',
212 |       );
213 |       expect(codeAssistReq.request.generationConfig).toEqual({
214 |         temperature: 0.1,
215 |         topP: 0.2,
216 |         topK: 3,
217 |         candidateCount: 4,
218 |         maxOutputTokens: 5,
219 |         stopSequences: ['a'],
220 |         responseLogprobs: true,
221 |         logprobs: 6,
222 |         presencePenalty: 0.7,
223 |         frequencyPenalty: 0.8,
224 |         seed: 9,
225 |         responseMimeType: 'application/json',
226 |       });
227 |     });
228 |   });
229 | 
230 |   describe('fromCodeAssistResponse', () => {
231 |     it('should convert a simple response', () => {
232 |       const codeAssistRes: CaGenerateContentResponse = {
233 |         response: {
234 |           candidates: [
235 |             {
236 |               index: 0,
237 |               content: {
238 |                 role: 'model',
239 |                 parts: [{ text: 'Hi there!' }],
240 |               },
241 |               finishReason: FinishReason.STOP,
242 |               safetyRatings: [],
243 |             },
244 |           ],
245 |         },
246 |       };
247 |       const genaiRes = fromGenerateContentResponse(codeAssistRes);
248 |       expect(genaiRes).toBeInstanceOf(GenerateContentResponse);
249 |       expect(genaiRes.candidates).toEqual(codeAssistRes.response.candidates);
250 |     });
251 | 
252 |     it('should handle prompt feedback and usage metadata', () => {
253 |       const codeAssistRes: CaGenerateContentResponse = {
254 |         response: {
255 |           candidates: [],
256 |           promptFeedback: {
257 |             blockReason: BlockedReason.SAFETY,
258 |             safetyRatings: [],
259 |           },
260 |           usageMetadata: {
261 |             promptTokenCount: 10,
262 |             candidatesTokenCount: 20,
263 |             totalTokenCount: 30,
264 |           },
265 |         },
266 |       };
267 |       const genaiRes = fromGenerateContentResponse(codeAssistRes);
268 |       expect(genaiRes.promptFeedback).toEqual(
269 |         codeAssistRes.response.promptFeedback,
270 |       );
271 |       expect(genaiRes.usageMetadata).toEqual(
272 |         codeAssistRes.response.usageMetadata,
273 |       );
274 |     });
275 | 
276 |     it('should handle automatic function calling history', () => {
277 |       const codeAssistRes: CaGenerateContentResponse = {
278 |         response: {
279 |           candidates: [],
280 |           automaticFunctionCallingHistory: [
281 |             {
282 |               role: 'model',
283 |               parts: [
284 |                 {
285 |                   functionCall: {
286 |                     name: 'test_function',
287 |                     args: {
288 |                       foo: 'bar',
289 |                     },
290 |                   },
291 |                 },
292 |               ],
293 |             },
294 |           ],
295 |         },
296 |       };
297 |       const genaiRes = fromGenerateContentResponse(codeAssistRes);
298 |       expect(genaiRes.automaticFunctionCallingHistory).toEqual(
299 |         codeAssistRes.response.automaticFunctionCallingHistory,
300 |       );
301 |     });
302 | 
303 |     it('should handle modelVersion', () => {
304 |       const codeAssistRes: CaGenerateContentResponse = {
305 |         response: {
306 |           candidates: [],
307 |           modelVersion: 'gemini-2.5-pro',
308 |         },
309 |       };
310 |       const genaiRes = fromGenerateContentResponse(codeAssistRes);
311 |       expect(genaiRes.modelVersion).toEqual('gemini-2.5-pro');
312 |     });
313 |   });
314 | 
315 |   describe('toContents', () => {
316 |     it('should handle Content', () => {
317 |       const content: ContentListUnion = {
318 |         role: 'user',
319 |         parts: [{ text: 'hello' }],
320 |       };
321 |       expect(toContents(content)).toEqual([
322 |         { role: 'user', parts: [{ text: 'hello' }] },
323 |       ]);
324 |     });
325 | 
326 |     it('should handle array of Contents', () => {
327 |       const contents: ContentListUnion = [
328 |         { role: 'user', parts: [{ text: 'hello' }] },
329 |         { role: 'model', parts: [{ text: 'hi' }] },
330 |       ];
331 |       expect(toContents(contents)).toEqual([
332 |         { role: 'user', parts: [{ text: 'hello' }] },
333 |         { role: 'model', parts: [{ text: 'hi' }] },
334 |       ]);
335 |     });
336 | 
337 |     it('should handle Part', () => {
338 |       const part: ContentListUnion = { text: 'a part' };
339 |       expect(toContents(part)).toEqual([
340 |         { role: 'user', parts: [{ text: 'a part' }] },
341 |       ]);
342 |     });
343 | 
344 |     it('should handle array of Parts', () => {
345 |       const parts = [{ text: 'part 1' }, 'part 2'];
346 |       expect(toContents(parts)).toEqual([
347 |         { role: 'user', parts: [{ text: 'part 1' }] },
348 |         { role: 'user', parts: [{ text: 'part 2' }] },
349 |       ]);
350 |     });
351 | 
352 |     it('should handle string', () => {
353 |       const str: ContentListUnion = 'a string';
354 |       expect(toContents(str)).toEqual([
355 |         { role: 'user', parts: [{ text: 'a string' }] },
356 |       ]);
357 |     });
358 | 
359 |     it('should handle array of strings', () => {
360 |       const strings: ContentListUnion = ['string 1', 'string 2'];
361 |       expect(toContents(strings)).toEqual([
362 |         { role: 'user', parts: [{ text: 'string 1' }] },
363 |         { role: 'user', parts: [{ text: 'string 2' }] },
364 |       ]);
365 |     });
366 | 
367 |     it('should convert thought parts to text parts for API compatibility', () => {
368 |       const contentWithThought: ContentListUnion = {
369 |         role: 'model',
370 |         parts: [
371 |           { text: 'regular text' },
372 |           { thought: 'thinking about the problem' } as Part & {
373 |             thought: string;
374 |           },
375 |           { text: 'more text' },
376 |         ],
377 |       };
378 |       expect(toContents(contentWithThought)).toEqual([
379 |         {
380 |           role: 'model',
381 |           parts: [
382 |             { text: 'regular text' },
383 |             { text: '[Thought: thinking about the problem]' },
384 |             { text: 'more text' },
385 |           ],
386 |         },
387 |       ]);
388 |     });
389 | 
390 |     it('should combine text and thought for text parts with thoughts', () => {
391 |       const contentWithTextAndThought: ContentListUnion = {
392 |         role: 'model',
393 |         parts: [
394 |           {
395 |             text: 'Here is my response',
396 |             thought: 'I need to be careful here',
397 |           } as Part & { thought: string },
398 |         ],
399 |       };
400 |       expect(toContents(contentWithTextAndThought)).toEqual([
401 |         {
402 |           role: 'model',
403 |           parts: [
404 |             {
405 |               text: 'Here is my response\n[Thought: I need to be careful here]',
406 |             },
407 |           ],
408 |         },
409 |       ]);
410 |     });
411 | 
412 |     it('should preserve non-thought properties while removing thought', () => {
413 |       const contentWithComplexPart: ContentListUnion = {
414 |         role: 'model',
415 |         parts: [
416 |           {
417 |             functionCall: { name: 'calculate', args: { x: 5, y: 10 } },
418 |             thought: 'Performing calculation',
419 |           } as Part & { thought: string },
420 |         ],
421 |       };
422 |       expect(toContents(contentWithComplexPart)).toEqual([
423 |         {
424 |           role: 'model',
425 |           parts: [
426 |             {
427 |               functionCall: { name: 'calculate', args: { x: 5, y: 10 } },
428 |             },
429 |           ],
430 |         },
431 |       ]);
432 |     });
433 | 
434 |     it('should convert invalid text content to valid text part with thought', () => {
435 |       const contentWithInvalidText: ContentListUnion = {
436 |         role: 'model',
437 |         parts: [
438 |           {
439 |             text: 123, // Invalid - should be string
440 |             thought: 'Processing number',
441 |           } as Part & { thought: string; text: number },
442 |         ],
443 |       };
444 |       expect(toContents(contentWithInvalidText)).toEqual([
445 |         {
446 |           role: 'model',
447 |           parts: [
448 |             {
449 |               text: '123\n[Thought: Processing number]',
450 |             },
451 |           ],
452 |         },
453 |       ]);
454 |     });
455 |   });
456 | });
```

src/code_assist/converter.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   Content,
9 |   ContentListUnion,
10 |   ContentUnion,
11 |   GenerateContentConfig,
12 |   GenerateContentParameters,
13 |   CountTokensParameters,
14 |   CountTokensResponse,
15 |   GenerationConfigRoutingConfig,
16 |   MediaResolution,
17 |   Candidate,
18 |   ModelSelectionConfig,
19 |   GenerateContentResponsePromptFeedback,
20 |   GenerateContentResponseUsageMetadata,
21 |   Part,
22 |   SafetySetting,
23 |   PartUnion,
24 |   SpeechConfigUnion,
25 |   ThinkingConfig,
26 |   ToolListUnion,
27 |   ToolConfig,
28 | } from '@google/genai';
29 | import { GenerateContentResponse } from '@google/genai';
30 | 
31 | export interface CAGenerateContentRequest {
32 |   model: string;
33 |   project?: string;
34 |   user_prompt_id?: string;
35 |   request: VertexGenerateContentRequest;
36 | }
37 | 
38 | interface VertexGenerateContentRequest {
39 |   contents: Content[];
40 |   systemInstruction?: Content;
41 |   cachedContent?: string;
42 |   tools?: ToolListUnion;
43 |   toolConfig?: ToolConfig;
44 |   labels?: Record<string, string>;
45 |   safetySettings?: SafetySetting[];
46 |   generationConfig?: VertexGenerationConfig;
47 |   session_id?: string;
48 | }
49 | 
50 | interface VertexGenerationConfig {
51 |   temperature?: number;
52 |   topP?: number;
53 |   topK?: number;
54 |   candidateCount?: number;
55 |   maxOutputTokens?: number;
56 |   stopSequences?: string[];
57 |   responseLogprobs?: boolean;
58 |   logprobs?: number;
59 |   presencePenalty?: number;
60 |   frequencyPenalty?: number;
61 |   seed?: number;
62 |   responseMimeType?: string;
63 |   responseJsonSchema?: unknown;
64 |   responseSchema?: unknown;
65 |   routingConfig?: GenerationConfigRoutingConfig;
66 |   modelSelectionConfig?: ModelSelectionConfig;
67 |   responseModalities?: string[];
68 |   mediaResolution?: MediaResolution;
69 |   speechConfig?: SpeechConfigUnion;
70 |   audioTimestamp?: boolean;
71 |   thinkingConfig?: ThinkingConfig;
72 | }
73 | 
74 | export interface CaGenerateContentResponse {
75 |   response: VertexGenerateContentResponse;
76 | }
77 | 
78 | interface VertexGenerateContentResponse {
79 |   candidates: Candidate[];
80 |   automaticFunctionCallingHistory?: Content[];
81 |   promptFeedback?: GenerateContentResponsePromptFeedback;
82 |   usageMetadata?: GenerateContentResponseUsageMetadata;
83 |   modelVersion?: string;
84 | }
85 | 
86 | export interface CaCountTokenRequest {
87 |   request: VertexCountTokenRequest;
88 | }
89 | 
90 | interface VertexCountTokenRequest {
91 |   model: string;
92 |   contents: Content[];
93 | }
94 | 
95 | export interface CaCountTokenResponse {
96 |   totalTokens: number;
97 | }
98 | 
99 | export function toCountTokenRequest(
100 |   req: CountTokensParameters,
101 | ): CaCountTokenRequest {
102 |   return {
103 |     request: {
104 |       model: 'models/' + req.model,
105 |       contents: toContents(req.contents),
106 |     },
107 |   };
108 | }
109 | 
110 | export function fromCountTokenResponse(
111 |   res: CaCountTokenResponse,
112 | ): CountTokensResponse {
113 |   return {
114 |     totalTokens: res.totalTokens,
115 |   };
116 | }
117 | 
118 | export function toGenerateContentRequest(
119 |   req: GenerateContentParameters,
120 |   userPromptId: string,
121 |   project?: string,
122 |   sessionId?: string,
123 | ): CAGenerateContentRequest {
124 |   return {
125 |     model: req.model,
126 |     project,
127 |     user_prompt_id: userPromptId,
128 |     request: toVertexGenerateContentRequest(req, sessionId),
129 |   };
130 | }
131 | 
132 | export function fromGenerateContentResponse(
133 |   res: CaGenerateContentResponse,
134 | ): GenerateContentResponse {
135 |   const inres = res.response;
136 |   const out = new GenerateContentResponse();
137 |   out.candidates = inres.candidates;
138 |   out.automaticFunctionCallingHistory = inres.automaticFunctionCallingHistory;
139 |   out.promptFeedback = inres.promptFeedback;
140 |   out.usageMetadata = inres.usageMetadata;
141 |   out.modelVersion = inres.modelVersion;
142 |   return out;
143 | }
144 | 
145 | function toVertexGenerateContentRequest(
146 |   req: GenerateContentParameters,
147 |   sessionId?: string,
148 | ): VertexGenerateContentRequest {
149 |   return {
150 |     contents: toContents(req.contents),
151 |     systemInstruction: maybeToContent(req.config?.systemInstruction),
152 |     cachedContent: req.config?.cachedContent,
153 |     tools: req.config?.tools,
154 |     toolConfig: req.config?.toolConfig,
155 |     labels: req.config?.labels,
156 |     safetySettings: req.config?.safetySettings,
157 |     generationConfig: toVertexGenerationConfig(req.config),
158 |     session_id: sessionId,
159 |   };
160 | }
161 | 
162 | export function toContents(contents: ContentListUnion): Content[] {
163 |   if (Array.isArray(contents)) {
164 |     // it's a Content[] or a PartsUnion[]
165 |     return contents.map(toContent);
166 |   }
167 |   // it's a Content or a PartsUnion
168 |   return [toContent(contents)];
169 | }
170 | 
171 | function maybeToContent(content?: ContentUnion): Content | undefined {
172 |   if (!content) {
173 |     return undefined;
174 |   }
175 |   return toContent(content);
176 | }
177 | 
178 | function toContent(content: ContentUnion): Content {
179 |   if (Array.isArray(content)) {
180 |     // it's a PartsUnion[]
181 |     return {
182 |       role: 'user',
183 |       parts: toParts(content),
184 |     };
185 |   }
186 |   if (typeof content === 'string') {
187 |     // it's a string
188 |     return {
189 |       role: 'user',
190 |       parts: [{ text: content }],
191 |     };
192 |   }
193 |   if ('parts' in content) {
194 |     // it's a Content - process parts to handle thought filtering
195 |     return {
196 |       ...content,
197 |       parts: content.parts
198 |         ? toParts(content.parts.filter((p) => p != null))
199 |         : [],
200 |     };
201 |   }
202 |   // it's a Part
203 |   return {
204 |     role: 'user',
205 |     parts: [toPart(content as Part)],
206 |   };
207 | }
208 | 
209 | export function toParts(parts: PartUnion[]): Part[] {
210 |   return parts.map(toPart);
211 | }
212 | 
213 | function toPart(part: PartUnion): Part {
214 |   if (typeof part === 'string') {
215 |     // it's a string
216 |     return { text: part };
217 |   }
218 | 
219 |   // Handle thought parts for CountToken API compatibility
220 |   // The CountToken API expects parts to have certain required "oneof" fields initialized,
221 |   // but thought parts don't conform to this schema and cause API failures
222 |   if ('thought' in part && part.thought) {
223 |     const thoughtText = `[Thought: ${part.thought}]`;
224 | 
225 |     const newPart = { ...part };
226 |     delete (newPart as Record<string, unknown>)['thought'];
227 | 
228 |     const hasApiContent =
229 |       'functionCall' in newPart ||
230 |       'functionResponse' in newPart ||
231 |       'inlineData' in newPart ||
232 |       'fileData' in newPart;
233 | 
234 |     if (hasApiContent) {
235 |       // It's a functionCall or other non-text part. Just strip the thought.
236 |       return newPart;
237 |     }
238 | 
239 |     // If no other valid API content, this must be a text part.
240 |     // Combine existing text (if any) with the thought, preserving other properties.
241 |     const text = (newPart as { text?: unknown }).text;
242 |     const existingText = text ? String(text) : '';
243 |     const combinedText = existingText
244 |       ? `${existingText}\n${thoughtText}`
245 |       : thoughtText;
246 | 
247 |     return {
248 |       ...newPart,
249 |       text: combinedText,
250 |     };
251 |   }
252 | 
253 |   return part;
254 | }
255 | 
256 | function toVertexGenerationConfig(
257 |   config?: GenerateContentConfig,
258 | ): VertexGenerationConfig | undefined {
259 |   if (!config) {
260 |     return undefined;
261 |   }
262 |   return {
263 |     temperature: config.temperature,
264 |     topP: config.topP,
265 |     topK: config.topK,
266 |     candidateCount: config.candidateCount,
267 |     maxOutputTokens: config.maxOutputTokens,
268 |     stopSequences: config.stopSequences,
269 |     responseLogprobs: config.responseLogprobs,
270 |     logprobs: config.logprobs,
271 |     presencePenalty: config.presencePenalty,
272 |     frequencyPenalty: config.frequencyPenalty,
273 |     seed: config.seed,
274 |     responseMimeType: config.responseMimeType,
275 |     responseSchema: config.responseSchema,
276 |     responseJsonSchema: config.responseJsonSchema,
277 |     routingConfig: config.routingConfig,
278 |     modelSelectionConfig: config.modelSelectionConfig,
279 |     responseModalities: config.responseModalities,
280 |     mediaResolution: config.mediaResolution,
281 |     speechConfig: config.speechConfig,
282 |     audioTimestamp: config.audioTimestamp,
283 |     thinkingConfig: config.thinkingConfig,
284 |   };
285 | }
```

src/code_assist/oauth2.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Credentials } from 'google-auth-library';
8 | import type { Mock } from 'vitest';
9 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
10 | import {
11 |   getOauthClient,
12 |   resetOauthClientForTesting,
13 |   clearCachedCredentialFile,
14 |   clearOauthClientCache,
15 | } from './oauth2.js';
16 | import { UserAccountManager } from '../utils/userAccountManager.js';
17 | import { OAuth2Client, Compute } from 'google-auth-library';
18 | import * as fs from 'node:fs';
19 | import * as path from 'node:path';
20 | import http from 'node:http';
21 | import open from 'open';
22 | import crypto from 'node:crypto';
23 | import * as os from 'node:os';
24 | import { AuthType } from '../core/contentGenerator.js';
25 | import type { Config } from '../config/config.js';
26 | import readline from 'node:readline';
27 | import { FORCE_ENCRYPTED_FILE_ENV_VAR } from '../mcp/token-storage/index.js';
28 | 
29 | vi.mock('os', async (importOriginal) => {
30 |   const os = await importOriginal<typeof import('os')>();
31 |   return {
32 |     ...os,
33 |     homedir: vi.fn(),
34 |   };
35 | });
36 | 
37 | vi.mock('google-auth-library');
38 | vi.mock('http');
39 | vi.mock('open');
40 | vi.mock('crypto');
41 | vi.mock('node:readline');
42 | vi.mock('../utils/browser.js', () => ({
43 |   shouldAttemptBrowserLaunch: () => true,
44 | }));
45 | 
46 | vi.mock('./oauth-credential-storage.js', () => ({
47 |   OAuthCredentialStorage: {
48 |     saveCredentials: vi.fn(),
49 |     loadCredentials: vi.fn(),
50 |     clearCredentials: vi.fn(),
51 |   },
52 | }));
53 | 
54 | const mockConfig = {
55 |   getNoBrowser: () => false,
56 |   getProxy: () => 'http://test.proxy.com:8080',
57 |   isBrowserLaunchSuppressed: () => false,
58 | } as unknown as Config;
59 | 
60 | // Mock fetch globally
61 | global.fetch = vi.fn();
62 | 
63 | describe('oauth2', () => {
64 |   describe('with encrypted flag false', () => {
65 |     let tempHomeDir: string;
66 | 
67 |     beforeEach(() => {
68 |       process.env[FORCE_ENCRYPTED_FILE_ENV_VAR] = 'false';
69 |       tempHomeDir = fs.mkdtempSync(
70 |         path.join(os.tmpdir(), 'gemini-cli-test-home-'),
71 |       );
72 |       (os.homedir as Mock).mockReturnValue(tempHomeDir);
73 |     });
74 |     afterEach(() => {
75 |       fs.rmSync(tempHomeDir, { recursive: true, force: true });
76 |       vi.clearAllMocks();
77 |       resetOauthClientForTesting();
78 |       vi.unstubAllEnvs();
79 |     });
80 | 
81 |     it('should perform a web login', async () => {
82 |       const mockAuthUrl = 'https://example.com/auth';
83 |       const mockCode = 'test-code';
84 |       const mockState = 'test-state';
85 |       const mockTokens = {
86 |         access_token: 'test-access-token',
87 |         refresh_token: 'test-refresh-token',
88 |       };
89 | 
90 |       const mockGenerateAuthUrl = vi.fn().mockReturnValue(mockAuthUrl);
91 |       const mockGetToken = vi.fn().mockResolvedValue({ tokens: mockTokens });
92 |       const mockSetCredentials = vi.fn();
93 |       const mockGetAccessToken = vi
94 |         .fn()
95 |         .mockResolvedValue({ token: 'mock-access-token' });
96 |       const mockOAuth2Client = {
97 |         generateAuthUrl: mockGenerateAuthUrl,
98 |         getToken: mockGetToken,
99 |         setCredentials: mockSetCredentials,
100 |         getAccessToken: mockGetAccessToken,
101 |         credentials: mockTokens,
102 |         on: vi.fn(),
103 |       } as unknown as OAuth2Client;
104 |       (OAuth2Client as unknown as Mock).mockImplementation(
105 |         () => mockOAuth2Client,
106 |       );
107 | 
108 |       vi.spyOn(crypto, 'randomBytes').mockReturnValue(mockState as never);
109 |       (open as Mock).mockImplementation(async () => ({ on: vi.fn() }) as never);
110 | 
111 |       // Mock the UserInfo API response
112 |       (global.fetch as Mock).mockResolvedValue({
113 |         ok: true,
114 |         json: vi
115 |           .fn()
116 |           .mockResolvedValue({ email: 'test-google-account@gmail.com' }),
117 |       } as unknown as Response);
118 | 
119 |       let requestCallback!: http.RequestListener<
120 |         typeof http.IncomingMessage,
121 |         typeof http.ServerResponse
122 |       >;
123 | 
124 |       let serverListeningCallback: (value: unknown) => void;
125 |       const serverListeningPromise = new Promise(
126 |         (resolve) => (serverListeningCallback = resolve),
127 |       );
128 | 
129 |       let capturedPort = 0;
130 |       const mockHttpServer = {
131 |         listen: vi.fn((port: number, _host: string, callback?: () => void) => {
132 |           capturedPort = port;
133 |           if (callback) {
134 |             callback();
135 |           }
136 |           serverListeningCallback(undefined);
137 |         }),
138 |         close: vi.fn((callback?: () => void) => {
139 |           if (callback) {
140 |             callback();
141 |           }
142 |         }),
143 |         on: vi.fn(),
144 |         address: () => ({ port: capturedPort }),
145 |       };
146 |       (http.createServer as Mock).mockImplementation((cb) => {
147 |         requestCallback = cb as http.RequestListener<
148 |           typeof http.IncomingMessage,
149 |           typeof http.ServerResponse
150 |         >;
151 |         return mockHttpServer as unknown as http.Server;
152 |       });
153 | 
154 |       const clientPromise = getOauthClient(
155 |         AuthType.LOGIN_WITH_GOOGLE,
156 |         mockConfig,
157 |       );
158 | 
159 |       // wait for server to start listening.
160 |       await serverListeningPromise;
161 | 
162 |       const mockReq = {
163 |         url: `/oauth2callback?code=${mockCode}&state=${mockState}`,
164 |       } as http.IncomingMessage;
165 |       const mockRes = {
166 |         writeHead: vi.fn(),
167 |         end: vi.fn(),
168 |       } as unknown as http.ServerResponse;
169 | 
170 |       await requestCallback(mockReq, mockRes);
171 | 
172 |       const client = await clientPromise;
173 |       expect(client).toBe(mockOAuth2Client);
174 | 
175 |       expect(open).toHaveBeenCalledWith(mockAuthUrl);
176 |       expect(mockGetToken).toHaveBeenCalledWith({
177 |         code: mockCode,
178 |         redirect_uri: `http://localhost:${capturedPort}/oauth2callback`,
179 |       });
180 |       expect(mockSetCredentials).toHaveBeenCalledWith(mockTokens);
181 | 
182 |       // Verify Google Account was cached
183 |       const googleAccountPath = path.join(
184 |         tempHomeDir,
185 |         '.gemini',
186 |         'google_accounts.json',
187 |       );
188 |       expect(fs.existsSync(googleAccountPath)).toBe(true);
189 |       const cachedGoogleAccount = fs.readFileSync(googleAccountPath, 'utf-8');
190 |       expect(JSON.parse(cachedGoogleAccount)).toEqual({
191 |         active: 'test-google-account@gmail.com',
192 |         old: [],
193 |       });
194 | 
195 |       // Verify the getCachedGoogleAccount function works
196 |       const userAccountManager = new UserAccountManager();
197 |       expect(userAccountManager.getCachedGoogleAccount()).toBe(
198 |         'test-google-account@gmail.com',
199 |       );
200 |     });
201 | 
202 |     it('should perform login with user code', async () => {
203 |       const mockConfigWithNoBrowser = {
204 |         getNoBrowser: () => true,
205 |         getProxy: () => 'http://test.proxy.com:8080',
206 |         isBrowserLaunchSuppressed: () => true,
207 |       } as unknown as Config;
208 | 
209 |       const mockCodeVerifier = {
210 |         codeChallenge: 'test-challenge',
211 |         codeVerifier: 'test-verifier',
212 |       };
213 |       const mockAuthUrl = 'https://example.com/auth-user-code';
214 |       const mockCode = 'test-user-code';
215 |       const mockTokens = {
216 |         access_token: 'test-access-token-user-code',
217 |         refresh_token: 'test-refresh-token-user-code',
218 |       };
219 | 
220 |       const mockGenerateAuthUrl = vi.fn().mockReturnValue(mockAuthUrl);
221 |       const mockGetToken = vi.fn().mockResolvedValue({ tokens: mockTokens });
222 |       const mockSetCredentials = vi.fn();
223 |       const mockGenerateCodeVerifierAsync = vi
224 |         .fn()
225 |         .mockResolvedValue(mockCodeVerifier);
226 | 
227 |       const mockOAuth2Client = {
228 |         generateAuthUrl: mockGenerateAuthUrl,
229 |         getToken: mockGetToken,
230 |         setCredentials: mockSetCredentials,
231 |         generateCodeVerifierAsync: mockGenerateCodeVerifierAsync,
232 |         on: vi.fn(),
233 |       } as unknown as OAuth2Client;
234 |       (OAuth2Client as unknown as Mock).mockImplementation(
235 |         () => mockOAuth2Client,
236 |       );
237 | 
238 |       const mockReadline = {
239 |         question: vi.fn((_query, callback) => callback(mockCode)),
240 |         close: vi.fn(),
241 |       };
242 |       (readline.createInterface as Mock).mockReturnValue(mockReadline);
243 | 
244 |       const consoleLogSpy = vi
245 |         .spyOn(console, 'log')
246 |         .mockImplementation(() => {});
247 | 
248 |       const client = await getOauthClient(
249 |         AuthType.LOGIN_WITH_GOOGLE,
250 |         mockConfigWithNoBrowser,
251 |       );
252 | 
253 |       expect(client).toBe(mockOAuth2Client);
254 | 
255 |       // Verify the auth flow
256 |       expect(mockGenerateCodeVerifierAsync).toHaveBeenCalled();
257 |       expect(mockGenerateAuthUrl).toHaveBeenCalled();
258 |       expect(consoleLogSpy).toHaveBeenCalledWith(
259 |         expect.stringContaining(mockAuthUrl),
260 |       );
261 |       expect(mockReadline.question).toHaveBeenCalledWith(
262 |         'Enter the authorization code: ',
263 |         expect.any(Function),
264 |       );
265 |       expect(mockGetToken).toHaveBeenCalledWith({
266 |         code: mockCode,
267 |         codeVerifier: mockCodeVerifier.codeVerifier,
268 |         redirect_uri: 'https://codeassist.google.com/authcode',
269 |       });
270 |       expect(mockSetCredentials).toHaveBeenCalledWith(mockTokens);
271 | 
272 |       consoleLogSpy.mockRestore();
273 |     });
274 | 
275 |     describe('in Cloud Shell', () => {
276 |       const mockGetAccessToken = vi.fn();
277 |       let mockComputeClient: Compute;
278 | 
279 |       beforeEach(() => {
280 |         mockGetAccessToken.mockResolvedValue({ token: 'test-access-token' });
281 |         mockComputeClient = {
282 |           credentials: { refresh_token: 'test-refresh-token' },
283 |           getAccessToken: mockGetAccessToken,
284 |         } as unknown as Compute;
285 | 
286 |         (Compute as unknown as Mock).mockImplementation(
287 |           () => mockComputeClient,
288 |         );
289 |       });
290 | 
291 |       it('should attempt to load cached credentials first', async () => {
292 |         const cachedCreds = { refresh_token: 'cached-token' };
293 |         const credsPath = path.join(tempHomeDir, '.gemini', 'oauth_creds.json');
294 |         await fs.promises.mkdir(path.dirname(credsPath), { recursive: true });
295 |         await fs.promises.writeFile(credsPath, JSON.stringify(cachedCreds));
296 | 
297 |         const mockClient = {
298 |           setCredentials: vi.fn(),
299 |           getAccessToken: vi.fn().mockResolvedValue({ token: 'test-token' }),
300 |           getTokenInfo: vi.fn().mockResolvedValue({}),
301 |           on: vi.fn(),
302 |         };
303 | 
304 |         // To mock the new OAuth2Client() inside the function
305 |         (OAuth2Client as unknown as Mock).mockImplementation(
306 |           () => mockClient as unknown as OAuth2Client,
307 |         );
308 | 
309 |         await getOauthClient(AuthType.LOGIN_WITH_GOOGLE, mockConfig);
310 | 
311 |         expect(mockClient.setCredentials).toHaveBeenCalledWith(cachedCreds);
312 |         expect(mockClient.getAccessToken).toHaveBeenCalled();
313 |         expect(mockClient.getTokenInfo).toHaveBeenCalled();
314 |         expect(Compute).not.toHaveBeenCalled(); // Should not fetch new client if cache is valid
315 |       });
316 | 
317 |       it('should use Compute to get a client if no cached credentials exist', async () => {
318 |         await getOauthClient(AuthType.CLOUD_SHELL, mockConfig);
319 | 
320 |         expect(Compute).toHaveBeenCalledWith({});
321 |         expect(mockGetAccessToken).toHaveBeenCalled();
322 |       });
323 | 
324 |       it('should not cache the credentials after fetching them via ADC', async () => {
325 |         const newCredentials = { refresh_token: 'new-adc-token' };
326 |         mockComputeClient.credentials = newCredentials;
327 |         mockGetAccessToken.mockResolvedValue({ token: 'new-adc-token' });
328 | 
329 |         await getOauthClient(AuthType.CLOUD_SHELL, mockConfig);
330 | 
331 |         const credsPath = path.join(tempHomeDir, '.gemini', 'oauth_creds.json');
332 |         expect(fs.existsSync(credsPath)).toBe(false);
333 |       });
334 | 
335 |       it('should return the Compute client on successful ADC authentication', async () => {
336 |         const client = await getOauthClient(AuthType.CLOUD_SHELL, mockConfig);
337 |         expect(client).toBe(mockComputeClient);
338 |       });
339 | 
340 |       it('should throw an error if ADC fails', async () => {
341 |         const testError = new Error('ADC Failed');
342 |         mockGetAccessToken.mockRejectedValue(testError);
343 | 
344 |         await expect(
345 |           getOauthClient(AuthType.CLOUD_SHELL, mockConfig),
346 |         ).rejects.toThrow(
347 |           'Could not authenticate using Cloud Shell credentials. Please select a different authentication method or ensure you are in a properly configured environment. Error: ADC Failed',
348 |         );
349 |       });
350 |     });
351 | 
352 |     describe('credential loading order', () => {
353 |       it('should prioritize default cached credentials over GOOGLE_APPLICATION_CREDENTIALS', async () => {
354 |         // Setup default cached credentials
355 |         const defaultCreds = { refresh_token: 'default-cached-token' };
356 |         const defaultCredsPath = path.join(
357 |           tempHomeDir,
358 |           '.gemini',
359 |           'oauth_creds.json',
360 |         );
361 |         await fs.promises.mkdir(path.dirname(defaultCredsPath), {
362 |           recursive: true,
363 |         });
364 |         await fs.promises.writeFile(
365 |           defaultCredsPath,
366 |           JSON.stringify(defaultCreds),
367 |         );
368 | 
369 |         // Setup credentials via environment variable
370 |         const envCreds = { refresh_token: 'env-var-token' };
371 |         const envCredsPath = path.join(tempHomeDir, 'env_creds.json');
372 |         await fs.promises.writeFile(envCredsPath, JSON.stringify(envCreds));
373 |         vi.stubEnv('GOOGLE_APPLICATION_CREDENTIALS', envCredsPath);
374 | 
375 |         const mockClient = {
376 |           setCredentials: vi.fn(),
377 |           getAccessToken: vi.fn().mockResolvedValue({ token: 'test-token' }),
378 |           getTokenInfo: vi.fn().mockResolvedValue({}),
379 |           on: vi.fn(),
380 |         };
381 |         (OAuth2Client as unknown as Mock).mockImplementation(
382 |           () => mockClient as unknown as OAuth2Client,
383 |         );
384 | 
385 |         await getOauthClient(AuthType.LOGIN_WITH_GOOGLE, mockConfig);
386 | 
387 |         // Assert the correct credentials were used
388 |         expect(mockClient.setCredentials).toHaveBeenCalledWith(defaultCreds);
389 |         expect(mockClient.setCredentials).not.toHaveBeenCalledWith(envCreds);
390 |       });
391 | 
392 |       it('should fall back to GOOGLE_APPLICATION_CREDENTIALS if default cache is missing', async () => {
393 |         // Setup credentials via environment variable
394 |         const envCreds = { refresh_token: 'env-var-token' };
395 |         const envCredsPath = path.join(tempHomeDir, 'env_creds.json');
396 |         await fs.promises.writeFile(envCredsPath, JSON.stringify(envCreds));
397 |         vi.stubEnv('GOOGLE_APPLICATION_CREDENTIALS', envCredsPath);
398 | 
399 |         const mockClient = {
400 |           setCredentials: vi.fn(),
401 |           getAccessToken: vi.fn().mockResolvedValue({ token: 'test-token' }),
402 |           getTokenInfo: vi.fn().mockResolvedValue({}),
403 |           on: vi.fn(),
404 |         };
405 |         (OAuth2Client as unknown as Mock).mockImplementation(
406 |           () => mockClient as unknown as OAuth2Client,
407 |         );
408 | 
409 |         await getOauthClient(AuthType.LOGIN_WITH_GOOGLE, mockConfig);
410 | 
411 |         // Assert the correct credentials were used
412 |         expect(mockClient.setCredentials).toHaveBeenCalledWith(envCreds);
413 |       });
414 |     });
415 | 
416 |     describe('with GCP environment variables', () => {
417 |       it('should use GOOGLE_CLOUD_ACCESS_TOKEN when GOOGLE_GENAI_USE_GCA is true', async () => {
418 |         vi.stubEnv('GOOGLE_GENAI_USE_GCA', 'true');
419 |         vi.stubEnv('GOOGLE_CLOUD_ACCESS_TOKEN', 'gcp-access-token');
420 | 
421 |         const mockSetCredentials = vi.fn();
422 |         const mockGetAccessToken = vi
423 |           .fn()
424 |           .mockResolvedValue({ token: 'gcp-access-token' });
425 |         const mockOAuth2Client = {
426 |           setCredentials: mockSetCredentials,
427 |           getAccessToken: mockGetAccessToken,
428 |           on: vi.fn(),
429 |         } as unknown as OAuth2Client;
430 |         (OAuth2Client as unknown as Mock).mockImplementation(
431 |           () => mockOAuth2Client,
432 |         );
433 | 
434 |         // Mock the UserInfo API response for fetchAndCacheUserInfo
435 |         (global.fetch as Mock).mockResolvedValue({
436 |           ok: true,
437 |           json: vi
438 |             .fn()
439 |             .mockResolvedValue({ email: 'test-gcp-account@gmail.com' }),
440 |         } as unknown as Response);
441 | 
442 |         const client = await getOauthClient(
443 |           AuthType.LOGIN_WITH_GOOGLE,
444 |           mockConfig,
445 |         );
446 | 
447 |         expect(client).toBe(mockOAuth2Client);
448 |         expect(mockSetCredentials).toHaveBeenCalledWith({
449 |           access_token: 'gcp-access-token',
450 |         });
451 | 
452 |         // Verify fetchAndCacheUserInfo was effectively called
453 |         expect(mockGetAccessToken).toHaveBeenCalled();
454 |         expect(global.fetch).toHaveBeenCalledWith(
455 |           'https://www.googleapis.com/oauth2/v2/userinfo',
456 |           {
457 |             headers: {
458 |               Authorization: 'Bearer gcp-access-token',
459 |             },
460 |           },
461 |         );
462 | 
463 |         // Verify Google Account was cached
464 |         const googleAccountPath = path.join(
465 |           tempHomeDir,
466 |           '.gemini',
467 |           'google_accounts.json',
468 |         );
469 |         const cachedContent = fs.readFileSync(googleAccountPath, 'utf-8');
470 |         expect(JSON.parse(cachedContent)).toEqual({
471 |           active: 'test-gcp-account@gmail.com',
472 |           old: [],
473 |         });
474 |       });
475 | 
476 |       it('should not use GCP token if GOOGLE_CLOUD_ACCESS_TOKEN is not set', async () => {
477 |         vi.stubEnv('GOOGLE_GENAI_USE_GCA', 'true');
478 | 
479 |         const mockSetCredentials = vi.fn();
480 |         const mockGetAccessToken = vi
481 |           .fn()
482 |           .mockResolvedValue({ token: 'cached-access-token' });
483 |         const mockGetTokenInfo = vi.fn().mockResolvedValue({});
484 |         const mockOAuth2Client = {
485 |           setCredentials: mockSetCredentials,
486 |           getAccessToken: mockGetAccessToken,
487 |           getTokenInfo: mockGetTokenInfo,
488 |           on: vi.fn(),
489 |         } as unknown as OAuth2Client;
490 |         (OAuth2Client as unknown as Mock).mockImplementation(
491 |           () => mockOAuth2Client,
492 |         );
493 | 
494 |         // Make it fall through to cached credentials path
495 |         const cachedCreds = { refresh_token: 'cached-token' };
496 |         const credsPath = path.join(tempHomeDir, '.gemini', 'oauth_creds.json');
497 |         await fs.promises.mkdir(path.dirname(credsPath), { recursive: true });
498 |         await fs.promises.writeFile(credsPath, JSON.stringify(cachedCreds));
499 | 
500 |         await getOauthClient(AuthType.LOGIN_WITH_GOOGLE, mockConfig);
501 | 
502 |         // It should be called with the cached credentials, not the GCP access token.
503 |         expect(mockSetCredentials).toHaveBeenCalledTimes(1);
504 |         expect(mockSetCredentials).toHaveBeenCalledWith(cachedCreds);
505 |       });
506 | 
507 |       it('should not use GCP token if GOOGLE_GENAI_USE_GCA is not set', async () => {
508 |         vi.stubEnv('GOOGLE_CLOUD_ACCESS_TOKEN', 'gcp-access-token');
509 | 
510 |         const mockSetCredentials = vi.fn();
511 |         const mockGetAccessToken = vi
512 |           .fn()
513 |           .mockResolvedValue({ token: 'cached-access-token' });
514 |         const mockGetTokenInfo = vi.fn().mockResolvedValue({});
515 |         const mockOAuth2Client = {
516 |           setCredentials: mockSetCredentials,
517 |           getAccessToken: mockGetAccessToken,
518 |           getTokenInfo: mockGetTokenInfo,
519 |           on: vi.fn(),
520 |         } as unknown as OAuth2Client;
521 |         (OAuth2Client as unknown as Mock).mockImplementation(
522 |           () => mockOAuth2Client,
523 |         );
524 | 
525 |         // Make it fall through to cached credentials path
526 |         const cachedCreds = { refresh_token: 'cached-token' };
527 |         const credsPath = path.join(tempHomeDir, '.gemini', 'oauth_creds.json');
528 |         await fs.promises.mkdir(path.dirname(credsPath), { recursive: true });
529 |         await fs.promises.writeFile(credsPath, JSON.stringify(cachedCreds));
530 | 
531 |         await getOauthClient(AuthType.LOGIN_WITH_GOOGLE, mockConfig);
532 | 
533 |         // It should be called with the cached credentials, not the GCP access token.
534 |         expect(mockSetCredentials).toHaveBeenCalledTimes(1);
535 |         expect(mockSetCredentials).toHaveBeenCalledWith(cachedCreds);
536 |       });
537 |     });
538 | 
539 |     describe('error handling', () => {
540 |       it('should handle browser launch failure with FatalAuthenticationError', async () => {
541 |         const mockError = new Error('Browser launch failed');
542 |         (open as Mock).mockRejectedValue(mockError);
543 | 
544 |         const mockOAuth2Client = {
545 |           generateAuthUrl: vi.fn().mockReturnValue('https://example.com/auth'),
546 |           on: vi.fn(),
547 |         } as unknown as OAuth2Client;
548 |         (OAuth2Client as unknown as Mock).mockImplementation(
549 |           () => mockOAuth2Client,
550 |         );
551 | 
552 |         await expect(
553 |           getOauthClient(AuthType.LOGIN_WITH_GOOGLE, mockConfig),
554 |         ).rejects.toThrow('Failed to open browser: Browser launch failed');
555 |       });
556 | 
557 |       it('should handle authentication timeout with proper error message', async () => {
558 |         const mockAuthUrl = 'https://example.com/auth';
559 |         const mockOAuth2Client = {
560 |           generateAuthUrl: vi.fn().mockReturnValue(mockAuthUrl),
561 |           on: vi.fn(),
562 |         } as unknown as OAuth2Client;
563 |         (OAuth2Client as unknown as Mock).mockImplementation(
564 |           () => mockOAuth2Client,
565 |         );
566 | 
567 |         (open as Mock).mockImplementation(
568 |           async () => ({ on: vi.fn() }) as never,
569 |         );
570 | 
571 |         const mockHttpServer = {
572 |           listen: vi.fn(),
573 |           close: vi.fn(),
574 |           on: vi.fn(),
575 |           address: () => ({ port: 3000 }),
576 |         };
577 |         (http.createServer as Mock).mockImplementation(
578 |           () => mockHttpServer as unknown as http.Server,
579 |         );
580 | 
581 |         // Mock setTimeout to trigger timeout immediately
582 |         const originalSetTimeout = global.setTimeout;
583 |         global.setTimeout = vi.fn(
584 |           (callback) => (callback(), {} as unknown as NodeJS.Timeout),
[TRUNCATED]
```

src/code_assist/oauth2.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Credentials } from 'google-auth-library';
8 | import {
9 |   OAuth2Client,
10 |   Compute,
11 |   CodeChallengeMethod,
12 | } from 'google-auth-library';
13 | import * as http from 'node:http';
14 | import url from 'node:url';
15 | import crypto from 'node:crypto';
16 | import * as net from 'node:net';
17 | import open from 'open';
18 | import path from 'node:path';
19 | import { promises as fs } from 'node:fs';
20 | import type { Config } from '../config/config.js';
21 | import { getErrorMessage, FatalAuthenticationError } from '../utils/errors.js';
22 | import { UserAccountManager } from '../utils/userAccountManager.js';
23 | import { AuthType } from '../core/contentGenerator.js';
24 | import readline from 'node:readline';
25 | import { Storage } from '../config/storage.js';
26 | import { OAuthCredentialStorage } from './oauth-credential-storage.js';
27 | import { FORCE_ENCRYPTED_FILE_ENV_VAR } from '../mcp/token-storage/index.js';
28 | 
29 | const userAccountManager = new UserAccountManager();
30 | 
31 | //  OAuth Client ID used to initiate OAuth2Client class.
32 | const OAUTH_CLIENT_ID =
33 |   '681255809395-oo8ft2oprdrnp9e3aqf6av3hmdib135j.apps.googleusercontent.com';
34 | 
35 | // OAuth Secret value used to initiate OAuth2Client class.
36 | // Note: It's ok to save this in git because this is an installed application
37 | // as described here: https://developers.google.com/identity/protocols/oauth2#installed
38 | // "The process results in a client ID and, in some cases, a client secret,
39 | // which you embed in the source code of your application. (In this context,
40 | // the client secret is obviously not treated as a secret.)"
41 | const OAUTH_CLIENT_SECRET = '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';
42 | 
43 | // OAuth Scopes for Cloud Code authorization.
44 | const OAUTH_SCOPE = [
45 |   'https://www.googleapis.com/auth/cloud-platform',
46 |   'https://www.googleapis.com/auth/userinfo.email',
47 |   'https://www.googleapis.com/auth/userinfo.profile',
48 | ];
49 | 
50 | const HTTP_REDIRECT = 301;
51 | const SIGN_IN_SUCCESS_URL =
52 |   'https://developers.google.com/gemini-code-assist/auth_success_gemini';
53 | const SIGN_IN_FAILURE_URL =
54 |   'https://developers.google.com/gemini-code-assist/auth_failure_gemini';
55 | 
56 | /**
57 |  * An Authentication URL for updating the credentials of a Oauth2Client
58 |  * as well as a promise that will resolve when the credentials have
59 |  * been refreshed (or which throws error when refreshing credentials failed).
60 |  */
61 | export interface OauthWebLogin {
62 |   authUrl: string;
63 |   loginCompletePromise: Promise<void>;
64 | }
65 | 
66 | const oauthClientPromises = new Map<AuthType, Promise<OAuth2Client>>();
67 | 
68 | function getUseEncryptedStorageFlag() {
69 |   return process.env[FORCE_ENCRYPTED_FILE_ENV_VAR] === 'true';
70 | }
71 | 
72 | async function initOauthClient(
73 |   authType: AuthType,
74 |   config: Config,
75 | ): Promise<OAuth2Client> {
76 |   const client = new OAuth2Client({
77 |     clientId: OAUTH_CLIENT_ID,
78 |     clientSecret: OAUTH_CLIENT_SECRET,
79 |     transporterOptions: {
80 |       proxy: config.getProxy(),
81 |     },
82 |   });
83 |   const useEncryptedStorage = getUseEncryptedStorageFlag();
84 | 
85 |   if (
86 |     process.env['GOOGLE_GENAI_USE_GCA'] &&
87 |     process.env['GOOGLE_CLOUD_ACCESS_TOKEN']
88 |   ) {
89 |     client.setCredentials({
90 |       access_token: process.env['GOOGLE_CLOUD_ACCESS_TOKEN'],
91 |     });
92 |     await fetchAndCacheUserInfo(client);
93 |     return client;
94 |   }
95 | 
96 |   client.on('tokens', async (tokens: Credentials) => {
97 |     if (useEncryptedStorage) {
98 |       await OAuthCredentialStorage.saveCredentials(tokens);
99 |     } else {
100 |       await cacheCredentials(tokens);
101 |     }
102 |   });
103 | 
104 |   // If there are cached creds on disk, they always take precedence
105 |   if (await loadCachedCredentials(client)) {
106 |     // Found valid cached credentials.
107 |     // Check if we need to retrieve Google Account ID or Email
108 |     if (!userAccountManager.getCachedGoogleAccount()) {
109 |       try {
110 |         await fetchAndCacheUserInfo(client);
111 |       } catch (error) {
112 |         // Non-fatal, continue with existing auth.
113 |         console.warn('Failed to fetch user info:', getErrorMessage(error));
114 |       }
115 |     }
116 |     console.log('Loaded cached credentials.');
117 |     return client;
118 |   }
119 | 
120 |   // In Google Cloud Shell, we can use Application Default Credentials (ADC)
121 |   // provided via its metadata server to authenticate non-interactively using
122 |   // the identity of the user logged into Cloud Shell.
123 |   if (authType === AuthType.CLOUD_SHELL) {
124 |     try {
125 |       console.log("Attempting to authenticate via Cloud Shell VM's ADC.");
126 |       const computeClient = new Compute({
127 |         // We can leave this empty, since the metadata server will provide
128 |         // the service account email.
129 |       });
130 |       await computeClient.getAccessToken();
131 |       console.log('Authentication successful.');
132 | 
133 |       // Do not cache creds in this case; note that Compute client will handle its own refresh
134 |       return computeClient;
135 |     } catch (e) {
136 |       throw new Error(
137 |         `Could not authenticate using Cloud Shell credentials. Please select a different authentication method or ensure you are in a properly configured environment. Error: ${getErrorMessage(
138 |           e,
139 |         )}`,
140 |       );
141 |     }
142 |   }
143 | 
144 |   if (config.isBrowserLaunchSuppressed()) {
145 |     let success = false;
146 |     const maxRetries = 2;
147 |     for (let i = 0; !success && i < maxRetries; i++) {
148 |       success = await authWithUserCode(client);
149 |       if (!success) {
150 |         console.error(
151 |           '\nFailed to authenticate with user code.',
152 |           i === maxRetries - 1 ? '' : 'Retrying...\n',
153 |         );
154 |       }
155 |     }
156 |     if (!success) {
157 |       throw new FatalAuthenticationError(
158 |         'Failed to authenticate with user code.',
159 |       );
160 |     }
161 |   } else {
162 |     const webLogin = await authWithWeb(client);
163 | 
164 |     console.log(
165 |       `\n\nCode Assist login required.\n` +
166 |         `Attempting to open authentication page in your browser.\n` +
167 |         `Otherwise navigate to:\n\n${webLogin.authUrl}\n\n`,
168 |     );
169 |     try {
170 |       // Attempt to open the authentication URL in the default browser.
171 |       // We do not use the `wait` option here because the main script's execution
172 |       // is already paused by `loginCompletePromise`, which awaits the server callback.
173 |       const childProcess = await open(webLogin.authUrl);
174 | 
175 |       // IMPORTANT: Attach an error handler to the returned child process.
176 |       // Without this, if `open` fails to spawn a process (e.g., `xdg-open` is not found
177 |       // in a minimal Docker container), it will emit an unhandled 'error' event,
178 |       // causing the entire Node.js process to crash.
179 |       childProcess.on('error', (error) => {
180 |         console.error(
181 |           'Failed to open browser automatically. Please try running again with NO_BROWSER=true set.',
182 |         );
183 |         console.error('Browser error details:', getErrorMessage(error));
184 |       });
185 |     } catch (err) {
186 |       console.error(
187 |         'An unexpected error occurred while trying to open the browser:',
188 |         getErrorMessage(err),
189 |         '\nThis might be due to browser compatibility issues or system configuration.',
190 |         '\nPlease try running again with NO_BROWSER=true set for manual authentication.',
191 |       );
192 |       throw new FatalAuthenticationError(
193 |         `Failed to open browser: ${getErrorMessage(err)}`,
194 |       );
195 |     }
196 |     console.log('Waiting for authentication...');
197 | 
198 |     // Add timeout to prevent infinite waiting when browser tab gets stuck
199 |     const authTimeout = 5 * 60 * 1000; // 5 minutes timeout
200 |     const timeoutPromise = new Promise<never>((_, reject) => {
201 |       setTimeout(() => {
202 |         reject(
203 |           new FatalAuthenticationError(
204 |             'Authentication timed out after 5 minutes. The browser tab may have gotten stuck in a loading state. ' +
205 |               'Please try again or use NO_BROWSER=true for manual authentication.',
206 |           ),
207 |         );
208 |       }, authTimeout);
209 |     });
210 | 
211 |     await Promise.race([webLogin.loginCompletePromise, timeoutPromise]);
212 |   }
213 | 
214 |   return client;
215 | }
216 | 
217 | export async function getOauthClient(
218 |   authType: AuthType,
219 |   config: Config,
220 | ): Promise<OAuth2Client> {
221 |   if (!oauthClientPromises.has(authType)) {
222 |     oauthClientPromises.set(authType, initOauthClient(authType, config));
223 |   }
224 |   return oauthClientPromises.get(authType)!;
225 | }
226 | 
227 | async function authWithUserCode(client: OAuth2Client): Promise<boolean> {
228 |   const redirectUri = 'https://codeassist.google.com/authcode';
229 |   const codeVerifier = await client.generateCodeVerifierAsync();
230 |   const state = crypto.randomBytes(32).toString('hex');
231 |   const authUrl: string = client.generateAuthUrl({
232 |     redirect_uri: redirectUri,
233 |     access_type: 'offline',
234 |     scope: OAUTH_SCOPE,
235 |     code_challenge_method: CodeChallengeMethod.S256,
236 |     code_challenge: codeVerifier.codeChallenge,
237 |     state,
238 |   });
239 |   console.log('Please visit the following URL to authorize the application:');
240 |   console.log('');
241 |   console.log(authUrl);
242 |   console.log('');
243 | 
244 |   const code = await new Promise<string>((resolve) => {
245 |     const rl = readline.createInterface({
246 |       input: process.stdin,
247 |       output: process.stdout,
248 |     });
249 |     rl.question('Enter the authorization code: ', (code) => {
250 |       rl.close();
251 |       resolve(code.trim());
252 |     });
253 |   });
254 | 
255 |   if (!code) {
256 |     console.error('Authorization code is required.');
257 |     return false;
258 |   }
259 | 
260 |   try {
261 |     const { tokens } = await client.getToken({
262 |       code,
263 |       codeVerifier: codeVerifier.codeVerifier,
264 |       redirect_uri: redirectUri,
265 |     });
266 |     client.setCredentials(tokens);
267 |   } catch (error) {
268 |     console.error(
269 |       'Failed to authenticate with authorization code:',
270 |       getErrorMessage(error),
271 |     );
272 |     return false;
273 |   }
274 |   return true;
275 | }
276 | 
277 | async function authWithWeb(client: OAuth2Client): Promise<OauthWebLogin> {
278 |   const port = await getAvailablePort();
279 |   // The hostname used for the HTTP server binding (e.g., '0.0.0.0' in Docker).
280 |   const host = process.env['OAUTH_CALLBACK_HOST'] || 'localhost';
281 |   // The `redirectUri` sent to Google's authorization server MUST use a loopback IP literal
282 |   // (i.e., 'localhost' or '127.0.0.1'). This is a strict security policy for credentials of
283 |   // type 'Desktop app' or 'Web application' (when using loopback flow) to mitigate
284 |   // authorization code interception attacks.
285 |   const redirectUri = `http://localhost:${port}/oauth2callback`;
286 |   const state = crypto.randomBytes(32).toString('hex');
287 |   const authUrl = client.generateAuthUrl({
288 |     redirect_uri: redirectUri,
289 |     access_type: 'offline',
290 |     scope: OAUTH_SCOPE,
291 |     state,
292 |   });
293 | 
294 |   const loginCompletePromise = new Promise<void>((resolve, reject) => {
295 |     const server = http.createServer(async (req, res) => {
296 |       try {
297 |         if (req.url!.indexOf('/oauth2callback') === -1) {
298 |           res.writeHead(HTTP_REDIRECT, { Location: SIGN_IN_FAILURE_URL });
299 |           res.end();
300 |           reject(
301 |             new FatalAuthenticationError(
302 |               'OAuth callback not received. Unexpected request: ' + req.url,
303 |             ),
304 |           );
305 |         }
306 |         // acquire the code from the querystring, and close the web server.
307 |         const qs = new url.URL(req.url!, 'http://localhost:3000').searchParams;
308 |         if (qs.get('error')) {
309 |           res.writeHead(HTTP_REDIRECT, { Location: SIGN_IN_FAILURE_URL });
310 |           res.end();
311 | 
312 |           const errorCode = qs.get('error');
313 |           const errorDescription =
314 |             qs.get('error_description') || 'No additional details provided';
315 |           reject(
316 |             new FatalAuthenticationError(
317 |               `Google OAuth error: ${errorCode}. ${errorDescription}`,
318 |             ),
319 |           );
320 |         } else if (qs.get('state') !== state) {
321 |           res.end('State mismatch. Possible CSRF attack');
322 | 
323 |           reject(
324 |             new FatalAuthenticationError(
325 |               'OAuth state mismatch. Possible CSRF attack or browser session issue.',
326 |             ),
327 |           );
328 |         } else if (qs.get('code')) {
329 |           try {
330 |             const { tokens } = await client.getToken({
331 |               code: qs.get('code')!,
332 |               redirect_uri: redirectUri,
333 |             });
334 |             client.setCredentials(tokens);
335 | 
336 |             // Retrieve and cache Google Account ID during authentication
337 |             try {
338 |               await fetchAndCacheUserInfo(client);
339 |             } catch (error) {
340 |               console.warn(
341 |                 'Failed to retrieve Google Account ID during authentication:',
342 |                 getErrorMessage(error),
343 |               );
344 |               // Don't fail the auth flow if Google Account ID retrieval fails
345 |             }
346 | 
347 |             res.writeHead(HTTP_REDIRECT, { Location: SIGN_IN_SUCCESS_URL });
348 |             res.end();
349 |             resolve();
350 |           } catch (error) {
351 |             res.writeHead(HTTP_REDIRECT, { Location: SIGN_IN_FAILURE_URL });
352 |             res.end();
353 |             reject(
354 |               new FatalAuthenticationError(
355 |                 `Failed to exchange authorization code for tokens: ${getErrorMessage(error)}`,
356 |               ),
357 |             );
358 |           }
359 |         } else {
360 |           reject(
361 |             new FatalAuthenticationError(
362 |               'No authorization code received from Google OAuth. Please try authenticating again.',
363 |             ),
364 |           );
365 |         }
366 |       } catch (e) {
367 |         // Provide more specific error message for unexpected errors during OAuth flow
368 |         if (e instanceof FatalAuthenticationError) {
369 |           reject(e);
370 |         } else {
371 |           reject(
372 |             new FatalAuthenticationError(
373 |               `Unexpected error during OAuth authentication: ${getErrorMessage(e)}`,
374 |             ),
375 |           );
376 |         }
377 |       } finally {
378 |         server.close();
379 |       }
380 |     });
381 | 
382 |     server.listen(port, host, () => {
383 |       // Server started successfully
384 |     });
385 | 
386 |     server.on('error', (err) => {
387 |       reject(
388 |         new FatalAuthenticationError(
389 |           `OAuth callback server error: ${getErrorMessage(err)}`,
390 |         ),
391 |       );
392 |     });
393 |   });
394 | 
395 |   return {
396 |     authUrl,
397 |     loginCompletePromise,
398 |   };
399 | }
400 | 
401 | export function getAvailablePort(): Promise<number> {
402 |   return new Promise((resolve, reject) => {
403 |     let port = 0;
404 |     try {
405 |       const portStr = process.env['OAUTH_CALLBACK_PORT'];
406 |       if (portStr) {
407 |         port = parseInt(portStr, 10);
408 |         if (isNaN(port) || port <= 0 || port > 65535) {
409 |           return reject(
410 |             new Error(`Invalid value for OAUTH_CALLBACK_PORT: "${portStr}"`),
411 |           );
412 |         }
413 |         return resolve(port);
414 |       }
415 |       const server = net.createServer();
416 |       server.listen(0, () => {
417 |         const address = server.address()! as net.AddressInfo;
418 |         port = address.port;
419 |       });
420 |       server.on('listening', () => {
421 |         server.close();
422 |         server.unref();
423 |       });
424 |       server.on('error', (e) => reject(e));
425 |       server.on('close', () => resolve(port));
426 |     } catch (e) {
427 |       reject(e);
428 |     }
429 |   });
430 | }
431 | 
432 | async function loadCachedCredentials(client: OAuth2Client): Promise<boolean> {
433 |   const useEncryptedStorage = getUseEncryptedStorageFlag();
434 |   if (useEncryptedStorage) {
435 |     const credentials = await OAuthCredentialStorage.loadCredentials();
436 |     if (credentials) {
437 |       client.setCredentials(credentials);
438 |       return true;
439 |     }
440 |     return false;
441 |   }
442 | 
443 |   const pathsToTry = [
444 |     Storage.getOAuthCredsPath(),
445 |     process.env['GOOGLE_APPLICATION_CREDENTIALS'],
446 |   ].filter((p): p is string => !!p);
447 | 
448 |   for (const keyFile of pathsToTry) {
449 |     try {
450 |       const creds = await fs.readFile(keyFile, 'utf-8');
451 |       client.setCredentials(JSON.parse(creds));
452 | 
453 |       // This will verify locally that the credentials look good.
454 |       const { token } = await client.getAccessToken();
455 |       if (!token) {
456 |         continue;
457 |       }
458 | 
459 |       // This will check with the server to see if it hasn't been revoked.
460 |       await client.getTokenInfo(token);
461 | 
462 |       return true;
463 |     } catch (error) {
464 |       // Log specific error for debugging, but continue trying other paths
465 |       console.debug(
466 |         `Failed to load credentials from ${keyFile}:`,
467 |         getErrorMessage(error),
468 |       );
469 |     }
470 |   }
471 | 
472 |   return false;
473 | }
474 | 
475 | async function cacheCredentials(credentials: Credentials) {
476 |   const filePath = Storage.getOAuthCredsPath();
477 |   await fs.mkdir(path.dirname(filePath), { recursive: true });
478 | 
479 |   const credString = JSON.stringify(credentials, null, 2);
480 |   await fs.writeFile(filePath, credString, { mode: 0o600 });
481 |   try {
482 |     await fs.chmod(filePath, 0o600);
483 |   } catch {
484 |     /* empty */
485 |   }
486 | }
487 | 
488 | export function clearOauthClientCache() {
489 |   oauthClientPromises.clear();
490 | }
491 | 
492 | export async function clearCachedCredentialFile() {
493 |   try {
494 |     const useEncryptedStorage = getUseEncryptedStorageFlag();
495 |     if (useEncryptedStorage) {
496 |       await OAuthCredentialStorage.clearCredentials();
497 |     } else {
498 |       await fs.rm(Storage.getOAuthCredsPath(), { force: true });
499 |     }
500 |     // Clear the Google Account ID cache when credentials are cleared
501 |     await userAccountManager.clearCachedGoogleAccount();
502 |     // Clear the in-memory OAuth client cache to force re-authentication
503 |     clearOauthClientCache();
504 |   } catch (e) {
505 |     console.error('Failed to clear cached credentials:', e);
506 |   }
507 | }
508 | 
509 | async function fetchAndCacheUserInfo(client: OAuth2Client): Promise<void> {
510 |   try {
511 |     const { token } = await client.getAccessToken();
512 |     if (!token) {
513 |       return;
514 |     }
515 | 
516 |     const response = await fetch(
517 |       'https://www.googleapis.com/oauth2/v2/userinfo',
518 |       {
519 |         headers: {
520 |           Authorization: `Bearer ${token}`,
521 |         },
522 |       },
523 |     );
524 | 
525 |     if (!response.ok) {
526 |       console.error(
527 |         'Failed to fetch user info:',
528 |         response.status,
529 |         response.statusText,
530 |       );
531 |       return;
532 |     }
533 | 
534 |     const userInfo = await response.json();
535 |     await userAccountManager.cacheGoogleAccount(userInfo.email);
536 |   } catch (error) {
537 |     console.error('Error retrieving user info:', error);
538 |   }
539 | }
540 | 
541 | // Helper to ensure test isolation
542 | export function resetOauthClientForTesting() {
543 |   oauthClientPromises.clear();
544 | }
```

src/code_assist/server.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { beforeEach, describe, it, expect, vi } from 'vitest';
8 | import { CodeAssistServer } from './server.js';
9 | import { OAuth2Client } from 'google-auth-library';
10 | import { UserTierId } from './types.js';
11 | 
12 | vi.mock('google-auth-library');
13 | 
14 | describe('CodeAssistServer', () => {
15 |   beforeEach(() => {
16 |     vi.resetAllMocks();
17 |   });
18 | 
19 |   it('should be able to be constructed', () => {
20 |     const auth = new OAuth2Client();
21 |     const server = new CodeAssistServer(
22 |       auth,
23 |       'test-project',
24 |       {},
25 |       'test-session',
26 |       UserTierId.FREE,
27 |     );
28 |     expect(server).toBeInstanceOf(CodeAssistServer);
29 |   });
30 | 
31 |   it('should call the generateContent endpoint', async () => {
32 |     const client = new OAuth2Client();
33 |     const server = new CodeAssistServer(
34 |       client,
35 |       'test-project',
36 |       {},
37 |       'test-session',
38 |       UserTierId.FREE,
39 |     );
40 |     const mockResponse = {
41 |       response: {
42 |         candidates: [
43 |           {
44 |             index: 0,
45 |             content: {
46 |               role: 'model',
47 |               parts: [{ text: 'response' }],
48 |             },
49 |             finishReason: 'STOP',
50 |             safetyRatings: [],
51 |           },
52 |         ],
53 |       },
54 |     };
55 |     vi.spyOn(server, 'requestPost').mockResolvedValue(mockResponse);
56 | 
57 |     const response = await server.generateContent(
58 |       {
59 |         model: 'test-model',
60 |         contents: [{ role: 'user', parts: [{ text: 'request' }] }],
61 |       },
62 |       'user-prompt-id',
63 |     );
64 | 
65 |     expect(server.requestPost).toHaveBeenCalledWith(
66 |       'generateContent',
67 |       expect.any(Object),
68 |       undefined,
69 |     );
70 |     expect(response.candidates?.[0]?.content?.parts?.[0]?.text).toBe(
71 |       'response',
72 |     );
73 |   });
74 | 
75 |   it('should call the generateContentStream endpoint', async () => {
76 |     const client = new OAuth2Client();
77 |     const server = new CodeAssistServer(
78 |       client,
79 |       'test-project',
80 |       {},
81 |       'test-session',
82 |       UserTierId.FREE,
83 |     );
84 |     const mockResponse = (async function* () {
85 |       yield {
86 |         response: {
87 |           candidates: [
88 |             {
89 |               index: 0,
90 |               content: {
91 |                 role: 'model',
92 |                 parts: [{ text: 'response' }],
93 |               },
94 |               finishReason: 'STOP',
95 |               safetyRatings: [],
96 |             },
97 |           ],
98 |         },
99 |       };
100 |     })();
101 |     vi.spyOn(server, 'requestStreamingPost').mockResolvedValue(mockResponse);
102 | 
103 |     const stream = await server.generateContentStream(
104 |       {
105 |         model: 'test-model',
106 |         contents: [{ role: 'user', parts: [{ text: 'request' }] }],
107 |       },
108 |       'user-prompt-id',
109 |     );
110 | 
111 |     for await (const res of stream) {
112 |       expect(server.requestStreamingPost).toHaveBeenCalledWith(
113 |         'streamGenerateContent',
114 |         expect.any(Object),
115 |         undefined,
116 |       );
117 |       expect(res.candidates?.[0]?.content?.parts?.[0]?.text).toBe('response');
118 |     }
119 |   });
120 | 
121 |   it('should call the onboardUser endpoint', async () => {
122 |     const client = new OAuth2Client();
123 |     const server = new CodeAssistServer(
124 |       client,
125 |       'test-project',
126 |       {},
127 |       'test-session',
128 |       UserTierId.FREE,
129 |     );
130 |     const mockResponse = {
131 |       name: 'operations/123',
132 |       done: true,
133 |     };
134 |     vi.spyOn(server, 'requestPost').mockResolvedValue(mockResponse);
135 | 
136 |     const response = await server.onboardUser({
137 |       tierId: 'test-tier',
138 |       cloudaicompanionProject: 'test-project',
139 |       metadata: {},
140 |     });
141 | 
142 |     expect(server.requestPost).toHaveBeenCalledWith(
143 |       'onboardUser',
144 |       expect.any(Object),
145 |     );
146 |     expect(response.name).toBe('operations/123');
147 |   });
148 | 
149 |   it('should call the loadCodeAssist endpoint', async () => {
150 |     const client = new OAuth2Client();
151 |     const server = new CodeAssistServer(
152 |       client,
153 |       'test-project',
154 |       {},
155 |       'test-session',
156 |       UserTierId.FREE,
157 |     );
158 |     const mockResponse = {
159 |       currentTier: {
160 |         id: UserTierId.FREE,
161 |         name: 'Free',
162 |         description: 'free tier',
163 |       },
164 |       allowedTiers: [],
165 |       ineligibleTiers: [],
166 |       cloudaicompanionProject: 'projects/test',
167 |     };
168 |     vi.spyOn(server, 'requestPost').mockResolvedValue(mockResponse);
169 | 
170 |     const response = await server.loadCodeAssist({
171 |       metadata: {},
172 |     });
173 | 
174 |     expect(server.requestPost).toHaveBeenCalledWith(
175 |       'loadCodeAssist',
176 |       expect.any(Object),
177 |     );
178 |     expect(response).toEqual(mockResponse);
179 |   });
180 | 
181 |   it('should return 0 for countTokens', async () => {
182 |     const client = new OAuth2Client();
183 |     const server = new CodeAssistServer(
184 |       client,
185 |       'test-project',
186 |       {},
187 |       'test-session',
188 |       UserTierId.FREE,
189 |     );
190 |     const mockResponse = {
191 |       totalTokens: 100,
192 |     };
193 |     vi.spyOn(server, 'requestPost').mockResolvedValue(mockResponse);
194 | 
195 |     const response = await server.countTokens({
196 |       model: 'test-model',
197 |       contents: [{ role: 'user', parts: [{ text: 'request' }] }],
198 |     });
199 |     expect(response.totalTokens).toBe(100);
200 |   });
201 | 
202 |   it('should throw an error for embedContent', async () => {
203 |     const client = new OAuth2Client();
204 |     const server = new CodeAssistServer(
205 |       client,
206 |       'test-project',
207 |       {},
208 |       'test-session',
209 |       UserTierId.FREE,
210 |     );
211 |     await expect(
212 |       server.embedContent({
213 |         model: 'test-model',
214 |         contents: [{ role: 'user', parts: [{ text: 'request' }] }],
215 |       }),
216 |     ).rejects.toThrow();
217 |   });
218 | 
219 |   it('should handle VPC-SC errors when calling loadCodeAssist', async () => {
220 |     const client = new OAuth2Client();
221 |     const server = new CodeAssistServer(
222 |       client,
223 |       'test-project',
224 |       {},
225 |       'test-session',
226 |       UserTierId.FREE,
227 |     );
228 |     const mockVpcScError = {
229 |       response: {
230 |         data: {
231 |           error: {
232 |             details: [
233 |               {
234 |                 reason: 'SECURITY_POLICY_VIOLATED',
235 |               },
236 |             ],
237 |           },
238 |         },
239 |       },
240 |     };
241 |     vi.spyOn(server, 'requestPost').mockRejectedValue(mockVpcScError);
242 | 
243 |     const response = await server.loadCodeAssist({
244 |       metadata: {},
245 |     });
246 | 
247 |     expect(server.requestPost).toHaveBeenCalledWith(
248 |       'loadCodeAssist',
249 |       expect.any(Object),
250 |     );
251 |     expect(response).toEqual({
252 |       currentTier: { id: UserTierId.STANDARD },
253 |     });
254 |   });
255 | });
```

src/code_assist/server.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { OAuth2Client } from 'google-auth-library';
8 | import type {
9 |   CodeAssistGlobalUserSettingResponse,
10 |   GoogleRpcResponse,
11 |   LoadCodeAssistRequest,
12 |   LoadCodeAssistResponse,
13 |   LongRunningOperationResponse,
14 |   OnboardUserRequest,
15 |   SetCodeAssistGlobalUserSettingRequest,
16 | } from './types.js';
17 | import type {
18 |   CountTokensParameters,
19 |   CountTokensResponse,
20 |   EmbedContentParameters,
21 |   EmbedContentResponse,
22 |   GenerateContentParameters,
23 |   GenerateContentResponse,
24 | } from '@google/genai';
25 | import * as readline from 'node:readline';
26 | import type { ContentGenerator } from '../core/contentGenerator.js';
27 | import { UserTierId } from './types.js';
28 | import type {
29 |   CaCountTokenResponse,
30 |   CaGenerateContentResponse,
31 | } from './converter.js';
32 | import {
33 |   fromCountTokenResponse,
34 |   fromGenerateContentResponse,
35 |   toCountTokenRequest,
36 |   toGenerateContentRequest,
37 | } from './converter.js';
38 | 
39 | /** HTTP options to be used in each of the requests. */
40 | export interface HttpOptions {
41 |   /** Additional HTTP headers to be sent with the request. */
42 |   headers?: Record<string, string>;
43 | }
44 | 
45 | export const CODE_ASSIST_ENDPOINT = 'https://cloudcode-pa.googleapis.com';
46 | export const CODE_ASSIST_API_VERSION = 'v1internal';
47 | 
48 | export class CodeAssistServer implements ContentGenerator {
49 |   constructor(
50 |     readonly client: OAuth2Client,
51 |     readonly projectId?: string,
52 |     readonly httpOptions: HttpOptions = {},
53 |     readonly sessionId?: string,
54 |     readonly userTier?: UserTierId,
55 |   ) {}
56 | 
57 |   async generateContentStream(
58 |     req: GenerateContentParameters,
59 |     userPromptId: string,
60 |   ): Promise<AsyncGenerator<GenerateContentResponse>> {
61 |     const resps = await this.requestStreamingPost<CaGenerateContentResponse>(
62 |       'streamGenerateContent',
63 |       toGenerateContentRequest(
64 |         req,
65 |         userPromptId,
66 |         this.projectId,
67 |         this.sessionId,
68 |       ),
69 |       req.config?.abortSignal,
70 |     );
71 |     return (async function* (): AsyncGenerator<GenerateContentResponse> {
72 |       for await (const resp of resps) {
73 |         yield fromGenerateContentResponse(resp);
74 |       }
75 |     })();
76 |   }
77 | 
78 |   async generateContent(
79 |     req: GenerateContentParameters,
80 |     userPromptId: string,
81 |   ): Promise<GenerateContentResponse> {
82 |     const resp = await this.requestPost<CaGenerateContentResponse>(
83 |       'generateContent',
84 |       toGenerateContentRequest(
85 |         req,
86 |         userPromptId,
87 |         this.projectId,
88 |         this.sessionId,
89 |       ),
90 |       req.config?.abortSignal,
91 |     );
92 |     return fromGenerateContentResponse(resp);
93 |   }
94 | 
95 |   async onboardUser(
96 |     req: OnboardUserRequest,
97 |   ): Promise<LongRunningOperationResponse> {
98 |     return await this.requestPost<LongRunningOperationResponse>(
99 |       'onboardUser',
100 |       req,
101 |     );
102 |   }
103 | 
104 |   async loadCodeAssist(
105 |     req: LoadCodeAssistRequest,
106 |   ): Promise<LoadCodeAssistResponse> {
107 |     try {
108 |       return await this.requestPost<LoadCodeAssistResponse>(
109 |         'loadCodeAssist',
110 |         req,
111 |       );
112 |     } catch (e) {
113 |       if (isVpcScAffectedUser(e)) {
114 |         return {
115 |           currentTier: { id: UserTierId.STANDARD },
116 |         };
117 |       } else {
118 |         throw e;
119 |       }
120 |     }
121 |   }
122 | 
123 |   async getCodeAssistGlobalUserSetting(): Promise<CodeAssistGlobalUserSettingResponse> {
124 |     return await this.requestGet<CodeAssistGlobalUserSettingResponse>(
125 |       'getCodeAssistGlobalUserSetting',
126 |     );
127 |   }
128 | 
129 |   async setCodeAssistGlobalUserSetting(
130 |     req: SetCodeAssistGlobalUserSettingRequest,
131 |   ): Promise<CodeAssistGlobalUserSettingResponse> {
132 |     return await this.requestPost<CodeAssistGlobalUserSettingResponse>(
133 |       'setCodeAssistGlobalUserSetting',
134 |       req,
135 |     );
136 |   }
137 | 
138 |   async countTokens(req: CountTokensParameters): Promise<CountTokensResponse> {
139 |     const resp = await this.requestPost<CaCountTokenResponse>(
140 |       'countTokens',
141 |       toCountTokenRequest(req),
142 |     );
143 |     return fromCountTokenResponse(resp);
144 |   }
145 | 
146 |   async embedContent(
147 |     _req: EmbedContentParameters,
148 |   ): Promise<EmbedContentResponse> {
149 |     throw Error();
150 |   }
151 | 
152 |   async requestPost<T>(
153 |     method: string,
154 |     req: object,
155 |     signal?: AbortSignal,
156 |   ): Promise<T> {
157 |     const res = await this.client.request({
158 |       url: this.getMethodUrl(method),
159 |       method: 'POST',
160 |       headers: {
161 |         'Content-Type': 'application/json',
162 |         ...this.httpOptions.headers,
163 |       },
164 |       responseType: 'json',
165 |       body: JSON.stringify(req),
166 |       signal,
167 |     });
168 |     return res.data as T;
169 |   }
170 | 
171 |   async requestGet<T>(method: string, signal?: AbortSignal): Promise<T> {
172 |     const res = await this.client.request({
173 |       url: this.getMethodUrl(method),
174 |       method: 'GET',
175 |       headers: {
176 |         'Content-Type': 'application/json',
177 |         ...this.httpOptions.headers,
178 |       },
179 |       responseType: 'json',
180 |       signal,
181 |     });
182 |     return res.data as T;
183 |   }
184 | 
185 |   async requestStreamingPost<T>(
186 |     method: string,
187 |     req: object,
188 |     signal?: AbortSignal,
189 |   ): Promise<AsyncGenerator<T>> {
190 |     const res = await this.client.request({
191 |       url: this.getMethodUrl(method),
192 |       method: 'POST',
193 |       params: {
194 |         alt: 'sse',
195 |       },
196 |       headers: {
197 |         'Content-Type': 'application/json',
198 |         ...this.httpOptions.headers,
199 |       },
200 |       responseType: 'stream',
201 |       body: JSON.stringify(req),
202 |       signal,
203 |     });
204 | 
205 |     return (async function* (): AsyncGenerator<T> {
206 |       const rl = readline.createInterface({
207 |         input: res.data as NodeJS.ReadableStream,
208 |         crlfDelay: Infinity, // Recognizes '\r\n' and '\n' as line breaks
209 |       });
210 | 
211 |       let bufferedLines: string[] = [];
212 |       for await (const line of rl) {
213 |         // blank lines are used to separate JSON objects in the stream
214 |         if (line === '') {
215 |           if (bufferedLines.length === 0) {
216 |             continue; // no data to yield
217 |           }
218 |           yield JSON.parse(bufferedLines.join('\n')) as T;
219 |           bufferedLines = []; // Reset the buffer after yielding
220 |         } else if (line.startsWith('data: ')) {
221 |           bufferedLines.push(line.slice(6).trim());
222 |         } else {
223 |           throw new Error(`Unexpected line format in response: ${line}`);
224 |         }
225 |       }
226 |     })();
227 |   }
228 | 
229 |   getMethodUrl(method: string): string {
230 |     const endpoint =
231 |       process.env['CODE_ASSIST_ENDPOINT'] ?? CODE_ASSIST_ENDPOINT;
232 |     return `${endpoint}/${CODE_ASSIST_API_VERSION}:${method}`;
233 |   }
234 | }
235 | 
236 | function isVpcScAffectedUser(error: unknown): boolean {
237 |   if (error && typeof error === 'object' && 'response' in error) {
238 |     const gaxiosError = error as {
239 |       response?: {
240 |         data?: unknown;
241 |       };
242 |     };
243 |     const response = gaxiosError.response?.data as
244 |       | GoogleRpcResponse
245 |       | undefined;
246 |     if (Array.isArray(response?.error?.details)) {
247 |       return response.error.details.some(
248 |         (detail) => detail.reason === 'SECURITY_POLICY_VIOLATED',
249 |       );
250 |     }
251 |   }
252 |   return false;
253 | }
```

src/code_assist/setup.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import { setupUser, ProjectIdRequiredError } from './setup.js';
9 | import { CodeAssistServer } from '../code_assist/server.js';
10 | import type { OAuth2Client } from 'google-auth-library';
11 | import type { GeminiUserTier } from './types.js';
12 | import { UserTierId } from './types.js';
13 | 
14 | vi.mock('../code_assist/server.js');
15 | 
16 | const mockPaidTier: GeminiUserTier = {
17 |   id: UserTierId.STANDARD,
18 |   name: 'paid',
19 |   description: 'Paid tier',
20 |   isDefault: true,
21 | };
22 | 
23 | const mockFreeTier: GeminiUserTier = {
24 |   id: UserTierId.FREE,
25 |   name: 'free',
26 |   description: 'Free tier',
27 |   isDefault: true,
28 | };
29 | 
30 | describe('setupUser for existing user', () => {
31 |   let mockLoad: ReturnType<typeof vi.fn>;
32 |   let mockOnboardUser: ReturnType<typeof vi.fn>;
33 | 
34 |   beforeEach(() => {
35 |     vi.resetAllMocks();
36 |     mockLoad = vi.fn();
37 |     mockOnboardUser = vi.fn().mockResolvedValue({
38 |       done: true,
39 |       response: {
40 |         cloudaicompanionProject: {
41 |           id: 'server-project',
42 |         },
43 |       },
44 |     });
45 |     vi.mocked(CodeAssistServer).mockImplementation(
46 |       () =>
47 |         ({
48 |           loadCodeAssist: mockLoad,
49 |           onboardUser: mockOnboardUser,
50 |         }) as unknown as CodeAssistServer,
51 |     );
52 |   });
53 | 
54 |   afterEach(() => {
55 |     vi.unstubAllEnvs();
56 |   });
57 | 
58 |   it('should use GOOGLE_CLOUD_PROJECT when set and project from server is undefined', async () => {
59 |     vi.stubEnv('GOOGLE_CLOUD_PROJECT', 'test-project');
60 |     mockLoad.mockResolvedValue({
61 |       currentTier: mockPaidTier,
62 |     });
63 |     await setupUser({} as OAuth2Client);
64 |     expect(CodeAssistServer).toHaveBeenCalledWith(
65 |       {},
66 |       'test-project',
67 |       {},
68 |       '',
69 |       undefined,
70 |     );
71 |   });
72 | 
73 |   it('should ignore GOOGLE_CLOUD_PROJECT when project from server is set', async () => {
74 |     vi.stubEnv('GOOGLE_CLOUD_PROJECT', 'test-project');
75 |     mockLoad.mockResolvedValue({
76 |       cloudaicompanionProject: 'server-project',
77 |       currentTier: mockPaidTier,
78 |     });
79 |     const projectId = await setupUser({} as OAuth2Client);
80 |     expect(CodeAssistServer).toHaveBeenCalledWith(
81 |       {},
82 |       'test-project',
83 |       {},
84 |       '',
85 |       undefined,
86 |     );
87 |     expect(projectId).toEqual({
88 |       projectId: 'server-project',
89 |       userTier: 'standard-tier',
90 |     });
91 |   });
92 | 
93 |   it('should throw ProjectIdRequiredError when no project ID is available', async () => {
94 |     vi.stubEnv('GOOGLE_CLOUD_PROJECT', '');
95 |     // And the server itself requires a project ID internally
96 |     vi.mocked(CodeAssistServer).mockImplementation(() => {
97 |       throw new ProjectIdRequiredError();
98 |     });
99 | 
100 |     await expect(setupUser({} as OAuth2Client)).rejects.toThrow(
101 |       ProjectIdRequiredError,
102 |     );
103 |   });
104 | });
105 | 
106 | describe('setupUser for new user', () => {
107 |   let mockLoad: ReturnType<typeof vi.fn>;
108 |   let mockOnboardUser: ReturnType<typeof vi.fn>;
109 | 
110 |   beforeEach(() => {
111 |     vi.resetAllMocks();
112 |     mockLoad = vi.fn();
113 |     mockOnboardUser = vi.fn().mockResolvedValue({
114 |       done: true,
115 |       response: {
116 |         cloudaicompanionProject: {
117 |           id: 'server-project',
118 |         },
119 |       },
120 |     });
121 |     vi.mocked(CodeAssistServer).mockImplementation(
122 |       () =>
123 |         ({
124 |           loadCodeAssist: mockLoad,
125 |           onboardUser: mockOnboardUser,
126 |         }) as unknown as CodeAssistServer,
127 |     );
128 |   });
129 | 
130 |   afterEach(() => {
131 |     vi.unstubAllEnvs();
132 |   });
133 | 
134 |   it('should use GOOGLE_CLOUD_PROJECT when set and onboard a new paid user', async () => {
135 |     vi.stubEnv('GOOGLE_CLOUD_PROJECT', 'test-project');
136 |     mockLoad.mockResolvedValue({
137 |       allowedTiers: [mockPaidTier],
138 |     });
139 |     const userData = await setupUser({} as OAuth2Client);
140 |     expect(CodeAssistServer).toHaveBeenCalledWith(
141 |       {},
142 |       'test-project',
143 |       {},
144 |       '',
145 |       undefined,
146 |     );
147 |     expect(mockLoad).toHaveBeenCalled();
148 |     expect(mockOnboardUser).toHaveBeenCalledWith({
149 |       tierId: 'standard-tier',
150 |       cloudaicompanionProject: 'test-project',
151 |       metadata: {
152 |         ideType: 'IDE_UNSPECIFIED',
153 |         platform: 'PLATFORM_UNSPECIFIED',
154 |         pluginType: 'GEMINI',
155 |         duetProject: 'test-project',
156 |       },
157 |     });
158 |     expect(userData).toEqual({
159 |       projectId: 'server-project',
160 |       userTier: 'standard-tier',
161 |     });
162 |   });
163 | 
164 |   it('should onboard a new free user when GOOGLE_CLOUD_PROJECT is not set', async () => {
165 |     vi.stubEnv('GOOGLE_CLOUD_PROJECT', '');
166 |     mockLoad.mockResolvedValue({
167 |       allowedTiers: [mockFreeTier],
168 |     });
169 |     const userData = await setupUser({} as OAuth2Client);
170 |     expect(CodeAssistServer).toHaveBeenCalledWith(
171 |       {},
172 |       undefined,
173 |       {},
174 |       '',
175 |       undefined,
176 |     );
177 |     expect(mockLoad).toHaveBeenCalled();
178 |     expect(mockOnboardUser).toHaveBeenCalledWith({
179 |       tierId: 'free-tier',
180 |       cloudaicompanionProject: undefined,
181 |       metadata: {
182 |         ideType: 'IDE_UNSPECIFIED',
183 |         platform: 'PLATFORM_UNSPECIFIED',
184 |         pluginType: 'GEMINI',
185 |       },
186 |     });
187 |     expect(userData).toEqual({
188 |       projectId: 'server-project',
189 |       userTier: 'free-tier',
190 |     });
191 |   });
192 | 
193 |   it('should use GOOGLE_CLOUD_PROJECT when onboard response has no project ID', async () => {
194 |     vi.stubEnv('GOOGLE_CLOUD_PROJECT', 'test-project');
195 |     mockLoad.mockResolvedValue({
196 |       allowedTiers: [mockPaidTier],
197 |     });
198 |     mockOnboardUser.mockResolvedValue({
199 |       done: true,
200 |       response: {
201 |         cloudaicompanionProject: undefined,
202 |       },
203 |     });
204 |     const userData = await setupUser({} as OAuth2Client);
205 |     expect(userData).toEqual({
206 |       projectId: 'test-project',
207 |       userTier: 'standard-tier',
208 |     });
209 |   });
210 | 
211 |   it('should throw ProjectIdRequiredError when no project ID is available', async () => {
212 |     vi.stubEnv('GOOGLE_CLOUD_PROJECT', '');
213 |     mockLoad.mockResolvedValue({
214 |       allowedTiers: [mockPaidTier],
215 |     });
216 |     mockOnboardUser.mockResolvedValue({
217 |       done: true,
218 |       response: {},
219 |     });
220 |     await expect(setupUser({} as OAuth2Client)).rejects.toThrow(
221 |       ProjectIdRequiredError,
222 |     );
223 |   });
224 | });
```

src/code_assist/setup.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   ClientMetadata,
9 |   GeminiUserTier,
10 |   LoadCodeAssistResponse,
11 |   OnboardUserRequest,
12 | } from './types.js';
13 | import { UserTierId } from './types.js';
14 | import { CodeAssistServer } from './server.js';
15 | import type { OAuth2Client } from 'google-auth-library';
16 | 
17 | export class ProjectIdRequiredError extends Error {
18 |   constructor() {
19 |     super(
20 |       'This account requires setting the GOOGLE_CLOUD_PROJECT or GOOGLE_CLOUD_PROJECT_ID env var. See https://goo.gle/gemini-cli-auth-docs#workspace-gca',
21 |     );
22 |   }
23 | }
24 | 
25 | export interface UserData {
26 |   projectId: string;
27 |   userTier: UserTierId;
28 | }
29 | 
30 | /**
31 |  *
32 |  * @param projectId the user's project id, if any
33 |  * @returns the user's actual project id
34 |  */
35 | export async function setupUser(client: OAuth2Client): Promise<UserData> {
36 |   const projectId =
37 |     process.env['GOOGLE_CLOUD_PROJECT'] ||
38 |     process.env['GOOGLE_CLOUD_PROJECT_ID'] ||
39 |     undefined;
40 |   const caServer = new CodeAssistServer(client, projectId, {}, '', undefined);
41 |   const coreClientMetadata: ClientMetadata = {
42 |     ideType: 'IDE_UNSPECIFIED',
43 |     platform: 'PLATFORM_UNSPECIFIED',
44 |     pluginType: 'GEMINI',
45 |   };
46 | 
47 |   const loadRes = await caServer.loadCodeAssist({
48 |     cloudaicompanionProject: projectId,
49 |     metadata: {
50 |       ...coreClientMetadata,
51 |       duetProject: projectId,
52 |     },
53 |   });
54 | 
55 |   if (loadRes.currentTier) {
56 |     if (!loadRes.cloudaicompanionProject) {
57 |       if (projectId) {
58 |         return {
59 |           projectId,
60 |           userTier: loadRes.currentTier.id,
61 |         };
62 |       }
63 |       throw new ProjectIdRequiredError();
64 |     }
65 |     return {
66 |       projectId: loadRes.cloudaicompanionProject,
67 |       userTier: loadRes.currentTier.id,
68 |     };
69 |   }
70 | 
71 |   const tier = getOnboardTier(loadRes);
72 | 
73 |   let onboardReq: OnboardUserRequest;
74 |   if (tier.id === UserTierId.FREE) {
75 |     // The free tier uses a managed google cloud project. Setting a project in the `onboardUser` request causes a `Precondition Failed` error.
76 |     onboardReq = {
77 |       tierId: tier.id,
78 |       cloudaicompanionProject: undefined,
79 |       metadata: coreClientMetadata,
80 |     };
81 |   } else {
82 |     onboardReq = {
83 |       tierId: tier.id,
84 |       cloudaicompanionProject: projectId,
85 |       metadata: {
86 |         ...coreClientMetadata,
87 |         duetProject: projectId,
88 |       },
89 |     };
90 |   }
91 | 
92 |   // Poll onboardUser until long running operation is complete.
93 |   let lroRes = await caServer.onboardUser(onboardReq);
94 |   while (!lroRes.done) {
95 |     await new Promise((f) => setTimeout(f, 5000));
96 |     lroRes = await caServer.onboardUser(onboardReq);
97 |   }
98 | 
99 |   if (!lroRes.response?.cloudaicompanionProject?.id) {
100 |     if (projectId) {
101 |       return {
102 |         projectId,
103 |         userTier: tier.id,
104 |       };
105 |     }
106 |     throw new ProjectIdRequiredError();
107 |   }
108 | 
109 |   return {
110 |     projectId: lroRes.response.cloudaicompanionProject.id,
111 |     userTier: tier.id,
112 |   };
113 | }
114 | 
115 | function getOnboardTier(res: LoadCodeAssistResponse): GeminiUserTier {
116 |   for (const tier of res.allowedTiers || []) {
117 |     if (tier.isDefault) {
118 |       return tier;
119 |     }
120 |   }
121 |   return {
122 |     name: '',
123 |     description: '',
124 |     id: UserTierId.LEGACY,
125 |     userDefinedCloudaicompanionProject: true,
126 |   };
127 | }
```

src/code_assist/types.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export interface ClientMetadata {
8 |   ideType?: ClientMetadataIdeType;
9 |   ideVersion?: string;
10 |   pluginVersion?: string;
11 |   platform?: ClientMetadataPlatform;
12 |   updateChannel?: string;
13 |   duetProject?: string;
14 |   pluginType?: ClientMetadataPluginType;
15 |   ideName?: string;
16 | }
17 | 
18 | export type ClientMetadataIdeType =
19 |   | 'IDE_UNSPECIFIED'
20 |   | 'VSCODE'
21 |   | 'INTELLIJ'
22 |   | 'VSCODE_CLOUD_WORKSTATION'
23 |   | 'INTELLIJ_CLOUD_WORKSTATION'
24 |   | 'CLOUD_SHELL';
25 | export type ClientMetadataPlatform =
26 |   | 'PLATFORM_UNSPECIFIED'
27 |   | 'DARWIN_AMD64'
28 |   | 'DARWIN_ARM64'
29 |   | 'LINUX_AMD64'
30 |   | 'LINUX_ARM64'
31 |   | 'WINDOWS_AMD64';
32 | export type ClientMetadataPluginType =
33 |   | 'PLUGIN_UNSPECIFIED'
34 |   | 'CLOUD_CODE'
35 |   | 'GEMINI'
36 |   | 'AIPLUGIN_INTELLIJ'
37 |   | 'AIPLUGIN_STUDIO';
38 | 
39 | export interface LoadCodeAssistRequest {
40 |   cloudaicompanionProject?: string;
41 |   metadata: ClientMetadata;
42 | }
43 | 
44 | /**
45 |  * Represents LoadCodeAssistResponse proto json field
46 |  * http://google3/google/internal/cloud/code/v1internal/cloudcode.proto;l=224
47 |  */
48 | export interface LoadCodeAssistResponse {
49 |   currentTier?: GeminiUserTier | null;
50 |   allowedTiers?: GeminiUserTier[] | null;
51 |   ineligibleTiers?: IneligibleTier[] | null;
52 |   cloudaicompanionProject?: string | null;
53 | }
54 | 
55 | /**
56 |  * GeminiUserTier reflects the structure received from the CodeAssist when calling LoadCodeAssist.
57 |  */
58 | export interface GeminiUserTier {
59 |   id: UserTierId;
60 |   name?: string;
61 |   description?: string;
62 |   // This value is used to declare whether a given tier requires the user to configure the project setting on the IDE settings or not.
63 |   userDefinedCloudaicompanionProject?: boolean | null;
64 |   isDefault?: boolean;
65 |   privacyNotice?: PrivacyNotice;
66 |   hasAcceptedTos?: boolean;
67 |   hasOnboardedPreviously?: boolean;
68 | }
69 | 
70 | /**
71 |  * Includes information specifying the reasons for a user's ineligibility for a specific tier.
72 |  * @param reasonCode mnemonic code representing the reason for in-eligibility.
73 |  * @param reasonMessage message to display to the user.
74 |  * @param tierId id of the tier.
75 |  * @param tierName name of the tier.
76 |  */
77 | export interface IneligibleTier {
78 |   reasonCode: IneligibleTierReasonCode;
79 |   reasonMessage: string;
80 |   tierId: UserTierId;
81 |   tierName: string;
82 | }
83 | 
84 | /**
85 |  * List of predefined reason codes when a tier is blocked from a specific tier.
86 |  * https://source.corp.google.com/piper///depot/google3/google/internal/cloud/code/v1internal/cloudcode.proto;l=378
87 |  */
88 | export enum IneligibleTierReasonCode {
89 |   // go/keep-sorted start
90 |   DASHER_USER = 'DASHER_USER',
91 |   INELIGIBLE_ACCOUNT = 'INELIGIBLE_ACCOUNT',
92 |   NON_USER_ACCOUNT = 'NON_USER_ACCOUNT',
93 |   RESTRICTED_AGE = 'RESTRICTED_AGE',
94 |   RESTRICTED_NETWORK = 'RESTRICTED_NETWORK',
95 |   UNKNOWN = 'UNKNOWN',
96 |   UNKNOWN_LOCATION = 'UNKNOWN_LOCATION',
97 |   UNSUPPORTED_LOCATION = 'UNSUPPORTED_LOCATION',
98 |   // go/keep-sorted end
99 | }
100 | /**
101 |  * UserTierId represents IDs returned from the Cloud Code Private API representing a user's tier
102 |  *
103 |  * //depot/google3/cloud/developer_experience/cloudcode/pa/service/usertier.go;l=16
104 |  */
105 | export enum UserTierId {
106 |   FREE = 'free-tier',
107 |   LEGACY = 'legacy-tier',
108 |   STANDARD = 'standard-tier',
109 | }
110 | 
111 | /**
112 |  * PrivacyNotice reflects the structure received from the CodeAssist in regards to a tier
113 |  * privacy notice.
114 |  */
115 | export interface PrivacyNotice {
116 |   showNotice: boolean;
117 |   noticeText?: string;
118 | }
119 | 
120 | /**
121 |  * Proto signature of OnboardUserRequest as payload to OnboardUser call
122 |  */
123 | export interface OnboardUserRequest {
124 |   tierId: string | undefined;
125 |   cloudaicompanionProject: string | undefined;
126 |   metadata: ClientMetadata | undefined;
127 | }
128 | 
129 | /**
130 |  * Represents LongRunningOperation proto
131 |  * http://google3/google/longrunning/operations.proto;rcl=698857719;l=107
132 |  */
133 | export interface LongRunningOperationResponse {
134 |   name: string;
135 |   done?: boolean;
136 |   response?: OnboardUserResponse;
137 | }
138 | 
139 | /**
140 |  * Represents OnboardUserResponse proto
141 |  * http://google3/google/internal/cloud/code/v1internal/cloudcode.proto;l=215
142 |  */
143 | export interface OnboardUserResponse {
144 |   // tslint:disable-next-line:enforce-name-casing This is the name of the field in the proto.
145 |   cloudaicompanionProject?: {
146 |     id: string;
147 |     name: string;
148 |   };
149 | }
150 | 
151 | /**
152 |  * Status code of user license status
153 |  * it does not strictly correspond to the proto
154 |  * Error value is an additional value assigned to error responses from OnboardUser
155 |  */
156 | export enum OnboardUserStatusCode {
157 |   Default = 'DEFAULT',
158 |   Notice = 'NOTICE',
159 |   Warning = 'WARNING',
160 |   Error = 'ERROR',
161 | }
162 | 
163 | /**
164 |  * Status of user onboarded to gemini
165 |  */
166 | export interface OnboardUserStatus {
167 |   statusCode: OnboardUserStatusCode;
168 |   displayMessage: string;
169 |   helpLink: HelpLinkUrl | undefined;
170 | }
171 | 
172 | export interface HelpLinkUrl {
173 |   description: string;
174 |   url: string;
175 | }
176 | 
177 | export interface SetCodeAssistGlobalUserSettingRequest {
178 |   cloudaicompanionProject?: string;
179 |   freeTierDataCollectionOptin: boolean;
180 | }
181 | 
182 | export interface CodeAssistGlobalUserSettingResponse {
183 |   cloudaicompanionProject?: string;
184 |   freeTierDataCollectionOptin: boolean;
185 | }
186 | 
187 | /**
188 |  * Relevant fields that can be returned from a Google RPC response
189 |  */
190 | export interface GoogleRpcResponse {
191 |   error?: {
192 |     details?: GoogleRpcErrorInfo[];
193 |   };
194 | }
195 | 
196 | /**
197 |  * Relevant fields that can be returned in the details of an error returned from GoogleRPCs
198 |  */
199 | interface GoogleRpcErrorInfo {
200 |   reason?: string;
201 | }
```

src/confirmation-bus/index.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export * from './message-bus.js';
8 | export * from './types.js';
```

src/confirmation-bus/message-bus.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, vi } from 'vitest';
8 | import { MessageBus } from './message-bus.js';
9 | import { PolicyEngine } from '../policy/policy-engine.js';
10 | import { PolicyDecision } from '../policy/types.js';
11 | import {
12 |   MessageBusType,
13 |   type ToolConfirmationRequest,
14 |   type ToolConfirmationResponse,
15 |   type ToolPolicyRejection,
16 |   type ToolExecutionSuccess,
17 | } from './types.js';
18 | 
19 | describe('MessageBus', () => {
20 |   let messageBus: MessageBus;
21 |   let policyEngine: PolicyEngine;
22 | 
23 |   beforeEach(() => {
24 |     policyEngine = new PolicyEngine();
25 |     messageBus = new MessageBus(policyEngine);
26 |   });
27 | 
28 |   describe('publish', () => {
29 |     it('should emit error for invalid message', () => {
30 |       const errorHandler = vi.fn();
31 |       messageBus.on('error', errorHandler);
32 | 
33 |       // @ts-expect-error - Testing invalid message
34 |       messageBus.publish({ invalid: 'message' });
35 | 
36 |       expect(errorHandler).toHaveBeenCalledWith(
37 |         expect.objectContaining({
38 |           message: expect.stringContaining('Invalid message structure'),
39 |         }),
40 |       );
41 |     });
42 | 
43 |     it('should validate tool confirmation requests have correlationId', () => {
44 |       const errorHandler = vi.fn();
45 |       messageBus.on('error', errorHandler);
46 | 
47 |       // @ts-expect-error - Testing missing correlationId
48 |       messageBus.publish({
49 |         type: MessageBusType.TOOL_CONFIRMATION_REQUEST,
50 |         toolCall: { name: 'test' },
51 |       });
52 | 
53 |       expect(errorHandler).toHaveBeenCalled();
54 |     });
55 | 
56 |     it('should emit confirmation response when policy allows', () => {
57 |       vi.spyOn(policyEngine, 'check').mockReturnValue(PolicyDecision.ALLOW);
58 | 
59 |       const responseHandler = vi.fn();
60 |       messageBus.subscribe(
61 |         MessageBusType.TOOL_CONFIRMATION_RESPONSE,
62 |         responseHandler,
63 |       );
64 | 
65 |       const request: ToolConfirmationRequest = {
66 |         type: MessageBusType.TOOL_CONFIRMATION_REQUEST,
67 |         toolCall: { name: 'test-tool', args: {} },
68 |         correlationId: '123',
69 |       };
70 | 
71 |       messageBus.publish(request);
72 | 
73 |       const expectedResponse: ToolConfirmationResponse = {
74 |         type: MessageBusType.TOOL_CONFIRMATION_RESPONSE,
75 |         correlationId: '123',
76 |         confirmed: true,
77 |       };
78 |       expect(responseHandler).toHaveBeenCalledWith(expectedResponse);
79 |     });
80 | 
81 |     it('should emit rejection and response when policy denies', () => {
82 |       vi.spyOn(policyEngine, 'check').mockReturnValue(PolicyDecision.DENY);
83 | 
84 |       const responseHandler = vi.fn();
85 |       const rejectionHandler = vi.fn();
86 |       messageBus.subscribe(
87 |         MessageBusType.TOOL_CONFIRMATION_RESPONSE,
88 |         responseHandler,
89 |       );
90 |       messageBus.subscribe(
91 |         MessageBusType.TOOL_POLICY_REJECTION,
92 |         rejectionHandler,
93 |       );
94 | 
95 |       const request: ToolConfirmationRequest = {
96 |         type: MessageBusType.TOOL_CONFIRMATION_REQUEST,
97 |         toolCall: { name: 'test-tool', args: {} },
98 |         correlationId: '123',
99 |       };
100 | 
101 |       messageBus.publish(request);
102 | 
103 |       const expectedRejection: ToolPolicyRejection = {
104 |         type: MessageBusType.TOOL_POLICY_REJECTION,
105 |         toolCall: { name: 'test-tool', args: {} },
106 |       };
107 |       expect(rejectionHandler).toHaveBeenCalledWith(expectedRejection);
108 | 
109 |       const expectedResponse: ToolConfirmationResponse = {
110 |         type: MessageBusType.TOOL_CONFIRMATION_RESPONSE,
111 |         correlationId: '123',
112 |         confirmed: false,
113 |       };
114 |       expect(responseHandler).toHaveBeenCalledWith(expectedResponse);
115 |     });
116 | 
117 |     it('should pass through to UI when policy says ASK_USER', () => {
118 |       vi.spyOn(policyEngine, 'check').mockReturnValue(PolicyDecision.ASK_USER);
119 | 
120 |       const requestHandler = vi.fn();
121 |       messageBus.subscribe(
122 |         MessageBusType.TOOL_CONFIRMATION_REQUEST,
123 |         requestHandler,
124 |       );
125 | 
126 |       const request: ToolConfirmationRequest = {
127 |         type: MessageBusType.TOOL_CONFIRMATION_REQUEST,
128 |         toolCall: { name: 'test-tool', args: {} },
129 |         correlationId: '123',
130 |       };
131 | 
132 |       messageBus.publish(request);
133 | 
134 |       expect(requestHandler).toHaveBeenCalledWith(request);
135 |     });
136 | 
137 |     it('should emit other message types directly', () => {
138 |       const successHandler = vi.fn();
139 |       messageBus.subscribe(
140 |         MessageBusType.TOOL_EXECUTION_SUCCESS,
141 |         successHandler,
142 |       );
143 | 
144 |       const message: ToolExecutionSuccess<string> = {
145 |         type: MessageBusType.TOOL_EXECUTION_SUCCESS as const,
146 |         toolCall: { name: 'test-tool' },
147 |         result: 'success',
148 |       };
149 | 
150 |       messageBus.publish(message);
151 | 
152 |       expect(successHandler).toHaveBeenCalledWith(message);
153 |     });
154 |   });
155 | 
156 |   describe('subscribe/unsubscribe', () => {
157 |     it('should allow subscribing to specific message types', () => {
158 |       const handler = vi.fn();
159 |       messageBus.subscribe(MessageBusType.TOOL_EXECUTION_SUCCESS, handler);
160 | 
161 |       const message: ToolExecutionSuccess<string> = {
162 |         type: MessageBusType.TOOL_EXECUTION_SUCCESS as const,
163 |         toolCall: { name: 'test' },
164 |         result: 'test',
165 |       };
166 | 
167 |       messageBus.publish(message);
168 | 
169 |       expect(handler).toHaveBeenCalledWith(message);
170 |     });
171 | 
172 |     it('should allow unsubscribing from message types', () => {
173 |       const handler = vi.fn();
174 |       messageBus.subscribe(MessageBusType.TOOL_EXECUTION_SUCCESS, handler);
175 |       messageBus.unsubscribe(MessageBusType.TOOL_EXECUTION_SUCCESS, handler);
176 | 
177 |       const message: ToolExecutionSuccess<string> = {
178 |         type: MessageBusType.TOOL_EXECUTION_SUCCESS as const,
179 |         toolCall: { name: 'test' },
180 |         result: 'test',
181 |       };
182 | 
183 |       messageBus.publish(message);
184 | 
185 |       expect(handler).not.toHaveBeenCalled();
186 |     });
187 | 
188 |     it('should support multiple subscribers for the same message type', () => {
189 |       const handler1 = vi.fn();
190 |       const handler2 = vi.fn();
191 | 
192 |       messageBus.subscribe(MessageBusType.TOOL_EXECUTION_SUCCESS, handler1);
193 |       messageBus.subscribe(MessageBusType.TOOL_EXECUTION_SUCCESS, handler2);
194 | 
195 |       const message: ToolExecutionSuccess<string> = {
196 |         type: MessageBusType.TOOL_EXECUTION_SUCCESS as const,
197 |         toolCall: { name: 'test' },
198 |         result: 'test',
199 |       };
200 | 
201 |       messageBus.publish(message);
202 | 
203 |       expect(handler1).toHaveBeenCalledWith(message);
204 |       expect(handler2).toHaveBeenCalledWith(message);
205 |     });
206 |   });
207 | 
208 |   describe('error handling', () => {
209 |     it('should not crash on errors during message processing', () => {
210 |       const errorHandler = vi.fn();
211 |       messageBus.on('error', errorHandler);
212 | 
213 |       // Mock policyEngine to throw an error
214 |       vi.spyOn(policyEngine, 'check').mockImplementation(() => {
215 |         throw new Error('Policy check failed');
216 |       });
217 | 
218 |       const request: ToolConfirmationRequest = {
219 |         type: MessageBusType.TOOL_CONFIRMATION_REQUEST,
220 |         toolCall: { name: 'test-tool' },
221 |         correlationId: '123',
222 |       };
223 | 
224 |       // Should not throw
225 |       expect(() => messageBus.publish(request)).not.toThrow();
226 | 
227 |       // Should emit error
228 |       expect(errorHandler).toHaveBeenCalledWith(
229 |         expect.objectContaining({
230 |           message: 'Policy check failed',
231 |         }),
232 |       );
233 |     });
234 |   });
235 | });
```

src/confirmation-bus/message-bus.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { EventEmitter } from 'node:events';
8 | import type { PolicyEngine } from '../policy/policy-engine.js';
9 | import { PolicyDecision } from '../policy/types.js';
10 | import { MessageBusType, type Message } from './types.js';
11 | import { safeJsonStringify } from '../utils/safeJsonStringify.js';
12 | 
13 | export class MessageBus extends EventEmitter {
14 |   constructor(private readonly policyEngine: PolicyEngine) {
15 |     super();
16 |   }
17 | 
18 |   private isValidMessage(message: Message): boolean {
19 |     if (!message || !message.type) {
20 |       return false;
21 |     }
22 | 
23 |     if (
24 |       message.type === MessageBusType.TOOL_CONFIRMATION_REQUEST &&
25 |       !('correlationId' in message)
26 |     ) {
27 |       return false;
28 |     }
29 | 
30 |     return true;
31 |   }
32 | 
33 |   private emitMessage(message: Message): void {
34 |     this.emit(message.type, message);
35 |   }
36 | 
37 |   publish(message: Message): void {
38 |     try {
39 |       if (!this.isValidMessage(message)) {
40 |         throw new Error(
41 |           `Invalid message structure: ${safeJsonStringify(message)}`,
42 |         );
43 |       }
44 | 
45 |       if (message.type === MessageBusType.TOOL_CONFIRMATION_REQUEST) {
46 |         const decision = this.policyEngine.check(message.toolCall);
47 | 
48 |         switch (decision) {
49 |           case PolicyDecision.ALLOW:
50 |             // Directly emit the response instead of recursive publish
51 |             this.emitMessage({
52 |               type: MessageBusType.TOOL_CONFIRMATION_RESPONSE,
53 |               correlationId: message.correlationId,
54 |               confirmed: true,
55 |             });
56 |             break;
57 |           case PolicyDecision.DENY:
58 |             // Emit both rejection and response messages
59 |             this.emitMessage({
60 |               type: MessageBusType.TOOL_POLICY_REJECTION,
61 |               toolCall: message.toolCall,
62 |             });
63 |             this.emitMessage({
64 |               type: MessageBusType.TOOL_CONFIRMATION_RESPONSE,
65 |               correlationId: message.correlationId,
66 |               confirmed: false,
67 |             });
68 |             break;
69 |           case PolicyDecision.ASK_USER:
70 |             // Pass through to UI for user confirmation
71 |             this.emitMessage(message);
72 |             break;
73 |           default:
74 |             throw new Error(`Unknown policy decision: ${decision}`);
75 |         }
76 |       } else {
77 |         // For all other message types, just emit them
78 |         this.emitMessage(message);
79 |       }
80 |     } catch (error) {
81 |       this.emit('error', error);
82 |     }
83 |   }
84 | 
85 |   subscribe<T extends Message>(
86 |     type: T['type'],
87 |     listener: (message: T) => void,
88 |   ): void {
89 |     this.on(type, listener);
90 |   }
91 | 
92 |   unsubscribe<T extends Message>(
93 |     type: T['type'],
94 |     listener: (message: T) => void,
95 |   ): void {
96 |     this.off(type, listener);
97 |   }
98 | }
```

src/confirmation-bus/types.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { type FunctionCall } from '@google/genai';
8 | 
9 | export enum MessageBusType {
10 |   TOOL_CONFIRMATION_REQUEST = 'tool-confirmation-request',
11 |   TOOL_CONFIRMATION_RESPONSE = 'tool-confirmation-response',
12 |   TOOL_POLICY_REJECTION = 'tool-policy-rejection',
13 |   TOOL_EXECUTION_SUCCESS = 'tool-execution-success',
14 |   TOOL_EXECUTION_FAILURE = 'tool-execution-failure',
15 | }
16 | 
17 | export interface ToolConfirmationRequest {
18 |   type: MessageBusType.TOOL_CONFIRMATION_REQUEST;
19 |   toolCall: FunctionCall;
20 |   correlationId: string;
21 | }
22 | 
23 | export interface ToolConfirmationResponse {
24 |   type: MessageBusType.TOOL_CONFIRMATION_RESPONSE;
25 |   correlationId: string;
26 |   confirmed: boolean;
27 | }
28 | 
29 | export interface ToolPolicyRejection {
30 |   type: MessageBusType.TOOL_POLICY_REJECTION;
31 |   toolCall: FunctionCall;
32 | }
33 | 
34 | export interface ToolExecutionSuccess<T = unknown> {
35 |   type: MessageBusType.TOOL_EXECUTION_SUCCESS;
36 |   toolCall: FunctionCall;
37 |   result: T;
38 | }
39 | 
40 | export interface ToolExecutionFailure<E = Error> {
41 |   type: MessageBusType.TOOL_EXECUTION_FAILURE;
42 |   toolCall: FunctionCall;
43 |   error: E;
44 | }
45 | 
46 | export type Message =
47 |   | ToolConfirmationRequest
48 |   | ToolConfirmationResponse
49 |   | ToolPolicyRejection
50 |   | ToolExecutionSuccess
51 |   | ToolExecutionFailure;
```

src/core/baseLlmClient.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   vi,
12 |   beforeEach,
13 |   afterEach,
14 |   type Mocked,
15 | } from 'vitest';
16 | 
17 | import type { GenerateContentResponse } from '@google/genai';
18 | import { BaseLlmClient, type GenerateJsonOptions } from './baseLlmClient.js';
19 | import type { ContentGenerator } from './contentGenerator.js';
20 | import type { Config } from '../config/config.js';
21 | import { AuthType } from './contentGenerator.js';
22 | import { reportError } from '../utils/errorReporting.js';
23 | import { logMalformedJsonResponse } from '../telemetry/loggers.js';
24 | import { retryWithBackoff } from '../utils/retry.js';
25 | import { MalformedJsonResponseEvent } from '../telemetry/types.js';
26 | import { getErrorMessage } from '../utils/errors.js';
27 | 
28 | vi.mock('../utils/errorReporting.js');
29 | vi.mock('../telemetry/loggers.js');
30 | vi.mock('../utils/errors.js', async (importOriginal) => {
31 |   const actual = await importOriginal<typeof import('../utils/errors.js')>();
32 |   return {
33 |     ...actual,
34 |     getErrorMessage: vi.fn((e) => (e instanceof Error ? e.message : String(e))),
35 |   };
36 | });
37 | 
38 | vi.mock('../utils/retry.js', () => ({
39 |   retryWithBackoff: vi.fn(async (fn, options) => {
40 |     // Default implementation - just call the function
41 |     const result = await fn();
42 | 
43 |     // If shouldRetryOnContent is provided, test it but don't actually retry
44 |     // (unless we want to simulate retry exhaustion for testing)
45 |     if (options?.shouldRetryOnContent) {
46 |       const shouldRetry = options.shouldRetryOnContent(result);
47 |       if (shouldRetry) {
48 |         // Check if we need to simulate retry exhaustion (for error testing)
49 |         const responseText = result?.candidates?.[0]?.content?.parts?.[0]?.text;
50 |         if (
51 |           !responseText ||
52 |           responseText.trim() === '' ||
53 |           responseText.includes('{"color": "blue"')
54 |         ) {
55 |           throw new Error('Retry attempts exhausted for invalid content');
56 |         }
57 |       }
58 |     }
59 | 
60 |     return result;
61 |   }),
62 | }));
63 | 
64 | const mockGenerateContent = vi.fn();
65 | const mockEmbedContent = vi.fn();
66 | 
67 | const mockContentGenerator = {
68 |   generateContent: mockGenerateContent,
69 |   embedContent: mockEmbedContent,
70 | } as unknown as Mocked<ContentGenerator>;
71 | 
72 | const mockConfig = {
73 |   getSessionId: vi.fn().mockReturnValue('test-session-id'),
74 |   getContentGeneratorConfig: vi
75 |     .fn()
76 |     .mockReturnValue({ authType: AuthType.USE_GEMINI }),
77 |   getEmbeddingModel: vi.fn().mockReturnValue('test-embedding-model'),
78 | } as unknown as Mocked<Config>;
79 | 
80 | // Helper to create a mock GenerateContentResponse
81 | const createMockResponse = (text: string): GenerateContentResponse =>
82 |   ({
83 |     candidates: [{ content: { role: 'model', parts: [{ text }] }, index: 0 }],
84 |   }) as GenerateContentResponse;
85 | 
86 | describe('BaseLlmClient', () => {
87 |   let client: BaseLlmClient;
88 |   let abortController: AbortController;
89 |   let defaultOptions: GenerateJsonOptions;
90 | 
91 |   beforeEach(() => {
92 |     vi.clearAllMocks();
93 |     // Reset the mocked implementation for getErrorMessage for accurate error message assertions
94 |     vi.mocked(getErrorMessage).mockImplementation((e) =>
95 |       e instanceof Error ? e.message : String(e),
96 |     );
97 |     client = new BaseLlmClient(mockContentGenerator, mockConfig);
98 |     abortController = new AbortController();
99 |     defaultOptions = {
100 |       contents: [{ role: 'user', parts: [{ text: 'Give me a color.' }] }],
101 |       schema: { type: 'object', properties: { color: { type: 'string' } } },
102 |       model: 'test-model',
103 |       abortSignal: abortController.signal,
104 |       promptId: 'test-prompt-id',
105 |     };
106 |   });
107 | 
108 |   afterEach(() => {
109 |     abortController.abort();
110 |   });
111 | 
112 |   describe('generateJson - Success Scenarios', () => {
113 |     it('should call generateContent with correct parameters, defaults, and utilize retry mechanism', async () => {
114 |       const mockResponse = createMockResponse('{"color": "blue"}');
115 |       mockGenerateContent.mockResolvedValue(mockResponse);
116 | 
117 |       const result = await client.generateJson(defaultOptions);
118 | 
119 |       expect(result).toEqual({ color: 'blue' });
120 | 
121 |       // Ensure the retry mechanism was engaged with shouldRetryOnContent
122 |       expect(retryWithBackoff).toHaveBeenCalledTimes(1);
123 |       expect(retryWithBackoff).toHaveBeenCalledWith(
124 |         expect.any(Function),
125 |         expect.objectContaining({
126 |           shouldRetryOnContent: expect.any(Function),
127 |         }),
128 |       );
129 | 
130 |       // Validate the parameters passed to the underlying generator
131 |       expect(mockGenerateContent).toHaveBeenCalledTimes(1);
132 |       expect(mockGenerateContent).toHaveBeenCalledWith(
133 |         {
134 |           model: 'test-model',
135 |           contents: defaultOptions.contents,
136 |           config: {
137 |             abortSignal: defaultOptions.abortSignal,
138 |             temperature: 0,
139 |             topP: 1,
140 |             responseJsonSchema: defaultOptions.schema,
141 |             responseMimeType: 'application/json',
142 |             // Crucial: systemInstruction should NOT be in the config object if not provided
143 |           },
144 |         },
145 |         'test-prompt-id',
146 |       );
147 |     });
148 | 
149 |     it('should respect configuration overrides', async () => {
150 |       const mockResponse = createMockResponse('{"color": "red"}');
151 |       mockGenerateContent.mockResolvedValue(mockResponse);
152 | 
153 |       const options: GenerateJsonOptions = {
154 |         ...defaultOptions,
155 |         config: { temperature: 0.8, topK: 10 },
156 |       };
157 | 
158 |       await client.generateJson(options);
159 | 
160 |       expect(mockGenerateContent).toHaveBeenCalledWith(
161 |         expect.objectContaining({
162 |           config: expect.objectContaining({
163 |             temperature: 0.8,
164 |             topP: 1, // Default should remain if not overridden
165 |             topK: 10,
166 |           }),
167 |         }),
168 |         expect.any(String),
169 |       );
170 |     });
171 | 
172 |     it('should include system instructions when provided', async () => {
173 |       const mockResponse = createMockResponse('{"color": "green"}');
174 |       mockGenerateContent.mockResolvedValue(mockResponse);
175 |       const systemInstruction = 'You are a helpful assistant.';
176 | 
177 |       const options: GenerateJsonOptions = {
178 |         ...defaultOptions,
179 |         systemInstruction,
180 |       };
181 | 
182 |       await client.generateJson(options);
183 | 
184 |       expect(mockGenerateContent).toHaveBeenCalledWith(
185 |         expect.objectContaining({
186 |           config: expect.objectContaining({
187 |             systemInstruction,
188 |           }),
189 |         }),
190 |         expect.any(String),
191 |       );
192 |     });
193 | 
194 |     it('should use the provided promptId', async () => {
195 |       const mockResponse = createMockResponse('{"color": "yellow"}');
196 |       mockGenerateContent.mockResolvedValue(mockResponse);
197 |       const customPromptId = 'custom-id-123';
198 | 
199 |       const options: GenerateJsonOptions = {
200 |         ...defaultOptions,
201 |         promptId: customPromptId,
202 |       };
203 | 
204 |       await client.generateJson(options);
205 | 
206 |       expect(mockGenerateContent).toHaveBeenCalledWith(
207 |         expect.any(Object),
208 |         customPromptId,
209 |       );
210 |     });
211 | 
212 |     it('should pass maxAttempts to retryWithBackoff when provided', async () => {
213 |       const mockResponse = createMockResponse('{"color": "cyan"}');
214 |       mockGenerateContent.mockResolvedValue(mockResponse);
215 |       const customMaxAttempts = 3;
216 | 
217 |       const options: GenerateJsonOptions = {
218 |         ...defaultOptions,
219 |         maxAttempts: customMaxAttempts,
220 |       };
221 | 
222 |       await client.generateJson(options);
223 | 
224 |       expect(retryWithBackoff).toHaveBeenCalledTimes(1);
225 |       expect(retryWithBackoff).toHaveBeenCalledWith(
226 |         expect.any(Function),
227 |         expect.objectContaining({
228 |           maxAttempts: customMaxAttempts,
229 |         }),
230 |       );
231 |     });
232 | 
233 |     it('should call retryWithBackoff without maxAttempts when not provided', async () => {
234 |       const mockResponse = createMockResponse('{"color": "indigo"}');
235 |       mockGenerateContent.mockResolvedValue(mockResponse);
236 | 
237 |       // No maxAttempts in defaultOptions
238 |       await client.generateJson(defaultOptions);
239 | 
240 |       expect(retryWithBackoff).toHaveBeenCalledWith(
241 |         expect.any(Function),
242 |         expect.objectContaining({
243 |           maxAttempts: 5,
244 |         }),
245 |       );
246 |     });
247 |   });
248 | 
249 |   describe('generateJson - Content Validation and Retries', () => {
250 |     it('should validate content using shouldRetryOnContent function', async () => {
251 |       const mockResponse = createMockResponse('{"color": "blue"}');
252 |       mockGenerateContent.mockResolvedValue(mockResponse);
253 | 
254 |       await client.generateJson(defaultOptions);
255 | 
256 |       // Verify that retryWithBackoff was called with shouldRetryOnContent
257 |       expect(retryWithBackoff).toHaveBeenCalledWith(
258 |         expect.any(Function),
259 |         expect.objectContaining({
260 |           shouldRetryOnContent: expect.any(Function),
261 |         }),
262 |       );
263 | 
264 |       // Test the shouldRetryOnContent function behavior
265 |       const retryCall = vi.mocked(retryWithBackoff).mock.calls[0];
266 |       const shouldRetryOnContent = retryCall[1]?.shouldRetryOnContent;
267 | 
268 |       // Valid JSON should not trigger retry
269 |       expect(shouldRetryOnContent!(mockResponse)).toBe(false);
270 | 
271 |       // Empty response should trigger retry
272 |       expect(shouldRetryOnContent!(createMockResponse(''))).toBe(true);
273 | 
274 |       // Invalid JSON should trigger retry
275 |       expect(
276 |         shouldRetryOnContent!(createMockResponse('{"color": "blue"')),
277 |       ).toBe(true);
278 |     });
279 |   });
280 | 
281 |   describe('generateJson - Response Cleaning', () => {
282 |     it('should clean JSON wrapped in markdown backticks and log telemetry', async () => {
283 |       const malformedResponse = '```json\n{"color": "purple"}\n```';
284 |       mockGenerateContent.mockResolvedValue(
285 |         createMockResponse(malformedResponse),
286 |       );
287 | 
288 |       const result = await client.generateJson(defaultOptions);
289 | 
290 |       expect(result).toEqual({ color: 'purple' });
291 |       expect(logMalformedJsonResponse).toHaveBeenCalledWith(
292 |         mockConfig,
293 |         expect.any(MalformedJsonResponseEvent),
294 |       );
295 |       // Validate the telemetry event content - find the most recent call
296 |       const calls = vi.mocked(logMalformedJsonResponse).mock.calls;
297 |       const lastCall = calls[calls.length - 1];
298 |       const event = lastCall[1] as MalformedJsonResponseEvent;
299 |       expect(event.model).toBe('test-model');
300 |     });
301 | 
302 |     it('should handle extra whitespace correctly without logging malformed telemetry', async () => {
303 |       const responseWithWhitespace = '  \n  {"color": "orange"}  \n';
304 |       mockGenerateContent.mockResolvedValue(
305 |         createMockResponse(responseWithWhitespace),
306 |       );
307 | 
308 |       const result = await client.generateJson(defaultOptions);
309 | 
310 |       expect(result).toEqual({ color: 'orange' });
311 |       expect(logMalformedJsonResponse).not.toHaveBeenCalled();
312 |     });
313 |   });
314 | 
315 |   describe('generateJson - Error Handling', () => {
316 |     it('should throw and report error for empty response after retry exhaustion', async () => {
317 |       mockGenerateContent.mockResolvedValue(createMockResponse(''));
318 | 
319 |       await expect(client.generateJson(defaultOptions)).rejects.toThrow(
320 |         'Failed to generate JSON content: Retry attempts exhausted for invalid content',
321 |       );
322 | 
323 |       // Verify error reporting details
324 |       expect(reportError).toHaveBeenCalledTimes(1);
325 |       expect(reportError).toHaveBeenCalledWith(
326 |         expect.any(Error),
327 |         'API returned invalid content (empty or unparsable JSON) after all retries.',
328 |         defaultOptions.contents,
329 |         'generateJson-invalid-content',
330 |       );
331 |     });
332 | 
333 |     it('should throw and report error for invalid JSON syntax after retry exhaustion', async () => {
334 |       const invalidJson = '{"color": "blue"'; // missing closing brace
335 |       mockGenerateContent.mockResolvedValue(createMockResponse(invalidJson));
336 | 
337 |       await expect(client.generateJson(defaultOptions)).rejects.toThrow(
338 |         'Failed to generate JSON content: Retry attempts exhausted for invalid content',
339 |       );
340 | 
341 |       expect(reportError).toHaveBeenCalledTimes(1);
342 |       expect(reportError).toHaveBeenCalledWith(
343 |         expect.any(Error),
344 |         'API returned invalid content (empty or unparsable JSON) after all retries.',
345 |         defaultOptions.contents,
346 |         'generateJson-invalid-content',
347 |       );
348 |     });
349 | 
350 |     it('should throw and report generic API errors', async () => {
351 |       const apiError = new Error('Service Unavailable (503)');
352 |       // Simulate the generator failing
353 |       mockGenerateContent.mockRejectedValue(apiError);
354 | 
355 |       await expect(client.generateJson(defaultOptions)).rejects.toThrow(
356 |         'Failed to generate JSON content: Service Unavailable (503)',
357 |       );
358 | 
359 |       // Verify generic error reporting
360 |       expect(reportError).toHaveBeenCalledTimes(1);
361 |       expect(reportError).toHaveBeenCalledWith(
362 |         apiError,
363 |         'Error generating JSON content via API.',
364 |         defaultOptions.contents,
365 |         'generateJson-api',
366 |       );
367 |     });
368 | 
369 |     it('should throw immediately without reporting if aborted', async () => {
370 |       const abortError = new DOMException('Aborted', 'AbortError');
371 | 
372 |       // Simulate abortion happening during the API call
373 |       mockGenerateContent.mockImplementation(() => {
374 |         abortController.abort(); // Ensure the signal is aborted when the service checks
375 |         throw abortError;
376 |       });
377 | 
378 |       const options = {
379 |         ...defaultOptions,
380 |         abortSignal: abortController.signal,
381 |       };
382 | 
383 |       await expect(client.generateJson(options)).rejects.toThrow(abortError);
384 | 
385 |       // Crucially, it should not report a cancellation as an application error
386 |       expect(reportError).not.toHaveBeenCalled();
387 |     });
388 |   });
389 | 
390 |   describe('generateEmbedding', () => {
391 |     const texts = ['hello world', 'goodbye world'];
392 |     const testEmbeddingModel = 'test-embedding-model';
393 | 
394 |     it('should call embedContent with correct parameters and return embeddings', async () => {
395 |       const mockEmbeddings = [
396 |         [0.1, 0.2, 0.3],
397 |         [0.4, 0.5, 0.6],
398 |       ];
399 |       mockEmbedContent.mockResolvedValue({
400 |         embeddings: [
401 |           { values: mockEmbeddings[0] },
402 |           { values: mockEmbeddings[1] },
403 |         ],
404 |       });
405 | 
406 |       const result = await client.generateEmbedding(texts);
407 | 
408 |       expect(mockEmbedContent).toHaveBeenCalledTimes(1);
409 |       expect(mockEmbedContent).toHaveBeenCalledWith({
410 |         model: testEmbeddingModel,
411 |         contents: texts,
412 |       });
413 |       expect(result).toEqual(mockEmbeddings);
414 |     });
415 | 
416 |     it('should return an empty array if an empty array is passed', async () => {
417 |       const result = await client.generateEmbedding([]);
418 |       expect(result).toEqual([]);
419 |       expect(mockEmbedContent).not.toHaveBeenCalled();
420 |     });
421 | 
422 |     it('should throw an error if API response has no embeddings array', async () => {
423 |       mockEmbedContent.mockResolvedValue({});
424 | 
425 |       await expect(client.generateEmbedding(texts)).rejects.toThrow(
426 |         'No embeddings found in API response.',
427 |       );
428 |     });
429 | 
430 |     it('should throw an error if API response has an empty embeddings array', async () => {
431 |       mockEmbedContent.mockResolvedValue({
432 |         embeddings: [],
433 |       });
434 | 
435 |       await expect(client.generateEmbedding(texts)).rejects.toThrow(
436 |         'No embeddings found in API response.',
437 |       );
438 |     });
439 | 
440 |     it('should throw an error if API returns a mismatched number of embeddings', async () => {
441 |       mockEmbedContent.mockResolvedValue({
442 |         embeddings: [{ values: [1, 2, 3] }], // Only one for two texts
443 |       });
444 | 
445 |       await expect(client.generateEmbedding(texts)).rejects.toThrow(
446 |         'API returned a mismatched number of embeddings. Expected 2, got 1.',
447 |       );
448 |     });
449 | 
450 |     it('should throw an error if any embedding has nullish values', async () => {
451 |       mockEmbedContent.mockResolvedValue({
452 |         embeddings: [{ values: [1, 2, 3] }, { values: undefined }], // Second one is bad
453 |       });
454 | 
455 |       await expect(client.generateEmbedding(texts)).rejects.toThrow(
456 |         'API returned an empty embedding for input text at index 1: "goodbye world"',
457 |       );
458 |     });
459 | 
460 |     it('should throw an error if any embedding has an empty values array', async () => {
461 |       mockEmbedContent.mockResolvedValue({
462 |         embeddings: [{ values: [] }, { values: [1, 2, 3] }], // First one is bad
463 |       });
464 | 
465 |       await expect(client.generateEmbedding(texts)).rejects.toThrow(
466 |         'API returned an empty embedding for input text at index 0: "hello world"',
467 |       );
468 |     });
469 | 
470 |     it('should propagate errors from the API call', async () => {
471 |       mockEmbedContent.mockRejectedValue(new Error('API Failure'));
472 | 
473 |       await expect(client.generateEmbedding(texts)).rejects.toThrow(
474 |         'API Failure',
475 |       );
476 |     });
477 |   });
478 | });
```

src/core/baseLlmClient.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   Content,
9 |   GenerateContentConfig,
10 |   Part,
11 |   EmbedContentParameters,
12 |   GenerateContentResponse,
13 | } from '@google/genai';
14 | import type { Config } from '../config/config.js';
15 | import type { ContentGenerator } from './contentGenerator.js';
16 | import { getResponseText } from '../utils/partUtils.js';
17 | import { reportError } from '../utils/errorReporting.js';
18 | import { getErrorMessage } from '../utils/errors.js';
19 | import { logMalformedJsonResponse } from '../telemetry/loggers.js';
20 | import { MalformedJsonResponseEvent } from '../telemetry/types.js';
21 | import { retryWithBackoff } from '../utils/retry.js';
22 | 
23 | const DEFAULT_MAX_ATTEMPTS = 5;
24 | 
25 | /**
26 |  * Options for the generateJson utility function.
27 |  */
28 | export interface GenerateJsonOptions {
29 |   /** The input prompt or history. */
30 |   contents: Content[];
31 |   /** The required JSON schema for the output. */
32 |   schema: Record<string, unknown>;
33 |   /** The specific model to use for this task. */
34 |   model: string;
35 |   /**
36 |    * Task-specific system instructions.
37 |    * If omitted, no system instruction is sent.
38 |    */
39 |   systemInstruction?: string | Part | Part[] | Content;
40 |   /**
41 |    * Overrides for generation configuration (e.g., temperature).
42 |    */
43 |   config?: Omit<
44 |     GenerateContentConfig,
45 |     | 'systemInstruction'
46 |     | 'responseJsonSchema'
47 |     | 'responseMimeType'
48 |     | 'tools'
49 |     | 'abortSignal'
50 |   >;
51 |   /** Signal for cancellation. */
52 |   abortSignal: AbortSignal;
53 |   /**
54 |    * A unique ID for the prompt, used for logging/telemetry correlation.
55 |    */
56 |   promptId: string;
57 |   /**
58 |    * The maximum number of attempts for the request.
59 |    */
60 |   maxAttempts?: number;
61 | }
62 | 
63 | /**
64 |  * A client dedicated to stateless, utility-focused LLM calls.
65 |  */
66 | export class BaseLlmClient {
67 |   // Default configuration for utility tasks
68 |   private readonly defaultUtilityConfig: GenerateContentConfig = {
69 |     temperature: 0,
70 |     topP: 1,
71 |   };
72 | 
73 |   constructor(
74 |     private readonly contentGenerator: ContentGenerator,
75 |     private readonly config: Config,
76 |   ) {}
77 | 
78 |   async generateJson(
79 |     options: GenerateJsonOptions,
80 |   ): Promise<Record<string, unknown>> {
81 |     const {
82 |       contents,
83 |       schema,
84 |       model,
85 |       abortSignal,
86 |       systemInstruction,
87 |       promptId,
88 |       maxAttempts,
89 |     } = options;
90 | 
91 |     const requestConfig: GenerateContentConfig = {
92 |       abortSignal,
93 |       ...this.defaultUtilityConfig,
94 |       ...options.config,
95 |       ...(systemInstruction && { systemInstruction }),
96 |       responseJsonSchema: schema,
97 |       responseMimeType: 'application/json',
98 |     };
99 | 
100 |     try {
101 |       const apiCall = () =>
102 |         this.contentGenerator.generateContent(
103 |           {
104 |             model,
105 |             config: requestConfig,
106 |             contents,
107 |           },
108 |           promptId,
109 |         );
110 | 
111 |       const shouldRetryOnContent = (response: GenerateContentResponse) => {
112 |         const text = getResponseText(response)?.trim();
113 |         if (!text) {
114 |           return true; // Retry on empty response
115 |         }
116 |         try {
117 |           JSON.parse(this.cleanJsonResponse(text, model));
118 |           return false;
119 |         } catch (_e) {
120 |           return true;
121 |         }
122 |       };
123 | 
124 |       const result = await retryWithBackoff(apiCall, {
125 |         shouldRetryOnContent,
126 |         maxAttempts: maxAttempts ?? DEFAULT_MAX_ATTEMPTS,
127 |       });
128 | 
129 |       // If we are here, the content is valid (not empty and parsable).
130 |       return JSON.parse(
131 |         this.cleanJsonResponse(getResponseText(result)!.trim(), model),
132 |       );
133 |     } catch (error) {
134 |       if (abortSignal.aborted) {
135 |         throw error;
136 |       }
137 | 
138 |       // Check if the error is from exhausting retries, and report accordingly.
139 |       if (
140 |         error instanceof Error &&
141 |         error.message.includes('Retry attempts exhausted')
142 |       ) {
143 |         await reportError(
144 |           error,
145 |           'API returned invalid content (empty or unparsable JSON) after all retries.',
146 |           contents,
147 |           'generateJson-invalid-content',
148 |         );
149 |       } else {
150 |         await reportError(
151 |           error,
152 |           'Error generating JSON content via API.',
153 |           contents,
154 |           'generateJson-api',
155 |         );
156 |       }
157 | 
158 |       throw new Error(
159 |         `Failed to generate JSON content: ${getErrorMessage(error)}`,
160 |       );
161 |     }
162 |   }
163 | 
164 |   async generateEmbedding(texts: string[]): Promise<number[][]> {
165 |     if (!texts || texts.length === 0) {
166 |       return [];
167 |     }
168 |     const embedModelParams: EmbedContentParameters = {
169 |       model: this.config.getEmbeddingModel(),
170 |       contents: texts,
171 |     };
172 | 
173 |     const embedContentResponse =
174 |       await this.contentGenerator.embedContent(embedModelParams);
175 |     if (
176 |       !embedContentResponse.embeddings ||
177 |       embedContentResponse.embeddings.length === 0
178 |     ) {
179 |       throw new Error('No embeddings found in API response.');
180 |     }
181 | 
182 |     if (embedContentResponse.embeddings.length !== texts.length) {
183 |       throw new Error(
184 |         `API returned a mismatched number of embeddings. Expected ${texts.length}, got ${embedContentResponse.embeddings.length}.`,
185 |       );
186 |     }
187 | 
188 |     return embedContentResponse.embeddings.map((embedding, index) => {
189 |       const values = embedding.values;
190 |       if (!values || values.length === 0) {
191 |         throw new Error(
192 |           `API returned an empty embedding for input text at index ${index}: "${texts[index]}"`,
193 |         );
194 |       }
195 |       return values;
196 |     });
197 |   }
198 | 
199 |   private cleanJsonResponse(text: string, model: string): string {
200 |     const prefix = '```json';
201 |     const suffix = '```';
202 |     if (text.startsWith(prefix) && text.endsWith(suffix)) {
203 |       logMalformedJsonResponse(
204 |         this.config,
205 |         new MalformedJsonResponseEvent(model),
206 |       );
207 |       return text.substring(prefix.length, text.length - suffix.length).trim();
208 |     }
209 |     return text;
210 |   }
211 | }
```

src/core/client.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   vi,
12 |   beforeEach,
13 |   afterEach,
14 |   type Mock,
15 | } from 'vitest';
16 | 
17 | import type { Content, GenerateContentResponse, Part } from '@google/genai';
18 | import {
19 |   findCompressSplitPoint,
20 |   isThinkingDefault,
21 |   isThinkingSupported,
22 |   GeminiClient,
23 | } from './client.js';
24 | import {
25 |   AuthType,
26 |   type ContentGenerator,
27 |   type ContentGeneratorConfig,
28 | } from './contentGenerator.js';
29 | import { type GeminiChat } from './geminiChat.js';
30 | import type { Config } from '../config/config.js';
31 | import {
32 |   CompressionStatus,
33 |   GeminiEventType,
34 |   Turn,
35 |   type ChatCompressionInfo,
36 | } from './turn.js';
37 | import { getCoreSystemPrompt } from './prompts.js';
38 | import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';
39 | import { FileDiscoveryService } from '../services/fileDiscoveryService.js';
40 | import { setSimulate429 } from '../utils/testUtils.js';
41 | import { tokenLimit } from './tokenLimits.js';
42 | import { ideContextStore } from '../ide/ideContext.js';
43 | import { ClearcutLogger } from '../telemetry/clearcut-logger/clearcut-logger.js';
44 | import type { ModelRouterService } from '../routing/modelRouterService.js';
45 | import { uiTelemetryService } from '../telemetry/uiTelemetry.js';
46 | 
47 | // Mock fs module to prevent actual file system operations during tests
48 | const mockFileSystem = new Map<string, string>();
49 | 
50 | vi.mock('node:fs', () => {
51 |   const fsModule = {
52 |     mkdirSync: vi.fn(),
53 |     writeFileSync: vi.fn((path: string, data: string) => {
54 |       mockFileSystem.set(path, data);
55 |     }),
56 |     readFileSync: vi.fn((path: string) => {
57 |       if (mockFileSystem.has(path)) {
58 |         return mockFileSystem.get(path);
59 |       }
60 |       throw Object.assign(new Error('ENOENT: no such file or directory'), {
61 |         code: 'ENOENT',
62 |       });
63 |     }),
64 |     existsSync: vi.fn((path: string) => mockFileSystem.has(path)),
65 |   };
66 | 
67 |   return {
68 |     default: fsModule,
69 |     ...fsModule,
70 |   };
71 | });
72 | 
73 | // --- Mocks ---
74 | const mockTurnRunFn = vi.fn();
75 | 
76 | vi.mock('./turn', async (importOriginal) => {
77 |   const actual = await importOriginal<typeof import('./turn.js')>();
78 |   // Define a mock class that has the same shape as the real Turn
79 |   class MockTurn {
80 |     pendingToolCalls = [];
81 |     // The run method is a property that holds our mock function
82 |     run = mockTurnRunFn;
83 | 
84 |     constructor() {
85 |       // The constructor can be empty or do some mock setup
86 |     }
87 |   }
88 |   // Export the mock class as 'Turn'
89 |   return {
90 |     ...actual,
91 |     Turn: MockTurn,
92 |   };
93 | });
94 | 
95 | vi.mock('../config/config.js');
96 | vi.mock('./prompts');
97 | vi.mock('../utils/getFolderStructure', () => ({
98 |   getFolderStructure: vi.fn().mockResolvedValue('Mock Folder Structure'),
99 | }));
100 | vi.mock('../utils/errorReporting', () => ({ reportError: vi.fn() }));
101 | vi.mock('../utils/nextSpeakerChecker', () => ({
102 |   checkNextSpeaker: vi.fn().mockResolvedValue(null),
103 | }));
104 | vi.mock('../utils/generateContentResponseUtilities', () => ({
105 |   getResponseText: (result: GenerateContentResponse) =>
106 |     result.candidates?.[0]?.content?.parts?.map((part) => part.text).join('') ||
107 |     undefined,
108 | }));
109 | vi.mock('../telemetry/index.js', () => ({
110 |   logApiRequest: vi.fn(),
111 |   logApiResponse: vi.fn(),
112 |   logApiError: vi.fn(),
113 | }));
114 | vi.mock('../ide/ideContext.js');
115 | vi.mock('../telemetry/uiTelemetry.js', () => ({
116 |   uiTelemetryService: {
117 |     setLastPromptTokenCount: vi.fn(),
118 |     getLastPromptTokenCount: vi.fn(),
119 |   },
120 | }));
121 | 
122 | /**
123 |  * Array.fromAsync ponyfill, which will be available in es 2024.
124 |  *
125 |  * Buffers an async generator into an array and returns the result.
126 |  */
127 | async function fromAsync<T>(promise: AsyncGenerator<T>): Promise<readonly T[]> {
128 |   const results: T[] = [];
129 |   for await (const result of promise) {
130 |     results.push(result);
131 |   }
132 |   return results;
133 | }
134 | 
135 | describe('findCompressSplitPoint', () => {
136 |   it('should throw an error for non-positive numbers', () => {
137 |     expect(() => findCompressSplitPoint([], 0)).toThrow(
138 |       'Fraction must be between 0 and 1',
139 |     );
140 |   });
141 | 
142 |   it('should throw an error for a fraction greater than or equal to 1', () => {
143 |     expect(() => findCompressSplitPoint([], 1)).toThrow(
144 |       'Fraction must be between 0 and 1',
145 |     );
146 |   });
147 | 
148 |   it('should handle an empty history', () => {
149 |     expect(findCompressSplitPoint([], 0.5)).toBe(0);
150 |   });
151 | 
152 |   it('should handle a fraction in the middle', () => {
153 |     const history: Content[] = [
154 |       { role: 'user', parts: [{ text: 'This is the first message.' }] }, // JSON length: 66 (19%)
155 |       { role: 'model', parts: [{ text: 'This is the second message.' }] }, // JSON length: 68 (40%)
156 |       { role: 'user', parts: [{ text: 'This is the third message.' }] }, // JSON length: 66 (60%)
157 |       { role: 'model', parts: [{ text: 'This is the fourth message.' }] }, // JSON length: 68 (80%)
158 |       { role: 'user', parts: [{ text: 'This is the fifth message.' }] }, // JSON length: 65 (100%)
159 |     ];
160 |     expect(findCompressSplitPoint(history, 0.5)).toBe(4);
161 |   });
162 | 
163 |   it('should handle a fraction of last index', () => {
164 |     const history: Content[] = [
165 |       { role: 'user', parts: [{ text: 'This is the first message.' }] }, // JSON length: 66 (19%)
166 |       { role: 'model', parts: [{ text: 'This is the second message.' }] }, // JSON length: 68 (40%)
167 |       { role: 'user', parts: [{ text: 'This is the third message.' }] }, // JSON length: 66 (60%)
168 |       { role: 'model', parts: [{ text: 'This is the fourth message.' }] }, // JSON length: 68 (80%)
169 |       { role: 'user', parts: [{ text: 'This is the fifth message.' }] }, // JSON length: 65 (100%)
170 |     ];
171 |     expect(findCompressSplitPoint(history, 0.9)).toBe(4);
172 |   });
173 | 
174 |   it('should handle a fraction of after last index', () => {
175 |     const history: Content[] = [
176 |       { role: 'user', parts: [{ text: 'This is the first message.' }] }, // JSON length: 66 (24%%)
177 |       { role: 'model', parts: [{ text: 'This is the second message.' }] }, // JSON length: 68 (50%)
178 |       { role: 'user', parts: [{ text: 'This is the third message.' }] }, // JSON length: 66 (74%)
179 |       { role: 'model', parts: [{ text: 'This is the fourth message.' }] }, // JSON length: 68 (100%)
180 |     ];
181 |     expect(findCompressSplitPoint(history, 0.8)).toBe(4);
182 |   });
183 | 
184 |   it('should return earlier splitpoint if no valid ones are after threshhold', () => {
185 |     const history: Content[] = [
186 |       { role: 'user', parts: [{ text: 'This is the first message.' }] },
187 |       { role: 'model', parts: [{ text: 'This is the second message.' }] },
188 |       { role: 'user', parts: [{ text: 'This is the third message.' }] },
189 |       { role: 'model', parts: [{ functionCall: {} }] },
190 |     ];
191 |     // Can't return 4 because the previous item has a function call.
192 |     expect(findCompressSplitPoint(history, 0.99)).toBe(2);
193 |   });
194 | 
195 |   it('should handle a history with only one item', () => {
196 |     const historyWithEmptyParts: Content[] = [
197 |       { role: 'user', parts: [{ text: 'Message 1' }] },
198 |     ];
199 |     expect(findCompressSplitPoint(historyWithEmptyParts, 0.5)).toBe(0);
200 |   });
201 | 
202 |   it('should handle history with weird parts', () => {
203 |     const historyWithEmptyParts: Content[] = [
204 |       { role: 'user', parts: [{ text: 'Message 1' }] },
205 |       { role: 'model', parts: [{ fileData: { fileUri: 'derp' } }] },
206 |       { role: 'user', parts: [{ text: 'Message 2' }] },
207 |     ];
208 |     expect(findCompressSplitPoint(historyWithEmptyParts, 0.5)).toBe(2);
209 |   });
210 | });
211 | 
212 | describe('isThinkingSupported', () => {
213 |   it('should return true for gemini-2.5', () => {
214 |     expect(isThinkingSupported('gemini-2.5')).toBe(true);
215 |   });
216 | 
217 |   it('should return true for gemini-2.5-pro', () => {
218 |     expect(isThinkingSupported('gemini-2.5-pro')).toBe(true);
219 |   });
220 | 
221 |   it('should return false for other models', () => {
222 |     expect(isThinkingSupported('gemini-1.5-flash')).toBe(false);
223 |     expect(isThinkingSupported('some-other-model')).toBe(false);
224 |   });
225 | });
226 | 
227 | describe('isThinkingDefault', () => {
228 |   it('should return false for gemini-2.5-flash-lite', () => {
229 |     expect(isThinkingDefault('gemini-2.5-flash-lite')).toBe(false);
230 |   });
231 | 
232 |   it('should return true for gemini-2.5', () => {
233 |     expect(isThinkingDefault('gemini-2.5')).toBe(true);
234 |   });
235 | 
236 |   it('should return true for gemini-2.5-pro', () => {
237 |     expect(isThinkingDefault('gemini-2.5-pro')).toBe(true);
238 |   });
239 | 
240 |   it('should return false for other models', () => {
241 |     expect(isThinkingDefault('gemini-1.5-flash')).toBe(false);
242 |     expect(isThinkingDefault('some-other-model')).toBe(false);
243 |   });
244 | });
245 | 
246 | describe('Gemini Client (client.ts)', () => {
247 |   let mockContentGenerator: ContentGenerator;
248 |   let mockConfig: Config;
249 |   let client: GeminiClient;
250 |   let mockGenerateContentFn: Mock;
251 |   beforeEach(async () => {
252 |     vi.resetAllMocks();
253 |     vi.mocked(uiTelemetryService.setLastPromptTokenCount).mockClear();
254 | 
255 |     mockGenerateContentFn = vi.fn().mockResolvedValue({
256 |       candidates: [{ content: { parts: [{ text: '{"key": "value"}' }] } }],
257 |     });
258 | 
259 |     // Disable 429 simulation for tests
260 |     setSimulate429(false);
261 | 
262 |     mockContentGenerator = {
263 |       generateContent: mockGenerateContentFn,
264 |       generateContentStream: vi.fn(),
265 |       batchEmbedContents: vi.fn(),
266 |     } as unknown as ContentGenerator;
267 | 
268 |     // Because the GeminiClient constructor kicks off an async process (startChat)
269 |     // that depends on a fully-formed Config object, we need to mock the
270 |     // entire implementation of Config for these tests.
271 |     const mockToolRegistry = {
272 |       getFunctionDeclarations: vi.fn().mockReturnValue([]),
273 |       getTool: vi.fn().mockReturnValue(null),
274 |     };
275 |     const fileService = new FileDiscoveryService('/test/dir');
276 |     const contentGeneratorConfig: ContentGeneratorConfig = {
277 |       apiKey: 'test-key',
278 |       vertexai: false,
279 |       authType: AuthType.USE_GEMINI,
280 |     };
281 |     mockConfig = {
282 |       getContentGeneratorConfig: vi
283 |         .fn()
284 |         .mockReturnValue(contentGeneratorConfig),
285 |       getToolRegistry: vi.fn().mockReturnValue(mockToolRegistry),
286 |       getModel: vi.fn().mockReturnValue('test-model'),
287 |       getEmbeddingModel: vi.fn().mockReturnValue('test-embedding-model'),
288 |       getApiKey: vi.fn().mockReturnValue('test-key'),
289 |       getVertexAI: vi.fn().mockReturnValue(false),
290 |       getUserAgent: vi.fn().mockReturnValue('test-agent'),
291 |       getUserMemory: vi.fn().mockReturnValue(''),
292 |       getFullContext: vi.fn().mockReturnValue(false),
293 |       getSessionId: vi.fn().mockReturnValue('test-session-id'),
294 |       getProxy: vi.fn().mockReturnValue(undefined),
295 |       getWorkingDir: vi.fn().mockReturnValue('/test/dir'),
296 |       getFileService: vi.fn().mockReturnValue(fileService),
297 |       getMaxSessionTurns: vi.fn().mockReturnValue(0),
298 |       getQuotaErrorOccurred: vi.fn().mockReturnValue(false),
299 |       setQuotaErrorOccurred: vi.fn(),
300 |       getNoBrowser: vi.fn().mockReturnValue(false),
301 |       getUsageStatisticsEnabled: vi.fn().mockReturnValue(true),
302 |       getIdeModeFeature: vi.fn().mockReturnValue(false),
303 |       getIdeMode: vi.fn().mockReturnValue(true),
304 |       getDebugMode: vi.fn().mockReturnValue(false),
305 |       getWorkspaceContext: vi.fn().mockReturnValue({
306 |         getDirectories: vi.fn().mockReturnValue(['/test/dir']),
307 |       }),
308 |       getGeminiClient: vi.fn(),
309 |       getModelRouterService: vi.fn().mockReturnValue({
310 |         route: vi.fn().mockResolvedValue({ model: 'default-routed-model' }),
311 |       }),
312 |       isInFallbackMode: vi.fn().mockReturnValue(false),
313 |       setFallbackMode: vi.fn(),
314 |       getChatCompression: vi.fn().mockReturnValue(undefined),
315 |       getSkipNextSpeakerCheck: vi.fn().mockReturnValue(false),
316 |       getUseSmartEdit: vi.fn().mockReturnValue(false),
317 |       getUseModelRouter: vi.fn().mockReturnValue(false),
318 |       getContinueOnFailedApiCall: vi.fn(),
319 |       getProjectRoot: vi.fn().mockReturnValue('/test/project/root'),
320 |       storage: {
321 |         getProjectTempDir: vi.fn().mockReturnValue('/test/temp'),
322 |       },
323 |       getContentGenerator: vi.fn().mockReturnValue(mockContentGenerator),
324 |       getBaseLlmClient: vi.fn().mockReturnValue({
325 |         generateJson: vi.fn().mockResolvedValue({
326 |           next_speaker: 'user',
327 |           reasoning: 'test',
328 |         }),
329 |       }),
330 |     } as unknown as Config;
331 | 
332 |     client = new GeminiClient(mockConfig);
333 |     await client.initialize();
334 |     vi.mocked(mockConfig.getGeminiClient).mockReturnValue(client);
335 |   });
336 | 
337 |   afterEach(() => {
338 |     vi.restoreAllMocks();
339 |   });
340 | 
341 |   describe('addHistory', () => {
342 |     it('should call chat.addHistory with the provided content', async () => {
343 |       const mockChat = {
344 |         addHistory: vi.fn(),
345 |       } as unknown as GeminiChat;
346 |       client['chat'] = mockChat;
347 | 
348 |       const newContent = {
349 |         role: 'user',
350 |         parts: [{ text: 'New history item' }],
351 |       };
352 |       await client.addHistory(newContent);
353 | 
354 |       expect(mockChat.addHistory).toHaveBeenCalledWith(newContent);
355 |     });
356 |   });
357 | 
358 |   describe('resetChat', () => {
359 |     it('should create a new chat session, clearing the old history', async () => {
360 |       // 1. Get the initial chat instance and add some history.
361 |       const initialChat = client.getChat();
362 |       const initialHistory = await client.getHistory();
363 |       await client.addHistory({
364 |         role: 'user',
365 |         parts: [{ text: 'some old message' }],
366 |       });
367 |       const historyWithOldMessage = await client.getHistory();
368 |       expect(historyWithOldMessage.length).toBeGreaterThan(
369 |         initialHistory.length,
370 |       );
371 | 
372 |       // 2. Call resetChat.
373 |       await client.resetChat();
374 | 
375 |       // 3. Get the new chat instance and its history.
376 |       const newChat = client.getChat();
377 |       const newHistory = await client.getHistory();
378 | 
379 |       // 4. Assert that the chat instance is new and the history is reset.
380 |       expect(newChat).not.toBe(initialChat);
381 |       expect(newHistory.length).toBe(initialHistory.length);
382 |       expect(JSON.stringify(newHistory)).not.toContain('some old message');
383 |     });
384 |   });
385 | 
386 |   describe('tryCompressChat', () => {
387 |     const mockGetHistory = vi.fn();
388 | 
389 |     beforeEach(() => {
390 |       vi.mock('./tokenLimits', () => ({
391 |         tokenLimit: vi.fn(),
392 |       }));
393 | 
394 |       client['chat'] = {
395 |         getHistory: mockGetHistory,
396 |         addHistory: vi.fn(),
397 |         setHistory: vi.fn(),
398 |       } as unknown as GeminiChat;
399 |     });
400 | 
401 |     function setup({
402 |       chatHistory = [
403 |         { role: 'user', parts: [{ text: 'Long conversation' }] },
404 |         { role: 'model', parts: [{ text: 'Long response' }] },
405 |       ] as Content[],
406 |       originalTokenCount = 1000,
407 |       summaryText = 'This is a summary.',
408 |     } = {}) {
409 |       const mockOriginalChat: Partial<GeminiChat> = {
410 |         getHistory: vi.fn((_curated?: boolean) => chatHistory),
411 |         setHistory: vi.fn(),
412 |       };
413 |       client['chat'] = mockOriginalChat as GeminiChat;
414 | 
415 |       vi.mocked(uiTelemetryService.getLastPromptTokenCount).mockReturnValue(
416 |         originalTokenCount,
417 |       );
418 | 
419 |       mockGenerateContentFn.mockResolvedValue({
420 |         candidates: [
421 |           {
422 |             content: {
423 |               role: 'model',
424 |               parts: [{ text: summaryText }],
425 |             },
426 |           },
427 |         ],
428 |       } as unknown as GenerateContentResponse);
429 | 
430 |       // Calculate what the new history will be
431 |       const splitPoint = findCompressSplitPoint(chatHistory, 0.7); // 1 - 0.3
432 |       const historyToKeep = chatHistory.slice(splitPoint);
433 | 
434 |       // This is the history that the new chat will have.
435 |       // It includes the default startChat history + the extra history from tryCompressChat
436 |       const newCompressedHistory: Content[] = [
437 |         // Mocked envParts + canned response from startChat
438 |         {
439 |           role: 'user',
440 |           parts: [{ text: 'Mocked env context' }],
441 |         },
442 |         {
443 |           role: 'model',
444 |           parts: [{ text: 'Got it. Thanks for the context!' }],
445 |         },
446 |         // extraHistory from tryCompressChat
447 |         {
448 |           role: 'user',
449 |           parts: [{ text: summaryText }],
450 |         },
451 |         {
452 |           role: 'model',
453 |           parts: [{ text: 'Got it. Thanks for the additional context!' }],
454 |         },
455 |         ...historyToKeep,
456 |       ];
457 | 
458 |       const mockNewChat: Partial<GeminiChat> = {
459 |         getHistory: vi.fn().mockReturnValue(newCompressedHistory),
460 |         setHistory: vi.fn(),
461 |       };
462 | 
463 |       client['startChat'] = vi
464 |         .fn()
465 |         .mockResolvedValue(mockNewChat as GeminiChat);
466 | 
467 |       const totalChars = newCompressedHistory.reduce(
468 |         (total, content) => total + JSON.stringify(content).length,
469 |         0,
470 |       );
471 |       const estimatedNewTokenCount = Math.floor(totalChars / 4);
472 | 
473 |       return {
474 |         client,
475 |         mockOriginalChat,
476 |         mockNewChat,
477 |         estimatedNewTokenCount,
478 |       };
479 |     }
480 | 
481 |     describe('when compression inflates the token count', () => {
482 |       it('allows compression to be forced/manual after a failure', async () => {
483 |         // Call 1 (Fails): Setup with a long summary to inflate tokens
484 |         const longSummary = 'long summary '.repeat(100);
485 |         const { client, estimatedNewTokenCount: inflatedTokenCount } = setup({
486 |           originalTokenCount: 100,
487 |           summaryText: longSummary,
488 |         });
489 |         expect(inflatedTokenCount).toBeGreaterThan(100); // Ensure setup is correct
490 | 
491 |         await client.tryCompressChat('prompt-id-4', false); // Fails
492 | 
493 |         // Call 2 (Forced): Re-setup with a short summary
494 |         const shortSummary = 'short';
495 |         const { estimatedNewTokenCount: compressedTokenCount } = setup({
496 |           originalTokenCount: 100,
497 |           summaryText: shortSummary,
498 |         });
499 |         expect(compressedTokenCount).toBeLessThanOrEqual(100); // Ensure setup is correct
500 | 
501 |         const result = await client.tryCompressChat('prompt-id-4', true); // Forced
502 | 
503 |         expect(result).toEqual({
504 |           compressionStatus: CompressionStatus.COMPRESSED,
505 |           newTokenCount: compressedTokenCount,
506 |           originalTokenCount: 100,
507 |         });
508 |       });
509 | 
510 |       it('yields the result even if the compression inflated the tokens', async () => {
511 |         const longSummary = 'long summary '.repeat(100);
512 |         const { client, estimatedNewTokenCount } = setup({
513 |           originalTokenCount: 100,
514 |           summaryText: longSummary,
515 |         });
516 |         expect(estimatedNewTokenCount).toBeGreaterThan(100); // Ensure setup is correct
517 | 
518 |         const result = await client.tryCompressChat('prompt-id-4', false);
519 | 
520 |         expect(result).toEqual({
521 |           compressionStatus:
522 |             CompressionStatus.COMPRESSION_FAILED_INFLATED_TOKEN_COUNT,
523 |           newTokenCount: estimatedNewTokenCount,
524 |           originalTokenCount: 100,
525 |         });
526 |         // IMPORTANT: The change in client.ts means setLastPromptTokenCount is NOT called on failure
527 |         expect(
528 |           uiTelemetryService.setLastPromptTokenCount,
529 |         ).not.toHaveBeenCalled();
530 |       });
531 | 
532 |       it('does not manipulate the source chat', async () => {
533 |         const longSummary = 'long summary '.repeat(100);
534 |         const { client, mockOriginalChat, estimatedNewTokenCount } = setup({
535 |           originalTokenCount: 100,
536 |           summaryText: longSummary,
537 |         });
538 |         expect(estimatedNewTokenCount).toBeGreaterThan(100); // Ensure setup is correct
539 | 
540 |         await client.tryCompressChat('prompt-id-4', false);
541 | 
542 |         // On failure, the chat should NOT be replaced
543 |         expect(client['chat']).toBe(mockOriginalChat);
544 |       });
545 | 
546 |       it('will not attempt to compress context after a failure', async () => {
547 |         const longSummary = 'long summary '.repeat(100);
548 |         const { client, estimatedNewTokenCount } = setup({
549 |           originalTokenCount: 100,
550 |           summaryText: longSummary,
551 |         });
552 |         expect(estimatedNewTokenCount).toBeGreaterThan(100); // Ensure setup is correct
553 | 
554 |         await client.tryCompressChat('prompt-id-4', false); // This fails and sets hasFailedCompressionAttempt = true
555 | 
556 |         // This call should now be a NOOP
557 |         const result = await client.tryCompressChat('prompt-id-5', false);
558 | 
559 |         // generateContent (for summary) should only have been called once
560 |         expect(mockGenerateContentFn).toHaveBeenCalledTimes(1);
561 |         expect(result).toEqual({
562 |           compressionStatus: CompressionStatus.NOOP,
563 |           newTokenCount: 0,
564 |           originalTokenCount: 0,
565 |         });
566 |       });
567 |     });
568 | 
[TRUNCATED]
```

src/core/client.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   GenerateContentConfig,
9 |   PartListUnion,
10 |   Content,
11 |   Tool,
12 |   GenerateContentResponse,
13 | } from '@google/genai';
14 | import {
15 |   getDirectoryContextString,
16 |   getEnvironmentContext,
17 | } from '../utils/environmentContext.js';
18 | import type { ServerGeminiStreamEvent, ChatCompressionInfo } from './turn.js';
19 | import { CompressionStatus } from './turn.js';
20 | import { Turn, GeminiEventType } from './turn.js';
21 | import type { Config } from '../config/config.js';
22 | import { getCoreSystemPrompt, getCompressionPrompt } from './prompts.js';
23 | import { getResponseText } from '../utils/partUtils.js';
24 | import { checkNextSpeaker } from '../utils/nextSpeakerChecker.js';
25 | import { reportError } from '../utils/errorReporting.js';
26 | import { GeminiChat } from './geminiChat.js';
27 | import { retryWithBackoff } from '../utils/retry.js';
28 | import { getErrorMessage } from '../utils/errors.js';
29 | import { tokenLimit } from './tokenLimits.js';
30 | import type { ChatRecordingService } from '../services/chatRecordingService.js';
31 | import type { ContentGenerator } from './contentGenerator.js';
32 | import {
33 |   DEFAULT_GEMINI_FLASH_MODEL,
34 |   DEFAULT_GEMINI_MODEL,
35 |   DEFAULT_GEMINI_MODEL_AUTO,
36 |   DEFAULT_THINKING_MODE,
37 |   getEffectiveModel,
38 | } from '../config/models.js';
39 | import { LoopDetectionService } from '../services/loopDetectionService.js';
40 | import { ideContextStore } from '../ide/ideContext.js';
41 | import {
42 |   logChatCompression,
43 |   logContentRetryFailure,
44 |   logNextSpeakerCheck,
45 | } from '../telemetry/loggers.js';
46 | import {
47 |   ContentRetryFailureEvent,
48 |   makeChatCompressionEvent,
49 |   NextSpeakerCheckEvent,
50 | } from '../telemetry/types.js';
51 | import type { IdeContext, File } from '../ide/types.js';
52 | import { handleFallback } from '../fallback/handler.js';
53 | import type { RoutingContext } from '../routing/routingStrategy.js';
54 | import { uiTelemetryService } from '../telemetry/uiTelemetry.js';
55 | 
56 | export function isThinkingSupported(model: string) {
57 |   return model.startsWith('gemini-2.5') || model === DEFAULT_GEMINI_MODEL_AUTO;
58 | }
59 | 
60 | export function isThinkingDefault(model: string) {
61 |   if (model.startsWith('gemini-2.5-flash-lite')) {
62 |     return false;
63 |   }
64 |   return model.startsWith('gemini-2.5') || model === DEFAULT_GEMINI_MODEL_AUTO;
65 | }
66 | 
67 | /**
68 |  * Returns the index of the oldest item to keep when compressing. May return
69 |  * contents.length which indicates that everything should be compressed.
70 |  *
71 |  * Exported for testing purposes.
72 |  */
73 | export function findCompressSplitPoint(
74 |   contents: Content[],
75 |   fraction: number,
76 | ): number {
77 |   if (fraction <= 0 || fraction >= 1) {
78 |     throw new Error('Fraction must be between 0 and 1');
79 |   }
80 | 
81 |   const charCounts = contents.map((content) => JSON.stringify(content).length);
82 |   const totalCharCount = charCounts.reduce((a, b) => a + b, 0);
83 |   const targetCharCount = totalCharCount * fraction;
84 | 
85 |   let lastSplitPoint = 0; // 0 is always valid (compress nothing)
86 |   let cumulativeCharCount = 0;
87 |   for (let i = 0; i < contents.length; i++) {
88 |     const content = contents[i];
89 |     if (
90 |       content.role === 'user' &&
91 |       !content.parts?.some((part) => !!part.functionResponse)
92 |     ) {
93 |       if (cumulativeCharCount >= targetCharCount) {
94 |         return i;
95 |       }
96 |       lastSplitPoint = i;
97 |     }
98 |     cumulativeCharCount += charCounts[i];
99 |   }
100 | 
101 |   // We found no split points after targetCharCount.
102 |   // Check if it's safe to compress everything.
103 |   const lastContent = contents[contents.length - 1];
104 |   if (
105 |     lastContent?.role === 'model' &&
106 |     !lastContent?.parts?.some((part) => part.functionCall)
107 |   ) {
108 |     return contents.length;
109 |   }
110 | 
111 |   // Can't compress everything so just compress at last splitpoint.
112 |   return lastSplitPoint;
113 | }
114 | 
115 | const MAX_TURNS = 100;
116 | 
117 | /**
118 |  * Threshold for compression token count as a fraction of the model's token limit.
119 |  * If the chat history exceeds this threshold, it will be compressed.
120 |  */
121 | const COMPRESSION_TOKEN_THRESHOLD = 0.7;
122 | 
123 | /**
124 |  * The fraction of the latest chat history to keep. A value of 0.3
125 |  * means that only the last 30% of the chat history will be kept after compression.
126 |  */
127 | const COMPRESSION_PRESERVE_THRESHOLD = 0.3;
128 | 
129 | export class GeminiClient {
130 |   private chat?: GeminiChat;
131 |   private readonly generateContentConfig: GenerateContentConfig = {
132 |     temperature: 0,
133 |     topP: 1,
134 |   };
135 |   private sessionTurnCount = 0;
136 | 
137 |   private readonly loopDetector: LoopDetectionService;
138 |   private lastPromptId: string;
139 |   private currentSequenceModel: string | null = null;
140 |   private lastSentIdeContext: IdeContext | undefined;
141 |   private forceFullIdeContext = true;
142 | 
143 |   /**
144 |    * At any point in this conversation, was compression triggered without
145 |    * being forced and did it fail?
146 |    */
147 |   private hasFailedCompressionAttempt = false;
148 | 
149 |   constructor(private readonly config: Config) {
150 |     this.loopDetector = new LoopDetectionService(config);
151 |     this.lastPromptId = this.config.getSessionId();
152 |   }
153 | 
154 |   async initialize() {
155 |     this.chat = await this.startChat();
156 |   }
157 | 
158 |   private getContentGeneratorOrFail(): ContentGenerator {
159 |     if (!this.config.getContentGenerator()) {
160 |       throw new Error('Content generator not initialized');
161 |     }
162 |     return this.config.getContentGenerator();
163 |   }
164 | 
165 |   async addHistory(content: Content) {
166 |     this.getChat().addHistory(content);
167 |   }
168 | 
169 |   getChat(): GeminiChat {
170 |     if (!this.chat) {
171 |       throw new Error('Chat not initialized');
172 |     }
173 |     return this.chat;
174 |   }
175 | 
176 |   isInitialized(): boolean {
177 |     return this.chat !== undefined;
178 |   }
179 | 
180 |   getHistory(): Content[] {
181 |     return this.getChat().getHistory();
182 |   }
183 | 
184 |   stripThoughtsFromHistory() {
185 |     this.getChat().stripThoughtsFromHistory();
186 |   }
187 | 
188 |   setHistory(history: Content[]) {
189 |     this.getChat().setHistory(history);
190 |     this.forceFullIdeContext = true;
191 |   }
192 | 
193 |   async setTools(): Promise<void> {
194 |     const toolRegistry = this.config.getToolRegistry();
195 |     const toolDeclarations = toolRegistry.getFunctionDeclarations();
196 |     const tools: Tool[] = [{ functionDeclarations: toolDeclarations }];
197 |     this.getChat().setTools(tools);
198 |   }
199 | 
200 |   async resetChat(): Promise<void> {
201 |     this.chat = await this.startChat();
202 |   }
203 | 
204 |   getChatRecordingService(): ChatRecordingService | undefined {
205 |     return this.chat?.getChatRecordingService();
206 |   }
207 | 
208 |   getLoopDetectionService(): LoopDetectionService {
209 |     return this.loopDetector;
210 |   }
211 | 
212 |   getCurrentSequenceModel(): string | null {
213 |     return this.currentSequenceModel;
214 |   }
215 | 
216 |   async addDirectoryContext(): Promise<void> {
217 |     if (!this.chat) {
218 |       return;
219 |     }
220 | 
221 |     this.getChat().addHistory({
222 |       role: 'user',
223 |       parts: [{ text: await getDirectoryContextString(this.config) }],
224 |     });
225 |   }
226 | 
227 |   async startChat(extraHistory?: Content[]): Promise<GeminiChat> {
228 |     this.forceFullIdeContext = true;
229 |     this.hasFailedCompressionAttempt = false;
230 | 
231 |     const toolRegistry = this.config.getToolRegistry();
232 |     const toolDeclarations = toolRegistry.getFunctionDeclarations();
233 |     const tools: Tool[] = [{ functionDeclarations: toolDeclarations }];
234 | 
235 |     // 1. Get the environment context parts as an array
236 |     const envParts = await getEnvironmentContext(this.config);
237 | 
238 |     // 2. Convert the array of parts into a single string
239 |     const envContextString = envParts
240 |       .map((part) => part.text || '')
241 |       .join('\n\n');
242 | 
243 |     // 3. Combine the dynamic context with the static handshake instruction
244 |     const allSetupText = `
245 | ${envContextString}
246 | 
247 | Reminder: Do not return an empty response when a tool call is required.
248 | 
249 | My setup is complete. I will provide my first command in the next turn.
250 |     `.trim();
251 | 
252 |     // 4. Create the history with a single, comprehensive user turn
253 |     const history: Content[] = [
254 |       {
255 |         role: 'user',
256 |         parts: [{ text: allSetupText }],
257 |       },
258 |       ...(extraHistory ?? []),
259 |     ];
260 | 
261 |     try {
262 |       const userMemory = this.config.getUserMemory();
263 |       const systemInstruction = getCoreSystemPrompt(this.config, userMemory);
264 |       const model = this.config.getModel();
265 | 
266 |       const config: GenerateContentConfig = { ...this.generateContentConfig };
267 | 
268 |       if (isThinkingSupported(model)) {
269 |         config.thinkingConfig = {
270 |           includeThoughts: true,
271 |           thinkingBudget: DEFAULT_THINKING_MODE,
272 |         };
273 |       }
274 | 
275 |       return new GeminiChat(
276 |         this.config,
277 |         {
278 |           systemInstruction,
279 |           ...config,
280 |           tools,
281 |         },
282 |         history,
283 |       );
284 |     } catch (error) {
285 |       await reportError(
286 |         error,
287 |         'Error initializing Gemini chat session.',
288 |         history,
289 |         'startChat',
290 |       );
291 |       throw new Error(`Failed to initialize chat: ${getErrorMessage(error)}`);
292 |     }
293 |   }
294 | 
295 |   private getIdeContextParts(forceFullContext: boolean): {
296 |     contextParts: string[];
297 |     newIdeContext: IdeContext | undefined;
298 |   } {
299 |     const currentIdeContext = ideContextStore.get();
300 |     if (!currentIdeContext) {
301 |       return { contextParts: [], newIdeContext: undefined };
302 |     }
303 | 
304 |     if (forceFullContext || !this.lastSentIdeContext) {
305 |       // Send full context as JSON
306 |       const openFiles = currentIdeContext.workspaceState?.openFiles || [];
307 |       const activeFile = openFiles.find((f) => f.isActive);
308 |       const otherOpenFiles = openFiles
309 |         .filter((f) => !f.isActive)
310 |         .map((f) => f.path);
311 | 
312 |       const contextData: Record<string, unknown> = {};
313 | 
314 |       if (activeFile) {
315 |         contextData['activeFile'] = {
316 |           path: activeFile.path,
317 |           cursor: activeFile.cursor
318 |             ? {
319 |                 line: activeFile.cursor.line,
320 |                 character: activeFile.cursor.character,
321 |               }
322 |             : undefined,
323 |           selectedText: activeFile.selectedText || undefined,
324 |         };
325 |       }
326 | 
327 |       if (otherOpenFiles.length > 0) {
328 |         contextData['otherOpenFiles'] = otherOpenFiles;
329 |       }
330 | 
331 |       if (Object.keys(contextData).length === 0) {
332 |         return { contextParts: [], newIdeContext: currentIdeContext };
333 |       }
334 | 
335 |       const jsonString = JSON.stringify(contextData, null, 2);
336 |       const contextParts = [
337 |         "Here is the user's editor context as a JSON object. This is for your information only.",
338 |         '```json',
339 |         jsonString,
340 |         '```',
341 |       ];
342 | 
343 |       if (this.config.getDebugMode()) {
344 |         console.log(contextParts.join('\n'));
345 |       }
346 |       return {
347 |         contextParts,
348 |         newIdeContext: currentIdeContext,
349 |       };
350 |     } else {
351 |       // Calculate and send delta as JSON
352 |       const delta: Record<string, unknown> = {};
353 |       const changes: Record<string, unknown> = {};
354 | 
355 |       const lastFiles = new Map(
356 |         (this.lastSentIdeContext.workspaceState?.openFiles || []).map(
357 |           (f: File) => [f.path, f],
358 |         ),
359 |       );
360 |       const currentFiles = new Map(
361 |         (currentIdeContext.workspaceState?.openFiles || []).map((f: File) => [
362 |           f.path,
363 |           f,
364 |         ]),
365 |       );
366 | 
367 |       const openedFiles: string[] = [];
368 |       for (const [path] of currentFiles.entries()) {
369 |         if (!lastFiles.has(path)) {
370 |           openedFiles.push(path);
371 |         }
372 |       }
373 |       if (openedFiles.length > 0) {
374 |         changes['filesOpened'] = openedFiles;
375 |       }
376 | 
377 |       const closedFiles: string[] = [];
378 |       for (const [path] of lastFiles.entries()) {
379 |         if (!currentFiles.has(path)) {
380 |           closedFiles.push(path);
381 |         }
382 |       }
383 |       if (closedFiles.length > 0) {
384 |         changes['filesClosed'] = closedFiles;
385 |       }
386 | 
387 |       const lastActiveFile = (
388 |         this.lastSentIdeContext.workspaceState?.openFiles || []
389 |       ).find((f: File) => f.isActive);
390 |       const currentActiveFile = (
391 |         currentIdeContext.workspaceState?.openFiles || []
392 |       ).find((f: File) => f.isActive);
393 | 
394 |       if (currentActiveFile) {
395 |         if (!lastActiveFile || lastActiveFile.path !== currentActiveFile.path) {
396 |           changes['activeFileChanged'] = {
397 |             path: currentActiveFile.path,
398 |             cursor: currentActiveFile.cursor
399 |               ? {
400 |                   line: currentActiveFile.cursor.line,
401 |                   character: currentActiveFile.cursor.character,
402 |                 }
403 |               : undefined,
404 |             selectedText: currentActiveFile.selectedText || undefined,
405 |           };
406 |         } else {
407 |           const lastCursor = lastActiveFile.cursor;
408 |           const currentCursor = currentActiveFile.cursor;
409 |           if (
410 |             currentCursor &&
411 |             (!lastCursor ||
412 |               lastCursor.line !== currentCursor.line ||
413 |               lastCursor.character !== currentCursor.character)
414 |           ) {
415 |             changes['cursorMoved'] = {
416 |               path: currentActiveFile.path,
417 |               cursor: {
418 |                 line: currentCursor.line,
419 |                 character: currentCursor.character,
420 |               },
421 |             };
422 |           }
423 | 
424 |           const lastSelectedText = lastActiveFile.selectedText || '';
425 |           const currentSelectedText = currentActiveFile.selectedText || '';
426 |           if (lastSelectedText !== currentSelectedText) {
427 |             changes['selectionChanged'] = {
428 |               path: currentActiveFile.path,
429 |               selectedText: currentSelectedText,
430 |             };
431 |           }
432 |         }
433 |       } else if (lastActiveFile) {
434 |         changes['activeFileChanged'] = {
435 |           path: null,
436 |           previousPath: lastActiveFile.path,
437 |         };
438 |       }
439 | 
440 |       if (Object.keys(changes).length === 0) {
441 |         return { contextParts: [], newIdeContext: currentIdeContext };
442 |       }
443 | 
444 |       delta['changes'] = changes;
445 |       const jsonString = JSON.stringify(delta, null, 2);
446 |       const contextParts = [
447 |         "Here is a summary of changes in the user's editor context, in JSON format. This is for your information only.",
448 |         '```json',
449 |         jsonString,
450 |         '```',
451 |       ];
452 | 
453 |       if (this.config.getDebugMode()) {
454 |         console.log(contextParts.join('\n'));
455 |       }
456 |       return {
457 |         contextParts,
458 |         newIdeContext: currentIdeContext,
459 |       };
460 |     }
461 |   }
462 | 
463 |   private _getEffectiveModelForCurrentTurn(): string {
464 |     if (this.currentSequenceModel) {
465 |       return this.currentSequenceModel;
466 |     }
467 | 
468 |     const configModel = this.config.getModel();
469 |     const model: string =
470 |       configModel === DEFAULT_GEMINI_MODEL_AUTO
471 |         ? DEFAULT_GEMINI_MODEL
472 |         : configModel;
473 |     return getEffectiveModel(this.config.isInFallbackMode(), model);
474 |   }
475 | 
476 |   async *sendMessageStream(
477 |     request: PartListUnion,
478 |     signal: AbortSignal,
479 |     prompt_id: string,
480 |     turns: number = MAX_TURNS,
481 |     isInvalidStreamRetry: boolean = false,
482 |   ): AsyncGenerator<ServerGeminiStreamEvent, Turn> {
483 |     if (this.lastPromptId !== prompt_id) {
484 |       this.loopDetector.reset(prompt_id);
485 |       this.lastPromptId = prompt_id;
486 |       this.currentSequenceModel = null;
487 |     }
488 |     this.sessionTurnCount++;
489 |     if (
490 |       this.config.getMaxSessionTurns() > 0 &&
491 |       this.sessionTurnCount > this.config.getMaxSessionTurns()
492 |     ) {
493 |       yield { type: GeminiEventType.MaxSessionTurns };
494 |       return new Turn(this.getChat(), prompt_id);
495 |     }
496 |     // Ensure turns never exceeds MAX_TURNS to prevent infinite loops
497 |     const boundedTurns = Math.min(turns, MAX_TURNS);
498 |     if (!boundedTurns) {
499 |       return new Turn(this.getChat(), prompt_id);
500 |     }
501 | 
502 |     // Check for context window overflow
503 |     const modelForLimitCheck = this._getEffectiveModelForCurrentTurn();
504 | 
505 |     const estimatedRequestTokenCount = Math.floor(
506 |       JSON.stringify(request).length / 4,
507 |     );
508 | 
509 |     const remainingTokenCount =
510 |       tokenLimit(modelForLimitCheck) -
511 |       uiTelemetryService.getLastPromptTokenCount();
512 | 
513 |     if (estimatedRequestTokenCount > remainingTokenCount * 0.95) {
514 |       yield {
515 |         type: GeminiEventType.ContextWindowWillOverflow,
516 |         value: { estimatedRequestTokenCount, remainingTokenCount },
517 |       };
518 |       return new Turn(this.getChat(), prompt_id);
519 |     }
520 | 
521 |     const compressed = await this.tryCompressChat(prompt_id, false);
522 | 
523 |     if (compressed.compressionStatus === CompressionStatus.COMPRESSED) {
524 |       yield { type: GeminiEventType.ChatCompressed, value: compressed };
525 |     }
526 | 
527 |     // Prevent context updates from being sent while a tool call is
528 |     // waiting for a response. The Gemini API requires that a functionResponse
529 |     // part from the user immediately follows a functionCall part from the model
530 |     // in the conversation history . The IDE context is not discarded; it will
531 |     // be included in the next regular message sent to the model.
532 |     const history = this.getHistory();
533 |     const lastMessage =
534 |       history.length > 0 ? history[history.length - 1] : undefined;
535 |     const hasPendingToolCall =
536 |       !!lastMessage &&
537 |       lastMessage.role === 'model' &&
538 |       (lastMessage.parts?.some((p) => 'functionCall' in p) || false);
539 | 
540 |     if (this.config.getIdeMode() && !hasPendingToolCall) {
541 |       const { contextParts, newIdeContext } = this.getIdeContextParts(
542 |         this.forceFullIdeContext || history.length === 0,
543 |       );
544 |       if (contextParts.length > 0) {
545 |         this.getChat().addHistory({
546 |           role: 'user',
547 |           parts: [{ text: contextParts.join('\n') }],
548 |         });
549 |       }
550 |       this.lastSentIdeContext = newIdeContext;
551 |       this.forceFullIdeContext = false;
552 |     }
553 | 
554 |     const turn = new Turn(this.getChat(), prompt_id);
555 | 
556 |     const controller = new AbortController();
557 |     const linkedSignal = AbortSignal.any([signal, controller.signal]);
558 | 
559 |     const loopDetected = await this.loopDetector.turnStarted(signal);
560 |     if (loopDetected) {
561 |       yield { type: GeminiEventType.LoopDetected };
562 |       return turn;
563 |     }
564 | 
565 |     const routingContext: RoutingContext = {
566 |       history: this.getChat().getHistory(/*curated=*/ true),
567 |       request,
568 |       signal,
569 |     };
570 | 
571 |     let modelToUse: string;
572 | 
573 |     // Determine Model (Stickiness vs. Routing)
574 |     if (this.currentSequenceModel) {
575 |       modelToUse = this.currentSequenceModel;
576 |     } else {
577 |       const router = await this.config.getModelRouterService();
578 |       const decision = await router.route(routingContext);
579 |       modelToUse = decision.model;
580 |       // Lock the model for the rest of the sequence
581 |       this.currentSequenceModel = modelToUse;
582 |     }
583 | 
584 |     const resultStream = turn.run(modelToUse, request, linkedSignal);
585 |     for await (const event of resultStream) {
586 |       if (this.loopDetector.addAndCheck(event)) {
587 |         yield { type: GeminiEventType.LoopDetected };
588 |         controller.abort();
589 |         return turn;
590 |       }
591 |       yield event;
592 |       if (event.type === GeminiEventType.InvalidStream) {
593 |         if (this.config.getContinueOnFailedApiCall()) {
594 |           if (isInvalidStreamRetry) {
595 |             // We already retried once, so stop here.
596 |             logContentRetryFailure(
597 |               this.config,
598 |               new ContentRetryFailureEvent(
599 |                 4, // 2 initial + 2 after injections
600 |                 'FAILED_AFTER_PROMPT_INJECTION',
601 |                 modelToUse,
602 |               ),
603 |             );
604 |             return turn;
605 |           }
606 |           const nextRequest = [{ text: 'System: Please continue.' }];
607 |           yield* this.sendMessageStream(
608 |             nextRequest,
609 |             signal,
610 |             prompt_id,
611 |             boundedTurns - 1,
612 |             true, // Set isInvalidStreamRetry to true
613 |           );
614 |           return turn;
615 |         }
616 |       }
617 |       if (event.type === GeminiEventType.Error) {
618 |         return turn;
619 |       }
620 |     }
621 |     if (!turn.pendingToolCalls.length && signal && !signal.aborted) {
622 |       // Check if next speaker check is needed
623 |       if (this.config.getQuotaErrorOccurred()) {
624 |         return turn;
625 |       }
626 | 
627 |       if (this.config.getSkipNextSpeakerCheck()) {
628 |         return turn;
629 |       }
630 | 
631 |       const nextSpeakerCheck = await checkNextSpeaker(
632 |         this.getChat(),
633 |         this.config.getBaseLlmClient(),
634 |         signal,
635 |         prompt_id,
636 |       );
637 |       logNextSpeakerCheck(
638 |         this.config,
639 |         new NextSpeakerCheckEvent(
640 |           prompt_id,
641 |           turn.finishReason?.toString() || '',
[TRUNCATED]
```

src/core/contentGenerator.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import type { ContentGenerator } from './contentGenerator.js';
9 | import {
10 |   createContentGenerator,
11 |   AuthType,
12 |   createContentGeneratorConfig,
13 | } from './contentGenerator.js';
14 | import { createCodeAssistContentGenerator } from '../code_assist/codeAssist.js';
15 | import { GoogleGenAI } from '@google/genai';
16 | import type { Config } from '../config/config.js';
17 | import { LoggingContentGenerator } from './loggingContentGenerator.js';
18 | 
19 | vi.mock('../code_assist/codeAssist.js');
20 | vi.mock('@google/genai');
21 | 
22 | const mockConfig = {} as unknown as Config;
23 | 
24 | describe('createContentGenerator', () => {
25 |   it('should create a CodeAssistContentGenerator', async () => {
26 |     const mockGenerator = {} as unknown as ContentGenerator;
27 |     vi.mocked(createCodeAssistContentGenerator).mockResolvedValue(
28 |       mockGenerator as never,
29 |     );
30 |     const generator = await createContentGenerator(
31 |       {
32 |         authType: AuthType.LOGIN_WITH_GOOGLE,
33 |       },
34 |       mockConfig,
35 |     );
36 |     expect(createCodeAssistContentGenerator).toHaveBeenCalled();
37 |     expect(generator).toEqual(
38 |       new LoggingContentGenerator(mockGenerator, mockConfig),
39 |     );
40 |   });
41 | 
42 |   it('should create a GoogleGenAI content generator', async () => {
43 |     const mockConfig = {
44 |       getUsageStatisticsEnabled: () => true,
45 |     } as unknown as Config;
46 | 
47 |     const mockGenerator = {
48 |       models: {},
49 |     } as unknown as GoogleGenAI;
50 |     vi.mocked(GoogleGenAI).mockImplementation(() => mockGenerator as never);
51 |     const generator = await createContentGenerator(
52 |       {
53 |         apiKey: 'test-api-key',
54 |         authType: AuthType.USE_GEMINI,
55 |       },
56 |       mockConfig,
57 |     );
58 |     expect(GoogleGenAI).toHaveBeenCalledWith({
59 |       apiKey: 'test-api-key',
60 |       vertexai: undefined,
61 |       httpOptions: {
62 |         headers: {
63 |           'User-Agent': expect.any(String),
64 |           'x-gemini-api-privileged-user-id': expect.any(String),
65 |         },
66 |       },
67 |     });
68 |     expect(generator).toEqual(
69 |       new LoggingContentGenerator(
70 |         (mockGenerator as GoogleGenAI).models,
71 |         mockConfig,
72 |       ),
73 |     );
74 |   });
75 | 
76 |   it('should create a GoogleGenAI content generator with client install id logging disabled', async () => {
77 |     const mockConfig = {
78 |       getUsageStatisticsEnabled: () => false,
79 |     } as unknown as Config;
80 |     const mockGenerator = {
81 |       models: {},
82 |     } as unknown as GoogleGenAI;
83 |     vi.mocked(GoogleGenAI).mockImplementation(() => mockGenerator as never);
84 |     const generator = await createContentGenerator(
85 |       {
86 |         apiKey: 'test-api-key',
87 |         authType: AuthType.USE_GEMINI,
88 |       },
89 |       mockConfig,
90 |     );
91 |     expect(GoogleGenAI).toHaveBeenCalledWith({
92 |       apiKey: 'test-api-key',
93 |       vertexai: undefined,
94 |       httpOptions: {
95 |         headers: {
96 |           'User-Agent': expect.any(String),
97 |         },
98 |       },
99 |     });
100 |     expect(generator).toEqual(
101 |       new LoggingContentGenerator(
102 |         (mockGenerator as GoogleGenAI).models,
103 |         mockConfig,
104 |       ),
105 |     );
106 |   });
107 | });
108 | 
109 | describe('createContentGeneratorConfig', () => {
110 |   const mockConfig = {
111 |     getModel: vi.fn().mockReturnValue('gemini-pro'),
112 |     setModel: vi.fn(),
113 |     flashFallbackHandler: vi.fn(),
114 |     getProxy: vi.fn(),
115 |   } as unknown as Config;
116 | 
117 |   beforeEach(() => {
118 |     // Reset modules to re-evaluate imports and environment variables
119 |     vi.resetModules();
120 |     vi.clearAllMocks();
121 |   });
122 | 
123 |   afterEach(() => {
124 |     vi.unstubAllEnvs();
125 |   });
126 | 
127 |   it('should configure for Gemini using GEMINI_API_KEY when set', async () => {
128 |     vi.stubEnv('GEMINI_API_KEY', 'env-gemini-key');
129 |     const config = await createContentGeneratorConfig(
130 |       mockConfig,
131 |       AuthType.USE_GEMINI,
132 |     );
133 |     expect(config.apiKey).toBe('env-gemini-key');
134 |     expect(config.vertexai).toBe(false);
135 |   });
136 | 
137 |   it('should not configure for Gemini if GEMINI_API_KEY is empty', async () => {
138 |     vi.stubEnv('GEMINI_API_KEY', '');
139 |     const config = await createContentGeneratorConfig(
140 |       mockConfig,
141 |       AuthType.USE_GEMINI,
142 |     );
143 |     expect(config.apiKey).toBeUndefined();
144 |     expect(config.vertexai).toBeUndefined();
145 |   });
146 | 
147 |   it('should configure for Vertex AI using GOOGLE_API_KEY when set', async () => {
148 |     vi.stubEnv('GOOGLE_API_KEY', 'env-google-key');
149 |     const config = await createContentGeneratorConfig(
150 |       mockConfig,
151 |       AuthType.USE_VERTEX_AI,
152 |     );
153 |     expect(config.apiKey).toBe('env-google-key');
154 |     expect(config.vertexai).toBe(true);
155 |   });
156 | 
157 |   it('should configure for Vertex AI using GCP project and location when set', async () => {
158 |     vi.stubEnv('GOOGLE_API_KEY', undefined);
159 |     vi.stubEnv('GOOGLE_CLOUD_PROJECT', 'env-gcp-project');
160 |     vi.stubEnv('GOOGLE_CLOUD_LOCATION', 'env-gcp-location');
161 |     const config = await createContentGeneratorConfig(
162 |       mockConfig,
163 |       AuthType.USE_VERTEX_AI,
164 |     );
165 |     expect(config.vertexai).toBe(true);
166 |     expect(config.apiKey).toBeUndefined();
167 |   });
168 | 
169 |   it('should not configure for Vertex AI if required env vars are empty', async () => {
170 |     vi.stubEnv('GOOGLE_API_KEY', '');
171 |     vi.stubEnv('GOOGLE_CLOUD_PROJECT', '');
172 |     vi.stubEnv('GOOGLE_CLOUD_LOCATION', '');
173 |     const config = await createContentGeneratorConfig(
174 |       mockConfig,
175 |       AuthType.USE_VERTEX_AI,
176 |     );
177 |     expect(config.apiKey).toBeUndefined();
178 |     expect(config.vertexai).toBeUndefined();
179 |   });
180 | });
```

src/core/contentGenerator.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   CountTokensResponse,
9 |   GenerateContentResponse,
10 |   GenerateContentParameters,
11 |   CountTokensParameters,
12 |   EmbedContentResponse,
13 |   EmbedContentParameters,
14 | } from '@google/genai';
15 | import { GoogleGenAI } from '@google/genai';
16 | import { createCodeAssistContentGenerator } from '../code_assist/codeAssist.js';
17 | import type { Config } from '../config/config.js';
18 | 
19 | import type { UserTierId } from '../code_assist/types.js';
20 | import { LoggingContentGenerator } from './loggingContentGenerator.js';
21 | import { InstallationManager } from '../utils/installationManager.js';
22 | 
23 | /**
24 |  * Interface abstracting the core functionalities for generating content and counting tokens.
25 |  */
26 | export interface ContentGenerator {
27 |   generateContent(
28 |     request: GenerateContentParameters,
29 |     userPromptId: string,
30 |   ): Promise<GenerateContentResponse>;
31 | 
32 |   generateContentStream(
33 |     request: GenerateContentParameters,
34 |     userPromptId: string,
35 |   ): Promise<AsyncGenerator<GenerateContentResponse>>;
36 | 
37 |   countTokens(request: CountTokensParameters): Promise<CountTokensResponse>;
38 | 
39 |   embedContent(request: EmbedContentParameters): Promise<EmbedContentResponse>;
40 | 
41 |   userTier?: UserTierId;
42 | }
43 | 
44 | export enum AuthType {
45 |   LOGIN_WITH_GOOGLE = 'oauth-personal',
46 |   USE_GEMINI = 'gemini-api-key',
47 |   USE_VERTEX_AI = 'vertex-ai',
48 |   CLOUD_SHELL = 'cloud-shell',
49 | }
50 | 
51 | export type ContentGeneratorConfig = {
52 |   apiKey?: string;
53 |   vertexai?: boolean;
54 |   authType?: AuthType;
55 |   proxy?: string;
56 | };
57 | 
58 | export function createContentGeneratorConfig(
59 |   config: Config,
60 |   authType: AuthType | undefined,
61 | ): ContentGeneratorConfig {
62 |   const geminiApiKey = process.env['GEMINI_API_KEY'] || undefined;
63 |   const googleApiKey = process.env['GOOGLE_API_KEY'] || undefined;
64 |   const googleCloudProject =
65 |     process.env['GOOGLE_CLOUD_PROJECT'] ||
66 |     process.env['GOOGLE_CLOUD_PROJECT_ID'] ||
67 |     undefined;
68 |   const googleCloudLocation = process.env['GOOGLE_CLOUD_LOCATION'] || undefined;
69 | 
70 |   const contentGeneratorConfig: ContentGeneratorConfig = {
71 |     authType,
72 |     proxy: config?.getProxy(),
73 |   };
74 | 
75 |   // If we are using Google auth or we are in Cloud Shell, there is nothing else to validate for now
76 |   if (
77 |     authType === AuthType.LOGIN_WITH_GOOGLE ||
78 |     authType === AuthType.CLOUD_SHELL
79 |   ) {
80 |     return contentGeneratorConfig;
81 |   }
82 | 
83 |   if (authType === AuthType.USE_GEMINI && geminiApiKey) {
84 |     contentGeneratorConfig.apiKey = geminiApiKey;
85 |     contentGeneratorConfig.vertexai = false;
86 | 
87 |     return contentGeneratorConfig;
88 |   }
89 | 
90 |   if (
91 |     authType === AuthType.USE_VERTEX_AI &&
92 |     (googleApiKey || (googleCloudProject && googleCloudLocation))
93 |   ) {
94 |     contentGeneratorConfig.apiKey = googleApiKey;
95 |     contentGeneratorConfig.vertexai = true;
96 | 
97 |     return contentGeneratorConfig;
98 |   }
99 | 
100 |   return contentGeneratorConfig;
101 | }
102 | 
103 | export async function createContentGenerator(
104 |   config: ContentGeneratorConfig,
105 |   gcConfig: Config,
106 |   sessionId?: string,
107 | ): Promise<ContentGenerator> {
108 |   const version = process.env['CLI_VERSION'] || process.version;
109 |   const userAgent = `GeminiCLI/${version} (${process.platform}; ${process.arch})`;
110 |   const baseHeaders: Record<string, string> = {
111 |     'User-Agent': userAgent,
112 |   };
113 | 
114 |   if (
115 |     config.authType === AuthType.LOGIN_WITH_GOOGLE ||
116 |     config.authType === AuthType.CLOUD_SHELL
117 |   ) {
118 |     const httpOptions = { headers: baseHeaders };
119 |     return new LoggingContentGenerator(
120 |       await createCodeAssistContentGenerator(
121 |         httpOptions,
122 |         config.authType,
123 |         gcConfig,
124 |         sessionId,
125 |       ),
126 |       gcConfig,
127 |     );
128 |   }
129 | 
130 |   if (
131 |     config.authType === AuthType.USE_GEMINI ||
132 |     config.authType === AuthType.USE_VERTEX_AI
133 |   ) {
134 |     let headers: Record<string, string> = { ...baseHeaders };
135 |     if (gcConfig?.getUsageStatisticsEnabled()) {
136 |       const installationManager = new InstallationManager();
137 |       const installationId = installationManager.getInstallationId();
138 |       headers = {
139 |         ...headers,
140 |         'x-gemini-api-privileged-user-id': `${installationId}`,
141 |       };
142 |     }
143 |     const httpOptions = { headers };
144 | 
145 |     const googleGenAI = new GoogleGenAI({
146 |       apiKey: config.apiKey === '' ? undefined : config.apiKey,
147 |       vertexai: config.vertexai,
148 |       httpOptions,
149 |     });
150 |     return new LoggingContentGenerator(googleGenAI.models, gcConfig);
151 |   }
152 |   throw new Error(
153 |     `Error creating contentGenerator: Unsupported authType: ${config.authType}`,
154 |   );
155 | }
```

src/core/coreToolScheduler.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach } from 'vitest';
8 | import type { Mock } from 'vitest';
9 | import type { ToolCall, WaitingToolCall } from './coreToolScheduler.js';
10 | import {
11 |   CoreToolScheduler,
12 |   convertToFunctionResponse,
13 |   truncateAndSaveToFile,
14 | } from './coreToolScheduler.js';
15 | import type {
16 |   ToolCallConfirmationDetails,
17 |   ToolConfirmationPayload,
18 |   ToolInvocation,
19 |   ToolResult,
20 |   Config,
21 |   ToolRegistry,
22 | } from '../index.js';
23 | import {
24 |   DEFAULT_TRUNCATE_TOOL_OUTPUT_LINES,
25 |   DEFAULT_TRUNCATE_TOOL_OUTPUT_THRESHOLD,
26 |   BaseDeclarativeTool,
27 |   BaseToolInvocation,
28 |   ToolConfirmationOutcome,
29 |   Kind,
30 |   ApprovalMode,
31 | } from '../index.js';
32 | import type { Part, PartListUnion } from '@google/genai';
33 | import {
34 |   MockModifiableTool,
35 |   MockTool,
36 |   MOCK_TOOL_SHOULD_CONFIRM_EXECUTE,
37 | } from '../test-utils/mock-tool.js';
38 | import * as fs from 'node:fs/promises';
39 | import * as path from 'node:path';
40 | 
41 | vi.mock('fs/promises', () => ({
42 |   writeFile: vi.fn(),
43 | }));
44 | 
45 | class TestApprovalTool extends BaseDeclarativeTool<{ id: string }, ToolResult> {
46 |   static readonly Name = 'testApprovalTool';
47 | 
48 |   constructor(private config: Config) {
49 |     super(
50 |       TestApprovalTool.Name,
51 |       'TestApprovalTool',
52 |       'A tool for testing approval logic',
53 |       Kind.Edit,
54 |       {
55 |         properties: { id: { type: 'string' } },
56 |         required: ['id'],
57 |         type: 'object',
58 |       },
59 |     );
60 |   }
61 | 
62 |   protected createInvocation(params: {
63 |     id: string;
64 |   }): ToolInvocation<{ id: string }, ToolResult> {
65 |     return new TestApprovalInvocation(this.config, params);
66 |   }
67 | }
68 | 
69 | class TestApprovalInvocation extends BaseToolInvocation<
70 |   { id: string },
71 |   ToolResult
72 | > {
73 |   constructor(
74 |     private config: Config,
75 |     params: { id: string },
76 |   ) {
77 |     super(params);
78 |   }
79 | 
80 |   getDescription(): string {
81 |     return `Test tool ${this.params.id}`;
82 |   }
83 | 
84 |   override async shouldConfirmExecute(): Promise<
85 |     ToolCallConfirmationDetails | false
86 |   > {
87 |     // Need confirmation unless approval mode is AUTO_EDIT
88 |     if (this.config.getApprovalMode() === ApprovalMode.AUTO_EDIT) {
89 |       return false;
90 |     }
91 | 
92 |     return {
93 |       type: 'edit',
94 |       title: `Confirm Test Tool ${this.params.id}`,
95 |       fileName: `test-${this.params.id}.txt`,
96 |       filePath: `/test-${this.params.id}.txt`,
97 |       fileDiff: 'Test diff content',
98 |       originalContent: '',
99 |       newContent: 'Test content',
100 |       onConfirm: async (outcome: ToolConfirmationOutcome) => {
101 |         if (outcome === ToolConfirmationOutcome.ProceedAlways) {
102 |           this.config.setApprovalMode(ApprovalMode.AUTO_EDIT);
103 |         }
104 |       },
105 |     };
106 |   }
107 | 
108 |   async execute(): Promise<ToolResult> {
109 |     return {
110 |       llmContent: `Executed test tool ${this.params.id}`,
111 |       returnDisplay: `Executed test tool ${this.params.id}`,
112 |     };
113 |   }
114 | }
115 | 
116 | class AbortDuringConfirmationInvocation extends BaseToolInvocation<
117 |   Record<string, unknown>,
118 |   ToolResult
119 | > {
120 |   constructor(
121 |     private readonly abortController: AbortController,
122 |     private readonly abortError: Error,
123 |     params: Record<string, unknown>,
124 |   ) {
125 |     super(params);
126 |   }
127 | 
128 |   override async shouldConfirmExecute(
129 |     _signal: AbortSignal,
130 |   ): Promise<ToolCallConfirmationDetails | false> {
131 |     this.abortController.abort();
132 |     throw this.abortError;
133 |   }
134 | 
135 |   async execute(_abortSignal: AbortSignal): Promise<ToolResult> {
136 |     throw new Error('execute should not be called when confirmation fails');
137 |   }
138 | 
139 |   getDescription(): string {
140 |     return 'Abort during confirmation invocation';
141 |   }
142 | }
143 | 
144 | class AbortDuringConfirmationTool extends BaseDeclarativeTool<
145 |   Record<string, unknown>,
146 |   ToolResult
147 | > {
148 |   constructor(
149 |     private readonly abortController: AbortController,
150 |     private readonly abortError: Error,
151 |   ) {
152 |     super(
153 |       'abortDuringConfirmationTool',
154 |       'Abort During Confirmation Tool',
155 |       'A tool that aborts while confirming execution.',
156 |       Kind.Other,
157 |       {
158 |         type: 'object',
159 |         properties: {},
160 |       },
161 |     );
162 |   }
163 | 
164 |   protected createInvocation(
165 |     params: Record<string, unknown>,
166 |   ): ToolInvocation<Record<string, unknown>, ToolResult> {
167 |     return new AbortDuringConfirmationInvocation(
168 |       this.abortController,
169 |       this.abortError,
170 |       params,
171 |     );
172 |   }
173 | }
174 | 
175 | async function waitForStatus(
176 |   onToolCallsUpdate: Mock,
177 |   status: 'awaiting_approval' | 'executing' | 'success' | 'error' | 'cancelled',
178 |   timeout = 5000,
179 | ): Promise<ToolCall> {
180 |   return new Promise((resolve, reject) => {
181 |     const startTime = Date.now();
182 |     const check = () => {
183 |       if (Date.now() - startTime > timeout) {
184 |         const seenStatuses = onToolCallsUpdate.mock.calls
185 |           .flatMap((call) => call[0])
186 |           .map((toolCall: ToolCall) => toolCall.status);
187 |         reject(
188 |           new Error(
189 |             `Timed out waiting for status "${status}". Seen statuses: ${seenStatuses.join(
190 |               ', ',
191 |             )}`,
192 |           ),
193 |         );
194 |         return;
195 |       }
196 | 
197 |       const foundCall = onToolCallsUpdate.mock.calls
198 |         .flatMap((call) => call[0])
199 |         .find((toolCall: ToolCall) => toolCall.status === status);
200 |       if (foundCall) {
201 |         resolve(foundCall);
202 |       } else {
203 |         setTimeout(check, 10); // Check again in 10ms
204 |       }
205 |     };
206 |     check();
207 |   });
208 | }
209 | 
210 | describe('CoreToolScheduler', () => {
211 |   it('should cancel a tool call if the signal is aborted before confirmation', async () => {
212 |     const mockTool = new MockTool({
213 |       name: 'mockTool',
214 |       shouldConfirmExecute: MOCK_TOOL_SHOULD_CONFIRM_EXECUTE,
215 |     });
216 |     const declarativeTool = mockTool;
217 |     const mockToolRegistry = {
218 |       getTool: () => declarativeTool,
219 |       getFunctionDeclarations: () => [],
220 |       tools: new Map(),
221 |       discovery: {},
222 |       registerTool: () => {},
223 |       getToolByName: () => declarativeTool,
224 |       getToolByDisplayName: () => declarativeTool,
225 |       getTools: () => [],
226 |       discoverTools: async () => {},
227 |       getAllTools: () => [],
228 |       getToolsByServer: () => [],
229 |     } as unknown as ToolRegistry;
230 | 
231 |     const onAllToolCallsComplete = vi.fn();
232 |     const onToolCallsUpdate = vi.fn();
233 | 
234 |     const mockConfig = {
235 |       getSessionId: () => 'test-session-id',
236 |       getUsageStatisticsEnabled: () => true,
237 |       getDebugMode: () => false,
238 |       getApprovalMode: () => ApprovalMode.DEFAULT,
239 |       getAllowedTools: () => [],
240 |       getContentGeneratorConfig: () => ({
241 |         model: 'test-model',
242 |         authType: 'oauth-personal',
243 |       }),
244 |       getShellExecutionConfig: () => ({
245 |         terminalWidth: 90,
246 |         terminalHeight: 30,
247 |       }),
248 |       storage: {
249 |         getProjectTempDir: () => '/tmp',
250 |       },
251 |       getTruncateToolOutputThreshold: () =>
252 |         DEFAULT_TRUNCATE_TOOL_OUTPUT_THRESHOLD,
253 |       getTruncateToolOutputLines: () => DEFAULT_TRUNCATE_TOOL_OUTPUT_LINES,
254 |       getToolRegistry: () => mockToolRegistry,
255 |       getUseSmartEdit: () => false,
256 |       getUseModelRouter: () => false,
257 |       getGeminiClient: () => null, // No client needed for these tests
258 |     } as unknown as Config;
259 | 
260 |     const scheduler = new CoreToolScheduler({
261 |       config: mockConfig,
262 |       onAllToolCallsComplete,
263 |       onToolCallsUpdate,
264 |       getPreferredEditor: () => 'vscode',
265 |       onEditorClose: vi.fn(),
266 |     });
267 | 
268 |     const abortController = new AbortController();
269 |     const request = {
270 |       callId: '1',
271 |       name: 'mockTool',
272 |       args: {},
273 |       isClientInitiated: false,
274 |       prompt_id: 'prompt-id-1',
275 |     };
276 | 
277 |     abortController.abort();
278 |     await scheduler.schedule([request], abortController.signal);
279 | 
280 |     expect(onAllToolCallsComplete).toHaveBeenCalled();
281 |     const completedCalls = onAllToolCallsComplete.mock
282 |       .calls[0][0] as ToolCall[];
283 |     expect(completedCalls[0].status).toBe('cancelled');
284 |   });
285 | 
286 |   it('should mark tool call as cancelled when abort happens during confirmation error', async () => {
287 |     const abortController = new AbortController();
288 |     const abortError = new Error('Abort requested during confirmation');
289 |     const declarativeTool = new AbortDuringConfirmationTool(
290 |       abortController,
291 |       abortError,
292 |     );
293 | 
294 |     const mockToolRegistry = {
295 |       getTool: () => declarativeTool,
296 |       getFunctionDeclarations: () => [],
297 |       tools: new Map(),
298 |       discovery: {},
299 |       registerTool: () => {},
300 |       getToolByName: () => declarativeTool,
301 |       getToolByDisplayName: () => declarativeTool,
302 |       getTools: () => [],
303 |       discoverTools: async () => {},
304 |       getAllTools: () => [],
305 |       getToolsByServer: () => [],
306 |     } as unknown as ToolRegistry;
307 | 
308 |     const onAllToolCallsComplete = vi.fn();
309 |     const onToolCallsUpdate = vi.fn();
310 | 
311 |     const mockConfig = {
312 |       getSessionId: () => 'test-session-id',
313 |       getUsageStatisticsEnabled: () => true,
314 |       getDebugMode: () => false,
315 |       getApprovalMode: () => ApprovalMode.DEFAULT,
316 |       getAllowedTools: () => [],
317 |       getContentGeneratorConfig: () => ({
318 |         model: 'test-model',
319 |         authType: 'oauth-personal',
320 |       }),
321 |       getShellExecutionConfig: () => ({
322 |         terminalWidth: 90,
323 |         terminalHeight: 30,
324 |       }),
325 |       storage: {
326 |         getProjectTempDir: () => '/tmp',
327 |       },
328 |       getTruncateToolOutputThreshold: () =>
329 |         DEFAULT_TRUNCATE_TOOL_OUTPUT_THRESHOLD,
330 |       getTruncateToolOutputLines: () => DEFAULT_TRUNCATE_TOOL_OUTPUT_LINES,
331 |       getToolRegistry: () => mockToolRegistry,
332 |       getUseSmartEdit: () => false,
333 |       getUseModelRouter: () => false,
334 |       getGeminiClient: () => null,
335 |     } as unknown as Config;
336 | 
337 |     const scheduler = new CoreToolScheduler({
338 |       config: mockConfig,
339 |       onAllToolCallsComplete,
340 |       onToolCallsUpdate,
341 |       getPreferredEditor: () => 'vscode',
342 |       onEditorClose: vi.fn(),
343 |     });
344 | 
345 |     const request = {
346 |       callId: 'abort-1',
347 |       name: 'abortDuringConfirmationTool',
348 |       args: {},
349 |       isClientInitiated: false,
350 |       prompt_id: 'prompt-id-abort',
351 |     };
352 | 
353 |     await scheduler.schedule([request], abortController.signal);
354 | 
355 |     expect(onAllToolCallsComplete).toHaveBeenCalled();
356 |     const completedCalls = onAllToolCallsComplete.mock
357 |       .calls[0][0] as ToolCall[];
358 |     expect(completedCalls[0].status).toBe('cancelled');
359 |     const statuses = onToolCallsUpdate.mock.calls.flatMap((call) =>
360 |       (call[0] as ToolCall[]).map((toolCall) => toolCall.status),
361 |     );
362 |     expect(statuses).not.toContain('error');
363 |   });
364 | 
365 |   describe('getToolSuggestion', () => {
366 |     it('should suggest the top N closest tool names for a typo', () => {
367 |       // Create mocked tool registry
368 |       const mockConfig = {
369 |         getToolRegistry: () => mockToolRegistry,
370 |         getUseSmartEdit: () => false,
371 |         getUseModelRouter: () => false,
372 |         getGeminiClient: () => null, // No client needed for these tests
373 |       } as unknown as Config;
374 |       const mockToolRegistry = {
375 |         getAllToolNames: () => ['list_files', 'read_file', 'write_file'],
376 |       } as unknown as ToolRegistry;
377 | 
378 |       // Create scheduler
379 |       const scheduler = new CoreToolScheduler({
380 |         config: mockConfig,
381 |         getPreferredEditor: () => 'vscode',
382 |         onEditorClose: vi.fn(),
383 |       });
384 | 
385 |       // Test that the right tool is selected, with only 1 result, for typos
386 |       // @ts-expect-error accessing private method
387 |       const misspelledTool = scheduler.getToolSuggestion('list_fils', 1);
388 |       expect(misspelledTool).toBe(' Did you mean "list_files"?');
389 | 
390 |       // Test that the right tool is selected, with only 1 result, for prefixes
391 |       // @ts-expect-error accessing private method
392 |       const prefixedTool = scheduler.getToolSuggestion('github.list_files', 1);
393 |       expect(prefixedTool).toBe(' Did you mean "list_files"?');
394 | 
395 |       // Test that the right tool is first
396 |       // @ts-expect-error accessing private method
397 |       const suggestionMultiple = scheduler.getToolSuggestion('list_fils');
398 |       expect(suggestionMultiple).toBe(
399 |         ' Did you mean one of: "list_files", "read_file", "write_file"?',
400 |       );
401 |     });
402 |   });
403 | });
404 | 
405 | describe('CoreToolScheduler with payload', () => {
406 |   it('should update args and diff and execute tool when payload is provided', async () => {
407 |     const mockTool = new MockModifiableTool();
408 |     mockTool.executeFn = vi.fn();
409 |     const declarativeTool = mockTool;
410 |     const mockToolRegistry = {
411 |       getTool: () => declarativeTool,
412 |       getFunctionDeclarations: () => [],
413 |       tools: new Map(),
414 |       discovery: {},
415 |       registerTool: () => {},
416 |       getToolByName: () => declarativeTool,
417 |       getToolByDisplayName: () => declarativeTool,
418 |       getTools: () => [],
419 |       discoverTools: async () => {},
420 |       getAllTools: () => [],
421 |       getToolsByServer: () => [],
422 |     } as unknown as ToolRegistry;
423 | 
424 |     const onAllToolCallsComplete = vi.fn();
425 |     const onToolCallsUpdate = vi.fn();
426 | 
427 |     const mockConfig = {
428 |       getSessionId: () => 'test-session-id',
429 |       getUsageStatisticsEnabled: () => true,
430 |       getDebugMode: () => false,
431 |       getApprovalMode: () => ApprovalMode.DEFAULT,
432 |       getAllowedTools: () => [],
433 |       getContentGeneratorConfig: () => ({
434 |         model: 'test-model',
435 |         authType: 'oauth-personal',
436 |       }),
437 |       getShellExecutionConfig: () => ({
438 |         terminalWidth: 90,
439 |         terminalHeight: 30,
440 |       }),
441 |       storage: {
442 |         getProjectTempDir: () => '/tmp',
443 |       },
444 |       getTruncateToolOutputThreshold: () =>
445 |         DEFAULT_TRUNCATE_TOOL_OUTPUT_THRESHOLD,
446 |       getTruncateToolOutputLines: () => DEFAULT_TRUNCATE_TOOL_OUTPUT_LINES,
447 |       getToolRegistry: () => mockToolRegistry,
448 |       getUseSmartEdit: () => false,
449 |       getUseModelRouter: () => false,
450 |       getGeminiClient: () => null, // No client needed for these tests
451 |     } as unknown as Config;
452 | 
453 |     const scheduler = new CoreToolScheduler({
454 |       config: mockConfig,
455 |       onAllToolCallsComplete,
456 |       onToolCallsUpdate,
457 |       getPreferredEditor: () => 'vscode',
458 |       onEditorClose: vi.fn(),
459 |     });
460 | 
461 |     const abortController = new AbortController();
462 |     const request = {
463 |       callId: '1',
464 |       name: 'mockModifiableTool',
465 |       args: {},
466 |       isClientInitiated: false,
467 |       prompt_id: 'prompt-id-2',
468 |     };
469 | 
470 |     await scheduler.schedule([request], abortController.signal);
471 | 
472 |     const awaitingCall = (await waitForStatus(
473 |       onToolCallsUpdate,
474 |       'awaiting_approval',
475 |     )) as WaitingToolCall;
476 |     const confirmationDetails = awaitingCall.confirmationDetails;
477 | 
478 |     if (confirmationDetails) {
479 |       const payload: ToolConfirmationPayload = { newContent: 'final version' };
480 |       await confirmationDetails.onConfirm(
481 |         ToolConfirmationOutcome.ProceedOnce,
482 |         payload,
483 |       );
484 |     }
485 | 
486 |     // Wait for the tool execution to complete
487 |     await vi.waitFor(() => {
488 |       expect(onAllToolCallsComplete).toHaveBeenCalled();
489 |     });
490 | 
491 |     const completedCalls = onAllToolCallsComplete.mock
492 |       .calls[0][0] as ToolCall[];
493 |     expect(completedCalls[0].status).toBe('success');
494 |     expect(mockTool.executeFn).toHaveBeenCalledWith({
495 |       newContent: 'final version',
496 |     });
497 |   });
498 | });
499 | 
500 | describe('convertToFunctionResponse', () => {
501 |   const toolName = 'testTool';
502 |   const callId = 'call1';
503 | 
504 |   it('should handle simple string llmContent', () => {
505 |     const llmContent = 'Simple text output';
506 |     const result = convertToFunctionResponse(toolName, callId, llmContent);
507 |     expect(result).toEqual([
508 |       {
509 |         functionResponse: {
510 |           name: toolName,
511 |           id: callId,
512 |           response: { output: 'Simple text output' },
513 |         },
514 |       },
515 |     ]);
516 |   });
517 | 
518 |   it('should handle llmContent as a single Part with text', () => {
519 |     const llmContent: Part = { text: 'Text from Part object' };
520 |     const result = convertToFunctionResponse(toolName, callId, llmContent);
521 |     expect(result).toEqual([
522 |       {
523 |         functionResponse: {
524 |           name: toolName,
525 |           id: callId,
526 |           response: { output: 'Text from Part object' },
527 |         },
528 |       },
529 |     ]);
530 |   });
531 | 
532 |   it('should handle llmContent as a PartListUnion array with a single text Part', () => {
533 |     const llmContent: PartListUnion = [{ text: 'Text from array' }];
534 |     const result = convertToFunctionResponse(toolName, callId, llmContent);
535 |     expect(result).toEqual([
536 |       {
537 |         functionResponse: {
538 |           name: toolName,
539 |           id: callId,
540 |           response: { output: 'Text from array' },
541 |         },
542 |       },
543 |     ]);
544 |   });
545 | 
546 |   it('should handle llmContent with inlineData', () => {
547 |     const llmContent: Part = {
548 |       inlineData: { mimeType: 'image/png', data: 'base64...' },
549 |     };
550 |     const result = convertToFunctionResponse(toolName, callId, llmContent);
551 |     expect(result).toEqual([
552 |       {
553 |         functionResponse: {
554 |           name: toolName,
555 |           id: callId,
556 |           response: {
557 |             output: 'Binary content of type image/png was processed.',
558 |           },
559 |         },
560 |       },
561 |       llmContent,
562 |     ]);
563 |   });
564 | 
565 |   it('should handle llmContent with fileData', () => {
566 |     const llmContent: Part = {
567 |       fileData: { mimeType: 'application/pdf', fileUri: 'gs://...' },
568 |     };
569 |     const result = convertToFunctionResponse(toolName, callId, llmContent);
570 |     expect(result).toEqual([
571 |       {
572 |         functionResponse: {
573 |           name: toolName,
574 |           id: callId,
575 |           response: {
576 |             output: 'Binary content of type application/pdf was processed.',
577 |           },
578 |         },
579 |       },
580 |       llmContent,
581 |     ]);
582 |   });
583 | 
584 |   it('should handle llmContent as an array of multiple Parts (text and inlineData)', () => {
585 |     const llmContent: PartListUnion = [
586 |       { text: 'Some textual description' },
587 |       { inlineData: { mimeType: 'image/jpeg', data: 'base64data...' } },
588 |       { text: 'Another text part' },
589 |     ];
590 |     const result = convertToFunctionResponse(toolName, callId, llmContent);
591 |     expect(result).toEqual([
592 |       {
593 |         functionResponse: {
594 |           name: toolName,
595 |           id: callId,
596 |           response: { output: 'Tool execution succeeded.' },
597 |         },
598 |       },
599 |       ...llmContent,
600 |     ]);
601 |   });
602 | 
603 |   it('should handle llmContent as an array with a single inlineData Part', () => {
604 |     const llmContent: PartListUnion = [
605 |       { inlineData: { mimeType: 'image/gif', data: 'gifdata...' } },
606 |     ];
607 |     const result = convertToFunctionResponse(toolName, callId, llmContent);
608 |     expect(result).toEqual([
609 |       {
610 |         functionResponse: {
611 |           name: toolName,
612 |           id: callId,
613 |           response: {
614 |             output: 'Binary content of type image/gif was processed.',
615 |           },
616 |         },
617 |       },
618 |       ...llmContent,
619 |     ]);
620 |   });
621 | 
622 |   it('should handle llmContent as a generic Part (not text, inlineData, or fileData)', () => {
623 |     const llmContent: Part = { functionCall: { name: 'test', args: {} } };
624 |     const result = convertToFunctionResponse(toolName, callId, llmContent);
625 |     expect(result).toEqual([
626 |       {
627 |         functionResponse: {
628 |           name: toolName,
629 |           id: callId,
630 |           response: { output: 'Tool execution succeeded.' },
631 |         },
632 |       },
633 |     ]);
634 |   });
635 | 
636 |   it('should handle empty string llmContent', () => {
637 |     const llmContent = '';
638 |     const result = convertToFunctionResponse(toolName, callId, llmContent);
639 |     expect(result).toEqual([
640 |       {
641 |         functionResponse: {
642 |           name: toolName,
643 |           id: callId,
644 |           response: { output: '' },
645 |         },
646 |       },
647 |     ]);
648 |   });
649 | 
650 |   it('should handle llmContent as an empty array', () => {
651 |     const llmContent: PartListUnion = [];
652 |     const result = convertToFunctionResponse(toolName, callId, llmContent);
653 |     expect(result).toEqual([
654 |       {
655 |         functionResponse: {
656 |           name: toolName,
657 |           id: callId,
658 |           response: { output: 'Tool execution succeeded.' },
659 |         },
660 |       },
661 |     ]);
662 |   });
663 | 
664 |   it('should handle llmContent as a Part with undefined inlineData/fileData/text', () => {
665 |     const llmContent: Part = {}; // An empty part object
666 |     const result = convertToFunctionResponse(toolName, callId, llmContent);
667 |     expect(result).toEqual([
668 |       {
669 |         functionResponse: {
670 |           name: toolName,
671 |           id: callId,
672 |           response: { output: 'Tool execution succeeded.' },
673 |         },
674 |       },
675 |     ]);
676 |   });
677 | });
678 | 
679 | class MockEditToolInvocation extends BaseToolInvocation<
680 |   Record<string, unknown>,
681 |   ToolResult
682 | > {
683 |   constructor(params: Record<string, unknown>) {
684 |     super(params);
685 |   }
686 | 
[TRUNCATED]
```

src/core/coreToolScheduler.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   ToolCallRequestInfo,
9 |   ToolCallResponseInfo,
10 |   ToolCallConfirmationDetails,
11 |   ToolResult,
12 |   ToolResultDisplay,
13 |   ToolRegistry,
14 |   EditorType,
15 |   Config,
16 |   ToolConfirmationPayload,
17 |   AnyDeclarativeTool,
18 |   AnyToolInvocation,
19 |   AnsiOutput,
20 | } from '../index.js';
21 | import {
22 |   ToolConfirmationOutcome,
23 |   ApprovalMode,
24 |   logToolCall,
25 |   ReadFileTool,
26 |   ToolErrorType,
27 |   ToolCallEvent,
28 |   ShellTool,
29 |   logToolOutputTruncated,
30 |   ToolOutputTruncatedEvent,
31 | } from '../index.js';
32 | import type { Part, PartListUnion } from '@google/genai';
33 | import { getResponseTextFromParts } from '../utils/generateContentResponseUtilities.js';
34 | import type { ModifyContext } from '../tools/modifiable-tool.js';
35 | import {
36 |   isModifiableDeclarativeTool,
37 |   modifyWithEditor,
38 | } from '../tools/modifiable-tool.js';
39 | import * as Diff from 'diff';
40 | import * as fs from 'node:fs/promises';
41 | import * as path from 'node:path';
42 | import { doesToolInvocationMatch } from '../utils/tool-utils.js';
43 | import levenshtein from 'fast-levenshtein';
44 | import { ShellToolInvocation } from '../tools/shell.js';
45 | 
46 | export type ValidatingToolCall = {
47 |   status: 'validating';
48 |   request: ToolCallRequestInfo;
49 |   tool: AnyDeclarativeTool;
50 |   invocation: AnyToolInvocation;
51 |   startTime?: number;
52 |   outcome?: ToolConfirmationOutcome;
53 | };
54 | 
55 | export type ScheduledToolCall = {
56 |   status: 'scheduled';
57 |   request: ToolCallRequestInfo;
58 |   tool: AnyDeclarativeTool;
59 |   invocation: AnyToolInvocation;
60 |   startTime?: number;
61 |   outcome?: ToolConfirmationOutcome;
62 | };
63 | 
64 | export type ErroredToolCall = {
65 |   status: 'error';
66 |   request: ToolCallRequestInfo;
67 |   response: ToolCallResponseInfo;
68 |   tool?: AnyDeclarativeTool;
69 |   durationMs?: number;
70 |   outcome?: ToolConfirmationOutcome;
71 | };
72 | 
73 | export type SuccessfulToolCall = {
74 |   status: 'success';
75 |   request: ToolCallRequestInfo;
76 |   tool: AnyDeclarativeTool;
77 |   response: ToolCallResponseInfo;
78 |   invocation: AnyToolInvocation;
79 |   durationMs?: number;
80 |   outcome?: ToolConfirmationOutcome;
81 | };
82 | 
83 | export type ExecutingToolCall = {
84 |   status: 'executing';
85 |   request: ToolCallRequestInfo;
86 |   tool: AnyDeclarativeTool;
87 |   invocation: AnyToolInvocation;
88 |   liveOutput?: string | AnsiOutput;
89 |   startTime?: number;
90 |   outcome?: ToolConfirmationOutcome;
91 |   pid?: number;
92 | };
93 | 
94 | export type CancelledToolCall = {
95 |   status: 'cancelled';
96 |   request: ToolCallRequestInfo;
97 |   response: ToolCallResponseInfo;
98 |   tool: AnyDeclarativeTool;
99 |   invocation: AnyToolInvocation;
100 |   durationMs?: number;
101 |   outcome?: ToolConfirmationOutcome;
102 | };
103 | 
104 | export type WaitingToolCall = {
105 |   status: 'awaiting_approval';
106 |   request: ToolCallRequestInfo;
107 |   tool: AnyDeclarativeTool;
108 |   invocation: AnyToolInvocation;
109 |   confirmationDetails: ToolCallConfirmationDetails;
110 |   startTime?: number;
111 |   outcome?: ToolConfirmationOutcome;
112 | };
113 | 
114 | export type Status = ToolCall['status'];
115 | 
116 | export type ToolCall =
117 |   | ValidatingToolCall
118 |   | ScheduledToolCall
119 |   | ErroredToolCall
120 |   | SuccessfulToolCall
121 |   | ExecutingToolCall
122 |   | CancelledToolCall
123 |   | WaitingToolCall;
124 | 
125 | export type CompletedToolCall =
126 |   | SuccessfulToolCall
127 |   | CancelledToolCall
128 |   | ErroredToolCall;
129 | 
130 | export type ConfirmHandler = (
131 |   toolCall: WaitingToolCall,
132 | ) => Promise<ToolConfirmationOutcome>;
133 | 
134 | export type OutputUpdateHandler = (
135 |   toolCallId: string,
136 |   outputChunk: string | AnsiOutput,
137 | ) => void;
138 | 
139 | export type AllToolCallsCompleteHandler = (
140 |   completedToolCalls: CompletedToolCall[],
141 | ) => Promise<void>;
142 | 
143 | export type ToolCallsUpdateHandler = (toolCalls: ToolCall[]) => void;
144 | 
145 | /**
146 |  * Formats tool output for a Gemini FunctionResponse.
147 |  */
148 | function createFunctionResponsePart(
149 |   callId: string,
150 |   toolName: string,
151 |   output: string,
152 | ): Part {
153 |   return {
154 |     functionResponse: {
155 |       id: callId,
156 |       name: toolName,
157 |       response: { output },
158 |     },
159 |   };
160 | }
161 | 
162 | export function convertToFunctionResponse(
163 |   toolName: string,
164 |   callId: string,
165 |   llmContent: PartListUnion,
166 | ): Part[] {
167 |   const contentToProcess =
168 |     Array.isArray(llmContent) && llmContent.length === 1
169 |       ? llmContent[0]
170 |       : llmContent;
171 | 
172 |   if (typeof contentToProcess === 'string') {
173 |     return [createFunctionResponsePart(callId, toolName, contentToProcess)];
174 |   }
175 | 
176 |   if (Array.isArray(contentToProcess)) {
177 |     const functionResponse = createFunctionResponsePart(
178 |       callId,
179 |       toolName,
180 |       'Tool execution succeeded.',
181 |     );
182 |     return [functionResponse, ...toParts(contentToProcess)];
183 |   }
184 | 
185 |   // After this point, contentToProcess is a single Part object.
186 |   if (contentToProcess.functionResponse) {
187 |     if (contentToProcess.functionResponse.response?.['content']) {
188 |       const stringifiedOutput =
189 |         getResponseTextFromParts(
190 |           contentToProcess.functionResponse.response['content'] as Part[],
191 |         ) || '';
192 |       return [createFunctionResponsePart(callId, toolName, stringifiedOutput)];
193 |     }
194 |     // It's a functionResponse that we should pass through as is.
195 |     return [contentToProcess];
196 |   }
197 | 
198 |   if (contentToProcess.inlineData || contentToProcess.fileData) {
199 |     const mimeType =
200 |       contentToProcess.inlineData?.mimeType ||
201 |       contentToProcess.fileData?.mimeType ||
202 |       'unknown';
203 |     const functionResponse = createFunctionResponsePart(
204 |       callId,
205 |       toolName,
206 |       `Binary content of type ${mimeType} was processed.`,
207 |     );
208 |     return [functionResponse, contentToProcess];
209 |   }
210 | 
211 |   if (contentToProcess.text !== undefined) {
212 |     return [
213 |       createFunctionResponsePart(callId, toolName, contentToProcess.text),
214 |     ];
215 |   }
216 | 
217 |   // Default case for other kinds of parts.
218 |   return [
219 |     createFunctionResponsePart(callId, toolName, 'Tool execution succeeded.'),
220 |   ];
221 | }
222 | 
223 | function toParts(input: PartListUnion): Part[] {
224 |   const parts: Part[] = [];
225 |   for (const part of Array.isArray(input) ? input : [input]) {
226 |     if (typeof part === 'string') {
227 |       parts.push({ text: part });
228 |     } else if (part) {
229 |       parts.push(part);
230 |     }
231 |   }
232 |   return parts;
233 | }
234 | 
235 | const createErrorResponse = (
236 |   request: ToolCallRequestInfo,
237 |   error: Error,
238 |   errorType: ToolErrorType | undefined,
239 | ): ToolCallResponseInfo => ({
240 |   callId: request.callId,
241 |   error,
242 |   responseParts: [
243 |     {
244 |       functionResponse: {
245 |         id: request.callId,
246 |         name: request.name,
247 |         response: { error: error.message },
248 |       },
249 |     },
250 |   ],
251 |   resultDisplay: error.message,
252 |   errorType,
253 |   contentLength: error.message.length,
254 | });
255 | 
256 | export async function truncateAndSaveToFile(
257 |   content: string,
258 |   callId: string,
259 |   projectTempDir: string,
260 |   threshold: number,
261 |   truncateLines: number,
262 | ): Promise<{ content: string; outputFile?: string }> {
263 |   if (content.length <= threshold) {
264 |     return { content };
265 |   }
266 | 
267 |   let lines = content.split('\n');
268 |   let fileContent = content;
269 | 
270 |   // If the content is long but has few lines, wrap it to enable line-based truncation.
271 |   if (lines.length <= truncateLines) {
272 |     const wrapWidth = 120; // A reasonable width for wrapping.
273 |     const wrappedLines: string[] = [];
274 |     for (const line of lines) {
275 |       if (line.length > wrapWidth) {
276 |         for (let i = 0; i < line.length; i += wrapWidth) {
277 |           wrappedLines.push(line.substring(i, i + wrapWidth));
278 |         }
279 |       } else {
280 |         wrappedLines.push(line);
281 |       }
282 |     }
283 |     lines = wrappedLines;
284 |     fileContent = lines.join('\n');
285 |   }
286 | 
287 |   const head = Math.floor(truncateLines / 5);
288 |   const beginning = lines.slice(0, head);
289 |   const end = lines.slice(-(truncateLines - head));
290 |   const truncatedContent =
291 |     beginning.join('\n') + '\n... [CONTENT TRUNCATED] ...\n' + end.join('\n');
292 | 
293 |   // Sanitize callId to prevent path traversal.
294 |   const safeFileName = `${path.basename(callId)}.output`;
295 |   const outputFile = path.join(projectTempDir, safeFileName);
296 |   try {
297 |     await fs.writeFile(outputFile, fileContent);
298 | 
299 |     return {
300 |       content: `Tool output was too large and has been truncated.
301 | The full output has been saved to: ${outputFile}
302 | To read the complete output, use the ${ReadFileTool.Name} tool with the absolute file path above. For large files, you can use the offset and limit parameters to read specific sections:
303 | - ${ReadFileTool.Name} tool with offset=0, limit=100 to see the first 100 lines
304 | - ${ReadFileTool.Name} tool with offset=N to skip N lines from the beginning
305 | - ${ReadFileTool.Name} tool with limit=M to read only M lines at a time
306 | The truncated output below shows the beginning and end of the content. The marker '... [CONTENT TRUNCATED] ...' indicates where content was removed.
307 | This allows you to efficiently examine different parts of the output without loading the entire file.
308 | Truncated part of the output:
309 | ${truncatedContent}`,
310 |       outputFile,
311 |     };
312 |   } catch (_error) {
313 |     return {
314 |       content:
315 |         truncatedContent + `\n[Note: Could not save full output to file]`,
316 |     };
317 |   }
318 | }
319 | 
320 | interface CoreToolSchedulerOptions {
321 |   config: Config;
322 |   outputUpdateHandler?: OutputUpdateHandler;
323 |   onAllToolCallsComplete?: AllToolCallsCompleteHandler;
324 |   onToolCallsUpdate?: ToolCallsUpdateHandler;
325 |   getPreferredEditor: () => EditorType | undefined;
326 |   onEditorClose: () => void;
327 | }
328 | 
329 | export class CoreToolScheduler {
330 |   private toolRegistry: ToolRegistry;
331 |   private toolCalls: ToolCall[] = [];
332 |   private outputUpdateHandler?: OutputUpdateHandler;
333 |   private onAllToolCallsComplete?: AllToolCallsCompleteHandler;
334 |   private onToolCallsUpdate?: ToolCallsUpdateHandler;
335 |   private getPreferredEditor: () => EditorType | undefined;
336 |   private config: Config;
337 |   private onEditorClose: () => void;
338 |   private isFinalizingToolCalls = false;
339 |   private isScheduling = false;
340 |   private requestQueue: Array<{
341 |     request: ToolCallRequestInfo | ToolCallRequestInfo[];
342 |     signal: AbortSignal;
343 |     resolve: () => void;
344 |     reject: (reason?: Error) => void;
345 |   }> = [];
346 | 
347 |   constructor(options: CoreToolSchedulerOptions) {
348 |     this.config = options.config;
349 |     this.toolRegistry = options.config.getToolRegistry();
350 |     this.outputUpdateHandler = options.outputUpdateHandler;
351 |     this.onAllToolCallsComplete = options.onAllToolCallsComplete;
352 |     this.onToolCallsUpdate = options.onToolCallsUpdate;
353 |     this.getPreferredEditor = options.getPreferredEditor;
354 |     this.onEditorClose = options.onEditorClose;
355 |   }
356 | 
357 |   private setStatusInternal(
358 |     targetCallId: string,
359 |     status: 'success',
360 |     response: ToolCallResponseInfo,
361 |   ): void;
362 |   private setStatusInternal(
363 |     targetCallId: string,
364 |     status: 'awaiting_approval',
365 |     confirmationDetails: ToolCallConfirmationDetails,
366 |   ): void;
367 |   private setStatusInternal(
368 |     targetCallId: string,
369 |     status: 'error',
370 |     response: ToolCallResponseInfo,
371 |   ): void;
372 |   private setStatusInternal(
373 |     targetCallId: string,
374 |     status: 'cancelled',
375 |     reason: string,
376 |   ): void;
377 |   private setStatusInternal(
378 |     targetCallId: string,
379 |     status: 'executing' | 'scheduled' | 'validating',
380 |   ): void;
381 |   private setStatusInternal(
382 |     targetCallId: string,
383 |     newStatus: Status,
384 |     auxiliaryData?: unknown,
385 |   ): void {
386 |     this.toolCalls = this.toolCalls.map((currentCall) => {
387 |       if (
388 |         currentCall.request.callId !== targetCallId ||
389 |         currentCall.status === 'success' ||
390 |         currentCall.status === 'error' ||
391 |         currentCall.status === 'cancelled'
392 |       ) {
393 |         return currentCall;
394 |       }
395 | 
396 |       // currentCall is a non-terminal state here and should have startTime and tool.
397 |       const existingStartTime = currentCall.startTime;
398 |       const toolInstance = currentCall.tool;
399 |       const invocation = currentCall.invocation;
400 | 
401 |       const outcome = currentCall.outcome;
402 | 
403 |       switch (newStatus) {
404 |         case 'success': {
405 |           const durationMs = existingStartTime
406 |             ? Date.now() - existingStartTime
407 |             : undefined;
408 |           return {
409 |             request: currentCall.request,
410 |             tool: toolInstance,
411 |             invocation,
412 |             status: 'success',
413 |             response: auxiliaryData as ToolCallResponseInfo,
414 |             durationMs,
415 |             outcome,
416 |           } as SuccessfulToolCall;
417 |         }
418 |         case 'error': {
419 |           const durationMs = existingStartTime
420 |             ? Date.now() - existingStartTime
421 |             : undefined;
422 |           return {
423 |             request: currentCall.request,
424 |             status: 'error',
425 |             tool: toolInstance,
426 |             response: auxiliaryData as ToolCallResponseInfo,
427 |             durationMs,
428 |             outcome,
429 |           } as ErroredToolCall;
430 |         }
431 |         case 'awaiting_approval':
432 |           return {
433 |             request: currentCall.request,
434 |             tool: toolInstance,
435 |             status: 'awaiting_approval',
436 |             confirmationDetails: auxiliaryData as ToolCallConfirmationDetails,
437 |             startTime: existingStartTime,
438 |             outcome,
439 |             invocation,
440 |           } as WaitingToolCall;
441 |         case 'scheduled':
442 |           return {
443 |             request: currentCall.request,
444 |             tool: toolInstance,
445 |             status: 'scheduled',
446 |             startTime: existingStartTime,
447 |             outcome,
448 |             invocation,
449 |           } as ScheduledToolCall;
450 |         case 'cancelled': {
451 |           const durationMs = existingStartTime
452 |             ? Date.now() - existingStartTime
453 |             : undefined;
454 | 
455 |           // Preserve diff for cancelled edit operations
456 |           let resultDisplay: ToolResultDisplay | undefined = undefined;
457 |           if (currentCall.status === 'awaiting_approval') {
458 |             const waitingCall = currentCall as WaitingToolCall;
459 |             if (waitingCall.confirmationDetails.type === 'edit') {
460 |               resultDisplay = {
461 |                 fileDiff: waitingCall.confirmationDetails.fileDiff,
462 |                 fileName: waitingCall.confirmationDetails.fileName,
463 |                 originalContent:
464 |                   waitingCall.confirmationDetails.originalContent,
465 |                 newContent: waitingCall.confirmationDetails.newContent,
466 |               };
467 |             }
468 |           }
469 | 
470 |           const errorMessage = `[Operation Cancelled] Reason: ${auxiliaryData}`;
471 |           return {
472 |             request: currentCall.request,
473 |             tool: toolInstance,
474 |             invocation,
475 |             status: 'cancelled',
476 |             response: {
477 |               callId: currentCall.request.callId,
478 |               responseParts: [
479 |                 {
480 |                   functionResponse: {
481 |                     id: currentCall.request.callId,
482 |                     name: currentCall.request.name,
483 |                     response: {
484 |                       error: errorMessage,
485 |                     },
486 |                   },
487 |                 },
488 |               ],
489 |               resultDisplay,
490 |               error: undefined,
491 |               errorType: undefined,
492 |               contentLength: errorMessage.length,
493 |             },
494 |             durationMs,
495 |             outcome,
496 |           } as CancelledToolCall;
497 |         }
498 |         case 'validating':
499 |           return {
500 |             request: currentCall.request,
501 |             tool: toolInstance,
502 |             status: 'validating',
503 |             startTime: existingStartTime,
504 |             outcome,
505 |             invocation,
506 |           } as ValidatingToolCall;
507 |         case 'executing':
508 |           return {
509 |             request: currentCall.request,
510 |             tool: toolInstance,
511 |             status: 'executing',
512 |             startTime: existingStartTime,
513 |             outcome,
514 |             invocation,
515 |           } as ExecutingToolCall;
516 |         default: {
517 |           const exhaustiveCheck: never = newStatus;
518 |           return exhaustiveCheck;
519 |         }
520 |       }
521 |     });
522 |     this.notifyToolCallsUpdate();
523 |     this.checkAndNotifyCompletion();
524 |   }
525 | 
526 |   private setArgsInternal(targetCallId: string, args: unknown): void {
527 |     this.toolCalls = this.toolCalls.map((call) => {
528 |       // We should never be asked to set args on an ErroredToolCall, but
529 |       // we guard for the case anyways.
530 |       if (call.request.callId !== targetCallId || call.status === 'error') {
531 |         return call;
532 |       }
533 | 
534 |       const invocationOrError = this.buildInvocation(
535 |         call.tool,
536 |         args as Record<string, unknown>,
537 |       );
538 |       if (invocationOrError instanceof Error) {
539 |         const response = createErrorResponse(
540 |           call.request,
541 |           invocationOrError,
542 |           ToolErrorType.INVALID_TOOL_PARAMS,
543 |         );
544 |         return {
545 |           request: { ...call.request, args: args as Record<string, unknown> },
546 |           status: 'error',
547 |           tool: call.tool,
548 |           response,
549 |         } as ErroredToolCall;
550 |       }
551 | 
552 |       return {
553 |         ...call,
554 |         request: { ...call.request, args: args as Record<string, unknown> },
555 |         invocation: invocationOrError,
556 |       };
557 |     });
558 |   }
559 | 
560 |   private isRunning(): boolean {
561 |     return (
562 |       this.isFinalizingToolCalls ||
563 |       this.toolCalls.some(
564 |         (call) =>
565 |           call.status === 'executing' || call.status === 'awaiting_approval',
566 |       )
567 |     );
568 |   }
569 | 
570 |   private buildInvocation(
571 |     tool: AnyDeclarativeTool,
572 |     args: object,
573 |   ): AnyToolInvocation | Error {
574 |     try {
575 |       return tool.build(args);
576 |     } catch (e) {
577 |       if (e instanceof Error) {
578 |         return e;
579 |       }
580 |       return new Error(String(e));
581 |     }
582 |   }
583 | 
584 |   /**
585 |    * Generates a suggestion string for a tool name that was not found in the registry.
586 |    * It finds the closest matches based on Levenshtein distance.
587 |    * @param unknownToolName The tool name that was not found.
588 |    * @param topN The number of suggestions to return. Defaults to 3.
589 |    * @returns A suggestion string like " Did you mean 'tool'?" or " Did you mean one of: 'tool1', 'tool2'?", or an empty string if no suggestions are found.
590 |    */
591 |   private getToolSuggestion(unknownToolName: string, topN = 3): string {
592 |     const allToolNames = this.toolRegistry.getAllToolNames();
593 | 
594 |     const matches = allToolNames.map((toolName) => ({
595 |       name: toolName,
596 |       distance: levenshtein.get(unknownToolName, toolName),
597 |     }));
598 | 
599 |     matches.sort((a, b) => a.distance - b.distance);
600 | 
601 |     const topNResults = matches.slice(0, topN);
602 | 
603 |     if (topNResults.length === 0) {
604 |       return '';
605 |     }
606 | 
607 |     const suggestedNames = topNResults
608 |       .map((match) => `"${match.name}"`)
609 |       .join(', ');
610 | 
611 |     if (topNResults.length > 1) {
612 |       return ` Did you mean one of: ${suggestedNames}?`;
613 |     } else {
614 |       return ` Did you mean ${suggestedNames}?`;
615 |     }
616 |   }
617 | 
618 |   schedule(
619 |     request: ToolCallRequestInfo | ToolCallRequestInfo[],
620 |     signal: AbortSignal,
621 |   ): Promise<void> {
622 |     if (this.isRunning() || this.isScheduling) {
623 |       return new Promise((resolve, reject) => {
624 |         const abortHandler = () => {
625 |           // Find and remove the request from the queue
626 |           const index = this.requestQueue.findIndex(
627 |             (item) => item.request === request,
628 |           );
629 |           if (index > -1) {
630 |             this.requestQueue.splice(index, 1);
631 |             reject(new Error('Tool call cancelled while in queue.'));
632 |           }
633 |         };
634 | 
635 |         signal.addEventListener('abort', abortHandler, { once: true });
636 | 
637 |         this.requestQueue.push({
638 |           request,
639 |           signal,
640 |           resolve: () => {
641 |             signal.removeEventListener('abort', abortHandler);
642 |             resolve();
643 |           },
644 |           reject: (reason?: Error) => {
645 |             signal.removeEventListener('abort', abortHandler);
646 |             reject(reason);
647 |           },
648 |         });
649 |       });
650 |     }
651 |     return this._schedule(request, signal);
652 |   }
653 | 
654 |   private async _schedule(
655 |     request: ToolCallRequestInfo | ToolCallRequestInfo[],
656 |     signal: AbortSignal,
657 |   ): Promise<void> {
658 |     this.isScheduling = true;
659 |     try {
660 |       if (this.isRunning()) {
661 |         throw new Error(
662 |           'Cannot schedule new tool calls while other tool calls are actively running (executing or awaiting approval).',
663 |         );
664 |       }
665 |       const requestsToProcess = Array.isArray(request) ? request : [request];
666 | 
667 |       const newToolCalls: ToolCall[] = requestsToProcess.map(
668 |         (reqInfo): ToolCall => {
669 |           const toolInstance = this.toolRegistry.getTool(reqInfo.name);
670 |           if (!toolInstance) {
671 |             const suggestion = this.getToolSuggestion(reqInfo.name);
672 |             const errorMessage = `Tool "${reqInfo.name}" not found in registry. Tools must use the exact names that are registered.${suggestion}`;
673 |             return {
674 |               status: 'error',
675 |               request: reqInfo,
676 |               response: createErrorResponse(
677 |                 reqInfo,
678 |                 new Error(errorMessage),
[TRUNCATED]
```

src/core/geminiChat.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import type {
9 |   Content,
10 |   GenerateContentConfig,
11 |   GenerateContentResponse,
12 | } from '@google/genai';
13 | import { ApiError } from '@google/genai';
14 | import type { ContentGenerator } from '../core/contentGenerator.js';
15 | import {
16 |   GeminiChat,
17 |   InvalidStreamError,
18 |   StreamEventType,
19 |   type StreamEvent,
20 | } from './geminiChat.js';
21 | import type { Config } from '../config/config.js';
22 | import { setSimulate429 } from '../utils/testUtils.js';
23 | import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';
24 | import { AuthType } from './contentGenerator.js';
25 | import { type RetryOptions } from '../utils/retry.js';
26 | import type { ToolRegistry } from '../tools/tool-registry.js';
27 | import { Kind } from '../tools/tools.js';
28 | import { uiTelemetryService } from '../telemetry/uiTelemetry.js';
29 | 
30 | // Mock fs module to prevent actual file system operations during tests
31 | const mockFileSystem = new Map<string, string>();
32 | 
33 | vi.mock('node:fs', () => {
34 |   const fsModule = {
35 |     mkdirSync: vi.fn(),
36 |     writeFileSync: vi.fn((path: string, data: string) => {
37 |       mockFileSystem.set(path, data);
38 |     }),
39 |     readFileSync: vi.fn((path: string) => {
40 |       if (mockFileSystem.has(path)) {
41 |         return mockFileSystem.get(path);
42 |       }
43 |       throw Object.assign(new Error('ENOENT: no such file or directory'), {
44 |         code: 'ENOENT',
45 |       });
46 |     }),
47 |     existsSync: vi.fn((path: string) => mockFileSystem.has(path)),
48 |   };
49 | 
50 |   return {
51 |     default: fsModule,
52 |     ...fsModule,
53 |   };
54 | });
55 | 
56 | const { mockHandleFallback } = vi.hoisted(() => ({
57 |   mockHandleFallback: vi.fn(),
58 | }));
59 | 
60 | // Add mock for the retry utility
61 | const { mockRetryWithBackoff } = vi.hoisted(() => ({
62 |   mockRetryWithBackoff: vi.fn(),
63 | }));
64 | 
65 | vi.mock('../utils/retry.js', () => ({
66 |   retryWithBackoff: mockRetryWithBackoff,
67 | }));
68 | 
69 | vi.mock('../fallback/handler.js', () => ({
70 |   handleFallback: mockHandleFallback,
71 | }));
72 | 
73 | const { mockLogContentRetry, mockLogContentRetryFailure } = vi.hoisted(() => ({
74 |   mockLogContentRetry: vi.fn(),
75 |   mockLogContentRetryFailure: vi.fn(),
76 | }));
77 | 
78 | vi.mock('../telemetry/loggers.js', () => ({
79 |   logContentRetry: mockLogContentRetry,
80 |   logContentRetryFailure: mockLogContentRetryFailure,
81 | }));
82 | 
83 | vi.mock('../telemetry/uiTelemetry.js', () => ({
84 |   uiTelemetryService: {
85 |     setLastPromptTokenCount: vi.fn(),
86 |   },
87 | }));
88 | 
89 | describe('GeminiChat', () => {
90 |   let mockContentGenerator: ContentGenerator;
91 |   let chat: GeminiChat;
92 |   let mockConfig: Config;
93 |   const config: GenerateContentConfig = {};
94 | 
95 |   beforeEach(() => {
96 |     vi.clearAllMocks();
97 |     vi.mocked(uiTelemetryService.setLastPromptTokenCount).mockClear();
98 |     mockContentGenerator = {
99 |       generateContent: vi.fn(),
100 |       generateContentStream: vi.fn(),
101 |       countTokens: vi.fn(),
102 |       embedContent: vi.fn(),
103 |       batchEmbedContents: vi.fn(),
104 |     } as unknown as ContentGenerator;
105 | 
106 |     mockHandleFallback.mockClear();
107 |     // Default mock implementation for tests that don't care about retry logic
108 |     mockRetryWithBackoff.mockImplementation(async (apiCall) => apiCall());
109 |     mockConfig = {
110 |       getSessionId: () => 'test-session-id',
111 |       getTelemetryLogPromptsEnabled: () => true,
112 |       getUsageStatisticsEnabled: () => true,
113 |       getDebugMode: () => false,
114 |       getContentGeneratorConfig: vi.fn().mockReturnValue({
115 |         authType: 'oauth-personal', // Ensure this is set for fallback tests
116 |         model: 'test-model',
117 |       }),
118 |       getModel: vi.fn().mockReturnValue('gemini-pro'),
119 |       setModel: vi.fn(),
120 |       isInFallbackMode: vi.fn().mockReturnValue(false),
121 |       getQuotaErrorOccurred: vi.fn().mockReturnValue(false),
122 |       setQuotaErrorOccurred: vi.fn(),
123 |       flashFallbackHandler: undefined,
124 |       getProjectRoot: vi.fn().mockReturnValue('/test/project/root'),
125 |       storage: {
126 |         getProjectTempDir: vi.fn().mockReturnValue('/test/temp'),
127 |       },
128 |       getToolRegistry: vi.fn().mockReturnValue({
129 |         getTool: vi.fn(),
130 |       }),
131 |       getContentGenerator: vi.fn().mockReturnValue(mockContentGenerator),
132 |     } as unknown as Config;
133 | 
134 |     // Disable 429 simulation for tests
135 |     setSimulate429(false);
136 |     // Reset history for each test by creating a new instance
137 |     chat = new GeminiChat(mockConfig, config, []);
138 |   });
139 | 
140 |   afterEach(() => {
141 |     vi.restoreAllMocks();
142 |     vi.resetAllMocks();
143 |   });
144 | 
145 |   describe('sendMessageStream', () => {
146 |     it('should succeed if a tool call is followed by an empty part', async () => {
147 |       // 1. Mock a stream that contains a tool call, then an invalid (empty) part.
148 |       const streamWithToolCall = (async function* () {
149 |         yield {
150 |           candidates: [
151 |             {
152 |               content: {
153 |                 role: 'model',
154 |                 parts: [{ functionCall: { name: 'test_tool', args: {} } }],
155 |               },
156 |             },
157 |           ],
158 |         } as unknown as GenerateContentResponse;
159 |         // This second chunk is invalid according to isValidResponse
160 |         yield {
161 |           candidates: [
162 |             {
163 |               content: {
164 |                 role: 'model',
165 |                 parts: [{ text: '' }],
166 |               },
167 |             },
168 |           ],
169 |         } as unknown as GenerateContentResponse;
170 |       })();
171 | 
172 |       vi.mocked(mockContentGenerator.generateContentStream).mockResolvedValue(
173 |         streamWithToolCall,
174 |       );
175 | 
176 |       // 2. Action & Assert: The stream processing should complete without throwing an error
177 |       // because the presence of a tool call makes the empty final chunk acceptable.
178 |       const stream = await chat.sendMessageStream(
179 |         'test-model',
180 |         { message: 'test message' },
181 |         'prompt-id-tool-call-empty-end',
182 |       );
183 |       await expect(
184 |         (async () => {
185 |           for await (const _ of stream) {
186 |             /* consume stream */
187 |           }
188 |         })(),
189 |       ).resolves.not.toThrow();
190 | 
191 |       // 3. Verify history was recorded correctly
192 |       const history = chat.getHistory();
193 |       expect(history.length).toBe(2); // user turn + model turn
194 |       const modelTurn = history[1]!;
195 |       expect(modelTurn?.parts?.length).toBe(1); // The empty part is discarded
196 |       expect(modelTurn?.parts![0]!.functionCall).toBeDefined();
197 |     });
198 | 
199 |     it('should fail if the stream ends with an empty part and has no finishReason', async () => {
200 |       // 1. Mock a stream that ends with an invalid part and has no finish reason.
201 |       const streamWithNoFinish = (async function* () {
202 |         yield {
203 |           candidates: [
204 |             {
205 |               content: {
206 |                 role: 'model',
207 |                 parts: [{ text: 'Initial content...' }],
208 |               },
209 |             },
210 |           ],
211 |         } as unknown as GenerateContentResponse;
212 |         // This second chunk is invalid and has no finishReason, so it should fail.
213 |         yield {
214 |           candidates: [
215 |             {
216 |               content: {
217 |                 role: 'model',
218 |                 parts: [{ text: '' }],
219 |               },
220 |             },
221 |           ],
222 |         } as unknown as GenerateContentResponse;
223 |       })();
224 | 
225 |       vi.mocked(mockContentGenerator.generateContentStream).mockResolvedValue(
226 |         streamWithNoFinish,
227 |       );
228 | 
229 |       // 2. Action & Assert: The stream should fail because there's no finish reason.
230 |       const stream = await chat.sendMessageStream(
231 |         'test-model',
232 |         { message: 'test message' },
233 |         'prompt-id-no-finish-empty-end',
234 |       );
235 |       await expect(
236 |         (async () => {
237 |           for await (const _ of stream) {
238 |             /* consume stream */
239 |           }
240 |         })(),
241 |       ).rejects.toThrow(InvalidStreamError);
242 |     });
243 | 
244 |     it('should succeed if the stream ends with an invalid part but has a finishReason and contained a valid part', async () => {
245 |       // 1. Mock a stream that sends a valid chunk, then an invalid one, but has a finish reason.
246 |       const streamWithInvalidEnd = (async function* () {
247 |         yield {
248 |           candidates: [
249 |             {
250 |               content: {
251 |                 role: 'model',
252 |                 parts: [{ text: 'Initial valid content...' }],
253 |               },
254 |             },
255 |           ],
256 |         } as unknown as GenerateContentResponse;
257 |         // This second chunk is invalid, but the response has a finishReason.
258 |         yield {
259 |           candidates: [
260 |             {
261 |               content: {
262 |                 role: 'model',
263 |                 parts: [{ text: '' }], // Invalid part
264 |               },
265 |               finishReason: 'STOP',
266 |             },
267 |           ],
268 |         } as unknown as GenerateContentResponse;
269 |       })();
270 | 
271 |       vi.mocked(mockContentGenerator.generateContentStream).mockResolvedValue(
272 |         streamWithInvalidEnd,
273 |       );
274 | 
275 |       // 2. Action & Assert: The stream should complete without throwing an error.
276 |       const stream = await chat.sendMessageStream(
277 |         'test-model',
278 |         { message: 'test message' },
279 |         'prompt-id-valid-then-invalid-end',
280 |       );
281 |       await expect(
282 |         (async () => {
283 |           for await (const _ of stream) {
284 |             /* consume stream */
285 |           }
286 |         })(),
287 |       ).resolves.not.toThrow();
288 | 
289 |       // 3. Verify history was recorded correctly with only the valid part.
290 |       const history = chat.getHistory();
291 |       expect(history.length).toBe(2); // user turn + model turn
292 |       const modelTurn = history[1]!;
293 |       expect(modelTurn?.parts?.length).toBe(1);
294 |       expect(modelTurn?.parts![0]!.text).toBe('Initial valid content...');
295 |     });
296 | 
297 |     it('should consolidate subsequent text chunks after receiving an empty text chunk', async () => {
298 |       // 1. Mock the API to return a stream where one chunk is just an empty text part.
299 |       const multiChunkStream = (async function* () {
300 |         yield {
301 |           candidates: [
302 |             { content: { role: 'model', parts: [{ text: 'Hello' }] } },
303 |           ],
304 |         } as unknown as GenerateContentResponse;
305 |         // FIX: The original test used { text: '' }, which is invalid.
306 |         // A chunk can be empty but still valid. This chunk is now removed
307 |         // as the important part is consolidating what comes after.
308 |         yield {
309 |           candidates: [
310 |             {
311 |               content: { role: 'model', parts: [{ text: ' World!' }] },
312 |               finishReason: 'STOP',
313 |             },
314 |           ],
315 |         } as unknown as GenerateContentResponse;
316 |       })();
317 | 
318 |       vi.mocked(mockContentGenerator.generateContentStream).mockResolvedValue(
319 |         multiChunkStream,
320 |       );
321 | 
322 |       // 2. Action: Send a message and consume the stream.
323 |       const stream = await chat.sendMessageStream(
324 |         'test-model',
325 |         { message: 'test message' },
326 |         'prompt-id-empty-chunk-consolidation',
327 |       );
328 |       for await (const _ of stream) {
329 |         // Consume the stream
330 |       }
331 | 
332 |       // 3. Assert: Check that the final history was correctly consolidated.
333 |       const history = chat.getHistory();
334 |       expect(history.length).toBe(2);
335 |       const modelTurn = history[1]!;
336 |       expect(modelTurn?.parts?.length).toBe(1);
337 |       expect(modelTurn?.parts![0]!.text).toBe('Hello World!');
338 |     });
339 | 
340 |     it('should consolidate adjacent text parts that arrive in separate stream chunks', async () => {
341 |       // 1. Mock the API to return a stream of multiple, adjacent text chunks.
342 |       const multiChunkStream = (async function* () {
343 |         yield {
344 |           candidates: [
345 |             { content: { role: 'model', parts: [{ text: 'This is the ' }] } },
346 |           ],
347 |         } as unknown as GenerateContentResponse;
348 |         yield {
349 |           candidates: [
350 |             { content: { role: 'model', parts: [{ text: 'first part.' }] } },
351 |           ],
352 |         } as unknown as GenerateContentResponse;
353 |         // This function call should break the consolidation.
354 |         yield {
355 |           candidates: [
356 |             {
357 |               content: {
358 |                 role: 'model',
359 |                 parts: [{ functionCall: { name: 'do_stuff', args: {} } }],
360 |               },
361 |             },
362 |           ],
363 |         } as unknown as GenerateContentResponse;
364 |         yield {
365 |           candidates: [
366 |             {
367 |               content: {
368 |                 role: 'model',
369 |                 parts: [{ text: 'This is the second part.' }],
370 |               },
371 |             },
372 |           ],
373 |         } as unknown as GenerateContentResponse;
374 |       })();
375 | 
376 |       vi.mocked(mockContentGenerator.generateContentStream).mockResolvedValue(
377 |         multiChunkStream,
378 |       );
379 | 
380 |       // 2. Action: Send a message and consume the stream.
381 |       const stream = await chat.sendMessageStream(
382 |         'test-model',
383 |         { message: 'test message' },
384 |         'prompt-id-multi-chunk',
385 |       );
386 |       for await (const _ of stream) {
387 |         // Consume the stream to trigger history recording.
388 |       }
389 | 
390 |       // 3. Assert: Check that the final history was correctly consolidated.
391 |       const history = chat.getHistory();
392 | 
393 |       // The history should contain the user's turn and ONE consolidated model turn.
394 |       expect(history.length).toBe(2);
395 | 
396 |       const modelTurn = history[1]!;
397 |       expect(modelTurn.role).toBe('model');
398 | 
399 |       // The model turn should have 3 distinct parts: the merged text, the function call, and the final text.
400 |       expect(modelTurn?.parts?.length).toBe(3);
401 |       expect(modelTurn?.parts![0]!.text).toBe('This is the first part.');
402 |       expect(modelTurn.parts![1]!.functionCall).toBeDefined();
403 |       expect(modelTurn.parts![2]!.text).toBe('This is the second part.');
404 |     });
405 |     it('should preserve text parts that stream in the same chunk as a thought', async () => {
406 |       // 1. Mock the API to return a single chunk containing both a thought and visible text.
407 |       const mixedContentStream = (async function* () {
408 |         yield {
409 |           candidates: [
410 |             {
411 |               content: {
412 |                 role: 'model',
413 |                 parts: [
414 |                   { thought: 'This is a thought.' },
415 |                   { text: 'This is the visible text that should not be lost.' },
416 |                 ],
417 |               },
418 |               finishReason: 'STOP',
419 |             },
420 |           ],
421 |         } as unknown as GenerateContentResponse;
422 |       })();
423 | 
424 |       vi.mocked(mockContentGenerator.generateContentStream).mockResolvedValue(
425 |         mixedContentStream,
426 |       );
427 | 
428 |       // 2. Action: Send a message and fully consume the stream to trigger history recording.
429 |       const stream = await chat.sendMessageStream(
430 |         'test-model',
431 |         { message: 'test message' },
432 |         'prompt-id-mixed-chunk',
433 |       );
434 |       for await (const _ of stream) {
435 |         // This loop consumes the stream.
436 |       }
437 | 
438 |       // 3. Assert: Check the final state of the history.
439 |       const history = chat.getHistory();
440 | 
441 |       // The history should contain two turns: the user's message and the model's response.
442 |       expect(history.length).toBe(2);
443 | 
444 |       const modelTurn = history[1]!;
445 |       expect(modelTurn.role).toBe('model');
446 | 
447 |       // CRUCIAL ASSERTION:
448 |       // The buggy code would fail here, resulting in parts.length being 0.
449 |       // The corrected code will pass, preserving the single visible text part.
450 |       expect(modelTurn?.parts?.length).toBe(1);
451 |       expect(modelTurn?.parts![0]!.text).toBe(
452 |         'This is the visible text that should not be lost.',
453 |       );
454 |     });
455 |     it('should throw an error when a tool call is followed by an empty stream response', async () => {
456 |       // 1. Setup: A history where the model has just made a function call.
457 |       const initialHistory: Content[] = [
458 |         {
459 |           role: 'user',
460 |           parts: [{ text: 'Find a good Italian restaurant for me.' }],
461 |         },
462 |         {
463 |           role: 'model',
464 |           parts: [
465 |             {
466 |               functionCall: {
467 |                 name: 'find_restaurant',
468 |                 args: { cuisine: 'Italian' },
469 |               },
470 |             },
471 |           ],
472 |         },
473 |       ];
474 |       chat.setHistory(initialHistory);
475 | 
476 |       // 2. Mock the API to return an empty/thought-only stream.
477 |       const emptyStreamResponse = (async function* () {
478 |         yield {
479 |           candidates: [
480 |             {
481 |               content: { role: 'model', parts: [{ thought: true }] },
482 |               finishReason: 'STOP',
483 |             },
484 |           ],
485 |         } as unknown as GenerateContentResponse;
486 |       })();
487 |       vi.mocked(mockContentGenerator.generateContentStream).mockResolvedValue(
488 |         emptyStreamResponse,
489 |       );
490 | 
491 |       // 3. Action: Send the function response back to the model and consume the stream.
492 |       const stream = await chat.sendMessageStream(
493 |         'test-model',
494 |         {
495 |           message: {
496 |             functionResponse: {
497 |               name: 'find_restaurant',
498 |               response: { name: 'Vesuvio' },
499 |             },
500 |           },
501 |         },
502 |         'prompt-id-stream-1',
503 |       );
504 | 
505 |       // 4. Assert: The stream processing should throw an InvalidStreamError.
506 |       await expect(
507 |         (async () => {
508 |           for await (const _ of stream) {
509 |             // This loop consumes the stream to trigger the internal logic.
510 |           }
511 |         })(),
512 |       ).rejects.toThrow(InvalidStreamError);
513 |     });
514 | 
515 |     it('should succeed when there is a tool call without finish reason', async () => {
516 |       // Setup: Stream with tool call but no finish reason
517 |       const streamWithToolCall = (async function* () {
518 |         yield {
519 |           candidates: [
520 |             {
521 |               content: {
522 |                 role: 'model',
523 |                 parts: [
524 |                   {
525 |                     functionCall: {
526 |                       name: 'test_function',
527 |                       args: { param: 'value' },
528 |                     },
529 |                   },
530 |                 ],
531 |               },
532 |               // No finishReason
533 |             },
534 |           ],
535 |         } as unknown as GenerateContentResponse;
536 |       })();
537 | 
538 |       vi.mocked(mockContentGenerator.generateContentStream).mockResolvedValue(
539 |         streamWithToolCall,
540 |       );
541 | 
542 |       const stream = await chat.sendMessageStream(
543 |         'test-model',
544 |         { message: 'test' },
545 |         'prompt-id-1',
546 |       );
547 | 
548 |       // Should not throw an error
549 |       await expect(
550 |         (async () => {
551 |           for await (const _ of stream) {
552 |             // consume stream
553 |           }
554 |         })(),
555 |       ).resolves.not.toThrow();
556 |     });
557 | 
558 |     it('should throw InvalidStreamError when no tool call and no finish reason', async () => {
559 |       // Setup: Stream with text but no finish reason and no tool call
560 |       const streamWithoutFinishReason = (async function* () {
561 |         yield {
562 |           candidates: [
563 |             {
564 |               content: {
565 |                 role: 'model',
566 |                 parts: [{ text: 'some response' }],
567 |               },
568 |               // No finishReason
569 |             },
570 |           ],
571 |         } as unknown as GenerateContentResponse;
572 |       })();
573 | 
574 |       vi.mocked(mockContentGenerator.generateContentStream).mockResolvedValue(
575 |         streamWithoutFinishReason,
576 |       );
577 | 
578 |       const stream = await chat.sendMessageStream(
579 |         'test-model',
580 |         { message: 'test' },
581 |         'prompt-id-1',
582 |       );
583 | 
584 |       await expect(
585 |         (async () => {
586 |           for await (const _ of stream) {
587 |             // consume stream
588 |           }
589 |         })(),
590 |       ).rejects.toThrow(InvalidStreamError);
591 |     });
592 | 
593 |     it('should throw InvalidStreamError when no tool call and empty response text', async () => {
594 |       // Setup: Stream with finish reason but empty response (only thoughts)
595 |       const streamWithEmptyResponse = (async function* () {
596 |         yield {
597 |           candidates: [
598 |             {
599 |               content: {
600 |                 role: 'model',
601 |                 parts: [{ thought: 'thinking...' }],
602 |               },
603 |               finishReason: 'STOP',
604 |             },
605 |           ],
606 |         } as unknown as GenerateContentResponse;
607 |       })();
608 | 
609 |       vi.mocked(mockContentGenerator.generateContentStream).mockResolvedValue(
610 |         streamWithEmptyResponse,
611 |       );
612 | 
613 |       const stream = await chat.sendMessageStream(
614 |         'test-model',
615 |         { message: 'test' },
616 |         'prompt-id-1',
617 |       );
618 | 
619 |       await expect(
620 |         (async () => {
621 |           for await (const _ of stream) {
622 |             // consume stream
623 |           }
624 |         })(),
625 |       ).rejects.toThrow(InvalidStreamError);
626 |     });
627 | 
628 |     it('should succeed when there is finish reason and response text', async () => {
629 |       // Setup: Stream with both finish reason and text content
630 |       const validStream = (async function* () {
631 |         yield {
632 |           candidates: [
633 |             {
634 |               content: {
635 |                 role: 'model',
[TRUNCATED]
```

src/core/geminiChat.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | // DISCLAIMER: This is a copied version of https://github.com/googleapis/js-genai/blob/main/src/chats.ts with the intention of working around a key bug
8 | // where function responses are not treated as "valid" responses: https://b.corp.google.com/issues/420354090
9 | 
10 | import {
11 |   GenerateContentResponse,
12 |   type Content,
13 |   type GenerateContentConfig,
14 |   type SendMessageParameters,
15 |   type Part,
16 |   type Tool,
17 |   FinishReason,
18 | } from '@google/genai';
19 | import { toParts } from '../code_assist/converter.js';
20 | import { createUserContent } from '@google/genai';
21 | import { retryWithBackoff } from '../utils/retry.js';
22 | import type { Config } from '../config/config.js';
23 | import {
24 |   DEFAULT_GEMINI_FLASH_MODEL,
25 |   getEffectiveModel,
26 | } from '../config/models.js';
27 | import { hasCycleInSchema, MUTATOR_KINDS } from '../tools/tools.js';
28 | import type { StructuredError } from './turn.js';
29 | import type { CompletedToolCall } from './coreToolScheduler.js';
30 | import {
31 |   logContentRetry,
32 |   logContentRetryFailure,
33 | } from '../telemetry/loggers.js';
34 | import { ChatRecordingService } from '../services/chatRecordingService.js';
35 | import {
36 |   ContentRetryEvent,
37 |   ContentRetryFailureEvent,
38 | } from '../telemetry/types.js';
39 | import { handleFallback } from '../fallback/handler.js';
40 | import { isFunctionResponse } from '../utils/messageInspectors.js';
41 | import { partListUnionToString } from './geminiRequest.js';
42 | import { uiTelemetryService } from '../telemetry/uiTelemetry.js';
43 | 
44 | export enum StreamEventType {
45 |   /** A regular content chunk from the API. */
46 |   CHUNK = 'chunk',
47 |   /** A signal that a retry is about to happen. The UI should discard any partial
48 |    * content from the attempt that just failed. */
49 |   RETRY = 'retry',
50 | }
51 | 
52 | export type StreamEvent =
53 |   | { type: StreamEventType.CHUNK; value: GenerateContentResponse }
54 |   | { type: StreamEventType.RETRY };
55 | 
56 | /**
57 |  * Options for retrying due to invalid content from the model.
58 |  */
59 | interface ContentRetryOptions {
60 |   /** Total number of attempts to make (1 initial + N retries). */
61 |   maxAttempts: number;
62 |   /** The base delay in milliseconds for linear backoff. */
63 |   initialDelayMs: number;
64 | }
65 | 
66 | const INVALID_CONTENT_RETRY_OPTIONS: ContentRetryOptions = {
67 |   maxAttempts: 2, // 1 initial call + 1 retry
68 |   initialDelayMs: 500,
69 | };
70 | 
71 | /**
72 |  * Returns true if the response is valid, false otherwise.
73 |  */
74 | function isValidResponse(response: GenerateContentResponse): boolean {
75 |   if (response.candidates === undefined || response.candidates.length === 0) {
76 |     return false;
77 |   }
78 |   const content = response.candidates[0]?.content;
79 |   if (content === undefined) {
80 |     return false;
81 |   }
82 |   return isValidContent(content);
83 | }
84 | 
85 | export function isValidNonThoughtTextPart(part: Part): boolean {
86 |   return (
87 |     typeof part.text === 'string' &&
88 |     !part.thought &&
89 |     // Technically, the model should never generate parts that have text and
90 |     //  any of these but we don't trust them so check anyways.
91 |     !part.functionCall &&
92 |     !part.functionResponse &&
93 |     !part.inlineData &&
94 |     !part.fileData
95 |   );
96 | }
97 | 
98 | function isValidContent(content: Content): boolean {
99 |   if (content.parts === undefined || content.parts.length === 0) {
100 |     return false;
101 |   }
102 |   for (const part of content.parts) {
103 |     if (part === undefined || Object.keys(part).length === 0) {
104 |       return false;
105 |     }
106 |     if (!part.thought && part.text !== undefined && part.text === '') {
107 |       return false;
108 |     }
109 |   }
110 |   return true;
111 | }
112 | 
113 | /**
114 |  * Validates the history contains the correct roles.
115 |  *
116 |  * @throws Error if the history does not start with a user turn.
117 |  * @throws Error if the history contains an invalid role.
118 |  */
119 | function validateHistory(history: Content[]) {
120 |   for (const content of history) {
121 |     if (content.role !== 'user' && content.role !== 'model') {
122 |       throw new Error(`Role must be user or model, but got ${content.role}.`);
123 |     }
124 |   }
125 | }
126 | 
127 | /**
128 |  * Extracts the curated (valid) history from a comprehensive history.
129 |  *
130 |  * @remarks
131 |  * The model may sometimes generate invalid or empty contents(e.g., due to safety
132 |  * filters or recitation). Extracting valid turns from the history
133 |  * ensures that subsequent requests could be accepted by the model.
134 |  */
135 | function extractCuratedHistory(comprehensiveHistory: Content[]): Content[] {
136 |   if (comprehensiveHistory === undefined || comprehensiveHistory.length === 0) {
137 |     return [];
138 |   }
139 |   const curatedHistory: Content[] = [];
140 |   const length = comprehensiveHistory.length;
141 |   let i = 0;
142 |   while (i < length) {
143 |     if (comprehensiveHistory[i].role === 'user') {
144 |       curatedHistory.push(comprehensiveHistory[i]);
145 |       i++;
146 |     } else {
147 |       const modelOutput: Content[] = [];
148 |       let isValid = true;
149 |       while (i < length && comprehensiveHistory[i].role === 'model') {
150 |         modelOutput.push(comprehensiveHistory[i]);
151 |         if (isValid && !isValidContent(comprehensiveHistory[i])) {
152 |           isValid = false;
153 |         }
154 |         i++;
155 |       }
156 |       if (isValid) {
157 |         curatedHistory.push(...modelOutput);
158 |       }
159 |     }
160 |   }
161 |   return curatedHistory;
162 | }
163 | 
164 | /**
165 |  * Custom error to signal that a stream completed with invalid content,
166 |  * which should trigger a retry.
167 |  */
168 | export class InvalidStreamError extends Error {
169 |   readonly type: 'NO_FINISH_REASON' | 'NO_RESPONSE_TEXT';
170 | 
171 |   constructor(message: string, type: 'NO_FINISH_REASON' | 'NO_RESPONSE_TEXT') {
172 |     super(message);
173 |     this.name = 'InvalidStreamError';
174 |     this.type = type;
175 |   }
176 | }
177 | 
178 | /**
179 |  * Chat session that enables sending messages to the model with previous
180 |  * conversation context.
181 |  *
182 |  * @remarks
183 |  * The session maintains all the turns between user and model.
184 |  */
185 | export class GeminiChat {
186 |   // A promise to represent the current state of the message being sent to the
187 |   // model.
188 |   private sendPromise: Promise<void> = Promise.resolve();
189 |   private readonly chatRecordingService: ChatRecordingService;
190 | 
191 |   constructor(
192 |     private readonly config: Config,
193 |     private readonly generationConfig: GenerateContentConfig = {},
194 |     private history: Content[] = [],
195 |   ) {
196 |     validateHistory(history);
197 |     this.chatRecordingService = new ChatRecordingService(config);
198 |     this.chatRecordingService.initialize();
199 |   }
200 | 
201 |   setSystemInstruction(sysInstr: string) {
202 |     this.generationConfig.systemInstruction = sysInstr;
203 |   }
204 | 
205 |   /**
206 |    * Sends a message to the model and returns the response in chunks.
207 |    *
208 |    * @remarks
209 |    * This method will wait for the previous message to be processed before
210 |    * sending the next message.
211 |    *
212 |    * @see {@link Chat#sendMessage} for non-streaming method.
213 |    * @param params - parameters for sending the message.
214 |    * @return The model's response.
215 |    *
216 |    * @example
217 |    * ```ts
218 |    * const chat = ai.chats.create({model: 'gemini-2.0-flash'});
219 |    * const response = await chat.sendMessageStream({
220 |    * message: 'Why is the sky blue?'
221 |    * });
222 |    * for await (const chunk of response) {
223 |    * console.log(chunk.text);
224 |    * }
225 |    * ```
226 |    */
227 |   async sendMessageStream(
228 |     model: string,
229 |     params: SendMessageParameters,
230 |     prompt_id: string,
231 |   ): Promise<AsyncGenerator<StreamEvent>> {
232 |     await this.sendPromise;
233 | 
234 |     let streamDoneResolver: () => void;
235 |     const streamDonePromise = new Promise<void>((resolve) => {
236 |       streamDoneResolver = resolve;
237 |     });
238 |     this.sendPromise = streamDonePromise;
239 | 
240 |     const userContent = createUserContent(params.message);
241 | 
242 |     // Record user input - capture complete message with all parts (text, files, images, etc.)
243 |     // but skip recording function responses (tool call results) as they should be stored in tool call records
244 |     if (!isFunctionResponse(userContent)) {
245 |       const userMessage = Array.isArray(params.message)
246 |         ? params.message
247 |         : [params.message];
248 |       const userMessageContent = partListUnionToString(toParts(userMessage));
249 |       this.chatRecordingService.recordMessage({
250 |         model,
251 |         type: 'user',
252 |         content: userMessageContent,
253 |       });
254 |     }
255 | 
256 |     // Add user content to history ONCE before any attempts.
257 |     this.history.push(userContent);
258 |     const requestContents = this.getHistory(true);
259 | 
260 |     // eslint-disable-next-line @typescript-eslint/no-this-alias
261 |     const self = this;
262 |     return (async function* () {
263 |       try {
264 |         let lastError: unknown = new Error('Request failed after all retries.');
265 | 
266 |         for (
267 |           let attempt = 0;
268 |           attempt < INVALID_CONTENT_RETRY_OPTIONS.maxAttempts;
269 |           attempt++
270 |         ) {
271 |           try {
272 |             if (attempt > 0) {
273 |               yield { type: StreamEventType.RETRY };
274 |             }
275 | 
276 |             // If this is a retry, set temperature to 1 to encourage different output.
277 |             const currentParams = { ...params };
278 |             if (attempt > 0) {
279 |               currentParams.config = {
280 |                 ...currentParams.config,
281 |                 temperature: 1,
282 |               };
283 |             }
284 | 
285 |             const stream = await self.makeApiCallAndProcessStream(
286 |               model,
287 |               requestContents,
288 |               currentParams,
289 |               prompt_id,
290 |             );
291 | 
292 |             for await (const chunk of stream) {
293 |               yield { type: StreamEventType.CHUNK, value: chunk };
294 |             }
295 | 
296 |             lastError = null;
297 |             break;
298 |           } catch (error) {
299 |             lastError = error;
300 |             const isContentError = error instanceof InvalidStreamError;
301 | 
302 |             if (isContentError) {
303 |               // Check if we have more attempts left.
304 |               if (attempt < INVALID_CONTENT_RETRY_OPTIONS.maxAttempts - 1) {
305 |                 logContentRetry(
306 |                   self.config,
307 |                   new ContentRetryEvent(
308 |                     attempt,
309 |                     (error as InvalidStreamError).type,
310 |                     INVALID_CONTENT_RETRY_OPTIONS.initialDelayMs,
311 |                     model,
312 |                   ),
313 |                 );
314 |                 await new Promise((res) =>
315 |                   setTimeout(
316 |                     res,
317 |                     INVALID_CONTENT_RETRY_OPTIONS.initialDelayMs *
318 |                       (attempt + 1),
319 |                   ),
320 |                 );
321 |                 continue;
322 |               }
323 |             }
324 |             break;
325 |           }
326 |         }
327 | 
328 |         if (lastError) {
329 |           if (lastError instanceof InvalidStreamError) {
330 |             logContentRetryFailure(
331 |               self.config,
332 |               new ContentRetryFailureEvent(
333 |                 INVALID_CONTENT_RETRY_OPTIONS.maxAttempts,
334 |                 (lastError as InvalidStreamError).type,
335 |                 model,
336 |               ),
337 |             );
338 |           }
339 |           throw lastError;
340 |         }
341 |       } finally {
342 |         streamDoneResolver!();
343 |       }
344 |     })();
345 |   }
346 | 
347 |   private async makeApiCallAndProcessStream(
348 |     model: string,
349 |     requestContents: Content[],
350 |     params: SendMessageParameters,
351 |     prompt_id: string,
352 |   ): Promise<AsyncGenerator<GenerateContentResponse>> {
353 |     const apiCall = () => {
354 |       const modelToUse = getEffectiveModel(
355 |         this.config.isInFallbackMode(),
356 |         model,
357 |       );
358 | 
359 |       if (
360 |         this.config.getQuotaErrorOccurred() &&
361 |         modelToUse === DEFAULT_GEMINI_FLASH_MODEL
362 |       ) {
363 |         throw new Error(
364 |           'Please submit a new query to continue with the Flash model.',
365 |         );
366 |       }
367 | 
368 |       return this.config.getContentGenerator().generateContentStream(
369 |         {
370 |           model: modelToUse,
371 |           contents: requestContents,
372 |           config: { ...this.generationConfig, ...params.config },
373 |         },
374 |         prompt_id,
375 |       );
376 |     };
377 | 
378 |     const onPersistent429Callback = async (
379 |       authType?: string,
380 |       error?: unknown,
381 |     ) => await handleFallback(this.config, model, authType, error);
382 | 
383 |     const streamResponse = await retryWithBackoff(apiCall, {
384 |       onPersistent429: onPersistent429Callback,
385 |       authType: this.config.getContentGeneratorConfig()?.authType,
386 |     });
387 | 
388 |     return this.processStreamResponse(model, streamResponse);
389 |   }
390 | 
391 |   /**
392 |    * Returns the chat history.
393 |    *
394 |    * @remarks
395 |    * The history is a list of contents alternating between user and model.
396 |    *
397 |    * There are two types of history:
398 |    * - The `curated history` contains only the valid turns between user and
399 |    * model, which will be included in the subsequent requests sent to the model.
400 |    * - The `comprehensive history` contains all turns, including invalid or
401 |    * empty model outputs, providing a complete record of the history.
402 |    *
403 |    * The history is updated after receiving the response from the model,
404 |    * for streaming response, it means receiving the last chunk of the response.
405 |    *
406 |    * The `comprehensive history` is returned by default. To get the `curated
407 |    * history`, set the `curated` parameter to `true`.
408 |    *
409 |    * @param curated - whether to return the curated history or the comprehensive
410 |    * history.
411 |    * @return History contents alternating between user and model for the entire
412 |    * chat session.
413 |    */
414 |   getHistory(curated: boolean = false): Content[] {
415 |     const history = curated
416 |       ? extractCuratedHistory(this.history)
417 |       : this.history;
418 |     // Deep copy the history to avoid mutating the history outside of the
419 |     // chat session.
420 |     return structuredClone(history);
421 |   }
422 | 
423 |   /**
424 |    * Clears the chat history.
425 |    */
426 |   clearHistory(): void {
427 |     this.history = [];
428 |   }
429 | 
430 |   /**
431 |    * Adds a new entry to the chat history.
432 |    */
433 |   addHistory(content: Content): void {
434 |     this.history.push(content);
435 |   }
436 | 
437 |   setHistory(history: Content[]): void {
438 |     this.history = history;
439 |   }
440 | 
441 |   stripThoughtsFromHistory(): void {
442 |     this.history = this.history.map((content) => {
443 |       const newContent = { ...content };
444 |       if (newContent.parts) {
445 |         newContent.parts = newContent.parts.map((part) => {
446 |           if (part && typeof part === 'object' && 'thoughtSignature' in part) {
447 |             const newPart = { ...part };
448 |             delete (newPart as { thoughtSignature?: string }).thoughtSignature;
449 |             return newPart;
450 |           }
451 |           return part;
452 |         });
453 |       }
454 |       return newContent;
455 |     });
456 |   }
457 | 
458 |   setTools(tools: Tool[]): void {
459 |     this.generationConfig.tools = tools;
460 |   }
461 | 
462 |   async maybeIncludeSchemaDepthContext(error: StructuredError): Promise<void> {
463 |     // Check for potentially problematic cyclic tools with cyclic schemas
464 |     // and include a recommendation to remove potentially problematic tools.
465 |     if (
466 |       isSchemaDepthError(error.message) ||
467 |       isInvalidArgumentError(error.message)
468 |     ) {
469 |       const tools = this.config.getToolRegistry().getAllTools();
470 |       const cyclicSchemaTools: string[] = [];
471 |       for (const tool of tools) {
472 |         if (
473 |           (tool.schema.parametersJsonSchema &&
474 |             hasCycleInSchema(tool.schema.parametersJsonSchema)) ||
475 |           (tool.schema.parameters && hasCycleInSchema(tool.schema.parameters))
476 |         ) {
477 |           cyclicSchemaTools.push(tool.displayName);
478 |         }
479 |       }
480 |       if (cyclicSchemaTools.length > 0) {
481 |         const extraDetails =
482 |           `\n\nThis error was probably caused by cyclic schema references in one of the following tools, try disabling them with excludeTools:\n\n - ` +
483 |           cyclicSchemaTools.join(`\n - `) +
484 |           `\n`;
485 |         error.message += extraDetails;
486 |       }
487 |     }
488 |   }
489 | 
490 |   private async *processStreamResponse(
491 |     model: string,
492 |     streamResponse: AsyncGenerator<GenerateContentResponse>,
493 |   ): AsyncGenerator<GenerateContentResponse> {
494 |     const modelResponseParts: Part[] = [];
495 | 
496 |     let hasToolCall = false;
497 |     let hasFinishReason = false;
498 | 
499 |     for await (const chunk of this.stopBeforeSecondMutator(streamResponse)) {
500 |       hasFinishReason =
501 |         chunk?.candidates?.some((candidate) => candidate.finishReason) ?? false;
502 |       if (isValidResponse(chunk)) {
503 |         const content = chunk.candidates?.[0]?.content;
504 |         if (content?.parts) {
505 |           if (content.parts.some((part) => part.thought)) {
506 |             // Record thoughts
507 |             this.recordThoughtFromContent(content);
508 |           }
509 |           if (content.parts.some((part) => part.functionCall)) {
510 |             hasToolCall = true;
511 |           }
512 | 
513 |           modelResponseParts.push(
514 |             ...content.parts.filter((part) => !part.thought),
515 |           );
516 |         }
517 |       }
518 | 
519 |       // Record token usage if this chunk has usageMetadata
520 |       if (chunk.usageMetadata) {
521 |         this.chatRecordingService.recordMessageTokens(chunk.usageMetadata);
522 |         if (chunk.usageMetadata.promptTokenCount !== undefined) {
523 |           uiTelemetryService.setLastPromptTokenCount(
524 |             chunk.usageMetadata.promptTokenCount,
525 |           );
526 |         }
527 |       }
528 | 
529 |       yield chunk; // Yield every chunk to the UI immediately.
530 |     }
531 | 
532 |     // String thoughts and consolidate text parts.
533 |     const consolidatedParts: Part[] = [];
534 |     for (const part of modelResponseParts) {
535 |       const lastPart = consolidatedParts[consolidatedParts.length - 1];
536 |       if (
537 |         lastPart?.text &&
538 |         isValidNonThoughtTextPart(lastPart) &&
539 |         isValidNonThoughtTextPart(part)
540 |       ) {
541 |         lastPart.text += part.text;
542 |       } else {
543 |         consolidatedParts.push(part);
544 |       }
545 |     }
546 | 
547 |     const responseText = consolidatedParts
548 |       .filter((part) => part.text)
549 |       .map((part) => part.text)
550 |       .join('')
551 |       .trim();
552 | 
553 |     // Record model response text from the collected parts
554 |     if (responseText) {
555 |       this.chatRecordingService.recordMessage({
556 |         model,
557 |         type: 'gemini',
558 |         content: responseText,
559 |       });
560 |     }
561 | 
562 |     // Stream validation logic: A stream is considered successful if:
563 |     // 1. There's a tool call (tool calls can end without explicit finish reasons), OR
564 |     // 2. There's a finish reason AND we have non-empty response text
565 |     //
566 |     // We throw an error only when there's no tool call AND:
567 |     // - No finish reason, OR
568 |     // - Empty response text (e.g., only thoughts with no actual content)
569 |     if (!hasToolCall && (!hasFinishReason || !responseText)) {
570 |       if (!hasFinishReason) {
571 |         throw new InvalidStreamError(
572 |           'Model stream ended without a finish reason.',
573 |           'NO_FINISH_REASON',
574 |         );
575 |       } else {
576 |         throw new InvalidStreamError(
577 |           'Model stream ended with empty response text.',
578 |           'NO_RESPONSE_TEXT',
579 |         );
580 |       }
581 |     }
582 | 
583 |     this.history.push({ role: 'model', parts: consolidatedParts });
584 |   }
585 | 
586 |   /**
587 |    * Gets the chat recording service instance.
588 |    */
589 |   getChatRecordingService(): ChatRecordingService {
590 |     return this.chatRecordingService;
591 |   }
592 | 
593 |   /**
594 |    * Records completed tool calls with full metadata.
595 |    * This is called by external components when tool calls complete, before sending responses to Gemini.
596 |    */
597 |   recordCompletedToolCalls(
598 |     model: string,
599 |     toolCalls: CompletedToolCall[],
600 |   ): void {
601 |     const toolCallRecords = toolCalls.map((call) => {
602 |       const resultDisplayRaw = call.response?.resultDisplay;
603 |       const resultDisplay =
604 |         typeof resultDisplayRaw === 'string' ? resultDisplayRaw : undefined;
605 | 
606 |       return {
607 |         id: call.request.callId,
608 |         name: call.request.name,
609 |         args: call.request.args,
610 |         result: call.response?.responseParts || null,
611 |         status: call.status as 'error' | 'success' | 'cancelled',
612 |         timestamp: new Date().toISOString(),
613 |         resultDisplay,
614 |       };
615 |     });
616 | 
617 |     this.chatRecordingService.recordToolCalls(model, toolCallRecords);
618 |   }
619 | 
620 |   /**
[TRUNCATED]
```

src/core/geminiRequest.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { type PartListUnion } from '@google/genai';
8 | import { partToString } from '../utils/partUtils.js';
9 | 
10 | /**
11 |  * Represents a request to be sent to the Gemini API.
12 |  * For now, it's an alias to PartListUnion as the primary content.
13 |  * This can be expanded later to include other request parameters.
14 |  */
15 | export type GeminiCodeRequest = PartListUnion;
16 | 
17 | export function partListUnionToString(value: PartListUnion): string {
18 |   return partToString(value, { verbose: true });
19 | }
```

src/core/logger.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   vi,
12 |   beforeEach,
13 |   afterEach,
14 |   afterAll,
15 | } from 'vitest';
16 | import type { LogEntry } from './logger.js';
17 | import {
18 |   Logger,
19 |   MessageSenderType,
20 |   encodeTagName,
21 |   decodeTagName,
22 | } from './logger.js';
23 | import { Storage } from '../config/storage.js';
24 | import { promises as fs, existsSync } from 'node:fs';
25 | import path from 'node:path';
26 | import type { Content } from '@google/genai';
27 | 
28 | import crypto from 'node:crypto';
29 | import os from 'node:os';
30 | 
31 | const GEMINI_DIR_NAME = '.gemini';
32 | const TMP_DIR_NAME = 'tmp';
33 | const LOG_FILE_NAME = 'logs.json';
34 | const CHECKPOINT_FILE_NAME = 'checkpoint.json';
35 | 
36 | const projectDir = process.cwd();
37 | const hash = crypto.createHash('sha256').update(projectDir).digest('hex');
38 | const TEST_GEMINI_DIR = path.join(
39 |   os.homedir(),
40 |   GEMINI_DIR_NAME,
41 |   TMP_DIR_NAME,
42 |   hash,
43 | );
44 | 
45 | const TEST_LOG_FILE_PATH = path.join(TEST_GEMINI_DIR, LOG_FILE_NAME);
46 | const TEST_CHECKPOINT_FILE_PATH = path.join(
47 |   TEST_GEMINI_DIR,
48 |   CHECKPOINT_FILE_NAME,
49 | );
50 | 
51 | async function cleanupLogAndCheckpointFiles() {
52 |   try {
53 |     await fs.rm(TEST_GEMINI_DIR, { recursive: true, force: true });
54 |   } catch (_error) {
55 |     // Ignore errors, as the directory may not exist, which is fine.
56 |   }
57 | }
58 | 
59 | async function readLogFile(): Promise<LogEntry[]> {
60 |   try {
61 |     const content = await fs.readFile(TEST_LOG_FILE_PATH, 'utf-8');
62 |     return JSON.parse(content) as LogEntry[];
63 |   } catch (error) {
64 |     if ((error as NodeJS.ErrnoException).code === 'ENOENT') {
65 |       return [];
66 |     }
67 |     throw error;
68 |   }
69 | }
70 | 
71 | vi.mock('../utils/session.js', () => ({
72 |   sessionId: 'test-session-id',
73 | }));
74 | 
75 | describe('Logger', () => {
76 |   let logger: Logger;
77 |   const testSessionId = 'test-session-id';
78 | 
79 |   beforeEach(async () => {
80 |     vi.resetAllMocks();
81 |     vi.useFakeTimers();
82 |     vi.setSystemTime(new Date('2025-01-01T12:00:00.000Z'));
83 |     // Clean up before the test
84 |     await cleanupLogAndCheckpointFiles();
85 |     // Ensure the directory exists for the test
86 |     await fs.mkdir(TEST_GEMINI_DIR, { recursive: true });
87 |     logger = new Logger(testSessionId, new Storage(process.cwd()));
88 |     await logger.initialize();
89 |   });
90 | 
91 |   afterEach(async () => {
92 |     if (logger) {
93 |       logger.close();
94 |     }
95 |     // Clean up after the test
96 |     await cleanupLogAndCheckpointFiles();
97 |     vi.useRealTimers();
98 |     vi.restoreAllMocks();
99 |   });
100 | 
101 |   afterAll(async () => {
102 |     // Final cleanup
103 |     await cleanupLogAndCheckpointFiles();
104 |   });
105 | 
106 |   describe('initialize', () => {
107 |     it('should create .gemini directory and an empty log file if none exist', async () => {
108 |       const dirExists = await fs
109 |         .access(TEST_GEMINI_DIR)
110 |         .then(() => true)
111 |         .catch(() => false);
112 |       expect(dirExists).toBe(true);
113 | 
114 |       const fileExists = await fs
115 |         .access(TEST_LOG_FILE_PATH)
116 |         .then(() => true)
117 |         .catch(() => false);
118 |       expect(fileExists).toBe(true);
119 | 
120 |       const logContent = await readLogFile();
121 |       expect(logContent).toEqual([]);
122 |     });
123 | 
124 |     it('should load existing logs and set correct messageId for the current session', async () => {
125 |       const currentSessionId = 'session-123';
126 |       const anotherSessionId = 'session-456';
127 |       const existingLogs: LogEntry[] = [
128 |         {
129 |           sessionId: currentSessionId,
130 |           messageId: 0,
131 |           timestamp: new Date('2025-01-01T10:00:05.000Z').toISOString(),
132 |           type: MessageSenderType.USER,
133 |           message: 'Msg1',
134 |         },
135 |         {
136 |           sessionId: anotherSessionId,
137 |           messageId: 5,
138 |           timestamp: new Date('2025-01-01T09:00:00.000Z').toISOString(),
139 |           type: MessageSenderType.USER,
140 |           message: 'OldMsg',
141 |         },
142 |         {
143 |           sessionId: currentSessionId,
144 |           messageId: 1,
145 |           timestamp: new Date('2025-01-01T10:00:10.000Z').toISOString(),
146 |           type: MessageSenderType.USER,
147 |           message: 'Msg2',
148 |         },
149 |       ];
150 |       await fs.writeFile(
151 |         TEST_LOG_FILE_PATH,
152 |         JSON.stringify(existingLogs, null, 2),
153 |       );
154 |       const newLogger = new Logger(
155 |         currentSessionId,
156 |         new Storage(process.cwd()),
157 |       );
158 |       await newLogger.initialize();
159 |       expect(newLogger['messageId']).toBe(2);
160 |       expect(newLogger['logs']).toEqual(existingLogs);
161 |       newLogger.close();
162 |     });
163 | 
164 |     it('should set messageId to 0 for a new session if log file exists but has no logs for current session', async () => {
165 |       const existingLogs: LogEntry[] = [
166 |         {
167 |           sessionId: 'some-other-session',
168 |           messageId: 5,
169 |           timestamp: new Date().toISOString(),
170 |           type: MessageSenderType.USER,
171 |           message: 'OldMsg',
172 |         },
173 |       ];
174 |       await fs.writeFile(
175 |         TEST_LOG_FILE_PATH,
176 |         JSON.stringify(existingLogs, null, 2),
177 |       );
178 |       const newLogger = new Logger('a-new-session', new Storage(process.cwd()));
179 |       await newLogger.initialize();
180 |       expect(newLogger['messageId']).toBe(0);
181 |       newLogger.close();
182 |     });
183 | 
184 |     it('should be idempotent', async () => {
185 |       await logger.logMessage(MessageSenderType.USER, 'test message');
186 |       const initialMessageId = logger['messageId'];
187 |       const initialLogCount = logger['logs'].length;
188 | 
189 |       await logger.initialize(); // Second call should not change state
190 | 
191 |       expect(logger['messageId']).toBe(initialMessageId);
192 |       expect(logger['logs'].length).toBe(initialLogCount);
193 |       const logsFromFile = await readLogFile();
194 |       expect(logsFromFile.length).toBe(1);
195 |     });
196 | 
197 |     it('should handle invalid JSON in log file by backing it up and starting fresh', async () => {
198 |       await fs.writeFile(TEST_LOG_FILE_PATH, 'invalid json');
199 |       const consoleDebugSpy = vi
200 |         .spyOn(console, 'debug')
201 |         .mockImplementation(() => {});
202 | 
203 |       const newLogger = new Logger(testSessionId, new Storage(process.cwd()));
204 |       await newLogger.initialize();
205 | 
206 |       expect(consoleDebugSpy).toHaveBeenCalledWith(
207 |         expect.stringContaining('Invalid JSON in log file'),
208 |         expect.any(SyntaxError),
209 |       );
210 |       const logContent = await readLogFile();
211 |       expect(logContent).toEqual([]);
212 |       const dirContents = await fs.readdir(TEST_GEMINI_DIR);
213 |       expect(
214 |         dirContents.some(
215 |           (f) =>
216 |             f.startsWith(LOG_FILE_NAME + '.invalid_json') && f.endsWith('.bak'),
217 |         ),
218 |       ).toBe(true);
219 |       newLogger.close();
220 |     });
221 | 
222 |     it('should handle non-array JSON in log file by backing it up and starting fresh', async () => {
223 |       await fs.writeFile(
224 |         TEST_LOG_FILE_PATH,
225 |         JSON.stringify({ not: 'an array' }),
226 |       );
227 |       const consoleDebugSpy = vi
228 |         .spyOn(console, 'debug')
229 |         .mockImplementation(() => {});
230 | 
231 |       const newLogger = new Logger(testSessionId, new Storage(process.cwd()));
232 |       await newLogger.initialize();
233 | 
234 |       expect(consoleDebugSpy).toHaveBeenCalledWith(
235 |         `Log file at ${TEST_LOG_FILE_PATH} is not a valid JSON array. Starting with empty logs.`,
236 |       );
237 |       const logContent = await readLogFile();
238 |       expect(logContent).toEqual([]);
239 |       const dirContents = await fs.readdir(TEST_GEMINI_DIR);
240 |       expect(
241 |         dirContents.some(
242 |           (f) =>
243 |             f.startsWith(LOG_FILE_NAME + '.malformed_array') &&
244 |             f.endsWith('.bak'),
245 |         ),
246 |       ).toBe(true);
247 |       newLogger.close();
248 |     });
249 |   });
250 | 
251 |   describe('logMessage', () => {
252 |     it('should append a message to the log file and update in-memory logs', async () => {
253 |       await logger.logMessage(MessageSenderType.USER, 'Hello, world!');
254 |       const logsFromFile = await readLogFile();
255 |       expect(logsFromFile.length).toBe(1);
256 |       expect(logsFromFile[0]).toMatchObject({
257 |         sessionId: testSessionId,
258 |         messageId: 0,
259 |         type: MessageSenderType.USER,
260 |         message: 'Hello, world!',
261 |         timestamp: new Date('2025-01-01T12:00:00.000Z').toISOString(),
262 |       });
263 |       expect(logger['logs'].length).toBe(1);
264 |       expect(logger['logs'][0]).toEqual(logsFromFile[0]);
265 |       expect(logger['messageId']).toBe(1);
266 |     });
267 | 
268 |     it('should correctly increment messageId for subsequent messages in the same session', async () => {
269 |       await logger.logMessage(MessageSenderType.USER, 'First');
270 |       vi.advanceTimersByTime(1000);
271 |       await logger.logMessage(MessageSenderType.USER, 'Second');
272 |       const logs = await readLogFile();
273 |       expect(logs.length).toBe(2);
274 |       expect(logs[0].messageId).toBe(0);
275 |       expect(logs[1].messageId).toBe(1);
276 |       expect(logs[1].timestamp).not.toBe(logs[0].timestamp);
277 |       expect(logger['messageId']).toBe(2);
278 |     });
279 | 
280 |     it('should handle logger not initialized', async () => {
281 |       const uninitializedLogger = new Logger(
282 |         testSessionId,
283 |         new Storage(process.cwd()),
284 |       );
285 |       uninitializedLogger.close(); // Ensure it's treated as uninitialized
286 |       const consoleDebugSpy = vi
287 |         .spyOn(console, 'debug')
288 |         .mockImplementation(() => {});
289 |       await uninitializedLogger.logMessage(MessageSenderType.USER, 'test');
290 |       expect(consoleDebugSpy).toHaveBeenCalledWith(
291 |         'Logger not initialized or session ID missing. Cannot log message.',
292 |       );
293 |       expect((await readLogFile()).length).toBe(0);
294 |       uninitializedLogger.close();
295 |     });
296 | 
297 |     it('should simulate concurrent writes from different logger instances to the same file', async () => {
298 |       const concurrentSessionId = 'concurrent-session';
299 |       const logger1 = new Logger(
300 |         concurrentSessionId,
301 |         new Storage(process.cwd()),
302 |       );
303 |       await logger1.initialize();
304 | 
305 |       const logger2 = new Logger(
306 |         concurrentSessionId,
307 |         new Storage(process.cwd()),
308 |       );
309 |       await logger2.initialize();
310 |       expect(logger2['sessionId']).toEqual(logger1['sessionId']);
311 | 
312 |       await logger1.logMessage(MessageSenderType.USER, 'L1M1');
313 |       vi.advanceTimersByTime(10);
314 |       await logger2.logMessage(MessageSenderType.USER, 'L2M1');
315 |       vi.advanceTimersByTime(10);
316 |       await logger1.logMessage(MessageSenderType.USER, 'L1M2');
317 |       vi.advanceTimersByTime(10);
318 |       await logger2.logMessage(MessageSenderType.USER, 'L2M2');
319 | 
320 |       const logsFromFile = await readLogFile();
321 |       expect(logsFromFile.length).toBe(4);
322 |       const messageIdsInFile = logsFromFile
323 |         .map((log) => log.messageId)
324 |         .sort((a, b) => a - b);
325 |       expect(messageIdsInFile).toEqual([0, 1, 2, 3]);
326 | 
327 |       const messagesInFile = logsFromFile
328 |         .sort((a, b) => a.messageId - b.messageId)
329 |         .map((l) => l.message);
330 |       expect(messagesInFile).toEqual(['L1M1', 'L2M1', 'L1M2', 'L2M2']);
331 | 
332 |       // Check internal state (next messageId each logger would use for that session)
333 |       expect(logger1['messageId']).toBe(3);
334 |       expect(logger2['messageId']).toBe(4);
335 | 
336 |       logger1.close();
337 |       logger2.close();
338 |     });
339 | 
340 |     it('should not throw, not increment messageId, and log error if writing to file fails', async () => {
341 |       vi.spyOn(fs, 'writeFile').mockRejectedValueOnce(new Error('Disk full'));
342 |       const consoleDebugSpy = vi
343 |         .spyOn(console, 'debug')
344 |         .mockImplementation(() => {});
345 |       const initialMessageId = logger['messageId'];
346 |       const initialLogCount = logger['logs'].length;
347 | 
348 |       await logger.logMessage(MessageSenderType.USER, 'test fail write');
349 | 
350 |       expect(consoleDebugSpy).toHaveBeenCalledWith(
351 |         'Error writing to log file:',
352 |         expect.any(Error),
353 |       );
354 |       expect(logger['messageId']).toBe(initialMessageId); // Not incremented
355 |       expect(logger['logs'].length).toBe(initialLogCount); // Log not added to in-memory cache
356 |     });
357 |   });
358 | 
359 |   describe('getPreviousUserMessages', () => {
360 |     it('should retrieve all user messages from logs, sorted newest first', async () => {
361 |       const loggerSort = new Logger('session-1', new Storage(process.cwd()));
362 |       await loggerSort.initialize();
363 |       await loggerSort.logMessage(MessageSenderType.USER, 'S1M0_ts100000');
364 |       vi.advanceTimersByTime(1000);
365 |       await loggerSort.logMessage(MessageSenderType.USER, 'S1M1_ts101000');
366 |       vi.advanceTimersByTime(1000);
367 |       // Switch to a different session to log
368 |       const loggerSort2 = new Logger('session-2', new Storage(process.cwd()));
369 |       await loggerSort2.initialize();
370 |       await loggerSort2.logMessage(MessageSenderType.USER, 'S2M0_ts102000');
371 |       vi.advanceTimersByTime(1000);
372 |       await loggerSort2.logMessage(
373 |         'model' as MessageSenderType,
374 |         'S2_Model_ts103000',
375 |       );
376 |       vi.advanceTimersByTime(1000);
377 |       await loggerSort2.logMessage(MessageSenderType.USER, 'S2M1_ts104000');
378 |       loggerSort.close();
379 |       loggerSort2.close();
380 | 
381 |       const finalLogger = new Logger(
382 |         'final-session',
383 |         new Storage(process.cwd()),
384 |       );
385 |       await finalLogger.initialize();
386 | 
387 |       const messages = await finalLogger.getPreviousUserMessages();
388 |       expect(messages).toEqual([
389 |         'S2M1_ts104000',
390 |         'S2M0_ts102000',
391 |         'S1M1_ts101000',
392 |         'S1M0_ts100000',
393 |       ]);
394 |       finalLogger.close();
395 |     });
396 | 
397 |     it('should return empty array if no user messages exist', async () => {
398 |       await logger.logMessage('system' as MessageSenderType, 'System boot');
399 |       const messages = await logger.getPreviousUserMessages();
400 |       expect(messages).toEqual([]);
401 |     });
402 | 
403 |     it('should return empty array if logger not initialized', async () => {
404 |       const uninitializedLogger = new Logger(
405 |         testSessionId,
406 |         new Storage(process.cwd()),
407 |       );
408 |       uninitializedLogger.close();
409 |       const messages = await uninitializedLogger.getPreviousUserMessages();
410 |       expect(messages).toEqual([]);
411 |       uninitializedLogger.close();
412 |     });
413 |   });
414 | 
415 |   describe('saveCheckpoint', () => {
416 |     const conversation: Content[] = [
417 |       { role: 'user', parts: [{ text: 'Hello' }] },
418 |       { role: 'model', parts: [{ text: 'Hi there' }] },
419 |     ];
420 | 
421 |     it.each([
422 |       {
423 |         tag: 'test-tag',
424 |         encodedTag: 'test-tag',
425 |       },
426 |       {
427 |         tag: '你好世界',
428 |         encodedTag: '%E4%BD%A0%E5%A5%BD%E4%B8%96%E7%95%8C',
429 |       },
430 |       {
431 |         tag: 'japanese-ひらがなひらがな形声',
432 |         encodedTag:
433 |           'japanese-%E3%81%B2%E3%82%89%E3%81%8C%E3%81%AA%E3%81%B2%E3%82%89%E3%81%8C%E3%81%AA%E5%BD%A2%E5%A3%B0',
434 |       },
435 |       {
436 |         tag: '../../secret',
437 |         encodedTag: '..%2F..%2Fsecret',
438 |       },
439 |     ])('should save a checkpoint', async ({ tag, encodedTag }) => {
440 |       await logger.saveCheckpoint(conversation, tag);
441 |       const taggedFilePath = path.join(
442 |         TEST_GEMINI_DIR,
443 |         `checkpoint-${encodedTag}.json`,
444 |       );
445 |       const fileContent = await fs.readFile(taggedFilePath, 'utf-8');
446 |       expect(JSON.parse(fileContent)).toEqual(conversation);
447 |     });
448 | 
449 |     it('should not throw if logger is not initialized', async () => {
450 |       const uninitializedLogger = new Logger(
451 |         testSessionId,
452 |         new Storage(process.cwd()),
453 |       );
454 |       uninitializedLogger.close();
455 |       const consoleErrorSpy = vi
456 |         .spyOn(console, 'error')
457 |         .mockImplementation(() => {});
458 | 
459 |       await expect(
460 |         uninitializedLogger.saveCheckpoint(conversation, 'tag'),
461 |       ).resolves.not.toThrow();
462 |       expect(consoleErrorSpy).toHaveBeenCalledWith(
463 |         'Logger not initialized or checkpoint file path not set. Cannot save a checkpoint.',
464 |       );
465 |     });
466 |   });
467 | 
468 |   describe('loadCheckpoint', () => {
469 |     const conversation: Content[] = [
470 |       { role: 'user', parts: [{ text: 'Hello' }] },
471 |       { role: 'model', parts: [{ text: 'Hi there' }] },
472 |     ];
473 | 
474 |     beforeEach(async () => {
475 |       await fs.writeFile(
476 |         TEST_CHECKPOINT_FILE_PATH,
477 |         JSON.stringify(conversation, null, 2),
478 |       );
479 |     });
480 | 
481 |     it.each([
482 |       {
483 |         tag: 'test-tag',
484 |         encodedTag: 'test-tag',
485 |       },
486 |       {
487 |         tag: '你好世界',
488 |         encodedTag: '%E4%BD%A0%E5%A5%BD%E4%B8%96%E7%95%8C',
489 |       },
490 |       {
491 |         tag: 'japanese-ひらがなひらがな形声',
492 |         encodedTag:
493 |           'japanese-%E3%81%B2%E3%82%89%E3%81%8C%E3%81%AA%E3%81%B2%E3%82%89%E3%81%8C%E3%81%AA%E5%BD%A2%E5%A3%B0',
494 |       },
495 |       {
496 |         tag: '../../secret',
497 |         encodedTag: '..%2F..%2Fsecret',
498 |       },
499 |     ])('should load from a checkpoint', async ({ tag, encodedTag }) => {
500 |       const taggedConversation = [
501 |         ...conversation,
502 |         { role: 'user', parts: [{ text: 'hello' }] },
503 |       ];
504 |       const taggedFilePath = path.join(
505 |         TEST_GEMINI_DIR,
506 |         `checkpoint-${encodedTag}.json`,
507 |       );
508 |       await fs.writeFile(
509 |         taggedFilePath,
510 |         JSON.stringify(taggedConversation, null, 2),
511 |       );
512 | 
513 |       const loaded = await logger.loadCheckpoint(tag);
514 |       expect(loaded).toEqual(taggedConversation);
515 |       expect(encodeTagName(tag)).toBe(encodedTag);
516 |       expect(decodeTagName(encodedTag)).toBe(tag);
517 |     });
518 | 
519 |     it('should return an empty array if a tagged checkpoint file does not exist', async () => {
520 |       const loaded = await logger.loadCheckpoint('nonexistent-tag');
521 |       expect(loaded).toEqual([]);
522 |     });
523 | 
524 |     it('should return an empty array if the checkpoint file does not exist', async () => {
525 |       await fs.unlink(TEST_CHECKPOINT_FILE_PATH); // Ensure it's gone
526 |       const loaded = await logger.loadCheckpoint('missing');
527 |       expect(loaded).toEqual([]);
528 |     });
529 | 
530 |     it('should return an empty array if the file contains invalid JSON', async () => {
531 |       const tag = 'invalid-json-tag';
532 |       const encodedTag = 'invalid-json-tag';
533 |       const taggedFilePath = path.join(
534 |         TEST_GEMINI_DIR,
535 |         `checkpoint-${encodedTag}.json`,
536 |       );
537 |       await fs.writeFile(taggedFilePath, 'invalid json');
538 |       const consoleErrorSpy = vi
539 |         .spyOn(console, 'error')
540 |         .mockImplementation(() => {});
541 |       const loadedCheckpoint = await logger.loadCheckpoint(tag);
542 |       expect(loadedCheckpoint).toEqual([]);
543 |       expect(consoleErrorSpy).toHaveBeenCalledWith(
544 |         expect.stringContaining('Failed to read or parse checkpoint file'),
545 |         expect.any(Error),
546 |       );
547 |     });
548 | 
549 |     it('should return an empty array if logger is not initialized', async () => {
550 |       const uninitializedLogger = new Logger(
551 |         testSessionId,
552 |         new Storage(process.cwd()),
553 |       );
554 |       uninitializedLogger.close();
555 |       const consoleErrorSpy = vi
556 |         .spyOn(console, 'error')
557 |         .mockImplementation(() => {});
558 |       const loadedCheckpoint = await uninitializedLogger.loadCheckpoint('tag');
559 |       expect(loadedCheckpoint).toEqual([]);
560 |       expect(consoleErrorSpy).toHaveBeenCalledWith(
561 |         'Logger not initialized or checkpoint file path not set. Cannot load checkpoint.',
562 |       );
563 |     });
564 |   });
565 | 
566 |   describe('deleteCheckpoint', () => {
567 |     const conversation: Content[] = [
568 |       { role: 'user', parts: [{ text: 'Content to be deleted' }] },
569 |     ];
570 |     const tag = 'delete-me';
571 |     const encodedTag = 'delete-me';
572 |     let taggedFilePath: string;
573 | 
574 |     beforeEach(async () => {
575 |       taggedFilePath = path.join(
576 |         TEST_GEMINI_DIR,
[TRUNCATED]
```

src/core/logger.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import path from 'node:path';
8 | import { promises as fs } from 'node:fs';
9 | import type { Content } from '@google/genai';
10 | import type { Storage } from '../config/storage.js';
11 | 
12 | const LOG_FILE_NAME = 'logs.json';
13 | 
14 | export enum MessageSenderType {
15 |   USER = 'user',
16 | }
17 | 
18 | export interface LogEntry {
19 |   sessionId: string;
20 |   messageId: number;
21 |   timestamp: string;
22 |   type: MessageSenderType;
23 |   message: string;
24 | }
25 | 
26 | // This regex matches any character that is NOT a letter (a-z, A-Z),
27 | // a number (0-9), a hyphen (-), an underscore (_), or a dot (.).
28 | 
29 | /**
30 |  * Encodes a string to be safe for use as a filename.
31 |  *
32 |  * It replaces any characters that are not alphanumeric or one of `_`, `-`, `.`
33 |  * with a URL-like percent-encoding (`%` followed by the 2-digit hex code).
34 |  *
35 |  * @param str The input string to encode.
36 |  * @returns The encoded, filename-safe string.
37 |  */
38 | export function encodeTagName(str: string): string {
39 |   return encodeURIComponent(str);
40 | }
41 | 
42 | /**
43 |  * Decodes a string that was encoded with the `encode` function.
44 |  *
45 |  * It finds any percent-encoded characters and converts them back to their
46 |  * original representation.
47 |  *
48 |  * @param str The encoded string to decode.
49 |  * @returns The decoded, original string.
50 |  */
51 | export function decodeTagName(str: string): string {
52 |   try {
53 |     return decodeURIComponent(str);
54 |   } catch (_e) {
55 |     // Fallback for old, potentially malformed encoding
56 |     return str.replace(/%([0-9A-F]{2})/g, (_, hex) =>
57 |       String.fromCharCode(parseInt(hex, 16)),
58 |     );
59 |   }
60 | }
61 | 
62 | export class Logger {
63 |   private geminiDir: string | undefined;
64 |   private logFilePath: string | undefined;
65 |   private sessionId: string | undefined;
66 |   private messageId = 0; // Instance-specific counter for the next messageId
67 |   private initialized = false;
68 |   private logs: LogEntry[] = []; // In-memory cache, ideally reflects the last known state of the file
69 | 
70 |   constructor(
71 |     sessionId: string,
72 |     private readonly storage: Storage,
73 |   ) {
74 |     this.sessionId = sessionId;
75 |   }
76 | 
77 |   private async _readLogFile(): Promise<LogEntry[]> {
78 |     if (!this.logFilePath) {
79 |       throw new Error('Log file path not set during read attempt.');
80 |     }
81 |     try {
82 |       const fileContent = await fs.readFile(this.logFilePath, 'utf-8');
83 |       const parsedLogs = JSON.parse(fileContent);
84 |       if (!Array.isArray(parsedLogs)) {
85 |         console.debug(
86 |           `Log file at ${this.logFilePath} is not a valid JSON array. Starting with empty logs.`,
87 |         );
88 |         await this._backupCorruptedLogFile('malformed_array');
89 |         return [];
90 |       }
91 |       return parsedLogs.filter(
92 |         (entry) =>
93 |           typeof entry.sessionId === 'string' &&
94 |           typeof entry.messageId === 'number' &&
95 |           typeof entry.timestamp === 'string' &&
96 |           typeof entry.type === 'string' &&
97 |           typeof entry.message === 'string',
98 |       ) as LogEntry[];
99 |     } catch (error) {
100 |       const nodeError = error as NodeJS.ErrnoException;
101 |       if (nodeError.code === 'ENOENT') {
102 |         return [];
103 |       }
104 |       if (error instanceof SyntaxError) {
105 |         console.debug(
106 |           `Invalid JSON in log file ${this.logFilePath}. Backing up and starting fresh.`,
107 |           error,
108 |         );
109 |         await this._backupCorruptedLogFile('invalid_json');
110 |         return [];
111 |       }
112 |       console.debug(
113 |         `Failed to read or parse log file ${this.logFilePath}:`,
114 |         error,
115 |       );
116 |       throw error;
117 |     }
118 |   }
119 | 
120 |   private async _backupCorruptedLogFile(reason: string): Promise<void> {
121 |     if (!this.logFilePath) return;
122 |     const backupPath = `${this.logFilePath}.${reason}.${Date.now()}.bak`;
123 |     try {
124 |       await fs.rename(this.logFilePath, backupPath);
125 |       console.debug(`Backed up corrupted log file to ${backupPath}`);
126 |     } catch (_backupError) {
127 |       // If rename fails (e.g. file doesn't exist), no need to log an error here as the primary error (e.g. invalid JSON) is already handled.
128 |     }
129 |   }
130 | 
131 |   async initialize(): Promise<void> {
132 |     if (this.initialized) {
133 |       return;
134 |     }
135 | 
136 |     this.geminiDir = this.storage.getProjectTempDir();
137 |     this.logFilePath = path.join(this.geminiDir, LOG_FILE_NAME);
138 | 
139 |     try {
140 |       await fs.mkdir(this.geminiDir, { recursive: true });
141 |       let fileExisted = true;
142 |       try {
143 |         await fs.access(this.logFilePath);
144 |       } catch (_e) {
145 |         fileExisted = false;
146 |       }
147 |       this.logs = await this._readLogFile();
148 |       if (!fileExisted && this.logs.length === 0) {
149 |         await fs.writeFile(this.logFilePath, '[]', 'utf-8');
150 |       }
151 |       const sessionLogs = this.logs.filter(
152 |         (entry) => entry.sessionId === this.sessionId,
153 |       );
154 |       this.messageId =
155 |         sessionLogs.length > 0
156 |           ? Math.max(...sessionLogs.map((entry) => entry.messageId)) + 1
157 |           : 0;
158 |       this.initialized = true;
159 |     } catch (err) {
160 |       console.error('Failed to initialize logger:', err);
161 |       this.initialized = false;
162 |     }
163 |   }
164 | 
165 |   private async _updateLogFile(
166 |     entryToAppend: LogEntry,
167 |   ): Promise<LogEntry | null> {
168 |     if (!this.logFilePath) {
169 |       console.debug('Log file path not set. Cannot persist log entry.');
170 |       throw new Error('Log file path not set during update attempt.');
171 |     }
172 | 
173 |     let currentLogsOnDisk: LogEntry[];
174 |     try {
175 |       currentLogsOnDisk = await this._readLogFile();
176 |     } catch (readError) {
177 |       console.debug(
178 |         'Critical error reading log file before append:',
179 |         readError,
180 |       );
181 |       throw readError;
182 |     }
183 | 
184 |     // Determine the correct messageId for the new entry based on current disk state for its session
185 |     const sessionLogsOnDisk = currentLogsOnDisk.filter(
186 |       (e) => e.sessionId === entryToAppend.sessionId,
187 |     );
188 |     const nextMessageIdForSession =
189 |       sessionLogsOnDisk.length > 0
190 |         ? Math.max(...sessionLogsOnDisk.map((e) => e.messageId)) + 1
191 |         : 0;
192 | 
193 |     // Update the messageId of the entry we are about to append
194 |     entryToAppend.messageId = nextMessageIdForSession;
195 | 
196 |     // Check if this entry (same session, same *recalculated* messageId, same content) might already exist
197 |     // This is a stricter check for true duplicates if multiple instances try to log the exact same thing
198 |     // at the exact same calculated messageId slot.
199 |     const entryExists = currentLogsOnDisk.some(
200 |       (e) =>
201 |         e.sessionId === entryToAppend.sessionId &&
202 |         e.messageId === entryToAppend.messageId &&
203 |         e.timestamp === entryToAppend.timestamp && // Timestamps are good for distinguishing
204 |         e.message === entryToAppend.message,
205 |     );
206 | 
207 |     if (entryExists) {
208 |       console.debug(
209 |         `Duplicate log entry detected and skipped: session ${entryToAppend.sessionId}, messageId ${entryToAppend.messageId}`,
210 |       );
211 |       this.logs = currentLogsOnDisk; // Ensure in-memory is synced with disk
212 |       return null; // Indicate that no new entry was actually added
213 |     }
214 | 
215 |     currentLogsOnDisk.push(entryToAppend);
216 | 
217 |     try {
218 |       await fs.writeFile(
219 |         this.logFilePath,
220 |         JSON.stringify(currentLogsOnDisk, null, 2),
221 |         'utf-8',
222 |       );
223 |       this.logs = currentLogsOnDisk;
224 |       return entryToAppend; // Return the successfully appended entry
225 |     } catch (error) {
226 |       console.debug('Error writing to log file:', error);
227 |       throw error;
228 |     }
229 |   }
230 | 
231 |   async getPreviousUserMessages(): Promise<string[]> {
232 |     if (!this.initialized) return [];
233 |     return this.logs
234 |       .filter((entry) => entry.type === MessageSenderType.USER)
235 |       .sort((a, b) => {
236 |         const dateA = new Date(a.timestamp).getTime();
237 |         const dateB = new Date(b.timestamp).getTime();
238 |         return dateB - dateA;
239 |       })
240 |       .map((entry) => entry.message);
241 |   }
242 | 
243 |   async logMessage(type: MessageSenderType, message: string): Promise<void> {
244 |     if (!this.initialized || this.sessionId === undefined) {
245 |       console.debug(
246 |         'Logger not initialized or session ID missing. Cannot log message.',
247 |       );
248 |       return;
249 |     }
250 | 
251 |     // The messageId used here is the instance's idea of the next ID.
252 |     // _updateLogFile will verify and potentially recalculate based on the file's actual state.
253 |     const newEntryObject: LogEntry = {
254 |       sessionId: this.sessionId,
255 |       messageId: this.messageId, // This will be recalculated in _updateLogFile
256 |       type,
257 |       message,
258 |       timestamp: new Date().toISOString(),
259 |     };
260 | 
261 |     try {
262 |       const writtenEntry = await this._updateLogFile(newEntryObject);
263 |       if (writtenEntry) {
264 |         // If an entry was actually written (not a duplicate skip),
265 |         // then this instance can increment its idea of the next messageId for this session.
266 |         this.messageId = writtenEntry.messageId + 1;
267 |       }
268 |     } catch (_error) {
269 |       // Error already logged by _updateLogFile or _readLogFile
270 |     }
271 |   }
272 | 
273 |   private _checkpointPath(tag: string): string {
274 |     if (!tag.length) {
275 |       throw new Error('No checkpoint tag specified.');
276 |     }
277 |     if (!this.geminiDir) {
278 |       throw new Error('Checkpoint file path not set.');
279 |     }
280 |     // Encode the tag to handle all special characters safely.
281 |     const encodedTag = encodeTagName(tag);
282 |     return path.join(this.geminiDir, `checkpoint-${encodedTag}.json`);
283 |   }
284 | 
285 |   private async _getCheckpointPath(tag: string): Promise<string> {
286 |     // 1. Check for the new encoded path first.
287 |     const newPath = this._checkpointPath(tag);
288 |     try {
289 |       await fs.access(newPath);
290 |       return newPath; // Found it, use the new path.
291 |     } catch (error) {
292 |       const nodeError = error as NodeJS.ErrnoException;
293 |       if (nodeError.code !== 'ENOENT') {
294 |         throw error; // A real error occurred, rethrow it.
295 |       }
296 |       // It was not found, so we'll check the old path next.
297 |     }
298 | 
299 |     // 2. Fallback for backward compatibility: check for the old raw path.
300 |     const oldPath = path.join(this.geminiDir!, `checkpoint-${tag}.json`);
301 |     try {
302 |       await fs.access(oldPath);
303 |       return oldPath; // Found it, use the old path.
304 |     } catch (error) {
305 |       const nodeError = error as NodeJS.ErrnoException;
306 |       if (nodeError.code !== 'ENOENT') {
307 |         throw error; // A real error occurred, rethrow it.
308 |       }
309 |     }
310 | 
311 |     // 3. If neither path exists, return the new encoded path as the canonical one.
312 |     return newPath;
313 |   }
314 | 
315 |   async saveCheckpoint(conversation: Content[], tag: string): Promise<void> {
316 |     if (!this.initialized) {
317 |       console.error(
318 |         'Logger not initialized or checkpoint file path not set. Cannot save a checkpoint.',
319 |       );
320 |       return;
321 |     }
322 |     // Always save with the new encoded path.
323 |     const path = this._checkpointPath(tag);
324 |     try {
325 |       await fs.writeFile(path, JSON.stringify(conversation, null, 2), 'utf-8');
326 |     } catch (error) {
327 |       console.error('Error writing to checkpoint file:', error);
328 |     }
329 |   }
330 | 
331 |   async loadCheckpoint(tag: string): Promise<Content[]> {
332 |     if (!this.initialized) {
333 |       console.error(
334 |         'Logger not initialized or checkpoint file path not set. Cannot load checkpoint.',
335 |       );
336 |       return [];
337 |     }
338 | 
339 |     const path = await this._getCheckpointPath(tag);
340 |     try {
341 |       const fileContent = await fs.readFile(path, 'utf-8');
342 |       const parsedContent = JSON.parse(fileContent);
343 |       if (!Array.isArray(parsedContent)) {
344 |         console.warn(
345 |           `Checkpoint file at ${path} is not a valid JSON array. Returning empty checkpoint.`,
346 |         );
347 |         return [];
348 |       }
349 |       return parsedContent as Content[];
350 |     } catch (error) {
351 |       const nodeError = error as NodeJS.ErrnoException;
352 |       if (nodeError.code === 'ENOENT') {
353 |         // This is okay, it just means the checkpoint doesn't exist in either format.
354 |         return [];
355 |       }
356 |       console.error(`Failed to read or parse checkpoint file ${path}:`, error);
357 |       return [];
358 |     }
359 |   }
360 | 
361 |   async deleteCheckpoint(tag: string): Promise<boolean> {
362 |     if (!this.initialized || !this.geminiDir) {
363 |       console.error(
364 |         'Logger not initialized or checkpoint file path not set. Cannot delete checkpoint.',
365 |       );
366 |       return false;
367 |     }
368 | 
369 |     let deletedSomething = false;
370 | 
371 |     // 1. Attempt to delete the new encoded path.
372 |     const newPath = this._checkpointPath(tag);
373 |     try {
374 |       await fs.unlink(newPath);
375 |       deletedSomething = true;
376 |     } catch (error) {
377 |       const nodeError = error as NodeJS.ErrnoException;
378 |       if (nodeError.code !== 'ENOENT') {
379 |         console.error(`Failed to delete checkpoint file ${newPath}:`, error);
380 |         throw error; // Rethrow unexpected errors
381 |       }
382 |       // It's okay if it doesn't exist.
383 |     }
384 | 
385 |     // 2. Attempt to delete the old raw path for backward compatibility.
386 |     const oldPath = path.join(this.geminiDir!, `checkpoint-${tag}.json`);
387 |     if (newPath !== oldPath) {
388 |       try {
389 |         await fs.unlink(oldPath);
390 |         deletedSomething = true;
391 |       } catch (error) {
392 |         const nodeError = error as NodeJS.ErrnoException;
393 |         if (nodeError.code !== 'ENOENT') {
394 |           console.error(`Failed to delete checkpoint file ${oldPath}:`, error);
395 |           throw error; // Rethrow unexpected errors
396 |         }
397 |         // It's okay if it doesn't exist.
398 |       }
399 |     }
400 | 
401 |     return deletedSomething;
402 |   }
403 | 
404 |   async checkpointExists(tag: string): Promise<boolean> {
405 |     if (!this.initialized) {
406 |       throw new Error(
407 |         'Logger not initialized. Cannot check for checkpoint existence.',
408 |       );
409 |     }
410 |     let filePath: string | undefined;
411 |     try {
412 |       filePath = await this._getCheckpointPath(tag);
413 |       // We need to check for existence again, because _getCheckpointPath
414 |       // returns a canonical path even if it doesn't exist yet.
415 |       await fs.access(filePath);
416 |       return true;
417 |     } catch (error) {
418 |       const nodeError = error as NodeJS.ErrnoException;
419 |       if (nodeError.code === 'ENOENT') {
420 |         return false; // It truly doesn't exist in either format.
421 |       }
422 |       // A different error occurred.
423 |       console.error(
424 |         `Failed to check checkpoint existence for ${
425 |           filePath ?? `path for tag "${tag}"`
426 |         }:`,
427 |         error,
428 |       );
429 |       throw error;
430 |     }
431 |   }
432 | 
433 |   close(): void {
434 |     this.initialized = false;
435 |     this.logFilePath = undefined;
436 |     this.logs = [];
437 |     this.sessionId = undefined;
438 |     this.messageId = 0;
439 |   }
440 | }
```

src/core/loggingContentGenerator.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   Content,
9 |   CountTokensParameters,
10 |   CountTokensResponse,
11 |   EmbedContentParameters,
12 |   EmbedContentResponse,
13 |   GenerateContentParameters,
14 |   GenerateContentResponseUsageMetadata,
15 |   GenerateContentResponse,
16 | } from '@google/genai';
17 | import {
18 |   ApiRequestEvent,
19 |   ApiResponseEvent,
20 |   ApiErrorEvent,
21 | } from '../telemetry/types.js';
22 | import type { Config } from '../config/config.js';
23 | import {
24 |   logApiError,
25 |   logApiRequest,
26 |   logApiResponse,
27 | } from '../telemetry/loggers.js';
28 | import type { ContentGenerator } from './contentGenerator.js';
29 | import { toContents } from '../code_assist/converter.js';
30 | import { isStructuredError } from '../utils/quotaErrorDetection.js';
31 | 
32 | interface StructuredError {
33 |   status: number;
34 | }
35 | 
36 | /**
37 |  * A decorator that wraps a ContentGenerator to add logging to API calls.
38 |  */
39 | export class LoggingContentGenerator implements ContentGenerator {
40 |   constructor(
41 |     private readonly wrapped: ContentGenerator,
42 |     private readonly config: Config,
43 |   ) {}
44 | 
45 |   getWrapped(): ContentGenerator {
46 |     return this.wrapped;
47 |   }
48 | 
49 |   private logApiRequest(
50 |     contents: Content[],
51 |     model: string,
52 |     promptId: string,
53 |   ): void {
54 |     const requestText = JSON.stringify(contents);
55 |     logApiRequest(
56 |       this.config,
57 |       new ApiRequestEvent(model, promptId, requestText),
58 |     );
59 |   }
60 | 
61 |   private _logApiResponse(
62 |     durationMs: number,
63 |     model: string,
64 |     prompt_id: string,
65 |     usageMetadata?: GenerateContentResponseUsageMetadata,
66 |     responseText?: string,
67 |   ): void {
68 |     logApiResponse(
69 |       this.config,
70 |       new ApiResponseEvent(
71 |         model,
72 |         durationMs,
73 |         prompt_id,
74 |         this.config.getContentGeneratorConfig()?.authType,
75 |         usageMetadata,
76 |         responseText,
77 |       ),
78 |     );
79 |   }
80 | 
81 |   private _logApiError(
82 |     durationMs: number,
83 |     error: unknown,
84 |     model: string,
85 |     prompt_id: string,
86 |   ): void {
87 |     const errorMessage = error instanceof Error ? error.message : String(error);
88 |     const errorType = error instanceof Error ? error.name : 'unknown';
89 | 
90 |     logApiError(
91 |       this.config,
92 |       new ApiErrorEvent(
93 |         model,
94 |         errorMessage,
95 |         durationMs,
96 |         prompt_id,
97 |         this.config.getContentGeneratorConfig()?.authType,
98 |         errorType,
99 |         isStructuredError(error)
100 |           ? (error as StructuredError).status
101 |           : undefined,
102 |       ),
103 |     );
104 |   }
105 | 
106 |   async generateContent(
107 |     req: GenerateContentParameters,
108 |     userPromptId: string,
109 |   ): Promise<GenerateContentResponse> {
110 |     const startTime = Date.now();
111 |     this.logApiRequest(toContents(req.contents), req.model, userPromptId);
112 |     try {
113 |       const response = await this.wrapped.generateContent(req, userPromptId);
114 |       const durationMs = Date.now() - startTime;
115 |       this._logApiResponse(
116 |         durationMs,
117 |         response.modelVersion || req.model,
118 |         userPromptId,
119 |         response.usageMetadata,
120 |         JSON.stringify(response),
121 |       );
122 |       return response;
123 |     } catch (error) {
124 |       const durationMs = Date.now() - startTime;
125 |       this._logApiError(durationMs, error, req.model, userPromptId);
126 |       throw error;
127 |     }
128 |   }
129 | 
130 |   async generateContentStream(
131 |     req: GenerateContentParameters,
132 |     userPromptId: string,
133 |   ): Promise<AsyncGenerator<GenerateContentResponse>> {
134 |     const startTime = Date.now();
135 |     this.logApiRequest(toContents(req.contents), req.model, userPromptId);
136 | 
137 |     let stream: AsyncGenerator<GenerateContentResponse>;
138 |     try {
139 |       stream = await this.wrapped.generateContentStream(req, userPromptId);
140 |     } catch (error) {
141 |       const durationMs = Date.now() - startTime;
142 |       this._logApiError(durationMs, error, req.model, userPromptId);
143 |       throw error;
144 |     }
145 | 
146 |     return this.loggingStreamWrapper(
147 |       stream,
148 |       startTime,
149 |       userPromptId,
150 |       req.model,
151 |     );
152 |   }
153 | 
154 |   private async *loggingStreamWrapper(
155 |     stream: AsyncGenerator<GenerateContentResponse>,
156 |     startTime: number,
157 |     userPromptId: string,
158 |     model: string,
159 |   ): AsyncGenerator<GenerateContentResponse> {
160 |     const responses: GenerateContentResponse[] = [];
161 | 
162 |     let lastUsageMetadata: GenerateContentResponseUsageMetadata | undefined;
163 |     try {
164 |       for await (const response of stream) {
165 |         responses.push(response);
166 |         if (response.usageMetadata) {
167 |           lastUsageMetadata = response.usageMetadata;
168 |         }
169 |         yield response;
170 |       }
171 |       // Only log successful API response if no error occurred
172 |       const durationMs = Date.now() - startTime;
173 |       this._logApiResponse(
174 |         durationMs,
175 |         responses[0]?.modelVersion || model,
176 |         userPromptId,
177 |         lastUsageMetadata,
178 |         JSON.stringify(responses),
179 |       );
180 |     } catch (error) {
181 |       const durationMs = Date.now() - startTime;
182 |       this._logApiError(
183 |         durationMs,
184 |         error,
185 |         responses[0]?.modelVersion || model,
186 |         userPromptId,
187 |       );
188 |       throw error;
189 |     }
190 |   }
191 | 
192 |   async countTokens(req: CountTokensParameters): Promise<CountTokensResponse> {
193 |     return this.wrapped.countTokens(req);
194 |   }
195 | 
196 |   async embedContent(
197 |     req: EmbedContentParameters,
198 |   ): Promise<EmbedContentResponse> {
199 |     return this.wrapped.embedContent(req);
200 |   }
201 | }
```

src/core/nonInteractiveToolExecutor.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach } from 'vitest';
8 | import type { Mock } from 'vitest';
9 | import { executeToolCall } from './nonInteractiveToolExecutor.js';
10 | import type {
11 |   ToolRegistry,
12 |   ToolCallRequestInfo,
13 |   ToolResult,
14 |   Config,
15 | } from '../index.js';
16 | import {
17 |   DEFAULT_TRUNCATE_TOOL_OUTPUT_LINES,
18 |   DEFAULT_TRUNCATE_TOOL_OUTPUT_THRESHOLD,
19 |   ToolErrorType,
20 |   ApprovalMode,
21 | } from '../index.js';
22 | import type { Part } from '@google/genai';
23 | import { MockTool } from '../test-utils/mock-tool.js';
24 | 
25 | describe('executeToolCall', () => {
26 |   let mockToolRegistry: ToolRegistry;
27 |   let mockTool: MockTool;
28 |   let executeFn: Mock;
29 |   let abortController: AbortController;
30 |   let mockConfig: Config;
31 | 
32 |   beforeEach(() => {
33 |     executeFn = vi.fn();
34 |     mockTool = new MockTool({ name: 'testTool', execute: executeFn });
35 | 
36 |     mockToolRegistry = {
37 |       getTool: vi.fn(),
38 |       getAllToolNames: vi.fn(),
39 |     } as unknown as ToolRegistry;
40 | 
41 |     mockConfig = {
42 |       getToolRegistry: () => mockToolRegistry,
43 |       getApprovalMode: () => ApprovalMode.DEFAULT,
44 |       getAllowedTools: () => [],
45 |       getSessionId: () => 'test-session-id',
46 |       getUsageStatisticsEnabled: () => true,
47 |       getDebugMode: () => false,
48 |       getContentGeneratorConfig: () => ({
49 |         model: 'test-model',
50 |         authType: 'oauth-personal',
51 |       }),
52 |       getShellExecutionConfig: () => ({
53 |         terminalWidth: 90,
54 |         terminalHeight: 30,
55 |       }),
56 |       storage: {
57 |         getProjectTempDir: () => '/tmp',
58 |       },
59 |       getTruncateToolOutputThreshold: () =>
60 |         DEFAULT_TRUNCATE_TOOL_OUTPUT_THRESHOLD,
61 |       getTruncateToolOutputLines: () => DEFAULT_TRUNCATE_TOOL_OUTPUT_LINES,
62 |       getUseSmartEdit: () => false,
63 |       getUseModelRouter: () => false,
64 |       getGeminiClient: () => null, // No client needed for these tests
65 |     } as unknown as Config;
66 | 
67 |     abortController = new AbortController();
68 |   });
69 | 
70 |   it('should execute a tool successfully', async () => {
71 |     const request: ToolCallRequestInfo = {
72 |       callId: 'call1',
73 |       name: 'testTool',
74 |       args: { param1: 'value1' },
75 |       isClientInitiated: false,
76 |       prompt_id: 'prompt-id-1',
77 |     };
78 |     const toolResult: ToolResult = {
79 |       llmContent: 'Tool executed successfully',
80 |       returnDisplay: 'Success!',
81 |     };
82 |     vi.mocked(mockToolRegistry.getTool).mockReturnValue(mockTool);
83 |     executeFn.mockResolvedValue(toolResult);
84 | 
85 |     const response = await executeToolCall(
86 |       mockConfig,
87 |       request,
88 |       abortController.signal,
89 |     );
90 | 
91 |     expect(mockToolRegistry.getTool).toHaveBeenCalledWith('testTool');
92 |     expect(executeFn).toHaveBeenCalledWith(request.args);
93 |     expect(response).toStrictEqual({
94 |       callId: 'call1',
95 |       error: undefined,
96 |       errorType: undefined,
97 |       outputFile: undefined,
98 |       resultDisplay: 'Success!',
99 |       contentLength:
100 |         typeof toolResult.llmContent === 'string'
101 |           ? toolResult.llmContent.length
102 |           : undefined,
103 |       responseParts: [
104 |         {
105 |           functionResponse: {
106 |             name: 'testTool',
107 |             id: 'call1',
108 |             response: { output: 'Tool executed successfully' },
109 |           },
110 |         },
111 |       ],
112 |     });
113 |   });
114 | 
115 |   it('should return an error if tool is not found', async () => {
116 |     const request: ToolCallRequestInfo = {
117 |       callId: 'call2',
118 |       name: 'nonexistentTool',
119 |       args: {},
120 |       isClientInitiated: false,
121 |       prompt_id: 'prompt-id-2',
122 |     };
123 |     vi.mocked(mockToolRegistry.getTool).mockReturnValue(undefined);
124 |     vi.mocked(mockToolRegistry.getAllToolNames).mockReturnValue([
125 |       'testTool',
126 |       'anotherTool',
127 |     ]);
128 | 
129 |     const response = await executeToolCall(
130 |       mockConfig,
131 |       request,
132 |       abortController.signal,
133 |     );
134 | 
135 |     const expectedErrorMessage =
136 |       'Tool "nonexistentTool" not found in registry. Tools must use the exact names that are registered. Did you mean one of: "testTool", "anotherTool"?';
137 |     expect(response).toStrictEqual({
138 |       callId: 'call2',
139 |       error: new Error(expectedErrorMessage),
140 |       errorType: ToolErrorType.TOOL_NOT_REGISTERED,
141 |       resultDisplay: expectedErrorMessage,
142 |       contentLength: expectedErrorMessage.length,
143 |       responseParts: [
144 |         {
145 |           functionResponse: {
146 |             name: 'nonexistentTool',
147 |             id: 'call2',
148 |             response: {
149 |               error: expectedErrorMessage,
150 |             },
151 |           },
152 |         },
153 |       ],
154 |     });
155 |   });
156 | 
157 |   it('should return an error if tool validation fails', async () => {
158 |     const request: ToolCallRequestInfo = {
159 |       callId: 'call3',
160 |       name: 'testTool',
161 |       args: { param1: 'invalid' },
162 |       isClientInitiated: false,
163 |       prompt_id: 'prompt-id-3',
164 |     };
165 |     vi.mocked(mockToolRegistry.getTool).mockReturnValue(mockTool);
166 |     vi.spyOn(mockTool, 'build').mockImplementation(() => {
167 |       throw new Error('Invalid parameters');
168 |     });
169 | 
170 |     const response = await executeToolCall(
171 |       mockConfig,
172 |       request,
173 |       abortController.signal,
174 |     );
175 | 
176 |     expect(response).toStrictEqual({
177 |       callId: 'call3',
178 |       error: new Error('Invalid parameters'),
179 |       errorType: ToolErrorType.INVALID_TOOL_PARAMS,
180 |       responseParts: [
181 |         {
182 |           functionResponse: {
183 |             id: 'call3',
184 |             name: 'testTool',
185 |             response: {
186 |               error: 'Invalid parameters',
187 |             },
188 |           },
189 |         },
190 |       ],
191 |       resultDisplay: 'Invalid parameters',
192 |       contentLength: 'Invalid parameters'.length,
193 |     });
194 |   });
195 | 
196 |   it('should return an error if tool execution fails', async () => {
197 |     const request: ToolCallRequestInfo = {
198 |       callId: 'call4',
199 |       name: 'testTool',
200 |       args: { param1: 'value1' },
201 |       isClientInitiated: false,
202 |       prompt_id: 'prompt-id-4',
203 |     };
204 |     const executionErrorResult: ToolResult = {
205 |       llmContent: 'Error: Execution failed',
206 |       returnDisplay: 'Execution failed',
207 |       error: {
208 |         message: 'Execution failed',
209 |         type: ToolErrorType.EXECUTION_FAILED,
210 |       },
211 |     };
212 |     vi.mocked(mockToolRegistry.getTool).mockReturnValue(mockTool);
213 |     executeFn.mockResolvedValue(executionErrorResult);
214 | 
215 |     const response = await executeToolCall(
216 |       mockConfig,
217 |       request,
218 |       abortController.signal,
219 |     );
220 |     expect(response).toStrictEqual({
221 |       callId: 'call4',
222 |       error: new Error('Execution failed'),
223 |       errorType: ToolErrorType.EXECUTION_FAILED,
224 |       responseParts: [
225 |         {
226 |           functionResponse: {
227 |             id: 'call4',
228 |             name: 'testTool',
229 |             response: {
230 |               error: 'Execution failed',
231 |             },
232 |           },
233 |         },
234 |       ],
235 |       resultDisplay: 'Execution failed',
236 |       contentLength: 'Execution failed'.length,
237 |     });
238 |   });
239 | 
240 |   it('should return an unhandled exception error if execution throws', async () => {
241 |     const request: ToolCallRequestInfo = {
242 |       callId: 'call5',
243 |       name: 'testTool',
244 |       args: { param1: 'value1' },
245 |       isClientInitiated: false,
246 |       prompt_id: 'prompt-id-5',
247 |     };
248 |     vi.mocked(mockToolRegistry.getTool).mockReturnValue(mockTool);
249 |     executeFn.mockRejectedValue(new Error('Something went very wrong'));
250 | 
251 |     const response = await executeToolCall(
252 |       mockConfig,
253 |       request,
254 |       abortController.signal,
255 |     );
256 | 
257 |     expect(response).toStrictEqual({
258 |       callId: 'call5',
259 |       error: new Error('Something went very wrong'),
260 |       errorType: ToolErrorType.UNHANDLED_EXCEPTION,
261 |       resultDisplay: 'Something went very wrong',
262 |       contentLength: 'Something went very wrong'.length,
263 |       responseParts: [
264 |         {
265 |           functionResponse: {
266 |             name: 'testTool',
267 |             id: 'call5',
268 |             response: { error: 'Something went very wrong' },
269 |           },
270 |         },
271 |       ],
272 |     });
273 |   });
274 | 
275 |   it('should correctly format llmContent with inlineData', async () => {
276 |     const request: ToolCallRequestInfo = {
277 |       callId: 'call6',
278 |       name: 'testTool',
279 |       args: {},
280 |       isClientInitiated: false,
281 |       prompt_id: 'prompt-id-6',
282 |     };
283 |     const imageDataPart: Part = {
284 |       inlineData: { mimeType: 'image/png', data: 'base64data' },
285 |     };
286 |     const toolResult: ToolResult = {
287 |       llmContent: [imageDataPart],
288 |       returnDisplay: 'Image processed',
289 |     };
290 |     vi.mocked(mockToolRegistry.getTool).mockReturnValue(mockTool);
291 |     executeFn.mockResolvedValue(toolResult);
292 | 
293 |     const response = await executeToolCall(
294 |       mockConfig,
295 |       request,
296 |       abortController.signal,
297 |     );
298 | 
299 |     expect(response).toStrictEqual({
300 |       callId: 'call6',
301 |       error: undefined,
302 |       errorType: undefined,
303 |       outputFile: undefined,
304 |       resultDisplay: 'Image processed',
305 |       contentLength: undefined,
306 |       responseParts: [
307 |         {
308 |           functionResponse: {
309 |             name: 'testTool',
310 |             id: 'call6',
311 |             response: {
312 |               output: 'Binary content of type image/png was processed.',
313 |             },
314 |           },
315 |         },
316 |         imageDataPart,
317 |       ],
318 |     });
319 |   });
320 | 
321 |   it('should calculate contentLength for a string llmContent', async () => {
322 |     const request: ToolCallRequestInfo = {
323 |       callId: 'call7',
324 |       name: 'testTool',
325 |       args: {},
326 |       isClientInitiated: false,
327 |       prompt_id: 'prompt-id-7',
328 |     };
329 |     const toolResult: ToolResult = {
330 |       llmContent: 'This is a test string.',
331 |       returnDisplay: 'String returned',
332 |     };
333 |     vi.mocked(mockToolRegistry.getTool).mockReturnValue(mockTool);
334 |     executeFn.mockResolvedValue(toolResult);
335 | 
336 |     const response = await executeToolCall(
337 |       mockConfig,
338 |       request,
339 |       abortController.signal,
340 |     );
341 | 
342 |     expect(response.contentLength).toBe(
343 |       typeof toolResult.llmContent === 'string'
344 |         ? toolResult.llmContent.length
345 |         : undefined,
346 |     );
347 |   });
348 | 
349 |   it('should have undefined contentLength for array llmContent with no string parts', async () => {
350 |     const request: ToolCallRequestInfo = {
351 |       callId: 'call8',
352 |       name: 'testTool',
353 |       args: {},
354 |       isClientInitiated: false,
355 |       prompt_id: 'prompt-id-8',
356 |     };
357 |     const toolResult: ToolResult = {
358 |       llmContent: [{ inlineData: { mimeType: 'image/png', data: 'fakedata' } }],
359 |       returnDisplay: 'Image data returned',
360 |     };
361 |     vi.mocked(mockToolRegistry.getTool).mockReturnValue(mockTool);
362 |     executeFn.mockResolvedValue(toolResult);
363 | 
364 |     const response = await executeToolCall(
365 |       mockConfig,
366 |       request,
367 |       abortController.signal,
368 |     );
369 | 
370 |     expect(response.contentLength).toBeUndefined();
371 |   });
372 | });
```

src/core/nonInteractiveToolExecutor.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   ToolCallRequestInfo,
9 |   ToolCallResponseInfo,
10 |   Config,
11 | } from '../index.js';
12 | import { CoreToolScheduler } from './coreToolScheduler.js';
13 | 
14 | /**
15 |  * Executes a single tool call non-interactively by leveraging the CoreToolScheduler.
16 |  */
17 | export async function executeToolCall(
18 |   config: Config,
19 |   toolCallRequest: ToolCallRequestInfo,
20 |   abortSignal: AbortSignal,
21 | ): Promise<ToolCallResponseInfo> {
22 |   return new Promise<ToolCallResponseInfo>((resolve, reject) => {
23 |     new CoreToolScheduler({
24 |       config,
25 |       getPreferredEditor: () => undefined,
26 |       onEditorClose: () => {},
27 |       onAllToolCallsComplete: async (completedToolCalls) => {
28 |         resolve(completedToolCalls[0].response);
29 |       },
30 |     })
31 |       .schedule(toolCallRequest, abortSignal)
32 |       .catch(reject);
33 |   });
34 | }
```

src/core/prompts.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach } from 'vitest';
8 | import { getCoreSystemPrompt, resolvePathFromEnv } from './prompts.js';
9 | import { isGitRepository } from '../utils/gitUtils.js';
10 | import fs from 'node:fs';
11 | import os from 'node:os';
12 | import path from 'node:path';
13 | import { GEMINI_CONFIG_DIR } from '../tools/memoryTool.js';
14 | import type { Config } from '../config/config.js';
15 | import { CodebaseInvestigatorAgent } from '../agents/codebase-investigator.js';
16 | 
17 | // Mock tool names if they are dynamically generated or complex
18 | vi.mock('../tools/ls', () => ({ LSTool: { Name: 'list_directory' } }));
19 | vi.mock('../tools/edit', () => ({ EditTool: { Name: 'replace' } }));
20 | vi.mock('../tools/glob', () => ({ GlobTool: { Name: 'glob' } }));
21 | vi.mock('../tools/grep', () => ({ GrepTool: { Name: 'search_file_content' } }));
22 | vi.mock('../tools/read-file', () => ({ ReadFileTool: { Name: 'read_file' } }));
23 | vi.mock('../tools/read-many-files', () => ({
24 |   ReadManyFilesTool: { Name: 'read_many_files' },
25 | }));
26 | vi.mock('../tools/shell', () => ({
27 |   ShellTool: { Name: 'run_shell_command' },
28 | }));
29 | vi.mock('../tools/write-file', () => ({
30 |   WriteFileTool: { Name: 'write_file' },
31 | }));
32 | vi.mock('../agents/codebase-investigator.js', () => ({
33 |   CodebaseInvestigatorAgent: { name: 'codebase_investigator' },
34 | }));
35 | vi.mock('../utils/gitUtils', () => ({
36 |   isGitRepository: vi.fn(),
37 | }));
38 | vi.mock('node:fs');
39 | 
40 | describe('Core System Prompt (prompts.ts)', () => {
41 |   let mockConfig: Config;
42 |   beforeEach(() => {
43 |     vi.resetAllMocks();
44 |     vi.stubEnv('GEMINI_SYSTEM_MD', undefined);
45 |     vi.stubEnv('GEMINI_WRITE_SYSTEM_MD', undefined);
46 |     mockConfig = {
47 |       getToolRegistry: vi.fn().mockReturnValue({
48 |         getAllToolNames: vi.fn().mockReturnValue([]),
49 |       }),
50 |     } as unknown as Config;
51 |   });
52 | 
53 |   it('should return the base prompt when no userMemory is provided', () => {
54 |     vi.stubEnv('SANDBOX', undefined);
55 |     const prompt = getCoreSystemPrompt(mockConfig, '');
56 |     expect(prompt).not.toContain('---\n\n'); // Separator should not be present
57 |     expect(prompt).toContain('You are an interactive CLI agent'); // Check for core content
58 |     expect(prompt).toMatchSnapshot(); // Use snapshot for base prompt structure
59 |   });
60 | 
61 |   it('should return the base prompt when userMemory is empty string', () => {
62 |     vi.stubEnv('SANDBOX', undefined);
63 |     const prompt = getCoreSystemPrompt(mockConfig, '');
64 |     expect(prompt).not.toContain('---\n\n');
65 |     expect(prompt).toContain('You are an interactive CLI agent');
66 |     expect(prompt).toMatchSnapshot();
67 |   });
68 | 
69 |   it('should return the base prompt when userMemory is whitespace only', () => {
70 |     vi.stubEnv('SANDBOX', undefined);
71 |     const prompt = getCoreSystemPrompt(mockConfig, '   \n  \t ');
72 |     expect(prompt).not.toContain('---\n\n');
73 |     expect(prompt).toContain('You are an interactive CLI agent');
74 |     expect(prompt).toMatchSnapshot();
75 |   });
76 | 
77 |   it('should append userMemory with separator when provided', () => {
78 |     vi.stubEnv('SANDBOX', undefined);
79 |     const memory = 'This is custom user memory.\nBe extra polite.';
80 |     const expectedSuffix = `\n\n---\n\n${memory}`;
81 |     const prompt = getCoreSystemPrompt(mockConfig, memory);
82 | 
83 |     expect(prompt.endsWith(expectedSuffix)).toBe(true);
84 |     expect(prompt).toContain('You are an interactive CLI agent'); // Ensure base prompt follows
85 |     expect(prompt).toMatchSnapshot(); // Snapshot the combined prompt
86 |   });
87 | 
88 |   it('should include sandbox-specific instructions when SANDBOX env var is set', () => {
89 |     vi.stubEnv('SANDBOX', 'true'); // Generic sandbox value
90 |     const prompt = getCoreSystemPrompt(mockConfig);
91 |     expect(prompt).toContain('# Sandbox');
92 |     expect(prompt).not.toContain('# macOS Seatbelt');
93 |     expect(prompt).not.toContain('# Outside of Sandbox');
94 |     expect(prompt).toMatchSnapshot();
95 |   });
96 | 
97 |   it('should include seatbelt-specific instructions when SANDBOX env var is "sandbox-exec"', () => {
98 |     vi.stubEnv('SANDBOX', 'sandbox-exec');
99 |     const prompt = getCoreSystemPrompt(mockConfig);
100 |     expect(prompt).toContain('# macOS Seatbelt');
101 |     expect(prompt).not.toContain('# Sandbox');
102 |     expect(prompt).not.toContain('# Outside of Sandbox');
103 |     expect(prompt).toMatchSnapshot();
104 |   });
105 | 
106 |   it('should include non-sandbox instructions when SANDBOX env var is not set', () => {
107 |     vi.stubEnv('SANDBOX', undefined); // Ensure it\'s not set
108 |     const prompt = getCoreSystemPrompt(mockConfig);
109 |     expect(prompt).toContain('# Outside of Sandbox');
110 |     expect(prompt).not.toContain('# Sandbox');
111 |     expect(prompt).not.toContain('# macOS Seatbelt');
112 |     expect(prompt).toMatchSnapshot();
113 |   });
114 | 
115 |   it('should include git instructions when in a git repo', () => {
116 |     vi.stubEnv('SANDBOX', undefined);
117 |     vi.mocked(isGitRepository).mockReturnValue(true);
118 |     const prompt = getCoreSystemPrompt(mockConfig);
119 |     expect(prompt).toContain('# Git Repository');
120 |     expect(prompt).toMatchSnapshot();
121 |   });
122 | 
123 |   it('should not include git instructions when not in a git repo', () => {
124 |     vi.stubEnv('SANDBOX', undefined);
125 |     vi.mocked(isGitRepository).mockReturnValue(false);
126 |     const prompt = getCoreSystemPrompt(mockConfig);
127 |     expect(prompt).not.toContain('# Git Repository');
128 |     expect(prompt).toMatchSnapshot();
129 |   });
130 | 
131 |   describe('with CodebaseInvestigator enabled', () => {
132 |     beforeEach(() => {
133 |       mockConfig = {
134 |         getToolRegistry: vi.fn().mockReturnValue({
135 |           getAllToolNames: vi
136 |             .fn()
137 |             .mockReturnValue([CodebaseInvestigatorAgent.name]),
138 |         }),
139 |       } as unknown as Config;
140 |     });
141 | 
142 |     it('should include CodebaseInvestigator instructions in the prompt', () => {
143 |       const prompt = getCoreSystemPrompt(mockConfig);
144 |       expect(prompt).toContain(
145 |         `your **first and primary tool** must be '${CodebaseInvestigatorAgent.name}'`,
146 |       );
147 |       expect(prompt).toContain(
148 |         `Do not ignore the output of '${CodebaseInvestigatorAgent.name}'`,
149 |       );
150 |       expect(prompt).not.toContain(
151 |         "Use 'search_file_content' and 'glob' search tools extensively",
152 |       );
153 |     });
154 | 
155 |     it('should include CodebaseInvestigator examples in the prompt', () => {
156 |       const prompt = getCoreSystemPrompt(mockConfig);
157 |       expect(prompt).toContain(
158 |         "First, I'll use the Codebase Investigator to understand the current implementation",
159 |       );
160 |       expect(prompt).toContain(
161 |         `[tool_call: ${CodebaseInvestigatorAgent.name} for query 'Analyze the authentication logic`,
162 |       );
163 |       expect(prompt).toContain(
164 |         "I'll use the Codebase Investigator to find the relevant code and APIs.",
165 |       );
166 |       expect(prompt).toContain(
167 |         `[tool_call: ${CodebaseInvestigatorAgent.name} for query 'Find the code responsible for updating user profile information`,
168 |       );
169 |     });
170 |   });
171 | 
172 |   describe('with CodebaseInvestigator disabled', () => {
173 |     // No beforeEach needed, will use the default from the parent describe
174 |     it('should include standard tool instructions in the prompt', () => {
175 |       const prompt = getCoreSystemPrompt(mockConfig);
176 |       expect(prompt).not.toContain(
177 |         `your **first and primary tool** must be '${CodebaseInvestigatorAgent.name}'`,
178 |       );
179 |       expect(prompt).toContain(
180 |         "Use 'search_file_content' and 'glob' search tools extensively",
181 |       );
182 |     });
183 | 
184 |     it('should include standard tool examples in the prompt', () => {
185 |       const prompt = getCoreSystemPrompt(mockConfig);
186 |       expect(prompt).not.toContain(
187 |         "First, I'll use the Codebase Investigator to understand the current implementation",
188 |       );
189 |       expect(prompt).not.toContain(
190 |         `[tool_call: ${CodebaseInvestigatorAgent.name} for query 'Analyze the authentication logic`,
191 |       );
192 |       expect(prompt).toContain(
193 |         "First, I'll analyze the code and check for a test safety net before planning any changes.",
194 |       );
195 |       expect(prompt).toContain(
196 |         "I'm not immediately sure how user profile information is updated. I'll search the codebase for terms like 'UserProfile'",
197 |       );
198 |     });
199 |   });
200 | 
201 |   describe('GEMINI_SYSTEM_MD environment variable', () => {
202 |     it('should use default prompt when GEMINI_SYSTEM_MD is "false"', () => {
203 |       vi.stubEnv('GEMINI_SYSTEM_MD', 'false');
204 |       const prompt = getCoreSystemPrompt(mockConfig);
205 |       expect(fs.readFileSync).not.toHaveBeenCalled();
206 |       expect(prompt).not.toContain('custom system prompt');
207 |     });
208 | 
209 |     it('should use default prompt when GEMINI_SYSTEM_MD is "0"', () => {
210 |       vi.stubEnv('GEMINI_SYSTEM_MD', '0');
211 |       const prompt = getCoreSystemPrompt(mockConfig);
212 |       expect(fs.readFileSync).not.toHaveBeenCalled();
213 |       expect(prompt).not.toContain('custom system prompt');
214 |     });
215 | 
216 |     it('should throw error if GEMINI_SYSTEM_MD points to a non-existent file', () => {
217 |       const customPath = '/non/existent/path/system.md';
218 |       vi.stubEnv('GEMINI_SYSTEM_MD', customPath);
219 |       vi.mocked(fs.existsSync).mockReturnValue(false);
220 |       expect(() => getCoreSystemPrompt(mockConfig)).toThrow(
221 |         `missing system prompt file '${path.resolve(customPath)}'`,
222 |       );
223 |     });
224 | 
225 |     it('should read from default path when GEMINI_SYSTEM_MD is "true"', () => {
226 |       const defaultPath = path.resolve(
227 |         path.join(GEMINI_CONFIG_DIR, 'system.md'),
228 |       );
229 |       vi.stubEnv('GEMINI_SYSTEM_MD', 'true');
230 |       vi.mocked(fs.existsSync).mockReturnValue(true);
231 |       vi.mocked(fs.readFileSync).mockReturnValue('custom system prompt');
232 | 
233 |       const prompt = getCoreSystemPrompt(mockConfig);
234 |       expect(fs.readFileSync).toHaveBeenCalledWith(defaultPath, 'utf8');
235 |       expect(prompt).toBe('custom system prompt');
236 |     });
237 | 
238 |     it('should read from default path when GEMINI_SYSTEM_MD is "1"', () => {
239 |       const defaultPath = path.resolve(
240 |         path.join(GEMINI_CONFIG_DIR, 'system.md'),
241 |       );
242 |       vi.stubEnv('GEMINI_SYSTEM_MD', '1');
243 |       vi.mocked(fs.existsSync).mockReturnValue(true);
244 |       vi.mocked(fs.readFileSync).mockReturnValue('custom system prompt');
245 | 
246 |       const prompt = getCoreSystemPrompt(mockConfig);
247 |       expect(fs.readFileSync).toHaveBeenCalledWith(defaultPath, 'utf8');
248 |       expect(prompt).toBe('custom system prompt');
249 |     });
250 | 
251 |     it('should read from custom path when GEMINI_SYSTEM_MD provides one, preserving case', () => {
252 |       const customPath = path.resolve('/custom/path/SyStEm.Md');
253 |       vi.stubEnv('GEMINI_SYSTEM_MD', customPath);
254 |       vi.mocked(fs.existsSync).mockReturnValue(true);
255 |       vi.mocked(fs.readFileSync).mockReturnValue('custom system prompt');
256 | 
257 |       const prompt = getCoreSystemPrompt(mockConfig);
258 |       expect(fs.readFileSync).toHaveBeenCalledWith(customPath, 'utf8');
259 |       expect(prompt).toBe('custom system prompt');
260 |     });
261 | 
262 |     it('should expand tilde in custom path when GEMINI_SYSTEM_MD is set', () => {
263 |       const homeDir = '/Users/test';
264 |       vi.spyOn(os, 'homedir').mockReturnValue(homeDir);
265 |       const customPath = '~/custom/system.md';
266 |       const expectedPath = path.join(homeDir, 'custom/system.md');
267 |       vi.stubEnv('GEMINI_SYSTEM_MD', customPath);
268 |       vi.mocked(fs.existsSync).mockReturnValue(true);
269 |       vi.mocked(fs.readFileSync).mockReturnValue('custom system prompt');
270 | 
271 |       const prompt = getCoreSystemPrompt(mockConfig);
272 |       expect(fs.readFileSync).toHaveBeenCalledWith(
273 |         path.resolve(expectedPath),
274 |         'utf8',
275 |       );
276 |       expect(prompt).toBe('custom system prompt');
277 |     });
278 |   });
279 | 
280 |   describe('GEMINI_WRITE_SYSTEM_MD environment variable', () => {
281 |     it('should not write to file when GEMINI_WRITE_SYSTEM_MD is "false"', () => {
282 |       vi.stubEnv('GEMINI_WRITE_SYSTEM_MD', 'false');
283 |       getCoreSystemPrompt(mockConfig);
284 |       expect(fs.writeFileSync).not.toHaveBeenCalled();
285 |     });
286 | 
287 |     it('should not write to file when GEMINI_WRITE_SYSTEM_MD is "0"', () => {
288 |       vi.stubEnv('GEMINI_WRITE_SYSTEM_MD', '0');
289 |       getCoreSystemPrompt(mockConfig);
290 |       expect(fs.writeFileSync).not.toHaveBeenCalled();
291 |     });
292 | 
293 |     it('should write to default path when GEMINI_WRITE_SYSTEM_MD is "true"', () => {
294 |       const defaultPath = path.resolve(
295 |         path.join(GEMINI_CONFIG_DIR, 'system.md'),
296 |       );
297 |       vi.stubEnv('GEMINI_WRITE_SYSTEM_MD', 'true');
298 |       getCoreSystemPrompt(mockConfig);
299 |       expect(fs.writeFileSync).toHaveBeenCalledWith(
300 |         defaultPath,
301 |         expect.any(String),
302 |       );
303 |     });
304 | 
305 |     it('should write to default path when GEMINI_WRITE_SYSTEM_MD is "1"', () => {
306 |       const defaultPath = path.resolve(
307 |         path.join(GEMINI_CONFIG_DIR, 'system.md'),
308 |       );
309 |       vi.stubEnv('GEMINI_WRITE_SYSTEM_MD', '1');
310 |       getCoreSystemPrompt(mockConfig);
311 |       expect(fs.writeFileSync).toHaveBeenCalledWith(
312 |         defaultPath,
313 |         expect.any(String),
314 |       );
315 |     });
316 | 
317 |     it('should write to custom path when GEMINI_WRITE_SYSTEM_MD provides one', () => {
318 |       const customPath = path.resolve('/custom/path/system.md');
319 |       vi.stubEnv('GEMINI_WRITE_SYSTEM_MD', customPath);
320 |       getCoreSystemPrompt(mockConfig);
321 |       expect(fs.writeFileSync).toHaveBeenCalledWith(
322 |         customPath,
323 |         expect.any(String),
324 |       );
325 |     });
326 | 
327 |     it('should expand tilde in custom path when GEMINI_WRITE_SYSTEM_MD is set', () => {
328 |       const homeDir = '/Users/test';
329 |       vi.spyOn(os, 'homedir').mockReturnValue(homeDir);
330 |       const customPath = '~/custom/system.md';
331 |       const expectedPath = path.join(homeDir, 'custom/system.md');
332 |       vi.stubEnv('GEMINI_WRITE_SYSTEM_MD', customPath);
333 |       getCoreSystemPrompt(mockConfig);
334 |       expect(fs.writeFileSync).toHaveBeenCalledWith(
335 |         path.resolve(expectedPath),
336 |         expect.any(String),
337 |       );
338 |     });
339 | 
340 |     it('should expand tilde in custom path when GEMINI_WRITE_SYSTEM_MD is just ~', () => {
341 |       const homeDir = '/Users/test';
342 |       vi.spyOn(os, 'homedir').mockReturnValue(homeDir);
343 |       const customPath = '~';
344 |       const expectedPath = homeDir;
345 |       vi.stubEnv('GEMINI_WRITE_SYSTEM_MD', customPath);
346 |       getCoreSystemPrompt(mockConfig);
347 |       expect(fs.writeFileSync).toHaveBeenCalledWith(
348 |         path.resolve(expectedPath),
349 |         expect.any(String),
350 |       );
351 |     });
352 |   });
353 | });
354 | 
355 | describe('resolvePathFromEnv helper function', () => {
356 |   beforeEach(() => {
357 |     vi.resetAllMocks();
358 |   });
359 | 
360 |   describe('when envVar is undefined, empty, or whitespace', () => {
361 |     it('should return null for undefined', () => {
362 |       const result = resolvePathFromEnv(undefined);
363 |       expect(result).toEqual({
364 |         isSwitch: false,
365 |         value: null,
366 |         isDisabled: false,
367 |       });
368 |     });
369 | 
370 |     it('should return null for empty string', () => {
371 |       const result = resolvePathFromEnv('');
372 |       expect(result).toEqual({
373 |         isSwitch: false,
374 |         value: null,
375 |         isDisabled: false,
376 |       });
377 |     });
378 | 
379 |     it('should return null for whitespace only', () => {
380 |       const result = resolvePathFromEnv('   \n\t  ');
381 |       expect(result).toEqual({
382 |         isSwitch: false,
383 |         value: null,
384 |         isDisabled: false,
385 |       });
386 |     });
387 |   });
388 | 
389 |   describe('when envVar is a boolean-like string', () => {
390 |     it('should handle "0" as disabled switch', () => {
391 |       const result = resolvePathFromEnv('0');
392 |       expect(result).toEqual({
393 |         isSwitch: true,
394 |         value: '0',
395 |         isDisabled: true,
396 |       });
397 |     });
398 | 
399 |     it('should handle "false" as disabled switch', () => {
400 |       const result = resolvePathFromEnv('false');
401 |       expect(result).toEqual({
402 |         isSwitch: true,
403 |         value: 'false',
404 |         isDisabled: true,
405 |       });
406 |     });
407 | 
408 |     it('should handle "1" as enabled switch', () => {
409 |       const result = resolvePathFromEnv('1');
410 |       expect(result).toEqual({
411 |         isSwitch: true,
412 |         value: '1',
413 |         isDisabled: false,
414 |       });
415 |     });
416 | 
417 |     it('should handle "true" as enabled switch', () => {
418 |       const result = resolvePathFromEnv('true');
419 |       expect(result).toEqual({
420 |         isSwitch: true,
421 |         value: 'true',
422 |         isDisabled: false,
423 |       });
424 |     });
425 | 
426 |     it('should be case-insensitive for boolean values', () => {
427 |       expect(resolvePathFromEnv('FALSE')).toEqual({
428 |         isSwitch: true,
429 |         value: 'false',
430 |         isDisabled: true,
431 |       });
432 |       expect(resolvePathFromEnv('TRUE')).toEqual({
433 |         isSwitch: true,
434 |         value: 'true',
435 |         isDisabled: false,
436 |       });
437 |     });
438 |   });
439 | 
440 |   describe('when envVar is a file path', () => {
441 |     it('should resolve absolute paths', () => {
442 |       const result = resolvePathFromEnv('/absolute/path/file.txt');
443 |       expect(result).toEqual({
444 |         isSwitch: false,
445 |         value: path.resolve('/absolute/path/file.txt'),
446 |         isDisabled: false,
447 |       });
448 |     });
449 | 
450 |     it('should resolve relative paths', () => {
451 |       const result = resolvePathFromEnv('relative/path/file.txt');
452 |       expect(result).toEqual({
453 |         isSwitch: false,
454 |         value: path.resolve('relative/path/file.txt'),
455 |         isDisabled: false,
456 |       });
457 |     });
458 | 
459 |     it('should expand tilde to home directory', () => {
460 |       const homeDir = '/Users/test';
461 |       vi.spyOn(os, 'homedir').mockReturnValue(homeDir);
462 | 
463 |       const result = resolvePathFromEnv('~/documents/file.txt');
464 |       expect(result).toEqual({
465 |         isSwitch: false,
466 |         value: path.resolve(path.join(homeDir, 'documents/file.txt')),
467 |         isDisabled: false,
468 |       });
469 |     });
470 | 
471 |     it('should handle standalone tilde', () => {
472 |       const homeDir = '/Users/test';
473 |       vi.spyOn(os, 'homedir').mockReturnValue(homeDir);
474 | 
475 |       const result = resolvePathFromEnv('~');
476 |       expect(result).toEqual({
477 |         isSwitch: false,
478 |         value: path.resolve(homeDir),
479 |         isDisabled: false,
480 |       });
481 |     });
482 | 
483 |     it('should handle os.homedir() errors gracefully', () => {
484 |       vi.spyOn(os, 'homedir').mockImplementation(() => {
485 |         throw new Error('Cannot resolve home directory');
486 |       });
487 |       const consoleSpy = vi.spyOn(console, 'warn').mockImplementation(() => {});
488 | 
489 |       const result = resolvePathFromEnv('~/documents/file.txt');
490 |       expect(result).toEqual({
491 |         isSwitch: false,
492 |         value: null,
493 |         isDisabled: false,
494 |       });
495 |       expect(consoleSpy).toHaveBeenCalledWith(
496 |         'Could not resolve home directory for path: ~/documents/file.txt',
497 |         expect.any(Error),
498 |       );
499 | 
500 |       consoleSpy.mockRestore();
501 |     });
502 |   });
503 | });
```

src/core/prompts.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import path from 'node:path';
8 | import fs from 'node:fs';
9 | import os from 'node:os';
10 | import { LSTool } from '../tools/ls.js';
11 | import { EditTool } from '../tools/edit.js';
12 | import { GlobTool } from '../tools/glob.js';
13 | import { GrepTool } from '../tools/grep.js';
14 | import { ReadFileTool } from '../tools/read-file.js';
15 | import { ReadManyFilesTool } from '../tools/read-many-files.js';
16 | import { ShellTool } from '../tools/shell.js';
17 | import { WRITE_FILE_TOOL_NAME } from '../tools/tool-names.js';
18 | import process from 'node:process';
19 | import { isGitRepository } from '../utils/gitUtils.js';
20 | import { MemoryTool, GEMINI_CONFIG_DIR } from '../tools/memoryTool.js';
21 | import { CodebaseInvestigatorAgent } from '../agents/codebase-investigator.js';
22 | import type { Config } from '../config/config.js';
23 | 
24 | export function resolvePathFromEnv(envVar?: string): {
25 |   isSwitch: boolean;
26 |   value: string | null;
27 |   isDisabled: boolean;
28 | } {
29 |   // Handle the case where the environment variable is not set, empty, or just whitespace.
30 |   const trimmedEnvVar = envVar?.trim();
31 |   if (!trimmedEnvVar) {
32 |     return { isSwitch: false, value: null, isDisabled: false };
33 |   }
34 | 
35 |   const lowerEnvVar = trimmedEnvVar.toLowerCase();
36 |   // Check if the input is a common boolean-like string.
37 |   if (['0', 'false', '1', 'true'].includes(lowerEnvVar)) {
38 |     // If so, identify it as a "switch" and return its value.
39 |     const isDisabled = ['0', 'false'].includes(lowerEnvVar);
40 |     return { isSwitch: true, value: lowerEnvVar, isDisabled };
41 |   }
42 | 
43 |   // If it's not a switch, treat it as a potential file path.
44 |   let customPath = trimmedEnvVar;
45 | 
46 |   // Safely expand the tilde (~) character to the user's home directory.
47 |   if (customPath.startsWith('~/') || customPath === '~') {
48 |     try {
49 |       const home = os.homedir(); // This is the call that can throw an error.
50 |       if (customPath === '~') {
51 |         customPath = home;
52 |       } else {
53 |         customPath = path.join(home, customPath.slice(2));
54 |       }
55 |     } catch (error) {
56 |       // If os.homedir() fails, we catch the error instead of crashing.
57 |       console.warn(
58 |         `Could not resolve home directory for path: ${trimmedEnvVar}`,
59 |         error,
60 |       );
61 |       // Return null to indicate the path resolution failed.
62 |       return { isSwitch: false, value: null, isDisabled: false };
63 |     }
64 |   }
65 | 
66 |   // Return it as a non-switch with the fully resolved absolute path.
67 |   return {
68 |     isSwitch: false,
69 |     value: path.resolve(customPath),
70 |     isDisabled: false,
71 |   };
72 | }
73 | 
74 | export function getCoreSystemPrompt(
75 |   config: Config,
76 |   userMemory?: string,
77 | ): string {
78 |   // A flag to indicate whether the system prompt override is active.
79 |   let systemMdEnabled = false;
80 |   // The default path for the system prompt file. This can be overridden.
81 |   let systemMdPath = path.resolve(path.join(GEMINI_CONFIG_DIR, 'system.md'));
82 |   // Resolve the environment variable to get either a path or a switch value.
83 |   const systemMdResolution = resolvePathFromEnv(
84 |     process.env['GEMINI_SYSTEM_MD'],
85 |   );
86 | 
87 |   // Proceed only if the environment variable is set and is not disabled.
88 |   if (systemMdResolution.value && !systemMdResolution.isDisabled) {
89 |     systemMdEnabled = true;
90 | 
91 |     // We update systemMdPath to this new custom path.
92 |     if (!systemMdResolution.isSwitch) {
93 |       systemMdPath = systemMdResolution.value;
94 |     }
95 | 
96 |     // require file to exist when override is enabled
97 |     if (!fs.existsSync(systemMdPath)) {
98 |       throw new Error(`missing system prompt file '${systemMdPath}'`);
99 |     }
100 |   }
101 | 
102 |   const enableCodebaseInvestigator = config
103 |     .getToolRegistry()
104 |     .getAllToolNames()
105 |     .includes(CodebaseInvestigatorAgent.name);
106 | 
107 |   const basePrompt = systemMdEnabled
108 |     ? fs.readFileSync(systemMdPath, 'utf8')
109 |     : `You are an interactive CLI agent specializing in software engineering tasks. Your primary goal is to help users safely and efficiently, adhering strictly to the following instructions and utilizing your available tools.
110 | 
111 | # Core Mandates
112 | 
113 | - **Conventions:** Rigorously adhere to existing project conventions when reading or modifying code. Analyze surrounding code, tests, and configuration first.
114 | - **Libraries/Frameworks:** NEVER assume a library/framework is available or appropriate. Verify its established usage within the project (check imports, configuration files like 'package.json', 'Cargo.toml', 'requirements.txt', 'build.gradle', etc., or observe neighboring files) before employing it.
115 | - **Style & Structure:** Mimic the style (formatting, naming), structure, framework choices, typing, and architectural patterns of existing code in the project.
116 | - **Idiomatic Changes:** When editing, understand the local context (imports, functions/classes) to ensure your changes integrate naturally and idiomatically.
117 | - **Comments:** Add code comments sparingly. Focus on *why* something is done, especially for complex logic, rather than *what* is done. Only add high-value comments if necessary for clarity or if requested by the user. Do not edit comments that are separate from the code you are changing. *NEVER* talk to the user or describe your changes through comments.
118 | - **Proactiveness:** Fulfill the user's request thoroughly. When adding features or fixing bugs, this includes adding tests to ensure quality. Consider all created files, especially tests, to be permanent artifacts unless the user says otherwise.
119 | - **Confirm Ambiguity/Expansion:** Do not take significant actions beyond the clear scope of the request without confirming with the user. If asked *how* to do something, explain first, don't just do it.
120 | - **Explaining Changes:** After completing a code modification or file operation *do not* provide summaries unless asked.
121 | - **Path Construction:** Before using any file system tool (e.g., ${ReadFileTool.Name}' or '${WRITE_FILE_TOOL_NAME}'), you must construct the full absolute path for the file_path argument. Always combine the absolute path of the project's root directory with the file's path relative to the root. For example, if the project root is /path/to/project/ and the file is foo/bar/baz.txt, the final path you must use is /path/to/project/foo/bar/baz.txt. If the user provides a relative path, you must resolve it against the root directory to create an absolute path.
122 | - **Do Not revert changes:** Do not revert changes to the codebase unless asked to do so by the user. Only revert changes made by you if they have resulted in an error or if the user has explicitly asked you to revert the changes.
123 | 
124 | 
125 | # Primary Workflows
126 | 
127 | ## Software Engineering Tasks
128 | When requested to perform tasks like fixing bugs, adding features, refactoring, or explaining code, follow this sequence:
129 | ${(function () {
130 |   if (enableCodebaseInvestigator) {
131 |     return `
132 | 1. **Understand & Strategize:** for any request that requires searching terms or explore the codebase, your **first and primary tool** must be '${CodebaseInvestigatorAgent.name}'. You must use it to build a comprehensive understanding of the relevant code, its structure, and dependencies. The output from '${CodebaseInvestigatorAgent.name}' will be the foundation of your plan. YOU MUST not use '${GrepTool.Name}' or '${GlobTool.Name}' as your initial exploration tool; they should only be used for secondary, targeted searches after the investigator has provided you with context.
133 | 2. **Plan:** Build a coherent and grounded (based on the understanding in step 1) plan for how you intend to resolve the user's task. Do not ignore the output of '${CodebaseInvestigatorAgent.name}', you must use it as the foundation of your plan. Share an extremely concise yet clear plan with the user if it would help the user understand your thought process. As part of the plan, you should use an iterative development process that includes writing unit tests to verify your changes. Use output logs or debug statements as part of this process to arrive at a solution.`;
134 |   }
135 |   return `
136 | 1. **Understand:** Think about the user's request and the relevant codebase context. Use '${GrepTool.Name}' and '${GlobTool.Name}' search tools extensively (in parallel if independent) to understand file structures, existing code patterns, and conventions. Use '${ReadFileTool.Name}' and '${ReadManyFilesTool.Name}' to understand context and validate any assumptions you may have.
137 | 2. **Plan:** Build a coherent and grounded (based on the understanding in step 1) plan for how you intend to resolve the user's task. Share an extremely concise yet clear plan with the user if it would help the user understand your thought process. As part of the plan, you should use an iterative development process that includes writing unit tests to verify your changes. Use output logs or debug statements as part of this process to arrive at a solution.`;
138 | })()}
139 | 3. **Implement:** Use the available tools (e.g., '${EditTool.Name}', '${WRITE_FILE_TOOL_NAME}' '${ShellTool.Name}' ...) to act on the plan, strictly adhering to the project's established conventions (detailed under 'Core Mandates').
140 | 4. **Verify (Tests):** If applicable and feasible, verify the changes using the project's testing procedures. Identify the correct test commands and frameworks by examining 'README' files, build/package configuration (e.g., 'package.json'), or existing test execution patterns. NEVER assume standard test commands.
141 | 5. **Verify (Standards):** VERY IMPORTANT: After making code changes, execute the project-specific build, linting and type-checking commands (e.g., 'tsc', 'npm run lint', 'ruff check .') that you have identified for this project (or obtained from the user). This ensures code quality and adherence to standards. If unsure about these commands, you can ask the user if they'd like you to run them and if so how to.
142 | 6. **Finalize:** After all verification passes, consider the task complete. Do not remove or revert any changes or created files (like tests). Await the user's next instruction.
143 | 
144 | ## New Applications
145 | 
146 | **Goal:** Autonomously implement and deliver a visually appealing, substantially complete, and functional prototype. Utilize all tools at your disposal to implement the application. Some tools you may especially find useful are '${WRITE_FILE_TOOL_NAME}', '${EditTool.Name}' and '${ShellTool.Name}'.
147 | 
148 | 1. **Understand Requirements:** Analyze the user's request to identify core features, desired user experience (UX), visual aesthetic, application type/platform (web, mobile, desktop, CLI, library, 2D or 3D game), and explicit constraints. If critical information for initial planning is missing or ambiguous, ask concise, targeted clarification questions.
149 | 2. **Propose Plan:** Formulate an internal development plan. Present a clear, concise, high-level summary to the user. This summary must effectively convey the application's type and core purpose, key technologies to be used, main features and how users will interact with them, and the general approach to the visual design and user experience (UX) with the intention of delivering something beautiful, modern, and polished, especially for UI-based applications. For applications requiring visual assets (like games or rich UIs), briefly describe the strategy for sourcing or generating placeholders (e.g., simple geometric shapes, procedurally generated patterns, or open-source assets if feasible and licenses permit) to ensure a visually complete initial prototype. Ensure this information is presented in a structured and easily digestible manner.
150 |   - When key technologies aren't specified, prefer the following:
151 |   - **Websites (Frontend):** React (JavaScript/TypeScript) with Bootstrap CSS, incorporating Material Design principles for UI/UX.
152 |   - **Back-End APIs:** Node.js with Express.js (JavaScript/TypeScript) or Python with FastAPI.
153 |   - **Full-stack:** Next.js (React/Node.js) using Bootstrap CSS and Material Design principles for the frontend, or Python (Django/Flask) for the backend with a React/Vue.js frontend styled with Bootstrap CSS and Material Design principles.
154 |   - **CLIs:** Python or Go.
155 |   - **Mobile App:** Compose Multiplatform (Kotlin Multiplatform) or Flutter (Dart) using Material Design libraries and principles, when sharing code between Android and iOS. Jetpack Compose (Kotlin JVM) with Material Design principles or SwiftUI (Swift) for native apps targeted at either Android or iOS, respectively.
156 |   - **3d Games:** HTML/CSS/JavaScript with Three.js.
157 |   - **2d Games:** HTML/CSS/JavaScript.
158 | 3. **User Approval:** Obtain user approval for the proposed plan.
159 | 4. **Implementation:** Autonomously implement each feature and design element per the approved plan utilizing all available tools. When starting ensure you scaffold the application using '${ShellTool.Name}' for commands like 'npm init', 'npx create-react-app'. Aim for full scope completion. Proactively create or source necessary placeholder assets (e.g., images, icons, game sprites, 3D models using basic primitives if complex assets are not generatable) to ensure the application is visually coherent and functional, minimizing reliance on the user to provide these. If the model can generate simple assets (e.g., a uniformly colored square sprite, a simple 3D cube), it should do so. Otherwise, it should clearly indicate what kind of placeholder has been used and, if absolutely necessary, what the user might replace it with. Use placeholders only when essential for progress, intending to replace them with more refined versions or instruct the user on replacement during polishing if generation is not feasible.
160 | 5. **Verify:** Review work against the original request, the approved plan. Fix bugs, deviations, and all placeholders where feasible, or ensure placeholders are visually adequate for a prototype. Ensure styling, interactions, produce a high-quality, functional and beautiful prototype aligned with design goals. Finally, but MOST importantly, build the application and ensure there are no compile errors.
161 | 6. **Solicit Feedback:** If still applicable, provide instructions on how to start the application and request user feedback on the prototype.
162 | 
163 | # Operational Guidelines
164 | 
165 | ## Tone and Style (CLI Interaction)
166 | - **Concise & Direct:** Adopt a professional, direct, and concise tone suitable for a CLI environment.
167 | - **Minimal Output:** Aim for fewer than 3 lines of text output (excluding tool use/code generation) per response whenever practical. Focus strictly on the user's query.
168 | - **Clarity over Brevity (When Needed):** While conciseness is key, prioritize clarity for essential explanations or when seeking necessary clarification if a request is ambiguous.
169 | - **No Chitchat:** Avoid conversational filler, preambles ("Okay, I will now..."), or postambles ("I have finished the changes..."). Get straight to the action or answer.
170 | - **Formatting:** Use GitHub-flavored Markdown. Responses will be rendered in monospace.
171 | - **Tools vs. Text:** Use tools for actions, text output *only* for communication. Do not add explanatory comments within tool calls or code blocks unless specifically part of the required code/command itself.
172 | - **Handling Inability:** If unable/unwilling to fulfill a request, state so briefly (1-2 sentences) without excessive justification. Offer alternatives if appropriate.
173 | 
174 | ## Security and Safety Rules
175 | - **Explain Critical Commands:** Before executing commands with '${ShellTool.Name}' that modify the file system, codebase, or system state, you *must* provide a brief explanation of the command's purpose and potential impact. Prioritize user understanding and safety. You should not ask permission to use the tool; the user will be presented with a confirmation dialogue upon use (you do not need to tell them this).
176 | - **Security First:** Always apply security best practices. Never introduce code that exposes, logs, or commits secrets, API keys, or other sensitive information.
177 | 
178 | ## Tool Usage
179 | - **File Paths:** Always use absolute paths when referring to files with tools like '${ReadFileTool.Name}' or '${WRITE_FILE_TOOL_NAME}'. Relative paths are not supported. You must provide an absolute path.
180 | - **Parallelism:** Execute multiple independent tool calls in parallel when feasible (i.e. searching the codebase).
181 | - **Command Execution:** Use the '${ShellTool.Name}' tool for running shell commands, remembering the safety rule to explain modifying commands first.
182 | - **Background Processes:** Use background processes (via \`&\`) for commands that are unlikely to stop on their own, e.g. \`node server.js &\`. If unsure, ask the user.
183 | - **Interactive Commands:** Try to avoid shell commands that are likely to require user interaction (e.g. \`git rebase -i\`). Use non-interactive versions of commands (e.g. \`npm init -y\` instead of \`npm init\`) when available, and otherwise remind the user that interactive shell commands are not supported and may cause hangs until canceled by the user.
184 | - **Remembering Facts:** Use the '${MemoryTool.Name}' tool to remember specific, *user-related* facts or preferences when the user explicitly asks, or when they state a clear, concise piece of information that would help personalize or streamline *your future interactions with them* (e.g., preferred coding style, common project paths they use, personal tool aliases). This tool is for user-specific information that should persist across sessions. Do *not* use it for general project context or information. If unsure whether to save something, you can ask the user, "Should I remember that for you?"
185 | - **Respect User Confirmations:** Most tool calls (also denoted as 'function calls') will first require confirmation from the user, where they will either approve or cancel the function call. If a user cancels a function call, respect their choice and do _not_ try to make the function call again. It is okay to request the tool call again _only_ if the user requests that same tool call on a subsequent prompt. When a user cancels a function call, assume best intentions from the user and consider inquiring if they prefer any alternative paths forward.
186 | 
187 | ## Interaction Details
188 | - **Help Command:** The user can use '/help' to display help information.
189 | - **Feedback:** To report a bug or provide feedback, please use the /bug command.
190 | 
191 | ${(function () {
192 |   // Determine sandbox status based on environment variables
193 |   const isSandboxExec = process.env['SANDBOX'] === 'sandbox-exec';
194 |   const isGenericSandbox = !!process.env['SANDBOX']; // Check if SANDBOX is set to any non-empty value
195 | 
196 |   if (isSandboxExec) {
197 |     return `
198 | # macOS Seatbelt
199 | You are running under macos seatbelt with limited access to files outside the project directory or system temp directory, and with limited access to host system resources such as ports. If you encounter failures that could be due to macOS Seatbelt (e.g. if a command fails with 'Operation not permitted' or similar error), as you report the error to the user, also explain why you think it could be due to macOS Seatbelt, and how the user may need to adjust their Seatbelt profile.
200 | `;
201 |   } else if (isGenericSandbox) {
202 |     return `
203 | # Sandbox
[TRUNCATED]
```

src/core/subagent.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { vi, describe, it, expect, beforeEach, afterEach } from 'vitest';
8 | import type { Mock } from 'vitest';
9 | import {
10 |   ContextState,
11 |   SubAgentScope,
12 |   SubagentTerminateMode,
13 | } from './subagent.js';
14 | import type {
15 |   PromptConfig,
16 |   ModelConfig,
17 |   RunConfig,
18 |   OutputConfig,
19 |   ToolConfig,
20 |   SubAgentOptions,
21 | } from './subagent.js';
22 | import { Config } from '../config/config.js';
23 | import type { ConfigParameters } from '../config/config.js';
24 | import { GeminiChat, StreamEventType } from './geminiChat.js';
25 | import { createContentGenerator } from './contentGenerator.js';
26 | import { getEnvironmentContext } from '../utils/environmentContext.js';
27 | import { executeToolCall } from './nonInteractiveToolExecutor.js';
28 | import type { ToolRegistry } from '../tools/tool-registry.js';
29 | import { DEFAULT_GEMINI_MODEL } from '../config/models.js';
30 | import { Type } from '@google/genai';
31 | import type {
32 |   Content,
33 |   FunctionCall,
34 |   FunctionDeclaration,
35 |   GenerateContentConfig,
36 |   GenerateContentResponse,
37 | } from '@google/genai';
38 | import { ToolErrorType } from '../tools/tool-error.js';
39 | 
40 | vi.mock('./geminiChat.js');
41 | vi.mock('./contentGenerator.js');
42 | vi.mock('../utils/environmentContext.js');
43 | vi.mock('./nonInteractiveToolExecutor.js');
44 | vi.mock('../ide/ide-client.js');
45 | 
46 | async function createMockConfig(
47 |   toolRegistryMocks = {},
48 |   configParameters: Partial<ConfigParameters> = {},
49 | ): Promise<{ config: Config; toolRegistry: ToolRegistry }> {
50 |   const configParams: ConfigParameters = {
51 |     sessionId: 'test-session',
52 |     model: DEFAULT_GEMINI_MODEL,
53 |     targetDir: '.',
54 |     debugMode: false,
55 |     cwd: process.cwd(),
56 |     ...configParameters,
57 |   };
58 |   const config = new Config(configParams);
59 |   await config.initialize();
60 | 
61 |   // Mock ToolRegistry
62 |   const mockToolRegistry = {
63 |     getTool: vi.fn(),
64 |     getFunctionDeclarationsFiltered: vi.fn().mockReturnValue([]),
65 |     ...toolRegistryMocks,
66 |   } as unknown as ToolRegistry;
67 | 
68 |   vi.spyOn(config, 'getToolRegistry').mockReturnValue(mockToolRegistry);
69 |   return { config, toolRegistry: mockToolRegistry };
70 | }
71 | 
72 | // Helper to simulate LLM responses (sequence of tool calls over multiple turns)
73 | const createMockStream = (
74 |   functionCallsList: Array<FunctionCall[] | 'stop'>,
75 | ) => {
76 |   let index = 0;
77 |   // This mock now returns a Promise that resolves to the async generator,
78 |   // matching the new signature for sendMessageStream.
79 |   return vi.fn().mockImplementation(async () => {
80 |     const response = functionCallsList[index] || 'stop';
81 |     index++;
82 | 
83 |     return (async function* () {
84 |       let mockResponseValue: Partial<GenerateContentResponse>;
85 | 
86 |       if (response === 'stop' || response.length === 0) {
87 |         // Simulate a text response for stop/empty conditions.
88 |         mockResponseValue = {
89 |           candidates: [{ content: { parts: [{ text: 'Done.' }] } }],
90 |         };
91 |       } else {
92 |         // Simulate a tool call response.
93 |         mockResponseValue = {
94 |           candidates: [], // Good practice to include for safety.
95 |           functionCalls: response,
96 |         };
97 |       }
98 | 
99 |       // The stream must now yield a StreamEvent object of type CHUNK.
100 |       yield {
101 |         type: StreamEventType.CHUNK,
102 |         value: mockResponseValue as GenerateContentResponse,
103 |       };
104 |     })();
105 |   });
106 | };
107 | 
108 | describe('subagent.ts', () => {
109 |   describe('ContextState', () => {
110 |     it('should set and get values correctly', () => {
111 |       const context = new ContextState();
112 |       context.set('key1', 'value1');
113 |       context.set('key2', 123);
114 |       expect(context.get('key1')).toBe('value1');
115 |       expect(context.get('key2')).toBe(123);
116 |       expect(context.get_keys()).toEqual(['key1', 'key2']);
117 |     });
118 | 
119 |     it('should return undefined for missing keys', () => {
120 |       const context = new ContextState();
121 |       expect(context.get('missing')).toBeUndefined();
122 |     });
123 |   });
124 | 
125 |   describe('SubAgentScope', () => {
126 |     let mockSendMessageStream: Mock;
127 | 
128 |     const defaultModelConfig: ModelConfig = {
129 |       model: 'gemini-1.5-flash-latest',
130 |       temp: 0.5, // Specific temp to test override
131 |       top_p: 1,
132 |     };
133 | 
134 |     const defaultRunConfig: RunConfig = {
135 |       max_time_minutes: 5,
136 |       max_turns: 10,
137 |     };
138 | 
139 |     beforeEach(async () => {
140 |       vi.clearAllMocks();
141 | 
142 |       vi.mocked(getEnvironmentContext).mockResolvedValue([
143 |         { text: 'Env Context' },
144 |       ]);
145 |       vi.mocked(createContentGenerator).mockResolvedValue({
146 |         getGenerativeModel: vi.fn(),
147 |         // eslint-disable-next-line @typescript-eslint/no-explicit-any
148 |       } as any);
149 | 
150 |       mockSendMessageStream = vi.fn();
151 |       // We mock the implementation of the constructor.
152 |       vi.mocked(GeminiChat).mockImplementation(
153 |         () =>
154 |           ({
155 |             sendMessageStream: mockSendMessageStream,
156 |           }) as unknown as GeminiChat,
157 |       );
158 |     });
159 | 
160 |     afterEach(() => {
161 |       vi.restoreAllMocks();
162 |     });
163 | 
164 |     // Helper to safely access generationConfig from mock calls
165 |     const getGenerationConfigFromMock = (
166 |       callIndex = 0,
167 |     ): GenerateContentConfig => {
168 |       const callArgs = vi.mocked(GeminiChat).mock.calls[callIndex];
169 |       const generationConfig = callArgs?.[1];
170 |       // Ensure it's defined before proceeding
171 |       expect(generationConfig).toBeDefined();
172 |       if (!generationConfig) throw new Error('generationConfig is undefined');
173 |       return generationConfig as GenerateContentConfig;
174 |     };
175 | 
176 |     describe('create (Tool Validation)', () => {
177 |       const promptConfig: PromptConfig = { systemPrompt: 'Test prompt' };
178 | 
179 |       it('should create a SubAgentScope successfully with minimal config', async () => {
180 |         const { config } = await createMockConfig();
181 |         const scope = await SubAgentScope.create(
182 |           'test-agent',
183 |           config,
184 |           promptConfig,
185 |           defaultModelConfig,
186 |           defaultRunConfig,
187 |         );
188 |         expect(scope).toBeInstanceOf(SubAgentScope);
189 |       });
190 | 
191 |       it('should throw an error if a tool requires confirmation', async () => {
192 |         const mockTool = {
193 |           name: 'risky_tool',
194 |           schema: { parametersJsonSchema: { type: 'object', properties: {} } },
195 |           build: vi.fn().mockReturnValue({
196 |             shouldConfirmExecute: vi.fn().mockResolvedValue({
197 |               type: 'exec',
198 |               title: 'Confirm',
199 |               command: 'rm -rf /',
200 |             }),
201 |           }),
202 |         };
203 | 
204 |         const { config } = await createMockConfig({
205 |           // eslint-disable-next-line @typescript-eslint/no-explicit-any
206 |           getTool: vi.fn().mockReturnValue(mockTool as any),
207 |         });
208 | 
209 |         const toolConfig: ToolConfig = { tools: ['risky_tool'] };
210 |         const options: SubAgentOptions = { toolConfig };
211 | 
212 |         await expect(
213 |           SubAgentScope.create(
214 |             'test-agent',
215 |             config,
216 |             promptConfig,
217 |             defaultModelConfig,
218 |             defaultRunConfig,
219 |             options,
220 |           ),
221 |         ).rejects.toThrow(
222 |           'Tool "risky_tool" requires user confirmation and cannot be used in a non-interactive subagent.',
223 |         );
224 |       });
225 | 
226 |       it('should succeed if tools do not require confirmation', async () => {
227 |         const mockTool = {
228 |           name: 'safe_tool',
229 |           schema: { parametersJsonSchema: { type: 'object', properties: {} } },
230 |           build: vi.fn().mockReturnValue({
231 |             shouldConfirmExecute: vi.fn().mockResolvedValue(null),
232 |           }),
233 |         };
234 |         const { config } = await createMockConfig({
235 |           // eslint-disable-next-line @typescript-eslint/no-explicit-any
236 |           getTool: vi.fn().mockReturnValue(mockTool as any),
237 |         });
238 | 
239 |         const toolConfig: ToolConfig = { tools: ['safe_tool'] };
240 |         const options: SubAgentOptions = { toolConfig };
241 | 
242 |         const scope = await SubAgentScope.create(
243 |           'test-agent',
244 |           config,
245 |           promptConfig,
246 |           defaultModelConfig,
247 |           defaultRunConfig,
248 |           options,
249 |         );
250 |         expect(scope).toBeInstanceOf(SubAgentScope);
251 |       });
252 | 
253 |       it('should skip interactivity check and warn for tools with required parameters', async () => {
254 |         const consoleWarnSpy = vi
255 |           .spyOn(console, 'warn')
256 |           .mockImplementation(() => {});
257 | 
258 |         const mockToolWithParams = {
259 |           name: 'tool_with_params',
260 |           schema: {
261 |             parametersJsonSchema: {
262 |               type: 'object',
263 |               properties: {
264 |                 path: { type: 'string' },
265 |               },
266 |               required: ['path'],
267 |             },
268 |           },
269 |           // build should not be called, but we mock it to be safe
270 |           build: vi.fn(),
271 |         };
272 | 
273 |         const { config } = await createMockConfig({
274 |           getTool: vi.fn().mockReturnValue(mockToolWithParams),
275 |           getAllTools: vi.fn().mockReturnValue([mockToolWithParams]),
276 |         });
277 | 
278 |         const toolConfig: ToolConfig = { tools: ['tool_with_params'] };
279 |         const options: SubAgentOptions = { toolConfig };
280 | 
281 |         // The creation should succeed without throwing
282 |         const scope = await SubAgentScope.create(
283 |           'test-agent',
284 |           config,
285 |           promptConfig,
286 |           defaultModelConfig,
287 |           defaultRunConfig,
288 |           options,
289 |         );
290 | 
291 |         expect(scope).toBeInstanceOf(SubAgentScope);
292 | 
293 |         // Check that the warning was logged
294 |         expect(consoleWarnSpy).toHaveBeenCalledWith(
295 |           'Cannot check tool "tool_with_params" for interactivity because it requires parameters. Assuming it is safe for non-interactive use.',
296 |         );
297 | 
298 |         // Ensure build was never called
299 |         expect(mockToolWithParams.build).not.toHaveBeenCalled();
300 | 
301 |         consoleWarnSpy.mockRestore();
302 |       });
303 |     });
304 | 
305 |     describe('runNonInteractive - Initialization and Prompting', () => {
306 |       it('should correctly template the system prompt and initialize GeminiChat', async () => {
307 |         const { config } = await createMockConfig();
308 | 
309 |         vi.mocked(GeminiChat).mockClear();
310 | 
311 |         const promptConfig: PromptConfig = {
312 |           systemPrompt: 'Hello ${name}, your task is ${task}.',
313 |         };
314 |         const context = new ContextState();
315 |         context.set('name', 'Agent');
316 |         context.set('task', 'Testing');
317 | 
318 |         // Model stops immediately
319 |         mockSendMessageStream.mockImplementation(createMockStream(['stop']));
320 | 
321 |         const scope = await SubAgentScope.create(
322 |           'test-agent',
323 |           config,
324 |           promptConfig,
325 |           defaultModelConfig,
326 |           defaultRunConfig,
327 |         );
328 | 
329 |         await scope.runNonInteractive(context);
330 | 
331 |         // Check if GeminiChat was initialized correctly by the subagent
332 |         expect(GeminiChat).toHaveBeenCalledTimes(1);
333 |         const callArgs = vi.mocked(GeminiChat).mock.calls[0];
334 | 
335 |         // Check Generation Config
336 |         const generationConfig = getGenerationConfigFromMock();
337 | 
338 |         // Check temperature override
339 |         expect(generationConfig.temperature).toBe(defaultModelConfig.temp);
340 |         expect(generationConfig.systemInstruction).toContain(
341 |           'Hello Agent, your task is Testing.',
342 |         );
343 |         expect(generationConfig.systemInstruction).toContain(
344 |           'Important Rules:',
345 |         );
346 | 
347 |         // Check History (should include environment context)
348 |         const history = callArgs[2];
349 |         expect(history).toEqual([
350 |           { role: 'user', parts: [{ text: 'Env Context' }] },
351 |           {
352 |             role: 'model',
353 |             parts: [{ text: 'Got it. Thanks for the context!' }],
354 |           },
355 |         ]);
356 |       });
357 | 
358 |       it('should include output instructions in the system prompt when outputs are defined', async () => {
359 |         const { config } = await createMockConfig();
360 |         vi.mocked(GeminiChat).mockClear();
361 | 
362 |         const promptConfig: PromptConfig = { systemPrompt: 'Do the task.' };
363 |         const outputConfig: OutputConfig = {
364 |           outputs: {
365 |             result1: 'The first result',
366 |           },
367 |         };
368 |         const context = new ContextState();
369 | 
370 |         // Model stops immediately
371 |         mockSendMessageStream.mockImplementation(createMockStream(['stop']));
372 | 
373 |         const scope = await SubAgentScope.create(
374 |           'test-agent',
375 |           config,
376 |           promptConfig,
377 |           defaultModelConfig,
378 |           defaultRunConfig,
379 |           { outputConfig },
380 |         );
381 | 
382 |         await scope.runNonInteractive(context);
383 | 
384 |         const generationConfig = getGenerationConfigFromMock();
385 |         const systemInstruction = generationConfig.systemInstruction as string;
386 | 
387 |         expect(systemInstruction).toContain('Do the task.');
388 |         expect(systemInstruction).toContain(
389 |           'you MUST emit the required output variables',
390 |         );
391 |         expect(systemInstruction).toContain(
392 |           "Use 'self.emitvalue' to emit the 'result1' key",
393 |         );
394 |       });
395 | 
396 |       it('should use initialMessages instead of systemPrompt if provided', async () => {
397 |         const { config } = await createMockConfig();
398 |         vi.mocked(GeminiChat).mockClear();
399 | 
400 |         const initialMessages: Content[] = [
401 |           { role: 'user', parts: [{ text: 'Hi' }] },
402 |         ];
403 |         const promptConfig: PromptConfig = { initialMessages };
404 |         const context = new ContextState();
405 | 
406 |         // Model stops immediately
407 |         mockSendMessageStream.mockImplementation(createMockStream(['stop']));
408 | 
409 |         const scope = await SubAgentScope.create(
410 |           'test-agent',
411 |           config,
412 |           promptConfig,
413 |           defaultModelConfig,
414 |           defaultRunConfig,
415 |         );
416 | 
417 |         await scope.runNonInteractive(context);
418 | 
419 |         const callArgs = vi.mocked(GeminiChat).mock.calls[0];
420 |         const generationConfig = getGenerationConfigFromMock();
421 |         const history = callArgs[2];
422 | 
423 |         expect(generationConfig.systemInstruction).toBeUndefined();
424 |         expect(history).toEqual([
425 |           { role: 'user', parts: [{ text: 'Env Context' }] },
426 |           {
427 |             role: 'model',
428 |             parts: [{ text: 'Got it. Thanks for the context!' }],
429 |           },
430 |           ...initialMessages,
431 |         ]);
432 |       });
433 | 
434 |       it('should throw an error if template variables are missing', async () => {
435 |         const { config } = await createMockConfig();
436 |         const promptConfig: PromptConfig = {
437 |           systemPrompt: 'Hello ${name}, you are missing ${missing}.',
438 |         };
439 |         const context = new ContextState();
440 |         context.set('name', 'Agent');
441 |         // 'missing' is not set
442 | 
443 |         const scope = await SubAgentScope.create(
444 |           'test-agent',
445 |           config,
446 |           promptConfig,
447 |           defaultModelConfig,
448 |           defaultRunConfig,
449 |         );
450 | 
451 |         // The error from templating causes the runNonInteractive to reject and the terminate_reason to be ERROR.
452 |         await expect(scope.runNonInteractive(context)).rejects.toThrow(
453 |           'Missing context values for the following keys: missing',
454 |         );
455 |         expect(scope.output.terminate_reason).toBe(SubagentTerminateMode.ERROR);
456 |       });
457 | 
458 |       it('should validate that systemPrompt and initialMessages are mutually exclusive', async () => {
459 |         const { config } = await createMockConfig();
460 |         const promptConfig: PromptConfig = {
461 |           systemPrompt: 'System',
462 |           initialMessages: [{ role: 'user', parts: [{ text: 'Hi' }] }],
463 |         };
464 |         const context = new ContextState();
465 | 
466 |         const agent = await SubAgentScope.create(
467 |           'TestAgent',
468 |           config,
469 |           promptConfig,
470 |           defaultModelConfig,
471 |           defaultRunConfig,
472 |         );
473 | 
474 |         await expect(agent.runNonInteractive(context)).rejects.toThrow(
475 |           'PromptConfig cannot have both `systemPrompt` and `initialMessages` defined.',
476 |         );
477 |         expect(agent.output.terminate_reason).toBe(SubagentTerminateMode.ERROR);
478 |       });
479 |     });
480 | 
481 |     describe('runNonInteractive - Execution and Tool Use', () => {
482 |       const promptConfig: PromptConfig = { systemPrompt: 'Execute task.' };
483 | 
484 |       it('should terminate with GOAL if no outputs are expected and model stops', async () => {
485 |         const { config } = await createMockConfig();
486 |         // Model stops immediately
487 |         mockSendMessageStream.mockImplementation(createMockStream(['stop']));
488 | 
489 |         const scope = await SubAgentScope.create(
490 |           'test-agent',
491 |           config,
492 |           promptConfig,
493 |           defaultModelConfig,
494 |           defaultRunConfig,
495 |           // No ToolConfig, No OutputConfig
496 |         );
497 | 
498 |         await scope.runNonInteractive(new ContextState());
499 | 
500 |         expect(scope.output.terminate_reason).toBe(SubagentTerminateMode.GOAL);
501 |         expect(scope.output.emitted_vars).toEqual({});
502 |         expect(mockSendMessageStream).toHaveBeenCalledTimes(1);
503 |         // Check the initial message
504 |         expect(mockSendMessageStream.mock.calls[0][1].message).toEqual([
505 |           { text: 'Get Started!' },
506 |         ]);
507 |       });
508 | 
509 |       it('should handle self.emitvalue and terminate with GOAL when outputs are met', async () => {
510 |         const { config } = await createMockConfig();
511 |         const outputConfig: OutputConfig = {
512 |           outputs: { result: 'The final result' },
513 |         };
514 | 
515 |         // Turn 1: Model responds with emitvalue call
516 |         // Turn 2: Model stops after receiving the tool response
517 |         mockSendMessageStream.mockImplementation(
518 |           createMockStream([
519 |             [
520 |               {
521 |                 name: 'self.emitvalue',
522 |                 args: {
523 |                   emit_variable_name: 'result',
524 |                   emit_variable_value: 'Success!',
525 |                 },
526 |               },
527 |             ],
528 |             'stop',
529 |           ]),
530 |         );
531 | 
532 |         const scope = await SubAgentScope.create(
533 |           'test-agent',
534 |           config,
535 |           promptConfig,
536 |           defaultModelConfig,
537 |           defaultRunConfig,
538 |           { outputConfig },
539 |         );
540 | 
541 |         await scope.runNonInteractive(new ContextState());
542 | 
543 |         expect(scope.output.terminate_reason).toBe(SubagentTerminateMode.GOAL);
544 |         expect(scope.output.emitted_vars).toEqual({ result: 'Success!' });
545 |         expect(mockSendMessageStream).toHaveBeenCalledTimes(1);
546 | 
547 |         // Check the tool response sent back in the second call
548 |         const secondCallArgs = mockSendMessageStream.mock.calls[0][1];
549 |         expect(secondCallArgs.message).toEqual([{ text: 'Get Started!' }]);
550 |       });
551 | 
552 |       it('should execute external tools and provide the response to the model', async () => {
553 |         const listFilesToolDef: FunctionDeclaration = {
554 |           name: 'list_files',
555 |           description: 'Lists files',
556 |           parameters: { type: Type.OBJECT, properties: {} },
557 |         };
558 | 
559 |         const { config } = await createMockConfig({
560 |           getFunctionDeclarationsFiltered: vi
561 |             .fn()
562 |             .mockReturnValue([listFilesToolDef]),
563 |           getTool: vi.fn().mockReturnValue(undefined),
564 |         });
565 |         const toolConfig: ToolConfig = { tools: ['list_files'] };
566 | 
567 |         // Turn 1: Model calls the external tool
568 |         // Turn 2: Model stops
569 |         mockSendMessageStream.mockImplementation(
570 |           createMockStream([
571 |             [
572 |               {
573 |                 id: 'call_1',
574 |                 name: 'list_files',
575 |                 args: { path: '.' },
576 |               },
577 |             ],
578 |             'stop',
579 |           ]),
580 |         );
581 | 
582 |         // Mock the tool execution result
583 |         vi.mocked(executeToolCall).mockResolvedValue({
584 |           callId: 'call_1',
585 |           responseParts: [{ text: 'file1.txt\nfile2.ts' }],
586 |           resultDisplay: 'Listed 2 files',
587 |           error: undefined,
588 |           errorType: undefined, // Or ToolErrorType.NONE if available and appropriate
589 |         });
590 | 
591 |         const scope = await SubAgentScope.create(
592 |           'test-agent',
593 |           config,
594 |           promptConfig,
595 |           defaultModelConfig,
596 |           defaultRunConfig,
597 |           { toolConfig },
598 |         );
599 | 
600 |         await scope.runNonInteractive(new ContextState());
601 | 
602 |         // Check tool execution
603 |         expect(executeToolCall).toHaveBeenCalledWith(
604 |           config,
605 |           expect.objectContaining({ name: 'list_files', args: { path: '.' } }),
606 |           expect.any(AbortSignal),
607 |         );
608 | 
609 |         // Check the response sent back to the model
610 |         const secondCallArgs = mockSendMessageStream.mock.calls[1][1];
611 |         expect(secondCallArgs.message).toEqual([
612 |           { text: 'file1.txt\nfile2.ts' },
613 |         ]);
614 | 
615 |         expect(scope.output.terminate_reason).toBe(SubagentTerminateMode.GOAL);
616 |       });
617 | 
618 |       it('should provide specific tool error responses to the model', async () => {
619 |         const { config } = await createMockConfig();
620 |         const toolConfig: ToolConfig = { tools: ['failing_tool'] };
621 | 
622 |         // Turn 1: Model calls the failing tool
623 |         // Turn 2: Model stops after receiving the error response
624 |         mockSendMessageStream.mockImplementation(
625 |           createMockStream([
626 |             [
627 |               {
628 |                 id: 'call_fail',
629 |                 name: 'failing_tool',
630 |                 args: {},
631 |               },
632 |             ],
633 |             'stop',
634 |           ]),
635 |         );
636 | 
637 |         // Mock the tool execution failure.
638 |         vi.mocked(executeToolCall).mockResolvedValue({
639 |           callId: 'call_fail',
640 |           responseParts: [{ text: 'ERROR: Tool failed catastrophically' }], // This should be sent to the model
641 |           resultDisplay: 'Tool failed catastrophically',
642 |           error: new Error('Failure'),
643 |           errorType: ToolErrorType.INVALID_TOOL_PARAMS,
644 |         });
645 | 
646 |         const scope = await SubAgentScope.create(
[TRUNCATED]
```

src/core/subagent.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { reportError } from '../utils/errorReporting.js';
8 | import { ToolRegistry } from '../tools/tool-registry.js';
9 | import type { AnyDeclarativeTool } from '../tools/tools.js';
10 | import type { Config } from '../config/config.js';
11 | import type { ToolCallRequestInfo } from './turn.js';
12 | import { executeToolCall } from './nonInteractiveToolExecutor.js';
13 | import { getEnvironmentContext } from '../utils/environmentContext.js';
14 | import type {
15 |   Content,
16 |   Part,
17 |   FunctionCall,
18 |   GenerateContentConfig,
19 |   FunctionDeclaration,
20 | } from '@google/genai';
21 | import { Type } from '@google/genai';
22 | import { GeminiChat, StreamEventType } from './geminiChat.js';
23 | 
24 | /**
25 |  * @fileoverview Defines the configuration interfaces for a subagent.
26 |  *
27 |  * These interfaces specify the structure for defining the subagent's prompt,
28 |  * the model parameters, and the execution settings.
29 |  */
30 | 
31 | /**
32 |  * Describes the possible termination modes for a subagent.
33 |  * This enum provides a clear indication of why a subagent's execution might have ended.
34 |  */
35 | export enum SubagentTerminateMode {
36 |   /**
37 |    * Indicates that the subagent's execution terminated due to an unrecoverable error.
38 |    */
39 |   ERROR = 'ERROR',
40 |   /**
41 |    * Indicates that the subagent's execution terminated because it exceeded the maximum allowed working time.
42 |    */
43 |   TIMEOUT = 'TIMEOUT',
44 |   /**
45 |    * Indicates that the subagent's execution successfully completed all its defined goals.
46 |    */
47 |   GOAL = 'GOAL',
48 |   /**
49 |    * Indicates that the subagent's execution terminated because it exceeded the maximum number of turns.
50 |    */
51 |   MAX_TURNS = 'MAX_TURNS',
52 | }
53 | 
54 | /**
55 |  * Represents the output structure of a subagent's execution.
56 |  * This interface defines the data that a subagent will return upon completion,
57 |  * including any emitted variables and the reason for its termination.
58 |  */
59 | export interface OutputObject {
60 |   /**
61 |    * A record of key-value pairs representing variables emitted by the subagent
62 |    * during its execution. These variables can be used by the calling agent.
63 |    */
64 |   emitted_vars: Record<string, string>;
65 |   /**
66 |    * The reason for the subagent's termination, indicating whether it completed
67 |    * successfully, timed out, or encountered an error.
68 |    */
69 |   terminate_reason: SubagentTerminateMode;
70 | }
71 | 
72 | /**
73 |  * Configures the initial prompt for the subagent.
74 |  */
75 | export interface PromptConfig {
76 |   /**
77 |    * A single system prompt string that defines the subagent's persona and instructions.
78 |    * Note: You should use either `systemPrompt` or `initialMessages`, but not both.
79 |    */
80 |   systemPrompt?: string;
81 | 
82 |   /**
83 |    * An array of user/model content pairs to seed the chat history for few-shot prompting.
84 |    * Note: You should use either `systemPrompt` or `initialMessages`, but not both.
85 |    */
86 |   initialMessages?: Content[];
87 | }
88 | 
89 | /**
90 |  * Configures the tools available to the subagent during its execution.
91 |  */
92 | export interface ToolConfig {
93 |   /**
94 |    * A list of tool names (from the tool registry), full function declarations,
95 |    * or BaseTool instances that the subagent is permitted to use.
96 |    */
97 |   tools: Array<string | FunctionDeclaration | AnyDeclarativeTool>;
98 | }
99 | 
100 | /**
101 |  * Configures the expected outputs for the subagent.
102 |  */
103 | export interface OutputConfig {
104 |   /**
105 |    * A record describing the variables the subagent is expected to emit.
106 |    * The subagent will be prompted to generate these values before terminating.
107 |    */
108 |   outputs: Record<string, string>;
109 | }
110 | 
111 | /**
112 |  * Configures the generative model parameters for the subagent.
113 |  * This interface specifies the model to be used and its associated generation settings,
114 |  * such as temperature and top-p values, which influence the creativity and diversity of the model's output.
115 |  */
116 | export interface ModelConfig {
117 |   /**
118 |    * The name or identifier of the model to be used (e.g., 'gemini-2.5-pro').
119 |    *
120 |    * TODO: In the future, this needs to support 'auto' or some other string to support routing use cases.
121 |    */
122 |   model: string;
123 |   /**
124 |    * The temperature for the model's sampling process.
125 |    */
126 |   temp: number;
127 |   /**
128 |    * The top-p value for nucleus sampling.
129 |    */
130 |   top_p: number;
131 | }
132 | 
133 | /**
134 |  * Configures the execution environment and constraints for the subagent.
135 |  * This interface defines parameters that control the subagent's runtime behavior,
136 |  * such as maximum execution time, to prevent infinite loops or excessive resource consumption.
137 |  *
138 |  * TODO: Consider adding max_tokens as a form of budgeting.
139 |  */
140 | export interface RunConfig {
141 |   /** The maximum execution time for the subagent in minutes. */
142 |   max_time_minutes: number;
143 |   /**
144 |    * The maximum number of conversational turns (a user message + model response)
145 |    * before the execution is terminated. Helps prevent infinite loops.
146 |    */
147 |   max_turns?: number;
148 | }
149 | 
150 | export interface SubAgentOptions {
151 |   toolConfig?: ToolConfig;
152 |   outputConfig?: OutputConfig;
153 |   onMessage?: (message: string) => void;
154 | }
155 | 
156 | /**
157 |  * Manages the runtime context state for the subagent.
158 |  * This class provides a mechanism to store and retrieve key-value pairs
159 |  * that represent the dynamic state and variables accessible to the subagent
160 |  * during its execution.
161 |  */
162 | export class ContextState {
163 |   private state: Record<string, unknown> = {};
164 | 
165 |   /**
166 |    * Retrieves a value from the context state.
167 |    *
168 |    * @param key - The key of the value to retrieve.
169 |    * @returns The value associated with the key, or undefined if the key is not found.
170 |    */
171 |   get(key: string): unknown {
172 |     return this.state[key];
173 |   }
174 | 
175 |   /**
176 |    * Sets a value in the context state.
177 |    *
178 |    * @param key - The key to set the value under.
179 |    * @param value - The value to set.
180 |    */
181 |   set(key: string, value: unknown): void {
182 |     this.state[key] = value;
183 |   }
184 | 
185 |   /**
186 |    * Retrieves all keys in the context state.
187 |    *
188 |    * @returns An array of all keys in the context state.
189 |    */
190 |   get_keys(): string[] {
191 |     return Object.keys(this.state);
192 |   }
193 | }
194 | 
195 | /**
196 |  * Replaces `${...}` placeholders in a template string with values from a context.
197 |  *
198 |  * This function identifies all placeholders in the format `${key}`, validates that
199 |  * each key exists in the provided `ContextState`, and then performs the substitution.
200 |  *
201 |  * @param template The template string containing placeholders.
202 |  * @param context The `ContextState` object providing placeholder values.
203 |  * @returns The populated string with all placeholders replaced.
204 |  * @throws {Error} if any placeholder key is not found in the context.
205 |  */
206 | function templateString(template: string, context: ContextState): string {
207 |   const placeholderRegex = /\$\{(\w+)\}/g;
208 | 
209 |   // First, find all unique keys required by the template.
210 |   const requiredKeys = new Set(
211 |     Array.from(template.matchAll(placeholderRegex), (match) => match[1]),
212 |   );
213 | 
214 |   // Check if all required keys exist in the context.
215 |   const contextKeys = new Set(context.get_keys());
216 |   const missingKeys = Array.from(requiredKeys).filter(
217 |     (key) => !contextKeys.has(key),
218 |   );
219 | 
220 |   if (missingKeys.length > 0) {
221 |     throw new Error(
222 |       `Missing context values for the following keys: ${missingKeys.join(
223 |         ', ',
224 |       )}`,
225 |     );
226 |   }
227 | 
228 |   // Perform the replacement using a replacer function.
229 |   return template.replace(placeholderRegex, (_match, key) =>
230 |     String(context.get(key)),
231 |   );
232 | }
233 | 
234 | /**
235 |  * Represents the scope and execution environment for a subagent.
236 |  * This class orchestrates the subagent's lifecycle, managing its chat interactions,
237 |  * runtime context, and the collection of its outputs.
238 |  */
239 | export class SubAgentScope {
240 |   output: OutputObject = {
241 |     terminate_reason: SubagentTerminateMode.ERROR,
242 |     emitted_vars: {},
243 |   };
244 |   private readonly subagentId: string;
245 |   private readonly toolConfig?: ToolConfig;
246 |   private readonly outputConfig?: OutputConfig;
247 |   private readonly onMessage?: (message: string) => void;
248 |   private readonly toolRegistry: ToolRegistry;
249 | 
250 |   /**
251 |    * Constructs a new SubAgentScope instance.
252 |    * @param name - The name for the subagent, used for logging and identification.
253 |    * @param runtimeContext - The shared runtime configuration and services.
254 |    * @param promptConfig - Configuration for the subagent's prompt and behavior.
255 |    * @param modelConfig - Configuration for the generative model parameters.
256 |    * @param runConfig - Configuration for the subagent's execution environment.
257 |    * @param options - Optional configurations for the subagent.
258 |    */
259 |   private constructor(
260 |     readonly name: string,
261 |     readonly runtimeContext: Config,
262 |     private readonly promptConfig: PromptConfig,
263 |     private readonly modelConfig: ModelConfig,
264 |     private readonly runConfig: RunConfig,
265 |     toolRegistry: ToolRegistry,
266 |     options: SubAgentOptions = {},
267 |   ) {
268 |     const randomPart = Math.random().toString(36).slice(2, 8);
269 |     this.subagentId = `${this.name}-${randomPart}`;
270 |     this.toolConfig = options.toolConfig;
271 |     this.outputConfig = options.outputConfig;
272 |     this.onMessage = options.onMessage;
273 |     this.toolRegistry = toolRegistry;
274 |   }
275 | 
276 |   /**
277 |    * Creates and validates a new SubAgentScope instance.
278 |    * This factory method ensures that all tools provided in the prompt configuration
279 |    * are valid for non-interactive use before creating the subagent instance.
280 |    * @param name - The name of the subagent.
281 |    * @param runtimeContext - The shared runtime configuration and services.
282 |    * @param promptConfig - Configuration for the subagent's prompt and behavior.
283 |    * @param modelConfig - Configuration for the generative model parameters.
284 |    * @param runConfig - Configuration for the subagent's execution environment.
285 |    * @param options - Optional configurations for the subagent.
286 |    * @returns A promise that resolves to a valid SubAgentScope instance.
287 |    * @throws {Error} If any tool requires user confirmation.
288 |    */
289 |   static async create(
290 |     name: string,
291 |     runtimeContext: Config,
292 |     promptConfig: PromptConfig,
293 |     modelConfig: ModelConfig,
294 |     runConfig: RunConfig,
295 |     options: SubAgentOptions = {},
296 |   ): Promise<SubAgentScope> {
297 |     const subagentToolRegistry = new ToolRegistry(runtimeContext);
298 |     if (options.toolConfig) {
299 |       for (const tool of options.toolConfig.tools) {
300 |         if (typeof tool === 'string') {
301 |           const toolFromRegistry = (
302 |             await runtimeContext.getToolRegistry()
303 |           ).getTool(tool);
304 |           if (toolFromRegistry) {
305 |             subagentToolRegistry.registerTool(toolFromRegistry);
306 |           }
307 |         } else if (
308 |           typeof tool === 'object' &&
309 |           'name' in tool &&
310 |           'build' in tool
311 |         ) {
312 |           subagentToolRegistry.registerTool(tool);
313 |         } else {
314 |           // This is a FunctionDeclaration, which we can't add to the registry.
315 |           // We'll rely on the validation below to catch any issues.
316 |         }
317 |       }
318 | 
319 |       for (const tool of subagentToolRegistry.getAllTools()) {
320 |         const schema = tool.schema.parametersJsonSchema as {
321 |           required?: string[];
322 |         };
323 |         const requiredParams = schema?.required ?? [];
324 |         if (requiredParams.length > 0) {
325 |           // This check is imperfect. A tool might require parameters but still
326 |           // be interactive (e.g., `delete_file(path)`). However, we cannot
327 |           // build a generic invocation without knowing what dummy parameters
328 |           // to provide. Crashing here because `build({})` fails is worse
329 |           // than allowing a potential hang later if an interactive tool is
330 |           // used. This is a best-effort check.
331 |           console.warn(
332 |             `Cannot check tool "${tool.name}" for interactivity because it requires parameters. Assuming it is safe for non-interactive use.`,
333 |           );
334 |           continue;
335 |         }
336 | 
337 |         const invocation = tool.build({});
338 |         const confirmationDetails = await invocation.shouldConfirmExecute(
339 |           new AbortController().signal,
340 |         );
341 |         if (confirmationDetails) {
342 |           throw new Error(
343 |             `Tool "${tool.name}" requires user confirmation and cannot be used in a non-interactive subagent.`,
344 |           );
345 |         }
346 |       }
347 |     }
348 | 
349 |     return new SubAgentScope(
350 |       name,
351 |       runtimeContext,
352 |       promptConfig,
353 |       modelConfig,
354 |       runConfig,
355 |       subagentToolRegistry,
356 |       options,
357 |     );
358 |   }
359 | 
360 |   /**
361 |    * Runs the subagent in a non-interactive mode.
362 |    * This method orchestrates the subagent's execution loop, including prompt templating,
363 |    * tool execution, and termination conditions.
364 |    * @param {ContextState} context - The current context state containing variables for prompt templating.
365 |    * @returns {Promise<void>} A promise that resolves when the subagent has completed its execution.
366 |    */
367 |   async runNonInteractive(context: ContextState): Promise<void> {
368 |     const startTime = Date.now();
369 |     let turnCounter = 0;
370 |     try {
371 |       const chat = await this.createChatObject(context);
372 | 
373 |       if (!chat) {
374 |         this.output.terminate_reason = SubagentTerminateMode.ERROR;
375 |         return;
376 |       }
377 | 
378 |       const abortController = new AbortController();
379 | 
380 |       // Prepare the list of tools available to the subagent.
381 |       const toolsList: FunctionDeclaration[] = [];
382 |       if (this.toolConfig) {
383 |         const toolsToLoad: string[] = [];
384 |         for (const tool of this.toolConfig.tools) {
385 |           if (typeof tool === 'string') {
386 |             toolsToLoad.push(tool);
387 |           } else if (typeof tool === 'object' && 'schema' in tool) {
388 |             // This is a tool instance with a schema property
389 |             toolsList.push(tool.schema);
390 |           } else {
391 |             // This is a raw FunctionDeclaration
392 |             toolsList.push(tool);
393 |           }
394 |         }
395 |         toolsList.push(
396 |           ...this.toolRegistry.getFunctionDeclarationsFiltered(toolsToLoad),
397 |         );
398 |       }
399 |       // Add local scope functions if outputs are expected.
400 |       if (this.outputConfig && this.outputConfig.outputs) {
401 |         toolsList.push(...this.getScopeLocalFuncDefs());
402 |       }
403 | 
404 |       let currentMessages: Content[] = [
405 |         { role: 'user', parts: [{ text: 'Get Started!' }] },
406 |       ];
407 | 
408 |       while (true) {
409 |         // Check termination conditions.
410 |         if (
411 |           this.runConfig.max_turns &&
412 |           turnCounter >= this.runConfig.max_turns
413 |         ) {
414 |           this.output.terminate_reason = SubagentTerminateMode.MAX_TURNS;
415 |           break;
416 |         }
417 |         let durationMin = (Date.now() - startTime) / (1000 * 60);
418 |         if (durationMin >= this.runConfig.max_time_minutes) {
419 |           this.output.terminate_reason = SubagentTerminateMode.TIMEOUT;
420 |           break;
421 |         }
422 | 
423 |         const promptId = `${this.runtimeContext.getSessionId()}#${this.subagentId}#${turnCounter++}`;
424 |         const messageParams = {
425 |           message: currentMessages[0]?.parts || [],
426 |           config: {
427 |             abortSignal: abortController.signal,
428 |             tools: [{ functionDeclarations: toolsList }],
429 |           },
430 |         };
431 | 
432 |         const responseStream = await chat.sendMessageStream(
433 |           this.modelConfig.model,
434 |           messageParams,
435 |           promptId,
436 |         );
437 | 
438 |         const functionCalls: FunctionCall[] = [];
439 |         let textResponse = '';
440 |         for await (const resp of responseStream) {
441 |           if (abortController.signal.aborted) return;
442 |           if (resp.type === StreamEventType.CHUNK && resp.value.functionCalls) {
443 |             functionCalls.push(...resp.value.functionCalls);
444 |           }
445 |           if (resp.type === StreamEventType.CHUNK && resp.value.text) {
446 |             textResponse += resp.value.text;
447 |           }
448 |         }
449 | 
450 |         if (this.onMessage && textResponse) {
451 |           this.onMessage(textResponse);
452 |         }
453 | 
454 |         durationMin = (Date.now() - startTime) / (1000 * 60);
455 |         if (durationMin >= this.runConfig.max_time_minutes) {
456 |           this.output.terminate_reason = SubagentTerminateMode.TIMEOUT;
457 |           break;
458 |         }
459 | 
460 |         if (functionCalls.length > 0) {
461 |           currentMessages = await this.processFunctionCalls(
462 |             functionCalls,
463 |             abortController,
464 |             promptId,
465 |           );
466 |         }
467 | 
468 |         // Check for goal completion after processing function calls,
469 |         // as `self.emitvalue` might have completed the requirements.
470 |         if (
471 |           this.outputConfig &&
472 |           Object.keys(this.outputConfig.outputs).length > 0
473 |         ) {
474 |           const remainingVars = Object.keys(this.outputConfig.outputs).filter(
475 |             (key) => !(key in this.output.emitted_vars),
476 |           );
477 | 
478 |           if (remainingVars.length === 0) {
479 |             this.output.terminate_reason = SubagentTerminateMode.GOAL;
480 |             break;
481 |           }
482 |         }
483 | 
484 |         if (functionCalls.length === 0) {
485 |           // Model stopped calling tools. Check if goal is met.
486 |           if (
487 |             !this.outputConfig ||
488 |             Object.keys(this.outputConfig.outputs).length === 0
489 |           ) {
490 |             this.output.terminate_reason = SubagentTerminateMode.GOAL;
491 |             break;
492 |           }
493 | 
494 |           const remainingVars = Object.keys(this.outputConfig.outputs).filter(
495 |             (key) => !(key in this.output.emitted_vars),
496 |           );
497 | 
498 |           if (remainingVars.length === 0) {
499 |             this.output.terminate_reason = SubagentTerminateMode.GOAL;
500 |             break;
501 |           }
502 | 
503 |           const nudgeMessage = `You have stopped calling tools but have not emitted the following required variables: ${remainingVars.join(
504 |             ', ',
505 |           )}. Please use the 'self.emitvalue' tool to emit them now, or continue working if necessary.`;
506 | 
507 |           console.debug(nudgeMessage);
508 | 
509 |           currentMessages = [
510 |             {
511 |               role: 'user',
512 |               parts: [{ text: nudgeMessage }],
513 |             },
514 |           ];
515 |         }
516 |       }
517 |     } catch (error) {
518 |       console.error('Error during subagent execution:', error);
519 |       this.output.terminate_reason = SubagentTerminateMode.ERROR;
520 |       throw error;
521 |     }
522 |   }
523 | 
524 |   /**
525 |    * Processes a list of function calls, executing each one and collecting their responses.
526 |    * This method iterates through the provided function calls, executes them using the
527 |    * `executeToolCall` function (or handles `self.emitvalue` internally), and aggregates
528 |    * their results. It also manages error reporting for failed tool executions.
529 |    * @param {FunctionCall[]} functionCalls - An array of `FunctionCall` objects to process.
530 |    * @param {ToolRegistry} toolRegistry - The tool registry to look up and execute tools.
531 |    * @param {AbortController} abortController - An `AbortController` to signal cancellation of tool executions.
532 |    * @returns {Promise<Content[]>} A promise that resolves to an array of `Content` parts representing the tool responses,
533 |    *          which are then used to update the chat history.
534 |    */
535 |   private async processFunctionCalls(
536 |     functionCalls: FunctionCall[],
537 |     abortController: AbortController,
538 |     promptId: string,
539 |   ): Promise<Content[]> {
540 |     const toolResponseParts: Part[] = [];
541 | 
542 |     for (const functionCall of functionCalls) {
543 |       if (this.onMessage) {
544 |         const args = JSON.stringify(functionCall.args ?? {});
545 |         // Truncate arguments
[TRUNCATED]
```

src/core/turn.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import type {
9 |   ServerGeminiToolCallRequestEvent,
10 |   ServerGeminiErrorEvent,
11 | } from './turn.js';
12 | import { Turn, GeminiEventType } from './turn.js';
13 | import type { GenerateContentResponse, Part, Content } from '@google/genai';
14 | import { reportError } from '../utils/errorReporting.js';
15 | import type { GeminiChat } from './geminiChat.js';
16 | import { InvalidStreamError, StreamEventType } from './geminiChat.js';
17 | 
18 | const mockSendMessageStream = vi.fn();
19 | const mockGetHistory = vi.fn();
20 | const mockMaybeIncludeSchemaDepthContext = vi.fn();
21 | 
22 | vi.mock('@google/genai', async (importOriginal) => {
23 |   const actual = await importOriginal<typeof import('@google/genai')>();
24 |   const MockChat = vi.fn().mockImplementation(() => ({
25 |     sendMessageStream: mockSendMessageStream,
26 |     getHistory: mockGetHistory,
27 |     maybeIncludeSchemaDepthContext: mockMaybeIncludeSchemaDepthContext,
28 |   }));
29 |   return {
30 |     ...actual,
31 |     Chat: MockChat,
32 |   };
33 | });
34 | 
35 | vi.mock('../utils/errorReporting', () => ({
36 |   reportError: vi.fn(),
37 | }));
38 | 
39 | // Use the actual implementation from partUtils now that it's provided.
40 | vi.mock('../utils/generateContentResponseUtilities', () => ({
41 |   getResponseText: (resp: GenerateContentResponse) =>
42 |     resp.candidates?.[0]?.content?.parts?.map((part) => part.text).join('') ||
43 |     undefined,
44 | }));
45 | 
46 | describe('Turn', () => {
47 |   let turn: Turn;
48 |   // Define a type for the mocked Chat instance for clarity
49 |   type MockedChatInstance = {
50 |     sendMessageStream: typeof mockSendMessageStream;
51 |     getHistory: typeof mockGetHistory;
52 |     maybeIncludeSchemaDepthContext: typeof mockMaybeIncludeSchemaDepthContext;
53 |   };
54 |   let mockChatInstance: MockedChatInstance;
55 | 
56 |   beforeEach(() => {
57 |     vi.resetAllMocks();
58 |     mockChatInstance = {
59 |       sendMessageStream: mockSendMessageStream,
60 |       getHistory: mockGetHistory,
61 |       maybeIncludeSchemaDepthContext: mockMaybeIncludeSchemaDepthContext,
62 |     };
63 |     turn = new Turn(mockChatInstance as unknown as GeminiChat, 'prompt-id-1');
64 |     mockGetHistory.mockReturnValue([]);
65 |     mockSendMessageStream.mockResolvedValue((async function* () {})());
66 |   });
67 | 
68 |   afterEach(() => {
69 |     vi.restoreAllMocks();
70 |   });
71 | 
72 |   describe('constructor', () => {
73 |     it('should initialize pendingToolCalls and debugResponses', () => {
74 |       expect(turn.pendingToolCalls).toEqual([]);
75 |       expect(turn.getDebugResponses()).toEqual([]);
76 |     });
77 |   });
78 | 
79 |   describe('run', () => {
80 |     it('should yield content events for text parts', async () => {
81 |       const mockResponseStream = (async function* () {
82 |         yield {
83 |           type: StreamEventType.CHUNK,
84 |           value: {
85 |             candidates: [{ content: { parts: [{ text: 'Hello' }] } }],
86 |           } as GenerateContentResponse,
87 |         };
88 |         yield {
89 |           type: StreamEventType.CHUNK,
90 |           value: {
91 |             candidates: [{ content: { parts: [{ text: ' world' }] } }],
92 |           } as GenerateContentResponse,
93 |         };
94 |       })();
95 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
96 | 
97 |       const events = [];
98 |       const reqParts: Part[] = [{ text: 'Hi' }];
99 |       for await (const event of turn.run(
100 |         'test-model',
101 |         reqParts,
102 |         new AbortController().signal,
103 |       )) {
104 |         events.push(event);
105 |       }
106 | 
107 |       expect(mockSendMessageStream).toHaveBeenCalledWith(
108 |         'test-model',
109 |         {
110 |           message: reqParts,
111 |           config: { abortSignal: expect.any(AbortSignal) },
112 |         },
113 |         'prompt-id-1',
114 |       );
115 | 
116 |       expect(events).toEqual([
117 |         { type: GeminiEventType.Content, value: 'Hello' },
118 |         { type: GeminiEventType.Content, value: ' world' },
119 |       ]);
120 |       expect(turn.getDebugResponses().length).toBe(2);
121 |     });
122 | 
123 |     it('should yield tool_call_request events for function calls', async () => {
124 |       const mockResponseStream = (async function* () {
125 |         yield {
126 |           type: StreamEventType.CHUNK,
127 |           value: {
128 |             functionCalls: [
129 |               {
130 |                 id: 'fc1',
131 |                 name: 'tool1',
132 |                 args: { arg1: 'val1' },
133 |                 isClientInitiated: false,
134 |               },
135 |               {
136 |                 name: 'tool2',
137 |                 args: { arg2: 'val2' },
138 |                 isClientInitiated: false,
139 |               }, // No ID
140 |             ],
141 |           } as unknown as GenerateContentResponse,
142 |         };
143 |       })();
144 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
145 | 
146 |       const events = [];
147 |       const reqParts: Part[] = [{ text: 'Use tools' }];
148 |       for await (const event of turn.run(
149 |         'test-model',
150 |         reqParts,
151 |         new AbortController().signal,
152 |       )) {
153 |         events.push(event);
154 |       }
155 | 
156 |       expect(events.length).toBe(2);
157 |       const event1 = events[0] as ServerGeminiToolCallRequestEvent;
158 |       expect(event1.type).toBe(GeminiEventType.ToolCallRequest);
159 |       expect(event1.value).toEqual(
160 |         expect.objectContaining({
161 |           callId: 'fc1',
162 |           name: 'tool1',
163 |           args: { arg1: 'val1' },
164 |           isClientInitiated: false,
165 |         }),
166 |       );
167 |       expect(turn.pendingToolCalls[0]).toEqual(event1.value);
168 | 
169 |       const event2 = events[1] as ServerGeminiToolCallRequestEvent;
170 |       expect(event2.type).toBe(GeminiEventType.ToolCallRequest);
171 |       expect(event2.value).toEqual(
172 |         expect.objectContaining({
173 |           name: 'tool2',
174 |           args: { arg2: 'val2' },
175 |           isClientInitiated: false,
176 |         }),
177 |       );
178 |       expect(event2.value.callId).toEqual(
179 |         expect.stringMatching(/^tool2-\d{13}-\w{10,}$/),
180 |       );
181 |       expect(turn.pendingToolCalls[1]).toEqual(event2.value);
182 |       expect(turn.getDebugResponses().length).toBe(1);
183 |     });
184 | 
185 |     it('should yield UserCancelled event if signal is aborted', async () => {
186 |       const abortController = new AbortController();
187 |       const mockResponseStream = (async function* () {
188 |         yield {
189 |           type: StreamEventType.CHUNK,
190 |           value: {
191 |             candidates: [{ content: { parts: [{ text: 'First part' }] } }],
192 |           } as GenerateContentResponse,
193 |         };
194 |         abortController.abort();
195 |         yield {
196 |           type: StreamEventType.CHUNK,
197 |           value: {
198 |             candidates: [
199 |               {
200 |                 content: {
201 |                   parts: [{ text: 'Second part - should not be processed' }],
202 |                 },
203 |               },
204 |             ],
205 |           } as GenerateContentResponse,
206 |         };
207 |       })();
208 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
209 | 
210 |       const events = [];
211 |       const reqParts: Part[] = [{ text: 'Test abort' }];
212 |       for await (const event of turn.run(
213 |         'test-model',
214 |         reqParts,
215 |         abortController.signal,
216 |       )) {
217 |         events.push(event);
218 |       }
219 |       expect(events).toEqual([
220 |         { type: GeminiEventType.Content, value: 'First part' },
221 |         { type: GeminiEventType.UserCancelled },
222 |       ]);
223 |       expect(turn.getDebugResponses().length).toBe(1);
224 |     });
225 | 
226 |     it('should yield InvalidStream event if sendMessageStream throws InvalidStreamError', async () => {
227 |       const error = new InvalidStreamError(
228 |         'Test invalid stream',
229 |         'NO_FINISH_REASON',
230 |       );
231 |       mockSendMessageStream.mockRejectedValue(error);
232 |       const reqParts: Part[] = [{ text: 'Trigger invalid stream' }];
233 | 
234 |       const events = [];
235 |       for await (const event of turn.run(
236 |         'test-model',
237 |         reqParts,
238 |         new AbortController().signal,
239 |       )) {
240 |         events.push(event);
241 |       }
242 | 
243 |       expect(events).toEqual([{ type: GeminiEventType.InvalidStream }]);
244 |       expect(turn.getDebugResponses().length).toBe(0);
245 |       expect(reportError).not.toHaveBeenCalled(); // Should not report as error
246 |     });
247 | 
248 |     it('should yield Error event and report if sendMessageStream throws', async () => {
249 |       const error = new Error('API Error');
250 |       mockSendMessageStream.mockRejectedValue(error);
251 |       const reqParts: Part[] = [{ text: 'Trigger error' }];
252 |       const historyContent: Content[] = [
253 |         { role: 'model', parts: [{ text: 'Previous history' }] },
254 |       ];
255 |       mockGetHistory.mockReturnValue(historyContent);
256 |       mockMaybeIncludeSchemaDepthContext.mockResolvedValue(undefined);
257 |       const events = [];
258 |       for await (const event of turn.run(
259 |         'test-model',
260 |         reqParts,
261 |         new AbortController().signal,
262 |       )) {
263 |         events.push(event);
264 |       }
265 | 
266 |       expect(events.length).toBe(1);
267 |       const errorEvent = events[0] as ServerGeminiErrorEvent;
268 |       expect(errorEvent.type).toBe(GeminiEventType.Error);
269 |       expect(errorEvent.value).toEqual({
270 |         error: { message: 'API Error', status: undefined },
271 |       });
272 |       expect(turn.getDebugResponses().length).toBe(0);
273 |       expect(reportError).toHaveBeenCalledWith(
274 |         error,
275 |         'Error when talking to Gemini API',
276 |         [...historyContent, { role: 'user', parts: reqParts }],
277 |         'Turn.run-sendMessageStream',
278 |       );
279 |     });
280 | 
281 |     it('should handle function calls with undefined name or args', async () => {
282 |       const mockResponseStream = (async function* () {
283 |         yield {
284 |           type: StreamEventType.CHUNK,
285 |           value: {
286 |             candidates: [],
287 |             functionCalls: [
288 |               // Add `id` back to the mock to match what the code expects
289 |               { id: 'fc1', name: undefined, args: { arg1: 'val1' } },
290 |               { id: 'fc2', name: 'tool2', args: undefined },
291 |               { id: 'fc3', name: undefined, args: undefined },
292 |             ],
293 |           },
294 |         };
295 |       })();
296 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
297 | 
298 |       const events = [];
299 |       for await (const event of turn.run(
300 |         'test-model',
301 |         [{ text: 'Test undefined tool parts' }],
302 |         new AbortController().signal,
303 |       )) {
304 |         events.push(event);
305 |       }
306 | 
307 |       expect(events.length).toBe(3);
308 | 
309 |       // Assertions for each specific tool call event
310 |       const event1 = events[0] as ServerGeminiToolCallRequestEvent;
311 |       expect(event1.value).toMatchObject({
312 |         callId: 'fc1',
313 |         name: 'undefined_tool_name',
314 |         args: { arg1: 'val1' },
315 |       });
316 | 
317 |       const event2 = events[1] as ServerGeminiToolCallRequestEvent;
318 |       expect(event2.value).toMatchObject({
319 |         callId: 'fc2',
320 |         name: 'tool2',
321 |         args: {},
322 |       });
323 | 
324 |       const event3 = events[2] as ServerGeminiToolCallRequestEvent;
325 |       expect(event3.value).toMatchObject({
326 |         callId: 'fc3',
327 |         name: 'undefined_tool_name',
328 |         args: {},
329 |       });
330 |     });
331 | 
332 |     it('should yield finished event when response has finish reason', async () => {
333 |       const mockResponseStream = (async function* () {
334 |         yield {
335 |           type: StreamEventType.CHUNK,
336 |           value: {
337 |             candidates: [
338 |               {
339 |                 content: { parts: [{ text: 'Partial response' }] },
340 |                 finishReason: 'STOP',
341 |               },
342 |             ],
343 |             usageMetadata: {
344 |               promptTokenCount: 17,
345 |               candidatesTokenCount: 50,
346 |               cachedContentTokenCount: 10,
347 |               thoughtsTokenCount: 5,
348 |               toolUsePromptTokenCount: 2,
349 |             },
350 |           } as GenerateContentResponse,
351 |         };
352 |       })();
353 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
354 | 
355 |       const events = [];
356 |       for await (const event of turn.run(
357 |         'test-model',
358 |         [{ text: 'Test finish reason' }],
359 |         new AbortController().signal,
360 |       )) {
361 |         events.push(event);
362 |       }
363 | 
364 |       expect(events).toEqual([
365 |         { type: GeminiEventType.Content, value: 'Partial response' },
366 |         {
367 |           type: GeminiEventType.Finished,
368 |           value: {
369 |             reason: 'STOP',
370 |             usageMetadata: {
371 |               promptTokenCount: 17,
372 |               candidatesTokenCount: 50,
373 |               cachedContentTokenCount: 10,
374 |               thoughtsTokenCount: 5,
375 |               toolUsePromptTokenCount: 2,
376 |             },
377 |           },
378 |         },
379 |       ]);
380 |     });
381 | 
382 |     it('should yield finished event for MAX_TOKENS finish reason', async () => {
383 |       const mockResponseStream = (async function* () {
384 |         yield {
385 |           type: StreamEventType.CHUNK,
386 |           value: {
387 |             candidates: [
388 |               {
389 |                 content: {
390 |                   parts: [
391 |                     { text: 'This is a long response that was cut off...' },
392 |                   ],
393 |                 },
394 |                 finishReason: 'MAX_TOKENS',
395 |               },
396 |             ],
397 |           },
398 |         };
399 |       })();
400 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
401 | 
402 |       const events = [];
403 |       const reqParts: Part[] = [{ text: 'Generate long text' }];
404 |       for await (const event of turn.run(
405 |         'test-model',
406 |         reqParts,
407 |         new AbortController().signal,
408 |       )) {
409 |         events.push(event);
410 |       }
411 | 
412 |       expect(events).toEqual([
413 |         {
414 |           type: GeminiEventType.Content,
415 |           value: 'This is a long response that was cut off...',
416 |         },
417 |         {
418 |           type: GeminiEventType.Finished,
419 |           value: { reason: 'MAX_TOKENS', usageMetadata: undefined },
420 |         },
421 |       ]);
422 |     });
423 | 
424 |     it('should yield finished event for SAFETY finish reason', async () => {
425 |       const mockResponseStream = (async function* () {
426 |         yield {
427 |           type: StreamEventType.CHUNK,
428 |           value: {
429 |             candidates: [
430 |               {
431 |                 content: { parts: [{ text: 'Content blocked' }] },
432 |                 finishReason: 'SAFETY',
433 |               },
434 |             ],
435 |           },
436 |         };
437 |       })();
438 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
439 | 
440 |       const events = [];
441 |       const reqParts: Part[] = [{ text: 'Test safety' }];
442 |       for await (const event of turn.run(
443 |         'test-model',
444 |         reqParts,
445 |         new AbortController().signal,
446 |       )) {
447 |         events.push(event);
448 |       }
449 | 
450 |       expect(events).toEqual([
451 |         { type: GeminiEventType.Content, value: 'Content blocked' },
452 |         {
453 |           type: GeminiEventType.Finished,
454 |           value: { reason: 'SAFETY', usageMetadata: undefined },
455 |         },
456 |       ]);
457 |     });
458 | 
459 |     it('should yield finished event with undefined reason when there is no finish reason', async () => {
460 |       const mockResponseStream = (async function* () {
461 |         yield {
462 |           type: StreamEventType.CHUNK,
463 |           value: {
464 |             candidates: [
465 |               {
466 |                 content: {
467 |                   parts: [{ text: 'Response without finish reason' }],
468 |                 },
469 |                 // No finishReason property
470 |               },
471 |             ],
472 |           },
473 |         };
474 |       })();
475 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
476 | 
477 |       const events = [];
478 |       const reqParts: Part[] = [{ text: 'Test no finish reason' }];
479 |       for await (const event of turn.run(
480 |         'test-model',
481 |         reqParts,
482 |         new AbortController().signal,
483 |       )) {
484 |         events.push(event);
485 |       }
486 | 
487 |       expect(events).toEqual([
488 |         {
489 |           type: GeminiEventType.Content,
490 |           value: 'Response without finish reason',
491 |         },
492 |       ]);
493 |     });
494 | 
495 |     it('should handle multiple responses with different finish reasons', async () => {
496 |       const mockResponseStream = (async function* () {
497 |         yield {
498 |           type: StreamEventType.CHUNK,
499 |           value: {
500 |             candidates: [
501 |               {
502 |                 content: { parts: [{ text: 'First part' }] },
503 |                 // No finish reason on first response
504 |               },
505 |             ],
506 |           },
507 |         };
508 |         yield {
509 |           value: {
510 |             type: StreamEventType.CHUNK,
511 |             candidates: [
512 |               {
513 |                 content: { parts: [{ text: 'Second part' }] },
514 |                 finishReason: 'OTHER',
515 |               },
516 |             ],
517 |           },
518 |         };
519 |       })();
520 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
521 | 
522 |       const events = [];
523 |       const reqParts: Part[] = [{ text: 'Test multiple responses' }];
524 |       for await (const event of turn.run(
525 |         'test-model',
526 |         reqParts,
527 |         new AbortController().signal,
528 |       )) {
529 |         events.push(event);
530 |       }
531 | 
532 |       expect(events).toEqual([
533 |         { type: GeminiEventType.Content, value: 'First part' },
534 |         { type: GeminiEventType.Content, value: 'Second part' },
535 |         {
536 |           type: GeminiEventType.Finished,
537 |           value: { reason: 'OTHER', usageMetadata: undefined },
538 |         },
539 |       ]);
540 |     });
541 | 
542 |     it('should yield citation and finished events when response has citationMetadata', async () => {
543 |       const mockResponseStream = (async function* () {
544 |         yield {
545 |           type: StreamEventType.CHUNK,
546 |           value: {
547 |             candidates: [
548 |               {
549 |                 content: { parts: [{ text: 'Some text.' }] },
550 |                 citationMetadata: {
551 |                   citations: [
552 |                     {
553 |                       uri: 'https://example.com/source1',
554 |                       title: 'Source 1 Title',
555 |                     },
556 |                   ],
557 |                 },
558 |                 finishReason: 'STOP',
559 |               },
560 |             ],
561 |           },
562 |         };
563 |       })();
564 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
565 | 
566 |       const events = [];
567 |       for await (const event of turn.run(
568 |         'test-model',
569 |         [{ text: 'Test citations' }],
570 |         new AbortController().signal,
571 |       )) {
572 |         events.push(event);
573 |       }
574 | 
575 |       expect(events).toEqual([
576 |         { type: GeminiEventType.Content, value: 'Some text.' },
577 |         {
578 |           type: GeminiEventType.Citation,
579 |           value: 'Citations:\n(Source 1 Title) https://example.com/source1',
580 |         },
581 |         {
582 |           type: GeminiEventType.Finished,
583 |           value: { reason: 'STOP', usageMetadata: undefined },
584 |         },
585 |       ]);
586 |     });
587 | 
588 |     it('should yield a single citation event for multiple citations in one response', async () => {
589 |       const mockResponseStream = (async function* () {
590 |         yield {
591 |           type: StreamEventType.CHUNK,
592 |           value: {
593 |             candidates: [
594 |               {
595 |                 content: { parts: [{ text: 'Some text.' }] },
596 |                 citationMetadata: {
597 |                   citations: [
598 |                     {
599 |                       uri: 'https://example.com/source2',
600 |                       title: 'Title2',
601 |                     },
602 |                     {
603 |                       uri: 'https://example.com/source1',
604 |                       title: 'Title1',
605 |                     },
606 |                   ],
607 |                 },
608 |                 finishReason: 'STOP',
609 |               },
610 |             ],
611 |           },
612 |         };
613 |       })();
614 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
615 | 
616 |       const events = [];
617 |       for await (const event of turn.run(
618 |         'test-model',
619 |         [{ text: 'test' }],
620 |         new AbortController().signal,
621 |       )) {
622 |         events.push(event);
623 |       }
624 | 
625 |       expect(events).toEqual([
626 |         { type: GeminiEventType.Content, value: 'Some text.' },
627 |         {
628 |           type: GeminiEventType.Citation,
629 |           value:
630 |             'Citations:\n(Title1) https://example.com/source1\n(Title2) https://example.com/source2',
631 |         },
632 |         {
633 |           type: GeminiEventType.Finished,
634 |           value: { reason: 'STOP', usageMetadata: undefined },
635 |         },
636 |       ]);
637 |     });
638 | 
639 |     it('should not yield citation event if there is no finish reason', async () => {
640 |       const mockResponseStream = (async function* () {
641 |         yield {
642 |           type: StreamEventType.CHUNK,
643 |           value: {
644 |             candidates: [
645 |               {
646 |                 content: { parts: [{ text: 'Some text.' }] },
647 |                 citationMetadata: {
648 |                   citations: [
649 |                     {
650 |                       uri: 'https://example.com/source1',
651 |                       title: 'Source 1 Title',
652 |                     },
653 |                   ],
654 |                 },
655 |                 // No finishReason
656 |               },
657 |             ],
658 |           },
659 |         };
660 |       })();
661 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
662 | 
663 |       const events = [];
664 |       for await (const event of turn.run(
665 |         'test-model',
666 |         [{ text: 'test' }],
667 |         new AbortController().signal,
668 |       )) {
669 |         events.push(event);
670 |       }
671 | 
672 |       expect(events).toEqual([
673 |         { type: GeminiEventType.Content, value: 'Some text.' },
674 |       ]);
675 |       // No Citation event (but we do get a Finished event with undefined reason)
676 |       expect(events.some((e) => e.type === GeminiEventType.Citation)).toBe(
677 |         false,
678 |       );
679 |     });
680 | 
681 |     it('should ignore citations without a URI', async () => {
682 |       const mockResponseStream = (async function* () {
683 |         yield {
684 |           type: StreamEventType.CHUNK,
685 |           value: {
686 |             candidates: [
687 |               {
688 |                 content: { parts: [{ text: 'Some text.' }] },
689 |                 citationMetadata: {
690 |                   citations: [
691 |                     {
692 |                       uri: 'https://example.com/source1',
693 |                       title: 'Good Source',
694 |                     },
695 |                     {
696 |                       // uri is undefined
697 |                       title: 'Bad Source',
698 |                     },
699 |                   ],
700 |                 },
701 |                 finishReason: 'STOP',
702 |               },
703 |             ],
704 |           },
705 |         };
706 |       })();
707 |       mockSendMessageStream.mockResolvedValue(mockResponseStream);
708 | 
709 |       const events = [];
710 |       for await (const event of turn.run(
711 |         'test-model',
712 |         [{ text: 'test' }],
713 |         new AbortController().signal,
714 |       )) {
715 |         events.push(event);
716 |       }
717 | 
718 |       expect(events).toEqual([
719 |         { type: GeminiEventType.Content, value: 'Some text.' },
720 |         {
721 |           type: GeminiEventType.Citation,
722 |           value: 'Citations:\n(Good Source) https://example.com/source1',
723 |         },
724 |         {
725 |           type: GeminiEventType.Finished,
726 |           value: { reason: 'STOP', usageMetadata: undefined },
727 |         },
728 |       ]);
[TRUNCATED]
```

src/core/turn.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   Part,
9 |   PartListUnion,
10 |   GenerateContentResponse,
11 |   FunctionCall,
12 |   FunctionDeclaration,
13 |   FinishReason,
14 |   GenerateContentResponseUsageMetadata,
15 | } from '@google/genai';
16 | import type {
17 |   ToolCallConfirmationDetails,
18 |   ToolResult,
19 |   ToolResultDisplay,
20 | } from '../tools/tools.js';
21 | import type { ToolErrorType } from '../tools/tool-error.js';
22 | import { getResponseText } from '../utils/partUtils.js';
23 | import { reportError } from '../utils/errorReporting.js';
24 | import {
25 |   getErrorMessage,
26 |   UnauthorizedError,
27 |   toFriendlyError,
28 | } from '../utils/errors.js';
29 | import type { GeminiChat } from './geminiChat.js';
30 | import { InvalidStreamError } from './geminiChat.js';
31 | import { parseThought, type ThoughtSummary } from '../utils/thoughtUtils.js';
32 | import { createUserContent } from '@google/genai';
33 | 
34 | // Define a structure for tools passed to the server
35 | export interface ServerTool {
36 |   name: string;
37 |   schema: FunctionDeclaration;
38 |   // The execute method signature might differ slightly or be wrapped
39 |   execute(
40 |     params: Record<string, unknown>,
41 |     signal?: AbortSignal,
42 |   ): Promise<ToolResult>;
43 |   shouldConfirmExecute(
44 |     params: Record<string, unknown>,
45 |     abortSignal: AbortSignal,
46 |   ): Promise<ToolCallConfirmationDetails | false>;
47 | }
48 | 
49 | export enum GeminiEventType {
50 |   Content = 'content',
51 |   ToolCallRequest = 'tool_call_request',
52 |   ToolCallResponse = 'tool_call_response',
53 |   ToolCallConfirmation = 'tool_call_confirmation',
54 |   UserCancelled = 'user_cancelled',
55 |   Error = 'error',
56 |   ChatCompressed = 'chat_compressed',
57 |   Thought = 'thought',
58 |   MaxSessionTurns = 'max_session_turns',
59 |   Finished = 'finished',
60 |   LoopDetected = 'loop_detected',
61 |   Citation = 'citation',
62 |   Retry = 'retry',
63 |   ContextWindowWillOverflow = 'context_window_will_overflow',
64 |   InvalidStream = 'invalid_stream',
65 | }
66 | 
67 | export type ServerGeminiRetryEvent = {
68 |   type: GeminiEventType.Retry;
69 | };
70 | 
71 | export type ServerGeminiContextWindowWillOverflowEvent = {
72 |   type: GeminiEventType.ContextWindowWillOverflow;
73 |   value: {
74 |     estimatedRequestTokenCount: number;
75 |     remainingTokenCount: number;
76 |   };
77 | };
78 | 
79 | export type ServerGeminiInvalidStreamEvent = {
80 |   type: GeminiEventType.InvalidStream;
81 | };
82 | 
83 | export interface StructuredError {
84 |   message: string;
85 |   status?: number;
86 | }
87 | 
88 | export interface GeminiErrorEventValue {
89 |   error: StructuredError;
90 | }
91 | 
92 | export interface GeminiFinishedEventValue {
93 |   reason: FinishReason | undefined;
94 |   usageMetadata: GenerateContentResponseUsageMetadata | undefined;
95 | }
96 | 
97 | export interface ToolCallRequestInfo {
98 |   callId: string;
99 |   name: string;
100 |   args: Record<string, unknown>;
101 |   isClientInitiated: boolean;
102 |   prompt_id: string;
103 | }
104 | 
105 | export interface ToolCallResponseInfo {
106 |   callId: string;
107 |   responseParts: Part[];
108 |   resultDisplay: ToolResultDisplay | undefined;
109 |   error: Error | undefined;
110 |   errorType: ToolErrorType | undefined;
111 |   outputFile?: string | undefined;
112 |   contentLength?: number;
113 | }
114 | 
115 | export interface ServerToolCallConfirmationDetails {
116 |   request: ToolCallRequestInfo;
117 |   details: ToolCallConfirmationDetails;
118 | }
119 | 
120 | export type ServerGeminiContentEvent = {
121 |   type: GeminiEventType.Content;
122 |   value: string;
123 | };
124 | 
125 | export type ServerGeminiThoughtEvent = {
126 |   type: GeminiEventType.Thought;
127 |   value: ThoughtSummary;
128 | };
129 | 
130 | export type ServerGeminiToolCallRequestEvent = {
131 |   type: GeminiEventType.ToolCallRequest;
132 |   value: ToolCallRequestInfo;
133 | };
134 | 
135 | export type ServerGeminiToolCallResponseEvent = {
136 |   type: GeminiEventType.ToolCallResponse;
137 |   value: ToolCallResponseInfo;
138 | };
139 | 
140 | export type ServerGeminiToolCallConfirmationEvent = {
141 |   type: GeminiEventType.ToolCallConfirmation;
142 |   value: ServerToolCallConfirmationDetails;
143 | };
144 | 
145 | export type ServerGeminiUserCancelledEvent = {
146 |   type: GeminiEventType.UserCancelled;
147 | };
148 | 
149 | export type ServerGeminiErrorEvent = {
150 |   type: GeminiEventType.Error;
151 |   value: GeminiErrorEventValue;
152 | };
153 | 
154 | export enum CompressionStatus {
155 |   /** The compression was successful */
156 |   COMPRESSED = 1,
157 | 
158 |   /** The compression failed due to the compression inflating the token count */
159 |   COMPRESSION_FAILED_INFLATED_TOKEN_COUNT,
160 | 
161 |   /** The compression failed due to an error counting tokens */
162 |   COMPRESSION_FAILED_TOKEN_COUNT_ERROR,
163 | 
164 |   /** The compression was not necessary and no action was taken */
165 |   NOOP,
166 | }
167 | 
168 | export interface ChatCompressionInfo {
169 |   originalTokenCount: number;
170 |   newTokenCount: number;
171 |   compressionStatus: CompressionStatus;
172 | }
173 | 
174 | export type ServerGeminiChatCompressedEvent = {
175 |   type: GeminiEventType.ChatCompressed;
176 |   value: ChatCompressionInfo | null;
177 | };
178 | 
179 | export type ServerGeminiMaxSessionTurnsEvent = {
180 |   type: GeminiEventType.MaxSessionTurns;
181 | };
182 | 
183 | export type ServerGeminiFinishedEvent = {
184 |   type: GeminiEventType.Finished;
185 |   value: GeminiFinishedEventValue;
186 | };
187 | 
188 | export type ServerGeminiLoopDetectedEvent = {
189 |   type: GeminiEventType.LoopDetected;
190 | };
191 | 
192 | export type ServerGeminiCitationEvent = {
193 |   type: GeminiEventType.Citation;
194 |   value: string;
195 | };
196 | 
197 | // The original union type, now composed of the individual types
198 | export type ServerGeminiStreamEvent =
199 |   | ServerGeminiChatCompressedEvent
200 |   | ServerGeminiCitationEvent
201 |   | ServerGeminiContentEvent
202 |   | ServerGeminiErrorEvent
203 |   | ServerGeminiFinishedEvent
204 |   | ServerGeminiLoopDetectedEvent
205 |   | ServerGeminiMaxSessionTurnsEvent
206 |   | ServerGeminiThoughtEvent
207 |   | ServerGeminiToolCallConfirmationEvent
208 |   | ServerGeminiToolCallRequestEvent
209 |   | ServerGeminiToolCallResponseEvent
210 |   | ServerGeminiUserCancelledEvent
211 |   | ServerGeminiRetryEvent
212 |   | ServerGeminiContextWindowWillOverflowEvent
213 |   | ServerGeminiInvalidStreamEvent;
214 | 
215 | // A turn manages the agentic loop turn within the server context.
216 | export class Turn {
217 |   readonly pendingToolCalls: ToolCallRequestInfo[] = [];
218 |   private debugResponses: GenerateContentResponse[] = [];
219 |   private pendingCitations = new Set<string>();
220 |   finishReason: FinishReason | undefined = undefined;
221 | 
222 |   constructor(
223 |     private readonly chat: GeminiChat,
224 |     private readonly prompt_id: string,
225 |   ) {}
226 |   // The run method yields simpler events suitable for server logic
227 |   async *run(
228 |     model: string,
229 |     req: PartListUnion,
230 |     signal: AbortSignal,
231 |   ): AsyncGenerator<ServerGeminiStreamEvent> {
232 |     try {
233 |       // Note: This assumes `sendMessageStream` yields events like
234 |       // { type: StreamEventType.RETRY } or { type: StreamEventType.CHUNK, value: GenerateContentResponse }
235 |       const responseStream = await this.chat.sendMessageStream(
236 |         model,
237 |         {
238 |           message: req,
239 |           config: {
240 |             abortSignal: signal,
241 |           },
242 |         },
243 |         this.prompt_id,
244 |       );
245 | 
246 |       for await (const streamEvent of responseStream) {
247 |         if (signal?.aborted) {
248 |           yield { type: GeminiEventType.UserCancelled };
249 |           return;
250 |         }
251 | 
252 |         // Handle the new RETRY event
253 |         if (streamEvent.type === 'retry') {
254 |           yield { type: GeminiEventType.Retry };
255 |           continue; // Skip to the next event in the stream
256 |         }
257 | 
258 |         // Assuming other events are chunks with a `value` property
259 |         const resp = streamEvent.value as GenerateContentResponse;
260 |         if (!resp) continue; // Skip if there's no response body
261 | 
262 |         this.debugResponses.push(resp);
263 | 
264 |         const thoughtPart = resp.candidates?.[0]?.content?.parts?.[0];
265 |         if (thoughtPart?.thought) {
266 |           const thought = parseThought(thoughtPart.text ?? '');
267 |           yield {
268 |             type: GeminiEventType.Thought,
269 |             value: thought,
270 |           };
271 |           continue;
272 |         }
273 | 
274 |         const text = getResponseText(resp);
275 |         if (text) {
276 |           yield { type: GeminiEventType.Content, value: text };
277 |         }
278 | 
279 |         // Handle function calls (requesting tool execution)
280 |         const functionCalls = resp.functionCalls ?? [];
281 |         for (const fnCall of functionCalls) {
282 |           const event = this.handlePendingFunctionCall(fnCall);
283 |           if (event) {
284 |             yield event;
285 |           }
286 |         }
287 | 
288 |         for (const citation of getCitations(resp)) {
289 |           this.pendingCitations.add(citation);
290 |         }
291 | 
292 |         // Check if response was truncated or stopped for various reasons
293 |         const finishReason = resp.candidates?.[0]?.finishReason;
294 | 
295 |         // This is the key change: Only yield 'Finished' if there is a finishReason.
296 |         if (finishReason) {
297 |           if (this.pendingCitations.size > 0) {
298 |             yield {
299 |               type: GeminiEventType.Citation,
300 |               value: `Citations:\n${[...this.pendingCitations].sort().join('\n')}`,
301 |             };
302 |             this.pendingCitations.clear();
303 |           }
304 | 
305 |           this.finishReason = finishReason;
306 |           yield {
307 |             type: GeminiEventType.Finished,
308 |             value: {
309 |               reason: finishReason,
310 |               usageMetadata: resp.usageMetadata,
311 |             },
312 |           };
313 |         }
314 |       }
315 |     } catch (e) {
316 |       if (signal.aborted) {
317 |         yield { type: GeminiEventType.UserCancelled };
318 |         // Regular cancellation error, fail gracefully.
319 |         return;
320 |       }
321 | 
322 |       if (e instanceof InvalidStreamError) {
323 |         yield { type: GeminiEventType.InvalidStream };
324 |         return;
325 |       }
326 | 
327 |       const error = toFriendlyError(e);
328 |       if (error instanceof UnauthorizedError) {
329 |         throw error;
330 |       }
331 | 
332 |       const contextForReport = [
333 |         ...this.chat.getHistory(/*curated*/ true),
334 |         createUserContent(req),
335 |       ];
336 |       await reportError(
337 |         error,
338 |         'Error when talking to Gemini API',
339 |         contextForReport,
340 |         'Turn.run-sendMessageStream',
341 |       );
342 |       const status =
343 |         typeof error === 'object' &&
344 |         error !== null &&
345 |         'status' in error &&
346 |         typeof (error as { status: unknown }).status === 'number'
347 |           ? (error as { status: number }).status
348 |           : undefined;
349 |       const structuredError: StructuredError = {
350 |         message: getErrorMessage(error),
351 |         status,
352 |       };
353 |       await this.chat.maybeIncludeSchemaDepthContext(structuredError);
354 |       yield { type: GeminiEventType.Error, value: { error: structuredError } };
355 |       return;
356 |     }
357 |   }
358 | 
359 |   private handlePendingFunctionCall(
360 |     fnCall: FunctionCall,
361 |   ): ServerGeminiStreamEvent | null {
362 |     const callId =
363 |       fnCall.id ??
364 |       `${fnCall.name}-${Date.now()}-${Math.random().toString(16).slice(2)}`;
365 |     const name = fnCall.name || 'undefined_tool_name';
366 |     const args = (fnCall.args || {}) as Record<string, unknown>;
367 | 
368 |     const toolCallRequest: ToolCallRequestInfo = {
369 |       callId,
370 |       name,
371 |       args,
372 |       isClientInitiated: false,
373 |       prompt_id: this.prompt_id,
374 |     };
375 | 
376 |     this.pendingToolCalls.push(toolCallRequest);
377 | 
378 |     // Yield a request for the tool call, not the pending/confirming status
379 |     return { type: GeminiEventType.ToolCallRequest, value: toolCallRequest };
380 |   }
381 | 
382 |   getDebugResponses(): GenerateContentResponse[] {
383 |     return this.debugResponses;
384 |   }
385 | }
386 | 
387 | function getCitations(resp: GenerateContentResponse): string[] {
388 |   return (resp.candidates?.[0]?.citationMetadata?.citations ?? [])
389 |     .filter((citation) => citation.uri !== undefined)
390 |     .map((citation) => {
391 |       if (citation.title) {
392 |         return `(${citation.title}) ${citation.uri}`;
393 |       }
394 |       return citation.uri!;
395 |     });
396 | }
```

src/fallback/handler.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   vi,
12 |   beforeEach,
13 |   type Mock,
14 |   type MockInstance,
15 |   afterEach,
16 | } from 'vitest';
17 | import { handleFallback } from './handler.js';
18 | import type { Config } from '../config/config.js';
19 | import { AuthType } from '../core/contentGenerator.js';
20 | import {
21 |   DEFAULT_GEMINI_FLASH_MODEL,
22 |   DEFAULT_GEMINI_MODEL,
23 | } from '../config/models.js';
24 | import { logFlashFallback } from '../telemetry/index.js';
25 | import type { FallbackModelHandler } from './types.js';
26 | 
27 | // Mock the telemetry logger and event class
28 | vi.mock('../telemetry/index.js', () => ({
29 |   logFlashFallback: vi.fn(),
30 |   FlashFallbackEvent: class {},
31 | }));
32 | 
33 | const MOCK_PRO_MODEL = DEFAULT_GEMINI_MODEL;
34 | const FALLBACK_MODEL = DEFAULT_GEMINI_FLASH_MODEL;
35 | const AUTH_OAUTH = AuthType.LOGIN_WITH_GOOGLE;
36 | const AUTH_API_KEY = AuthType.USE_GEMINI;
37 | 
38 | const createMockConfig = (overrides: Partial<Config> = {}): Config =>
39 |   ({
40 |     isInFallbackMode: vi.fn(() => false),
41 |     setFallbackMode: vi.fn(),
42 |     fallbackHandler: undefined,
43 |     ...overrides,
44 |   }) as unknown as Config;
45 | 
46 | describe('handleFallback', () => {
47 |   let mockConfig: Config;
48 |   let mockHandler: Mock<FallbackModelHandler>;
49 |   let consoleErrorSpy: MockInstance;
50 | 
51 |   beforeEach(() => {
52 |     vi.clearAllMocks();
53 |     mockHandler = vi.fn();
54 |     // Default setup: OAuth user, Pro model failed, handler injected
55 |     mockConfig = createMockConfig({
56 |       fallbackModelHandler: mockHandler,
57 |     });
58 |     consoleErrorSpy = vi.spyOn(console, 'error').mockImplementation(() => {});
59 |   });
60 | 
61 |   afterEach(() => {
62 |     consoleErrorSpy.mockRestore();
63 |   });
64 | 
65 |   it('should return null immediately if authType is not OAuth', async () => {
66 |     const result = await handleFallback(
67 |       mockConfig,
68 |       MOCK_PRO_MODEL,
69 |       AUTH_API_KEY,
70 |     );
71 |     expect(result).toBeNull();
72 |     expect(mockHandler).not.toHaveBeenCalled();
73 |     expect(mockConfig.setFallbackMode).not.toHaveBeenCalled();
74 |   });
75 | 
76 |   it('should return null if the failed model is already the fallback model', async () => {
77 |     const result = await handleFallback(
78 |       mockConfig,
79 |       FALLBACK_MODEL, // Failed model is Flash
80 |       AUTH_OAUTH,
81 |     );
82 |     expect(result).toBeNull();
83 |     expect(mockHandler).not.toHaveBeenCalled();
84 |   });
85 | 
86 |   it('should return null if no fallbackHandler is injected in config', async () => {
87 |     const configWithoutHandler = createMockConfig({
88 |       fallbackModelHandler: undefined,
89 |     });
90 |     const result = await handleFallback(
91 |       configWithoutHandler,
92 |       MOCK_PRO_MODEL,
93 |       AUTH_OAUTH,
94 |     );
95 |     expect(result).toBeNull();
96 |   });
97 | 
98 |   describe('when handler returns "retry"', () => {
99 |     it('should activate fallback mode, log telemetry, and return true', async () => {
100 |       mockHandler.mockResolvedValue('retry');
101 | 
102 |       const result = await handleFallback(
103 |         mockConfig,
104 |         MOCK_PRO_MODEL,
105 |         AUTH_OAUTH,
106 |       );
107 | 
108 |       expect(result).toBe(true);
109 |       expect(mockConfig.setFallbackMode).toHaveBeenCalledWith(true);
110 |       expect(logFlashFallback).toHaveBeenCalled();
111 |     });
112 |   });
113 | 
114 |   describe('when handler returns "stop"', () => {
115 |     it('should activate fallback mode, log telemetry, and return false', async () => {
116 |       mockHandler.mockResolvedValue('stop');
117 | 
118 |       const result = await handleFallback(
119 |         mockConfig,
120 |         MOCK_PRO_MODEL,
121 |         AUTH_OAUTH,
122 |       );
123 | 
124 |       expect(result).toBe(false);
125 |       expect(mockConfig.setFallbackMode).toHaveBeenCalledWith(true);
126 |       expect(logFlashFallback).toHaveBeenCalled();
127 |     });
128 |   });
129 | 
130 |   describe('when handler returns "auth"', () => {
131 |     it('should NOT activate fallback mode and return false', async () => {
132 |       mockHandler.mockResolvedValue('auth');
133 | 
134 |       const result = await handleFallback(
135 |         mockConfig,
136 |         MOCK_PRO_MODEL,
137 |         AUTH_OAUTH,
138 |       );
139 | 
140 |       expect(result).toBe(false);
141 |       expect(mockConfig.setFallbackMode).not.toHaveBeenCalled();
142 |       expect(logFlashFallback).not.toHaveBeenCalled();
143 |     });
144 |   });
145 | 
146 |   describe('when handler returns an unexpected value', () => {
147 |     it('should log an error and return null', async () => {
148 |       mockHandler.mockResolvedValue(null);
149 | 
150 |       const result = await handleFallback(
151 |         mockConfig,
152 |         MOCK_PRO_MODEL,
153 |         AUTH_OAUTH,
154 |       );
155 | 
156 |       expect(result).toBeNull();
157 |       expect(consoleErrorSpy).toHaveBeenCalledWith(
158 |         'Fallback UI handler failed:',
159 |         new Error(
160 |           'Unexpected fallback intent received from fallbackModelHandler: "null"',
161 |         ),
162 |       );
163 |       expect(mockConfig.setFallbackMode).not.toHaveBeenCalled();
164 |     });
165 |   });
166 | 
167 |   it('should pass the correct context (failedModel, fallbackModel, error) to the handler', async () => {
168 |     const mockError = new Error('Quota Exceeded');
169 |     mockHandler.mockResolvedValue('retry');
170 | 
171 |     await handleFallback(mockConfig, MOCK_PRO_MODEL, AUTH_OAUTH, mockError);
172 | 
173 |     expect(mockHandler).toHaveBeenCalledWith(
174 |       MOCK_PRO_MODEL,
175 |       FALLBACK_MODEL,
176 |       mockError,
177 |     );
178 |   });
179 | 
180 |   it('should not call setFallbackMode or log telemetry if already in fallback mode', async () => {
181 |     // Setup config where fallback mode is already active
182 |     const activeFallbackConfig = createMockConfig({
183 |       fallbackModelHandler: mockHandler,
184 |       isInFallbackMode: vi.fn(() => true), // Already active
185 |       setFallbackMode: vi.fn(),
186 |     });
187 | 
188 |     mockHandler.mockResolvedValue('retry');
189 | 
190 |     const result = await handleFallback(
191 |       activeFallbackConfig,
192 |       MOCK_PRO_MODEL,
193 |       AUTH_OAUTH,
194 |     );
195 | 
196 |     // Should still return true to allow the retry (which will use the active fallback mode)
197 |     expect(result).toBe(true);
198 |     // Should still consult the handler
199 |     expect(mockHandler).toHaveBeenCalled();
200 |     // But should not mutate state or log telemetry again
201 |     expect(activeFallbackConfig.setFallbackMode).not.toHaveBeenCalled();
202 |     expect(logFlashFallback).not.toHaveBeenCalled();
203 |   });
204 | 
205 |   it('should catch errors from the handler, log an error, and return null', async () => {
206 |     const handlerError = new Error('UI interaction failed');
207 |     mockHandler.mockRejectedValue(handlerError);
208 | 
209 |     const result = await handleFallback(mockConfig, MOCK_PRO_MODEL, AUTH_OAUTH);
210 | 
211 |     expect(result).toBeNull();
212 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
213 |       'Fallback UI handler failed:',
214 |       handlerError,
215 |     );
216 |     expect(mockConfig.setFallbackMode).not.toHaveBeenCalled();
217 |   });
218 | });
```

src/fallback/handler.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Config } from '../config/config.js';
8 | import { AuthType } from '../core/contentGenerator.js';
9 | import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';
10 | import { logFlashFallback, FlashFallbackEvent } from '../telemetry/index.js';
11 | 
12 | export async function handleFallback(
13 |   config: Config,
14 |   failedModel: string,
15 |   authType?: string,
16 |   error?: unknown,
17 | ): Promise<string | boolean | null> {
18 |   // Applicability Checks
19 |   if (authType !== AuthType.LOGIN_WITH_GOOGLE) return null;
20 | 
21 |   const fallbackModel = DEFAULT_GEMINI_FLASH_MODEL;
22 | 
23 |   if (failedModel === fallbackModel) return null;
24 | 
25 |   // Consult UI Handler for Intent
26 |   const fallbackModelHandler = config.fallbackModelHandler;
27 |   if (typeof fallbackModelHandler !== 'function') return null;
28 | 
29 |   try {
30 |     // Pass the specific failed model to the UI handler.
31 |     const intent = await fallbackModelHandler(
32 |       failedModel,
33 |       fallbackModel,
34 |       error,
35 |     );
36 | 
37 |     // Process Intent and Update State
38 |     switch (intent) {
39 |       case 'retry':
40 |         // Activate fallback mode. The NEXT retry attempt will pick this up.
41 |         activateFallbackMode(config, authType);
42 |         return true; // Signal retryWithBackoff to continue.
43 | 
44 |       case 'stop':
45 |         activateFallbackMode(config, authType);
46 |         return false;
47 | 
48 |       case 'auth':
49 |         return false;
50 | 
51 |       default:
52 |         throw new Error(
53 |           `Unexpected fallback intent received from fallbackModelHandler: "${intent}"`,
54 |         );
55 |     }
56 |   } catch (handlerError) {
57 |     console.error('Fallback UI handler failed:', handlerError);
58 |     return null;
59 |   }
60 | }
61 | 
62 | function activateFallbackMode(config: Config, authType: string | undefined) {
63 |   if (!config.isInFallbackMode()) {
64 |     config.setFallbackMode(true);
65 |     if (authType) {
66 |       logFlashFallback(config, new FlashFallbackEvent(authType));
67 |     }
68 |   }
69 | }
```

src/fallback/types.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Defines the intent returned by the UI layer during a fallback scenario.
9 |  */
10 | export type FallbackIntent =
11 |   | 'retry' // Immediately retry the current request with the fallback model.
12 |   | 'stop' // Switch to fallback for future requests, but stop the current request.
13 |   | 'auth'; // Stop the current request; user intends to change authentication.
14 | 
15 | /**
16 |  * The interface for the handler provided by the UI layer (e.g., the CLI)
17 |  * to interact with the user during a fallback scenario.
18 |  */
19 | export type FallbackModelHandler = (
20 |   failedModel: string,
21 |   fallbackModel: string,
22 |   error?: unknown,
23 | ) => Promise<FallbackIntent | null>;
```

src/ide/constants.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export const GEMINI_CLI_COMPANION_EXTENSION_NAME = 'Gemini CLI Companion';
8 | export const IDE_MAX_OPEN_FILES = 10;
9 | export const IDE_MAX_SELECTED_TEXT_LENGTH = 16384; // 16 KiB limit
10 | export const IDE_REQUEST_TIMEOUT_MS = 10 * 60 * 1000; // 10 minutes
```

src/ide/detect-ide.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, afterEach } from 'vitest';
8 | import { detectIde, IDE_DEFINITIONS } from './detect-ide.js';
9 | 
10 | describe('detectIde', () => {
11 |   const ideProcessInfo = { pid: 123, command: 'some/path/to/code' };
12 |   const ideProcessInfoNoCode = { pid: 123, command: 'some/path/to/fork' };
13 | 
14 |   afterEach(() => {
15 |     vi.unstubAllEnvs();
16 |     // Clear Cursor-specific environment variables that might interfere with tests
17 |     delete process.env['CURSOR_TRACE_ID'];
18 |   });
19 | 
20 |   it('should return undefined if TERM_PROGRAM is not vscode', () => {
21 |     vi.stubEnv('TERM_PROGRAM', '');
22 |     expect(detectIde(ideProcessInfo)).toBeUndefined();
23 |   });
24 | 
25 |   it('should detect Devin', () => {
26 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
27 |     vi.stubEnv('__COG_BASHRC_SOURCED', '1');
28 |     expect(detectIde(ideProcessInfo)).toBe(IDE_DEFINITIONS.devin);
29 |   });
30 | 
31 |   it('should detect Replit', () => {
32 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
33 |     vi.stubEnv('REPLIT_USER', 'testuser');
34 |     expect(detectIde(ideProcessInfo)).toBe(IDE_DEFINITIONS.replit);
35 |   });
36 | 
37 |   it('should detect Cursor', () => {
38 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
39 |     vi.stubEnv('CURSOR_TRACE_ID', 'some-id');
40 |     expect(detectIde(ideProcessInfo)).toBe(IDE_DEFINITIONS.cursor);
41 |   });
42 | 
43 |   it('should detect Codespaces', () => {
44 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
45 |     vi.stubEnv('CODESPACES', 'true');
46 |     vi.stubEnv('CURSOR_TRACE_ID', '');
47 |     expect(detectIde(ideProcessInfo)).toBe(IDE_DEFINITIONS.codespaces);
48 |   });
49 | 
50 |   it('should detect Cloud Shell via EDITOR_IN_CLOUD_SHELL', () => {
51 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
52 |     vi.stubEnv('EDITOR_IN_CLOUD_SHELL', 'true');
53 |     vi.stubEnv('CURSOR_TRACE_ID', '');
54 |     expect(detectIde(ideProcessInfo)).toBe(IDE_DEFINITIONS.cloudshell);
55 |   });
56 | 
57 |   it('should detect Cloud Shell via CLOUD_SHELL', () => {
58 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
59 |     vi.stubEnv('CLOUD_SHELL', 'true');
60 |     vi.stubEnv('CURSOR_TRACE_ID', '');
61 |     expect(detectIde(ideProcessInfo)).toBe(IDE_DEFINITIONS.cloudshell);
62 |   });
63 | 
64 |   it('should detect Trae', () => {
65 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
66 |     vi.stubEnv('TERM_PRODUCT', 'Trae');
67 |     vi.stubEnv('CURSOR_TRACE_ID', '');
68 |     expect(detectIde(ideProcessInfo)).toBe(IDE_DEFINITIONS.trae);
69 |   });
70 | 
71 |   it('should detect Firebase Studio via MONOSPACE_ENV', () => {
72 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
73 |     vi.stubEnv('MONOSPACE_ENV', 'true');
74 |     vi.stubEnv('CURSOR_TRACE_ID', '');
75 |     expect(detectIde(ideProcessInfo)).toBe(IDE_DEFINITIONS.firebasestudio);
76 |   });
77 | 
78 |   it('should detect VSCode when no other IDE is detected and command includes "code"', () => {
79 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
80 |     vi.stubEnv('MONOSPACE_ENV', '');
81 |     vi.stubEnv('CURSOR_TRACE_ID', '');
82 |     expect(detectIde(ideProcessInfo)).toBe(IDE_DEFINITIONS.vscode);
83 |   });
84 | 
85 |   it('should detect VSCodeFork when no other IDE is detected and command does not include "code"', () => {
86 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
87 |     vi.stubEnv('MONOSPACE_ENV', '');
88 |     vi.stubEnv('CURSOR_TRACE_ID', '');
89 |     expect(detectIde(ideProcessInfoNoCode)).toBe(IDE_DEFINITIONS.vscodefork);
90 |   });
91 | });
92 | 
93 | describe('detectIde with ideInfoFromFile', () => {
94 |   const ideProcessInfo = { pid: 123, command: 'some/path/to/code' };
95 | 
96 |   afterEach(() => {
97 |     vi.unstubAllEnvs();
98 |   });
99 | 
100 |   it('should use the name and displayName from the file', () => {
101 |     const ideInfoFromFile = {
102 |       name: 'custom-ide',
103 |       displayName: 'Custom IDE',
104 |     };
105 |     expect(detectIde(ideProcessInfo, ideInfoFromFile)).toEqual(ideInfoFromFile);
106 |   });
107 | 
108 |   it('should fall back to env detection if name is missing', () => {
109 |     const ideInfoFromFile = { displayName: 'Custom IDE' };
110 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
111 |     vi.stubEnv('CURSOR_TRACE_ID', '');
112 |     expect(detectIde(ideProcessInfo, ideInfoFromFile)).toBe(
113 |       IDE_DEFINITIONS.vscode,
114 |     );
115 |   });
116 | 
117 |   it('should fall back to env detection if displayName is missing', () => {
118 |     const ideInfoFromFile = { name: 'custom-ide' };
119 |     vi.stubEnv('TERM_PROGRAM', 'vscode');
120 |     vi.stubEnv('CURSOR_TRACE_ID', '');
121 |     expect(detectIde(ideProcessInfo, ideInfoFromFile)).toBe(
122 |       IDE_DEFINITIONS.vscode,
123 |     );
124 |   });
125 | });
```

src/ide/detect-ide.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export const IDE_DEFINITIONS = {
8 |   devin: { name: 'devin', displayName: 'Devin' },
9 |   replit: { name: 'replit', displayName: 'Replit' },
10 |   cursor: { name: 'cursor', displayName: 'Cursor' },
11 |   cloudshell: { name: 'cloudshell', displayName: 'Cloud Shell' },
12 |   codespaces: { name: 'codespaces', displayName: 'GitHub Codespaces' },
13 |   firebasestudio: { name: 'firebasestudio', displayName: 'Firebase Studio' },
14 |   trae: { name: 'trae', displayName: 'Trae' },
15 |   vscode: { name: 'vscode', displayName: 'VS Code' },
16 |   vscodefork: { name: 'vscodefork', displayName: 'IDE' },
17 | } as const;
18 | 
19 | export interface IdeInfo {
20 |   name: string;
21 |   displayName: string;
22 | }
23 | 
24 | export function isCloudShell(): boolean {
25 |   return !!(process.env['EDITOR_IN_CLOUD_SHELL'] || process.env['CLOUD_SHELL']);
26 | }
27 | 
28 | export function detectIdeFromEnv(): IdeInfo {
29 |   if (process.env['__COG_BASHRC_SOURCED']) {
30 |     return IDE_DEFINITIONS.devin;
31 |   }
32 |   if (process.env['REPLIT_USER']) {
33 |     return IDE_DEFINITIONS.replit;
34 |   }
35 |   if (process.env['CURSOR_TRACE_ID']) {
36 |     return IDE_DEFINITIONS.cursor;
37 |   }
38 |   if (process.env['CODESPACES']) {
39 |     return IDE_DEFINITIONS.codespaces;
40 |   }
41 |   if (isCloudShell()) {
42 |     return IDE_DEFINITIONS.cloudshell;
43 |   }
44 |   if (process.env['TERM_PRODUCT'] === 'Trae') {
45 |     return IDE_DEFINITIONS.trae;
46 |   }
47 |   if (process.env['MONOSPACE_ENV']) {
48 |     return IDE_DEFINITIONS.firebasestudio;
49 |   }
50 |   return IDE_DEFINITIONS.vscode;
51 | }
52 | 
53 | function verifyVSCode(
54 |   ide: IdeInfo,
55 |   ideProcessInfo: {
56 |     pid: number;
57 |     command: string;
58 |   },
59 | ): IdeInfo {
60 |   if (ide.name !== IDE_DEFINITIONS.vscode.name) {
61 |     return ide;
62 |   }
63 |   if (ideProcessInfo.command.toLowerCase().includes('code')) {
64 |     return IDE_DEFINITIONS.vscode;
65 |   }
66 |   return IDE_DEFINITIONS.vscodefork;
67 | }
68 | 
69 | export function detectIde(
70 |   ideProcessInfo: {
71 |     pid: number;
72 |     command: string;
73 |   },
74 |   ideInfoFromFile?: { name?: string; displayName?: string },
75 | ): IdeInfo | undefined {
76 |   if (ideInfoFromFile?.name && ideInfoFromFile.displayName) {
77 |     return {
78 |       name: ideInfoFromFile.name,
79 |       displayName: ideInfoFromFile.displayName,
80 |     };
81 |   }
82 | 
83 |   // Only VSCode-based integrations are currently supported.
84 |   if (process.env['TERM_PROGRAM'] !== 'vscode') {
85 |     return undefined;
86 |   }
87 | 
88 |   const ide = detectIdeFromEnv();
89 |   return verifyVSCode(ide, ideProcessInfo);
90 | }
```

src/ide/ide-client.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   vi,
12 |   beforeEach,
13 |   afterEach,
14 |   type Mocked,
15 |   type Mock,
16 | } from 'vitest';
17 | import { IdeClient, IDEConnectionStatus } from './ide-client.js';
18 | import * as fs from 'node:fs';
19 | import { getIdeProcessInfo } from './process-utils.js';
20 | import { Client } from '@modelcontextprotocol/sdk/client/index.js';
21 | import { StreamableHTTPClientTransport } from '@modelcontextprotocol/sdk/client/streamableHttp.js';
22 | import { StdioClientTransport } from '@modelcontextprotocol/sdk/client/stdio.js';
23 | import { detectIde, IDE_DEFINITIONS } from './detect-ide.js';
24 | import * as os from 'node:os';
25 | import * as path from 'node:path';
26 | 
27 | vi.mock('node:fs', async (importOriginal) => {
28 |   const actual = await importOriginal<typeof fs>();
29 |   return {
30 |     ...(actual as object),
31 |     promises: {
32 |       ...actual.promises,
33 |       readFile: vi.fn(),
34 |       readdir: vi.fn(),
35 |     },
36 |     realpathSync: (p: string) => p,
37 |     existsSync: () => false,
38 |   };
39 | });
40 | vi.mock('./process-utils.js');
41 | vi.mock('@modelcontextprotocol/sdk/client/index.js');
42 | vi.mock('@modelcontextprotocol/sdk/client/streamableHttp.js');
43 | vi.mock('@modelcontextprotocol/sdk/client/stdio.js');
44 | vi.mock('./detect-ide.js');
45 | vi.mock('node:os');
46 | 
47 | describe('IdeClient', () => {
48 |   let mockClient: Mocked<Client>;
49 |   let mockHttpTransport: Mocked<StreamableHTTPClientTransport>;
50 |   let mockStdioTransport: Mocked<StdioClientTransport>;
51 | 
52 |   beforeEach(async () => {
53 |     // Reset singleton instance for test isolation
54 |     (IdeClient as unknown as { instance: IdeClient | undefined }).instance =
55 |       undefined;
56 | 
57 |     // Mock environment variables
58 |     process.env['GEMINI_CLI_IDE_WORKSPACE_PATH'] = '/test/workspace';
59 |     delete process.env['GEMINI_CLI_IDE_SERVER_PORT'];
60 |     delete process.env['GEMINI_CLI_IDE_SERVER_STDIO_COMMAND'];
61 |     delete process.env['GEMINI_CLI_IDE_SERVER_STDIO_ARGS'];
62 | 
63 |     // Mock dependencies
64 |     vi.spyOn(process, 'cwd').mockReturnValue('/test/workspace/sub-dir');
65 |     vi.mocked(detectIde).mockReturnValue(IDE_DEFINITIONS.vscode);
66 |     vi.mocked(getIdeProcessInfo).mockResolvedValue({
67 |       pid: 12345,
68 |       command: 'test-ide',
69 |     });
70 |     vi.mocked(os.tmpdir).mockReturnValue('/tmp');
71 | 
72 |     // Mock MCP client and transports
73 |     mockClient = {
74 |       connect: vi.fn().mockResolvedValue(undefined),
75 |       close: vi.fn(),
76 |       setNotificationHandler: vi.fn(),
77 |       callTool: vi.fn(),
78 |       request: vi.fn(),
79 |     } as unknown as Mocked<Client>;
80 |     mockHttpTransport = {
81 |       close: vi.fn(),
82 |     } as unknown as Mocked<StreamableHTTPClientTransport>;
83 |     mockStdioTransport = {
84 |       close: vi.fn(),
85 |     } as unknown as Mocked<StdioClientTransport>;
86 | 
87 |     vi.mocked(Client).mockReturnValue(mockClient);
88 |     vi.mocked(StreamableHTTPClientTransport).mockReturnValue(mockHttpTransport);
89 |     vi.mocked(StdioClientTransport).mockReturnValue(mockStdioTransport);
90 | 
91 |     await IdeClient.getInstance();
92 |   });
93 | 
94 |   afterEach(() => {
95 |     vi.restoreAllMocks();
96 |   });
97 | 
98 |   describe('connect', () => {
99 |     it('should connect using HTTP when port is provided in config file', async () => {
100 |       const config = { port: '8080' };
101 |       vi.mocked(fs.promises.readFile).mockResolvedValue(JSON.stringify(config));
102 |       (
103 |         vi.mocked(fs.promises.readdir) as Mock<
104 |           (path: fs.PathLike) => Promise<string[]>
105 |         >
106 |       ).mockResolvedValue([]);
107 | 
108 |       const ideClient = await IdeClient.getInstance();
109 |       await ideClient.connect();
110 | 
111 |       expect(fs.promises.readFile).toHaveBeenCalledWith(
112 |         path.join('/tmp/', 'gemini-ide-server-12345.json'),
113 |         'utf8',
114 |       );
115 |       expect(StreamableHTTPClientTransport).toHaveBeenCalledWith(
116 |         new URL('http://127.0.0.1:8080/mcp'),
117 |         expect.any(Object),
118 |       );
119 |       expect(mockClient.connect).toHaveBeenCalledWith(mockHttpTransport);
120 |       expect(ideClient.getConnectionStatus().status).toBe(
121 |         IDEConnectionStatus.Connected,
122 |       );
123 |     });
124 | 
125 |     it('should connect using stdio when stdio config is provided in file', async () => {
126 |       const config = { stdio: { command: 'test-cmd', args: ['--foo'] } };
127 |       vi.mocked(fs.promises.readFile).mockResolvedValue(JSON.stringify(config));
128 |       (
129 |         vi.mocked(fs.promises.readdir) as Mock<
130 |           (path: fs.PathLike) => Promise<string[]>
131 |         >
132 |       ).mockResolvedValue([]);
133 | 
134 |       const ideClient = await IdeClient.getInstance();
135 |       await ideClient.connect();
136 | 
137 |       expect(StdioClientTransport).toHaveBeenCalledWith({
138 |         command: 'test-cmd',
139 |         args: ['--foo'],
140 |       });
141 |       expect(mockClient.connect).toHaveBeenCalledWith(mockStdioTransport);
142 |       expect(ideClient.getConnectionStatus().status).toBe(
143 |         IDEConnectionStatus.Connected,
144 |       );
145 |     });
146 | 
147 |     it('should prioritize port over stdio when both are in config file', async () => {
148 |       const config = {
149 |         port: '8080',
150 |         stdio: { command: 'test-cmd', args: ['--foo'] },
151 |       };
152 |       vi.mocked(fs.promises.readFile).mockResolvedValue(JSON.stringify(config));
153 |       (
154 |         vi.mocked(fs.promises.readdir) as Mock<
155 |           (path: fs.PathLike) => Promise<string[]>
156 |         >
157 |       ).mockResolvedValue([]);
158 | 
159 |       const ideClient = await IdeClient.getInstance();
160 |       await ideClient.connect();
161 | 
162 |       expect(StreamableHTTPClientTransport).toHaveBeenCalled();
163 |       expect(StdioClientTransport).not.toHaveBeenCalled();
164 |       expect(ideClient.getConnectionStatus().status).toBe(
165 |         IDEConnectionStatus.Connected,
166 |       );
167 |     });
168 | 
169 |     it('should connect using HTTP when port is provided in environment variables', async () => {
170 |       vi.mocked(fs.promises.readFile).mockRejectedValue(
171 |         new Error('File not found'),
172 |       );
173 |       (
174 |         vi.mocked(fs.promises.readdir) as Mock<
175 |           (path: fs.PathLike) => Promise<string[]>
176 |         >
177 |       ).mockResolvedValue([]);
178 |       process.env['GEMINI_CLI_IDE_SERVER_PORT'] = '9090';
179 | 
180 |       const ideClient = await IdeClient.getInstance();
181 |       await ideClient.connect();
182 | 
183 |       expect(StreamableHTTPClientTransport).toHaveBeenCalledWith(
184 |         new URL('http://127.0.0.1:9090/mcp'),
185 |         expect.any(Object),
186 |       );
187 |       expect(mockClient.connect).toHaveBeenCalledWith(mockHttpTransport);
188 |       expect(ideClient.getConnectionStatus().status).toBe(
189 |         IDEConnectionStatus.Connected,
190 |       );
191 |     });
192 | 
193 |     it('should connect using stdio when stdio config is in environment variables', async () => {
194 |       vi.mocked(fs.promises.readFile).mockRejectedValue(
195 |         new Error('File not found'),
196 |       );
197 |       (
198 |         vi.mocked(fs.promises.readdir) as Mock<
199 |           (path: fs.PathLike) => Promise<string[]>
200 |         >
201 |       ).mockResolvedValue([]);
202 |       process.env['GEMINI_CLI_IDE_SERVER_STDIO_COMMAND'] = 'env-cmd';
203 |       process.env['GEMINI_CLI_IDE_SERVER_STDIO_ARGS'] = '["--bar"]';
204 | 
205 |       const ideClient = await IdeClient.getInstance();
206 |       await ideClient.connect();
207 | 
208 |       expect(StdioClientTransport).toHaveBeenCalledWith({
209 |         command: 'env-cmd',
210 |         args: ['--bar'],
211 |       });
212 |       expect(mockClient.connect).toHaveBeenCalledWith(mockStdioTransport);
213 |       expect(ideClient.getConnectionStatus().status).toBe(
214 |         IDEConnectionStatus.Connected,
215 |       );
216 |     });
217 | 
218 |     it('should prioritize file config over environment variables', async () => {
219 |       const config = { port: '8080' };
220 |       vi.mocked(fs.promises.readFile).mockResolvedValue(JSON.stringify(config));
221 |       (
222 |         vi.mocked(fs.promises.readdir) as Mock<
223 |           (path: fs.PathLike) => Promise<string[]>
224 |         >
225 |       ).mockResolvedValue([]);
226 |       process.env['GEMINI_CLI_IDE_SERVER_PORT'] = '9090';
227 | 
228 |       const ideClient = await IdeClient.getInstance();
229 |       await ideClient.connect();
230 | 
231 |       expect(StreamableHTTPClientTransport).toHaveBeenCalledWith(
232 |         new URL('http://127.0.0.1:8080/mcp'),
233 |         expect.any(Object),
234 |       );
235 |       expect(ideClient.getConnectionStatus().status).toBe(
236 |         IDEConnectionStatus.Connected,
237 |       );
238 |     });
239 | 
240 |     it('should be disconnected if no config is found', async () => {
241 |       vi.mocked(fs.promises.readFile).mockRejectedValue(
242 |         new Error('File not found'),
243 |       );
244 |       (
245 |         vi.mocked(fs.promises.readdir) as Mock<
246 |           (path: fs.PathLike) => Promise<string[]>
247 |         >
248 |       ).mockResolvedValue([]);
249 | 
250 |       const ideClient = await IdeClient.getInstance();
251 |       await ideClient.connect();
252 | 
253 |       expect(StreamableHTTPClientTransport).not.toHaveBeenCalled();
254 |       expect(StdioClientTransport).not.toHaveBeenCalled();
255 |       expect(ideClient.getConnectionStatus().status).toBe(
256 |         IDEConnectionStatus.Disconnected,
257 |       );
258 |       expect(ideClient.getConnectionStatus().details).toContain(
259 |         'Failed to connect',
260 |       );
261 |     });
262 |   });
263 | 
264 |   describe('getConnectionConfigFromFile', () => {
265 |     it('should return config from the specific pid file if it exists', async () => {
266 |       const config = { port: '1234', workspacePath: '/test/workspace' };
267 |       vi.mocked(fs.promises.readFile).mockResolvedValue(JSON.stringify(config));
268 | 
269 |       const ideClient = await IdeClient.getInstance();
270 |       // In tests, the private method can be accessed like this.
271 |       const result = await (
272 |         ideClient as unknown as {
273 |           getConnectionConfigFromFile: () => Promise<unknown>;
274 |         }
275 |       ).getConnectionConfigFromFile();
276 | 
277 |       expect(result).toEqual(config);
278 |       expect(fs.promises.readFile).toHaveBeenCalledWith(
279 |         path.join('/tmp', 'gemini-ide-server-12345.json'),
280 |         'utf8',
281 |       );
282 |     });
283 | 
284 |     it('should return undefined if no config files are found', async () => {
285 |       vi.mocked(fs.promises.readFile).mockRejectedValue(new Error('not found'));
286 |       (
287 |         vi.mocked(fs.promises.readdir) as Mock<
288 |           (path: fs.PathLike) => Promise<string[]>
289 |         >
290 |       ).mockResolvedValue([]);
291 | 
292 |       const ideClient = await IdeClient.getInstance();
293 |       const result = await (
294 |         ideClient as unknown as {
295 |           getConnectionConfigFromFile: () => Promise<unknown>;
296 |         }
297 |       ).getConnectionConfigFromFile();
298 | 
299 |       expect(result).toBeUndefined();
300 |     });
301 | 
302 |     it('should find and parse a single config file with the new naming scheme', async () => {
303 |       const config = { port: '5678', workspacePath: '/test/workspace' };
304 |       vi.mocked(fs.promises.readFile).mockRejectedValueOnce(
305 |         new Error('not found'),
306 |       ); // For old path
307 |       (
308 |         vi.mocked(fs.promises.readdir) as Mock<
309 |           (path: fs.PathLike) => Promise<string[]>
310 |         >
311 |       ).mockResolvedValue(['gemini-ide-server-12345-123.json']);
312 |       vi.mocked(fs.promises.readFile).mockResolvedValue(JSON.stringify(config));
313 |       vi.spyOn(IdeClient, 'validateWorkspacePath').mockReturnValue({
314 |         isValid: true,
315 |       });
316 | 
317 |       const ideClient = await IdeClient.getInstance();
318 |       const result = await (
319 |         ideClient as unknown as {
320 |           getConnectionConfigFromFile: () => Promise<unknown>;
321 |         }
322 |       ).getConnectionConfigFromFile();
323 | 
324 |       expect(result).toEqual(config);
325 |       expect(fs.promises.readFile).toHaveBeenCalledWith(
326 |         path.join('/tmp/gemini/ide', 'gemini-ide-server-12345-123.json'),
327 |         'utf8',
328 |       );
329 |     });
330 | 
331 |     it('should filter out configs with invalid workspace paths', async () => {
332 |       const validConfig = {
333 |         port: '5678',
334 |         workspacePath: '/test/workspace',
335 |       };
336 |       const invalidConfig = {
337 |         port: '1111',
338 |         workspacePath: '/invalid/workspace',
339 |       };
340 |       vi.mocked(fs.promises.readFile).mockRejectedValueOnce(
341 |         new Error('not found'),
342 |       );
343 |       (
344 |         vi.mocked(fs.promises.readdir) as Mock<
345 |           (path: fs.PathLike) => Promise<string[]>
346 |         >
347 |       ).mockResolvedValue([
348 |         'gemini-ide-server-12345-111.json',
349 |         'gemini-ide-server-12345-222.json',
350 |       ]);
351 |       vi.mocked(fs.promises.readFile)
352 |         .mockResolvedValueOnce(JSON.stringify(invalidConfig))
353 |         .mockResolvedValueOnce(JSON.stringify(validConfig));
354 | 
355 |       const validateSpy = vi
356 |         .spyOn(IdeClient, 'validateWorkspacePath')
357 |         .mockReturnValueOnce({ isValid: false })
358 |         .mockReturnValueOnce({ isValid: true });
359 | 
360 |       const ideClient = await IdeClient.getInstance();
361 |       const result = await (
362 |         ideClient as unknown as {
363 |           getConnectionConfigFromFile: () => Promise<unknown>;
364 |         }
365 |       ).getConnectionConfigFromFile();
366 | 
367 |       expect(result).toEqual(validConfig);
368 |       expect(validateSpy).toHaveBeenCalledWith(
369 |         '/invalid/workspace',
370 |         '/test/workspace/sub-dir',
371 |       );
372 |       expect(validateSpy).toHaveBeenCalledWith(
373 |         '/test/workspace',
374 |         '/test/workspace/sub-dir',
375 |       );
376 |     });
377 | 
378 |     it('should return the first valid config when multiple workspaces are valid', async () => {
379 |       const config1 = { port: '1111', workspacePath: '/test/workspace' };
380 |       const config2 = { port: '2222', workspacePath: '/test/workspace2' };
381 |       vi.mocked(fs.promises.readFile).mockRejectedValueOnce(
382 |         new Error('not found'),
383 |       );
384 |       (
385 |         vi.mocked(fs.promises.readdir) as Mock<
386 |           (path: fs.PathLike) => Promise<string[]>
387 |         >
388 |       ).mockResolvedValue([
389 |         'gemini-ide-server-12345-111.json',
390 |         'gemini-ide-server-12345-222.json',
391 |       ]);
392 |       vi.mocked(fs.promises.readFile)
393 |         .mockResolvedValueOnce(JSON.stringify(config1))
394 |         .mockResolvedValueOnce(JSON.stringify(config2));
395 |       vi.spyOn(IdeClient, 'validateWorkspacePath').mockReturnValue({
396 |         isValid: true,
397 |       });
398 | 
399 |       const ideClient = await IdeClient.getInstance();
400 |       const result = await (
401 |         ideClient as unknown as {
402 |           getConnectionConfigFromFile: () => Promise<unknown>;
403 |         }
404 |       ).getConnectionConfigFromFile();
405 | 
406 |       expect(result).toEqual(config1);
407 |     });
408 | 
409 |     it('should prioritize the config matching the port from the environment variable', async () => {
410 |       process.env['GEMINI_CLI_IDE_SERVER_PORT'] = '2222';
411 |       const config1 = { port: '1111', workspacePath: '/test/workspace' };
412 |       const config2 = { port: '2222', workspacePath: '/test/workspace2' };
413 |       vi.mocked(fs.promises.readFile).mockRejectedValueOnce(
414 |         new Error('not found'),
415 |       );
416 |       (
417 |         vi.mocked(fs.promises.readdir) as Mock<
418 |           (path: fs.PathLike) => Promise<string[]>
419 |         >
420 |       ).mockResolvedValue([
421 |         'gemini-ide-server-12345-111.json',
422 |         'gemini-ide-server-12345-222.json',
423 |       ]);
424 |       vi.mocked(fs.promises.readFile)
425 |         .mockResolvedValueOnce(JSON.stringify(config1))
426 |         .mockResolvedValueOnce(JSON.stringify(config2));
427 |       vi.spyOn(IdeClient, 'validateWorkspacePath').mockReturnValue({
428 |         isValid: true,
429 |       });
430 | 
431 |       const ideClient = await IdeClient.getInstance();
432 |       const result = await (
433 |         ideClient as unknown as {
434 |           getConnectionConfigFromFile: () => Promise<unknown>;
435 |         }
436 |       ).getConnectionConfigFromFile();
437 | 
438 |       expect(result).toEqual(config2);
439 |     });
440 | 
441 |     it('should handle invalid JSON in one of the config files', async () => {
442 |       const validConfig = { port: '2222', workspacePath: '/test/workspace' };
443 |       vi.mocked(fs.promises.readFile).mockRejectedValueOnce(
444 |         new Error('not found'),
445 |       );
446 |       (
447 |         vi.mocked(fs.promises.readdir) as Mock<
448 |           (path: fs.PathLike) => Promise<string[]>
449 |         >
450 |       ).mockResolvedValue([
451 |         'gemini-ide-server-12345-111.json',
452 |         'gemini-ide-server-12345-222.json',
453 |       ]);
454 |       vi.mocked(fs.promises.readFile)
455 |         .mockResolvedValueOnce('invalid json')
456 |         .mockResolvedValueOnce(JSON.stringify(validConfig));
457 |       vi.spyOn(IdeClient, 'validateWorkspacePath').mockReturnValue({
458 |         isValid: true,
459 |       });
460 | 
461 |       const ideClient = await IdeClient.getInstance();
462 |       const result = await (
463 |         ideClient as unknown as {
464 |           getConnectionConfigFromFile: () => Promise<unknown>;
465 |         }
466 |       ).getConnectionConfigFromFile();
467 | 
468 |       expect(result).toEqual(validConfig);
469 |     });
470 | 
471 |     it('should return undefined if readdir throws an error', async () => {
472 |       vi.mocked(fs.promises.readFile).mockRejectedValueOnce(
473 |         new Error('not found'),
474 |       );
475 |       vi.mocked(fs.promises.readdir).mockRejectedValue(
476 |         new Error('readdir failed'),
477 |       );
478 | 
479 |       const ideClient = await IdeClient.getInstance();
480 |       const result = await (
481 |         ideClient as unknown as {
482 |           getConnectionConfigFromFile: () => Promise<unknown>;
483 |         }
484 |       ).getConnectionConfigFromFile();
485 | 
486 |       expect(result).toBeUndefined();
487 |     });
488 | 
489 |     it('should ignore files with invalid names', async () => {
490 |       const validConfig = { port: '3333', workspacePath: '/test/workspace' };
491 |       vi.mocked(fs.promises.readFile).mockRejectedValueOnce(
492 |         new Error('not found'),
493 |       );
494 |       (
495 |         vi.mocked(fs.promises.readdir) as Mock<
496 |           (path: fs.PathLike) => Promise<string[]>
497 |         >
498 |       ).mockResolvedValue([
499 |         'gemini-ide-server-12345-111.json', // valid
500 |         'not-a-config-file.txt', // invalid
501 |         'gemini-ide-server-asdf.json', // invalid
502 |       ]);
503 |       vi.mocked(fs.promises.readFile).mockResolvedValueOnce(
504 |         JSON.stringify(validConfig),
505 |       );
506 |       vi.spyOn(IdeClient, 'validateWorkspacePath').mockReturnValue({
507 |         isValid: true,
508 |       });
509 | 
510 |       const ideClient = await IdeClient.getInstance();
511 |       const result = await (
512 |         ideClient as unknown as {
513 |           getConnectionConfigFromFile: () => Promise<unknown>;
514 |         }
515 |       ).getConnectionConfigFromFile();
516 | 
517 |       expect(result).toEqual(validConfig);
518 |       expect(fs.promises.readFile).toHaveBeenCalledWith(
519 |         path.join('/tmp/gemini/ide', 'gemini-ide-server-12345-111.json'),
520 |         'utf8',
521 |       );
522 |       expect(fs.promises.readFile).not.toHaveBeenCalledWith(
523 |         path.join('/tmp/gemini/ide', 'not-a-config-file.txt'),
524 |         'utf8',
525 |       );
526 |     });
527 | 
528 |     it('should match env port string to a number port in the config', async () => {
529 |       process.env['GEMINI_CLI_IDE_SERVER_PORT'] = '3333';
530 |       const config1 = { port: 1111, workspacePath: '/test/workspace' };
531 |       const config2 = { port: 3333, workspacePath: '/test/workspace2' };
532 |       vi.mocked(fs.promises.readFile).mockRejectedValueOnce(
533 |         new Error('not found'),
534 |       );
535 |       (
536 |         vi.mocked(fs.promises.readdir) as Mock<
537 |           (path: fs.PathLike) => Promise<string[]>
538 |         >
539 |       ).mockResolvedValue([
540 |         'gemini-ide-server-12345-111.json',
541 |         'gemini-ide-server-12345-222.json',
542 |       ]);
543 |       vi.mocked(fs.promises.readFile)
544 |         .mockResolvedValueOnce(JSON.stringify(config1))
545 |         .mockResolvedValueOnce(JSON.stringify(config2));
546 |       vi.spyOn(IdeClient, 'validateWorkspacePath').mockReturnValue({
547 |         isValid: true,
548 |       });
549 | 
550 |       const ideClient = await IdeClient.getInstance();
551 |       const result = await (
552 |         ideClient as unknown as {
553 |           getConnectionConfigFromFile: () => Promise<unknown>;
554 |         }
555 |       ).getConnectionConfigFromFile();
556 | 
557 |       expect(result).toEqual(config2);
558 |     });
559 |   });
560 | 
561 |   describe('isDiffingEnabled', () => {
562 |     it('should return false if not connected', async () => {
563 |       const ideClient = await IdeClient.getInstance();
564 |       expect(ideClient.isDiffingEnabled()).toBe(false);
565 |     });
566 | 
567 |     it('should return false if tool discovery fails', async () => {
568 |       const config = { port: '8080' };
569 |       vi.mocked(fs.promises.readFile).mockResolvedValue(JSON.stringify(config));
570 |       (
571 |         vi.mocked(fs.promises.readdir) as Mock<
572 |           (path: fs.PathLike) => Promise<string[]>
573 |         >
574 |       ).mockResolvedValue([]);
575 |       mockClient.request.mockRejectedValue(new Error('Method not found'));
576 | 
577 |       const ideClient = await IdeClient.getInstance();
578 |       await ideClient.connect();
579 | 
580 |       expect(ideClient.getConnectionStatus().status).toBe(
581 |         IDEConnectionStatus.Connected,
582 |       );
583 |       expect(ideClient.isDiffingEnabled()).toBe(false);
584 |     });
585 | 
586 |     it('should return false if diffing tools are not available', async () => {
587 |       const config = { port: '8080' };
588 |       vi.mocked(fs.promises.readFile).mockResolvedValue(JSON.stringify(config));
589 |       (
590 |         vi.mocked(fs.promises.readdir) as Mock<
591 |           (path: fs.PathLike) => Promise<string[]>
592 |         >
593 |       ).mockResolvedValue([]);
[TRUNCATED]
```

src/ide/ide-client.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs';
8 | import { isSubpath } from '../utils/paths.js';
9 | import { detectIde, type IdeInfo } from '../ide/detect-ide.js';
10 | import { ideContextStore } from './ideContext.js';
11 | import {
12 |   IdeContextNotificationSchema,
13 |   IdeDiffAcceptedNotificationSchema,
14 |   IdeDiffClosedNotificationSchema,
15 |   IdeDiffRejectedNotificationSchema,
16 | } from './types.js';
17 | import { getIdeProcessInfo } from './process-utils.js';
18 | import { Client } from '@modelcontextprotocol/sdk/client/index.js';
19 | import { StreamableHTTPClientTransport } from '@modelcontextprotocol/sdk/client/streamableHttp.js';
20 | import { StdioClientTransport } from '@modelcontextprotocol/sdk/client/stdio.js';
21 | import { CallToolResultSchema } from '@modelcontextprotocol/sdk/types.js';
22 | import * as os from 'node:os';
23 | import * as path from 'node:path';
24 | import { EnvHttpProxyAgent } from 'undici';
25 | import { ListToolsResultSchema } from '@modelcontextprotocol/sdk/types.js';
26 | import { IDE_REQUEST_TIMEOUT_MS } from './constants.js';
27 | 
28 | const logger = {
29 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
30 |   debug: (...args: any[]) => console.debug('[DEBUG] [IDEClient]', ...args),
31 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
32 |   error: (...args: any[]) => console.error('[ERROR] [IDEClient]', ...args),
33 | };
34 | 
35 | export type DiffUpdateResult =
36 |   | {
37 |       status: 'accepted';
38 |       content?: string;
39 |     }
40 |   | {
41 |       status: 'rejected';
42 |       content: undefined;
43 |     };
44 | 
45 | export type IDEConnectionState = {
46 |   status: IDEConnectionStatus;
47 |   details?: string; // User-facing
48 | };
49 | 
50 | export enum IDEConnectionStatus {
51 |   Connected = 'connected',
52 |   Disconnected = 'disconnected',
53 |   Connecting = 'connecting',
54 | }
55 | 
56 | type StdioConfig = {
57 |   command: string;
58 |   args: string[];
59 | };
60 | 
61 | type ConnectionConfig = {
62 |   port?: string;
63 |   authToken?: string;
64 |   stdio?: StdioConfig;
65 | };
66 | 
67 | function getRealPath(path: string): string {
68 |   try {
69 |     return fs.realpathSync(path);
70 |   } catch (_e) {
71 |     // If realpathSync fails, it might be because the path doesn't exist.
72 |     // In that case, we can fall back to the original path.
73 |     return path;
74 |   }
75 | }
76 | 
77 | /**
78 |  * Manages the connection to and interaction with the IDE server.
79 |  */
80 | export class IdeClient {
81 |   private static instancePromise: Promise<IdeClient> | null = null;
82 |   private client: Client | undefined = undefined;
83 |   private state: IDEConnectionState = {
84 |     status: IDEConnectionStatus.Disconnected,
85 |     details:
86 |       'IDE integration is currently disabled. To enable it, run /ide enable.',
87 |   };
88 |   private currentIde: IdeInfo | undefined;
89 |   private ideProcessInfo: { pid: number; command: string } | undefined;
90 |   private connectionConfig:
91 |     | (ConnectionConfig & { workspacePath?: string; ideInfo?: IdeInfo })
92 |     | undefined;
93 |   private authToken: string | undefined;
94 |   private diffResponses = new Map<string, (result: DiffUpdateResult) => void>();
95 |   private statusListeners = new Set<(state: IDEConnectionState) => void>();
96 |   private trustChangeListeners = new Set<(isTrusted: boolean) => void>();
97 |   private availableTools: string[] = [];
98 |   /**
99 |    * A mutex to ensure that only one diff view is open in the IDE at a time.
100 |    * This prevents race conditions and UI issues in IDEs like VSCode that
101 |    * can't handle multiple diff views being opened simultaneously.
102 |    */
103 |   private diffMutex = Promise.resolve();
104 | 
105 |   private constructor() {}
106 | 
107 |   static getInstance(): Promise<IdeClient> {
108 |     if (!IdeClient.instancePromise) {
109 |       IdeClient.instancePromise = (async () => {
110 |         const client = new IdeClient();
111 |         client.ideProcessInfo = await getIdeProcessInfo();
112 |         client.connectionConfig = await client.getConnectionConfigFromFile();
113 |         client.currentIde = detectIde(
114 |           client.ideProcessInfo,
115 |           client.connectionConfig?.ideInfo,
116 |         );
117 |         return client;
118 |       })();
119 |     }
120 |     return IdeClient.instancePromise;
121 |   }
122 | 
123 |   addStatusChangeListener(listener: (state: IDEConnectionState) => void) {
124 |     this.statusListeners.add(listener);
125 |   }
126 | 
127 |   removeStatusChangeListener(listener: (state: IDEConnectionState) => void) {
128 |     this.statusListeners.delete(listener);
129 |   }
130 | 
131 |   addTrustChangeListener(listener: (isTrusted: boolean) => void) {
132 |     this.trustChangeListeners.add(listener);
133 |   }
134 | 
135 |   removeTrustChangeListener(listener: (isTrusted: boolean) => void) {
136 |     this.trustChangeListeners.delete(listener);
137 |   }
138 | 
139 |   async connect(): Promise<void> {
140 |     if (!this.currentIde) {
141 |       this.setState(
142 |         IDEConnectionStatus.Disconnected,
143 |         `IDE integration is not supported in your current environment. To use this feature, run Gemini CLI in one of these supported IDEs: VS Code or VS Code forks`,
144 |         false,
145 |       );
146 |       return;
147 |     }
148 | 
149 |     this.setState(IDEConnectionStatus.Connecting);
150 | 
151 |     this.connectionConfig = await this.getConnectionConfigFromFile();
152 |     if (this.connectionConfig?.authToken) {
153 |       this.authToken = this.connectionConfig.authToken;
154 |     }
155 |     const workspacePath =
156 |       this.connectionConfig?.workspacePath ??
157 |       process.env['GEMINI_CLI_IDE_WORKSPACE_PATH'];
158 | 
159 |     const { isValid, error } = IdeClient.validateWorkspacePath(
160 |       workspacePath,
161 |       process.cwd(),
162 |     );
163 | 
164 |     if (!isValid) {
165 |       this.setState(IDEConnectionStatus.Disconnected, error, true);
166 |       return;
167 |     }
168 | 
169 |     if (this.connectionConfig) {
170 |       if (this.connectionConfig.port) {
171 |         const connected = await this.establishHttpConnection(
172 |           this.connectionConfig.port,
173 |         );
174 |         if (connected) {
175 |           return;
176 |         }
177 |       }
178 |       if (this.connectionConfig.stdio) {
179 |         const connected = await this.establishStdioConnection(
180 |           this.connectionConfig.stdio,
181 |         );
182 |         if (connected) {
183 |           return;
184 |         }
185 |       }
186 |     }
187 | 
188 |     const portFromEnv = this.getPortFromEnv();
189 |     if (portFromEnv) {
190 |       const connected = await this.establishHttpConnection(portFromEnv);
191 |       if (connected) {
192 |         return;
193 |       }
194 |     }
195 | 
196 |     const stdioConfigFromEnv = this.getStdioConfigFromEnv();
197 |     if (stdioConfigFromEnv) {
198 |       const connected = await this.establishStdioConnection(stdioConfigFromEnv);
199 |       if (connected) {
200 |         return;
201 |       }
202 |     }
203 | 
204 |     this.setState(
205 |       IDEConnectionStatus.Disconnected,
206 |       `Failed to connect to IDE companion extension in ${this.currentIde.displayName}. Please ensure the extension is running. To install the extension, run /ide install.`,
207 |       true,
208 |     );
209 |   }
210 | 
211 |   /**
212 |    * Opens a diff view in the IDE, allowing the user to review and accept or
213 |    * reject changes.
214 |    *
215 |    * This method sends a request to the IDE to display a diff between the
216 |    * current content of a file and the new content provided. It then waits for
217 |    * a notification from the IDE indicating that the user has either accepted
218 |    * (potentially with manual edits) or rejected the diff.
219 |    *
220 |    * A mutex ensures that only one diff view can be open at a time to prevent
221 |    * race conditions.
222 |    *
223 |    * @param filePath The absolute path to the file to be diffed.
224 |    * @param newContent The proposed new content for the file.
225 |    * @returns A promise that resolves with a `DiffUpdateResult`, indicating
226 |    *   whether the diff was 'accepted' or 'rejected' and including the final
227 |    *   content if accepted.
228 |    */
229 |   async openDiff(
230 |     filePath: string,
231 |     newContent: string,
232 |   ): Promise<DiffUpdateResult> {
233 |     const release = await this.acquireMutex();
234 | 
235 |     const promise = new Promise<DiffUpdateResult>((resolve, reject) => {
236 |       if (!this.client) {
237 |         // The promise will be rejected, and the finally block below will release the mutex.
238 |         return reject(new Error('IDE client is not connected.'));
239 |       }
240 |       this.diffResponses.set(filePath, resolve);
241 |       this.client
242 |         .request(
243 |           {
244 |             method: 'tools/call',
245 |             params: {
246 |               name: `openDiff`,
247 |               arguments: {
248 |                 filePath,
249 |                 newContent,
250 |               },
251 |             },
252 |           },
253 |           CallToolResultSchema,
254 |           { timeout: IDE_REQUEST_TIMEOUT_MS },
255 |         )
256 |         .then((parsedResultData) => {
257 |           if (parsedResultData.isError) {
258 |             const textPart = parsedResultData.content.find(
259 |               (part) => part.type === 'text',
260 |             );
261 |             const errorMessage =
262 |               textPart?.text ?? `Tool 'openDiff' reported an error.`;
263 |             logger.debug(
264 |               `Request for openDiff ${filePath} failed with isError:`,
265 |               errorMessage,
266 |             );
267 |             this.diffResponses.delete(filePath);
268 |             reject(new Error(errorMessage));
269 |           }
270 |         })
271 |         .catch((err) => {
272 |           logger.debug(`Request for openDiff ${filePath} failed:`, err);
273 |           this.diffResponses.delete(filePath);
274 |           reject(err);
275 |         });
276 |     });
277 | 
278 |     // Ensure the mutex is released only after the diff interaction is complete.
279 |     promise.finally(release);
280 | 
281 |     return promise;
282 |   }
283 | 
284 |   /**
285 |    * Acquires a lock to ensure sequential execution of critical sections.
286 |    *
287 |    * This method implements a promise-based mutex. It works by chaining promises.
288 |    * Each call to `acquireMutex` gets the current `diffMutex` promise. It then
289 |    * creates a *new* promise (`newMutex`) that will be resolved when the caller
290 |    * invokes the returned `release` function. The `diffMutex` is immediately
291 |    * updated to this `newMutex`.
292 |    *
293 |    * The method returns a promise that resolves with the `release` function only
294 |    * *after* the *previous* `diffMutex` promise has resolved. This creates a
295 |    * queue where each subsequent operation must wait for the previous one to release
296 |    * the lock.
297 |    *
298 |    * @returns A promise that resolves to a function that must be called to
299 |    *   release the lock.
300 |    */
301 |   private acquireMutex(): Promise<() => void> {
302 |     let release: () => void;
303 |     const newMutex = new Promise<void>((resolve) => {
304 |       release = resolve;
305 |     });
306 |     const oldMutex = this.diffMutex;
307 |     this.diffMutex = newMutex;
308 |     return oldMutex.then(() => release);
309 |   }
310 | 
311 |   async closeDiff(
312 |     filePath: string,
313 |     options?: { suppressNotification?: boolean },
314 |   ): Promise<string | undefined> {
315 |     try {
316 |       if (!this.client) {
317 |         return undefined;
318 |       }
319 |       const resultData = await this.client.request(
320 |         {
321 |           method: 'tools/call',
322 |           params: {
323 |             name: `closeDiff`,
324 |             arguments: {
325 |               filePath,
326 |               suppressNotification: options?.suppressNotification,
327 |             },
328 |           },
329 |         },
330 |         CallToolResultSchema,
331 |         { timeout: IDE_REQUEST_TIMEOUT_MS },
332 |       );
333 | 
334 |       if (!resultData) {
335 |         return undefined;
336 |       }
337 | 
338 |       if (resultData.isError) {
339 |         const textPart = resultData.content.find(
340 |           (part) => part.type === 'text',
341 |         );
342 |         const errorMessage =
343 |           textPart?.text ?? `Tool 'closeDiff' reported an error.`;
344 |         logger.debug(
345 |           `Request for closeDiff ${filePath} failed with isError:`,
346 |           errorMessage,
347 |         );
348 |         return undefined;
349 |       }
350 | 
351 |       const textPart = resultData.content.find((part) => part.type === 'text');
352 | 
353 |       if (textPart?.text) {
354 |         try {
355 |           const parsedJson = JSON.parse(textPart.text);
356 |           if (parsedJson && typeof parsedJson.content === 'string') {
357 |             return parsedJson.content;
358 |           }
359 |           if (parsedJson && parsedJson.content === null) {
360 |             return undefined;
361 |           }
362 |         } catch (_e) {
363 |           logger.debug(
364 |             `Invalid JSON in closeDiff response for ${filePath}:`,
365 |             textPart.text,
366 |           );
367 |         }
368 |       }
369 |     } catch (err) {
370 |       logger.debug(`Request for closeDiff ${filePath} failed:`, err);
371 |     }
372 |     return undefined;
373 |   }
374 | 
375 |   // Closes the diff. Instead of waiting for a notification,
376 |   // manually resolves the diff resolver as the desired outcome.
377 |   async resolveDiffFromCli(filePath: string, outcome: 'accepted' | 'rejected') {
378 |     const resolver = this.diffResponses.get(filePath);
379 |     const content = await this.closeDiff(filePath, {
380 |       // Suppress notification to avoid race where closing the diff rejects the
381 |       // request.
382 |       suppressNotification: true,
383 |     });
384 | 
385 |     if (resolver) {
386 |       if (outcome === 'accepted') {
387 |         resolver({ status: 'accepted', content });
388 |       } else {
389 |         resolver({ status: 'rejected', content: undefined });
390 |       }
391 |       this.diffResponses.delete(filePath);
392 |     }
393 |   }
394 | 
395 |   async disconnect() {
396 |     if (this.state.status === IDEConnectionStatus.Disconnected) {
397 |       return;
398 |     }
399 |     for (const filePath of this.diffResponses.keys()) {
400 |       await this.closeDiff(filePath);
401 |     }
402 |     this.diffResponses.clear();
403 |     this.setState(
404 |       IDEConnectionStatus.Disconnected,
405 |       'IDE integration disabled. To enable it again, run /ide enable.',
406 |     );
407 |     this.client?.close();
408 |   }
409 | 
410 |   getCurrentIde(): IdeInfo | undefined {
411 |     return this.currentIde;
412 |   }
413 | 
414 |   getConnectionStatus(): IDEConnectionState {
415 |     return this.state;
416 |   }
417 | 
418 |   getDetectedIdeDisplayName(): string | undefined {
419 |     return this.currentIde?.displayName;
420 |   }
421 | 
422 |   isDiffingEnabled(): boolean {
423 |     return (
424 |       !!this.client &&
425 |       this.state.status === IDEConnectionStatus.Connected &&
426 |       this.availableTools.includes('openDiff') &&
427 |       this.availableTools.includes('closeDiff')
428 |     );
429 |   }
430 | 
431 |   private async discoverTools(): Promise<void> {
432 |     if (!this.client) {
433 |       return;
434 |     }
435 |     try {
436 |       logger.debug('Discovering tools from IDE...');
437 |       const response = await this.client.request(
438 |         { method: 'tools/list', params: {} },
439 |         ListToolsResultSchema,
440 |       );
441 | 
442 |       // Map the array of tool objects to an array of tool names (strings)
443 |       this.availableTools = response.tools.map((tool) => tool.name);
444 | 
445 |       if (this.availableTools.length > 0) {
446 |         logger.debug(
447 |           `Discovered ${this.availableTools.length} tools from IDE: ${this.availableTools.join(', ')}`,
448 |         );
449 |       } else {
450 |         logger.debug(
451 |           'IDE supports tool discovery, but no tools are available.',
452 |         );
453 |       }
454 |     } catch (error) {
455 |       // It's okay if this fails, the IDE might not support it.
456 |       // Don't log an error if the method is not found, which is a common case.
457 |       if (
458 |         error instanceof Error &&
459 |         !error.message?.includes('Method not found')
460 |       ) {
461 |         logger.error(`Error discovering tools from IDE: ${error.message}`);
462 |       } else {
463 |         logger.debug('IDE does not support tool discovery.');
464 |       }
465 |       this.availableTools = [];
466 |     }
467 |   }
468 | 
469 |   private setState(
470 |     status: IDEConnectionStatus,
471 |     details?: string,
472 |     logToConsole = false,
473 |   ) {
474 |     const isAlreadyDisconnected =
475 |       this.state.status === IDEConnectionStatus.Disconnected &&
476 |       status === IDEConnectionStatus.Disconnected;
477 | 
478 |     // Only update details & log to console if the state wasn't already
479 |     // disconnected, so that the first detail message is preserved.
480 |     if (!isAlreadyDisconnected) {
481 |       this.state = { status, details };
482 |       for (const listener of this.statusListeners) {
483 |         listener(this.state);
484 |       }
485 |       if (details) {
486 |         if (logToConsole) {
487 |           logger.error(details);
488 |         } else {
489 |           // We only want to log disconnect messages to debug
490 |           // if they are not already being logged to the console.
491 |           logger.debug(details);
492 |         }
493 |       }
494 |     }
495 | 
496 |     if (status === IDEConnectionStatus.Disconnected) {
497 |       ideContextStore.clear();
498 |     }
499 |   }
500 | 
501 |   static validateWorkspacePath(
502 |     ideWorkspacePath: string | undefined,
503 |     cwd: string,
504 |   ): { isValid: boolean; error?: string } {
505 |     if (ideWorkspacePath === undefined) {
506 |       return {
507 |         isValid: false,
508 |         error: `Failed to connect to IDE companion extension. Please ensure the extension is running. To install the extension, run /ide install.`,
509 |       };
510 |     }
511 | 
512 |     if (ideWorkspacePath === '') {
513 |       return {
514 |         isValid: false,
515 |         error: `To use this feature, please open a workspace folder in your IDE and try again.`,
516 |       };
517 |     }
518 | 
519 |     const ideWorkspacePaths = ideWorkspacePath.split(path.delimiter);
520 |     const realCwd = getRealPath(cwd);
521 |     const isWithinWorkspace = ideWorkspacePaths.some((workspacePath) => {
522 |       const idePath = getRealPath(workspacePath);
523 |       return isSubpath(idePath, realCwd);
524 |     });
525 | 
526 |     if (!isWithinWorkspace) {
527 |       return {
528 |         isValid: false,
529 |         error: `Directory mismatch. Gemini CLI is running in a different location than the open workspace in the IDE. Please run the CLI from one of the following directories: ${ideWorkspacePaths.join(
530 |           ', ',
531 |         )}`,
532 |       };
533 |     }
534 |     return { isValid: true };
535 |   }
536 | 
537 |   private getPortFromEnv(): string | undefined {
538 |     const port = process.env['GEMINI_CLI_IDE_SERVER_PORT'];
539 |     if (!port) {
540 |       return undefined;
541 |     }
542 |     return port;
543 |   }
544 | 
545 |   private getStdioConfigFromEnv(): StdioConfig | undefined {
546 |     const command = process.env['GEMINI_CLI_IDE_SERVER_STDIO_COMMAND'];
547 |     if (!command) {
548 |       return undefined;
549 |     }
550 | 
551 |     const argsStr = process.env['GEMINI_CLI_IDE_SERVER_STDIO_ARGS'];
552 |     let args: string[] = [];
553 |     if (argsStr) {
554 |       try {
555 |         const parsedArgs = JSON.parse(argsStr);
556 |         if (Array.isArray(parsedArgs)) {
557 |           args = parsedArgs;
558 |         } else {
559 |           logger.error(
560 |             'GEMINI_CLI_IDE_SERVER_STDIO_ARGS must be a JSON array string.',
561 |           );
562 |         }
563 |       } catch (e) {
564 |         logger.error('Failed to parse GEMINI_CLI_IDE_SERVER_STDIO_ARGS:', e);
565 |       }
566 |     }
567 | 
568 |     return { command, args };
569 |   }
570 | 
571 |   private async getConnectionConfigFromFile(): Promise<
572 |     | (ConnectionConfig & { workspacePath?: string; ideInfo?: IdeInfo })
573 |     | undefined
574 |   > {
575 |     if (!this.ideProcessInfo) {
576 |       return undefined;
577 |     }
578 | 
579 |     // For backwards compatability
580 |     try {
581 |       const portFile = path.join(
582 |         os.tmpdir(),
583 |         `gemini-ide-server-${this.ideProcessInfo.pid}.json`,
584 |       );
585 |       const portFileContents = await fs.promises.readFile(portFile, 'utf8');
586 |       return JSON.parse(portFileContents);
587 |     } catch (_) {
588 |       // For newer extension versions, the file name matches the pattern
589 |       // /^gemini-ide-server-${pid}-\d+\.json$/. If multiple IDE
590 |       // windows are open, multiple files matching the pattern are expected to
591 |       // exist.
592 |     }
593 | 
594 |     const portFileDir = path.join(os.tmpdir(), 'gemini', 'ide');
595 |     let portFiles;
596 |     try {
597 |       portFiles = await fs.promises.readdir(portFileDir);
598 |     } catch (e) {
599 |       logger.debug('Failed to read IDE connection directory:', e);
600 |       return undefined;
601 |     }
602 | 
603 |     if (!portFiles) {
604 |       return undefined;
605 |     }
606 | 
607 |     const fileRegex = new RegExp(
608 |       `^gemini-ide-server-${this.ideProcessInfo.pid}-\\d+\\.json$`,
609 |     );
[TRUNCATED]
```

src/ide/ide-installer.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { vi } from 'vitest';
8 | 
9 | vi.mock('node:child_process', async (importOriginal) => {
10 |   const actual =
11 |     (await importOriginal()) as typeof import('node:child_process');
12 |   return {
13 |     ...actual,
14 |     execSync: vi.fn(),
15 |     spawnSync: vi.fn(() => ({ status: 0 })),
16 |   };
17 | });
18 | vi.mock('fs');
19 | vi.mock('os');
20 | 
21 | import { describe, it, expect, beforeEach, afterEach } from 'vitest';
22 | import { getIdeInstaller } from './ide-installer.js';
23 | import * as child_process from 'node:child_process';
24 | import * as fs from 'node:fs';
25 | import * as os from 'node:os';
26 | import * as path from 'node:path';
27 | import { IDE_DEFINITIONS, type IdeInfo } from './detect-ide.js';
28 | 
29 | describe('ide-installer', () => {
30 |   const HOME_DIR = '/home/user';
31 | 
32 |   beforeEach(() => {
33 |     vi.spyOn(os, 'homedir').mockReturnValue(HOME_DIR);
34 |   });
35 | 
36 |   afterEach(() => {
37 |     vi.restoreAllMocks();
38 |   });
39 | 
40 |   describe('getIdeInstaller', () => {
41 |     it.each([
42 |       { ide: IDE_DEFINITIONS.vscode },
43 |       { ide: IDE_DEFINITIONS.firebasestudio },
44 |     ])('returns a VsCodeInstaller for "$ide.name"', ({ ide }) => {
45 |       const installer = getIdeInstaller(ide);
46 | 
47 |       expect(installer).not.toBeNull();
48 |       expect(installer?.install).toEqual(expect.any(Function));
49 |     });
50 |   });
51 | 
52 |   describe('VsCodeInstaller', () => {
53 |     function setup({
54 |       ide = IDE_DEFINITIONS.vscode,
55 |       existsResult = false,
56 |       execSync = () => '',
57 |       platform = 'linux' as NodeJS.Platform,
58 |     }: {
59 |       ide?: IdeInfo;
60 |       existsResult?: boolean;
61 |       execSync?: () => string;
62 |       platform?: NodeJS.Platform;
63 |     } = {}) {
64 |       vi.spyOn(child_process, 'execSync').mockImplementation(execSync);
65 |       vi.spyOn(fs, 'existsSync').mockReturnValue(existsResult);
66 |       const installer = getIdeInstaller(ide, platform)!;
67 | 
68 |       return { installer };
69 |     }
70 | 
71 |     describe('install', () => {
72 |       it.each([
73 |         {
74 |           platform: 'win32' as NodeJS.Platform,
75 |           expectedLookupPaths: [
76 |             path.join('C:\\Program Files', 'Microsoft VS Code/bin/code.cmd'),
77 |             path.join(
78 |               HOME_DIR,
79 |               '/AppData/Local/Programs/Microsoft VS Code/bin/code.cmd',
80 |             ),
81 |           ],
82 |         },
83 |         {
84 |           platform: 'darwin' as NodeJS.Platform,
85 |           expectedLookupPaths: [
86 |             '/Applications/Visual Studio Code.app/Contents/Resources/app/bin/code',
87 |             path.join(HOME_DIR, 'Library/Application Support/Code/bin/code'),
88 |           ],
89 |         },
90 |         {
91 |           platform: 'linux' as NodeJS.Platform,
92 |           expectedLookupPaths: ['/usr/share/code/bin/code'],
93 |         },
94 |       ])(
95 |         'identifies the path to code cli on platform: $platform',
96 |         async ({ platform, expectedLookupPaths }) => {
97 |           const { installer } = setup({
98 |             platform,
99 |             execSync: () => {
100 |               throw new Error('Command not found'); // `code` is not in PATH
101 |             },
102 |           });
103 |           await installer.install();
104 |           for (const [idx, path] of expectedLookupPaths.entries()) {
105 |             expect(fs.existsSync).toHaveBeenNthCalledWith(idx + 1, path);
106 |           }
107 |         },
108 |       );
109 | 
110 |       it('installs the extension using code cli', async () => {
111 |         const { installer } = setup({
112 |           platform: 'linux',
113 |         });
114 |         await installer.install();
115 |         expect(child_process.spawnSync).toHaveBeenCalledWith(
116 |           'code',
117 |           [
118 |             '--install-extension',
119 |             'google.gemini-cli-vscode-ide-companion',
120 |             '--force',
121 |           ],
122 |           { stdio: 'pipe', shell: false },
123 |         );
124 |       });
125 | 
126 |       it('installs the extension using code cli on windows', async () => {
127 |         const { installer } = setup({
128 |           platform: 'win32',
129 |           execSync: () => 'C:\\Program Files\\Microsoft VS Code\\bin\\code.cmd',
130 |         });
131 |         await installer.install();
132 |         expect(child_process.spawnSync).toHaveBeenCalledWith(
133 |           'C:\\Program Files\\Microsoft VS Code\\bin\\code.cmd',
134 |           [
135 |             '--install-extension',
136 |             'google.gemini-cli-vscode-ide-companion',
137 |             '--force',
138 |           ],
139 |           { stdio: 'pipe', shell: true },
140 |         );
141 |       });
142 | 
143 |       it.each([
144 |         {
145 |           ide: IDE_DEFINITIONS.vscode,
146 |           expectedMessage:
147 |             'VS Code companion extension was installed successfully',
148 |         },
149 |         {
150 |           ide: IDE_DEFINITIONS.firebasestudio,
151 |           expectedMessage:
152 |             'Firebase Studio companion extension was installed successfully',
153 |         },
154 |       ])(
155 |         'returns that the cli was installed successfully',
156 |         async ({ ide, expectedMessage }) => {
157 |           const { installer } = setup({ ide });
158 |           const result = await installer.install();
159 |           expect(result.success).toBe(true);
160 |           expect(result.message).toContain(expectedMessage);
161 |         },
162 |       );
163 | 
164 |       it.each([
165 |         {
166 |           ide: IDE_DEFINITIONS.vscode,
167 |           expectedErr: 'VS Code CLI not found',
168 |         },
169 |         {
170 |           ide: IDE_DEFINITIONS.firebasestudio,
171 |           expectedErr: 'Firebase Studio CLI not found',
172 |         },
173 |       ])(
174 |         'should return a failure message if $ide is not installed',
175 |         async ({ ide, expectedErr }) => {
176 |           const { installer } = setup({
177 |             ide,
178 |             execSync: () => {
179 |               throw new Error('Command not found');
180 |             },
181 |             existsResult: false,
182 |           });
183 |           const result = await installer.install();
184 |           expect(result.success).toBe(false);
185 |           expect(result.message).toContain(expectedErr);
186 |         },
187 |       );
188 |     });
189 |   });
190 | });
```

src/ide/ide-installer.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as child_process from 'node:child_process';
8 | import * as process from 'node:process';
9 | import * as path from 'node:path';
10 | import * as fs from 'node:fs';
11 | import * as os from 'node:os';
12 | import { IDE_DEFINITIONS, type IdeInfo } from './detect-ide.js';
13 | import { GEMINI_CLI_COMPANION_EXTENSION_NAME } from './constants.js';
14 | 
15 | function getVsCodeCommand(platform: NodeJS.Platform = process.platform) {
16 |   return platform === 'win32' ? 'code.cmd' : 'code';
17 | }
18 | 
19 | export interface IdeInstaller {
20 |   install(): Promise<InstallResult>;
21 | }
22 | 
23 | export interface InstallResult {
24 |   success: boolean;
25 |   message: string;
26 | }
27 | 
28 | async function findVsCodeCommand(
29 |   platform: NodeJS.Platform = process.platform,
30 | ): Promise<string | null> {
31 |   // 1. Check PATH first.
32 |   const vscodeCommand = getVsCodeCommand(platform);
33 |   try {
34 |     if (platform === 'win32') {
35 |       const result = child_process
36 |         .execSync(`where.exe ${vscodeCommand}`)
37 |         .toString()
38 |         .trim();
39 |       // `where.exe` can return multiple paths. Return the first one.
40 |       const firstPath = result.split(/\r?\n/)[0];
41 |       if (firstPath) {
42 |         return firstPath;
43 |       }
44 |     } else {
45 |       child_process.execSync(`command -v ${vscodeCommand}`, {
46 |         stdio: 'ignore',
47 |       });
48 |       return vscodeCommand;
49 |     }
50 |   } catch {
51 |     // Not in PATH, continue to check common locations.
52 |   }
53 | 
54 |   // 2. Check common installation locations.
55 |   const locations: string[] = [];
56 |   const homeDir = os.homedir();
57 | 
58 |   if (platform === 'darwin') {
59 |     // macOS
60 |     locations.push(
61 |       '/Applications/Visual Studio Code.app/Contents/Resources/app/bin/code',
62 |       path.join(homeDir, 'Library/Application Support/Code/bin/code'),
63 |     );
64 |   } else if (platform === 'linux') {
65 |     // Linux
66 |     locations.push(
67 |       '/usr/share/code/bin/code',
68 |       '/snap/bin/code',
69 |       path.join(homeDir, '.local/share/code/bin/code'),
70 |     );
71 |   } else if (platform === 'win32') {
72 |     // Windows
73 |     locations.push(
74 |       path.join(
75 |         process.env['ProgramFiles'] || 'C:\\Program Files',
76 |         'Microsoft VS Code',
77 |         'bin',
78 |         'code.cmd',
79 |       ),
80 |       path.join(
81 |         homeDir,
82 |         'AppData',
83 |         'Local',
84 |         'Programs',
85 |         'Microsoft VS Code',
86 |         'bin',
87 |         'code.cmd',
88 |       ),
89 |     );
90 |   }
91 | 
92 |   for (const location of locations) {
93 |     if (fs.existsSync(location)) {
94 |       return location;
95 |     }
96 |   }
97 | 
98 |   return null;
99 | }
100 | 
101 | class VsCodeInstaller implements IdeInstaller {
102 |   private vsCodeCommand: Promise<string | null>;
103 | 
104 |   constructor(
105 |     readonly ideInfo: IdeInfo,
106 |     readonly platform = process.platform,
107 |   ) {
108 |     this.vsCodeCommand = findVsCodeCommand(platform);
109 |   }
110 | 
111 |   async install(): Promise<InstallResult> {
112 |     const commandPath = await this.vsCodeCommand;
113 |     if (!commandPath) {
114 |       return {
115 |         success: false,
116 |         message: `${this.ideInfo.displayName} CLI not found. Please ensure 'code' is in your system's PATH. For help, see https://code.visualstudio.com/docs/configure/command-line#_code-is-not-recognized-as-an-internal-or-external-command. You can also install the '${GEMINI_CLI_COMPANION_EXTENSION_NAME}' extension manually from the VS Code marketplace.`,
117 |       };
118 |     }
119 | 
120 |     try {
121 |       const result = child_process.spawnSync(
122 |         commandPath,
123 |         [
124 |           '--install-extension',
125 |           'google.gemini-cli-vscode-ide-companion',
126 |           '--force',
127 |         ],
128 |         { stdio: 'pipe', shell: this.platform === 'win32' },
129 |       );
130 | 
131 |       if (result.status !== 0) {
132 |         throw new Error(
133 |           `Failed to install extension: ${result.stderr?.toString()}`,
134 |         );
135 |       }
136 | 
137 |       return {
138 |         success: true,
139 |         message: `${this.ideInfo.displayName} companion extension was installed successfully.`,
140 |       };
141 |     } catch (_error) {
142 |       return {
143 |         success: false,
144 |         message: `Failed to install ${this.ideInfo.displayName} companion extension. Please try installing '${GEMINI_CLI_COMPANION_EXTENSION_NAME}' manually from the ${this.ideInfo.displayName} extension marketplace.`,
145 |       };
146 |     }
147 |   }
148 | }
149 | 
150 | export function getIdeInstaller(
151 |   ide: IdeInfo,
152 |   platform = process.platform,
153 | ): IdeInstaller | null {
154 |   switch (ide.name) {
155 |     case IDE_DEFINITIONS.vscode.name:
156 |     case IDE_DEFINITIONS.firebasestudio.name:
157 |       return new VsCodeInstaller(ide, platform);
158 |     default:
159 |       return null;
160 |   }
161 | }
```

src/ide/ideContext.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   IDE_MAX_OPEN_FILES,
9 |   IDE_MAX_SELECTED_TEXT_LENGTH,
10 | } from './constants.js';
11 | import { describe, it, expect, beforeEach, vi, afterEach } from 'vitest';
12 | import { IdeContextStore } from './ideContext.js';
13 | import {
14 |   type IdeContext,
15 |   FileSchema,
16 |   IdeContextSchema,
17 |   type File,
18 | } from './types.js';
19 | 
20 | describe('ideContext', () => {
21 |   describe('createIdeContextStore', () => {
22 |     let ideContextStore: IdeContextStore;
23 | 
24 |     beforeEach(() => {
25 |       // Create a fresh, isolated instance for each test
26 |       ideContextStore = new IdeContextStore();
27 |     });
28 | 
29 |     afterEach(() => {
30 |       vi.restoreAllMocks();
31 |     });
32 | 
33 |     it('should return undefined initially for ide context', () => {
34 |       expect(ideContextStore.get()).toBeUndefined();
35 |     });
36 | 
37 |     it('should set and retrieve the ide context', () => {
38 |       const testFile = {
39 |         workspaceState: {
40 |           openFiles: [
41 |             {
42 |               path: '/path/to/test/file.ts',
43 |               isActive: true,
44 |               selectedText: '1234',
45 |               timestamp: 0,
46 |             },
47 |           ],
48 |         },
49 |       };
50 | 
51 |       ideContextStore.set(testFile);
52 | 
53 |       const activeFile = ideContextStore.get();
54 |       expect(activeFile).toEqual(testFile);
55 |     });
56 | 
57 |     it('should update the ide context when called multiple times', () => {
58 |       const firstFile = {
59 |         workspaceState: {
60 |           openFiles: [
61 |             {
62 |               path: '/path/to/first.js',
63 |               isActive: true,
64 |               selectedText: '1234',
65 |               timestamp: 0,
66 |             },
67 |           ],
68 |         },
69 |       };
70 |       ideContextStore.set(firstFile);
71 | 
72 |       const secondFile = {
73 |         workspaceState: {
74 |           openFiles: [
75 |             {
76 |               path: '/path/to/second.py',
77 |               isActive: true,
78 |               cursor: { line: 20, character: 30 },
79 |               timestamp: 0,
80 |             },
81 |           ],
82 |         },
83 |       };
84 |       ideContextStore.set(secondFile);
85 | 
86 |       const activeFile = ideContextStore.get();
87 |       expect(activeFile).toEqual(secondFile);
88 |     });
89 | 
90 |     it('should handle empty string for file path', () => {
91 |       const testFile = {
92 |         workspaceState: {
93 |           openFiles: [
94 |             {
95 |               path: '',
96 |               isActive: true,
97 |               selectedText: '1234',
98 |               timestamp: 0,
99 |             },
100 |           ],
101 |         },
102 |       };
103 |       ideContextStore.set(testFile);
104 |       expect(ideContextStore.get()).toEqual(testFile);
105 |     });
106 | 
107 |     it('should notify subscribers when ide context changes', () => {
108 |       const subscriber1 = vi.fn();
109 |       const subscriber2 = vi.fn();
110 | 
111 |       ideContextStore.subscribe(subscriber1);
112 |       ideContextStore.subscribe(subscriber2);
113 | 
114 |       const testFile = {
115 |         workspaceState: {
116 |           openFiles: [
117 |             {
118 |               path: '/path/to/subscribed.ts',
119 |               isActive: true,
120 |               cursor: { line: 15, character: 25 },
121 |               timestamp: 0,
122 |             },
123 |           ],
124 |         },
125 |       };
126 |       ideContextStore.set(testFile);
127 | 
128 |       expect(subscriber1).toHaveBeenCalledTimes(1);
129 |       expect(subscriber1).toHaveBeenCalledWith(testFile);
130 |       expect(subscriber2).toHaveBeenCalledTimes(1);
131 |       expect(subscriber2).toHaveBeenCalledWith(testFile);
132 | 
133 |       // Test with another update
134 |       const newFile = {
135 |         workspaceState: {
136 |           openFiles: [
137 |             {
138 |               path: '/path/to/new.js',
139 |               isActive: true,
140 |               selectedText: '1234',
141 |               timestamp: 0,
142 |             },
143 |           ],
144 |         },
145 |       };
146 |       ideContextStore.set(newFile);
147 | 
148 |       expect(subscriber1).toHaveBeenCalledTimes(2);
149 |       expect(subscriber1).toHaveBeenCalledWith(newFile);
150 |       expect(subscriber2).toHaveBeenCalledTimes(2);
151 |       expect(subscriber2).toHaveBeenCalledWith(newFile);
152 |     });
153 | 
154 |     it('should stop notifying a subscriber after unsubscribe', () => {
155 |       const subscriber1 = vi.fn();
156 |       const subscriber2 = vi.fn();
157 | 
158 |       const unsubscribe1 = ideContextStore.subscribe(subscriber1);
159 |       ideContextStore.subscribe(subscriber2);
160 | 
161 |       ideContextStore.set({
162 |         workspaceState: {
163 |           openFiles: [
164 |             {
165 |               path: '/path/to/file1.txt',
166 |               isActive: true,
167 |               selectedText: '1234',
168 |               timestamp: 0,
169 |             },
170 |           ],
171 |         },
172 |       });
173 |       expect(subscriber1).toHaveBeenCalledTimes(1);
174 |       expect(subscriber2).toHaveBeenCalledTimes(1);
175 | 
176 |       unsubscribe1();
177 | 
178 |       ideContextStore.set({
179 |         workspaceState: {
180 |           openFiles: [
181 |             {
182 |               path: '/path/to/file2.txt',
183 |               isActive: true,
184 |               selectedText: '1234',
185 |               timestamp: 0,
186 |             },
187 |           ],
188 |         },
189 |       });
190 |       expect(subscriber1).toHaveBeenCalledTimes(1); // Should not be called again
191 |       expect(subscriber2).toHaveBeenCalledTimes(2);
192 |     });
193 | 
194 |     it('should clear the ide context', () => {
195 |       const testFile = {
196 |         workspaceState: {
197 |           openFiles: [
198 |             {
199 |               path: '/path/to/test/file.ts',
200 |               isActive: true,
201 |               selectedText: '1234',
202 |               timestamp: 0,
203 |             },
204 |           ],
205 |         },
206 |       };
207 | 
208 |       ideContextStore.set(testFile);
209 | 
210 |       expect(ideContextStore.get()).toEqual(testFile);
211 | 
212 |       ideContextStore.clear();
213 | 
214 |       expect(ideContextStore.get()).toBeUndefined();
215 |     });
216 | 
217 |     it('should set the context and notify subscribers when no workspaceState is present', () => {
218 |       const subscriber = vi.fn();
219 |       ideContextStore.subscribe(subscriber);
220 |       const context: IdeContext = {};
221 |       ideContextStore.set(context);
222 |       expect(ideContextStore.get()).toBe(context);
223 |       expect(subscriber).toHaveBeenCalledWith(context);
224 |     });
225 | 
226 |     it('should handle an empty openFiles array', () => {
227 |       const context: IdeContext = {
228 |         workspaceState: {
229 |           openFiles: [],
230 |         },
231 |       };
232 |       ideContextStore.set(context);
233 |       expect(ideContextStore.get()?.workspaceState?.openFiles).toEqual([]);
234 |     });
235 | 
236 |     it('should sort openFiles by timestamp in descending order', () => {
237 |       const context: IdeContext = {
238 |         workspaceState: {
239 |           openFiles: [
240 |             { path: 'file1.ts', timestamp: 100, isActive: false },
241 |             { path: 'file2.ts', timestamp: 300, isActive: true },
242 |             { path: 'file3.ts', timestamp: 200, isActive: false },
243 |           ],
244 |         },
245 |       };
246 |       ideContextStore.set(context);
247 |       const openFiles = ideContextStore.get()?.workspaceState?.openFiles;
248 |       expect(openFiles?.[0]?.path).toBe('file2.ts');
249 |       expect(openFiles?.[1]?.path).toBe('file3.ts');
250 |       expect(openFiles?.[2]?.path).toBe('file1.ts');
251 |     });
252 | 
253 |     it('should mark only the most recent file as active and clear other active files', () => {
254 |       const context: IdeContext = {
255 |         workspaceState: {
256 |           openFiles: [
257 |             {
258 |               path: 'file1.ts',
259 |               timestamp: 100,
260 |               isActive: true,
261 |               selectedText: 'hello',
262 |             },
263 |             {
264 |               path: 'file2.ts',
265 |               timestamp: 300,
266 |               isActive: true,
267 |               cursor: { line: 1, character: 1 },
268 |               selectedText: 'hello',
269 |             },
270 |             {
271 |               path: 'file3.ts',
272 |               timestamp: 200,
273 |               isActive: false,
274 |               selectedText: 'hello',
275 |             },
276 |           ],
277 |         },
278 |       };
279 |       ideContextStore.set(context);
280 |       const openFiles = ideContextStore.get()?.workspaceState?.openFiles;
281 |       expect(openFiles?.[0]?.isActive).toBe(true);
282 |       expect(openFiles?.[0]?.cursor).toBeDefined();
283 |       expect(openFiles?.[0]?.selectedText).toBeDefined();
284 | 
285 |       expect(openFiles?.[1]?.isActive).toBe(false);
286 |       expect(openFiles?.[1]?.cursor).toBeUndefined();
287 |       expect(openFiles?.[1]?.selectedText).toBeUndefined();
288 | 
289 |       expect(openFiles?.[2]?.isActive).toBe(false);
290 |       expect(openFiles?.[2]?.cursor).toBeUndefined();
291 |       expect(openFiles?.[2]?.selectedText).toBeUndefined();
292 |     });
293 | 
294 |     it('should truncate selectedText if it exceeds the max length', () => {
295 |       const longText = 'a'.repeat(IDE_MAX_SELECTED_TEXT_LENGTH + 10);
296 |       const context: IdeContext = {
297 |         workspaceState: {
298 |           openFiles: [
299 |             {
300 |               path: 'file1.ts',
301 |               timestamp: 100,
302 |               isActive: true,
303 |               selectedText: longText,
304 |             },
305 |           ],
306 |         },
307 |       };
308 |       ideContextStore.set(context);
309 |       const selectedText =
310 |         ideContextStore.get()?.workspaceState?.openFiles?.[0]?.selectedText;
311 |       expect(selectedText).toHaveLength(
312 |         IDE_MAX_SELECTED_TEXT_LENGTH + '... [TRUNCATED]'.length,
313 |       );
314 |       expect(selectedText?.endsWith('... [TRUNCATED]')).toBe(true);
315 |     });
316 | 
317 |     it('should not truncate selectedText if it is within the max length', () => {
318 |       const shortText = 'a'.repeat(IDE_MAX_SELECTED_TEXT_LENGTH);
319 |       const context: IdeContext = {
320 |         workspaceState: {
321 |           openFiles: [
322 |             {
323 |               path: 'file1.ts',
324 |               timestamp: 100,
325 |               isActive: true,
326 |               selectedText: shortText,
327 |             },
328 |           ],
329 |         },
330 |       };
331 |       ideContextStore.set(context);
332 |       const selectedText =
333 |         ideContextStore.get()?.workspaceState?.openFiles?.[0]?.selectedText;
334 |       expect(selectedText).toBe(shortText);
335 |     });
336 | 
337 |     it('should truncate the openFiles list if it exceeds the max length', () => {
338 |       const files: File[] = Array.from(
339 |         { length: IDE_MAX_OPEN_FILES + 5 },
340 |         (_, i) => ({
341 |           path: `file${i}.ts`,
342 |           timestamp: i,
343 |           isActive: false,
344 |         }),
345 |       );
346 |       const context: IdeContext = {
347 |         workspaceState: {
348 |           openFiles: files,
349 |         },
350 |       };
351 |       ideContextStore.set(context);
352 |       const openFiles = ideContextStore.get()?.workspaceState?.openFiles;
353 |       expect(openFiles).toHaveLength(IDE_MAX_OPEN_FILES);
354 |     });
355 |   });
356 | 
357 |   describe('FileSchema', () => {
358 |     it('should validate a file with only required fields', () => {
359 |       const file = {
360 |         path: '/path/to/file.ts',
361 |         timestamp: 12345,
362 |       };
363 |       const result = FileSchema.safeParse(file);
364 |       expect(result.success).toBe(true);
365 |     });
366 | 
367 |     it('should validate a file with all fields', () => {
368 |       const file = {
369 |         path: '/path/to/file.ts',
370 |         timestamp: 12345,
371 |         isActive: true,
372 |         selectedText: 'const x = 1;',
373 |         cursor: {
374 |           line: 10,
375 |           character: 20,
376 |         },
377 |       };
378 |       const result = FileSchema.safeParse(file);
379 |       expect(result.success).toBe(true);
380 |     });
381 | 
382 |     it('should fail validation if path is missing', () => {
383 |       const file = {
384 |         timestamp: 12345,
385 |       };
386 |       const result = FileSchema.safeParse(file);
387 |       expect(result.success).toBe(false);
388 |     });
389 | 
390 |     it('should fail validation if timestamp is missing', () => {
391 |       const file = {
392 |         path: '/path/to/file.ts',
393 |       };
394 |       const result = FileSchema.safeParse(file);
395 |       expect(result.success).toBe(false);
396 |     });
397 |   });
398 | 
399 |   describe('IdeContextSchema', () => {
400 |     it('should validate an empty context', () => {
401 |       const context = {};
402 |       const result = IdeContextSchema.safeParse(context);
403 |       expect(result.success).toBe(true);
404 |     });
405 | 
406 |     it('should validate a context with an empty workspaceState', () => {
407 |       const context = {
408 |         workspaceState: {},
409 |       };
410 |       const result = IdeContextSchema.safeParse(context);
411 |       expect(result.success).toBe(true);
412 |     });
413 | 
414 |     it('should validate a context with an empty openFiles array', () => {
415 |       const context = {
416 |         workspaceState: {
417 |           openFiles: [],
418 |         },
419 |       };
420 |       const result = IdeContextSchema.safeParse(context);
421 |       expect(result.success).toBe(true);
422 |     });
423 | 
424 |     it('should validate a context with a valid file', () => {
425 |       const context = {
426 |         workspaceState: {
427 |           openFiles: [
428 |             {
429 |               path: '/path/to/file.ts',
430 |               timestamp: 12345,
431 |             },
432 |           ],
433 |         },
434 |       };
435 |       const result = IdeContextSchema.safeParse(context);
436 |       expect(result.success).toBe(true);
437 |     });
438 | 
439 |     it('should fail validation with an invalid file', () => {
440 |       const context = {
441 |         workspaceState: {
442 |           openFiles: [
443 |             {
444 |               timestamp: 12345, // path is missing
445 |             },
446 |           ],
447 |         },
448 |       };
449 |       const result = IdeContextSchema.safeParse(context);
450 |       expect(result.success).toBe(false);
451 |     });
452 |   });
453 | });
```

src/ide/ideContext.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   IDE_MAX_OPEN_FILES,
9 |   IDE_MAX_SELECTED_TEXT_LENGTH,
10 | } from './constants.js';
11 | import type { IdeContext } from './types.js';
12 | 
13 | type IdeContextSubscriber = (ideContext?: IdeContext) => void;
14 | 
15 | export class IdeContextStore {
16 |   private ideContextState?: IdeContext;
17 |   private readonly subscribers = new Set<IdeContextSubscriber>();
18 | 
19 |   /**
20 |    * Notifies all registered subscribers about the current IDE context.
21 |    */
22 |   private notifySubscribers(): void {
23 |     for (const subscriber of this.subscribers) {
24 |       subscriber(this.ideContextState);
25 |     }
26 |   }
27 | 
28 |   /**
29 |    * Sets the IDE context and notifies all registered subscribers of the change.
30 |    * @param newIdeContext The new IDE context from the IDE.
31 |    */
32 |   set(newIdeContext: IdeContext): void {
33 |     const { workspaceState } = newIdeContext;
34 |     if (!workspaceState) {
35 |       this.ideContextState = newIdeContext;
36 |       this.notifySubscribers();
37 |       return;
38 |     }
39 | 
40 |     const { openFiles } = workspaceState;
41 | 
42 |     if (openFiles && openFiles.length > 0) {
43 |       // Sort by timestamp descending (newest first)
44 |       openFiles.sort((a, b) => b.timestamp - a.timestamp);
45 | 
46 |       // The most recent file is now at index 0.
47 |       const mostRecentFile = openFiles[0];
48 | 
49 |       // If the most recent file is not active, then no file is active.
50 |       if (!mostRecentFile.isActive) {
51 |         openFiles.forEach((file) => {
52 |           file.isActive = false;
53 |           file.cursor = undefined;
54 |           file.selectedText = undefined;
55 |         });
56 |       } else {
57 |         // The most recent file is active. Ensure it's the only one.
58 |         openFiles.forEach((file, index: number) => {
59 |           if (index !== 0) {
60 |             file.isActive = false;
61 |             file.cursor = undefined;
62 |             file.selectedText = undefined;
63 |           }
64 |         });
65 | 
66 |         // Truncate selected text in the active file
67 |         if (
68 |           mostRecentFile.selectedText &&
69 |           mostRecentFile.selectedText.length > IDE_MAX_SELECTED_TEXT_LENGTH
70 |         ) {
71 |           mostRecentFile.selectedText =
72 |             mostRecentFile.selectedText.substring(
73 |               0,
74 |               IDE_MAX_SELECTED_TEXT_LENGTH,
75 |             ) + '... [TRUNCATED]';
76 |         }
77 |       }
78 | 
79 |       // Truncate files list
80 |       if (openFiles.length > IDE_MAX_OPEN_FILES) {
81 |         workspaceState.openFiles = openFiles.slice(0, IDE_MAX_OPEN_FILES);
82 |       }
83 |     }
84 |     this.ideContextState = newIdeContext;
85 |     this.notifySubscribers();
86 |   }
87 | 
88 |   /**
89 |    * Clears the IDE context and notifies all registered subscribers of the change.
90 |    */
91 |   clear(): void {
92 |     this.ideContextState = undefined;
93 |     this.notifySubscribers();
94 |   }
95 | 
96 |   /**
97 |    * Retrieves the current IDE context.
98 |    * @returns The `IdeContext` object if a file is active; otherwise, `undefined`.
99 |    */
100 |   get(): IdeContext | undefined {
101 |     return this.ideContextState;
102 |   }
103 | 
104 |   /**
105 |    * Subscribes to changes in the IDE context.
106 |    *
107 |    * When the IDE context changes, the provided `subscriber` function will be called.
108 |    * Note: The subscriber is not called with the current value upon subscription.
109 |    *
110 |    * @param subscriber The function to be called when the IDE context changes.
111 |    * @returns A function that, when called, will unsubscribe the provided subscriber.
112 |    */
113 |   subscribe(subscriber: IdeContextSubscriber): () => void {
114 |     this.subscribers.add(subscriber);
115 |     return () => {
116 |       this.subscribers.delete(subscriber);
117 |     };
118 |   }
119 | }
120 | 
121 | /**
122 |  * The default, shared instance of the IDE context store for the application.
123 |  */
124 | export const ideContextStore = new IdeContextStore();
```

src/ide/process-utils.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   vi,
12 |   afterEach,
13 |   beforeEach,
14 |   type Mock,
15 | } from 'vitest';
16 | import { getIdeProcessInfo } from './process-utils.js';
17 | import os from 'node:os';
18 | 
19 | const mockedExec = vi.hoisted(() => vi.fn());
20 | vi.mock('node:util', () => ({
21 |   promisify: vi.fn().mockReturnValue(mockedExec),
22 | }));
23 | vi.mock('node:os', () => ({
24 |   default: {
25 |     platform: vi.fn(),
26 |   },
27 | }));
28 | 
29 | describe('getIdeProcessInfo', () => {
30 |   beforeEach(() => {
31 |     Object.defineProperty(process, 'pid', { value: 1000, configurable: true });
32 |     mockedExec.mockReset();
33 |   });
34 | 
35 |   afterEach(() => {
36 |     vi.restoreAllMocks();
37 |   });
38 | 
39 |   describe('on Unix', () => {
40 |     it('should traverse up to find the shell and return grandparent process info', async () => {
41 |       (os.platform as Mock).mockReturnValue('linux');
42 |       // process (1000) -> shell (800) -> IDE (700)
43 |       mockedExec
44 |         .mockResolvedValueOnce({ stdout: '800 /bin/bash' }) // pid 1000 -> ppid 800 (shell)
45 |         .mockResolvedValueOnce({ stdout: '700 /usr/lib/vscode/code' }) // pid 800 -> ppid 700 (IDE)
46 |         .mockResolvedValueOnce({ stdout: '700 /usr/lib/vscode/code' }); // get command for pid 700
47 | 
48 |       const result = await getIdeProcessInfo();
49 | 
50 |       expect(result).toEqual({ pid: 700, command: '/usr/lib/vscode/code' });
51 |     });
52 | 
53 |     it('should return parent process info if grandparent lookup fails', async () => {
54 |       (os.platform as Mock).mockReturnValue('linux');
55 |       mockedExec
56 |         .mockResolvedValueOnce({ stdout: '800 /bin/bash' }) // pid 1000 -> ppid 800 (shell)
57 |         .mockRejectedValueOnce(new Error('ps failed')) // lookup for ppid of 800 fails
58 |         .mockResolvedValueOnce({ stdout: '800 /bin/bash' }); // get command for pid 800
59 | 
60 |       const result = await getIdeProcessInfo();
61 |       expect(result).toEqual({ pid: 800, command: '/bin/bash' });
62 |     });
63 |   });
64 | 
65 |   describe('on Windows', () => {
66 |     it('should traverse up and find the great-grandchild of the root process', async () => {
67 |       (os.platform as Mock).mockReturnValue('win32');
68 |       const processInfoMap = new Map([
69 |         [
70 |           1000,
71 |           {
72 |             stdout:
73 |               '{"Name":"node.exe","ParentProcessId":900,"CommandLine":"node.exe"}',
74 |           },
75 |         ],
76 |         [
77 |           900,
78 |           {
79 |             stdout:
80 |               '{"Name":"powershell.exe","ParentProcessId":800,"CommandLine":"powershell.exe"}',
81 |           },
82 |         ],
83 |         [
84 |           800,
85 |           {
86 |             stdout:
87 |               '{"Name":"code.exe","ParentProcessId":700,"CommandLine":"code.exe"}',
88 |           },
89 |         ],
90 |         [
91 |           700,
92 |           {
93 |             stdout:
94 |               '{"Name":"wininit.exe","ParentProcessId":0,"CommandLine":"wininit.exe"}',
95 |           },
96 |         ],
97 |       ]);
98 |       mockedExec.mockImplementation((command: string) => {
99 |         const pidMatch = command.match(/ProcessId=(\d+)/);
100 |         if (pidMatch) {
101 |           const pid = parseInt(pidMatch[1], 10);
102 |           return Promise.resolve(processInfoMap.get(pid));
103 |         }
104 |         return Promise.reject(new Error('Invalid command for mock'));
105 |       });
106 | 
107 |       const result = await getIdeProcessInfo();
108 |       expect(result).toEqual({ pid: 900, command: 'powershell.exe' });
109 |     });
110 | 
111 |     it('should handle non-existent process gracefully', async () => {
112 |       (os.platform as Mock).mockReturnValue('win32');
113 |       mockedExec
114 |         .mockResolvedValueOnce({ stdout: '' }) // Non-existent PID returns empty due to -ErrorAction SilentlyContinue
115 |         .mockResolvedValueOnce({
116 |           stdout:
117 |             '{"Name":"fallback.exe","ParentProcessId":0,"CommandLine":"fallback.exe"}',
118 |         }); // Fallback call
119 | 
120 |       const result = await getIdeProcessInfo();
121 |       expect(result).toEqual({ pid: 1000, command: 'fallback.exe' });
122 |     });
123 | 
124 |     it('should handle malformed JSON output gracefully', async () => {
125 |       (os.platform as Mock).mockReturnValue('win32');
126 |       mockedExec
127 |         .mockResolvedValueOnce({ stdout: '{"invalid":json}' }) // Malformed JSON
128 |         .mockResolvedValueOnce({
129 |           stdout:
130 |             '{"Name":"fallback.exe","ParentProcessId":0,"CommandLine":"fallback.exe"}',
131 |         }); // Fallback call
132 | 
133 |       const result = await getIdeProcessInfo();
134 |       expect(result).toEqual({ pid: 1000, command: 'fallback.exe' });
135 |     });
136 | 
137 |     it('should handle PowerShell errors without crashing the process chain', async () => {
138 |       (os.platform as Mock).mockReturnValue('win32');
139 |       const processInfoMap = new Map([
140 |         [1000, { stdout: '' }], // First process doesn't exist (empty due to -ErrorAction)
141 |         [
142 |           1001,
143 |           {
144 |             stdout:
145 |               '{"Name":"parent.exe","ParentProcessId":800,"CommandLine":"parent.exe"}',
146 |           },
147 |         ],
148 |         [
149 |           800,
150 |           {
151 |             stdout:
152 |               '{"Name":"ide.exe","ParentProcessId":0,"CommandLine":"ide.exe"}',
153 |           },
154 |         ],
155 |       ]);
156 | 
157 |       // Mock the process.pid to test traversal with missing processes
158 |       Object.defineProperty(process, 'pid', {
159 |         value: 1001,
160 |         configurable: true,
161 |       });
162 | 
163 |       mockedExec.mockImplementation((command: string) => {
164 |         const pidMatch = command.match(/ProcessId=(\d+)/);
165 |         if (pidMatch) {
166 |           const pid = parseInt(pidMatch[1], 10);
167 |           return Promise.resolve(processInfoMap.get(pid) || { stdout: '' });
168 |         }
169 |         return Promise.reject(new Error('Invalid command for mock'));
170 |       });
171 | 
172 |       const result = await getIdeProcessInfo();
173 |       // Should return the current process command since traversal continues despite missing processes
174 |       expect(result).toEqual({ pid: 1001, command: 'parent.exe' });
175 | 
176 |       // Reset process.pid
177 |       Object.defineProperty(process, 'pid', {
178 |         value: 1000,
179 |         configurable: true,
180 |       });
181 |     });
182 | 
183 |     it('should handle partial JSON data with defaults', async () => {
184 |       (os.platform as Mock).mockReturnValue('win32');
185 |       mockedExec
186 |         .mockResolvedValueOnce({ stdout: '{"Name":"partial.exe"}' }) // Missing ParentProcessId, defaults to 0
187 |         .mockResolvedValueOnce({
188 |           stdout:
189 |             '{"Name":"root.exe","ParentProcessId":0,"CommandLine":"root.exe"}',
190 |         }); // Get grandparent info
191 | 
192 |       const result = await getIdeProcessInfo();
193 |       expect(result).toEqual({ pid: 1000, command: 'root.exe' });
194 |     });
195 |   });
196 | });
```

src/ide/process-utils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { exec } from 'node:child_process';
8 | import { promisify } from 'node:util';
9 | import os from 'node:os';
10 | import path from 'node:path';
11 | 
12 | const execAsync = promisify(exec);
13 | 
14 | const MAX_TRAVERSAL_DEPTH = 32;
15 | 
16 | /**
17 |  * Fetches the parent process ID, name, and command for a given process ID.
18 |  *
19 |  * @param pid The process ID to inspect.
20 |  * @returns A promise that resolves to the parent's PID, name, and command.
21 |  */
22 | async function getProcessInfo(pid: number): Promise<{
23 |   parentPid: number;
24 |   name: string;
25 |   command: string;
26 | }> {
27 |   try {
28 |     const platform = os.platform();
29 |     if (platform === 'win32') {
30 |       const powershellCommand = [
31 |         '$p = Get-CimInstance Win32_Process',
32 |         `-Filter 'ProcessId=${pid}'`,
33 |         '-ErrorAction SilentlyContinue;',
34 |         'if ($p) {',
35 |         '@{Name=$p.Name;ParentProcessId=$p.ParentProcessId;CommandLine=$p.CommandLine}',
36 |         '| ConvertTo-Json',
37 |         '}',
38 |       ].join(' ');
39 |       const { stdout } = await execAsync(`powershell "${powershellCommand}"`);
40 |       const output = stdout.trim();
41 |       if (!output) return { parentPid: 0, name: '', command: '' };
42 |       const {
43 |         Name = '',
44 |         ParentProcessId = 0,
45 |         CommandLine = '',
46 |       } = JSON.parse(output);
47 |       return {
48 |         parentPid: ParentProcessId,
49 |         name: Name,
50 |         command: CommandLine ?? '',
51 |       };
52 |     } else {
53 |       const command = `ps -o ppid=,command= -p ${pid}`;
54 |       const { stdout } = await execAsync(command);
55 |       const trimmedStdout = stdout.trim();
56 |       if (!trimmedStdout) {
57 |         return { parentPid: 0, name: '', command: '' };
58 |       }
59 |       const ppidString = trimmedStdout.split(/\s+/)[0];
60 |       const parentPid = parseInt(ppidString, 10);
61 |       const fullCommand = trimmedStdout.substring(ppidString.length).trim();
62 |       const processName = path.basename(fullCommand.split(' ')[0]);
63 |       return {
64 |         parentPid: isNaN(parentPid) ? 1 : parentPid,
65 |         name: processName,
66 |         command: fullCommand,
67 |       };
68 |     }
69 |   } catch (_e) {
70 |     console.debug(`Failed to get process info for pid ${pid}:`, _e);
71 |     return { parentPid: 0, name: '', command: '' };
72 |   }
73 | }
74 | 
75 | /**
76 |  * Finds the IDE process info on Unix-like systems.
77 |  *
78 |  * The strategy is to find the shell process that spawned the CLI, and then
79 |  * find that shell's parent process (the IDE). To get the true IDE process,
80 |  * we traverse one level higher to get the grandparent.
81 |  *
82 |  * @returns A promise that resolves to the PID and command of the IDE process.
83 |  */
84 | async function getIdeProcessInfoForUnix(): Promise<{
85 |   pid: number;
86 |   command: string;
87 | }> {
88 |   const shells = ['zsh', 'bash', 'sh', 'tcsh', 'csh', 'ksh', 'fish', 'dash'];
89 |   let currentPid = process.pid;
90 | 
91 |   for (let i = 0; i < MAX_TRAVERSAL_DEPTH; i++) {
92 |     try {
93 |       const { parentPid, name } = await getProcessInfo(currentPid);
94 | 
95 |       const isShell = shells.some((shell) => name === shell);
96 |       if (isShell) {
97 |         // The direct parent of the shell is often a utility process (e.g. VS
98 |         // Code's `ptyhost` process). To get the true IDE process, we need to
99 |         // traverse one level higher to get the grandparent.
100 |         let idePid = parentPid;
101 |         try {
102 |           const { parentPid: grandParentPid } = await getProcessInfo(parentPid);
103 |           if (grandParentPid > 1) {
104 |             idePid = grandParentPid;
105 |           }
106 |         } catch {
107 |           // Ignore if getting grandparent fails, we'll just use the parent pid.
108 |         }
109 |         const { command } = await getProcessInfo(idePid);
110 |         return { pid: idePid, command };
111 |       }
112 | 
113 |       if (parentPid <= 1) {
114 |         break; // Reached the root
115 |       }
116 |       currentPid = parentPid;
117 |     } catch {
118 |       // Process in chain died
119 |       break;
120 |     }
121 |   }
122 | 
123 |   const { command } = await getProcessInfo(currentPid);
124 |   return { pid: currentPid, command };
125 | }
126 | 
127 | /**
128 |  * Finds the IDE process info on Windows.
129 |  *
130 |  * The strategy is to find the great-grandchild of the root process.
131 |  *
132 |  * @returns A promise that resolves to the PID and command of the IDE process.
133 |  */
134 | async function getIdeProcessInfoForWindows(): Promise<{
135 |   pid: number;
136 |   command: string;
137 | }> {
138 |   let currentPid = process.pid;
139 |   let previousPid = process.pid;
140 | 
141 |   for (let i = 0; i < MAX_TRAVERSAL_DEPTH; i++) {
142 |     try {
143 |       const { parentPid } = await getProcessInfo(currentPid);
144 | 
145 |       if (parentPid > 0) {
146 |         try {
147 |           const { parentPid: grandParentPid } = await getProcessInfo(parentPid);
148 |           if (grandParentPid === 0) {
149 |             // We've found the grandchild of the root (`currentPid`). The IDE
150 |             // process is its child, which we've stored in `previousPid`.
151 |             const { command } = await getProcessInfo(previousPid);
152 |             return { pid: previousPid, command };
153 |           }
154 |         } catch {
155 |           // getting grandparent failed, proceed
156 |         }
157 |       }
158 | 
159 |       if (parentPid <= 0) {
160 |         break; // Reached the root
161 |       }
162 |       previousPid = currentPid;
163 |       currentPid = parentPid;
164 |     } catch {
165 |       // Process in chain died
166 |       break;
167 |     }
168 |   }
169 |   const { command } = await getProcessInfo(currentPid);
170 |   return { pid: currentPid, command };
171 | }
172 | 
173 | /**
174 |  * Traverses up the process tree to find the process ID and command of the IDE.
175 |  *
176 |  * This function uses different strategies depending on the operating system
177 |  * to identify the main application process (e.g., the main VS Code window
178 |  * process).
179 |  *
180 |  * If the IDE process cannot be reliably identified, it will return the
181 |  * top-level ancestor process ID and command as a fallback.
182 |  *
183 |  * @returns A promise that resolves to the PID and command of the IDE process.
184 |  */
185 | export async function getIdeProcessInfo(): Promise<{
186 |   pid: number;
187 |   command: string;
188 | }> {
189 |   const platform = os.platform();
190 | 
191 |   if (platform === 'win32') {
192 |     return getIdeProcessInfoForWindows();
193 |   }
194 | 
195 |   return getIdeProcessInfoForUnix();
196 | }
```

src/ide/types.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { z } from 'zod';
8 | 
9 | /**
10 |  * A file that is open in the IDE.
11 |  */
12 | export const FileSchema = z.object({
13 |   /**
14 |    * The absolute path to the file.
15 |    */
16 |   path: z.string(),
17 |   /**
18 |    * The unix timestamp of when the file was last focused.
19 |    */
20 |   timestamp: z.number(),
21 |   /**
22 |    * Whether the file is the currently active file. Only one file can be active at a time.
23 |    */
24 |   isActive: z.boolean().optional(),
25 |   /**
26 |    * The text that is currently selected in the active file.
27 |    */
28 |   selectedText: z.string().optional(),
29 |   /**
30 |    * The cursor position in the active file.
31 |    */
32 |   cursor: z
33 |     .object({
34 |       /**
35 |        * The 1-based line number.
36 |        */
37 |       line: z.number(),
38 |       /**
39 |        * The 1-based character offset.
40 |        */
41 |       character: z.number(),
42 |     })
43 |     .optional(),
44 | });
45 | export type File = z.infer<typeof FileSchema>;
46 | 
47 | /**
48 |  * The context of the IDE.
49 |  */
50 | export const IdeContextSchema = z.object({
51 |   workspaceState: z
52 |     .object({
53 |       /**
54 |        * The list of files that are currently open.
55 |        */
56 |       openFiles: z.array(FileSchema).optional(),
57 |       /**
58 |        * Whether the workspace is trusted.
59 |        */
60 |       isTrusted: z.boolean().optional(),
61 |     })
62 |     .optional(),
63 | });
64 | export type IdeContext = z.infer<typeof IdeContextSchema>;
65 | 
66 | /**
67 |  * A notification that the IDE context has been updated.
68 |  */
69 | export const IdeContextNotificationSchema = z.object({
70 |   jsonrpc: z.literal('2.0'),
71 |   method: z.literal('ide/contextUpdate'),
72 |   params: IdeContextSchema,
73 | });
74 | 
75 | /**
76 |  * A notification that a diff has been accepted in the IDE.
77 |  */
78 | export const IdeDiffAcceptedNotificationSchema = z.object({
79 |   jsonrpc: z.literal('2.0'),
80 |   method: z.literal('ide/diffAccepted'),
81 |   params: z.object({
82 |     /**
83 |      * The absolute path to the file that was diffed.
84 |      */
85 |     filePath: z.string(),
86 |     /**
87 |      * The full content of the file after the diff was accepted, which includes any manual edits the user may have made.
88 |      */
89 |     content: z.string(),
90 |   }),
91 | });
92 | 
93 | /**
94 |  * A notification that a diff has been rejected in the IDE.
95 |  */
96 | export const IdeDiffRejectedNotificationSchema = z.object({
97 |   jsonrpc: z.literal('2.0'),
98 |   method: z.literal('ide/diffRejected'),
99 |   params: z.object({
100 |     /**
101 |      * The absolute path to the file that was diffed.
102 |      */
103 |     filePath: z.string(),
104 |   }),
105 | });
106 | 
107 | /**
108 |  * This is defineded for backwards compatability only. Newer extension versions
109 |  * will only send IdeDiffRejectedNotificationSchema.
110 |  *
111 |  * A notification that a diff has been closed in the IDE.
112 |  */
113 | export const IdeDiffClosedNotificationSchema = z.object({
114 |   jsonrpc: z.literal('2.0'),
115 |   method: z.literal('ide/diffClosed'),
116 |   params: z.object({
117 |     filePath: z.string(),
118 |     content: z.string().optional(),
119 |   }),
120 | });
121 | 
122 | /**
123 |  * The request to open a diff view in the IDE.
124 |  */
125 | export const OpenDiffRequestSchema = z.object({
126 |   /**
127 |    * The absolute path to the file to be diffed.
128 |    */
129 |   filePath: z.string(),
130 |   /**
131 |    * The proposed new content for the file.
132 |    */
133 |   newContent: z.string(),
134 | });
135 | 
136 | /**
137 |  * The request to close a diff view in the IDE.
138 |  */
139 | export const CloseDiffRequestSchema = z.object({
140 |   /**
141 |    * The absolute path to the file to be diffed.
142 |    */
143 |   filePath: z.string(),
144 |   /**
145 |    * @deprecated
146 |    */
147 |   suppressNotification: z.boolean().optional(),
148 | });
```

src/mcp/google-auth-provider.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { GoogleAuth } from 'google-auth-library';
8 | import { GoogleCredentialProvider } from './google-auth-provider.js';
9 | import type { Mock } from 'vitest';
10 | import { vi, describe, beforeEach, it, expect } from 'vitest';
11 | import type { MCPServerConfig } from '../config/config.js';
12 | 
13 | vi.mock('google-auth-library');
14 | 
15 | describe('GoogleCredentialProvider', () => {
16 |   const validConfig = {
17 |     url: 'https://test.googleapis.com',
18 |     oauth: {
19 |       scopes: ['scope1', 'scope2'],
20 |     },
21 |   } as MCPServerConfig;
22 | 
23 |   it('should throw an error if no scopes are provided', () => {
24 |     const config = {
25 |       url: 'https://test.googleapis.com',
26 |     } as MCPServerConfig;
27 |     expect(() => new GoogleCredentialProvider(config)).toThrow(
28 |       'Scopes must be provided in the oauth config for Google Credentials provider',
29 |     );
30 |   });
31 | 
32 |   it('should use scopes from the config if provided', () => {
33 |     new GoogleCredentialProvider(validConfig);
34 |     expect(GoogleAuth).toHaveBeenCalledWith({
35 |       scopes: ['scope1', 'scope2'],
36 |     });
37 |   });
38 | 
39 |   it('should throw an error for a non-allowlisted host', () => {
40 |     const config = {
41 |       url: 'https://example.com',
42 |       oauth: {
43 |         scopes: ['scope1', 'scope2'],
44 |       },
45 |     } as MCPServerConfig;
46 |     expect(() => new GoogleCredentialProvider(config)).toThrow(
47 |       'Host "example.com" is not an allowed host for Google Credential provider.',
48 |     );
49 |   });
50 | 
51 |   it('should allow luci.app', () => {
52 |     const config = {
53 |       url: 'https://luci.app',
54 |       oauth: {
55 |         scopes: ['scope1', 'scope2'],
56 |       },
57 |     } as MCPServerConfig;
58 |     new GoogleCredentialProvider(config);
59 |   });
60 | 
61 |   it('should allow sub.luci.app', () => {
62 |     const config = {
63 |       url: 'https://sub.luci.app',
64 |       oauth: {
65 |         scopes: ['scope1', 'scope2'],
66 |       },
67 |     } as MCPServerConfig;
68 |     new GoogleCredentialProvider(config);
69 |   });
70 | 
71 |   it('should not allow googleapis.com without a subdomain', () => {
72 |     const config = {
73 |       url: 'https://googleapis.com',
74 |       oauth: {
75 |         scopes: ['scope1', 'scope2'],
76 |       },
77 |     } as MCPServerConfig;
78 |     expect(() => new GoogleCredentialProvider(config)).toThrow(
79 |       'Host "googleapis.com" is not an allowed host for Google Credential provider.',
80 |     );
81 |   });
82 | 
83 |   describe('with provider instance', () => {
84 |     let provider: GoogleCredentialProvider;
85 | 
86 |     beforeEach(() => {
87 |       provider = new GoogleCredentialProvider(validConfig);
88 |       vi.clearAllMocks();
89 |     });
90 | 
91 |     it('should return credentials', async () => {
92 |       const mockClient = {
93 |         getAccessToken: vi.fn().mockResolvedValue({ token: 'test-token' }),
94 |       };
95 |       (GoogleAuth.prototype.getClient as Mock).mockResolvedValue(mockClient);
96 | 
97 |       const credentials = await provider.tokens();
98 | 
99 |       expect(credentials?.access_token).toBe('test-token');
100 |     });
101 | 
102 |     it('should return undefined if access token is not available', async () => {
103 |       const mockClient = {
104 |         getAccessToken: vi.fn().mockResolvedValue({ token: null }),
105 |       };
106 |       (GoogleAuth.prototype.getClient as Mock).mockResolvedValue(mockClient);
107 | 
108 |       const credentials = await provider.tokens();
109 |       expect(credentials).toBeUndefined();
110 |     });
111 |   });
112 | });
```

src/mcp/google-auth-provider.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { OAuthClientProvider } from '@modelcontextprotocol/sdk/client/auth.js';
8 | import type {
9 |   OAuthClientInformation,
10 |   OAuthClientInformationFull,
11 |   OAuthClientMetadata,
12 |   OAuthTokens,
13 | } from '@modelcontextprotocol/sdk/shared/auth.js';
14 | import { GoogleAuth } from 'google-auth-library';
15 | import type { MCPServerConfig } from '../config/config.js';
16 | 
17 | const ALLOWED_HOSTS = [/^.+\.googleapis\.com$/, /^(.*\.)?luci\.app$/];
18 | 
19 | export class GoogleCredentialProvider implements OAuthClientProvider {
20 |   private readonly auth: GoogleAuth;
21 | 
22 |   // Properties required by OAuthClientProvider, with no-op values
23 |   readonly redirectUrl = '';
24 |   readonly clientMetadata: OAuthClientMetadata = {
25 |     client_name: 'Gemini CLI (Google ADC)',
26 |     redirect_uris: [],
27 |     grant_types: [],
28 |     response_types: [],
29 |     token_endpoint_auth_method: 'none',
30 |   };
31 |   private _clientInformation?: OAuthClientInformationFull;
32 | 
33 |   constructor(private readonly config?: MCPServerConfig) {
34 |     const url = this.config?.url || this.config?.httpUrl;
35 |     if (!url) {
36 |       throw new Error(
37 |         'URL must be provided in the config for Google Credentials provider',
38 |       );
39 |     }
40 | 
41 |     const hostname = new URL(url).hostname;
42 |     if (!ALLOWED_HOSTS.some((pattern) => pattern.test(hostname))) {
43 |       throw new Error(
44 |         `Host "${hostname}" is not an allowed host for Google Credential provider.`,
45 |       );
46 |     }
47 | 
48 |     const scopes = this.config?.oauth?.scopes;
49 |     if (!scopes || scopes.length === 0) {
50 |       throw new Error(
51 |         'Scopes must be provided in the oauth config for Google Credentials provider',
52 |       );
53 |     }
54 |     this.auth = new GoogleAuth({
55 |       scopes,
56 |     });
57 |   }
58 | 
59 |   clientInformation(): OAuthClientInformation | undefined {
60 |     return this._clientInformation;
61 |   }
62 | 
63 |   saveClientInformation(clientInformation: OAuthClientInformationFull): void {
64 |     this._clientInformation = clientInformation;
65 |   }
66 | 
67 |   async tokens(): Promise<OAuthTokens | undefined> {
68 |     const client = await this.auth.getClient();
69 |     const accessTokenResponse = await client.getAccessToken();
70 | 
71 |     if (!accessTokenResponse.token) {
72 |       console.error('Failed to get access token from Google ADC');
73 |       return undefined;
74 |     }
75 | 
76 |     const tokens: OAuthTokens = {
77 |       access_token: accessTokenResponse.token,
78 |       token_type: 'Bearer',
79 |     };
80 |     return tokens;
81 |   }
82 | 
83 |   saveTokens(_tokens: OAuthTokens): void {
84 |     // No-op, ADC manages tokens.
85 |   }
86 | 
87 |   redirectToAuthorization(_authorizationUrl: URL): void {
88 |     // No-op
89 |   }
90 | 
91 |   saveCodeVerifier(_codeVerifier: string): void {
92 |     // No-op
93 |   }
94 | 
95 |   codeVerifier(): string {
96 |     // No-op
97 |     return '';
98 |   }
99 | }
```

src/mcp/oauth-provider.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { vi } from 'vitest';
8 | 
9 | // Mock dependencies AT THE TOP
10 | const mockOpenBrowserSecurely = vi.hoisted(() => vi.fn());
11 | vi.mock('../utils/secure-browser-launcher.js', () => ({
12 |   openBrowserSecurely: mockOpenBrowserSecurely,
13 | }));
14 | vi.mock('node:crypto');
15 | vi.mock('./oauth-token-storage.js', () => {
16 |   const mockSaveToken = vi.fn();
17 |   const mockGetCredentials = vi.fn();
18 |   const mockIsTokenExpired = vi.fn();
19 |   const mockdeleteCredentials = vi.fn();
20 | 
21 |   return {
22 |     MCPOAuthTokenStorage: vi.fn(() => ({
23 |       saveToken: mockSaveToken,
24 |       getCredentials: mockGetCredentials,
25 |       isTokenExpired: mockIsTokenExpired,
26 |       deleteCredentials: mockdeleteCredentials,
27 |     })),
28 |   };
29 | });
30 | 
31 | import { describe, it, expect, beforeEach, afterEach } from 'vitest';
32 | import * as http from 'node:http';
33 | import * as crypto from 'node:crypto';
34 | import type {
35 |   MCPOAuthConfig,
36 |   OAuthTokenResponse,
37 |   OAuthClientRegistrationResponse,
38 | } from './oauth-provider.js';
39 | import { MCPOAuthProvider } from './oauth-provider.js';
40 | import type { OAuthToken } from './token-storage/types.js';
41 | import { MCPOAuthTokenStorage } from './oauth-token-storage.js';
42 | import type {
43 |   OAuthAuthorizationServerMetadata,
44 |   OAuthProtectedResourceMetadata,
45 | } from './oauth-utils.js';
46 | 
47 | // Mock fetch globally
48 | const mockFetch = vi.fn();
49 | global.fetch = mockFetch;
50 | 
51 | // Helper function to create mock fetch responses with proper headers
52 | const createMockResponse = (options: {
53 |   ok: boolean;
54 |   status?: number;
55 |   contentType?: string;
56 |   text?: string | (() => Promise<string>);
57 |   json?: unknown | (() => Promise<unknown>);
58 | }) => {
59 |   const response: {
60 |     ok: boolean;
61 |     status?: number;
62 |     headers: {
63 |       get: (name: string) => string | null;
64 |     };
65 |     text?: () => Promise<string>;
66 |     json?: () => Promise<unknown>;
67 |   } = {
68 |     ok: options.ok,
69 |     headers: {
70 |       get: (name: string) => {
71 |         if (name.toLowerCase() === 'content-type') {
72 |           return options.contentType || null;
73 |         }
74 |         return null;
75 |       },
76 |     },
77 |   };
78 | 
79 |   if (options.status !== undefined) {
80 |     response.status = options.status;
81 |   }
82 | 
83 |   if (options.text !== undefined) {
84 |     response.text =
85 |       typeof options.text === 'string'
86 |         ? () => Promise.resolve(options.text as string)
87 |         : (options.text as () => Promise<string>);
88 |   }
89 | 
90 |   if (options.json !== undefined) {
91 |     response.json =
92 |       typeof options.json === 'function'
93 |         ? (options.json as () => Promise<unknown>)
94 |         : () => Promise.resolve(options.json);
95 |   }
96 | 
97 |   return response;
98 | };
99 | 
100 | // Define a reusable mock server with .listen, .close, and .on methods
101 | const mockHttpServer = {
102 |   listen: vi.fn(),
103 |   close: vi.fn(),
104 |   on: vi.fn(),
105 | };
106 | vi.mock('node:http', () => ({
107 |   createServer: vi.fn(() => mockHttpServer),
108 | }));
109 | 
110 | describe('MCPOAuthProvider', () => {
111 |   const mockConfig: MCPOAuthConfig = {
112 |     enabled: true,
113 |     clientId: 'test-client-id',
114 |     clientSecret: 'test-client-secret',
115 |     authorizationUrl: 'https://auth.example.com/authorize',
116 |     tokenUrl: 'https://auth.example.com/token',
117 |     scopes: ['read', 'write'],
118 |     redirectUri: 'http://localhost:7777/oauth/callback',
119 |     audiences: ['https://api.example.com'],
120 |   };
121 | 
122 |   const mockToken: OAuthToken = {
123 |     accessToken: 'access_token_123',
124 |     refreshToken: 'refresh_token_456',
125 |     tokenType: 'Bearer',
126 |     scope: 'read write',
127 |     expiresAt: Date.now() + 3600000,
128 |   };
129 | 
130 |   const mockTokenResponse: OAuthTokenResponse = {
131 |     access_token: 'access_token_123',
132 |     token_type: 'Bearer',
133 |     expires_in: 3600,
134 |     refresh_token: 'refresh_token_456',
135 |     scope: 'read write',
136 |   };
137 | 
138 |   beforeEach(() => {
139 |     vi.clearAllMocks();
140 |     mockOpenBrowserSecurely.mockClear();
141 |     vi.spyOn(console, 'log').mockImplementation(() => {});
142 |     vi.spyOn(console, 'warn').mockImplementation(() => {});
143 |     vi.spyOn(console, 'error').mockImplementation(() => {});
144 | 
145 |     // Mock crypto functions
146 |     vi.mocked(crypto.randomBytes).mockImplementation((size: number) => {
147 |       if (size === 32) return Buffer.from('code_verifier_mock_32_bytes_long');
148 |       if (size === 16) return Buffer.from('state_mock_16_by');
149 |       return Buffer.alloc(size);
150 |     });
151 | 
152 |     vi.mocked(crypto.createHash).mockReturnValue({
153 |       update: vi.fn().mockReturnThis(),
154 |       digest: vi.fn().mockReturnValue('code_challenge_mock'),
155 |     } as unknown as crypto.Hash);
156 | 
157 |     // Mock randomBytes to return predictable values for state
158 |     vi.mocked(crypto.randomBytes).mockImplementation((size) => {
159 |       if (size === 32) {
160 |         return Buffer.from('mock_code_verifier_32_bytes_long_string');
161 |       } else if (size === 16) {
162 |         return Buffer.from('mock_state_16_bytes');
163 |       }
164 |       return Buffer.alloc(size);
165 |     });
166 | 
167 |     // Mock token storage
168 |     const tokenStorage = new MCPOAuthTokenStorage();
169 |     vi.mocked(tokenStorage.saveToken).mockResolvedValue(undefined);
170 |     vi.mocked(tokenStorage.getCredentials).mockResolvedValue(null);
171 |   });
172 | 
173 |   afterEach(() => {
174 |     vi.restoreAllMocks();
175 |   });
176 | 
177 |   describe('authenticate', () => {
178 |     it('should perform complete OAuth flow with PKCE', async () => {
179 |       // Mock HTTP server callback
180 |       let callbackHandler: unknown;
181 |       vi.mocked(http.createServer).mockImplementation((handler) => {
182 |         callbackHandler = handler;
183 |         return mockHttpServer as unknown as http.Server;
184 |       });
185 | 
186 |       mockHttpServer.listen.mockImplementation((port, callback) => {
187 |         callback?.();
188 |         // Simulate OAuth callback
189 |         setTimeout(() => {
190 |           const mockReq = {
191 |             url: '/oauth/callback?code=auth_code_123&state=bW9ja19zdGF0ZV8xNl9ieXRlcw',
192 |           };
193 |           const mockRes = {
194 |             writeHead: vi.fn(),
195 |             end: vi.fn(),
196 |           };
197 |           (callbackHandler as (req: unknown, res: unknown) => void)(
198 |             mockReq,
199 |             mockRes,
200 |           );
201 |         }, 10);
202 |       });
203 | 
204 |       // Mock token exchange
205 |       mockFetch.mockResolvedValueOnce(
206 |         createMockResponse({
207 |           ok: true,
208 |           contentType: 'application/json',
209 |           text: JSON.stringify(mockTokenResponse),
210 |           json: mockTokenResponse,
211 |         }),
212 |       );
213 | 
214 |       const authProvider = new MCPOAuthProvider();
215 |       const result = await authProvider.authenticate('test-server', mockConfig);
216 | 
217 |       expect(result).toEqual({
218 |         accessToken: 'access_token_123',
219 |         refreshToken: 'refresh_token_456',
220 |         tokenType: 'Bearer',
221 |         scope: 'read write',
222 |         expiresAt: expect.any(Number),
223 |       });
224 | 
225 |       expect(mockOpenBrowserSecurely).toHaveBeenCalledWith(
226 |         expect.stringContaining('authorize'),
227 |       );
228 |       const tokenStorage = new MCPOAuthTokenStorage();
229 |       expect(tokenStorage.saveToken).toHaveBeenCalledWith(
230 |         'test-server',
231 |         expect.objectContaining({ accessToken: 'access_token_123' }),
232 |         'test-client-id',
233 |         'https://auth.example.com/token',
234 |         undefined,
235 |       );
236 |     });
237 | 
238 |     it('should handle OAuth discovery when no authorization URL provided', async () => {
239 |       // Use a mutable config object
240 |       const configWithoutAuth: MCPOAuthConfig = {
241 |         ...mockConfig,
242 |         clientId: 'test-client-id',
243 |         clientSecret: 'test-client-secret',
244 |       };
245 |       delete configWithoutAuth.authorizationUrl;
246 |       delete configWithoutAuth.tokenUrl;
247 | 
248 |       const mockResourceMetadata = {
249 |         authorization_servers: ['https://discovered.auth.com'],
250 |       };
251 | 
252 |       const mockAuthServerMetadata = {
253 |         authorization_endpoint: 'https://discovered.auth.com/authorize',
254 |         token_endpoint: 'https://discovered.auth.com/token',
255 |         scopes_supported: ['read', 'write'],
256 |       };
257 | 
258 |       // Mock HEAD request for WWW-Authenticate check
259 |       mockFetch
260 |         .mockResolvedValueOnce(
261 |           createMockResponse({
262 |             ok: true,
263 |             status: 200,
264 |           }),
265 |         )
266 |         .mockResolvedValueOnce(
267 |           createMockResponse({
268 |             ok: true,
269 |             contentType: 'application/json',
270 |             text: JSON.stringify(mockResourceMetadata),
271 |             json: mockResourceMetadata,
272 |           }),
273 |         )
274 |         .mockResolvedValueOnce(
275 |           createMockResponse({
276 |             ok: true,
277 |             contentType: 'application/json',
278 |             text: JSON.stringify(mockAuthServerMetadata),
279 |             json: mockAuthServerMetadata,
280 |           }),
281 |         );
282 | 
283 |       // Setup callback handler
284 |       let callbackHandler: unknown;
285 |       vi.mocked(http.createServer).mockImplementation((handler) => {
286 |         callbackHandler = handler;
287 |         return mockHttpServer as unknown as http.Server;
288 |       });
289 | 
290 |       mockHttpServer.listen.mockImplementation((port, callback) => {
291 |         callback?.();
292 |         setTimeout(() => {
293 |           const mockReq = {
294 |             url: '/oauth/callback?code=auth_code_123&state=bW9ja19zdGF0ZV8xNl9ieXRlcw',
295 |           };
296 |           const mockRes = {
297 |             writeHead: vi.fn(),
298 |             end: vi.fn(),
299 |           };
300 |           (callbackHandler as (req: unknown, res: unknown) => void)(
301 |             mockReq,
302 |             mockRes,
303 |           );
304 |         }, 10);
305 |       });
306 | 
307 |       // Mock token exchange with discovered endpoint
308 |       mockFetch.mockResolvedValueOnce(
309 |         createMockResponse({
310 |           ok: true,
311 |           contentType: 'application/json',
312 |           text: JSON.stringify(mockTokenResponse),
313 |           json: mockTokenResponse,
314 |         }),
315 |       );
316 | 
317 |       const authProvider = new MCPOAuthProvider();
318 |       const result = await authProvider.authenticate(
319 |         'test-server',
320 |         configWithoutAuth,
321 |         'https://api.example.com',
322 |       );
323 | 
324 |       expect(result).toBeDefined();
325 |       expect(mockFetch).toHaveBeenCalledWith(
326 |         'https://discovered.auth.com/token',
327 |         expect.objectContaining({
328 |           method: 'POST',
329 |           headers: expect.objectContaining({
330 |             'Content-Type': 'application/x-www-form-urlencoded',
331 |           }),
332 |         }),
333 |       );
334 |     });
335 | 
336 |     it('should perform dynamic client registration when no client ID is provided but registration URL is provided', async () => {
337 |       const configWithoutClient: MCPOAuthConfig = {
338 |         ...mockConfig,
339 |         registrationUrl: 'https://auth.example.com/register',
340 |       };
341 |       delete configWithoutClient.clientId;
342 | 
343 |       const mockRegistrationResponse: OAuthClientRegistrationResponse = {
344 |         client_id: 'dynamic_client_id',
345 |         client_secret: 'dynamic_client_secret',
346 |         redirect_uris: ['http://localhost:7777/oauth/callback'],
347 |         grant_types: ['authorization_code', 'refresh_token'],
348 |         response_types: ['code'],
349 |         token_endpoint_auth_method: 'none',
350 |       };
351 | 
352 |       mockFetch.mockResolvedValueOnce(
353 |         createMockResponse({
354 |           ok: true,
355 |           contentType: 'application/json',
356 |           text: JSON.stringify(mockRegistrationResponse),
357 |           json: mockRegistrationResponse,
358 |         }),
359 |       );
360 | 
361 |       // Setup callback handler
362 |       let callbackHandler: unknown;
363 |       vi.mocked(http.createServer).mockImplementation((handler) => {
364 |         callbackHandler = handler;
365 |         return mockHttpServer as unknown as http.Server;
366 |       });
367 | 
368 |       mockHttpServer.listen.mockImplementation((port, callback) => {
369 |         callback?.();
370 |         setTimeout(() => {
371 |           const mockReq = {
372 |             url: '/oauth/callback?code=auth_code_123&state=bW9ja19zdGF0ZV8xNl9ieXRlcw',
373 |           };
374 |           const mockRes = {
375 |             writeHead: vi.fn(),
376 |             end: vi.fn(),
377 |           };
378 |           (callbackHandler as (req: unknown, res: unknown) => void)(
379 |             mockReq,
380 |             mockRes,
381 |           );
382 |         }, 10);
383 |       });
384 | 
385 |       // Mock token exchange
386 |       mockFetch.mockResolvedValueOnce(
387 |         createMockResponse({
388 |           ok: true,
389 |           contentType: 'application/json',
390 |           text: JSON.stringify(mockTokenResponse),
391 |           json: mockTokenResponse,
392 |         }),
393 |       );
394 | 
395 |       const authProvider = new MCPOAuthProvider();
396 |       const result = await authProvider.authenticate(
397 |         'test-server',
398 |         configWithoutClient,
399 |       );
400 | 
401 |       expect(result).toBeDefined();
402 |       expect(mockFetch).toHaveBeenCalledWith(
403 |         'https://auth.example.com/register',
404 |         expect.objectContaining({
405 |           method: 'POST',
406 |           headers: { 'Content-Type': 'application/json' },
407 |         }),
408 |       );
409 |     });
410 | 
411 |     it('should perform OAuth discovery and dynamic client registration when no client ID or registration URL provided', async () => {
412 |       const configWithoutClient: MCPOAuthConfig = { ...mockConfig };
413 |       delete configWithoutClient.clientId;
414 | 
415 |       const mockRegistrationResponse: OAuthClientRegistrationResponse = {
416 |         client_id: 'dynamic_client_id',
417 |         client_secret: 'dynamic_client_secret',
418 |         redirect_uris: ['http://localhost:7777/oauth/callback'],
419 |         grant_types: ['authorization_code', 'refresh_token'],
420 |         response_types: ['code'],
421 |         token_endpoint_auth_method: 'none',
422 |       };
423 | 
424 |       const mockAuthServerMetadata: OAuthAuthorizationServerMetadata = {
425 |         issuer: 'https://auth.example.com',
426 |         authorization_endpoint: 'https://auth.example.com/authorize',
427 |         token_endpoint: 'https://auth.example.com/token',
428 |         registration_endpoint: 'https://auth.example.com/register',
429 |       };
430 | 
431 |       mockFetch
432 |         .mockResolvedValueOnce(
433 |           createMockResponse({
434 |             ok: true,
435 |             contentType: 'application/json',
436 |             text: JSON.stringify(mockAuthServerMetadata),
437 |             json: mockAuthServerMetadata,
438 |           }),
439 |         )
440 |         .mockResolvedValueOnce(
441 |           createMockResponse({
442 |             ok: true,
443 |             contentType: 'application/json',
444 |             text: JSON.stringify(mockRegistrationResponse),
445 |             json: mockRegistrationResponse,
446 |           }),
447 |         );
448 | 
449 |       // Setup callback handler
450 |       let callbackHandler: unknown;
451 |       vi.mocked(http.createServer).mockImplementation((handler) => {
452 |         callbackHandler = handler;
453 |         return mockHttpServer as unknown as http.Server;
454 |       });
455 | 
456 |       mockHttpServer.listen.mockImplementation((port, callback) => {
457 |         callback?.();
458 |         setTimeout(() => {
459 |           const mockReq = {
460 |             url: '/oauth/callback?code=auth_code_123&state=bW9ja19zdGF0ZV8xNl9ieXRlcw',
461 |           };
462 |           const mockRes = {
463 |             writeHead: vi.fn(),
464 |             end: vi.fn(),
465 |           };
466 |           (callbackHandler as (req: unknown, res: unknown) => void)(
467 |             mockReq,
468 |             mockRes,
469 |           );
470 |         }, 10);
471 |       });
472 | 
473 |       // Mock token exchange
474 |       mockFetch.mockResolvedValueOnce(
475 |         createMockResponse({
476 |           ok: true,
477 |           contentType: 'application/json',
478 |           text: JSON.stringify(mockTokenResponse),
479 |           json: mockTokenResponse,
480 |         }),
481 |       );
482 | 
483 |       const authProvider = new MCPOAuthProvider();
484 |       const result = await authProvider.authenticate(
485 |         'test-server',
486 |         configWithoutClient,
487 |       );
488 | 
489 |       expect(result).toBeDefined();
490 |       expect(mockFetch).toHaveBeenCalledWith(
491 |         'https://auth.example.com/register',
492 |         expect.objectContaining({
493 |           method: 'POST',
494 |           headers: { 'Content-Type': 'application/json' },
495 |         }),
496 |       );
497 |     });
498 | 
499 |     it('should perform OAuth discovery once and dynamic client registration when no client ID, authorization URL or registration URL provided', async () => {
500 |       const configWithoutClientAndAuthorizationUrl: MCPOAuthConfig = {
501 |         ...mockConfig,
502 |       };
503 |       delete configWithoutClientAndAuthorizationUrl.clientId;
504 |       delete configWithoutClientAndAuthorizationUrl.authorizationUrl;
505 | 
506 |       const mockResourceMetadata: OAuthProtectedResourceMetadata = {
507 |         resource: 'https://api.example.com',
508 |         authorization_servers: ['https://auth.example.com'],
509 |       };
510 | 
511 |       const mockAuthServerMetadata: OAuthAuthorizationServerMetadata = {
512 |         issuer: 'https://auth.example.com',
513 |         authorization_endpoint: 'https://auth.example.com/authorize',
514 |         token_endpoint: 'https://auth.example.com/token',
515 |         registration_endpoint: 'https://auth.example.com/register',
516 |       };
517 | 
518 |       const mockRegistrationResponse: OAuthClientRegistrationResponse = {
519 |         client_id: 'dynamic_client_id',
520 |         client_secret: 'dynamic_client_secret',
521 |         redirect_uris: ['http://localhost:7777/oauth/callback'],
522 |         grant_types: ['authorization_code', 'refresh_token'],
523 |         response_types: ['code'],
524 |         token_endpoint_auth_method: 'none',
525 |       };
526 | 
527 |       mockFetch
528 |         .mockResolvedValueOnce(
529 |           createMockResponse({
530 |             ok: true,
531 |             status: 200,
532 |           }),
533 |         )
534 |         .mockResolvedValueOnce(
535 |           createMockResponse({
536 |             ok: true,
537 |             contentType: 'application/json',
538 |             text: JSON.stringify(mockResourceMetadata),
539 |             json: mockResourceMetadata,
540 |           }),
541 |         )
542 |         .mockResolvedValueOnce(
543 |           createMockResponse({
544 |             ok: true,
545 |             contentType: 'application/json',
546 |             text: JSON.stringify(mockAuthServerMetadata),
547 |             json: mockAuthServerMetadata,
548 |           }),
549 |         )
550 |         .mockResolvedValueOnce(
551 |           createMockResponse({
552 |             ok: true,
553 |             contentType: 'application/json',
554 |             text: JSON.stringify(mockRegistrationResponse),
555 |             json: mockRegistrationResponse,
556 |           }),
557 |         );
558 | 
559 |       // Setup callback handler
560 |       let callbackHandler: unknown;
561 |       vi.mocked(http.createServer).mockImplementation((handler) => {
562 |         callbackHandler = handler;
563 |         return mockHttpServer as unknown as http.Server;
564 |       });
565 | 
566 |       mockHttpServer.listen.mockImplementation((port, callback) => {
567 |         callback?.();
568 |         setTimeout(() => {
569 |           const mockReq = {
570 |             url: '/oauth/callback?code=auth_code_123&state=bW9ja19zdGF0ZV8xNl9ieXRlcw',
571 |           };
572 |           const mockRes = {
573 |             writeHead: vi.fn(),
574 |             end: vi.fn(),
575 |           };
576 |           (callbackHandler as (req: unknown, res: unknown) => void)(
577 |             mockReq,
578 |             mockRes,
579 |           );
580 |         }, 10);
581 |       });
582 | 
583 |       // Mock token exchange
584 |       mockFetch.mockResolvedValueOnce(
585 |         createMockResponse({
586 |           ok: true,
587 |           contentType: 'application/json',
588 |           text: JSON.stringify(mockTokenResponse),
589 |           json: mockTokenResponse,
590 |         }),
591 |       );
592 | 
593 |       const authProvider = new MCPOAuthProvider();
594 |       const result = await authProvider.authenticate(
595 |         'test-server',
596 |         configWithoutClientAndAuthorizationUrl,
597 |         'https://api.example.com',
598 |       );
599 | 
600 |       expect(result).toBeDefined();
601 |       expect(mockFetch).toHaveBeenCalledWith(
602 |         'https://auth.example.com/register',
603 |         expect.objectContaining({
604 |           method: 'POST',
605 |           headers: { 'Content-Type': 'application/json' },
606 |         }),
607 |       );
608 |     });
609 | 
610 |     it('should handle OAuth callback errors', async () => {
611 |       let callbackHandler: unknown;
612 |       vi.mocked(http.createServer).mockImplementation((handler) => {
613 |         callbackHandler = handler;
614 |         return mockHttpServer as unknown as http.Server;
615 |       });
616 | 
617 |       mockHttpServer.listen.mockImplementation((port, callback) => {
618 |         callback?.();
619 |         setTimeout(() => {
620 |           const mockReq = {
621 |             url: '/oauth/callback?error=access_denied&error_description=User%20denied%20access',
622 |           };
623 |           const mockRes = {
624 |             writeHead: vi.fn(),
625 |             end: vi.fn(),
626 |           };
627 |           (callbackHandler as (req: unknown, res: unknown) => void)(
628 |             mockReq,
629 |             mockRes,
630 |           );
631 |         }, 10);
632 |       });
633 | 
634 |       const authProvider = new MCPOAuthProvider();
635 |       await expect(
636 |         authProvider.authenticate('test-server', mockConfig),
637 |       ).rejects.toThrow('OAuth error: access_denied');
638 |     });
639 | 
640 |     it('should handle state mismatch in callback', async () => {
641 |       let callbackHandler: unknown;
642 |       vi.mocked(http.createServer).mockImplementation((handler) => {
643 |         callbackHandler = handler;
644 |         return mockHttpServer as unknown as http.Server;
645 |       });
646 | 
647 |       mockHttpServer.listen.mockImplementation((port, callback) => {
648 |         callback?.();
649 |         setTimeout(() => {
650 |           const mockReq = {
651 |             url: '/oauth/callback?code=auth_code_123&state=wrong_state',
652 |           };
653 |           const mockRes = {
654 |             writeHead: vi.fn(),
655 |             end: vi.fn(),
656 |           };
657 |           (callbackHandler as (req: unknown, res: unknown) => void)(
658 |             mockReq,
659 |             mockRes,
660 |           );
661 |         }, 10);
662 |       });
663 | 
664 |       const authProvider = new MCPOAuthProvider();
665 |       await expect(
666 |         authProvider.authenticate('test-server', mockConfig),
667 |       ).rejects.toThrow('State mismatch - possible CSRF attack');
668 |     });
669 | 
670 |     it('should handle token exchange failure', async () => {
671 |       let callbackHandler: unknown;
672 |       vi.mocked(http.createServer).mockImplementation((handler) => {
673 |         callbackHandler = handler;
674 |         return mockHttpServer as unknown as http.Server;
675 |       });
676 | 
677 |       mockHttpServer.listen.mockImplementation((port, callback) => {
678 |         callback?.();
679 |         setTimeout(() => {
[TRUNCATED]
```

src/mcp/oauth-provider.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as http from 'node:http';
8 | import * as crypto from 'node:crypto';
9 | import { URL } from 'node:url';
10 | import type { EventEmitter } from 'node:events';
11 | import { openBrowserSecurely } from '../utils/secure-browser-launcher.js';
12 | import type { OAuthToken } from './token-storage/types.js';
13 | import { MCPOAuthTokenStorage } from './oauth-token-storage.js';
14 | import { getErrorMessage } from '../utils/errors.js';
15 | import { OAuthUtils } from './oauth-utils.js';
16 | 
17 | export const OAUTH_DISPLAY_MESSAGE_EVENT = 'oauth-display-message' as const;
18 | 
19 | /**
20 |  * OAuth configuration for an MCP server.
21 |  */
22 | export interface MCPOAuthConfig {
23 |   enabled?: boolean; // Whether OAuth is enabled for this server
24 |   clientId?: string;
25 |   clientSecret?: string;
26 |   authorizationUrl?: string;
27 |   tokenUrl?: string;
28 |   scopes?: string[];
29 |   audiences?: string[];
30 |   redirectUri?: string;
31 |   tokenParamName?: string; // For SSE connections, specifies the query parameter name for the token
32 |   registrationUrl?: string;
33 | }
34 | 
35 | /**
36 |  * OAuth authorization response.
37 |  */
38 | export interface OAuthAuthorizationResponse {
39 |   code: string;
40 |   state: string;
41 | }
42 | 
43 | /**
44 |  * OAuth token response from the authorization server.
45 |  */
46 | export interface OAuthTokenResponse {
47 |   access_token: string;
48 |   token_type: string;
49 |   expires_in?: number;
50 |   refresh_token?: string;
51 |   scope?: string;
52 | }
53 | 
54 | /**
55 |  * Dynamic client registration request.
56 |  */
57 | export interface OAuthClientRegistrationRequest {
58 |   client_name: string;
59 |   redirect_uris: string[];
60 |   grant_types: string[];
61 |   response_types: string[];
62 |   token_endpoint_auth_method: string;
63 |   code_challenge_method?: string[];
64 |   scope?: string;
65 | }
66 | 
67 | /**
68 |  * Dynamic client registration response.
69 |  */
70 | export interface OAuthClientRegistrationResponse {
71 |   client_id: string;
72 |   client_secret?: string;
73 |   client_id_issued_at?: number;
74 |   client_secret_expires_at?: number;
75 |   redirect_uris: string[];
76 |   grant_types: string[];
77 |   response_types: string[];
78 |   token_endpoint_auth_method: string;
79 |   code_challenge_method?: string[];
80 |   scope?: string;
81 | }
82 | 
83 | /**
84 |  * PKCE (Proof Key for Code Exchange) parameters.
85 |  */
86 | interface PKCEParams {
87 |   codeVerifier: string;
88 |   codeChallenge: string;
89 |   state: string;
90 | }
91 | 
92 | const REDIRECT_PORT = 7777;
93 | const REDIRECT_PATH = '/oauth/callback';
94 | const HTTP_OK = 200;
95 | 
96 | /**
97 |  * Provider for handling OAuth authentication for MCP servers.
98 |  */
99 | export class MCPOAuthProvider {
100 |   private readonly tokenStorage: MCPOAuthTokenStorage;
101 | 
102 |   constructor(tokenStorage: MCPOAuthTokenStorage = new MCPOAuthTokenStorage()) {
103 |     this.tokenStorage = tokenStorage;
104 |   }
105 | 
106 |   /**
107 |    * Register a client dynamically with the OAuth server.
108 |    *
109 |    * @param registrationUrl The client registration endpoint URL
110 |    * @param config OAuth configuration
111 |    * @returns The registered client information
112 |    */
113 |   private async registerClient(
114 |     registrationUrl: string,
115 |     config: MCPOAuthConfig,
116 |   ): Promise<OAuthClientRegistrationResponse> {
117 |     const redirectUri =
118 |       config.redirectUri || `http://localhost:${REDIRECT_PORT}${REDIRECT_PATH}`;
119 | 
120 |     const registrationRequest: OAuthClientRegistrationRequest = {
121 |       client_name: 'Gemini CLI MCP Client',
122 |       redirect_uris: [redirectUri],
123 |       grant_types: ['authorization_code', 'refresh_token'],
124 |       response_types: ['code'],
125 |       token_endpoint_auth_method: 'none', // Public client
126 |       code_challenge_method: ['S256'],
127 |       scope: config.scopes?.join(' ') || '',
128 |     };
129 | 
130 |     const response = await fetch(registrationUrl, {
131 |       method: 'POST',
132 |       headers: {
133 |         'Content-Type': 'application/json',
134 |       },
135 |       body: JSON.stringify(registrationRequest),
136 |     });
137 | 
138 |     if (!response.ok) {
139 |       const errorText = await response.text();
140 |       throw new Error(
141 |         `Client registration failed: ${response.status} ${response.statusText} - ${errorText}`,
142 |       );
143 |     }
144 | 
145 |     return (await response.json()) as OAuthClientRegistrationResponse;
146 |   }
147 | 
148 |   /**
149 |    * Discover OAuth configuration from an MCP server URL.
150 |    *
151 |    * @param mcpServerUrl The MCP server URL
152 |    * @returns OAuth configuration if discovered, null otherwise
153 |    */
154 |   private async discoverOAuthFromMCPServer(
155 |     mcpServerUrl: string,
156 |   ): Promise<MCPOAuthConfig | null> {
157 |     // Use the full URL with path preserved for OAuth discovery
158 |     return OAuthUtils.discoverOAuthConfig(mcpServerUrl);
159 |   }
160 | 
161 |   /**
162 |    * Generate PKCE parameters for OAuth flow.
163 |    *
164 |    * @returns PKCE parameters including code verifier, challenge, and state
165 |    */
166 |   private generatePKCEParams(): PKCEParams {
167 |     // Generate code verifier (43-128 characters)
168 |     const codeVerifier = crypto.randomBytes(32).toString('base64url');
169 | 
170 |     // Generate code challenge using SHA256
171 |     const codeChallenge = crypto
172 |       .createHash('sha256')
173 |       .update(codeVerifier)
174 |       .digest('base64url');
175 | 
176 |     // Generate state for CSRF protection
177 |     const state = crypto.randomBytes(16).toString('base64url');
178 | 
179 |     return { codeVerifier, codeChallenge, state };
180 |   }
181 | 
182 |   /**
183 |    * Start a local HTTP server to handle OAuth callback.
184 |    *
185 |    * @param expectedState The state parameter to validate
186 |    * @returns Promise that resolves with the authorization code
187 |    */
188 |   private async startCallbackServer(
189 |     expectedState: string,
190 |   ): Promise<OAuthAuthorizationResponse> {
191 |     return new Promise((resolve, reject) => {
192 |       const server = http.createServer(
193 |         async (req: http.IncomingMessage, res: http.ServerResponse) => {
194 |           try {
195 |             const url = new URL(req.url!, `http://localhost:${REDIRECT_PORT}`);
196 | 
197 |             if (url.pathname !== REDIRECT_PATH) {
198 |               res.writeHead(404);
199 |               res.end('Not found');
200 |               return;
201 |             }
202 | 
203 |             const code = url.searchParams.get('code');
204 |             const state = url.searchParams.get('state');
205 |             const error = url.searchParams.get('error');
206 | 
207 |             if (error) {
208 |               res.writeHead(HTTP_OK, { 'Content-Type': 'text/html' });
209 |               res.end(`
210 |               <html>
211 |                 <body>
212 |                   <h1>Authentication Failed</h1>
213 |                   <p>Error: ${(error as string).replace(/</g, '&lt;').replace(/>/g, '&gt;')}</p>
214 |                   <p>${((url.searchParams.get('error_description') || '') as string).replace(/</g, '&lt;').replace(/>/g, '&gt;')}</p>
215 |                   <p>You can close this window.</p>
216 |                 </body>
217 |               </html>
218 |             `);
219 |               server.close();
220 |               reject(new Error(`OAuth error: ${error}`));
221 |               return;
222 |             }
223 | 
224 |             if (!code || !state) {
225 |               res.writeHead(400);
226 |               res.end('Missing code or state parameter');
227 |               return;
228 |             }
229 | 
230 |             if (state !== expectedState) {
231 |               res.writeHead(400);
232 |               res.end('Invalid state parameter');
233 |               server.close();
234 |               reject(new Error('State mismatch - possible CSRF attack'));
235 |               return;
236 |             }
237 | 
238 |             // Send success response to browser
239 |             res.writeHead(HTTP_OK, { 'Content-Type': 'text/html' });
240 |             res.end(`
241 |             <html>
242 |               <body>
243 |                 <h1>Authentication Successful!</h1>
244 |                 <p>You can close this window and return to Gemini CLI.</p>
245 |                 <script>window.close();</script>
246 |               </body>
247 |             </html>
248 |           `);
249 | 
250 |             server.close();
251 |             resolve({ code, state });
252 |           } catch (error) {
253 |             server.close();
254 |             reject(error);
255 |           }
256 |         },
257 |       );
258 | 
259 |       server.on('error', reject);
260 |       server.listen(REDIRECT_PORT, () => {
261 |         console.log(`OAuth callback server listening on port ${REDIRECT_PORT}`);
262 |       });
263 | 
264 |       // Timeout after 5 minutes
265 |       setTimeout(
266 |         () => {
267 |           server.close();
268 |           reject(new Error('OAuth callback timeout'));
269 |         },
270 |         5 * 60 * 1000,
271 |       );
272 |     });
273 |   }
274 | 
275 |   /**
276 |    * Build the authorization URL with PKCE parameters.
277 |    *
278 |    * @param config OAuth configuration
279 |    * @param pkceParams PKCE parameters
280 |    * @param mcpServerUrl The MCP server URL to use as the resource parameter
281 |    * @returns The authorization URL
282 |    */
283 |   private buildAuthorizationUrl(
284 |     config: MCPOAuthConfig,
285 |     pkceParams: PKCEParams,
286 |     mcpServerUrl?: string,
287 |   ): string {
288 |     const redirectUri =
289 |       config.redirectUri || `http://localhost:${REDIRECT_PORT}${REDIRECT_PATH}`;
290 | 
291 |     const params = new URLSearchParams({
292 |       client_id: config.clientId!,
293 |       response_type: 'code',
294 |       redirect_uri: redirectUri,
295 |       state: pkceParams.state,
296 |       code_challenge: pkceParams.codeChallenge,
297 |       code_challenge_method: 'S256',
298 |     });
299 | 
300 |     if (config.scopes && config.scopes.length > 0) {
301 |       params.append('scope', config.scopes.join(' '));
302 |     }
303 | 
304 |     if (config.audiences && config.audiences.length > 0) {
305 |       params.append('audience', config.audiences.join(' '));
306 |     }
307 | 
308 |     // Add resource parameter for MCP OAuth spec compliance
309 |     // Only add if we have an MCP server URL (indicates MCP OAuth flow, not standard OAuth)
310 |     if (mcpServerUrl) {
311 |       try {
312 |         params.append(
313 |           'resource',
314 |           OAuthUtils.buildResourceParameter(mcpServerUrl),
315 |         );
316 |       } catch (error) {
317 |         console.warn(
318 |           `Could not add resource parameter: ${getErrorMessage(error)}`,
319 |         );
320 |       }
321 |     }
322 | 
323 |     const url = new URL(config.authorizationUrl!);
324 |     params.forEach((value, key) => {
325 |       url.searchParams.append(key, value);
326 |     });
327 |     return url.toString();
328 |   }
329 | 
330 |   /**
331 |    * Exchange authorization code for tokens.
332 |    *
333 |    * @param config OAuth configuration
334 |    * @param code Authorization code
335 |    * @param codeVerifier PKCE code verifier
336 |    * @param mcpServerUrl The MCP server URL to use as the resource parameter
337 |    * @returns The token response
338 |    */
339 |   private async exchangeCodeForToken(
340 |     config: MCPOAuthConfig,
341 |     code: string,
342 |     codeVerifier: string,
343 |     mcpServerUrl?: string,
344 |   ): Promise<OAuthTokenResponse> {
345 |     const redirectUri =
346 |       config.redirectUri || `http://localhost:${REDIRECT_PORT}${REDIRECT_PATH}`;
347 | 
348 |     const params = new URLSearchParams({
349 |       grant_type: 'authorization_code',
350 |       code,
351 |       redirect_uri: redirectUri,
352 |       code_verifier: codeVerifier,
353 |       client_id: config.clientId!,
354 |     });
355 | 
356 |     if (config.clientSecret) {
357 |       params.append('client_secret', config.clientSecret);
358 |     }
359 | 
360 |     if (config.audiences && config.audiences.length > 0) {
361 |       params.append('audience', config.audiences.join(' '));
362 |     }
363 | 
364 |     // Add resource parameter for MCP OAuth spec compliance
365 |     // Only add if we have an MCP server URL (indicates MCP OAuth flow, not standard OAuth)
366 |     if (mcpServerUrl) {
367 |       const resourceUrl = mcpServerUrl;
368 |       try {
369 |         params.append(
370 |           'resource',
371 |           OAuthUtils.buildResourceParameter(resourceUrl),
372 |         );
373 |       } catch (error) {
374 |         console.warn(
375 |           `Could not add resource parameter: ${getErrorMessage(error)}`,
376 |         );
377 |       }
378 |     }
379 | 
380 |     const response = await fetch(config.tokenUrl!, {
381 |       method: 'POST',
382 |       headers: {
383 |         'Content-Type': 'application/x-www-form-urlencoded',
384 |         Accept: 'application/json, application/x-www-form-urlencoded',
385 |       },
386 |       body: params.toString(),
387 |     });
388 | 
389 |     const responseText = await response.text();
390 |     const contentType = response.headers.get('content-type') || '';
391 | 
392 |     if (!response.ok) {
393 |       // Try to parse error from form-urlencoded response
394 |       let errorMessage: string | null = null;
395 |       try {
396 |         const errorParams = new URLSearchParams(responseText);
397 |         const error = errorParams.get('error');
398 |         const errorDescription = errorParams.get('error_description');
399 |         if (error) {
400 |           errorMessage = `Token exchange failed: ${error} - ${errorDescription || 'No description'}`;
401 |         }
402 |       } catch {
403 |         // Fall back to raw error
404 |       }
405 |       throw new Error(
406 |         errorMessage ||
407 |           `Token exchange failed: ${response.status} - ${responseText}`,
408 |       );
409 |     }
410 | 
411 |     // Log unexpected content types for debugging
412 |     if (
413 |       !contentType.includes('application/json') &&
414 |       !contentType.includes('application/x-www-form-urlencoded')
415 |     ) {
416 |       console.warn(
417 |         `Token endpoint returned unexpected content-type: ${contentType}. ` +
418 |           `Expected application/json or application/x-www-form-urlencoded. ` +
419 |           `Will attempt to parse response.`,
420 |       );
421 |     }
422 | 
423 |     // Try to parse as JSON first, fall back to form-urlencoded
424 |     try {
425 |       return JSON.parse(responseText) as OAuthTokenResponse;
426 |     } catch {
427 |       // Parse form-urlencoded response
428 |       const tokenParams = new URLSearchParams(responseText);
429 |       const accessToken = tokenParams.get('access_token');
430 |       const tokenType = tokenParams.get('token_type') || 'Bearer';
431 |       const expiresIn = tokenParams.get('expires_in');
432 |       const refreshToken = tokenParams.get('refresh_token');
433 |       const scope = tokenParams.get('scope');
434 | 
435 |       if (!accessToken) {
436 |         // Check for error in response
437 |         const error = tokenParams.get('error');
438 |         const errorDescription = tokenParams.get('error_description');
439 |         throw new Error(
440 |           `Token exchange failed: ${error || 'no_access_token'} - ${errorDescription || responseText}`,
441 |         );
442 |       }
443 | 
444 |       return {
445 |         access_token: accessToken,
446 |         token_type: tokenType,
447 |         expires_in: expiresIn ? parseInt(expiresIn, 10) : undefined,
448 |         refresh_token: refreshToken || undefined,
449 |         scope: scope || undefined,
450 |       } as OAuthTokenResponse;
451 |     }
452 |   }
453 | 
454 |   /**
455 |    * Refresh an access token using a refresh token.
456 |    *
457 |    * @param config OAuth configuration
458 |    * @param refreshToken The refresh token
459 |    * @param tokenUrl The token endpoint URL
460 |    * @param mcpServerUrl The MCP server URL to use as the resource parameter
461 |    * @returns The new token response
462 |    */
463 |   async refreshAccessToken(
464 |     config: MCPOAuthConfig,
465 |     refreshToken: string,
466 |     tokenUrl: string,
467 |     mcpServerUrl?: string,
468 |   ): Promise<OAuthTokenResponse> {
469 |     const params = new URLSearchParams({
470 |       grant_type: 'refresh_token',
471 |       refresh_token: refreshToken,
472 |       client_id: config.clientId!,
473 |     });
474 | 
475 |     if (config.clientSecret) {
476 |       params.append('client_secret', config.clientSecret);
477 |     }
478 | 
479 |     if (config.scopes && config.scopes.length > 0) {
480 |       params.append('scope', config.scopes.join(' '));
481 |     }
482 | 
483 |     if (config.audiences && config.audiences.length > 0) {
484 |       params.append('audience', config.audiences.join(' '));
485 |     }
486 | 
487 |     // Add resource parameter for MCP OAuth spec compliance
488 |     // Only add if we have an MCP server URL (indicates MCP OAuth flow, not standard OAuth)
489 |     if (mcpServerUrl) {
490 |       try {
491 |         params.append(
492 |           'resource',
493 |           OAuthUtils.buildResourceParameter(mcpServerUrl),
494 |         );
495 |       } catch (error) {
496 |         console.warn(
497 |           `Could not add resource parameter: ${getErrorMessage(error)}`,
498 |         );
499 |       }
500 |     }
501 | 
502 |     const response = await fetch(tokenUrl, {
503 |       method: 'POST',
504 |       headers: {
505 |         'Content-Type': 'application/x-www-form-urlencoded',
506 |         Accept: 'application/json, application/x-www-form-urlencoded',
507 |       },
508 |       body: params.toString(),
509 |     });
510 | 
511 |     const responseText = await response.text();
512 |     const contentType = response.headers.get('content-type') || '';
513 | 
514 |     if (!response.ok) {
515 |       // Try to parse error from form-urlencoded response
516 |       let errorMessage: string | null = null;
517 |       try {
518 |         const errorParams = new URLSearchParams(responseText);
519 |         const error = errorParams.get('error');
520 |         const errorDescription = errorParams.get('error_description');
521 |         if (error) {
522 |           errorMessage = `Token refresh failed: ${error} - ${errorDescription || 'No description'}`;
523 |         }
524 |       } catch {
525 |         // Fall back to raw error
526 |       }
527 |       throw new Error(
528 |         errorMessage ||
529 |           `Token refresh failed: ${response.status} - ${responseText}`,
530 |       );
531 |     }
532 | 
533 |     // Log unexpected content types for debugging
534 |     if (
535 |       !contentType.includes('application/json') &&
536 |       !contentType.includes('application/x-www-form-urlencoded')
537 |     ) {
538 |       console.warn(
539 |         `Token refresh endpoint returned unexpected content-type: ${contentType}. ` +
540 |           `Expected application/json or application/x-www-form-urlencoded. ` +
541 |           `Will attempt to parse response.`,
542 |       );
543 |     }
544 | 
545 |     // Try to parse as JSON first, fall back to form-urlencoded
546 |     try {
547 |       return JSON.parse(responseText) as OAuthTokenResponse;
548 |     } catch {
549 |       // Parse form-urlencoded response
550 |       const tokenParams = new URLSearchParams(responseText);
551 |       const accessToken = tokenParams.get('access_token');
552 |       const tokenType = tokenParams.get('token_type') || 'Bearer';
553 |       const expiresIn = tokenParams.get('expires_in');
554 |       const refreshToken = tokenParams.get('refresh_token');
555 |       const scope = tokenParams.get('scope');
556 | 
557 |       if (!accessToken) {
558 |         // Check for error in response
559 |         const error = tokenParams.get('error');
560 |         const errorDescription = tokenParams.get('error_description');
561 |         throw new Error(
562 |           `Token refresh failed: ${error || 'unknown_error'} - ${errorDescription || responseText}`,
563 |         );
564 |       }
565 | 
566 |       return {
567 |         access_token: accessToken,
568 |         token_type: tokenType,
569 |         expires_in: expiresIn ? parseInt(expiresIn, 10) : undefined,
570 |         refresh_token: refreshToken || undefined,
571 |         scope: scope || undefined,
572 |       } as OAuthTokenResponse;
573 |     }
574 |   }
575 | 
576 |   /**
577 |    * Perform the full OAuth authorization code flow with PKCE.
578 |    *
579 |    * @param serverName The name of the MCP server
580 |    * @param config OAuth configuration
581 |    * @param mcpServerUrl Optional MCP server URL for OAuth discovery
582 |    * @param messageHandler Optional handler for displaying user-facing messages
583 |    * @returns The obtained OAuth token
584 |    */
585 |   async authenticate(
586 |     serverName: string,
587 |     config: MCPOAuthConfig,
588 |     mcpServerUrl?: string,
589 |     events?: EventEmitter,
590 |   ): Promise<OAuthToken> {
591 |     // Helper function to display messages through handler or fallback to console.log
592 |     const displayMessage = (message: string) => {
593 |       if (events) {
594 |         events.emit(OAUTH_DISPLAY_MESSAGE_EVENT, message);
595 |       } else {
596 |         console.log(message);
597 |       }
598 |     };
599 | 
600 |     // If no authorization URL is provided, try to discover OAuth configuration
601 |     if (!config.authorizationUrl && mcpServerUrl) {
602 |       console.debug(`Starting OAuth for MCP server "${serverName}"…
603 | ✓ No authorization URL; using OAuth discovery`);
604 | 
605 |       // First check if the server requires authentication via WWW-Authenticate header
[TRUNCATED]
```

src/mcp/oauth-utils.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import type {
9 |   OAuthAuthorizationServerMetadata,
10 |   OAuthProtectedResourceMetadata,
11 | } from './oauth-utils.js';
12 | import { OAuthUtils } from './oauth-utils.js';
13 | 
14 | // Mock fetch globally
15 | const mockFetch = vi.fn();
16 | global.fetch = mockFetch;
17 | 
18 | describe('OAuthUtils', () => {
19 |   beforeEach(() => {
20 |     vi.clearAllMocks();
21 |     vi.spyOn(console, 'debug').mockImplementation(() => {});
22 |     vi.spyOn(console, 'error').mockImplementation(() => {});
23 |     vi.spyOn(console, 'log').mockImplementation(() => {});
24 |   });
25 | 
26 |   afterEach(() => {
27 |     vi.restoreAllMocks();
28 |   });
29 | 
30 |   describe('buildWellKnownUrls', () => {
31 |     it('should build standard root-based URLs by default', () => {
32 |       const urls = OAuthUtils.buildWellKnownUrls('https://example.com/mcp');
33 |       expect(urls.protectedResource).toBe(
34 |         'https://example.com/.well-known/oauth-protected-resource',
35 |       );
36 |       expect(urls.authorizationServer).toBe(
37 |         'https://example.com/.well-known/oauth-authorization-server',
38 |       );
39 |     });
40 | 
41 |     it('should build path-based URLs when includePathSuffix is true', () => {
42 |       const urls = OAuthUtils.buildWellKnownUrls(
43 |         'https://example.com/mcp',
44 |         true,
45 |       );
46 |       expect(urls.protectedResource).toBe(
47 |         'https://example.com/.well-known/oauth-protected-resource/mcp',
48 |       );
49 |       expect(urls.authorizationServer).toBe(
50 |         'https://example.com/.well-known/oauth-authorization-server/mcp',
51 |       );
52 |     });
53 | 
54 |     it('should handle root path correctly', () => {
55 |       const urls = OAuthUtils.buildWellKnownUrls('https://example.com', true);
56 |       expect(urls.protectedResource).toBe(
57 |         'https://example.com/.well-known/oauth-protected-resource',
58 |       );
59 |       expect(urls.authorizationServer).toBe(
60 |         'https://example.com/.well-known/oauth-authorization-server',
61 |       );
62 |     });
63 | 
64 |     it('should handle trailing slash in path', () => {
65 |       const urls = OAuthUtils.buildWellKnownUrls(
66 |         'https://example.com/mcp/',
67 |         true,
68 |       );
69 |       expect(urls.protectedResource).toBe(
70 |         'https://example.com/.well-known/oauth-protected-resource/mcp',
71 |       );
72 |       expect(urls.authorizationServer).toBe(
73 |         'https://example.com/.well-known/oauth-authorization-server/mcp',
74 |       );
75 |     });
76 |   });
77 | 
78 |   describe('fetchProtectedResourceMetadata', () => {
79 |     const mockResourceMetadata: OAuthProtectedResourceMetadata = {
80 |       resource: 'https://api.example.com',
81 |       authorization_servers: ['https://auth.example.com'],
82 |       bearer_methods_supported: ['header'],
83 |     };
84 | 
85 |     it('should fetch protected resource metadata successfully', async () => {
86 |       mockFetch.mockResolvedValueOnce({
87 |         ok: true,
88 |         json: () => Promise.resolve(mockResourceMetadata),
89 |       });
90 | 
91 |       const result = await OAuthUtils.fetchProtectedResourceMetadata(
92 |         'https://example.com/.well-known/oauth-protected-resource',
93 |       );
94 | 
95 |       expect(result).toEqual(mockResourceMetadata);
96 |     });
97 | 
98 |     it('should return null when fetch fails', async () => {
99 |       mockFetch.mockResolvedValueOnce({
100 |         ok: false,
101 |       });
102 | 
103 |       const result = await OAuthUtils.fetchProtectedResourceMetadata(
104 |         'https://example.com/.well-known/oauth-protected-resource',
105 |       );
106 | 
107 |       expect(result).toBeNull();
108 |     });
109 |   });
110 | 
111 |   describe('fetchAuthorizationServerMetadata', () => {
112 |     const mockAuthServerMetadata: OAuthAuthorizationServerMetadata = {
113 |       issuer: 'https://auth.example.com',
114 |       authorization_endpoint: 'https://auth.example.com/authorize',
115 |       token_endpoint: 'https://auth.example.com/token',
116 |       scopes_supported: ['read', 'write'],
117 |     };
118 | 
119 |     it('should fetch authorization server metadata successfully', async () => {
120 |       mockFetch.mockResolvedValueOnce({
121 |         ok: true,
122 |         json: () => Promise.resolve(mockAuthServerMetadata),
123 |       });
124 | 
125 |       const result = await OAuthUtils.fetchAuthorizationServerMetadata(
126 |         'https://auth.example.com/.well-known/oauth-authorization-server',
127 |       );
128 | 
129 |       expect(result).toEqual(mockAuthServerMetadata);
130 |     });
131 | 
132 |     it('should return null when fetch fails', async () => {
133 |       mockFetch.mockResolvedValueOnce({
134 |         ok: false,
135 |       });
136 | 
137 |       const result = await OAuthUtils.fetchAuthorizationServerMetadata(
138 |         'https://auth.example.com/.well-known/oauth-authorization-server',
139 |       );
140 | 
141 |       expect(result).toBeNull();
142 |     });
143 |   });
144 | 
145 |   describe('discoverAuthorizationServerMetadata', () => {
146 |     const mockAuthServerMetadata: OAuthAuthorizationServerMetadata = {
147 |       issuer: 'https://auth.example.com',
148 |       authorization_endpoint: 'https://auth.example.com/authorize',
149 |       token_endpoint: 'https://auth.example.com/token',
150 |       scopes_supported: ['read', 'write'],
151 |     };
152 | 
153 |     it('should handle URLs without path components correctly', async () => {
154 |       mockFetch
155 |         .mockResolvedValueOnce({
156 |           ok: false,
157 |         })
158 |         .mockResolvedValueOnce({
159 |           ok: true,
160 |           json: () => Promise.resolve(mockAuthServerMetadata),
161 |         });
162 | 
163 |       const result = await OAuthUtils.discoverAuthorizationServerMetadata(
164 |         'https://auth.example.com/',
165 |       );
166 | 
167 |       expect(result).toEqual(mockAuthServerMetadata);
168 | 
169 |       expect(mockFetch).nthCalledWith(
170 |         1,
171 |         'https://auth.example.com/.well-known/oauth-authorization-server',
172 |       );
173 |       expect(mockFetch).nthCalledWith(
174 |         2,
175 |         'https://auth.example.com/.well-known/openid-configuration',
176 |       );
177 |     });
178 | 
179 |     it('should handle URLs with path components correctly', async () => {
180 |       mockFetch
181 |         .mockResolvedValueOnce({
182 |           ok: false,
183 |         })
184 |         .mockResolvedValueOnce({
185 |           ok: false,
186 |         })
187 |         .mockResolvedValueOnce({
188 |           ok: true,
189 |           json: () => Promise.resolve(mockAuthServerMetadata),
190 |         });
191 | 
192 |       const result = await OAuthUtils.discoverAuthorizationServerMetadata(
193 |         'https://auth.example.com/mcp',
194 |       );
195 | 
196 |       expect(result).toEqual(mockAuthServerMetadata);
197 | 
198 |       expect(mockFetch).nthCalledWith(
199 |         1,
200 |         'https://auth.example.com/.well-known/oauth-authorization-server/mcp',
201 |       );
202 |       expect(mockFetch).nthCalledWith(
203 |         2,
204 |         'https://auth.example.com/.well-known/openid-configuration/mcp',
205 |       );
206 |       expect(mockFetch).nthCalledWith(
207 |         3,
208 |         'https://auth.example.com/mcp/.well-known/openid-configuration',
209 |       );
210 |     });
211 |   });
212 | 
213 |   describe('metadataToOAuthConfig', () => {
214 |     it('should convert metadata to OAuth config', () => {
215 |       const metadata: OAuthAuthorizationServerMetadata = {
216 |         issuer: 'https://auth.example.com',
217 |         authorization_endpoint: 'https://auth.example.com/authorize',
218 |         token_endpoint: 'https://auth.example.com/token',
219 |         scopes_supported: ['read', 'write'],
220 |       };
221 | 
222 |       const config = OAuthUtils.metadataToOAuthConfig(metadata);
223 | 
224 |       expect(config).toEqual({
225 |         authorizationUrl: 'https://auth.example.com/authorize',
226 |         tokenUrl: 'https://auth.example.com/token',
227 |         scopes: ['read', 'write'],
228 |       });
229 |     });
230 | 
231 |     it('should handle empty scopes', () => {
232 |       const metadata: OAuthAuthorizationServerMetadata = {
233 |         issuer: 'https://auth.example.com',
234 |         authorization_endpoint: 'https://auth.example.com/authorize',
235 |         token_endpoint: 'https://auth.example.com/token',
236 |       };
237 | 
238 |       const config = OAuthUtils.metadataToOAuthConfig(metadata);
239 | 
240 |       expect(config.scopes).toEqual([]);
241 |     });
242 |   });
243 | 
244 |   describe('parseWWWAuthenticateHeader', () => {
245 |     it('should parse resource metadata URI from WWW-Authenticate header', () => {
246 |       const header =
247 |         'Bearer realm="example", resource_metadata="https://example.com/.well-known/oauth-protected-resource"';
248 |       const result = OAuthUtils.parseWWWAuthenticateHeader(header);
249 |       expect(result).toBe(
250 |         'https://example.com/.well-known/oauth-protected-resource',
251 |       );
252 |     });
253 | 
254 |     it('should return null when no resource metadata URI is found', () => {
255 |       const header = 'Bearer realm="example"';
256 |       const result = OAuthUtils.parseWWWAuthenticateHeader(header);
257 |       expect(result).toBeNull();
258 |     });
259 |   });
260 | 
261 |   describe('extractBaseUrl', () => {
262 |     it('should extract base URL from MCP server URL', () => {
263 |       const result = OAuthUtils.extractBaseUrl('https://example.com/mcp/v1');
264 |       expect(result).toBe('https://example.com');
265 |     });
266 | 
267 |     it('should handle URLs with ports', () => {
268 |       const result = OAuthUtils.extractBaseUrl(
269 |         'https://example.com:8080/mcp/v1',
270 |       );
271 |       expect(result).toBe('https://example.com:8080');
272 |     });
273 |   });
274 | 
275 |   describe('isSSEEndpoint', () => {
276 |     it('should return true for SSE endpoints', () => {
277 |       expect(OAuthUtils.isSSEEndpoint('https://example.com/sse')).toBe(true);
278 |       expect(OAuthUtils.isSSEEndpoint('https://example.com/api/v1/sse')).toBe(
279 |         true,
280 |       );
281 |     });
282 | 
283 |     it('should return true for non-MCP endpoints', () => {
284 |       expect(OAuthUtils.isSSEEndpoint('https://example.com/api')).toBe(true);
285 |     });
286 | 
287 |     it('should return false for MCP endpoints', () => {
288 |       expect(OAuthUtils.isSSEEndpoint('https://example.com/mcp')).toBe(false);
289 |       expect(OAuthUtils.isSSEEndpoint('https://example.com/api/mcp/v1')).toBe(
290 |         false,
291 |       );
292 |     });
293 |   });
294 | 
295 |   describe('buildResourceParameter', () => {
296 |     it('should build resource parameter from endpoint URL', () => {
297 |       const result = OAuthUtils.buildResourceParameter(
298 |         'https://example.com/oauth/token',
299 |       );
300 |       expect(result).toBe('https://example.com');
301 |     });
302 | 
303 |     it('should handle URLs with ports', () => {
304 |       const result = OAuthUtils.buildResourceParameter(
305 |         'https://example.com:8080/oauth/token',
306 |       );
307 |       expect(result).toBe('https://example.com:8080');
308 |     });
309 |   });
310 | });
```

src/mcp/oauth-utils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { MCPOAuthConfig } from './oauth-provider.js';
8 | import { getErrorMessage } from '../utils/errors.js';
9 | 
10 | /**
11 |  * OAuth authorization server metadata as per RFC 8414.
12 |  */
13 | export interface OAuthAuthorizationServerMetadata {
14 |   issuer: string;
15 |   authorization_endpoint: string;
16 |   token_endpoint: string;
17 |   token_endpoint_auth_methods_supported?: string[];
18 |   revocation_endpoint?: string;
19 |   revocation_endpoint_auth_methods_supported?: string[];
20 |   registration_endpoint?: string;
21 |   response_types_supported?: string[];
22 |   grant_types_supported?: string[];
23 |   code_challenge_methods_supported?: string[];
24 |   scopes_supported?: string[];
25 | }
26 | 
27 | /**
28 |  * OAuth protected resource metadata as per RFC 9728.
29 |  */
30 | export interface OAuthProtectedResourceMetadata {
31 |   resource: string;
32 |   authorization_servers?: string[];
33 |   bearer_methods_supported?: string[];
34 |   resource_documentation?: string;
35 |   resource_signing_alg_values_supported?: string[];
36 |   resource_encryption_alg_values_supported?: string[];
37 |   resource_encryption_enc_values_supported?: string[];
38 | }
39 | 
40 | /**
41 |  * Utility class for common OAuth operations.
42 |  */
43 | export class OAuthUtils {
44 |   /**
45 |    * Construct well-known OAuth endpoint URLs.
46 |    * By default, uses standard root-based well-known URLs.
47 |    * If includePathSuffix is true, appends any path from the base URL to the well-known endpoints.
48 |    */
49 |   static buildWellKnownUrls(baseUrl: string, includePathSuffix = false) {
50 |     const serverUrl = new URL(baseUrl);
51 |     const base = `${serverUrl.protocol}//${serverUrl.host}`;
52 | 
53 |     if (!includePathSuffix) {
54 |       // Standard discovery: use root-based well-known URLs
55 |       return {
56 |         protectedResource: new URL(
57 |           '/.well-known/oauth-protected-resource',
58 |           base,
59 |         ).toString(),
60 |         authorizationServer: new URL(
61 |           '/.well-known/oauth-authorization-server',
62 |           base,
63 |         ).toString(),
64 |       };
65 |     }
66 | 
67 |     // Path-based discovery: append path suffix to well-known URLs
68 |     const pathSuffix = serverUrl.pathname.replace(/\/$/, ''); // Remove trailing slash
69 |     return {
70 |       protectedResource: new URL(
71 |         `/.well-known/oauth-protected-resource${pathSuffix}`,
72 |         base,
73 |       ).toString(),
74 |       authorizationServer: new URL(
75 |         `/.well-known/oauth-authorization-server${pathSuffix}`,
76 |         base,
77 |       ).toString(),
78 |     };
79 |   }
80 | 
81 |   /**
82 |    * Fetch OAuth protected resource metadata.
83 |    *
84 |    * @param resourceMetadataUrl The protected resource metadata URL
85 |    * @returns The protected resource metadata or null if not available
86 |    */
87 |   static async fetchProtectedResourceMetadata(
88 |     resourceMetadataUrl: string,
89 |   ): Promise<OAuthProtectedResourceMetadata | null> {
90 |     try {
91 |       const response = await fetch(resourceMetadataUrl);
92 |       if (!response.ok) {
93 |         return null;
94 |       }
95 |       return (await response.json()) as OAuthProtectedResourceMetadata;
96 |     } catch (error) {
97 |       console.debug(
98 |         `Failed to fetch protected resource metadata from ${resourceMetadataUrl}: ${getErrorMessage(error)}`,
99 |       );
100 |       return null;
101 |     }
102 |   }
103 | 
104 |   /**
105 |    * Fetch OAuth authorization server metadata.
106 |    *
107 |    * @param authServerMetadataUrl The authorization server metadata URL
108 |    * @returns The authorization server metadata or null if not available
109 |    */
110 |   static async fetchAuthorizationServerMetadata(
111 |     authServerMetadataUrl: string,
112 |   ): Promise<OAuthAuthorizationServerMetadata | null> {
113 |     try {
114 |       const response = await fetch(authServerMetadataUrl);
115 |       if (!response.ok) {
116 |         return null;
117 |       }
118 |       return (await response.json()) as OAuthAuthorizationServerMetadata;
119 |     } catch (error) {
120 |       console.debug(
121 |         `Failed to fetch authorization server metadata from ${authServerMetadataUrl}: ${getErrorMessage(error)}`,
122 |       );
123 |       return null;
124 |     }
125 |   }
126 | 
127 |   /**
128 |    * Convert authorization server metadata to OAuth configuration.
129 |    *
130 |    * @param metadata The authorization server metadata
131 |    * @returns The OAuth configuration
132 |    */
133 |   static metadataToOAuthConfig(
134 |     metadata: OAuthAuthorizationServerMetadata,
135 |   ): MCPOAuthConfig {
136 |     return {
137 |       authorizationUrl: metadata.authorization_endpoint,
138 |       tokenUrl: metadata.token_endpoint,
139 |       scopes: metadata.scopes_supported || [],
140 |       registrationUrl: metadata.registration_endpoint,
141 |     };
142 |   }
143 | 
144 |   /**
145 |    * Discover Oauth Authorization server metadata given an Auth server URL, by
146 |    * trying the standard well-known endpoints.
147 |    *
148 |    * @param authServerUrl The authorization server URL
149 |    * @returns The authorization server metadata or null if not found
150 |    */
151 |   static async discoverAuthorizationServerMetadata(
152 |     authServerUrl: string,
153 |   ): Promise<OAuthAuthorizationServerMetadata | null> {
154 |     const authServerUrlObj = new URL(authServerUrl);
155 |     const base = `${authServerUrlObj.protocol}//${authServerUrlObj.host}`;
156 | 
157 |     const endpointsToTry: string[] = [];
158 | 
159 |     // With issuer URLs with path components, try the following well-known
160 |     // endpoints in order:
161 |     if (authServerUrlObj.pathname !== '/') {
162 |       // 1. OAuth 2.0 Authorization Server Metadata with path insertion
163 |       endpointsToTry.push(
164 |         new URL(
165 |           `/.well-known/oauth-authorization-server${authServerUrlObj.pathname}`,
166 |           base,
167 |         ).toString(),
168 |       );
169 | 
170 |       // 2. OpenID Connect Discovery 1.0 with path insertion
171 |       endpointsToTry.push(
172 |         new URL(
173 |           `/.well-known/openid-configuration${authServerUrlObj.pathname}`,
174 |           base,
175 |         ).toString(),
176 |       );
177 | 
178 |       // 3. OpenID Connect Discovery 1.0 with path appending
179 |       endpointsToTry.push(
180 |         new URL(
181 |           `${authServerUrlObj.pathname}/.well-known/openid-configuration`,
182 |           base,
183 |         ).toString(),
184 |       );
185 |     }
186 | 
187 |     // With issuer URLs without path components, and those that failed previous
188 |     // discoveries, try the following well-known endpoints in order:
189 | 
190 |     // 1. OAuth 2.0 Authorization Server Metadata
191 |     endpointsToTry.push(
192 |       new URL('/.well-known/oauth-authorization-server', base).toString(),
193 |     );
194 | 
195 |     // 2. OpenID Connect Discovery 1.0
196 |     endpointsToTry.push(
197 |       new URL('/.well-known/openid-configuration', base).toString(),
198 |     );
199 | 
200 |     for (const endpoint of endpointsToTry) {
201 |       const authServerMetadata =
202 |         await this.fetchAuthorizationServerMetadata(endpoint);
203 |       if (authServerMetadata) {
204 |         return authServerMetadata;
205 |       }
206 |     }
207 | 
208 |     console.debug(
209 |       `Metadata discovery failed for authorization server ${authServerUrl}`,
210 |     );
211 |     return null;
212 |   }
213 | 
214 |   /**
215 |    * Discover OAuth configuration using the standard well-known endpoints.
216 |    *
217 |    * @param serverUrl The base URL of the server
218 |    * @returns The discovered OAuth configuration or null if not available
219 |    */
220 |   static async discoverOAuthConfig(
221 |     serverUrl: string,
222 |   ): Promise<MCPOAuthConfig | null> {
223 |     try {
224 |       // First try standard root-based discovery
225 |       const wellKnownUrls = this.buildWellKnownUrls(serverUrl, false);
226 | 
227 |       // Try to get the protected resource metadata at root
228 |       let resourceMetadata = await this.fetchProtectedResourceMetadata(
229 |         wellKnownUrls.protectedResource,
230 |       );
231 | 
232 |       // If root discovery fails and we have a path, try path-based discovery
233 |       if (!resourceMetadata) {
234 |         const url = new URL(serverUrl);
235 |         if (url.pathname && url.pathname !== '/') {
236 |           const pathBasedUrls = this.buildWellKnownUrls(serverUrl, true);
237 |           resourceMetadata = await this.fetchProtectedResourceMetadata(
238 |             pathBasedUrls.protectedResource,
239 |           );
240 |         }
241 |       }
242 | 
243 |       if (resourceMetadata?.authorization_servers?.length) {
244 |         // Use the first authorization server
245 |         const authServerUrl = resourceMetadata.authorization_servers[0];
246 |         const authServerMetadata =
247 |           await this.discoverAuthorizationServerMetadata(authServerUrl);
248 | 
249 |         if (authServerMetadata) {
250 |           const config = this.metadataToOAuthConfig(authServerMetadata);
251 |           if (authServerMetadata.registration_endpoint) {
252 |             console.log(
253 |               'Dynamic client registration is supported at:',
254 |               authServerMetadata.registration_endpoint,
255 |             );
256 |           }
257 |           return config;
258 |         }
259 |       }
260 | 
261 |       // Fallback: try well-known endpoints at the base URL
262 |       console.debug(`Trying OAuth discovery fallback at ${serverUrl}`);
263 |       const authServerMetadata =
264 |         await this.discoverAuthorizationServerMetadata(serverUrl);
265 | 
266 |       if (authServerMetadata) {
267 |         const config = this.metadataToOAuthConfig(authServerMetadata);
268 |         if (authServerMetadata.registration_endpoint) {
269 |           console.log(
270 |             'Dynamic client registration is supported at:',
271 |             authServerMetadata.registration_endpoint,
272 |           );
273 |         }
274 |         return config;
275 |       }
276 | 
277 |       return null;
278 |     } catch (error) {
279 |       console.debug(
280 |         `Failed to discover OAuth configuration: ${getErrorMessage(error)}`,
281 |       );
282 |       return null;
283 |     }
284 |   }
285 | 
286 |   /**
287 |    * Parse WWW-Authenticate header to extract OAuth information.
288 |    *
289 |    * @param header The WWW-Authenticate header value
290 |    * @returns The resource metadata URI if found
291 |    */
292 |   static parseWWWAuthenticateHeader(header: string): string | null {
293 |     // Parse Bearer realm and resource_metadata
294 |     const match = header.match(/resource_metadata="([^"]+)"/);
295 |     if (match) {
296 |       return match[1];
297 |     }
298 |     return null;
299 |   }
300 | 
301 |   /**
302 |    * Discover OAuth configuration from WWW-Authenticate header.
303 |    *
304 |    * @param wwwAuthenticate The WWW-Authenticate header value
305 |    * @returns The discovered OAuth configuration or null if not available
306 |    */
307 |   static async discoverOAuthFromWWWAuthenticate(
308 |     wwwAuthenticate: string,
309 |   ): Promise<MCPOAuthConfig | null> {
310 |     const resourceMetadataUri =
311 |       this.parseWWWAuthenticateHeader(wwwAuthenticate);
312 |     if (!resourceMetadataUri) {
313 |       return null;
314 |     }
315 | 
316 |     const resourceMetadata =
317 |       await this.fetchProtectedResourceMetadata(resourceMetadataUri);
318 |     if (!resourceMetadata?.authorization_servers?.length) {
319 |       return null;
320 |     }
321 | 
322 |     const authServerUrl = resourceMetadata.authorization_servers[0];
323 |     const authServerMetadata =
324 |       await this.discoverAuthorizationServerMetadata(authServerUrl);
325 | 
326 |     if (authServerMetadata) {
327 |       return this.metadataToOAuthConfig(authServerMetadata);
328 |     }
329 | 
330 |     return null;
331 |   }
332 | 
333 |   /**
334 |    * Extract base URL from an MCP server URL.
335 |    *
336 |    * @param mcpServerUrl The MCP server URL
337 |    * @returns The base URL
338 |    */
339 |   static extractBaseUrl(mcpServerUrl: string): string {
340 |     const serverUrl = new URL(mcpServerUrl);
341 |     return `${serverUrl.protocol}//${serverUrl.host}`;
342 |   }
343 | 
344 |   /**
345 |    * Check if a URL is an SSE endpoint.
346 |    *
347 |    * @param url The URL to check
348 |    * @returns True if the URL appears to be an SSE endpoint
349 |    */
350 |   static isSSEEndpoint(url: string): boolean {
351 |     return url.includes('/sse') || !url.includes('/mcp');
352 |   }
353 | 
354 |   /**
355 |    * Build a resource parameter for OAuth requests.
356 |    *
357 |    * @param endpointUrl The endpoint URL
358 |    * @returns The resource parameter value
359 |    */
360 |   static buildResourceParameter(endpointUrl: string): string {
361 |     const url = new URL(endpointUrl);
362 |     return `${url.protocol}//${url.host}`;
363 |   }
364 | }
```

src/mcp/sa-impersonation-provider.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach } from 'vitest';
8 | import { ServiceAccountImpersonationProvider } from './sa-impersonation-provider.js';
9 | import type { MCPServerConfig } from '../config/config.js';
10 | 
11 | const mockRequest = vi.fn();
12 | const mockGetClient = vi.fn(() => ({
13 |   request: mockRequest,
14 | }));
15 | 
16 | // Mock the google-auth-library to use a shared mock function
17 | vi.mock('google-auth-library', async (importOriginal) => {
18 |   const actual = await importOriginal<typeof import('google-auth-library')>();
19 |   return {
20 |     ...actual,
21 |     GoogleAuth: vi.fn().mockImplementation(() => ({
22 |       getClient: mockGetClient,
23 |     })),
24 |   };
25 | });
26 | 
27 | const defaultSAConfig: MCPServerConfig = {
28 |   url: 'https://my-iap-service.run.app',
29 |   targetAudience: 'my-audience',
30 |   targetServiceAccount: 'my-sa',
31 | };
32 | 
33 | describe('ServiceAccountImpersonationProvider', () => {
34 |   beforeEach(() => {
35 |     // Reset mocks before each test
36 |     vi.clearAllMocks();
37 |   });
38 | 
39 |   it('should throw an error if no URL is provided', () => {
40 |     const config: MCPServerConfig = {};
41 |     expect(() => new ServiceAccountImpersonationProvider(config)).toThrow(
42 |       'A url or httpUrl must be provided for the Service Account Impersonation provider',
43 |     );
44 |   });
45 | 
46 |   it('should throw an error if no targetAudience is provided', () => {
47 |     const config: MCPServerConfig = {
48 |       url: 'https://my-iap-service.run.app',
49 |     };
50 |     expect(() => new ServiceAccountImpersonationProvider(config)).toThrow(
51 |       'targetAudience must be provided for the Service Account Impersonation provider',
52 |     );
53 |   });
54 | 
55 |   it('should throw an error if no targetSA is provided', () => {
56 |     const config: MCPServerConfig = {
57 |       url: 'https://my-iap-service.run.app',
58 |       targetAudience: 'my-audience',
59 |     };
60 |     expect(() => new ServiceAccountImpersonationProvider(config)).toThrow(
61 |       'targetServiceAccount must be provided for the Service Account Impersonation provider',
62 |     );
63 |   });
64 | 
65 |   it('should correctly get tokens for a valid config', async () => {
66 |     const mockToken = 'mock-id-token-123';
67 |     mockRequest.mockResolvedValue({ data: { token: mockToken } });
68 | 
69 |     const provider = new ServiceAccountImpersonationProvider(defaultSAConfig);
70 |     const tokens = await provider.tokens();
71 | 
72 |     expect(tokens).toBeDefined();
73 |     expect(tokens?.access_token).toBe(mockToken);
74 |     expect(tokens?.token_type).toBe('Bearer');
75 |   });
76 | 
77 |   it('should return undefined if token acquisition fails', async () => {
78 |     mockRequest.mockResolvedValue({ data: { token: null } });
79 | 
80 |     const provider = new ServiceAccountImpersonationProvider(defaultSAConfig);
81 |     const tokens = await provider.tokens();
82 | 
83 |     expect(tokens).toBeUndefined();
84 |   });
85 | 
86 |   it('should make a request with the correct parameters', async () => {
87 |     mockRequest.mockResolvedValue({ data: { token: 'test-token' } });
88 | 
89 |     const provider = new ServiceAccountImpersonationProvider(defaultSAConfig);
90 |     await provider.tokens();
91 | 
92 |     expect(mockRequest).toHaveBeenCalledWith({
93 |       url: 'https://iamcredentials.googleapis.com/v1/projects/-/serviceAccounts/my-sa:generateIdToken',
94 |       method: 'POST',
95 |       data: {
96 |         audience: 'my-audience',
97 |         includeEmail: true,
98 |       },
99 |     });
100 |   });
101 | 
102 |   it('should return a cached token if it is not expired', async () => {
103 |     const provider = new ServiceAccountImpersonationProvider(defaultSAConfig);
104 |     vi.useFakeTimers();
105 | 
106 |     // jwt payload with exp set to 1 hour from now
107 |     const payload = { exp: Math.floor(Date.now() / 1000) + 3600 };
108 |     const jwt = `header.${Buffer.from(JSON.stringify(payload)).toString('base64')}.signature`;
109 |     mockRequest.mockResolvedValue({ data: { token: jwt } });
110 | 
111 |     const firstTokens = await provider.tokens();
112 |     expect(firstTokens?.access_token).toBe(jwt);
113 |     expect(mockRequest).toHaveBeenCalledTimes(1);
114 | 
115 |     // Advance time by 30 minutes
116 |     vi.advanceTimersByTime(1800 * 1000);
117 | 
118 |     // Seturn cached token
119 |     const secondTokens = await provider.tokens();
120 |     expect(secondTokens).toBe(firstTokens);
121 |     expect(mockRequest).toHaveBeenCalledTimes(1);
122 | 
123 |     vi.useRealTimers();
124 |   });
125 | 
126 |   it('should fetch a new token if the cached token is expired (using fake timers)', async () => {
127 |     const provider = new ServiceAccountImpersonationProvider(defaultSAConfig);
128 |     vi.useFakeTimers();
129 | 
130 |     // Get and cache a token that expires in 1 second
131 |     const expiredPayload = { exp: Math.floor(Date.now() / 1000) + 1 };
132 |     const expiredJwt = `header.${Buffer.from(JSON.stringify(expiredPayload)).toString('base64')}.signature`;
133 | 
134 |     mockRequest.mockResolvedValue({ data: { token: expiredJwt } });
135 |     const firstTokens = await provider.tokens();
136 |     expect(firstTokens?.access_token).toBe(expiredJwt);
137 |     expect(mockRequest).toHaveBeenCalledTimes(1);
138 | 
139 |     // Prepare the mock for the *next* call
140 |     const newPayload = { exp: Math.floor(Date.now() / 1000) + 3600 };
141 |     const newJwt = `header.${Buffer.from(JSON.stringify(newPayload)).toString('base64')}.signature`;
142 |     mockRequest.mockResolvedValue({ data: { token: newJwt } });
143 | 
144 |     vi.advanceTimersByTime(1001);
145 | 
146 |     const newTokens = await provider.tokens();
147 |     expect(newTokens?.access_token).toBe(newJwt);
148 |     expect(newTokens?.access_token).not.toBe(expiredJwt);
149 |     expect(mockRequest).toHaveBeenCalledTimes(2); // Confirms a new fetch
150 | 
151 |     vi.useRealTimers();
152 |   });
153 | });
```

src/mcp/sa-impersonation-provider.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   OAuthClientInformation,
9 |   OAuthClientInformationFull,
10 |   OAuthClientMetadata,
11 |   OAuthTokens,
12 | } from '@modelcontextprotocol/sdk/shared/auth.js';
13 | import { GoogleAuth } from 'google-auth-library';
14 | import type { MCPServerConfig } from '../config/config.js';
15 | import type { OAuthClientProvider } from '@modelcontextprotocol/sdk/client/auth.js';
16 | 
17 | const fiveMinBufferMs = 5 * 60 * 1000;
18 | 
19 | function createIamApiUrl(targetSA: string): string {
20 |   return `https://iamcredentials.googleapis.com/v1/projects/-/serviceAccounts/${encodeURIComponent(targetSA)}:generateIdToken`;
21 | }
22 | 
23 | export class ServiceAccountImpersonationProvider
24 |   implements OAuthClientProvider
25 | {
26 |   private readonly targetServiceAccount: string;
27 |   private readonly targetAudience: string; // OAuth Client Id
28 |   private readonly auth: GoogleAuth;
29 |   private cachedToken?: OAuthTokens;
30 |   private tokenExpiryTime?: number;
31 | 
32 |   // Properties required by OAuthClientProvider, with no-op values
33 |   readonly redirectUrl = '';
34 |   readonly clientMetadata: OAuthClientMetadata = {
35 |     client_name: 'Gemini CLI (Service Account Impersonation)',
36 |     redirect_uris: [],
37 |     grant_types: [],
38 |     response_types: [],
39 |     token_endpoint_auth_method: 'none',
40 |   };
41 |   private _clientInformation?: OAuthClientInformationFull;
42 | 
43 |   constructor(private readonly config: MCPServerConfig) {
44 |     // This check is done in mcp-client.ts. This is just an additional check.
45 |     if (!this.config.httpUrl && !this.config.url) {
46 |       throw new Error(
47 |         'A url or httpUrl must be provided for the Service Account Impersonation provider',
48 |       );
49 |     }
50 | 
51 |     if (!config.targetAudience) {
52 |       throw new Error(
53 |         'targetAudience must be provided for the Service Account Impersonation provider',
54 |       );
55 |     }
56 |     this.targetAudience = config.targetAudience;
57 | 
58 |     if (!config.targetServiceAccount) {
59 |       throw new Error(
60 |         'targetServiceAccount must be provided for the Service Account Impersonation provider',
61 |       );
62 |     }
63 |     this.targetServiceAccount = config.targetServiceAccount;
64 | 
65 |     this.auth = new GoogleAuth();
66 |   }
67 | 
68 |   clientInformation(): OAuthClientInformation | undefined {
69 |     return this._clientInformation;
70 |   }
71 | 
72 |   saveClientInformation(clientInformation: OAuthClientInformationFull): void {
73 |     this._clientInformation = clientInformation;
74 |   }
75 | 
76 |   async tokens(): Promise<OAuthTokens | undefined> {
77 |     // 1. Check if we have a valid, non-expired cached token.
78 |     if (
79 |       this.cachedToken &&
80 |       this.tokenExpiryTime &&
81 |       Date.now() < this.tokenExpiryTime - fiveMinBufferMs
82 |     ) {
83 |       return this.cachedToken;
84 |     }
85 | 
86 |     // 2. Clear any invalid/expired cache.
87 |     this.cachedToken = undefined;
88 |     this.tokenExpiryTime = undefined;
89 | 
90 |     // 3. Fetch a new ID token.
91 |     const client = await this.auth.getClient();
92 |     const url = createIamApiUrl(this.targetServiceAccount);
93 | 
94 |     let idToken: string;
95 |     try {
96 |       const res = await client.request<{ token: string }>({
97 |         url,
98 |         method: 'POST',
99 |         data: {
100 |           audience: this.targetAudience,
101 |           includeEmail: true,
102 |         },
103 |       });
104 |       idToken = res.data.token;
105 | 
106 |       if (!idToken || idToken.length === 0) {
107 |         console.error('Failed to get ID token from Google');
108 |         return undefined;
109 |       }
110 |     } catch (e) {
111 |       console.error('Failed to fetch ID token from Google:', e);
112 |       return undefined;
113 |     }
114 | 
115 |     const expiryTime = this.parseTokenExpiry(idToken);
116 |     // Note: We are placing the OIDC ID Token into the `access_token` field.
117 |     // This is because the CLI uses this field to construct the
118 |     // `Authorization: Bearer <token>` header, which is the correct way to
119 |     // present an ID token.
120 |     const newTokens: OAuthTokens = {
121 |       access_token: idToken,
122 |       token_type: 'Bearer',
123 |     };
124 | 
125 |     if (expiryTime) {
126 |       this.tokenExpiryTime = expiryTime;
127 |       this.cachedToken = newTokens;
128 |     }
129 | 
130 |     return newTokens;
131 |   }
132 | 
133 |   saveTokens(_tokens: OAuthTokens): void {
134 |     // No-op
135 |   }
136 | 
137 |   redirectToAuthorization(_authorizationUrl: URL): void {
138 |     // No-op
139 |   }
140 | 
141 |   saveCodeVerifier(_codeVerifier: string): void {
142 |     // No-op
143 |   }
144 | 
145 |   codeVerifier(): string {
146 |     // No-op
147 |     return '';
148 |   }
149 | 
150 |   /**
151 |    * Parses a JWT string to extract its expiry time.
152 |    * @param idToken The JWT ID token.
153 |    * @returns The expiry time in **milliseconds**, or undefined if parsing fails.
154 |    */
155 |   private parseTokenExpiry(idToken: string): number | undefined {
156 |     try {
157 |       const payload = JSON.parse(
158 |         Buffer.from(idToken.split('.')[1], 'base64').toString(),
159 |       );
160 | 
161 |       if (payload && typeof payload.exp === 'number') {
162 |         return payload.exp * 1000; // Convert seconds to milliseconds
163 |       }
164 |     } catch (e) {
165 |       console.error('Failed to parse ID token for expiry time with error:', e);
166 |     }
167 | 
168 |     // Return undefined if try block fails or 'exp' is missing/invalid
169 |     return undefined;
170 |   }
171 | }
```

src/output/json-formatter.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { expect, describe, it } from 'vitest';
8 | import type { SessionMetrics } from '../telemetry/uiTelemetry.js';
9 | import { JsonFormatter } from './json-formatter.js';
10 | import type { JsonError } from './types.js';
11 | 
12 | describe('JsonFormatter', () => {
13 |   it('should format the response as JSON', () => {
14 |     const formatter = new JsonFormatter();
15 |     const response = 'This is a test response.';
16 |     const formatted = formatter.format(response);
17 |     const expected = {
18 |       response,
19 |     };
20 |     expect(JSON.parse(formatted)).toEqual(expected);
21 |   });
22 | 
23 |   it('should strip ANSI escape sequences from response text', () => {
24 |     const formatter = new JsonFormatter();
25 |     const responseWithAnsi =
26 |       '\x1B[31mRed text\x1B[0m and \x1B[32mGreen text\x1B[0m';
27 |     const formatted = formatter.format(responseWithAnsi);
28 |     const parsed = JSON.parse(formatted);
29 |     expect(parsed.response).toBe('Red text and Green text');
30 |   });
31 | 
32 |   it('should strip control characters from response text', () => {
33 |     const formatter = new JsonFormatter();
34 |     const responseWithControlChars =
35 |       'Text with\x07 bell\x08 and\x0B vertical tab';
36 |     const formatted = formatter.format(responseWithControlChars);
37 |     const parsed = JSON.parse(formatted);
38 |     // Only ANSI codes are stripped, other control chars are preserved
39 |     expect(parsed.response).toBe('Text with\x07 bell\x08 and\x0B vertical tab');
40 |   });
41 | 
42 |   it('should preserve newlines and tabs in response text', () => {
43 |     const formatter = new JsonFormatter();
44 |     const responseWithWhitespace = 'Line 1\nLine 2\r\nLine 3\twith tab';
45 |     const formatted = formatter.format(responseWithWhitespace);
46 |     const parsed = JSON.parse(formatted);
47 |     expect(parsed.response).toBe('Line 1\nLine 2\r\nLine 3\twith tab');
48 |   });
49 | 
50 |   it('should format the response as JSON with stats', () => {
51 |     const formatter = new JsonFormatter();
52 |     const response = 'This is a test response.';
53 |     const stats: SessionMetrics = {
54 |       models: {
55 |         'gemini-2.5-pro': {
56 |           api: {
57 |             totalRequests: 2,
58 |             totalErrors: 0,
59 |             totalLatencyMs: 5672,
60 |           },
61 |           tokens: {
62 |             prompt: 24401,
63 |             candidates: 215,
64 |             total: 24719,
65 |             cached: 10656,
66 |             thoughts: 103,
67 |             tool: 0,
68 |           },
69 |         },
70 |         'gemini-2.5-flash': {
71 |           api: {
72 |             totalRequests: 2,
73 |             totalErrors: 0,
74 |             totalLatencyMs: 5914,
75 |           },
76 |           tokens: {
77 |             prompt: 20803,
78 |             candidates: 716,
79 |             total: 21657,
80 |             cached: 0,
81 |             thoughts: 138,
82 |             tool: 0,
83 |           },
84 |         },
85 |       },
86 |       tools: {
87 |         totalCalls: 1,
88 |         totalSuccess: 1,
89 |         totalFail: 0,
90 |         totalDurationMs: 4582,
91 |         totalDecisions: {
92 |           accept: 0,
93 |           reject: 0,
94 |           modify: 0,
95 |           auto_accept: 1,
96 |         },
97 |         byName: {
98 |           google_web_search: {
99 |             count: 1,
100 |             success: 1,
101 |             fail: 0,
102 |             durationMs: 4582,
103 |             decisions: {
104 |               accept: 0,
105 |               reject: 0,
106 |               modify: 0,
107 |               auto_accept: 1,
108 |             },
109 |           },
110 |         },
111 |       },
112 |       files: {
113 |         totalLinesAdded: 0,
114 |         totalLinesRemoved: 0,
115 |       },
116 |     };
117 |     const formatted = formatter.format(response, stats);
118 |     const expected = {
119 |       response,
120 |       stats,
121 |     };
122 |     expect(JSON.parse(formatted)).toEqual(expected);
123 |   });
124 | 
125 |   it('should format error as JSON', () => {
126 |     const formatter = new JsonFormatter();
127 |     const error: JsonError = {
128 |       type: 'ValidationError',
129 |       message: 'Invalid input provided',
130 |       code: 400,
131 |     };
132 |     const formatted = formatter.format(undefined, undefined, error);
133 |     const expected = {
134 |       error,
135 |     };
136 |     expect(JSON.parse(formatted)).toEqual(expected);
137 |   });
138 | 
139 |   it('should format response with error as JSON', () => {
140 |     const formatter = new JsonFormatter();
141 |     const response = 'Partial response';
142 |     const error: JsonError = {
143 |       type: 'TimeoutError',
144 |       message: 'Request timed out',
145 |       code: 'TIMEOUT',
146 |     };
147 |     const formatted = formatter.format(response, undefined, error);
148 |     const expected = {
149 |       response,
150 |       error,
151 |     };
152 |     expect(JSON.parse(formatted)).toEqual(expected);
153 |   });
154 | 
155 |   it('should format error using formatError method', () => {
156 |     const formatter = new JsonFormatter();
157 |     const error = new Error('Something went wrong');
158 |     const formatted = formatter.formatError(error, 500);
159 |     const parsed = JSON.parse(formatted);
160 | 
161 |     expect(parsed).toEqual({
162 |       error: {
163 |         type: 'Error',
164 |         message: 'Something went wrong',
165 |         code: 500,
166 |       },
167 |     });
168 |   });
169 | 
170 |   it('should format custom error using formatError method', () => {
171 |     class CustomError extends Error {
172 |       constructor(message: string) {
173 |         super(message);
174 |         this.name = 'CustomError';
175 |       }
176 |     }
177 | 
178 |     const formatter = new JsonFormatter();
179 |     const error = new CustomError('Custom error occurred');
180 |     const formatted = formatter.formatError(error);
181 |     const parsed = JSON.parse(formatted);
182 | 
183 |     expect(parsed).toEqual({
184 |       error: {
185 |         type: 'CustomError',
186 |         message: 'Custom error occurred',
187 |       },
188 |     });
189 |   });
190 | 
191 |   it('should format complete JSON output with response, stats, and error', () => {
192 |     const formatter = new JsonFormatter();
193 |     const response = 'Partial response before error';
194 |     const stats: SessionMetrics = {
195 |       models: {},
196 |       tools: {
197 |         totalCalls: 0,
198 |         totalSuccess: 0,
199 |         totalFail: 1,
200 |         totalDurationMs: 0,
201 |         totalDecisions: {
202 |           accept: 0,
203 |           reject: 0,
204 |           modify: 0,
205 |           auto_accept: 0,
206 |         },
207 |         byName: {},
208 |       },
209 |       files: {
210 |         totalLinesAdded: 0,
211 |         totalLinesRemoved: 0,
212 |       },
213 |     };
214 |     const error: JsonError = {
215 |       type: 'ApiError',
216 |       message: 'Rate limit exceeded',
217 |       code: 429,
218 |     };
219 | 
220 |     const formatted = formatter.format(response, stats, error);
221 |     const expected = {
222 |       response,
223 |       stats,
224 |       error,
225 |     };
226 |     expect(JSON.parse(formatted)).toEqual(expected);
227 |   });
228 | 
229 |   it('should handle error messages containing JSON content', () => {
230 |     const formatter = new JsonFormatter();
231 |     const errorWithJson = new Error(
232 |       'API returned: {"error": "Invalid request", "code": 400}',
233 |     );
234 |     const formatted = formatter.formatError(errorWithJson, 'API_ERROR');
235 |     const parsed = JSON.parse(formatted);
236 | 
237 |     expect(parsed).toEqual({
238 |       error: {
239 |         type: 'Error',
240 |         message: 'API returned: {"error": "Invalid request", "code": 400}',
241 |         code: 'API_ERROR',
242 |       },
243 |     });
244 | 
245 |     // Verify the entire output is valid JSON
246 |     expect(() => JSON.parse(formatted)).not.toThrow();
247 |   });
248 | 
249 |   it('should handle error messages with quotes and special characters', () => {
250 |     const formatter = new JsonFormatter();
251 |     const errorWithQuotes = new Error('Error: "quoted text" and \\backslash');
252 |     const formatted = formatter.formatError(errorWithQuotes);
253 |     const parsed = JSON.parse(formatted);
254 | 
255 |     expect(parsed).toEqual({
256 |       error: {
257 |         type: 'Error',
258 |         message: 'Error: "quoted text" and \\backslash',
259 |       },
260 |     });
261 | 
262 |     // Verify the entire output is valid JSON
263 |     expect(() => JSON.parse(formatted)).not.toThrow();
264 |   });
265 | 
266 |   it('should handle error messages with control characters', () => {
267 |     const formatter = new JsonFormatter();
268 |     const errorWithControlChars = new Error('Error with\n newline and\t tab');
269 |     const formatted = formatter.formatError(errorWithControlChars);
270 |     const parsed = JSON.parse(formatted);
271 | 
272 |     // Should preserve newlines and tabs as they are common whitespace characters
273 |     expect(parsed.error.message).toBe('Error with\n newline and\t tab');
274 | 
275 |     // Verify the entire output is valid JSON
276 |     expect(() => JSON.parse(formatted)).not.toThrow();
277 |   });
278 | 
279 |   it('should strip ANSI escape sequences from error messages', () => {
280 |     const formatter = new JsonFormatter();
281 |     const errorWithAnsi = new Error('\x1B[31mRed error\x1B[0m message');
282 |     const formatted = formatter.formatError(errorWithAnsi);
283 |     const parsed = JSON.parse(formatted);
284 | 
285 |     expect(parsed.error.message).toBe('Red error message');
286 |     expect(() => JSON.parse(formatted)).not.toThrow();
287 |   });
288 | 
289 |   it('should strip unsafe control characters from error messages', () => {
290 |     const formatter = new JsonFormatter();
291 |     const errorWithControlChars = new Error(
292 |       'Error\x07 with\x08 control\x0B chars',
293 |     );
294 |     const formatted = formatter.formatError(errorWithControlChars);
295 |     const parsed = JSON.parse(formatted);
296 | 
297 |     // Only ANSI codes are stripped, other control chars are preserved
298 |     expect(parsed.error.message).toBe('Error\x07 with\x08 control\x0B chars');
299 |     expect(() => JSON.parse(formatted)).not.toThrow();
300 |   });
301 | });
```

src/output/json-formatter.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import stripAnsi from 'strip-ansi';
8 | import type { SessionMetrics } from '../telemetry/uiTelemetry.js';
9 | import type { JsonError, JsonOutput } from './types.js';
10 | 
11 | export class JsonFormatter {
12 |   format(response?: string, stats?: SessionMetrics, error?: JsonError): string {
13 |     const output: JsonOutput = {};
14 | 
15 |     if (response !== undefined) {
16 |       output.response = stripAnsi(response);
17 |     }
18 | 
19 |     if (stats) {
20 |       output.stats = stats;
21 |     }
22 | 
23 |     if (error) {
24 |       output.error = error;
25 |     }
26 | 
27 |     return JSON.stringify(output, null, 2);
28 |   }
29 | 
30 |   formatError(error: Error, code?: string | number): string {
31 |     const jsonError: JsonError = {
32 |       type: error.constructor.name,
33 |       message: stripAnsi(error.message),
34 |       ...(code && { code }),
35 |     };
36 | 
37 |     return this.format(undefined, undefined, jsonError);
38 |   }
39 | }
```

src/output/types.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { SessionMetrics } from '../telemetry/uiTelemetry.js';
8 | 
9 | export enum OutputFormat {
10 |   TEXT = 'text',
11 |   JSON = 'json',
12 | }
13 | 
14 | export interface JsonError {
15 |   type: string;
16 |   message: string;
17 |   code?: string | number;
18 | }
19 | 
20 | export interface JsonOutput {
21 |   response?: string;
22 |   stats?: SessionMetrics;
23 |   error?: JsonError;
24 | }
```

src/mocks/msw.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { setupServer } from 'msw/node';
8 | 
9 | export const server = setupServer();
```

src/policy/index.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export * from './policy-engine.js';
8 | export * from './types.js';
```

src/policy/policy-engine.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach } from 'vitest';
8 | import { PolicyEngine } from './policy-engine.js';
9 | import {
10 |   PolicyDecision,
11 |   type PolicyRule,
12 |   type PolicyEngineConfig,
13 | } from './types.js';
14 | import type { FunctionCall } from '@google/genai';
15 | 
16 | describe('PolicyEngine', () => {
17 |   let engine: PolicyEngine;
18 | 
19 |   beforeEach(() => {
20 |     engine = new PolicyEngine();
21 |   });
22 | 
23 |   describe('constructor', () => {
24 |     it('should use default config when none provided', () => {
25 |       const decision = engine.check({ name: 'test' });
26 |       expect(decision).toBe(PolicyDecision.ASK_USER);
27 |     });
28 | 
29 |     it('should respect custom default decision', () => {
30 |       engine = new PolicyEngine({ defaultDecision: PolicyDecision.DENY });
31 |       const decision = engine.check({ name: 'test' });
32 |       expect(decision).toBe(PolicyDecision.DENY);
33 |     });
34 | 
35 |     it('should sort rules by priority', () => {
36 |       const rules: PolicyRule[] = [
37 |         { toolName: 'tool1', decision: PolicyDecision.DENY, priority: 1 },
38 |         { toolName: 'tool2', decision: PolicyDecision.ALLOW, priority: 10 },
39 |         { toolName: 'tool3', decision: PolicyDecision.ASK_USER, priority: 5 },
40 |       ];
41 | 
42 |       engine = new PolicyEngine({ rules });
43 |       const sortedRules = engine.getRules();
44 | 
45 |       expect(sortedRules[0].priority).toBe(10);
46 |       expect(sortedRules[1].priority).toBe(5);
47 |       expect(sortedRules[2].priority).toBe(1);
48 |     });
49 |   });
50 | 
51 |   describe('check', () => {
52 |     it('should match tool by name', () => {
53 |       const rules: PolicyRule[] = [
54 |         { toolName: 'shell', decision: PolicyDecision.ALLOW },
55 |         { toolName: 'edit', decision: PolicyDecision.DENY },
56 |       ];
57 | 
58 |       engine = new PolicyEngine({ rules });
59 | 
60 |       expect(engine.check({ name: 'shell' })).toBe(PolicyDecision.ALLOW);
61 |       expect(engine.check({ name: 'edit' })).toBe(PolicyDecision.DENY);
62 |       expect(engine.check({ name: 'other' })).toBe(PolicyDecision.ASK_USER);
63 |     });
64 | 
65 |     it('should match by args pattern', () => {
66 |       const rules: PolicyRule[] = [
67 |         {
68 |           toolName: 'shell',
69 |           argsPattern: /rm -rf/,
70 |           decision: PolicyDecision.DENY,
71 |         },
72 |         {
73 |           toolName: 'shell',
74 |           decision: PolicyDecision.ALLOW,
75 |         },
76 |       ];
77 | 
78 |       engine = new PolicyEngine({ rules });
79 | 
80 |       const dangerousCall: FunctionCall = {
81 |         name: 'shell',
82 |         args: { command: 'rm -rf /' },
83 |       };
84 | 
85 |       const safeCall: FunctionCall = {
86 |         name: 'shell',
87 |         args: { command: 'ls -la' },
88 |       };
89 | 
90 |       expect(engine.check(dangerousCall)).toBe(PolicyDecision.DENY);
91 |       expect(engine.check(safeCall)).toBe(PolicyDecision.ALLOW);
92 |     });
93 | 
94 |     it('should apply rules by priority', () => {
95 |       const rules: PolicyRule[] = [
96 |         { toolName: 'shell', decision: PolicyDecision.DENY, priority: 1 },
97 |         { toolName: 'shell', decision: PolicyDecision.ALLOW, priority: 10 },
98 |       ];
99 | 
100 |       engine = new PolicyEngine({ rules });
101 | 
102 |       // Higher priority rule (ALLOW) should win
103 |       expect(engine.check({ name: 'shell' })).toBe(PolicyDecision.ALLOW);
104 |     });
105 | 
106 |     it('should apply wildcard rules (no toolName)', () => {
107 |       const rules: PolicyRule[] = [
108 |         { decision: PolicyDecision.DENY }, // Applies to all tools
109 |         { toolName: 'safe-tool', decision: PolicyDecision.ALLOW, priority: 10 },
110 |       ];
111 | 
112 |       engine = new PolicyEngine({ rules });
113 | 
114 |       expect(engine.check({ name: 'safe-tool' })).toBe(PolicyDecision.ALLOW);
115 |       expect(engine.check({ name: 'any-other-tool' })).toBe(
116 |         PolicyDecision.DENY,
117 |       );
118 |     });
119 | 
120 |     it('should handle non-interactive mode', () => {
121 |       const config: PolicyEngineConfig = {
122 |         nonInteractive: true,
123 |         rules: [
124 |           { toolName: 'interactive-tool', decision: PolicyDecision.ASK_USER },
125 |           { toolName: 'allowed-tool', decision: PolicyDecision.ALLOW },
126 |         ],
127 |       };
128 | 
129 |       engine = new PolicyEngine(config);
130 | 
131 |       // ASK_USER should become DENY in non-interactive mode
132 |       expect(engine.check({ name: 'interactive-tool' })).toBe(
133 |         PolicyDecision.DENY,
134 |       );
135 |       // ALLOW should remain ALLOW
136 |       expect(engine.check({ name: 'allowed-tool' })).toBe(PolicyDecision.ALLOW);
137 |       // Default ASK_USER should also become DENY
138 |       expect(engine.check({ name: 'unknown-tool' })).toBe(PolicyDecision.DENY);
139 |     });
140 |   });
141 | 
142 |   describe('addRule', () => {
143 |     it('should add a new rule and maintain priority order', () => {
144 |       engine.addRule({
145 |         toolName: 'tool1',
146 |         decision: PolicyDecision.ALLOW,
147 |         priority: 5,
148 |       });
149 |       engine.addRule({
150 |         toolName: 'tool2',
151 |         decision: PolicyDecision.DENY,
152 |         priority: 10,
153 |       });
154 |       engine.addRule({
155 |         toolName: 'tool3',
156 |         decision: PolicyDecision.ASK_USER,
157 |         priority: 1,
158 |       });
159 | 
160 |       const rules = engine.getRules();
161 |       expect(rules).toHaveLength(3);
162 |       expect(rules[0].priority).toBe(10);
163 |       expect(rules[1].priority).toBe(5);
164 |       expect(rules[2].priority).toBe(1);
165 |     });
166 | 
167 |     it('should apply newly added rules', () => {
168 |       expect(engine.check({ name: 'new-tool' })).toBe(PolicyDecision.ASK_USER);
169 | 
170 |       engine.addRule({ toolName: 'new-tool', decision: PolicyDecision.ALLOW });
171 | 
172 |       expect(engine.check({ name: 'new-tool' })).toBe(PolicyDecision.ALLOW);
173 |     });
174 |   });
175 | 
176 |   describe('removeRulesForTool', () => {
177 |     it('should remove rules for specific tool', () => {
178 |       engine.addRule({ toolName: 'tool1', decision: PolicyDecision.ALLOW });
179 |       engine.addRule({ toolName: 'tool2', decision: PolicyDecision.DENY });
180 |       engine.addRule({
181 |         toolName: 'tool1',
182 |         decision: PolicyDecision.ASK_USER,
183 |         priority: 10,
184 |       });
185 | 
186 |       expect(engine.getRules()).toHaveLength(3);
187 | 
188 |       engine.removeRulesForTool('tool1');
189 | 
190 |       const remainingRules = engine.getRules();
191 |       expect(remainingRules).toHaveLength(1);
192 |       expect(remainingRules.some((r) => r.toolName === 'tool1')).toBe(false);
193 |       expect(remainingRules.some((r) => r.toolName === 'tool2')).toBe(true);
194 |     });
195 | 
196 |     it('should handle removing non-existent tool', () => {
197 |       engine.addRule({ toolName: 'existing', decision: PolicyDecision.ALLOW });
198 | 
199 |       expect(() => engine.removeRulesForTool('non-existent')).not.toThrow();
200 |       expect(engine.getRules()).toHaveLength(1);
201 |     });
202 |   });
203 | 
204 |   describe('getRules', () => {
205 |     it('should return readonly array of rules', () => {
206 |       const rules: PolicyRule[] = [
207 |         { toolName: 'tool1', decision: PolicyDecision.ALLOW },
208 |         { toolName: 'tool2', decision: PolicyDecision.DENY },
209 |       ];
210 | 
211 |       engine = new PolicyEngine({ rules });
212 | 
213 |       const retrievedRules = engine.getRules();
214 |       expect(retrievedRules).toHaveLength(2);
215 |       expect(retrievedRules[0].toolName).toBe('tool1');
216 |       expect(retrievedRules[1].toolName).toBe('tool2');
217 |     });
218 |   });
219 | 
220 |   describe('MCP server wildcard patterns', () => {
221 |     it('should match MCP server wildcard patterns', () => {
222 |       const rules: PolicyRule[] = [
223 |         {
224 |           toolName: 'my-server__*',
225 |           decision: PolicyDecision.ALLOW,
226 |           priority: 10,
227 |         },
228 |         {
229 |           toolName: 'blocked-server__*',
230 |           decision: PolicyDecision.DENY,
231 |           priority: 20,
232 |         },
233 |       ];
234 | 
235 |       engine = new PolicyEngine({ rules });
236 | 
237 |       // Should match my-server tools
238 |       expect(engine.check({ name: 'my-server__tool1' })).toBe(
239 |         PolicyDecision.ALLOW,
240 |       );
241 |       expect(engine.check({ name: 'my-server__another_tool' })).toBe(
242 |         PolicyDecision.ALLOW,
243 |       );
244 | 
245 |       // Should match blocked-server tools
246 |       expect(engine.check({ name: 'blocked-server__tool1' })).toBe(
247 |         PolicyDecision.DENY,
248 |       );
249 |       expect(engine.check({ name: 'blocked-server__dangerous' })).toBe(
250 |         PolicyDecision.DENY,
251 |       );
252 | 
253 |       // Should not match other patterns
254 |       expect(engine.check({ name: 'other-server__tool' })).toBe(
255 |         PolicyDecision.ASK_USER,
256 |       );
257 |       expect(engine.check({ name: 'my-server-tool' })).toBe(
258 |         PolicyDecision.ASK_USER,
259 |       ); // No __ separator
260 |       expect(engine.check({ name: 'my-server' })).toBe(PolicyDecision.ASK_USER); // No tool name
261 |     });
262 | 
263 |     it('should prioritize specific tool rules over server wildcards', () => {
264 |       const rules: PolicyRule[] = [
265 |         {
266 |           toolName: 'my-server__*',
267 |           decision: PolicyDecision.ALLOW,
268 |           priority: 10,
269 |         },
270 |         {
271 |           toolName: 'my-server__dangerous-tool',
272 |           decision: PolicyDecision.DENY,
273 |           priority: 20,
274 |         },
275 |       ];
276 | 
277 |       engine = new PolicyEngine({ rules });
278 | 
279 |       // Specific tool deny should override server allow
280 |       expect(engine.check({ name: 'my-server__dangerous-tool' })).toBe(
281 |         PolicyDecision.DENY,
282 |       );
283 |       expect(engine.check({ name: 'my-server__safe-tool' })).toBe(
284 |         PolicyDecision.ALLOW,
285 |       );
286 |     });
287 |   });
288 | 
289 |   describe('complex scenarios', () => {
290 |     it('should handle multiple matching rules with different priorities', () => {
291 |       const rules: PolicyRule[] = [
292 |         { decision: PolicyDecision.DENY, priority: 0 }, // Default deny all
293 |         { toolName: 'shell', decision: PolicyDecision.ASK_USER, priority: 5 },
294 |         {
295 |           toolName: 'shell',
296 |           argsPattern: /"command":"ls/,
297 |           decision: PolicyDecision.ALLOW,
298 |           priority: 10,
299 |         },
300 |       ];
301 | 
302 |       engine = new PolicyEngine({ rules });
303 | 
304 |       // Matches highest priority rule (ls command)
305 |       expect(engine.check({ name: 'shell', args: { command: 'ls -la' } })).toBe(
306 |         PolicyDecision.ALLOW,
307 |       );
308 | 
309 |       // Matches middle priority rule (shell without ls)
310 |       expect(engine.check({ name: 'shell', args: { command: 'pwd' } })).toBe(
311 |         PolicyDecision.ASK_USER,
312 |       );
313 | 
314 |       // Matches lowest priority rule (not shell)
315 |       expect(engine.check({ name: 'edit' })).toBe(PolicyDecision.DENY);
316 |     });
317 | 
318 |     it('should handle tools with no args', () => {
319 |       const rules: PolicyRule[] = [
320 |         {
321 |           toolName: 'read',
322 |           argsPattern: /secret/,
323 |           decision: PolicyDecision.DENY,
324 |         },
325 |       ];
326 | 
327 |       engine = new PolicyEngine({ rules });
328 | 
329 |       // Tool call without args should not match pattern
330 |       expect(engine.check({ name: 'read' })).toBe(PolicyDecision.ASK_USER);
331 | 
332 |       // Tool call with args not matching pattern
333 |       expect(engine.check({ name: 'read', args: { file: 'public.txt' } })).toBe(
334 |         PolicyDecision.ASK_USER,
335 |       );
336 | 
337 |       // Tool call with args matching pattern
338 |       expect(engine.check({ name: 'read', args: { file: 'secret.txt' } })).toBe(
339 |         PolicyDecision.DENY,
340 |       );
341 |     });
342 | 
343 |     it('should match args pattern regardless of property order', () => {
344 |       const rules: PolicyRule[] = [
345 |         {
346 |           toolName: 'shell',
347 |           // Pattern matches the stable stringified format
348 |           argsPattern: /"command":"rm[^"]*-rf/,
349 |           decision: PolicyDecision.DENY,
350 |         },
351 |       ];
352 | 
353 |       engine = new PolicyEngine({ rules });
354 | 
355 |       // Same args with different property order should both match
356 |       const args1 = { command: 'rm -rf /', path: '/home' };
357 |       const args2 = { path: '/home', command: 'rm -rf /' };
358 | 
359 |       expect(engine.check({ name: 'shell', args: args1 })).toBe(
360 |         PolicyDecision.DENY,
361 |       );
362 |       expect(engine.check({ name: 'shell', args: args2 })).toBe(
363 |         PolicyDecision.DENY,
364 |       );
365 | 
366 |       // Verify safe command doesn't match
367 |       const safeArgs = { command: 'ls -la', path: '/home' };
368 |       expect(engine.check({ name: 'shell', args: safeArgs })).toBe(
369 |         PolicyDecision.ASK_USER,
370 |       );
371 |     });
372 | 
373 |     it('should handle nested objects in args with stable stringification', () => {
374 |       const rules: PolicyRule[] = [
375 |         {
376 |           toolName: 'api',
377 |           argsPattern: /"sensitive":true/,
378 |           decision: PolicyDecision.DENY,
379 |         },
380 |       ];
381 | 
382 |       engine = new PolicyEngine({ rules });
383 | 
384 |       // Nested objects with different key orders should match consistently
385 |       const args1 = {
386 |         data: { sensitive: true, value: 'secret' },
387 |         method: 'POST',
388 |       };
389 |       const args2 = {
390 |         method: 'POST',
391 |         data: { value: 'secret', sensitive: true },
392 |       };
393 | 
394 |       expect(engine.check({ name: 'api', args: args1 })).toBe(
395 |         PolicyDecision.DENY,
396 |       );
397 |       expect(engine.check({ name: 'api', args: args2 })).toBe(
398 |         PolicyDecision.DENY,
399 |       );
400 |     });
401 | 
402 |     it('should handle circular references without stack overflow', () => {
403 |       const rules: PolicyRule[] = [
404 |         {
405 |           toolName: 'test',
406 |           argsPattern: /\[Circular\]/,
407 |           decision: PolicyDecision.DENY,
408 |         },
409 |       ];
410 | 
411 |       engine = new PolicyEngine({ rules });
412 | 
413 |       // Create an object with a circular reference
414 |       type CircularArgs = Record<string, unknown> & {
415 |         data?: Record<string, unknown>;
416 |       };
417 |       const circularArgs: CircularArgs = {
418 |         name: 'test',
419 |         data: {},
420 |       };
421 |       // Create circular reference - TypeScript allows this since data is Record<string, unknown>
422 |       (circularArgs.data as Record<string, unknown>)['self'] =
423 |         circularArgs.data;
424 | 
425 |       // Should not throw stack overflow error
426 |       expect(() =>
427 |         engine.check({ name: 'test', args: circularArgs }),
428 |       ).not.toThrow();
429 | 
430 |       // Should detect the circular reference pattern
431 |       expect(engine.check({ name: 'test', args: circularArgs })).toBe(
432 |         PolicyDecision.DENY,
433 |       );
434 | 
435 |       // Non-circular object should not match
436 |       const normalArgs = { name: 'test', data: { value: 'normal' } };
437 |       expect(engine.check({ name: 'test', args: normalArgs })).toBe(
438 |         PolicyDecision.ASK_USER,
439 |       );
440 |     });
441 | 
442 |     it('should handle deep circular references', () => {
443 |       const rules: PolicyRule[] = [
444 |         {
445 |           toolName: 'deep',
446 |           argsPattern: /\[Circular\]/,
447 |           decision: PolicyDecision.DENY,
448 |         },
449 |       ];
450 | 
451 |       engine = new PolicyEngine({ rules });
452 | 
453 |       // Create a deep circular reference
454 |       type DeepCircular = Record<string, unknown> & {
455 |         level1?: {
456 |           level2?: {
457 |             level3?: Record<string, unknown>;
458 |           };
459 |         };
460 |       };
461 |       const deepCircular: DeepCircular = {
462 |         level1: {
463 |           level2: {
464 |             level3: {},
465 |           },
466 |         },
467 |       };
468 |       // Create circular reference with proper type assertions
469 |       const level3 = deepCircular.level1!.level2!.level3!;
470 |       level3['back'] = deepCircular.level1;
471 | 
472 |       // Should handle without stack overflow
473 |       expect(() =>
474 |         engine.check({ name: 'deep', args: deepCircular }),
475 |       ).not.toThrow();
476 | 
477 |       // Should detect the circular reference
478 |       expect(engine.check({ name: 'deep', args: deepCircular })).toBe(
479 |         PolicyDecision.DENY,
480 |       );
481 |     });
482 | 
483 |     it('should handle repeated non-circular objects correctly', () => {
484 |       const rules: PolicyRule[] = [
485 |         {
486 |           toolName: 'test',
487 |           argsPattern: /\[Circular\]/,
488 |           decision: PolicyDecision.DENY,
489 |         },
490 |         {
491 |           toolName: 'test',
492 |           argsPattern: /"value":"shared"/,
493 |           decision: PolicyDecision.ALLOW,
494 |           priority: 10,
495 |         },
496 |       ];
497 | 
498 |       engine = new PolicyEngine({ rules });
499 | 
500 |       // Create an object with repeated references but no cycles
501 |       const sharedObj = { value: 'shared' };
502 |       const args = {
503 |         first: sharedObj,
504 |         second: sharedObj,
505 |         third: { nested: sharedObj },
506 |       };
507 | 
508 |       // Should NOT mark repeated objects as circular, and should match the shared value pattern
509 |       expect(engine.check({ name: 'test', args })).toBe(PolicyDecision.ALLOW);
510 |     });
511 | 
512 |     it('should omit undefined and function values from objects', () => {
513 |       const rules: PolicyRule[] = [
514 |         {
515 |           toolName: 'test',
516 |           argsPattern: /"definedValue":"test"/,
517 |           decision: PolicyDecision.ALLOW,
518 |         },
519 |       ];
520 | 
521 |       engine = new PolicyEngine({ rules });
522 | 
523 |       const args = {
524 |         definedValue: 'test',
525 |         undefinedValue: undefined,
526 |         functionValue: () => 'hello',
527 |         nullValue: null,
528 |       };
529 | 
530 |       // Should match pattern with defined value, undefined and functions omitted
531 |       expect(engine.check({ name: 'test', args })).toBe(PolicyDecision.ALLOW);
532 | 
533 |       // Check that the pattern would NOT match if undefined was included
534 |       const rulesWithUndefined: PolicyRule[] = [
535 |         {
536 |           toolName: 'test',
537 |           argsPattern: /undefinedValue/,
538 |           decision: PolicyDecision.DENY,
539 |         },
540 |       ];
541 |       engine = new PolicyEngine({ rules: rulesWithUndefined });
542 |       expect(engine.check({ name: 'test', args })).toBe(
543 |         PolicyDecision.ASK_USER,
544 |       );
545 | 
546 |       // Check that the pattern would NOT match if function was included
547 |       const rulesWithFunction: PolicyRule[] = [
548 |         {
549 |           toolName: 'test',
550 |           argsPattern: /functionValue/,
551 |           decision: PolicyDecision.DENY,
552 |         },
553 |       ];
554 |       engine = new PolicyEngine({ rules: rulesWithFunction });
555 |       expect(engine.check({ name: 'test', args })).toBe(
556 |         PolicyDecision.ASK_USER,
557 |       );
558 |     });
559 | 
560 |     it('should convert undefined and functions to null in arrays', () => {
561 |       const rules: PolicyRule[] = [
562 |         {
563 |           toolName: 'test',
564 |           argsPattern: /\["value",null,null,null\]/,
565 |           decision: PolicyDecision.ALLOW,
566 |         },
567 |       ];
568 | 
569 |       engine = new PolicyEngine({ rules });
570 | 
571 |       const args = {
572 |         array: ['value', undefined, () => 'hello', null],
573 |       };
574 | 
575 |       // Should match pattern with undefined and functions converted to null
576 |       expect(engine.check({ name: 'test', args })).toBe(PolicyDecision.ALLOW);
577 |     });
578 | 
579 |     it('should produce valid JSON for all inputs', () => {
580 |       const testCases: Array<{ input: Record<string, unknown>; desc: string }> =
581 |         [
582 |           { input: { simple: 'string' }, desc: 'simple object' },
583 |           {
584 |             input: { nested: { deep: { value: 123 } } },
585 |             desc: 'nested object',
586 |           },
587 |           { input: { data: [1, 2, 3] }, desc: 'simple array' },
588 |           { input: { mixed: [1, { a: 'b' }, null] }, desc: 'mixed array' },
589 |           {
590 |             input: { undef: undefined, func: () => {}, normal: 'value' },
591 |             desc: 'object with undefined and function',
592 |           },
593 |           {
594 |             input: { data: ['a', undefined, () => {}, null] },
595 |             desc: 'array with undefined and function',
596 |           },
597 |         ];
598 | 
599 |       for (const { input } of testCases) {
600 |         const rules: PolicyRule[] = [
601 |           {
602 |             toolName: 'test',
603 |             argsPattern: /.*/,
604 |             decision: PolicyDecision.ALLOW,
605 |           },
606 |         ];
607 |         engine = new PolicyEngine({ rules });
608 | 
609 |         // Should not throw when checking (which internally uses stableStringify)
610 |         expect(() => engine.check({ name: 'test', args: input })).not.toThrow();
611 | 
612 |         // The check should succeed
613 |         expect(engine.check({ name: 'test', args: input })).toBe(
614 |           PolicyDecision.ALLOW,
615 |         );
616 |       }
617 |     });
618 | 
619 |     it('should respect toJSON methods on objects', () => {
620 |       const rules: PolicyRule[] = [
621 |         {
622 |           toolName: 'test',
623 |           argsPattern: /"sanitized":"safe"/,
624 |           decision: PolicyDecision.ALLOW,
625 |         },
626 |         {
627 |           toolName: 'test',
628 |           argsPattern: /"dangerous":"data"/,
629 |           decision: PolicyDecision.DENY,
630 |         },
631 |       ];
632 | 
633 |       engine = new PolicyEngine({ rules });
634 | 
635 |       // Object with toJSON that sanitizes output
636 |       const args = {
637 |         data: {
638 |           dangerous: 'data',
639 |           toJSON: () => ({ sanitized: 'safe' }),
640 |         },
641 |       };
642 | 
[TRUNCATED]
```

src/policy/policy-engine.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { type FunctionCall } from '@google/genai';
8 | import {
9 |   PolicyDecision,
10 |   type PolicyEngineConfig,
11 |   type PolicyRule,
12 | } from './types.js';
13 | import { stableStringify } from './stable-stringify.js';
14 | 
15 | function ruleMatches(
16 |   rule: PolicyRule,
17 |   toolCall: FunctionCall,
18 |   stringifiedArgs: string | undefined,
19 | ): boolean {
20 |   // Check tool name if specified
21 |   if (rule.toolName) {
22 |     // Support wildcard patterns: "serverName__*" matches "serverName__anyTool"
23 |     if (rule.toolName.endsWith('__*')) {
24 |       const prefix = rule.toolName.slice(0, -3); // Remove "__*"
25 |       if (!toolCall.name || !toolCall.name.startsWith(prefix + '__')) {
26 |         return false;
27 |       }
28 |     } else if (toolCall.name !== rule.toolName) {
29 |       return false;
30 |     }
31 |   }
32 | 
33 |   // Check args pattern if specified
34 |   if (rule.argsPattern) {
35 |     // If rule has an args pattern but tool has no args, no match
36 |     if (!toolCall.args) {
37 |       return false;
38 |     }
39 |     // Use stable JSON stringification with sorted keys to ensure consistent matching
40 |     if (
41 |       stringifiedArgs === undefined ||
42 |       !rule.argsPattern.test(stringifiedArgs)
43 |     ) {
44 |       return false;
45 |     }
46 |   }
47 | 
48 |   return true;
49 | }
50 | 
51 | export class PolicyEngine {
52 |   private rules: PolicyRule[];
53 |   private readonly defaultDecision: PolicyDecision;
54 |   private readonly nonInteractive: boolean;
55 | 
56 |   constructor(config: PolicyEngineConfig = {}) {
57 |     this.rules = (config.rules ?? []).sort(
58 |       (a, b) => (b.priority ?? 0) - (a.priority ?? 0),
59 |     );
60 |     this.defaultDecision = config.defaultDecision ?? PolicyDecision.ASK_USER;
61 |     this.nonInteractive = config.nonInteractive ?? false;
62 |   }
63 | 
64 |   /**
65 |    * Check if a tool call is allowed based on the configured policies.
66 |    */
67 |   check(toolCall: FunctionCall): PolicyDecision {
68 |     let stringifiedArgs: string | undefined;
69 |     // Compute stringified args once before the loop
70 |     if (toolCall.args && this.rules.some((rule) => rule.argsPattern)) {
71 |       stringifiedArgs = stableStringify(toolCall.args);
72 |     }
73 | 
74 |     // Find the first matching rule (already sorted by priority)
75 |     for (const rule of this.rules) {
76 |       if (ruleMatches(rule, toolCall, stringifiedArgs)) {
77 |         return this.applyNonInteractiveMode(rule.decision);
78 |       }
79 |     }
80 | 
81 |     // No matching rule found, use default decision
82 |     return this.applyNonInteractiveMode(this.defaultDecision);
83 |   }
84 | 
85 |   /**
86 |    * Add a new rule to the policy engine.
87 |    */
88 |   addRule(rule: PolicyRule): void {
89 |     this.rules.push(rule);
90 |     // Re-sort rules by priority
91 |     this.rules.sort((a, b) => (b.priority ?? 0) - (a.priority ?? 0));
92 |   }
93 | 
94 |   /**
95 |    * Remove rules for a specific tool.
96 |    */
97 |   removeRulesForTool(toolName: string): void {
98 |     this.rules = this.rules.filter((rule) => rule.toolName !== toolName);
99 |   }
100 | 
101 |   /**
102 |    * Get all current rules.
103 |    */
104 |   getRules(): readonly PolicyRule[] {
105 |     return this.rules;
106 |   }
107 | 
108 |   private applyNonInteractiveMode(decision: PolicyDecision): PolicyDecision {
109 |     // In non-interactive mode, ASK_USER becomes DENY
110 |     if (this.nonInteractive && decision === PolicyDecision.ASK_USER) {
111 |       return PolicyDecision.DENY;
112 |     }
113 |     return decision;
114 |   }
115 | }
```

src/policy/stable-stringify.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Produces a stable, deterministic JSON string representation with sorted keys.
9 |  *
10 |  * This method is critical for security policy matching. It ensures that the same
11 |  * object always produces the same string representation, regardless of property
12 |  * insertion order, which could vary across different JavaScript engines or
13 |  * runtime conditions.
14 |  *
15 |  * Key behaviors:
16 |  * 1. **Sorted Keys**: Object properties are always serialized in alphabetical order,
17 |  *    ensuring deterministic output for pattern matching.
18 |  *
19 |  * 2. **Circular Reference Protection**: Uses ancestor chain tracking (not just
20 |  *    object identity) to detect true circular references while correctly handling
21 |  *    repeated non-circular object references. Circular references are replaced
22 |  *    with "[Circular]" to prevent stack overflow attacks.
23 |  *
24 |  * 3. **JSON Spec Compliance**:
25 |  *    - undefined values: Omitted from objects, converted to null in arrays
26 |  *    - Functions: Omitted from objects, converted to null in arrays
27 |  *    - toJSON methods: Respected and called when present (per JSON.stringify spec)
28 |  *
29 |  * 4. **Security Considerations**:
30 |  *    - Prevents DoS via circular references that would cause infinite recursion
31 |  *    - Ensures consistent policy rule matching by normalizing property order
32 |  *    - Respects toJSON for objects that sanitize their output
33 |  *    - Handles toJSON methods that throw errors gracefully
34 |  *
35 |  * @param obj - The object to stringify (typically toolCall.args)
36 |  * @returns A deterministic JSON string representation
37 |  *
38 |  * @example
39 |  * // Different property orders produce the same output:
40 |  * stableStringify({b: 2, a: 1}) === stableStringify({a: 1, b: 2})
41 |  * // Returns: '{"a":1,"b":2}'
42 |  *
43 |  * @example
44 |  * // Circular references are handled safely:
45 |  * const obj = {a: 1};
46 |  * obj.self = obj;
47 |  * stableStringify(obj)
48 |  * // Returns: '{"a":1,"self":"[Circular]"}'
49 |  *
50 |  * @example
51 |  * // toJSON methods are respected:
52 |  * const obj = {
53 |  *   sensitive: 'secret',
54 |  *   toJSON: () => ({ safe: 'data' })
55 |  * };
56 |  * stableStringify(obj)
57 |  * // Returns: '{"safe":"data"}'
58 |  */
59 | export function stableStringify(obj: unknown): string {
60 |   const stringify = (currentObj: unknown, ancestors: Set<unknown>): string => {
61 |     // Handle primitives and null
62 |     if (currentObj === undefined) {
63 |       return 'null'; // undefined in arrays becomes null in JSON
64 |     }
65 |     if (currentObj === null) {
66 |       return 'null';
67 |     }
68 |     if (typeof currentObj === 'function') {
69 |       return 'null'; // functions in arrays become null in JSON
70 |     }
71 |     if (typeof currentObj !== 'object') {
72 |       return JSON.stringify(currentObj);
73 |     }
74 | 
75 |     // Check for circular reference (object is in ancestor chain)
76 |     if (ancestors.has(currentObj)) {
77 |       return '"[Circular]"';
78 |     }
79 | 
80 |     ancestors.add(currentObj);
81 | 
82 |     try {
83 |       // Check for toJSON method and use it if present
84 |       const objWithToJSON = currentObj as { toJSON?: () => unknown };
85 |       if (typeof objWithToJSON.toJSON === 'function') {
86 |         try {
87 |           const jsonValue = objWithToJSON.toJSON();
88 |           // The result of toJSON needs to be stringified recursively
89 |           if (jsonValue === null) {
90 |             return 'null';
91 |           }
92 |           return stringify(jsonValue, ancestors);
93 |         } catch {
94 |           // If toJSON throws, treat as a regular object
95 |         }
96 |       }
97 | 
98 |       if (Array.isArray(currentObj)) {
99 |         const items = currentObj.map((item) => {
100 |           // undefined and functions in arrays become null
101 |           if (item === undefined || typeof item === 'function') {
102 |             return 'null';
103 |           }
104 |           return stringify(item, ancestors);
105 |         });
106 |         return '[' + items.join(',') + ']';
107 |       }
108 | 
109 |       // Handle objects - sort keys and filter out undefined/function values
110 |       const sortedKeys = Object.keys(currentObj).sort();
111 |       const pairs: string[] = [];
112 | 
113 |       for (const key of sortedKeys) {
114 |         const value = (currentObj as Record<string, unknown>)[key];
115 |         // Skip undefined and function values in objects (per JSON spec)
116 |         if (value !== undefined && typeof value !== 'function') {
117 |           pairs.push(JSON.stringify(key) + ':' + stringify(value, ancestors));
118 |         }
119 |       }
120 | 
121 |       return '{' + pairs.join(',') + '}';
122 |     } finally {
123 |       ancestors.delete(currentObj);
124 |     }
125 |   };
126 | 
127 |   return stringify(obj, new Set());
128 | }
```

src/policy/types.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export enum PolicyDecision {
8 |   ALLOW = 'allow',
9 |   DENY = 'deny',
10 |   ASK_USER = 'ask_user',
11 | }
12 | 
13 | export interface PolicyRule {
14 |   /**
15 |    * The name of the tool this rule applies to.
16 |    * If undefined, the rule applies to all tools.
17 |    */
18 |   toolName?: string;
19 | 
20 |   /**
21 |    * Pattern to match against tool arguments.
22 |    * Can be used for more fine-grained control.
23 |    */
24 |   argsPattern?: RegExp;
25 | 
26 |   /**
27 |    * The decision to make when this rule matches.
28 |    */
29 |   decision: PolicyDecision;
30 | 
31 |   /**
32 |    * Priority of this rule. Higher numbers take precedence.
33 |    * Default is 0.
34 |    */
35 |   priority?: number;
36 | }
37 | 
38 | export interface PolicyEngineConfig {
39 |   /**
40 |    * List of policy rules to apply.
41 |    */
42 |   rules?: PolicyRule[];
43 | 
44 |   /**
45 |    * Default decision when no rules match.
46 |    * Defaults to ASK_USER.
47 |    */
48 |   defaultDecision?: PolicyDecision;
49 | 
50 |   /**
51 |    * Whether to allow tools in non-interactive mode.
52 |    * When true, ASK_USER decisions become DENY.
53 |    */
54 |   nonInteractive?: boolean;
55 | }
```

src/prompts/mcp-prompts.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Config } from '../config/config.js';
8 | import type { DiscoveredMCPPrompt } from '../tools/mcp-client.js';
9 | 
10 | export function getMCPServerPrompts(
11 |   config: Config,
12 |   serverName: string,
13 | ): DiscoveredMCPPrompt[] {
14 |   const promptRegistry = config.getPromptRegistry();
15 |   if (!promptRegistry) {
16 |     return [];
17 |   }
18 |   return promptRegistry.getPromptsByServer(serverName);
19 | }
```

src/prompts/prompt-registry.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { DiscoveredMCPPrompt } from '../tools/mcp-client.js';
8 | 
9 | export class PromptRegistry {
10 |   private prompts: Map<string, DiscoveredMCPPrompt> = new Map();
11 | 
12 |   /**
13 |    * Registers a prompt definition.
14 |    * @param prompt - The prompt object containing schema and execution logic.
15 |    */
16 |   registerPrompt(prompt: DiscoveredMCPPrompt): void {
17 |     if (this.prompts.has(prompt.name)) {
18 |       const newName = `${prompt.serverName}_${prompt.name}`;
19 |       console.warn(
20 |         `Prompt with name "${prompt.name}" is already registered. Renaming to "${newName}".`,
21 |       );
22 |       this.prompts.set(newName, { ...prompt, name: newName });
23 |     } else {
24 |       this.prompts.set(prompt.name, prompt);
25 |     }
26 |   }
27 | 
28 |   /**
29 |    * Returns an array of all registered and discovered prompt instances.
30 |    */
31 |   getAllPrompts(): DiscoveredMCPPrompt[] {
32 |     return Array.from(this.prompts.values()).sort((a, b) =>
33 |       a.name.localeCompare(b.name),
34 |     );
35 |   }
36 | 
37 |   /**
38 |    * Get the definition of a specific prompt.
39 |    */
40 |   getPrompt(name: string): DiscoveredMCPPrompt | undefined {
41 |     return this.prompts.get(name);
42 |   }
43 | 
44 |   /**
45 |    * Returns an array of prompts registered from a specific MCP server.
46 |    */
47 |   getPromptsByServer(serverName: string): DiscoveredMCPPrompt[] {
48 |     const serverPrompts: DiscoveredMCPPrompt[] = [];
49 |     for (const prompt of this.prompts.values()) {
50 |       if (prompt.serverName === serverName) {
51 |         serverPrompts.push(prompt);
52 |       }
53 |     }
54 |     return serverPrompts.sort((a, b) => a.name.localeCompare(b.name));
55 |   }
56 | 
57 |   /**
58 |    * Clears all the prompts from the registry.
59 |    */
60 |   clear(): void {
61 |     this.prompts.clear();
62 |   }
63 | 
64 |   /**
65 |    * Removes all prompts from a specific server.
66 |    */
67 |   removePromptsByServer(serverName: string): void {
68 |     for (const [name, prompt] of this.prompts.entries()) {
69 |       if (prompt.serverName === serverName) {
70 |         this.prompts.delete(name);
71 |       }
72 |     }
73 |   }
74 | }
```

src/routing/modelRouterService.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach } from 'vitest';
8 | import { ModelRouterService } from './modelRouterService.js';
9 | import { Config } from '../config/config.js';
10 | import type { BaseLlmClient } from '../core/baseLlmClient.js';
11 | import type { RoutingContext, RoutingDecision } from './routingStrategy.js';
12 | import { DefaultStrategy } from './strategies/defaultStrategy.js';
13 | import { CompositeStrategy } from './strategies/compositeStrategy.js';
14 | import { FallbackStrategy } from './strategies/fallbackStrategy.js';
15 | import { OverrideStrategy } from './strategies/overrideStrategy.js';
16 | import { ClassifierStrategy } from './strategies/classifierStrategy.js';
17 | import { logModelRouting } from '../telemetry/loggers.js';
18 | import { ModelRoutingEvent } from '../telemetry/types.js';
19 | 
20 | vi.mock('../config/config.js');
21 | vi.mock('../core/baseLlmClient.js');
22 | vi.mock('./strategies/defaultStrategy.js');
23 | vi.mock('./strategies/compositeStrategy.js');
24 | vi.mock('./strategies/fallbackStrategy.js');
25 | vi.mock('./strategies/overrideStrategy.js');
26 | vi.mock('./strategies/classifierStrategy.js');
27 | vi.mock('../telemetry/loggers.js');
28 | vi.mock('../telemetry/types.js');
29 | 
30 | describe('ModelRouterService', () => {
31 |   let service: ModelRouterService;
32 |   let mockConfig: Config;
33 |   let mockBaseLlmClient: BaseLlmClient;
34 |   let mockContext: RoutingContext;
35 |   let mockCompositeStrategy: CompositeStrategy;
36 | 
37 |   beforeEach(() => {
38 |     vi.clearAllMocks();
39 | 
40 |     mockConfig = new Config({} as never);
41 |     mockBaseLlmClient = {} as BaseLlmClient;
42 |     vi.spyOn(mockConfig, 'getBaseLlmClient').mockReturnValue(mockBaseLlmClient);
43 | 
44 |     mockCompositeStrategy = new CompositeStrategy(
45 |       [
46 |         new FallbackStrategy(),
47 |         new OverrideStrategy(),
48 |         new ClassifierStrategy(),
49 |         new DefaultStrategy(),
50 |       ],
51 |       'agent-router',
52 |     );
53 |     vi.mocked(CompositeStrategy).mockImplementation(
54 |       () => mockCompositeStrategy,
55 |     );
56 | 
57 |     service = new ModelRouterService(mockConfig);
58 | 
59 |     mockContext = {
60 |       history: [],
61 |       request: [{ text: 'test prompt' }],
62 |       signal: new AbortController().signal,
63 |     };
64 |   });
65 | 
66 |   it('should initialize with a CompositeStrategy', () => {
67 |     expect(CompositeStrategy).toHaveBeenCalled();
68 |     expect(service['strategy']).toBeInstanceOf(CompositeStrategy);
69 |   });
70 | 
71 |   it('should initialize the CompositeStrategy with the correct child strategies in order', () => {
72 |     // This test relies on the mock implementation detail of the constructor
73 |     const compositeStrategyArgs = vi.mocked(CompositeStrategy).mock.calls[0];
74 |     const childStrategies = compositeStrategyArgs[0];
75 | 
76 |     expect(childStrategies.length).toBe(4);
77 |     expect(childStrategies[0]).toBeInstanceOf(FallbackStrategy);
78 |     expect(childStrategies[1]).toBeInstanceOf(OverrideStrategy);
79 |     expect(childStrategies[2]).toBeInstanceOf(ClassifierStrategy);
80 |     expect(childStrategies[3]).toBeInstanceOf(DefaultStrategy);
81 |     expect(compositeStrategyArgs[1]).toBe('agent-router');
82 |   });
83 | 
84 |   describe('route()', () => {
85 |     const strategyDecision: RoutingDecision = {
86 |       model: 'strategy-chosen-model',
87 |       metadata: {
88 |         source: 'test-router/fallback',
89 |         latencyMs: 10,
90 |         reasoning: 'Strategy reasoning',
91 |       },
92 |     };
93 | 
94 |     it('should delegate routing to the composite strategy', async () => {
95 |       const strategySpy = vi
96 |         .spyOn(mockCompositeStrategy, 'route')
97 |         .mockResolvedValue(strategyDecision);
98 | 
99 |       const decision = await service.route(mockContext);
100 | 
101 |       expect(strategySpy).toHaveBeenCalledWith(
102 |         mockContext,
103 |         mockConfig,
104 |         mockBaseLlmClient,
105 |       );
106 |       expect(decision).toEqual(strategyDecision);
107 |     });
108 | 
109 |     it('should log a telemetry event on a successful decision', async () => {
110 |       vi.spyOn(mockCompositeStrategy, 'route').mockResolvedValue(
111 |         strategyDecision,
112 |       );
113 | 
114 |       await service.route(mockContext);
115 | 
116 |       expect(ModelRoutingEvent).toHaveBeenCalledWith(
117 |         'strategy-chosen-model',
118 |         'test-router/fallback',
119 |         10,
120 |         'Strategy reasoning',
121 |         false,
122 |         undefined,
123 |       );
124 |       expect(logModelRouting).toHaveBeenCalledWith(
125 |         mockConfig,
126 |         expect.any(ModelRoutingEvent),
127 |       );
128 |     });
129 | 
130 |     it('should log a telemetry event and re-throw on a failed decision', async () => {
131 |       const testError = new Error('Strategy failed');
132 |       vi.spyOn(mockCompositeStrategy, 'route').mockRejectedValue(testError);
133 |       vi.spyOn(mockConfig, 'getModel').mockReturnValue('default-model');
134 | 
135 |       await expect(service.route(mockContext)).rejects.toThrow(testError);
136 | 
137 |       expect(ModelRoutingEvent).toHaveBeenCalledWith(
138 |         'default-model',
139 |         'router-exception',
140 |         expect.any(Number),
141 |         'An exception occurred during routing.',
142 |         true,
143 |         'Strategy failed',
144 |       );
145 |       expect(logModelRouting).toHaveBeenCalledWith(
146 |         mockConfig,
147 |         expect.any(ModelRoutingEvent),
148 |       );
149 |     });
150 |   });
151 | });
```

src/routing/modelRouterService.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Config } from '../config/config.js';
8 | import type {
9 |   RoutingContext,
10 |   RoutingDecision,
11 |   TerminalStrategy,
12 | } from './routingStrategy.js';
13 | import { DefaultStrategy } from './strategies/defaultStrategy.js';
14 | import { ClassifierStrategy } from './strategies/classifierStrategy.js';
15 | import { CompositeStrategy } from './strategies/compositeStrategy.js';
16 | import { FallbackStrategy } from './strategies/fallbackStrategy.js';
17 | import { OverrideStrategy } from './strategies/overrideStrategy.js';
18 | 
19 | import { logModelRouting } from '../telemetry/loggers.js';
20 | import { ModelRoutingEvent } from '../telemetry/types.js';
21 | 
22 | /**
23 |  * A centralized service for making model routing decisions.
24 |  */
25 | export class ModelRouterService {
26 |   private config: Config;
27 |   private strategy: TerminalStrategy;
28 | 
29 |   constructor(config: Config) {
30 |     this.config = config;
31 |     this.strategy = this.initializeDefaultStrategy();
32 |   }
33 | 
34 |   private initializeDefaultStrategy(): TerminalStrategy {
35 |     // Initialize the composite strategy with the desired priority order.
36 |     // The strategies are ordered in order of highest priority.
37 |     return new CompositeStrategy(
38 |       [
39 |         new FallbackStrategy(),
40 |         new OverrideStrategy(),
41 |         new ClassifierStrategy(),
42 |         new DefaultStrategy(),
43 |       ],
44 |       'agent-router',
45 |     );
46 |   }
47 | 
48 |   /**
49 |    * Determines which model to use for a given request context.
50 |    *
51 |    * @param context The full context of the request.
52 |    * @returns A promise that resolves to a RoutingDecision.
53 |    */
54 |   async route(context: RoutingContext): Promise<RoutingDecision> {
55 |     const startTime = Date.now();
56 |     let decision: RoutingDecision;
57 | 
58 |     try {
59 |       decision = await this.strategy.route(
60 |         context,
61 |         this.config,
62 |         this.config.getBaseLlmClient(),
63 |       );
64 | 
65 |       const event = new ModelRoutingEvent(
66 |         decision.model,
67 |         decision.metadata.source,
68 |         decision.metadata.latencyMs,
69 |         decision.metadata.reasoning,
70 |         false, // failed
71 |         undefined, // error_message
72 |       );
73 |       logModelRouting(this.config, event);
74 | 
75 |       return decision;
76 |     } catch (e) {
77 |       const failed = true;
78 |       const error_message = e instanceof Error ? e.message : String(e);
79 |       // Create a fallback decision for logging purposes
80 |       // We do not actually route here. This should never happen so we should
81 |       // fail loudly to catch any issues where this happens.
82 |       decision = {
83 |         model: this.config.getModel(),
84 |         metadata: {
85 |           source: 'router-exception',
86 |           latencyMs: Date.now() - startTime,
87 |           reasoning: 'An exception occurred during routing.',
88 |           error: error_message,
89 |         },
90 |       };
91 | 
92 |       const event = new ModelRoutingEvent(
93 |         decision.model,
94 |         decision.metadata.source,
95 |         decision.metadata.latencyMs,
96 |         decision.metadata.reasoning,
97 |         failed,
98 |         error_message,
99 |       );
100 | 
101 |       logModelRouting(this.config, event);
102 | 
103 |       throw e;
104 |     }
105 |   }
106 | }
```

src/routing/routingStrategy.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Content, PartListUnion } from '@google/genai';
8 | import type { BaseLlmClient } from '../core/baseLlmClient.js';
9 | import type { Config } from '../config/config.js';
10 | 
11 | /**
12 |  * The output of a routing decision. It specifies which model to use and why.
13 |  */
14 | export interface RoutingDecision {
15 |   /** The model identifier string to use for the next API call (e.g., 'gemini-2.5-pro'). */
16 |   model: string;
17 |   /**
18 |    * Metadata about the routing decision for logging purposes.
19 |    */
20 |   metadata: {
21 |     source: string;
22 |     latencyMs: number;
23 |     reasoning: string;
24 |     error?: string;
25 |   };
26 | }
27 | 
28 | /**
29 |  * The context provided to the router for making a decision.
30 |  */
31 | export interface RoutingContext {
32 |   /** The full history of the conversation. */
33 |   history: Content[];
34 |   /** The immediate request parts to be processed. */
35 |   request: PartListUnion;
36 |   /** An abort signal to cancel an LLM call during routing. */
37 |   signal: AbortSignal;
38 | }
39 | 
40 | /**
41 |  * The core interface that all routing strategies must implement.
42 |  * Strategies implementing this interface may decline a request by returning null.
43 |  */
44 | export interface RoutingStrategy {
45 |   /** The name of the strategy (e.g., 'fallback', 'override', 'composite'). */
46 |   readonly name: string;
47 | 
48 |   /**
49 |    * Determines which model to use for a given request context.
50 |    * @param context The full context of the request.
51 |    * @param config The current configuration.
52 |    * @param client A reference to the GeminiClient, allowing the strategy to make its own API calls if needed.
53 |    * @returns A promise that resolves to a RoutingDecision, or null if the strategy is not applicable.
54 |    */
55 |   route(
56 |     context: RoutingContext,
57 |     config: Config,
58 |     baseLlmClient: BaseLlmClient,
59 |   ): Promise<RoutingDecision | null>;
60 | }
61 | 
62 | /**
63 |  * A strategy that is guaranteed to return a decision. It must not return null.
64 |  * This is used to ensure that a composite chain always terminates.
65 |  */
66 | export interface TerminalStrategy extends RoutingStrategy {
67 |   /**
68 |    * Determines which model to use for a given request context.
69 |    * @returns A promise that resolves to a RoutingDecision.
70 |    */
71 |   route(
72 |     context: RoutingContext,
73 |     config: Config,
74 |     baseLlmClient: BaseLlmClient,
75 |   ): Promise<RoutingDecision>;
76 | }
```

src/services/chatRecordingService.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { MockInstance } from 'vitest';
8 | import { expect, it, describe, vi, beforeEach, afterEach } from 'vitest';
9 | import fs from 'node:fs';
10 | import path from 'node:path';
11 | import { randomUUID } from 'node:crypto';
12 | import type {
13 |   ConversationRecord,
14 |   ToolCallRecord,
15 | } from './chatRecordingService.js';
16 | import { ChatRecordingService } from './chatRecordingService.js';
17 | import type { Config } from '../config/config.js';
18 | import { getProjectHash } from '../utils/paths.js';
19 | 
20 | vi.mock('node:fs');
21 | vi.mock('node:path');
22 | vi.mock('node:crypto', () => ({
23 |   randomUUID: vi.fn(),
24 |   createHash: vi.fn(() => ({
25 |     update: vi.fn(() => ({
26 |       digest: vi.fn(() => 'mocked-hash'),
27 |     })),
28 |   })),
29 | }));
30 | vi.mock('../utils/paths.js');
31 | 
32 | describe('ChatRecordingService', () => {
33 |   let chatRecordingService: ChatRecordingService;
34 |   let mockConfig: Config;
35 | 
36 |   let mkdirSyncSpy: MockInstance<typeof fs.mkdirSync>;
37 |   let writeFileSyncSpy: MockInstance<typeof fs.writeFileSync>;
38 | 
39 |   beforeEach(() => {
40 |     mockConfig = {
41 |       getSessionId: vi.fn().mockReturnValue('test-session-id'),
42 |       getProjectRoot: vi.fn().mockReturnValue('/test/project/root'),
43 |       storage: {
44 |         getProjectTempDir: vi
45 |           .fn()
46 |           .mockReturnValue('/test/project/root/.gemini/tmp'),
47 |       },
48 |       getModel: vi.fn().mockReturnValue('gemini-pro'),
49 |       getDebugMode: vi.fn().mockReturnValue(false),
50 |       getToolRegistry: vi.fn().mockReturnValue({
51 |         getTool: vi.fn().mockReturnValue({
52 |           displayName: 'Test Tool',
53 |           description: 'A test tool',
54 |           isOutputMarkdown: false,
55 |         }),
56 |       }),
57 |     } as unknown as Config;
58 | 
59 |     vi.mocked(getProjectHash).mockReturnValue('test-project-hash');
60 |     vi.mocked(randomUUID).mockReturnValue('this-is-a-test-uuid');
61 |     vi.mocked(path.join).mockImplementation((...args) => args.join('/'));
62 | 
63 |     chatRecordingService = new ChatRecordingService(mockConfig);
64 | 
65 |     mkdirSyncSpy = vi
66 |       .spyOn(fs, 'mkdirSync')
67 |       .mockImplementation(() => undefined);
68 | 
69 |     writeFileSyncSpy = vi
70 |       .spyOn(fs, 'writeFileSync')
71 |       .mockImplementation(() => undefined);
72 |   });
73 | 
74 |   afterEach(() => {
75 |     vi.restoreAllMocks();
76 |   });
77 | 
78 |   describe('initialize', () => {
79 |     it('should create a new session if none is provided', () => {
80 |       chatRecordingService.initialize();
81 | 
82 |       expect(mkdirSyncSpy).toHaveBeenCalledWith(
83 |         '/test/project/root/.gemini/tmp/chats',
84 |         { recursive: true },
85 |       );
86 |       expect(writeFileSyncSpy).not.toHaveBeenCalled();
87 |     });
88 | 
89 |     it('should resume from an existing session if provided', () => {
90 |       const readFileSyncSpy = vi.spyOn(fs, 'readFileSync').mockReturnValue(
91 |         JSON.stringify({
92 |           sessionId: 'old-session-id',
93 |           projectHash: 'test-project-hash',
94 |           messages: [],
95 |         }),
96 |       );
97 |       const writeFileSyncSpy = vi
98 |         .spyOn(fs, 'writeFileSync')
99 |         .mockImplementation(() => undefined);
100 | 
101 |       chatRecordingService.initialize({
102 |         filePath: '/test/project/root/.gemini/tmp/chats/session.json',
103 |         conversation: {
104 |           sessionId: 'old-session-id',
105 |         } as ConversationRecord,
106 |       });
107 | 
108 |       expect(mkdirSyncSpy).not.toHaveBeenCalled();
109 |       expect(readFileSyncSpy).toHaveBeenCalled();
110 |       expect(writeFileSyncSpy).not.toHaveBeenCalled();
111 |     });
112 |   });
113 | 
114 |   describe('recordMessage', () => {
115 |     beforeEach(() => {
116 |       chatRecordingService.initialize();
117 |       vi.spyOn(fs, 'readFileSync').mockReturnValue(
118 |         JSON.stringify({
119 |           sessionId: 'test-session-id',
120 |           projectHash: 'test-project-hash',
121 |           messages: [],
122 |         }),
123 |       );
124 |     });
125 | 
126 |     it('should record a new message', () => {
127 |       const writeFileSyncSpy = vi
128 |         .spyOn(fs, 'writeFileSync')
129 |         .mockImplementation(() => undefined);
130 |       chatRecordingService.recordMessage({
131 |         type: 'user',
132 |         content: 'Hello',
133 |         model: 'gemini-pro',
134 |       });
135 |       expect(mkdirSyncSpy).toHaveBeenCalled();
136 |       expect(writeFileSyncSpy).toHaveBeenCalled();
137 |       const conversation = JSON.parse(
138 |         writeFileSyncSpy.mock.calls[0][1] as string,
139 |       ) as ConversationRecord;
140 |       expect(conversation.messages).toHaveLength(1);
141 |       expect(conversation.messages[0].content).toBe('Hello');
142 |       expect(conversation.messages[0].type).toBe('user');
143 |     });
144 | 
145 |     it('should create separate messages when recording multiple messages', () => {
146 |       const writeFileSyncSpy = vi
147 |         .spyOn(fs, 'writeFileSync')
148 |         .mockImplementation(() => undefined);
149 |       const initialConversation = {
150 |         sessionId: 'test-session-id',
151 |         projectHash: 'test-project-hash',
152 |         messages: [
153 |           {
154 |             id: '1',
155 |             type: 'user',
156 |             content: 'Hello',
157 |             timestamp: new Date().toISOString(),
158 |           },
159 |         ],
160 |       };
161 |       vi.spyOn(fs, 'readFileSync').mockReturnValue(
162 |         JSON.stringify(initialConversation),
163 |       );
164 | 
165 |       chatRecordingService.recordMessage({
166 |         type: 'user',
167 |         content: 'World',
168 |         model: 'gemini-pro',
169 |       });
170 | 
171 |       expect(mkdirSyncSpy).toHaveBeenCalled();
172 |       expect(writeFileSyncSpy).toHaveBeenCalled();
173 |       const conversation = JSON.parse(
174 |         writeFileSyncSpy.mock.calls[0][1] as string,
175 |       ) as ConversationRecord;
176 |       expect(conversation.messages).toHaveLength(2);
177 |       expect(conversation.messages[0].content).toBe('Hello');
178 |       expect(conversation.messages[1].content).toBe('World');
179 |     });
180 |   });
181 | 
182 |   describe('recordThought', () => {
183 |     it('should queue a thought', () => {
184 |       chatRecordingService.initialize();
185 |       chatRecordingService.recordThought({
186 |         subject: 'Thinking',
187 |         description: 'Thinking...',
188 |       });
189 |       // @ts-expect-error private property
190 |       expect(chatRecordingService.queuedThoughts).toHaveLength(1);
191 |       // @ts-expect-error private property
192 |       expect(chatRecordingService.queuedThoughts[0].subject).toBe('Thinking');
193 |       // @ts-expect-error private property
194 |       expect(chatRecordingService.queuedThoughts[0].description).toBe(
195 |         'Thinking...',
196 |       );
197 |     });
198 |   });
199 | 
200 |   describe('recordMessageTokens', () => {
201 |     beforeEach(() => {
202 |       chatRecordingService.initialize();
203 |     });
204 | 
205 |     it('should update the last message with token info', () => {
206 |       const writeFileSyncSpy = vi
207 |         .spyOn(fs, 'writeFileSync')
208 |         .mockImplementation(() => undefined);
209 |       const initialConversation = {
210 |         sessionId: 'test-session-id',
211 |         projectHash: 'test-project-hash',
212 |         messages: [
213 |           {
214 |             id: '1',
215 |             type: 'gemini',
216 |             content: 'Response',
217 |             timestamp: new Date().toISOString(),
218 |           },
219 |         ],
220 |       };
221 |       vi.spyOn(fs, 'readFileSync').mockReturnValue(
222 |         JSON.stringify(initialConversation),
223 |       );
224 | 
225 |       chatRecordingService.recordMessageTokens({
226 |         promptTokenCount: 1,
227 |         candidatesTokenCount: 2,
228 |         totalTokenCount: 3,
229 |         cachedContentTokenCount: 0,
230 |       });
231 | 
232 |       expect(mkdirSyncSpy).toHaveBeenCalled();
233 |       expect(writeFileSyncSpy).toHaveBeenCalled();
234 |       const conversation = JSON.parse(
235 |         writeFileSyncSpy.mock.calls[0][1] as string,
236 |       ) as ConversationRecord;
237 |       expect(conversation.messages[0]).toEqual({
238 |         ...initialConversation.messages[0],
239 |         tokens: {
240 |           input: 1,
241 |           output: 2,
242 |           total: 3,
243 |           cached: 0,
244 |           thoughts: 0,
245 |           tool: 0,
246 |         },
247 |       });
248 |     });
249 | 
250 |     it('should queue token info if the last message already has tokens', () => {
251 |       const initialConversation = {
252 |         sessionId: 'test-session-id',
253 |         projectHash: 'test-project-hash',
254 |         messages: [
255 |           {
256 |             id: '1',
257 |             type: 'gemini',
258 |             content: 'Response',
259 |             timestamp: new Date().toISOString(),
260 |             tokens: { input: 1, output: 1, total: 2, cached: 0 },
261 |           },
262 |         ],
263 |       };
264 |       vi.spyOn(fs, 'readFileSync').mockReturnValue(
265 |         JSON.stringify(initialConversation),
266 |       );
267 | 
268 |       chatRecordingService.recordMessageTokens({
269 |         promptTokenCount: 2,
270 |         candidatesTokenCount: 2,
271 |         totalTokenCount: 4,
272 |         cachedContentTokenCount: 0,
273 |       });
274 | 
275 |       // @ts-expect-error private property
276 |       expect(chatRecordingService.queuedTokens).toEqual({
277 |         input: 2,
278 |         output: 2,
279 |         total: 4,
280 |         cached: 0,
281 |         thoughts: 0,
282 |         tool: 0,
283 |       });
284 |     });
285 |   });
286 | 
287 |   describe('recordToolCalls', () => {
288 |     beforeEach(() => {
289 |       chatRecordingService.initialize();
290 |     });
291 | 
292 |     it('should add new tool calls to the last message', () => {
293 |       const writeFileSyncSpy = vi
294 |         .spyOn(fs, 'writeFileSync')
295 |         .mockImplementation(() => undefined);
296 |       const initialConversation = {
297 |         sessionId: 'test-session-id',
298 |         projectHash: 'test-project-hash',
299 |         messages: [
300 |           {
301 |             id: '1',
302 |             type: 'gemini',
303 |             content: '',
304 |             timestamp: new Date().toISOString(),
305 |           },
306 |         ],
307 |       };
308 |       vi.spyOn(fs, 'readFileSync').mockReturnValue(
309 |         JSON.stringify(initialConversation),
310 |       );
311 | 
312 |       const toolCall: ToolCallRecord = {
313 |         id: 'tool-1',
314 |         name: 'testTool',
315 |         args: {},
316 |         status: 'awaiting_approval',
317 |         timestamp: new Date().toISOString(),
318 |       };
319 |       chatRecordingService.recordToolCalls('gemini-pro', [toolCall]);
320 | 
321 |       expect(mkdirSyncSpy).toHaveBeenCalled();
322 |       expect(writeFileSyncSpy).toHaveBeenCalled();
323 |       const conversation = JSON.parse(
324 |         writeFileSyncSpy.mock.calls[0][1] as string,
325 |       ) as ConversationRecord;
326 |       expect(conversation.messages[0]).toEqual({
327 |         ...initialConversation.messages[0],
328 |         toolCalls: [
329 |           {
330 |             ...toolCall,
331 |             displayName: 'Test Tool',
332 |             description: 'A test tool',
333 |             renderOutputAsMarkdown: false,
334 |           },
335 |         ],
336 |       });
337 |     });
338 | 
339 |     it('should create a new message if the last message is not from gemini', () => {
340 |       const writeFileSyncSpy = vi
341 |         .spyOn(fs, 'writeFileSync')
342 |         .mockImplementation(() => undefined);
343 |       const initialConversation = {
344 |         sessionId: 'test-session-id',
345 |         projectHash: 'test-project-hash',
346 |         messages: [
347 |           {
348 |             id: 'a-uuid',
349 |             type: 'user',
350 |             content: 'call a tool',
351 |             timestamp: new Date().toISOString(),
352 |           },
353 |         ],
354 |       };
355 |       vi.spyOn(fs, 'readFileSync').mockReturnValue(
356 |         JSON.stringify(initialConversation),
357 |       );
358 | 
359 |       const toolCall: ToolCallRecord = {
360 |         id: 'tool-1',
361 |         name: 'testTool',
362 |         args: {},
363 |         status: 'awaiting_approval',
364 |         timestamp: new Date().toISOString(),
365 |       };
366 |       chatRecordingService.recordToolCalls('gemini-pro', [toolCall]);
367 | 
368 |       expect(mkdirSyncSpy).toHaveBeenCalled();
369 |       expect(writeFileSyncSpy).toHaveBeenCalled();
370 |       const conversation = JSON.parse(
371 |         writeFileSyncSpy.mock.calls[0][1] as string,
372 |       ) as ConversationRecord;
373 |       expect(conversation.messages).toHaveLength(2);
374 |       expect(conversation.messages[1]).toEqual({
375 |         ...conversation.messages[1],
376 |         id: 'this-is-a-test-uuid',
377 |         model: 'gemini-pro',
378 |         type: 'gemini',
379 |         thoughts: [],
380 |         content: '',
381 |         toolCalls: [
382 |           {
383 |             ...toolCall,
384 |             displayName: 'Test Tool',
385 |             description: 'A test tool',
386 |             renderOutputAsMarkdown: false,
387 |           },
388 |         ],
389 |       });
390 |     });
391 |   });
392 | 
393 |   describe('deleteSession', () => {
394 |     it('should delete the session file', () => {
395 |       const unlinkSyncSpy = vi
396 |         .spyOn(fs, 'unlinkSync')
397 |         .mockImplementation(() => undefined);
398 |       chatRecordingService.deleteSession('test-session-id');
399 |       expect(unlinkSyncSpy).toHaveBeenCalledWith(
400 |         '/test/project/root/.gemini/tmp/chats/test-session-id.json',
401 |       );
402 |     });
403 |   });
404 | });
```

src/services/chatRecordingService.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { type Config } from '../config/config.js';
8 | import { type Status } from '../core/coreToolScheduler.js';
9 | import { type ThoughtSummary } from '../utils/thoughtUtils.js';
10 | import { getProjectHash } from '../utils/paths.js';
11 | import path from 'node:path';
12 | import fs from 'node:fs';
13 | import { randomUUID } from 'node:crypto';
14 | import type {
15 |   PartListUnion,
16 |   GenerateContentResponseUsageMetadata,
17 | } from '@google/genai';
18 | 
19 | export const SESSION_FILE_PREFIX = 'session-';
20 | 
21 | /**
22 |  * Token usage summary for a message or conversation.
23 |  */
24 | export interface TokensSummary {
25 |   input: number; // promptTokenCount
26 |   output: number; // candidatesTokenCount
27 |   cached: number; // cachedContentTokenCount
28 |   thoughts?: number; // thoughtsTokenCount
29 |   tool?: number; // toolUsePromptTokenCount
30 |   total: number; // totalTokenCount
31 | }
32 | 
33 | /**
34 |  * Base fields common to all messages.
35 |  */
36 | export interface BaseMessageRecord {
37 |   id: string;
38 |   timestamp: string;
39 |   content: PartListUnion;
40 | }
41 | 
42 | /**
43 |  * Record of a tool call execution within a conversation.
44 |  */
45 | export interface ToolCallRecord {
46 |   id: string;
47 |   name: string;
48 |   args: Record<string, unknown>;
49 |   result?: PartListUnion | null;
50 |   status: Status;
51 |   timestamp: string;
52 |   // UI-specific fields for display purposes
53 |   displayName?: string;
54 |   description?: string;
55 |   resultDisplay?: string;
56 |   renderOutputAsMarkdown?: boolean;
57 | }
58 | 
59 | /**
60 |  * Message type and message type-specific fields.
61 |  */
62 | export type ConversationRecordExtra =
63 |   | {
64 |       type: 'user';
65 |     }
66 |   | {
67 |       type: 'gemini';
68 |       toolCalls?: ToolCallRecord[];
69 |       thoughts?: Array<ThoughtSummary & { timestamp: string }>;
70 |       tokens?: TokensSummary | null;
71 |       model?: string;
72 |     };
73 | 
74 | /**
75 |  * A single message record in a conversation.
76 |  */
77 | export type MessageRecord = BaseMessageRecord & ConversationRecordExtra;
78 | 
79 | /**
80 |  * Complete conversation record stored in session files.
81 |  */
82 | export interface ConversationRecord {
83 |   sessionId: string;
84 |   projectHash: string;
85 |   startTime: string;
86 |   lastUpdated: string;
87 |   messages: MessageRecord[];
88 | }
89 | 
90 | /**
91 |  * Data structure for resuming an existing session.
92 |  */
93 | export interface ResumedSessionData {
94 |   conversation: ConversationRecord;
95 |   filePath: string;
96 | }
97 | 
98 | /**
99 |  * Service for automatically recording chat conversations to disk.
100 |  *
101 |  * This service provides comprehensive conversation recording that captures:
102 |  * - All user and assistant messages
103 |  * - Tool calls and their execution results
104 |  * - Token usage statistics
105 |  * - Assistant thoughts and reasoning
106 |  *
107 |  * Sessions are stored as JSON files in ~/.gemini/tmp/<project_hash>/chats/
108 |  */
109 | export class ChatRecordingService {
110 |   private conversationFile: string | null = null;
111 |   private cachedLastConvData: string | null = null;
112 |   private sessionId: string;
113 |   private projectHash: string;
114 |   private queuedThoughts: Array<ThoughtSummary & { timestamp: string }> = [];
115 |   private queuedTokens: TokensSummary | null = null;
116 |   private config: Config;
117 | 
118 |   constructor(config: Config) {
119 |     this.config = config;
120 |     this.sessionId = config.getSessionId();
121 |     this.projectHash = getProjectHash(config.getProjectRoot());
122 |   }
123 | 
124 |   /**
125 |    * Initializes the chat recording service: creates a new conversation file and associates it with
126 |    * this service instance, or resumes from an existing session if resumedSessionData is provided.
127 |    */
128 |   initialize(resumedSessionData?: ResumedSessionData): void {
129 |     try {
130 |       if (resumedSessionData) {
131 |         // Resume from existing session
132 |         this.conversationFile = resumedSessionData.filePath;
133 |         this.sessionId = resumedSessionData.conversation.sessionId;
134 | 
135 |         // Update the session ID in the existing file
136 |         this.updateConversation((conversation) => {
137 |           conversation.sessionId = this.sessionId;
138 |         });
139 | 
140 |         // Clear any cached data to force fresh reads
141 |         this.cachedLastConvData = null;
142 |       } else {
143 |         // Create new session
144 |         const chatsDir = path.join(
145 |           this.config.storage.getProjectTempDir(),
146 |           'chats',
147 |         );
148 |         fs.mkdirSync(chatsDir, { recursive: true });
149 | 
150 |         const timestamp = new Date()
151 |           .toISOString()
152 |           .slice(0, 16)
153 |           .replace(/:/g, '-');
154 |         const filename = `${SESSION_FILE_PREFIX}${timestamp}-${this.sessionId.slice(
155 |           0,
156 |           8,
157 |         )}.json`;
158 |         this.conversationFile = path.join(chatsDir, filename);
159 | 
160 |         this.writeConversation({
161 |           sessionId: this.sessionId,
162 |           projectHash: this.projectHash,
163 |           startTime: new Date().toISOString(),
164 |           lastUpdated: new Date().toISOString(),
165 |           messages: [],
166 |         });
167 |       }
168 | 
169 |       // Clear any queued data since this is a fresh start
170 |       this.queuedThoughts = [];
171 |       this.queuedTokens = null;
172 |     } catch (error) {
173 |       console.error('Error initializing chat recording service:', error);
174 |       throw error;
175 |     }
176 |   }
177 | 
178 |   private getLastMessage(
179 |     conversation: ConversationRecord,
180 |   ): MessageRecord | undefined {
181 |     return conversation.messages.at(-1);
182 |   }
183 | 
184 |   private newMessage(
185 |     type: ConversationRecordExtra['type'],
186 |     content: PartListUnion,
187 |   ): MessageRecord {
188 |     return {
189 |       id: randomUUID(),
190 |       timestamp: new Date().toISOString(),
191 |       type,
192 |       content,
193 |     };
194 |   }
195 | 
196 |   /**
197 |    * Records a message in the conversation.
198 |    */
199 |   recordMessage(message: {
200 |     model: string | undefined;
201 |     type: ConversationRecordExtra['type'];
202 |     content: PartListUnion;
203 |   }): void {
204 |     if (!this.conversationFile) return;
205 | 
206 |     try {
207 |       this.updateConversation((conversation) => {
208 |         const msg = this.newMessage(message.type, message.content);
209 |         if (msg.type === 'gemini') {
210 |           // If it's a new Gemini message then incorporate any queued thoughts.
211 |           conversation.messages.push({
212 |             ...msg,
213 |             thoughts: this.queuedThoughts,
214 |             tokens: this.queuedTokens,
215 |             model: message.model,
216 |           });
217 |           this.queuedThoughts = [];
218 |           this.queuedTokens = null;
219 |         } else {
220 |           // Or else just add it.
221 |           conversation.messages.push(msg);
222 |         }
223 |       });
224 |     } catch (error) {
225 |       console.error('Error saving message:', error);
226 |       throw error;
227 |     }
228 |   }
229 | 
230 |   /**
231 |    * Records a thought from the assistant's reasoning process.
232 |    */
233 |   recordThought(thought: ThoughtSummary): void {
234 |     if (!this.conversationFile) return;
235 | 
236 |     try {
237 |       this.queuedThoughts.push({
238 |         ...thought,
239 |         timestamp: new Date().toISOString(),
240 |       });
241 |     } catch (error) {
242 |       console.error('Error saving thought:', error);
243 |       throw error;
244 |     }
245 |   }
246 | 
247 |   /**
248 |    * Updates the tokens for the last message in the conversation (which should be by Gemini).
249 |    */
250 |   recordMessageTokens(
251 |     respUsageMetadata: GenerateContentResponseUsageMetadata,
252 |   ): void {
253 |     if (!this.conversationFile) return;
254 | 
255 |     try {
256 |       const tokens = {
257 |         input: respUsageMetadata.promptTokenCount ?? 0,
258 |         output: respUsageMetadata.candidatesTokenCount ?? 0,
259 |         cached: respUsageMetadata.cachedContentTokenCount ?? 0,
260 |         thoughts: respUsageMetadata.thoughtsTokenCount ?? 0,
261 |         tool: respUsageMetadata.toolUsePromptTokenCount ?? 0,
262 |         total: respUsageMetadata.totalTokenCount ?? 0,
263 |       };
264 |       this.updateConversation((conversation) => {
265 |         const lastMsg = this.getLastMessage(conversation);
266 |         // If the last message already has token info, it's because this new token info is for a
267 |         // new message that hasn't been recorded yet.
268 |         if (lastMsg && lastMsg.type === 'gemini' && !lastMsg.tokens) {
269 |           lastMsg.tokens = tokens;
270 |           this.queuedTokens = null;
271 |         } else {
272 |           this.queuedTokens = tokens;
273 |         }
274 |       });
275 |     } catch (error) {
276 |       console.error('Error updating message tokens:', error);
277 |       throw error;
278 |     }
279 |   }
280 | 
281 |   /**
282 |    * Adds tool calls to the last message in the conversation (which should be by Gemini).
283 |    * This method enriches tool calls with metadata from the ToolRegistry.
284 |    */
285 |   recordToolCalls(model: string, toolCalls: ToolCallRecord[]): void {
286 |     if (!this.conversationFile) return;
287 | 
288 |     // Enrich tool calls with metadata from the ToolRegistry
289 |     const toolRegistry = this.config.getToolRegistry();
290 |     const enrichedToolCalls = toolCalls.map((toolCall) => {
291 |       const toolInstance = toolRegistry.getTool(toolCall.name);
292 |       return {
293 |         ...toolCall,
294 |         displayName: toolInstance?.displayName || toolCall.name,
295 |         description: toolInstance?.description || '',
296 |         renderOutputAsMarkdown: toolInstance?.isOutputMarkdown || false,
297 |       };
298 |     });
299 | 
300 |     try {
301 |       this.updateConversation((conversation) => {
302 |         const lastMsg = this.getLastMessage(conversation);
303 |         // If a tool call was made, but the last message isn't from Gemini, it's because Gemini is
304 |         // calling tools without starting the message with text.  So the user submits a prompt, and
305 |         // Gemini immediately calls a tool (maybe with some thinking first).  In that case, create
306 |         // a new empty Gemini message.
307 |         // Also if there are any queued thoughts, it means this tool call(s) is from a new Gemini
308 |         // message--because it's thought some more since we last, if ever, created a new Gemini
309 |         // message from tool calls, when we dequeued the thoughts.
310 |         if (
311 |           !lastMsg ||
312 |           lastMsg.type !== 'gemini' ||
313 |           this.queuedThoughts.length > 0
314 |         ) {
315 |           const newMsg: MessageRecord = {
316 |             ...this.newMessage('gemini' as const, ''),
317 |             // This isn't strictly necessary, but TypeScript apparently can't
318 |             // tell that the first parameter to newMessage() becomes the
319 |             // resulting message's type, and so it thinks that toolCalls may
320 |             // not be present.  Confirming the type here satisfies it.
321 |             type: 'gemini' as const,
322 |             toolCalls: enrichedToolCalls,
323 |             thoughts: this.queuedThoughts,
324 |             model,
325 |           };
326 |           // If there are any queued thoughts join them to this message.
327 |           if (this.queuedThoughts.length > 0) {
328 |             newMsg.thoughts = this.queuedThoughts;
329 |             this.queuedThoughts = [];
330 |           }
331 |           // If there's any queued tokens info join it to this message.
332 |           if (this.queuedTokens) {
333 |             newMsg.tokens = this.queuedTokens;
334 |             this.queuedTokens = null;
335 |           }
336 |           conversation.messages.push(newMsg);
337 |         } else {
338 |           // The last message is an existing Gemini message that we need to update.
339 | 
340 |           // Update any existing tool call entries.
341 |           if (!lastMsg.toolCalls) {
342 |             lastMsg.toolCalls = [];
343 |           }
344 |           lastMsg.toolCalls = lastMsg.toolCalls.map((toolCall) => {
345 |             // If there are multiple tool calls with the same ID, this will take the first one.
346 |             const incomingToolCall = toolCalls.find(
347 |               (tc) => tc.id === toolCall.id,
348 |             );
349 |             if (incomingToolCall) {
350 |               // Merge in the new data to keep preserve thoughts, etc., that were assigned to older
351 |               // versions of the tool call.
352 |               return { ...toolCall, ...incomingToolCall };
353 |             } else {
354 |               return toolCall;
355 |             }
356 |           });
357 | 
358 |           // Add any new tools calls that aren't in the message yet.
359 |           for (const toolCall of enrichedToolCalls) {
360 |             const existingToolCall = lastMsg.toolCalls.find(
361 |               (tc) => tc.id === toolCall.id,
362 |             );
363 |             if (!existingToolCall) {
364 |               lastMsg.toolCalls.push(toolCall);
365 |             }
366 |           }
367 |         }
368 |       });
369 |     } catch (error) {
370 |       console.error('Error adding tool call to message:', error);
371 |       throw error;
372 |     }
373 |   }
374 | 
375 |   /**
376 |    * Loads up the conversation record from disk.
377 |    */
378 |   private readConversation(): ConversationRecord {
379 |     try {
380 |       this.cachedLastConvData = fs.readFileSync(this.conversationFile!, 'utf8');
381 |       return JSON.parse(this.cachedLastConvData);
382 |     } catch (error) {
383 |       if ((error as NodeJS.ErrnoException).code !== 'ENOENT') {
384 |         console.error('Error reading conversation file:', error);
385 |         throw error;
386 |       }
387 | 
388 |       // Placeholder empty conversation if file doesn't exist.
389 |       return {
390 |         sessionId: this.sessionId,
391 |         projectHash: this.projectHash,
392 |         startTime: new Date().toISOString(),
393 |         lastUpdated: new Date().toISOString(),
394 |         messages: [],
395 |       };
396 |     }
397 |   }
398 | 
399 |   /**
400 |    * Saves the conversation record; overwrites the file.
401 |    */
402 |   private writeConversation(conversation: ConversationRecord): void {
403 |     try {
404 |       if (!this.conversationFile) return;
405 |       // Don't write the file yet until there's at least one message.
406 |       if (conversation.messages.length === 0) return;
407 | 
408 |       // Only write the file if this change would change the file.
409 |       if (this.cachedLastConvData !== JSON.stringify(conversation, null, 2)) {
410 |         conversation.lastUpdated = new Date().toISOString();
411 |         const newContent = JSON.stringify(conversation, null, 2);
412 |         this.cachedLastConvData = newContent;
413 |         fs.writeFileSync(this.conversationFile, newContent);
414 |       }
415 |     } catch (error) {
416 |       console.error('Error writing conversation file:', error);
417 |       throw error;
418 |     }
419 |   }
420 | 
421 |   /**
422 |    * Convenient helper for updating the conversation without file reading and writing and time
423 |    * updating boilerplate.
424 |    */
425 |   private updateConversation(
426 |     updateFn: (conversation: ConversationRecord) => void,
427 |   ) {
428 |     const conversation = this.readConversation();
429 |     updateFn(conversation);
430 |     this.writeConversation(conversation);
431 |   }
432 | 
433 |   /**
434 |    * Deletes a session file by session ID.
435 |    */
436 |   deleteSession(sessionId: string): void {
437 |     try {
438 |       const chatsDir = path.join(
439 |         this.config.storage.getProjectTempDir(),
440 |         'chats',
441 |       );
442 |       const sessionPath = path.join(chatsDir, `${sessionId}.json`);
443 |       fs.unlinkSync(sessionPath);
444 |     } catch (error) {
445 |       console.error('Error deleting session:', error);
446 |       throw error;
447 |     }
448 |   }
449 | }
```

src/services/fileDiscoveryService.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach } from 'vitest';
8 | import * as fs from 'node:fs/promises';
9 | import * as os from 'node:os';
10 | import * as path from 'node:path';
11 | import { FileDiscoveryService } from './fileDiscoveryService.js';
12 | 
13 | describe('FileDiscoveryService', () => {
14 |   let testRootDir: string;
15 |   let projectRoot: string;
16 | 
17 |   async function createTestFile(filePath: string, content = '') {
18 |     const fullPath = path.join(projectRoot, filePath);
19 |     await fs.mkdir(path.dirname(fullPath), { recursive: true });
20 |     await fs.writeFile(fullPath, content);
21 |     return fullPath;
22 |   }
23 | 
24 |   beforeEach(async () => {
25 |     testRootDir = await fs.mkdtemp(
26 |       path.join(os.tmpdir(), 'file-discovery-test-'),
27 |     );
28 |     projectRoot = path.join(testRootDir, 'project');
29 |     await fs.mkdir(projectRoot, { recursive: true });
30 |   });
31 | 
32 |   afterEach(async () => {
33 |     await fs.rm(testRootDir, { recursive: true, force: true });
34 |   });
35 | 
36 |   describe('initialization', () => {
37 |     it('should initialize git ignore parser by default in a git repo', async () => {
38 |       await fs.mkdir(path.join(projectRoot, '.git'));
39 |       await createTestFile('.gitignore', 'node_modules/');
40 | 
41 |       const service = new FileDiscoveryService(projectRoot);
42 |       // Let's check the effect of the parser instead of mocking it.
43 |       expect(service.shouldGitIgnoreFile('node_modules/foo.js')).toBe(true);
44 |       expect(service.shouldGitIgnoreFile('src/foo.js')).toBe(false);
45 |     });
46 | 
47 |     it('should not load git repo patterns when not in a git repo', async () => {
48 |       // No .git directory
49 |       await createTestFile('.gitignore', 'node_modules/');
50 |       const service = new FileDiscoveryService(projectRoot);
51 | 
52 |       // .gitignore is not loaded in non-git repos
53 |       expect(service.shouldGitIgnoreFile('node_modules/foo.js')).toBe(false);
54 |     });
55 | 
56 |     it('should load .geminiignore patterns even when not in a git repo', async () => {
57 |       await createTestFile('.geminiignore', 'secrets.txt');
58 |       const service = new FileDiscoveryService(projectRoot);
59 | 
60 |       expect(service.shouldGeminiIgnoreFile('secrets.txt')).toBe(true);
61 |       expect(service.shouldGeminiIgnoreFile('src/index.js')).toBe(false);
62 |     });
63 |   });
64 | 
65 |   describe('filterFiles', () => {
66 |     beforeEach(async () => {
67 |       await fs.mkdir(path.join(projectRoot, '.git'));
68 |       await createTestFile('.gitignore', 'node_modules/\n.git/\ndist');
69 |       await createTestFile('.geminiignore', 'logs/');
70 |     });
71 | 
72 |     it('should filter out git-ignored and gemini-ignored files by default', () => {
73 |       const files = [
74 |         'src/index.ts',
75 |         'node_modules/package/index.js',
76 |         'README.md',
77 |         '.git/config',
78 |         'dist/bundle.js',
79 |         'logs/latest.log',
80 |       ].map((f) => path.join(projectRoot, f));
81 | 
82 |       const service = new FileDiscoveryService(projectRoot);
83 | 
84 |       expect(service.filterFiles(files)).toEqual(
85 |         ['src/index.ts', 'README.md'].map((f) => path.join(projectRoot, f)),
86 |       );
87 |     });
88 | 
89 |     it('should not filter files when respectGitIgnore is false', () => {
90 |       const files = [
91 |         'src/index.ts',
92 |         'node_modules/package/index.js',
93 |         '.git/config',
94 |         'logs/latest.log',
95 |       ].map((f) => path.join(projectRoot, f));
96 | 
97 |       const service = new FileDiscoveryService(projectRoot);
98 | 
99 |       const filtered = service.filterFiles(files, {
100 |         respectGitIgnore: false,
101 |         respectGeminiIgnore: true, // still respect this one
102 |       });
103 | 
104 |       expect(filtered).toEqual(
105 |         ['src/index.ts', 'node_modules/package/index.js', '.git/config'].map(
106 |           (f) => path.join(projectRoot, f),
107 |         ),
108 |       );
109 |     });
110 | 
111 |     it('should not filter files when respectGeminiIgnore is false', () => {
112 |       const files = [
113 |         'src/index.ts',
114 |         'node_modules/package/index.js',
115 |         'logs/latest.log',
116 |       ].map((f) => path.join(projectRoot, f));
117 | 
118 |       const service = new FileDiscoveryService(projectRoot);
119 | 
120 |       const filtered = service.filterFiles(files, {
121 |         respectGitIgnore: true,
122 |         respectGeminiIgnore: false,
123 |       });
124 | 
125 |       expect(filtered).toEqual(
126 |         ['src/index.ts', 'logs/latest.log'].map((f) =>
127 |           path.join(projectRoot, f),
128 |         ),
129 |       );
130 |     });
131 | 
132 |     it('should handle empty file list', () => {
133 |       const service = new FileDiscoveryService(projectRoot);
134 | 
135 |       expect(service.filterFiles([])).toEqual([]);
136 |     });
137 |   });
138 | 
139 |   describe('shouldGitIgnoreFile & shouldGeminiIgnoreFile', () => {
140 |     beforeEach(async () => {
141 |       await fs.mkdir(path.join(projectRoot, '.git'));
142 |       await createTestFile('.gitignore', 'node_modules/');
143 |       await createTestFile('.geminiignore', '*.log');
144 |     });
145 | 
146 |     it('should return true for git-ignored files', () => {
147 |       const service = new FileDiscoveryService(projectRoot);
148 | 
149 |       expect(
150 |         service.shouldGitIgnoreFile(
151 |           path.join(projectRoot, 'node_modules/package/index.js'),
152 |         ),
153 |       ).toBe(true);
154 |     });
155 | 
156 |     it('should return false for non-git-ignored files', () => {
157 |       const service = new FileDiscoveryService(projectRoot);
158 | 
159 |       expect(
160 |         service.shouldGitIgnoreFile(path.join(projectRoot, 'src/index.ts')),
161 |       ).toBe(false);
162 |     });
163 | 
164 |     it('should return true for gemini-ignored files', () => {
165 |       const service = new FileDiscoveryService(projectRoot);
166 | 
167 |       expect(
168 |         service.shouldGeminiIgnoreFile(path.join(projectRoot, 'debug.log')),
169 |       ).toBe(true);
170 |     });
171 | 
172 |     it('should return false for non-gemini-ignored files', () => {
173 |       const service = new FileDiscoveryService(projectRoot);
174 | 
175 |       expect(
176 |         service.shouldGeminiIgnoreFile(path.join(projectRoot, 'src/index.ts')),
177 |       ).toBe(false);
178 |     });
179 |   });
180 | 
181 |   describe('edge cases', () => {
182 |     it('should handle relative project root paths', async () => {
183 |       await fs.mkdir(path.join(projectRoot, '.git'));
184 |       await createTestFile('.gitignore', 'ignored.txt');
185 |       const service = new FileDiscoveryService(
186 |         path.relative(process.cwd(), projectRoot),
187 |       );
188 | 
189 |       expect(
190 |         service.shouldGitIgnoreFile(path.join(projectRoot, 'ignored.txt')),
191 |       ).toBe(true);
192 |       expect(
193 |         service.shouldGitIgnoreFile(path.join(projectRoot, 'not-ignored.txt')),
194 |       ).toBe(false);
195 |     });
196 | 
197 |     it('should handle filterFiles with undefined options', async () => {
198 |       await fs.mkdir(path.join(projectRoot, '.git'));
199 |       await createTestFile('.gitignore', 'ignored.txt');
200 |       const service = new FileDiscoveryService(projectRoot);
201 | 
202 |       const files = ['src/index.ts', 'ignored.txt'].map((f) =>
203 |         path.join(projectRoot, f),
204 |       );
205 | 
206 |       expect(service.filterFiles(files, undefined)).toEqual([
207 |         path.join(projectRoot, 'src/index.ts'),
208 |       ]);
209 |     });
210 |   });
211 | });
```

src/services/fileDiscoveryService.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { GitIgnoreFilter } from '../utils/gitIgnoreParser.js';
8 | import type { GeminiIgnoreFilter } from '../utils/geminiIgnoreParser.js';
9 | import { GitIgnoreParser } from '../utils/gitIgnoreParser.js';
10 | import { GeminiIgnoreParser } from '../utils/geminiIgnoreParser.js';
11 | import { isGitRepository } from '../utils/gitUtils.js';
12 | import * as path from 'node:path';
13 | 
14 | export interface FilterFilesOptions {
15 |   respectGitIgnore?: boolean;
16 |   respectGeminiIgnore?: boolean;
17 | }
18 | 
19 | export interface FilterReport {
20 |   filteredPaths: string[];
21 |   gitIgnoredCount: number;
22 |   geminiIgnoredCount: number;
23 | }
24 | 
25 | export class FileDiscoveryService {
26 |   private gitIgnoreFilter: GitIgnoreFilter | null = null;
27 |   private geminiIgnoreFilter: GeminiIgnoreFilter | null = null;
28 |   private projectRoot: string;
29 | 
30 |   constructor(projectRoot: string) {
31 |     this.projectRoot = path.resolve(projectRoot);
32 |     if (isGitRepository(this.projectRoot)) {
33 |       this.gitIgnoreFilter = new GitIgnoreParser(this.projectRoot);
34 |     }
35 |     this.geminiIgnoreFilter = new GeminiIgnoreParser(this.projectRoot);
36 |   }
37 | 
38 |   /**
39 |    * Filters a list of file paths based on git ignore rules
40 |    */
41 |   filterFiles(
42 |     filePaths: string[],
43 |     options: FilterFilesOptions = {
44 |       respectGitIgnore: true,
45 |       respectGeminiIgnore: true,
46 |     },
47 |   ): string[] {
48 |     return filePaths.filter((filePath) => {
49 |       if (options.respectGitIgnore && this.shouldGitIgnoreFile(filePath)) {
50 |         return false;
51 |       }
52 |       if (
53 |         options.respectGeminiIgnore &&
54 |         this.shouldGeminiIgnoreFile(filePath)
55 |       ) {
56 |         return false;
57 |       }
58 |       return true;
59 |     });
60 |   }
61 | 
62 |   /**
63 |    * Filters a list of file paths based on git ignore rules and returns a report
64 |    * with counts of ignored files.
65 |    */
66 |   filterFilesWithReport(
67 |     filePaths: string[],
68 |     opts: FilterFilesOptions = {
69 |       respectGitIgnore: true,
70 |       respectGeminiIgnore: true,
71 |     },
72 |   ): FilterReport {
73 |     const filteredPaths: string[] = [];
74 |     let gitIgnoredCount = 0;
75 |     let geminiIgnoredCount = 0;
76 | 
77 |     for (const filePath of filePaths) {
78 |       if (opts.respectGitIgnore && this.shouldGitIgnoreFile(filePath)) {
79 |         gitIgnoredCount++;
80 |         continue;
81 |       }
82 | 
83 |       if (opts.respectGeminiIgnore && this.shouldGeminiIgnoreFile(filePath)) {
84 |         geminiIgnoredCount++;
85 |         continue;
86 |       }
87 | 
88 |       filteredPaths.push(filePath);
89 |     }
90 | 
91 |     return {
92 |       filteredPaths,
93 |       gitIgnoredCount,
94 |       geminiIgnoredCount,
95 |     };
96 |   }
97 | 
98 |   /**
99 |    * Checks if a single file should be git-ignored
100 |    */
101 |   shouldGitIgnoreFile(filePath: string): boolean {
102 |     if (this.gitIgnoreFilter) {
103 |       return this.gitIgnoreFilter.isIgnored(filePath);
104 |     }
105 |     return false;
106 |   }
107 | 
108 |   /**
109 |    * Checks if a single file should be gemini-ignored
110 |    */
111 |   shouldGeminiIgnoreFile(filePath: string): boolean {
112 |     if (this.geminiIgnoreFilter) {
113 |       return this.geminiIgnoreFilter.isIgnored(filePath);
114 |     }
115 |     return false;
116 |   }
117 | 
118 |   /**
119 |    * Unified method to check if a file should be ignored based on filtering options
120 |    */
121 |   shouldIgnoreFile(
122 |     filePath: string,
123 |     options: FilterFilesOptions = {},
124 |   ): boolean {
125 |     const { respectGitIgnore = true, respectGeminiIgnore = true } = options;
126 | 
127 |     if (respectGitIgnore && this.shouldGitIgnoreFile(filePath)) {
128 |       return true;
129 |     }
130 |     if (respectGeminiIgnore && this.shouldGeminiIgnoreFile(filePath)) {
131 |       return true;
132 |     }
133 |     return false;
134 |   }
135 | 
136 |   /**
137 |    * Returns loaded patterns from .geminiignore
138 |    */
139 |   getGeminiIgnorePatterns(): string[] {
140 |     return this.geminiIgnoreFilter?.getPatterns() ?? [];
141 |   }
142 | }
```

src/services/fileSystemService.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
8 | import fs from 'node:fs/promises';
9 | import { StandardFileSystemService } from './fileSystemService.js';
10 | 
11 | vi.mock('fs/promises');
12 | 
13 | describe('StandardFileSystemService', () => {
14 |   let fileSystem: StandardFileSystemService;
15 | 
16 |   beforeEach(() => {
17 |     vi.resetAllMocks();
18 |     fileSystem = new StandardFileSystemService();
19 |   });
20 | 
21 |   afterEach(() => {
22 |     vi.restoreAllMocks();
23 |   });
24 | 
25 |   describe('readTextFile', () => {
26 |     it('should read file content using fs', async () => {
27 |       const testContent = 'Hello, World!';
28 |       vi.mocked(fs.readFile).mockResolvedValue(testContent);
29 | 
30 |       const result = await fileSystem.readTextFile('/test/file.txt');
31 | 
32 |       expect(fs.readFile).toHaveBeenCalledWith('/test/file.txt', 'utf-8');
33 |       expect(result).toBe(testContent);
34 |     });
35 | 
36 |     it('should propagate fs.readFile errors', async () => {
37 |       const error = new Error('ENOENT: File not found');
38 |       vi.mocked(fs.readFile).mockRejectedValue(error);
39 | 
40 |       await expect(fileSystem.readTextFile('/test/file.txt')).rejects.toThrow(
41 |         'ENOENT: File not found',
42 |       );
43 |     });
44 |   });
45 | 
46 |   describe('writeTextFile', () => {
47 |     it('should write file content using fs', async () => {
48 |       vi.mocked(fs.writeFile).mockResolvedValue();
49 | 
50 |       await fileSystem.writeTextFile('/test/file.txt', 'Hello, World!');
51 | 
52 |       expect(fs.writeFile).toHaveBeenCalledWith(
53 |         '/test/file.txt',
54 |         'Hello, World!',
55 |         'utf-8',
56 |       );
57 |     });
58 |   });
59 | });
```

src/services/fileSystemService.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import fs from 'node:fs/promises';
8 | import * as path from 'node:path';
9 | import { globSync } from 'glob';
10 | 
11 | /**
12 |  * Interface for file system operations that may be delegated to different implementations
13 |  */
14 | export interface FileSystemService {
15 |   /**
16 |    * Read text content from a file
17 |    *
18 |    * @param filePath - The path to the file to read
19 |    * @returns The file content as a string
20 |    */
21 |   readTextFile(filePath: string): Promise<string>;
22 | 
23 |   /**
24 |    * Write text content to a file
25 |    *
26 |    * @param filePath - The path to the file to write
27 |    * @param content - The content to write
28 |    */
29 |   writeTextFile(filePath: string, content: string): Promise<void>;
30 | 
31 |   /**
32 |    * Finds files with a given name within specified search paths.
33 |    *
34 |    * @param fileName - The name of the file to find.
35 |    * @param searchPaths - An array of directory paths to search within.
36 |    * @returns An array of absolute paths to the found files.
37 |    */
38 |   findFiles(fileName: string, searchPaths: readonly string[]): string[];
39 | }
40 | 
41 | /**
42 |  * Standard file system implementation
43 |  */
44 | export class StandardFileSystemService implements FileSystemService {
45 |   async readTextFile(filePath: string): Promise<string> {
46 |     return fs.readFile(filePath, 'utf-8');
47 |   }
48 | 
49 |   async writeTextFile(filePath: string, content: string): Promise<void> {
50 |     await fs.writeFile(filePath, content, 'utf-8');
51 |   }
52 | 
53 |   findFiles(fileName: string, searchPaths: readonly string[]): string[] {
54 |     return searchPaths.flatMap((searchPath) => {
55 |       const pattern = path.posix.join(searchPath, '**', fileName);
56 |       return globSync(pattern, {
57 |         nodir: true,
58 |         absolute: true,
59 |       });
60 |     });
61 |   }
62 | }
```

src/services/gitService.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   vi,
12 |   beforeEach,
13 |   afterEach,
14 |   type Mock,
15 | } from 'vitest';
16 | import { GitService } from './gitService.js';
17 | import { Storage } from '../config/storage.js';
18 | import * as path from 'node:path';
19 | import * as fs from 'node:fs/promises';
20 | import * as os from 'node:os';
21 | import { getProjectHash, GEMINI_DIR } from '../utils/paths.js';
22 | import { spawnAsync } from '../utils/shell-utils.js';
23 | 
24 | vi.mock('../utils/shell-utils.js', () => ({
25 |   spawnAsync: vi.fn(),
26 | }));
27 | 
28 | const hoistedMockEnv = vi.hoisted(() => vi.fn());
29 | const hoistedMockSimpleGit = vi.hoisted(() => vi.fn());
30 | const hoistedMockCheckIsRepo = vi.hoisted(() => vi.fn());
31 | const hoistedMockInit = vi.hoisted(() => vi.fn());
32 | const hoistedMockRaw = vi.hoisted(() => vi.fn());
33 | const hoistedMockAdd = vi.hoisted(() => vi.fn());
34 | const hoistedMockCommit = vi.hoisted(() => vi.fn());
35 | vi.mock('simple-git', () => ({
36 |   simpleGit: hoistedMockSimpleGit.mockImplementation(() => ({
37 |     checkIsRepo: hoistedMockCheckIsRepo,
38 |     init: hoistedMockInit,
39 |     raw: hoistedMockRaw,
40 |     add: hoistedMockAdd,
41 |     commit: hoistedMockCommit,
42 |     env: hoistedMockEnv,
43 |   })),
44 |   CheckRepoActions: { IS_REPO_ROOT: 'is-repo-root' },
45 | }));
46 | 
47 | const hoistedIsGitRepositoryMock = vi.hoisted(() => vi.fn());
48 | vi.mock('../utils/gitUtils.js', () => ({
49 |   isGitRepository: hoistedIsGitRepositoryMock,
50 | }));
51 | 
52 | const hoistedMockHomedir = vi.hoisted(() => vi.fn());
53 | vi.mock('os', async (importOriginal) => {
54 |   const actual = await importOriginal<typeof os>();
55 |   return {
56 |     ...actual,
57 |     homedir: hoistedMockHomedir,
58 |   };
59 | });
60 | 
61 | describe('GitService', () => {
62 |   let testRootDir: string;
63 |   let projectRoot: string;
64 |   let homedir: string;
65 |   let hash: string;
66 |   let storage: Storage;
67 | 
68 |   beforeEach(async () => {
69 |     testRootDir = await fs.mkdtemp(path.join(os.tmpdir(), 'git-service-test-'));
70 |     projectRoot = path.join(testRootDir, 'project');
71 |     homedir = path.join(testRootDir, 'home');
72 |     await fs.mkdir(projectRoot, { recursive: true });
73 |     await fs.mkdir(homedir, { recursive: true });
74 | 
75 |     hash = getProjectHash(projectRoot);
76 | 
77 |     vi.clearAllMocks();
78 |     hoistedIsGitRepositoryMock.mockReturnValue(true);
79 |     (spawnAsync as Mock).mockResolvedValue({
80 |       stdout: 'git version 2.0.0',
81 |       stderr: '',
82 |     });
83 | 
84 |     hoistedMockHomedir.mockReturnValue(homedir);
85 | 
86 |     hoistedMockEnv.mockImplementation(() => ({
87 |       checkIsRepo: hoistedMockCheckIsRepo,
88 |       init: hoistedMockInit,
89 |       raw: hoistedMockRaw,
90 |       add: hoistedMockAdd,
91 |       commit: hoistedMockCommit,
92 |     }));
93 |     hoistedMockSimpleGit.mockImplementation(() => ({
94 |       checkIsRepo: hoistedMockCheckIsRepo,
95 |       init: hoistedMockInit,
96 |       raw: hoistedMockRaw,
97 |       add: hoistedMockAdd,
98 |       commit: hoistedMockCommit,
99 |       env: hoistedMockEnv,
100 |     }));
101 |     hoistedMockCheckIsRepo.mockResolvedValue(false);
102 |     hoistedMockInit.mockResolvedValue(undefined);
103 |     hoistedMockRaw.mockResolvedValue('');
104 |     hoistedMockAdd.mockResolvedValue(undefined);
105 |     hoistedMockCommit.mockResolvedValue({
106 |       commit: 'initial',
107 |     });
108 |     storage = new Storage(projectRoot);
109 |   });
110 | 
111 |   afterEach(async () => {
112 |     vi.restoreAllMocks();
113 |     await fs.rm(testRootDir, { recursive: true, force: true });
114 |   });
115 | 
116 |   describe('constructor', () => {
117 |     it('should successfully create an instance', () => {
118 |       expect(() => new GitService(projectRoot, storage)).not.toThrow();
119 |     });
120 |   });
121 | 
122 |   describe('verifyGitAvailability', () => {
123 |     it('should resolve true if git --version command succeeds', async () => {
124 |       const service = new GitService(projectRoot, storage);
125 |       await expect(service.verifyGitAvailability()).resolves.toBe(true);
126 |       expect(spawnAsync).toHaveBeenCalledWith('git', ['--version']);
127 |     });
128 | 
129 |     it('should resolve false if git --version command fails', async () => {
130 |       (spawnAsync as Mock).mockRejectedValue(new Error('git not found'));
131 |       const service = new GitService(projectRoot, storage);
132 |       await expect(service.verifyGitAvailability()).resolves.toBe(false);
133 |     });
134 |   });
135 | 
136 |   describe('initialize', () => {
137 |     it('should throw an error if Git is not available', async () => {
138 |       (spawnAsync as Mock).mockRejectedValue(new Error('git not found'));
139 |       const service = new GitService(projectRoot, storage);
140 |       await expect(service.initialize()).rejects.toThrow(
141 |         'Checkpointing is enabled, but Git is not installed. Please install Git or disable checkpointing to continue.',
142 |       );
143 |     });
144 | 
145 |     it('should call setupShadowGitRepository if Git is available', async () => {
146 |       const service = new GitService(projectRoot, storage);
147 |       const setupSpy = vi
148 |         .spyOn(service, 'setupShadowGitRepository')
149 |         .mockResolvedValue(undefined);
150 | 
151 |       await service.initialize();
152 |       expect(setupSpy).toHaveBeenCalled();
153 |     });
154 |   });
155 | 
156 |   describe('setupShadowGitRepository', () => {
157 |     let repoDir: string;
158 |     let gitConfigPath: string;
159 | 
160 |     beforeEach(() => {
161 |       repoDir = path.join(homedir, GEMINI_DIR, 'history', hash);
162 |       gitConfigPath = path.join(repoDir, '.gitconfig');
163 |     });
164 | 
165 |     it('should create history and repository directories', async () => {
166 |       const service = new GitService(projectRoot, storage);
167 |       await service.setupShadowGitRepository();
168 |       const stats = await fs.stat(repoDir);
169 |       expect(stats.isDirectory()).toBe(true);
170 |     });
171 | 
172 |     it('should create a .gitconfig file with the correct content', async () => {
173 |       const service = new GitService(projectRoot, storage);
174 |       await service.setupShadowGitRepository();
175 | 
176 |       const expectedConfigContent =
177 |         '[user]\n  name = Gemini CLI\n  email = gemini-cli@google.com\n[commit]\n  gpgsign = false\n';
178 |       const actualConfigContent = await fs.readFile(gitConfigPath, 'utf-8');
179 |       expect(actualConfigContent).toBe(expectedConfigContent);
180 |     });
181 | 
182 |     it('should initialize git repo in historyDir if not already initialized', async () => {
183 |       hoistedMockCheckIsRepo.mockResolvedValue(false);
184 |       const service = new GitService(projectRoot, storage);
185 |       await service.setupShadowGitRepository();
186 |       expect(hoistedMockSimpleGit).toHaveBeenCalledWith(repoDir);
187 |       expect(hoistedMockInit).toHaveBeenCalled();
188 |     });
189 | 
190 |     it('should not initialize git repo if already initialized', async () => {
191 |       hoistedMockCheckIsRepo.mockResolvedValue(true);
192 |       const service = new GitService(projectRoot, storage);
193 |       await service.setupShadowGitRepository();
194 |       expect(hoistedMockInit).not.toHaveBeenCalled();
195 |     });
196 | 
197 |     it('should copy .gitignore from projectRoot if it exists', async () => {
198 |       const gitignoreContent = 'node_modules/\n.env';
199 |       const visibleGitIgnorePath = path.join(projectRoot, '.gitignore');
200 |       await fs.writeFile(visibleGitIgnorePath, gitignoreContent);
201 | 
202 |       const service = new GitService(projectRoot, storage);
203 |       await service.setupShadowGitRepository();
204 | 
205 |       const hiddenGitIgnorePath = path.join(repoDir, '.gitignore');
206 |       const copiedContent = await fs.readFile(hiddenGitIgnorePath, 'utf-8');
207 |       expect(copiedContent).toBe(gitignoreContent);
208 |     });
209 | 
210 |     it('should not create a .gitignore in shadow repo if project .gitignore does not exist', async () => {
211 |       const service = new GitService(projectRoot, storage);
212 |       await service.setupShadowGitRepository();
213 | 
214 |       const hiddenGitIgnorePath = path.join(repoDir, '.gitignore');
215 |       // An empty string is written if the file doesn't exist.
216 |       const content = await fs.readFile(hiddenGitIgnorePath, 'utf-8');
217 |       expect(content).toBe('');
218 |     });
219 | 
220 |     it('should throw an error if reading projectRoot .gitignore fails with other errors', async () => {
221 |       const visibleGitIgnorePath = path.join(projectRoot, '.gitignore');
222 |       // Create a directory instead of a file to cause a read error
223 |       await fs.mkdir(visibleGitIgnorePath);
224 | 
225 |       const service = new GitService(projectRoot, storage);
226 |       // EISDIR is the expected error code on Unix-like systems
227 |       await expect(service.setupShadowGitRepository()).rejects.toThrow(
228 |         /EISDIR: illegal operation on a directory, read|EBUSY: resource busy or locked, read/,
229 |       );
230 |     });
231 | 
232 |     it('should make an initial commit if no commits exist in history repo', async () => {
233 |       hoistedMockCheckIsRepo.mockResolvedValue(false);
234 |       const service = new GitService(projectRoot, storage);
235 |       await service.setupShadowGitRepository();
236 |       expect(hoistedMockCommit).toHaveBeenCalledWith('Initial commit', {
237 |         '--allow-empty': null,
238 |       });
239 |     });
240 | 
241 |     it('should not make an initial commit if commits already exist', async () => {
242 |       hoistedMockCheckIsRepo.mockResolvedValue(true);
243 |       const service = new GitService(projectRoot, storage);
244 |       await service.setupShadowGitRepository();
245 |       expect(hoistedMockCommit).not.toHaveBeenCalled();
246 |     });
247 |   });
248 | });
```

src/services/gitService.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs/promises';
8 | import * as path from 'node:path';
9 | import { isNodeError } from '../utils/errors.js';
10 | import { spawnAsync } from '../utils/shell-utils.js';
11 | import type { SimpleGit } from 'simple-git';
12 | import { simpleGit, CheckRepoActions } from 'simple-git';
13 | import type { Storage } from '../config/storage.js';
14 | 
15 | export class GitService {
16 |   private projectRoot: string;
17 |   private storage: Storage;
18 | 
19 |   constructor(projectRoot: string, storage: Storage) {
20 |     this.projectRoot = path.resolve(projectRoot);
21 |     this.storage = storage;
22 |   }
23 | 
24 |   private getHistoryDir(): string {
25 |     return this.storage.getHistoryDir();
26 |   }
27 | 
28 |   async initialize(): Promise<void> {
29 |     const gitAvailable = await this.verifyGitAvailability();
30 |     if (!gitAvailable) {
31 |       throw new Error(
32 |         'Checkpointing is enabled, but Git is not installed. Please install Git or disable checkpointing to continue.',
33 |       );
34 |     }
35 |     try {
36 |       await this.setupShadowGitRepository();
37 |     } catch (error) {
38 |       throw new Error(
39 |         `Failed to initialize checkpointing: ${error instanceof Error ? error.message : 'Unknown error'}. Please check that Git is working properly or disable checkpointing.`,
40 |       );
41 |     }
42 |   }
43 | 
44 |   async verifyGitAvailability(): Promise<boolean> {
45 |     try {
46 |       await spawnAsync('git', ['--version']);
47 |       return true;
48 |     } catch (_error) {
49 |       return false;
50 |     }
51 |   }
52 | 
53 |   /**
54 |    * Creates a hidden git repository in the project root.
55 |    * The Git repository is used to support checkpointing.
56 |    */
57 |   async setupShadowGitRepository() {
58 |     const repoDir = this.getHistoryDir();
59 |     const gitConfigPath = path.join(repoDir, '.gitconfig');
60 | 
61 |     await fs.mkdir(repoDir, { recursive: true });
62 | 
63 |     // We don't want to inherit the user's name, email, or gpg signing
64 |     // preferences for the shadow repository, so we create a dedicated gitconfig.
65 |     const gitConfigContent =
66 |       '[user]\n  name = Gemini CLI\n  email = gemini-cli@google.com\n[commit]\n  gpgsign = false\n';
67 |     await fs.writeFile(gitConfigPath, gitConfigContent);
68 | 
69 |     const repo = simpleGit(repoDir);
70 |     const isRepoDefined = await repo.checkIsRepo(CheckRepoActions.IS_REPO_ROOT);
71 | 
72 |     if (!isRepoDefined) {
73 |       await repo.init(false, {
74 |         '--initial-branch': 'main',
75 |       });
76 | 
77 |       await repo.commit('Initial commit', { '--allow-empty': null });
78 |     }
79 | 
80 |     const userGitIgnorePath = path.join(this.projectRoot, '.gitignore');
81 |     const shadowGitIgnorePath = path.join(repoDir, '.gitignore');
82 | 
83 |     let userGitIgnoreContent = '';
84 |     try {
85 |       userGitIgnoreContent = await fs.readFile(userGitIgnorePath, 'utf-8');
86 |     } catch (error) {
87 |       if (isNodeError(error) && error.code !== 'ENOENT') {
88 |         throw error;
89 |       }
90 |     }
91 | 
92 |     await fs.writeFile(shadowGitIgnorePath, userGitIgnoreContent);
93 |   }
94 | 
95 |   private get shadowGitRepository(): SimpleGit {
96 |     const repoDir = this.getHistoryDir();
97 |     return simpleGit(this.projectRoot).env({
98 |       GIT_DIR: path.join(repoDir, '.git'),
99 |       GIT_WORK_TREE: this.projectRoot,
100 |       // Prevent git from using the user's global git config.
101 |       HOME: repoDir,
102 |       XDG_CONFIG_HOME: repoDir,
103 |     });
104 |   }
105 | 
106 |   async getCurrentCommitHash(): Promise<string> {
107 |     const hash = await this.shadowGitRepository.raw('rev-parse', 'HEAD');
108 |     return hash.trim();
109 |   }
110 | 
111 |   async createFileSnapshot(message: string): Promise<string> {
112 |     try {
113 |       const repo = this.shadowGitRepository;
114 |       await repo.add('.');
115 |       const commitResult = await repo.commit(message);
116 |       return commitResult.commit;
117 |     } catch (error) {
118 |       throw new Error(
119 |         `Failed to create checkpoint snapshot: ${error instanceof Error ? error.message : 'Unknown error'}. Checkpointing may not be working properly.`,
120 |       );
121 |     }
122 |   }
123 | 
124 |   async restoreProjectFromSnapshot(commitHash: string): Promise<void> {
125 |     const repo = this.shadowGitRepository;
126 |     await repo.raw(['restore', '--source', commitHash, '.']);
127 |     // Removes any untracked files that were introduced post snapshot.
128 |     await repo.clean('f', ['-d']);
129 |   }
130 | }
```

src/services/loopDetectionService.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
8 | import type { Config } from '../config/config.js';
9 | import type { GeminiClient } from '../core/client.js';
10 | import type { BaseLlmClient } from '../core/baseLlmClient.js';
11 | import type {
12 |   ServerGeminiContentEvent,
13 |   ServerGeminiStreamEvent,
14 |   ServerGeminiToolCallRequestEvent,
15 | } from '../core/turn.js';
16 | import { GeminiEventType } from '../core/turn.js';
17 | import * as loggers from '../telemetry/loggers.js';
18 | import { LoopType } from '../telemetry/types.js';
19 | import { LoopDetectionService } from './loopDetectionService.js';
20 | 
21 | vi.mock('../telemetry/loggers.js', () => ({
22 |   logLoopDetected: vi.fn(),
23 |   logLoopDetectionDisabled: vi.fn(),
24 | }));
25 | 
26 | const TOOL_CALL_LOOP_THRESHOLD = 5;
27 | const CONTENT_LOOP_THRESHOLD = 10;
28 | const CONTENT_CHUNK_SIZE = 50;
29 | 
30 | describe('LoopDetectionService', () => {
31 |   let service: LoopDetectionService;
32 |   let mockConfig: Config;
33 | 
34 |   beforeEach(() => {
35 |     mockConfig = {
36 |       getTelemetryEnabled: () => true,
37 |     } as unknown as Config;
38 |     service = new LoopDetectionService(mockConfig);
39 |     vi.clearAllMocks();
40 |   });
41 | 
42 |   const createToolCallRequestEvent = (
43 |     name: string,
44 |     args: Record<string, unknown>,
45 |   ): ServerGeminiToolCallRequestEvent => ({
46 |     type: GeminiEventType.ToolCallRequest,
47 |     value: {
48 |       name,
49 |       args,
50 |       callId: 'test-id',
51 |       isClientInitiated: false,
52 |       prompt_id: 'test-prompt-id',
53 |     },
54 |   });
55 | 
56 |   const createContentEvent = (content: string): ServerGeminiContentEvent => ({
57 |     type: GeminiEventType.Content,
58 |     value: content,
59 |   });
60 | 
61 |   const createRepetitiveContent = (id: number, length: number): string => {
62 |     const baseString = `This is a unique sentence, id=${id}. `;
63 |     let content = '';
64 |     while (content.length < length) {
65 |       content += baseString;
66 |     }
67 |     return content.slice(0, length);
68 |   };
69 | 
70 |   describe('Tool Call Loop Detection', () => {
71 |     it(`should not detect a loop for fewer than TOOL_CALL_LOOP_THRESHOLD identical calls`, () => {
72 |       const event = createToolCallRequestEvent('testTool', { param: 'value' });
73 |       for (let i = 0; i < TOOL_CALL_LOOP_THRESHOLD - 1; i++) {
74 |         expect(service.addAndCheck(event)).toBe(false);
75 |       }
76 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
77 |     });
78 | 
79 |     it(`should detect a loop on the TOOL_CALL_LOOP_THRESHOLD-th identical call`, () => {
80 |       const event = createToolCallRequestEvent('testTool', { param: 'value' });
81 |       for (let i = 0; i < TOOL_CALL_LOOP_THRESHOLD - 1; i++) {
82 |         service.addAndCheck(event);
83 |       }
84 |       expect(service.addAndCheck(event)).toBe(true);
85 |       expect(loggers.logLoopDetected).toHaveBeenCalledTimes(1);
86 |     });
87 | 
88 |     it('should detect a loop on subsequent identical calls', () => {
89 |       const event = createToolCallRequestEvent('testTool', { param: 'value' });
90 |       for (let i = 0; i < TOOL_CALL_LOOP_THRESHOLD; i++) {
91 |         service.addAndCheck(event);
92 |       }
93 |       expect(service.addAndCheck(event)).toBe(true);
94 |       expect(loggers.logLoopDetected).toHaveBeenCalledTimes(1);
95 |     });
96 | 
97 |     it('should not detect a loop for different tool calls', () => {
98 |       const event1 = createToolCallRequestEvent('testTool', {
99 |         param: 'value1',
100 |       });
101 |       const event2 = createToolCallRequestEvent('testTool', {
102 |         param: 'value2',
103 |       });
104 |       const event3 = createToolCallRequestEvent('anotherTool', {
105 |         param: 'value1',
106 |       });
107 | 
108 |       for (let i = 0; i < TOOL_CALL_LOOP_THRESHOLD - 2; i++) {
109 |         expect(service.addAndCheck(event1)).toBe(false);
110 |         expect(service.addAndCheck(event2)).toBe(false);
111 |         expect(service.addAndCheck(event3)).toBe(false);
112 |       }
113 |     });
114 | 
115 |     it('should not reset tool call counter for other event types', () => {
116 |       const toolCallEvent = createToolCallRequestEvent('testTool', {
117 |         param: 'value',
118 |       });
119 |       const otherEvent = {
120 |         type: 'thought',
121 |       } as unknown as ServerGeminiStreamEvent;
122 | 
123 |       // Send events just below the threshold
124 |       for (let i = 0; i < TOOL_CALL_LOOP_THRESHOLD - 1; i++) {
125 |         expect(service.addAndCheck(toolCallEvent)).toBe(false);
126 |       }
127 | 
128 |       // Send a different event type
129 |       expect(service.addAndCheck(otherEvent)).toBe(false);
130 | 
131 |       // Send the tool call event again, which should now trigger the loop
132 |       expect(service.addAndCheck(toolCallEvent)).toBe(true);
133 |       expect(loggers.logLoopDetected).toHaveBeenCalledTimes(1);
134 |     });
135 | 
136 |     it('should not detect a loop when disabled for session', () => {
137 |       service.disableForSession();
138 |       expect(loggers.logLoopDetectionDisabled).toHaveBeenCalledTimes(1);
139 |       const event = createToolCallRequestEvent('testTool', { param: 'value' });
140 |       for (let i = 0; i < TOOL_CALL_LOOP_THRESHOLD; i++) {
141 |         expect(service.addAndCheck(event)).toBe(false);
142 |       }
143 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
144 |     });
145 |   });
146 | 
147 |   describe('Content Loop Detection', () => {
148 |     const generateRandomString = (length: number) => {
149 |       let result = '';
150 |       const characters =
151 |         'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789';
152 |       const charactersLength = characters.length;
153 |       for (let i = 0; i < length; i++) {
154 |         result += characters.charAt(
155 |           Math.floor(Math.random() * charactersLength),
156 |         );
157 |       }
158 |       return result;
159 |     };
160 | 
161 |     it('should not detect a loop for random content', () => {
162 |       service.reset('');
163 |       for (let i = 0; i < 1000; i++) {
164 |         const content = generateRandomString(10);
165 |         const isLoop = service.addAndCheck(createContentEvent(content));
166 |         expect(isLoop).toBe(false);
167 |       }
168 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
169 |     });
170 | 
171 |     it('should detect a loop when a chunk of content repeats consecutively', () => {
172 |       service.reset('');
173 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
174 | 
175 |       let isLoop = false;
176 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD; i++) {
177 |         isLoop = service.addAndCheck(createContentEvent(repeatedContent));
178 |       }
179 |       expect(isLoop).toBe(true);
180 |       expect(loggers.logLoopDetected).toHaveBeenCalledTimes(1);
181 |     });
182 | 
183 |     it('should not detect a loop if repetitions are very far apart', () => {
184 |       service.reset('');
185 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
186 |       const fillerContent = generateRandomString(500);
187 | 
188 |       let isLoop = false;
189 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD; i++) {
190 |         isLoop = service.addAndCheck(createContentEvent(repeatedContent));
191 |         isLoop = service.addAndCheck(createContentEvent(fillerContent));
192 |       }
193 |       expect(isLoop).toBe(false);
194 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
195 |     });
196 |   });
197 | 
198 |   describe('Content Loop Detection with Code Blocks', () => {
199 |     it('should not detect a loop when repetitive content is inside a code block', () => {
200 |       service.reset('');
201 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
202 | 
203 |       service.addAndCheck(createContentEvent('```\n'));
204 | 
205 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD; i++) {
206 |         const isLoop = service.addAndCheck(createContentEvent(repeatedContent));
207 |         expect(isLoop).toBe(false);
208 |       }
209 | 
210 |       const isLoop = service.addAndCheck(createContentEvent('\n```'));
211 |       expect(isLoop).toBe(false);
212 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
213 |     });
214 | 
215 |     it('should not detect loops when content transitions into a code block', () => {
216 |       service.reset('');
217 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
218 | 
219 |       // Add some repetitive content outside of code block
220 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 2; i++) {
221 |         service.addAndCheck(createContentEvent(repeatedContent));
222 |       }
223 | 
224 |       // Now transition into a code block - this should prevent loop detection
225 |       // even though we were already close to the threshold
226 |       const codeBlockStart = '```javascript\n';
227 |       const isLoop = service.addAndCheck(createContentEvent(codeBlockStart));
228 |       expect(isLoop).toBe(false);
229 | 
230 |       // Continue adding repetitive content inside the code block - should not trigger loop
231 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD; i++) {
232 |         const isLoopInside = service.addAndCheck(
233 |           createContentEvent(repeatedContent),
234 |         );
235 |         expect(isLoopInside).toBe(false);
236 |       }
237 | 
238 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
239 |     });
240 | 
241 |     it('should skip loop detection when already inside a code block (this.inCodeBlock)', () => {
242 |       service.reset('');
243 | 
244 |       // Start with content that puts us inside a code block
245 |       service.addAndCheck(createContentEvent('Here is some code:\n```\n'));
246 | 
247 |       // Verify we are now inside a code block and any content should be ignored for loop detection
248 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
249 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD + 5; i++) {
250 |         const isLoop = service.addAndCheck(createContentEvent(repeatedContent));
251 |         expect(isLoop).toBe(false);
252 |       }
253 | 
254 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
255 |     });
256 | 
257 |     it('should correctly track inCodeBlock state with multiple fence transitions', () => {
258 |       service.reset('');
259 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
260 | 
261 |       // Outside code block - should track content
262 |       service.addAndCheck(createContentEvent('Normal text '));
263 | 
264 |       // Enter code block (1 fence) - should stop tracking
265 |       const enterResult = service.addAndCheck(createContentEvent('```\n'));
266 |       expect(enterResult).toBe(false);
267 | 
268 |       // Inside code block - should not track loops
269 |       for (let i = 0; i < 5; i++) {
270 |         const insideResult = service.addAndCheck(
271 |           createContentEvent(repeatedContent),
272 |         );
273 |         expect(insideResult).toBe(false);
274 |       }
275 | 
276 |       // Exit code block (2nd fence) - should reset tracking but still return false
277 |       const exitResult = service.addAndCheck(createContentEvent('```\n'));
278 |       expect(exitResult).toBe(false);
279 | 
280 |       // Enter code block again (3rd fence) - should stop tracking again
281 |       const reenterResult = service.addAndCheck(
282 |         createContentEvent('```python\n'),
283 |       );
284 |       expect(reenterResult).toBe(false);
285 | 
286 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
287 |     });
288 | 
289 |     it('should detect a loop when repetitive content is outside a code block', () => {
290 |       service.reset('');
291 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
292 | 
293 |       service.addAndCheck(createContentEvent('```'));
294 |       service.addAndCheck(createContentEvent('\nsome code\n'));
295 |       service.addAndCheck(createContentEvent('```'));
296 | 
297 |       let isLoop = false;
298 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD; i++) {
299 |         isLoop = service.addAndCheck(createContentEvent(repeatedContent));
300 |       }
301 |       expect(isLoop).toBe(true);
302 |       expect(loggers.logLoopDetected).toHaveBeenCalledTimes(1);
303 |     });
304 | 
305 |     it('should handle content with multiple code blocks and no loops', () => {
306 |       service.reset('');
307 |       service.addAndCheck(createContentEvent('```\ncode1\n```'));
308 |       service.addAndCheck(createContentEvent('\nsome text\n'));
309 |       const isLoop = service.addAndCheck(createContentEvent('```\ncode2\n```'));
310 | 
311 |       expect(isLoop).toBe(false);
312 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
313 |     });
314 | 
315 |     it('should handle content with mixed code blocks and looping text', () => {
316 |       service.reset('');
317 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
318 | 
319 |       service.addAndCheck(createContentEvent('```'));
320 |       service.addAndCheck(createContentEvent('\ncode1\n'));
321 |       service.addAndCheck(createContentEvent('```'));
322 | 
323 |       let isLoop = false;
324 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD; i++) {
325 |         isLoop = service.addAndCheck(createContentEvent(repeatedContent));
326 |       }
327 | 
328 |       expect(isLoop).toBe(true);
329 |       expect(loggers.logLoopDetected).toHaveBeenCalledTimes(1);
330 |     });
331 | 
332 |     it('should not detect a loop for a long code block with some repeating tokens', () => {
333 |       service.reset('');
334 |       const repeatingTokens =
335 |         'for (let i = 0; i < 10; i++) { console.log(i); }';
336 | 
337 |       service.addAndCheck(createContentEvent('```\n'));
338 | 
339 |       for (let i = 0; i < 20; i++) {
340 |         const isLoop = service.addAndCheck(createContentEvent(repeatingTokens));
341 |         expect(isLoop).toBe(false);
342 |       }
343 | 
344 |       const isLoop = service.addAndCheck(createContentEvent('\n```'));
345 |       expect(isLoop).toBe(false);
346 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
347 |     });
348 | 
349 |     it('should reset tracking when a code fence is found', () => {
350 |       service.reset('');
351 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
352 | 
353 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
354 |         service.addAndCheck(createContentEvent(repeatedContent));
355 |       }
356 | 
357 |       // This should not trigger a loop because of the reset
358 |       service.addAndCheck(createContentEvent('```'));
359 | 
360 |       // We are now in a code block, so loop detection should be off.
361 |       // Let's add the repeated content again, it should not trigger a loop.
362 |       let isLoop = false;
363 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD; i++) {
364 |         isLoop = service.addAndCheck(createContentEvent(repeatedContent));
365 |         expect(isLoop).toBe(false);
366 |       }
367 | 
368 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
369 |     });
370 |     it('should reset tracking when a table is detected', () => {
371 |       service.reset('');
372 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
373 | 
374 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
375 |         service.addAndCheck(createContentEvent(repeatedContent));
376 |       }
377 | 
378 |       // This should reset tracking and not trigger a loop
379 |       service.addAndCheck(createContentEvent('| Column 1 | Column 2 |'));
380 | 
381 |       // Add more repeated content after table - should not trigger loop
382 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
383 |         const isLoop = service.addAndCheck(createContentEvent(repeatedContent));
384 |         expect(isLoop).toBe(false);
385 |       }
386 | 
387 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
388 |     });
389 | 
390 |     it('should reset tracking when a list item is detected', () => {
391 |       service.reset('');
392 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
393 | 
394 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
395 |         service.addAndCheck(createContentEvent(repeatedContent));
396 |       }
397 | 
398 |       // This should reset tracking and not trigger a loop
399 |       service.addAndCheck(createContentEvent('* List item'));
400 | 
401 |       // Add more repeated content after list - should not trigger loop
402 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
403 |         const isLoop = service.addAndCheck(createContentEvent(repeatedContent));
404 |         expect(isLoop).toBe(false);
405 |       }
406 | 
407 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
408 |     });
409 | 
410 |     it('should reset tracking when a heading is detected', () => {
411 |       service.reset('');
412 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
413 | 
414 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
415 |         service.addAndCheck(createContentEvent(repeatedContent));
416 |       }
417 | 
418 |       // This should reset tracking and not trigger a loop
419 |       service.addAndCheck(createContentEvent('## Heading'));
420 | 
421 |       // Add more repeated content after heading - should not trigger loop
422 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
423 |         const isLoop = service.addAndCheck(createContentEvent(repeatedContent));
424 |         expect(isLoop).toBe(false);
425 |       }
426 | 
427 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
428 |     });
429 | 
430 |     it('should reset tracking when a blockquote is detected', () => {
431 |       service.reset('');
432 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
433 | 
434 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
435 |         service.addAndCheck(createContentEvent(repeatedContent));
436 |       }
437 | 
438 |       // This should reset tracking and not trigger a loop
439 |       service.addAndCheck(createContentEvent('> Quote text'));
440 | 
441 |       // Add more repeated content after blockquote - should not trigger loop
442 |       for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
443 |         const isLoop = service.addAndCheck(createContentEvent(repeatedContent));
444 |         expect(isLoop).toBe(false);
445 |       }
446 | 
447 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
448 |     });
449 | 
450 |     it('should reset tracking for various list item formats', () => {
451 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
452 | 
453 |       // Test different list formats - make sure they start at beginning of line
454 |       const listFormats = [
455 |         '* Bullet item',
456 |         '- Dash item',
457 |         '+ Plus item',
458 |         '1. Numbered item',
459 |         '42. Another numbered item',
460 |       ];
461 | 
462 |       listFormats.forEach((listFormat, index) => {
463 |         service.reset('');
464 | 
465 |         // Build up to near threshold
466 |         for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
467 |           service.addAndCheck(createContentEvent(repeatedContent));
468 |         }
469 | 
470 |         // Reset should occur with list item - add newline to ensure it starts at beginning
471 |         service.addAndCheck(createContentEvent('\n' + listFormat));
472 | 
473 |         // Should not trigger loop after reset - use different content to avoid any cached state issues
474 |         const newRepeatedContent = createRepetitiveContent(
475 |           index + 100,
476 |           CONTENT_CHUNK_SIZE,
477 |         );
478 |         for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
479 |           const isLoop = service.addAndCheck(
480 |             createContentEvent(newRepeatedContent),
481 |           );
482 |           expect(isLoop).toBe(false);
483 |         }
484 |       });
485 | 
486 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
487 |     });
488 | 
489 |     it('should reset tracking for various table formats', () => {
490 |       const repeatedContent = createRepetitiveContent(1, CONTENT_CHUNK_SIZE);
491 | 
492 |       const tableFormats = [
493 |         '| Column 1 | Column 2 |',
494 |         '|---|---|',
495 |         '|++|++|',
496 |         '+---+---+',
497 |       ];
498 | 
499 |       tableFormats.forEach((tableFormat, index) => {
500 |         service.reset('');
501 | 
502 |         // Build up to near threshold
503 |         for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
504 |           service.addAndCheck(createContentEvent(repeatedContent));
505 |         }
506 | 
507 |         // Reset should occur with table format - add newline to ensure it starts at beginning
508 |         service.addAndCheck(createContentEvent('\n' + tableFormat));
509 | 
510 |         // Should not trigger loop after reset - use different content to avoid any cached state issues
511 |         const newRepeatedContent = createRepetitiveContent(
512 |           index + 200,
513 |           CONTENT_CHUNK_SIZE,
514 |         );
515 |         for (let i = 0; i < CONTENT_LOOP_THRESHOLD - 1; i++) {
516 |           const isLoop = service.addAndCheck(
517 |             createContentEvent(newRepeatedContent),
518 |           );
519 |           expect(isLoop).toBe(false);
520 |         }
521 |       });
522 | 
523 |       expect(loggers.logLoopDetected).not.toHaveBeenCalled();
524 |     });
525 | 
526 |     it('should reset tracking for various heading levels', () => {
[TRUNCATED]
```

src/services/loopDetectionService.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Content } from '@google/genai';
8 | import { createHash } from 'node:crypto';
9 | import type { ServerGeminiStreamEvent } from '../core/turn.js';
10 | import { GeminiEventType } from '../core/turn.js';
11 | import {
12 |   logLoopDetected,
13 |   logLoopDetectionDisabled,
14 | } from '../telemetry/loggers.js';
15 | import {
16 |   LoopDetectedEvent,
17 |   LoopDetectionDisabledEvent,
18 |   LoopType,
19 | } from '../telemetry/types.js';
20 | import type { Config } from '../config/config.js';
21 | import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/config.js';
22 | import {
23 |   isFunctionCall,
24 |   isFunctionResponse,
25 | } from '../utils/messageInspectors.js';
26 | 
27 | const TOOL_CALL_LOOP_THRESHOLD = 5;
28 | const CONTENT_LOOP_THRESHOLD = 10;
29 | const CONTENT_CHUNK_SIZE = 50;
30 | const MAX_HISTORY_LENGTH = 1000;
31 | 
32 | /**
33 |  * The number of recent conversation turns to include in the history when asking the LLM to check for a loop.
34 |  */
35 | const LLM_LOOP_CHECK_HISTORY_COUNT = 20;
36 | 
37 | /**
38 |  * The number of turns that must pass in a single prompt before the LLM-based loop check is activated.
39 |  */
40 | const LLM_CHECK_AFTER_TURNS = 30;
41 | 
42 | /**
43 |  * The default interval, in number of turns, at which the LLM-based loop check is performed.
44 |  * This value is adjusted dynamically based on the LLM's confidence.
45 |  */
46 | const DEFAULT_LLM_CHECK_INTERVAL = 3;
47 | 
48 | /**
49 |  * The minimum interval for LLM-based loop checks.
50 |  * This is used when the confidence of a loop is high, to check more frequently.
51 |  */
52 | const MIN_LLM_CHECK_INTERVAL = 5;
53 | 
54 | /**
55 |  * The maximum interval for LLM-based loop checks.
56 |  * This is used when the confidence of a loop is low, to check less frequently.
57 |  */
58 | const MAX_LLM_CHECK_INTERVAL = 15;
59 | 
60 | const LOOP_DETECTION_SYSTEM_PROMPT = `You are a sophisticated AI diagnostic agent specializing in identifying when a conversational AI is stuck in an unproductive state. Your task is to analyze the provided conversation history and determine if the assistant has ceased to make meaningful progress.
61 | 
62 | An unproductive state is characterized by one or more of the following patterns over the last 5 or more assistant turns:
63 | 
64 | Repetitive Actions: The assistant repeats the same tool calls or conversational responses a decent number of times. This includes simple loops (e.g., tool_A, tool_A, tool_A) and alternating patterns (e.g., tool_A, tool_B, tool_A, tool_B, ...).
65 | 
66 | Cognitive Loop: The assistant seems unable to determine the next logical step. It might express confusion, repeatedly ask the same questions, or generate responses that don't logically follow from the previous turns, indicating it's stuck and not advancing the task.
67 | 
68 | Crucially, differentiate between a true unproductive state and legitimate, incremental progress.
69 | For example, a series of 'tool_A' or 'tool_B' tool calls that make small, distinct changes to the same file (like adding docstrings to functions one by one) is considered forward progress and is NOT a loop. A loop would be repeatedly replacing the same text with the same content, or cycling between a small set of files with no net change.`;
70 | 
71 | /**
72 |  * Service for detecting and preventing infinite loops in AI responses.
73 |  * Monitors tool call repetitions and content sentence repetitions.
74 |  */
75 | export class LoopDetectionService {
76 |   private readonly config: Config;
77 |   private promptId = '';
78 | 
79 |   // Tool call tracking
80 |   private lastToolCallKey: string | null = null;
81 |   private toolCallRepetitionCount: number = 0;
82 | 
83 |   // Content streaming tracking
84 |   private streamContentHistory = '';
85 |   private contentStats = new Map<string, number[]>();
86 |   private lastContentIndex = 0;
87 |   private loopDetected = false;
88 |   private inCodeBlock = false;
89 | 
90 |   // LLM loop track tracking
91 |   private turnsInCurrentPrompt = 0;
92 |   private llmCheckInterval = DEFAULT_LLM_CHECK_INTERVAL;
93 |   private lastCheckTurn = 0;
94 | 
95 |   // Session-level disable flag
96 |   private disabledForSession = false;
97 | 
98 |   constructor(config: Config) {
99 |     this.config = config;
100 |   }
101 | 
102 |   /**
103 |    * Disables loop detection for the current session.
104 |    */
105 |   disableForSession(): void {
106 |     this.disabledForSession = true;
107 |     logLoopDetectionDisabled(
108 |       this.config,
109 |       new LoopDetectionDisabledEvent(this.promptId),
110 |     );
111 |   }
112 | 
113 |   private getToolCallKey(toolCall: { name: string; args: object }): string {
114 |     const argsString = JSON.stringify(toolCall.args);
115 |     const keyString = `${toolCall.name}:${argsString}`;
116 |     return createHash('sha256').update(keyString).digest('hex');
117 |   }
118 | 
119 |   /**
120 |    * Processes a stream event and checks for loop conditions.
121 |    * @param event - The stream event to process
122 |    * @returns true if a loop is detected, false otherwise
123 |    */
124 |   addAndCheck(event: ServerGeminiStreamEvent): boolean {
125 |     if (this.loopDetected || this.disabledForSession) {
126 |       return this.loopDetected;
127 |     }
128 | 
129 |     switch (event.type) {
130 |       case GeminiEventType.ToolCallRequest:
131 |         // content chanting only happens in one single stream, reset if there
132 |         // is a tool call in between
133 |         this.resetContentTracking();
134 |         this.loopDetected = this.checkToolCallLoop(event.value);
135 |         break;
136 |       case GeminiEventType.Content:
137 |         this.loopDetected = this.checkContentLoop(event.value);
138 |         break;
139 |       default:
140 |         break;
141 |     }
142 |     return this.loopDetected;
143 |   }
144 | 
145 |   /**
146 |    * Signals the start of a new turn in the conversation.
147 |    *
148 |    * This method increments the turn counter and, if specific conditions are met,
149 |    * triggers an LLM-based check to detect potential conversation loops. The check
150 |    * is performed periodically based on the `llmCheckInterval`.
151 |    *
152 |    * @param signal - An AbortSignal to allow for cancellation of the asynchronous LLM check.
153 |    * @returns A promise that resolves to `true` if a loop is detected, and `false` otherwise.
154 |    */
155 |   async turnStarted(signal: AbortSignal) {
156 |     if (this.disabledForSession) {
157 |       return false;
158 |     }
159 |     this.turnsInCurrentPrompt++;
160 | 
161 |     if (
162 |       this.turnsInCurrentPrompt >= LLM_CHECK_AFTER_TURNS &&
163 |       this.turnsInCurrentPrompt - this.lastCheckTurn >= this.llmCheckInterval
164 |     ) {
165 |       this.lastCheckTurn = this.turnsInCurrentPrompt;
166 |       return await this.checkForLoopWithLLM(signal);
167 |     }
168 | 
169 |     return false;
170 |   }
171 | 
172 |   private checkToolCallLoop(toolCall: { name: string; args: object }): boolean {
173 |     const key = this.getToolCallKey(toolCall);
174 |     if (this.lastToolCallKey === key) {
175 |       this.toolCallRepetitionCount++;
176 |     } else {
177 |       this.lastToolCallKey = key;
178 |       this.toolCallRepetitionCount = 1;
179 |     }
180 |     if (this.toolCallRepetitionCount >= TOOL_CALL_LOOP_THRESHOLD) {
181 |       logLoopDetected(
182 |         this.config,
183 |         new LoopDetectedEvent(
184 |           LoopType.CONSECUTIVE_IDENTICAL_TOOL_CALLS,
185 |           this.promptId,
186 |         ),
187 |       );
188 |       return true;
189 |     }
190 |     return false;
191 |   }
192 | 
193 |   /**
194 |    * Detects content loops by analyzing streaming text for repetitive patterns.
195 |    *
196 |    * The algorithm works by:
197 |    * 1. Appending new content to the streaming history
198 |    * 2. Truncating history if it exceeds the maximum length
199 |    * 3. Analyzing content chunks for repetitive patterns using hashing
200 |    * 4. Detecting loops when identical chunks appear frequently within a short distance
201 |    * 5. Disabling loop detection within code blocks to prevent false positives,
202 |    *    as repetitive code structures are common and not necessarily loops.
203 |    */
204 |   private checkContentLoop(content: string): boolean {
205 |     // Different content elements can often contain repetitive syntax that is not indicative of a loop.
206 |     // To avoid false positives, we detect when we encounter different content types and
207 |     // reset tracking to avoid analyzing content that spans across different element boundaries.
208 |     const numFences = (content.match(/```/g) ?? []).length;
209 |     const hasTable = /(^|\n)\s*(\|.*\||[|+-]{3,})/.test(content);
210 |     const hasListItem =
211 |       /(^|\n)\s*[*-+]\s/.test(content) || /(^|\n)\s*\d+\.\s/.test(content);
212 |     const hasHeading = /(^|\n)#+\s/.test(content);
213 |     const hasBlockquote = /(^|\n)>\s/.test(content);
214 |     const isDivider = /^[+-_=*\u2500-\u257F]+$/.test(content);
215 | 
216 |     if (
217 |       numFences ||
218 |       hasTable ||
219 |       hasListItem ||
220 |       hasHeading ||
221 |       hasBlockquote ||
222 |       isDivider
223 |     ) {
224 |       // Reset tracking when different content elements are detected to avoid analyzing content
225 |       // that spans across different element boundaries.
226 |       this.resetContentTracking();
227 |     }
228 | 
229 |     const wasInCodeBlock = this.inCodeBlock;
230 |     this.inCodeBlock =
231 |       numFences % 2 === 0 ? this.inCodeBlock : !this.inCodeBlock;
232 |     if (wasInCodeBlock || this.inCodeBlock || isDivider) {
233 |       return false;
234 |     }
235 | 
236 |     this.streamContentHistory += content;
237 | 
238 |     this.truncateAndUpdate();
239 |     return this.analyzeContentChunksForLoop();
240 |   }
241 | 
242 |   /**
243 |    * Truncates the content history to prevent unbounded memory growth.
244 |    * When truncating, adjusts all stored indices to maintain their relative positions.
245 |    */
246 |   private truncateAndUpdate(): void {
247 |     if (this.streamContentHistory.length <= MAX_HISTORY_LENGTH) {
248 |       return;
249 |     }
250 | 
251 |     // Calculate how much content to remove from the beginning
252 |     const truncationAmount =
253 |       this.streamContentHistory.length - MAX_HISTORY_LENGTH;
254 |     this.streamContentHistory =
255 |       this.streamContentHistory.slice(truncationAmount);
256 |     this.lastContentIndex = Math.max(
257 |       0,
258 |       this.lastContentIndex - truncationAmount,
259 |     );
260 | 
261 |     // Update all stored chunk indices to account for the truncation
262 |     for (const [hash, oldIndices] of this.contentStats.entries()) {
263 |       const adjustedIndices = oldIndices
264 |         .map((index) => index - truncationAmount)
265 |         .filter((index) => index >= 0);
266 | 
267 |       if (adjustedIndices.length > 0) {
268 |         this.contentStats.set(hash, adjustedIndices);
269 |       } else {
270 |         this.contentStats.delete(hash);
271 |       }
272 |     }
273 |   }
274 | 
275 |   /**
276 |    * Analyzes content in fixed-size chunks to detect repetitive patterns.
277 |    *
278 |    * Uses a sliding window approach:
279 |    * 1. Extract chunks of fixed size (CONTENT_CHUNK_SIZE)
280 |    * 2. Hash each chunk for efficient comparison
281 |    * 3. Track positions where identical chunks appear
282 |    * 4. Detect loops when chunks repeat frequently within a short distance
283 |    */
284 |   private analyzeContentChunksForLoop(): boolean {
285 |     while (this.hasMoreChunksToProcess()) {
286 |       // Extract current chunk of text
287 |       const currentChunk = this.streamContentHistory.substring(
288 |         this.lastContentIndex,
289 |         this.lastContentIndex + CONTENT_CHUNK_SIZE,
290 |       );
291 |       const chunkHash = createHash('sha256').update(currentChunk).digest('hex');
292 | 
293 |       if (this.isLoopDetectedForChunk(currentChunk, chunkHash)) {
294 |         logLoopDetected(
295 |           this.config,
296 |           new LoopDetectedEvent(
297 |             LoopType.CHANTING_IDENTICAL_SENTENCES,
298 |             this.promptId,
299 |           ),
300 |         );
301 |         return true;
302 |       }
303 | 
304 |       // Move to next position in the sliding window
305 |       this.lastContentIndex++;
306 |     }
307 | 
308 |     return false;
309 |   }
310 | 
311 |   private hasMoreChunksToProcess(): boolean {
312 |     return (
313 |       this.lastContentIndex + CONTENT_CHUNK_SIZE <=
314 |       this.streamContentHistory.length
315 |     );
316 |   }
317 | 
318 |   /**
319 |    * Determines if a content chunk indicates a loop pattern.
320 |    *
321 |    * Loop detection logic:
322 |    * 1. Check if we've seen this hash before (new chunks are stored for future comparison)
323 |    * 2. Verify actual content matches to prevent hash collisions
324 |    * 3. Track all positions where this chunk appears
325 |    * 4. A loop is detected when the same chunk appears CONTENT_LOOP_THRESHOLD times
326 |    *    within a small average distance (≤ 1.5 * chunk size)
327 |    */
328 |   private isLoopDetectedForChunk(chunk: string, hash: string): boolean {
329 |     const existingIndices = this.contentStats.get(hash);
330 | 
331 |     if (!existingIndices) {
332 |       this.contentStats.set(hash, [this.lastContentIndex]);
333 |       return false;
334 |     }
335 | 
336 |     if (!this.isActualContentMatch(chunk, existingIndices[0])) {
337 |       return false;
338 |     }
339 | 
340 |     existingIndices.push(this.lastContentIndex);
341 | 
342 |     if (existingIndices.length < CONTENT_LOOP_THRESHOLD) {
343 |       return false;
344 |     }
345 | 
346 |     // Analyze the most recent occurrences to see if they're clustered closely together
347 |     const recentIndices = existingIndices.slice(-CONTENT_LOOP_THRESHOLD);
348 |     const totalDistance =
349 |       recentIndices[recentIndices.length - 1] - recentIndices[0];
350 |     const averageDistance = totalDistance / (CONTENT_LOOP_THRESHOLD - 1);
351 |     const maxAllowedDistance = CONTENT_CHUNK_SIZE * 1.5;
352 | 
353 |     return averageDistance <= maxAllowedDistance;
354 |   }
355 | 
356 |   /**
357 |    * Verifies that two chunks with the same hash actually contain identical content.
358 |    * This prevents false positives from hash collisions.
359 |    */
360 |   private isActualContentMatch(
361 |     currentChunk: string,
362 |     originalIndex: number,
363 |   ): boolean {
364 |     const originalChunk = this.streamContentHistory.substring(
365 |       originalIndex,
366 |       originalIndex + CONTENT_CHUNK_SIZE,
367 |     );
368 |     return originalChunk === currentChunk;
369 |   }
370 | 
371 |   private trimRecentHistory(recentHistory: Content[]): Content[] {
372 |     // A function response must be preceded by a function call.
373 |     // Continuously removes dangling function calls from the end of the history
374 |     // until the last turn is not a function call.
375 |     while (
376 |       recentHistory.length > 0 &&
377 |       isFunctionCall(recentHistory[recentHistory.length - 1])
378 |     ) {
379 |       recentHistory.pop();
380 |     }
381 | 
382 |     // A function response should follow a function call.
383 |     // Continuously removes leading function responses from the beginning of history
384 |     // until the first turn is not a function response.
385 |     while (recentHistory.length > 0 && isFunctionResponse(recentHistory[0])) {
386 |       recentHistory.shift();
387 |     }
388 | 
389 |     return recentHistory;
390 |   }
391 | 
392 |   private async checkForLoopWithLLM(signal: AbortSignal) {
393 |     const recentHistory = this.config
394 |       .getGeminiClient()
395 |       .getHistory()
396 |       .slice(-LLM_LOOP_CHECK_HISTORY_COUNT);
397 | 
398 |     const trimmedHistory = this.trimRecentHistory(recentHistory);
399 | 
400 |     const taskPrompt = `Please analyze the conversation history to determine the possibility that the conversation is stuck in a repetitive, non-productive state. Provide your response in the requested JSON format.`;
401 | 
402 |     const contents = [
403 |       ...trimmedHistory,
404 |       { role: 'user', parts: [{ text: taskPrompt }] },
405 |     ];
406 |     const schema: Record<string, unknown> = {
407 |       type: 'object',
408 |       properties: {
409 |         reasoning: {
410 |           type: 'string',
411 |           description:
412 |             'Your reasoning on if the conversation is looping without forward progress.',
413 |         },
414 |         confidence: {
415 |           type: 'number',
416 |           description:
417 |             'A number between 0.0 and 1.0 representing your confidence that the conversation is in an unproductive state.',
418 |         },
419 |       },
420 |       required: ['reasoning', 'confidence'],
421 |     };
422 |     let result;
423 |     try {
424 |       result = await this.config.getBaseLlmClient().generateJson({
425 |         contents,
426 |         schema,
427 |         model: DEFAULT_GEMINI_FLASH_MODEL,
428 |         systemInstruction: LOOP_DETECTION_SYSTEM_PROMPT,
429 |         abortSignal: signal,
430 |         promptId: this.promptId,
431 |       });
432 |     } catch (e) {
433 |       // Do nothing, treat it as a non-loop.
434 |       this.config.getDebugMode() ? console.error(e) : console.debug(e);
435 |       return false;
436 |     }
437 | 
438 |     if (typeof result['confidence'] === 'number') {
439 |       if (result['confidence'] > 0.9) {
440 |         if (typeof result['reasoning'] === 'string' && result['reasoning']) {
441 |           console.warn(result['reasoning']);
442 |         }
443 |         logLoopDetected(
444 |           this.config,
445 |           new LoopDetectedEvent(LoopType.LLM_DETECTED_LOOP, this.promptId),
446 |         );
447 |         return true;
448 |       } else {
449 |         this.llmCheckInterval = Math.round(
450 |           MIN_LLM_CHECK_INTERVAL +
451 |             (MAX_LLM_CHECK_INTERVAL - MIN_LLM_CHECK_INTERVAL) *
452 |               (1 - result['confidence']),
453 |         );
454 |       }
455 |     }
456 |     return false;
457 |   }
458 | 
459 |   /**
460 |    * Resets all loop detection state.
461 |    */
462 |   reset(promptId: string): void {
463 |     this.promptId = promptId;
464 |     this.resetToolCallCount();
465 |     this.resetContentTracking();
466 |     this.resetLlmCheckTracking();
467 |     this.loopDetected = false;
468 |   }
469 | 
470 |   private resetToolCallCount(): void {
471 |     this.lastToolCallKey = null;
472 |     this.toolCallRepetitionCount = 0;
473 |   }
474 | 
475 |   private resetContentTracking(resetHistory = true): void {
476 |     if (resetHistory) {
477 |       this.streamContentHistory = '';
478 |     }
479 |     this.contentStats.clear();
480 |     this.lastContentIndex = 0;
481 |   }
482 | 
483 |   private resetLlmCheckTracking(): void {
484 |     this.turnsInCurrentPrompt = 0;
485 |     this.llmCheckInterval = DEFAULT_LLM_CHECK_INTERVAL;
486 |     this.lastCheckTurn = 0;
487 |   }
488 | }
```

src/services/shellExecutionService.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { vi, describe, it, expect, beforeEach, type Mock } from 'vitest';
8 | import EventEmitter from 'node:events';
9 | import type { Readable } from 'node:stream';
10 | import { type ChildProcess } from 'node:child_process';
11 | import type { ShellOutputEvent } from './shellExecutionService.js';
12 | import { ShellExecutionService } from './shellExecutionService.js';
13 | import type { AnsiOutput } from '../utils/terminalSerializer.js';
14 | 
15 | // Hoisted Mocks
16 | const mockPtySpawn = vi.hoisted(() => vi.fn());
17 | const mockCpSpawn = vi.hoisted(() => vi.fn());
18 | const mockIsBinary = vi.hoisted(() => vi.fn());
19 | const mockPlatform = vi.hoisted(() => vi.fn());
20 | const mockGetPty = vi.hoisted(() => vi.fn());
21 | const mockSerializeTerminalToObject = vi.hoisted(() => vi.fn());
22 | 
23 | // Top-level Mocks
24 | vi.mock('@lydell/node-pty', () => ({
25 |   spawn: mockPtySpawn,
26 | }));
27 | vi.mock('child_process', () => ({
28 |   spawn: mockCpSpawn,
29 | }));
30 | vi.mock('../utils/textUtils.js', () => ({
31 |   isBinary: mockIsBinary,
32 | }));
33 | vi.mock('os', () => ({
34 |   default: {
35 |     platform: mockPlatform,
36 |     constants: {
37 |       signals: {
38 |         SIGTERM: 15,
39 |         SIGKILL: 9,
40 |       },
41 |     },
42 |   },
43 |   platform: mockPlatform,
44 |   constants: {
45 |     signals: {
46 |       SIGTERM: 15,
47 |       SIGKILL: 9,
48 |     },
49 |   },
50 | }));
51 | vi.mock('../utils/getPty.js', () => ({
52 |   getPty: mockGetPty,
53 | }));
54 | vi.mock('../utils/terminalSerializer.js', () => ({
55 |   serializeTerminalToObject: mockSerializeTerminalToObject,
56 | }));
57 | 
58 | const mockProcessKill = vi
59 |   .spyOn(process, 'kill')
60 |   .mockImplementation(() => true);
61 | 
62 | const shellExecutionConfig = {
63 |   terminalWidth: 80,
64 |   terminalHeight: 24,
65 |   pager: 'cat',
66 |   showColor: false,
67 |   disableDynamicLineTrimming: true,
68 | };
69 | 
70 | const createExpectedAnsiOutput = (text: string | string[]): AnsiOutput => {
71 |   const lines = Array.isArray(text) ? text : text.split('\n');
72 |   const expected: AnsiOutput = Array.from(
73 |     { length: shellExecutionConfig.terminalHeight },
74 |     (_, i) => [
75 |       {
76 |         text: expect.stringMatching((lines[i] || '').trim()),
77 |         bold: false,
78 |         italic: false,
79 |         underline: false,
80 |         dim: false,
81 |         inverse: false,
82 |         fg: '',
83 |         bg: '',
84 |       },
85 |     ],
86 |   );
87 |   return expected;
88 | };
89 | 
90 | describe('ShellExecutionService', () => {
91 |   let mockPtyProcess: EventEmitter & {
92 |     pid: number;
93 |     kill: Mock;
94 |     onData: Mock;
95 |     onExit: Mock;
96 |     write: Mock;
97 |     resize: Mock;
98 |   };
99 |   let mockHeadlessTerminal: {
100 |     resize: Mock;
101 |     scrollLines: Mock;
102 |     buffer: {
103 |       active: {
104 |         viewportY: number;
105 |       };
106 |     };
107 |   };
108 |   let onOutputEventMock: Mock<(event: ShellOutputEvent) => void>;
109 | 
110 |   beforeEach(() => {
111 |     vi.clearAllMocks();
112 | 
113 |     mockIsBinary.mockReturnValue(false);
114 |     mockPlatform.mockReturnValue('linux');
115 |     mockGetPty.mockResolvedValue({
116 |       module: { spawn: mockPtySpawn },
117 |       name: 'mock-pty',
118 |     });
119 | 
120 |     onOutputEventMock = vi.fn();
121 | 
122 |     mockPtyProcess = new EventEmitter() as EventEmitter & {
123 |       pid: number;
124 |       kill: Mock;
125 |       onData: Mock;
126 |       onExit: Mock;
127 |       write: Mock;
128 |       resize: Mock;
129 |     };
130 |     mockPtyProcess.pid = 12345;
131 |     mockPtyProcess.kill = vi.fn();
132 |     mockPtyProcess.onData = vi.fn();
133 |     mockPtyProcess.onExit = vi.fn();
134 |     mockPtyProcess.write = vi.fn();
135 |     mockPtyProcess.resize = vi.fn();
136 | 
137 |     mockHeadlessTerminal = {
138 |       resize: vi.fn(),
139 |       scrollLines: vi.fn(),
140 |       buffer: {
141 |         active: {
142 |           viewportY: 0,
143 |         },
144 |       },
145 |     };
146 | 
147 |     mockPtySpawn.mockReturnValue(mockPtyProcess);
148 |   });
149 | 
150 |   // Helper function to run a standard execution simulation
151 |   const simulateExecution = async (
152 |     command: string,
153 |     simulation: (
154 |       ptyProcess: typeof mockPtyProcess,
155 |       ac: AbortController,
156 |     ) => void | Promise<void>,
157 |     config = shellExecutionConfig,
158 |   ) => {
159 |     const abortController = new AbortController();
160 |     const handle = await ShellExecutionService.execute(
161 |       command,
162 |       '/test/dir',
163 |       onOutputEventMock,
164 |       abortController.signal,
165 |       true,
166 |       config,
167 |     );
168 | 
169 |     await new Promise((resolve) => process.nextTick(resolve));
170 |     await simulation(mockPtyProcess, abortController);
171 |     const result = await handle.result;
172 |     return { result, handle, abortController };
173 |   };
174 | 
175 |   describe('Successful Execution', () => {
176 |     it('should execute a command and capture output', async () => {
177 |       const { result, handle } = await simulateExecution('ls -l', (pty) => {
178 |         pty.onData.mock.calls[0][0]('file1.txt\n');
179 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
180 |       });
181 | 
182 |       expect(mockPtySpawn).toHaveBeenCalledWith(
183 |         'bash',
184 |         ['-c', 'ls -l'],
185 |         expect.any(Object),
186 |       );
187 |       expect(result.exitCode).toBe(0);
188 |       expect(result.signal).toBeNull();
189 |       expect(result.error).toBeNull();
190 |       expect(result.aborted).toBe(false);
191 |       expect(result.output.trim()).toBe('file1.txt');
192 |       expect(handle.pid).toBe(12345);
193 | 
194 |       expect(onOutputEventMock).toHaveBeenCalledWith({
195 |         type: 'data',
196 |         chunk: createExpectedAnsiOutput('file1.txt'),
197 |       });
198 |     });
199 | 
200 |     it('should strip ANSI codes from output', async () => {
201 |       const { result } = await simulateExecution('ls --color=auto', (pty) => {
202 |         pty.onData.mock.calls[0][0]('a\u001b[31mred\u001b[0mword');
203 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
204 |       });
205 | 
206 |       expect(result.output.trim()).toBe('aredword');
207 |       expect(onOutputEventMock).toHaveBeenCalledWith(
208 |         expect.objectContaining({
209 |           type: 'data',
210 |           chunk: createExpectedAnsiOutput('aredword'),
211 |         }),
212 |       );
213 |     });
214 | 
215 |     it('should correctly decode multi-byte characters split across chunks', async () => {
216 |       const { result } = await simulateExecution('echo "你好"', (pty) => {
217 |         const multiByteChar = '你好';
218 |         pty.onData.mock.calls[0][0](multiByteChar.slice(0, 1));
219 |         pty.onData.mock.calls[0][0](multiByteChar.slice(1));
220 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
221 |       });
222 |       expect(result.output.trim()).toBe('你好');
223 |     });
224 | 
225 |     it('should handle commands with no output', async () => {
226 |       await simulateExecution('touch file', (pty) => {
227 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
228 |       });
229 | 
230 |       expect(onOutputEventMock).toHaveBeenCalledWith(
231 |         expect.objectContaining({
232 |           chunk: createExpectedAnsiOutput(''),
233 |         }),
234 |       );
235 |     });
236 | 
237 |     it('should call onPid with the process id', async () => {
238 |       const abortController = new AbortController();
239 |       const handle = await ShellExecutionService.execute(
240 |         'ls -l',
241 |         '/test/dir',
242 |         onOutputEventMock,
243 |         abortController.signal,
244 |         true,
245 |         shellExecutionConfig,
246 |       );
247 |       mockPtyProcess.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
248 |       await handle.result;
249 |       expect(handle.pid).toBe(12345);
250 |     });
251 |   });
252 | 
253 |   describe('pty interaction', () => {
254 |     beforeEach(() => {
255 |       vi.spyOn(ShellExecutionService['activePtys'], 'get').mockReturnValue({
256 |         // eslint-disable-next-line @typescript-eslint/no-explicit-any
257 |         ptyProcess: mockPtyProcess as any,
258 |         // eslint-disable-next-line @typescript-eslint/no-explicit-any
259 |         headlessTerminal: mockHeadlessTerminal as any,
260 |       });
261 |     });
262 | 
263 |     it('should write to the pty and trigger a render', async () => {
264 |       vi.useFakeTimers();
265 |       await simulateExecution('interactive-app', (pty) => {
266 |         ShellExecutionService.writeToPty(pty.pid!, 'input');
267 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
268 |       });
269 | 
270 |       expect(mockPtyProcess.write).toHaveBeenCalledWith('input');
271 |       // Use fake timers to check for the delayed render
272 |       await vi.advanceTimersByTimeAsync(17);
273 |       // The render will cause an output event
274 |       expect(onOutputEventMock).toHaveBeenCalled();
275 |       vi.useRealTimers();
276 |     });
277 | 
278 |     it('should resize the pty and the headless terminal', async () => {
279 |       await simulateExecution('ls -l', (pty) => {
280 |         pty.onData.mock.calls[0][0]('file1.txt\n');
281 |         ShellExecutionService.resizePty(pty.pid!, 100, 40);
282 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
283 |       });
284 | 
285 |       expect(mockPtyProcess.resize).toHaveBeenCalledWith(100, 40);
286 |       expect(mockHeadlessTerminal.resize).toHaveBeenCalledWith(100, 40);
287 |     });
288 | 
289 |     it('should scroll the headless terminal', async () => {
290 |       await simulateExecution('ls -l', (pty) => {
291 |         pty.onData.mock.calls[0][0]('file1.txt\n');
292 |         ShellExecutionService.scrollPty(pty.pid!, 10);
293 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
294 |       });
295 | 
296 |       expect(mockHeadlessTerminal.scrollLines).toHaveBeenCalledWith(10);
297 |     });
298 |   });
299 | 
300 |   describe('Failed Execution', () => {
301 |     it('should capture a non-zero exit code', async () => {
302 |       const { result } = await simulateExecution('a-bad-command', (pty) => {
303 |         pty.onData.mock.calls[0][0]('command not found');
304 |         pty.onExit.mock.calls[0][0]({ exitCode: 127, signal: null });
305 |       });
306 | 
307 |       expect(result.exitCode).toBe(127);
308 |       expect(result.output.trim()).toBe('command not found');
309 |       expect(result.error).toBeNull();
310 |     });
311 | 
312 |     it('should capture a termination signal', async () => {
313 |       const { result } = await simulateExecution('long-process', (pty) => {
314 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: 15 });
315 |       });
316 | 
317 |       expect(result.exitCode).toBe(0);
318 |       expect(result.signal).toBe(15);
319 |     });
320 | 
321 |     it('should handle a synchronous spawn error', async () => {
322 |       mockGetPty.mockImplementation(() => null);
323 | 
324 |       mockCpSpawn.mockImplementation(() => {
325 |         throw new Error('Simulated PTY spawn error');
326 |       });
327 | 
328 |       const handle = await ShellExecutionService.execute(
329 |         'any-command',
330 |         '/test/dir',
331 |         onOutputEventMock,
332 |         new AbortController().signal,
333 |         true,
334 |         {},
335 |       );
336 |       const result = await handle.result;
337 | 
338 |       expect(result.error).toBeInstanceOf(Error);
339 |       expect(result.error?.message).toContain('Simulated PTY spawn error');
340 |       expect(result.exitCode).toBe(1);
341 |       expect(result.output).toBe('');
342 |       expect(handle.pid).toBeUndefined();
343 |     });
344 |   });
345 | 
346 |   describe('Aborting Commands', () => {
347 |     it('should abort a running process and set the aborted flag', async () => {
348 |       const { result } = await simulateExecution(
349 |         'sleep 10',
350 |         (pty, abortController) => {
351 |           abortController.abort();
352 |           pty.onExit.mock.calls[0][0]({ exitCode: 1, signal: null });
353 |         },
354 |       );
355 | 
356 |       expect(result.aborted).toBe(true);
357 |       // The process kill is mocked, so we just check that the flag is set.
358 |     });
359 | 
360 |     it('should send SIGTERM and then SIGKILL on abort', async () => {
361 |       const sigkillPromise = new Promise<void>((resolve) => {
362 |         mockProcessKill.mockImplementation((pid, signal) => {
363 |           if (signal === 'SIGKILL' && pid === -mockPtyProcess.pid) {
364 |             resolve();
365 |           }
366 |           return true;
367 |         });
368 |       });
369 | 
370 |       const { result } = await simulateExecution(
371 |         'long-running-process',
372 |         async (pty, abortController) => {
373 |           abortController.abort();
374 |           await sigkillPromise; // Wait for SIGKILL to be sent before exiting.
375 |           pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: 9 });
376 |         },
377 |       );
378 | 
379 |       expect(result.aborted).toBe(true);
380 | 
381 |       // Verify the calls were made in the correct order.
382 |       const killCalls = mockProcessKill.mock.calls;
383 |       const sigtermCallIndex = killCalls.findIndex(
384 |         (call) => call[0] === -mockPtyProcess.pid && call[1] === 'SIGTERM',
385 |       );
386 |       const sigkillCallIndex = killCalls.findIndex(
387 |         (call) => call[0] === -mockPtyProcess.pid && call[1] === 'SIGKILL',
388 |       );
389 | 
390 |       expect(sigtermCallIndex).toBe(0);
391 |       expect(sigkillCallIndex).toBe(1);
392 |       expect(sigtermCallIndex).toBeLessThan(sigkillCallIndex);
393 | 
394 |       expect(result.signal).toBe(9);
395 |     });
396 | 
397 |     it('should resolve without waiting for the processing chain on abort', async () => {
398 |       const { result } = await simulateExecution(
399 |         'long-output',
400 |         (pty, abortController) => {
401 |           // Simulate a lot of data being in the queue to be processed
402 |           for (let i = 0; i < 1000; i++) {
403 |             pty.onData.mock.calls[0][0]('some data');
404 |           }
405 |           abortController.abort();
406 |           pty.onExit.mock.calls[0][0]({ exitCode: 1, signal: null });
407 |         },
408 |       );
409 | 
410 |       // The main assertion here is implicit: the `await` for the result above
411 |       // should complete without timing out. This proves that the resolution
412 |       // was not blocked by the long chain of data processing promises,
413 |       // which is the desired behavior on abort.
414 |       expect(result.aborted).toBe(true);
415 |     });
416 |   });
417 | 
418 |   describe('Binary Output', () => {
419 |     it('should detect binary output and switch to progress events', async () => {
420 |       mockIsBinary.mockReturnValueOnce(true);
421 |       const binaryChunk1 = Buffer.from([0x89, 0x50, 0x4e, 0x47]);
422 |       const binaryChunk2 = Buffer.from([0x0d, 0x0a, 0x1a, 0x0a]);
423 | 
424 |       const { result } = await simulateExecution('cat image.png', (pty) => {
425 |         pty.onData.mock.calls[0][0](binaryChunk1);
426 |         pty.onData.mock.calls[0][0](binaryChunk2);
427 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
428 |       });
429 | 
430 |       expect(result.rawOutput).toEqual(
431 |         Buffer.concat([binaryChunk1, binaryChunk2]),
432 |       );
433 |       expect(onOutputEventMock).toHaveBeenCalledTimes(3);
434 |       expect(onOutputEventMock.mock.calls[0][0]).toEqual({
435 |         type: 'binary_detected',
436 |       });
437 |       expect(onOutputEventMock.mock.calls[1][0]).toEqual({
438 |         type: 'binary_progress',
439 |         bytesReceived: 4,
440 |       });
441 |       expect(onOutputEventMock.mock.calls[2][0]).toEqual({
442 |         type: 'binary_progress',
443 |         bytesReceived: 8,
444 |       });
445 |     });
446 | 
447 |     it('should not emit data events after binary is detected', async () => {
448 |       mockIsBinary.mockImplementation((buffer) => buffer.includes(0x00));
449 | 
450 |       await simulateExecution('cat mixed_file', (pty) => {
451 |         pty.onData.mock.calls[0][0](Buffer.from([0x00, 0x01, 0x02]));
452 |         pty.onData.mock.calls[0][0](Buffer.from('more text'));
453 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
454 |       });
455 | 
456 |       const eventTypes = onOutputEventMock.mock.calls.map(
457 |         (call: [ShellOutputEvent]) => call[0].type,
458 |       );
459 |       expect(eventTypes).toEqual([
460 |         'binary_detected',
461 |         'binary_progress',
462 |         'binary_progress',
463 |       ]);
464 |     });
465 |   });
466 | 
467 |   describe('Platform-Specific Behavior', () => {
468 |     it('should use cmd.exe on Windows', async () => {
469 |       mockPlatform.mockReturnValue('win32');
470 |       await simulateExecution('dir "foo bar"', (pty) =>
471 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null }),
472 |       );
473 | 
474 |       expect(mockPtySpawn).toHaveBeenCalledWith(
475 |         'cmd.exe',
476 |         '/c dir "foo bar"',
477 |         expect.any(Object),
478 |       );
479 |     });
480 | 
481 |     it('should use bash on Linux', async () => {
482 |       mockPlatform.mockReturnValue('linux');
483 |       await simulateExecution('ls "foo bar"', (pty) =>
484 |         pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null }),
485 |       );
486 | 
487 |       expect(mockPtySpawn).toHaveBeenCalledWith(
488 |         'bash',
489 |         ['-c', 'ls "foo bar"'],
490 |         expect.any(Object),
491 |       );
492 |     });
493 |   });
494 | 
495 |   describe('AnsiOutput rendering', () => {
496 |     it('should call onOutputEvent with AnsiOutput when showColor is true', async () => {
497 |       const coloredShellExecutionConfig = {
498 |         ...shellExecutionConfig,
499 |         showColor: true,
500 |         defaultFg: '#ffffff',
501 |         defaultBg: '#000000',
502 |         disableDynamicLineTrimming: true,
503 |       };
504 |       const mockAnsiOutput = [
505 |         [{ text: 'hello', fg: '#ffffff', bg: '#000000' }],
506 |       ];
507 |       mockSerializeTerminalToObject.mockReturnValue(mockAnsiOutput);
508 | 
509 |       await simulateExecution(
510 |         'ls --color=auto',
511 |         (pty) => {
512 |           pty.onData.mock.calls[0][0]('a\u001b[31mred\u001b[0mword');
513 |           pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
514 |         },
515 |         coloredShellExecutionConfig,
516 |       );
517 | 
518 |       expect(mockSerializeTerminalToObject).toHaveBeenCalledWith(
519 |         expect.anything(), // The terminal object
520 |       );
521 | 
522 |       expect(onOutputEventMock).toHaveBeenCalledWith(
523 |         expect.objectContaining({
524 |           type: 'data',
525 |           chunk: mockAnsiOutput,
526 |         }),
527 |       );
528 |     });
529 | 
530 |     it('should call onOutputEvent with AnsiOutput when showColor is false', async () => {
531 |       await simulateExecution(
532 |         'ls --color=auto',
533 |         (pty) => {
534 |           pty.onData.mock.calls[0][0]('a\u001b[31mred\u001b[0mword');
535 |           pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
536 |         },
537 |         {
538 |           ...shellExecutionConfig,
539 |           showColor: false,
540 |           disableDynamicLineTrimming: true,
541 |         },
542 |       );
543 | 
544 |       const expected = createExpectedAnsiOutput('aredword');
545 | 
546 |       expect(onOutputEventMock).toHaveBeenCalledWith(
547 |         expect.objectContaining({
548 |           type: 'data',
549 |           chunk: expected,
550 |         }),
551 |       );
552 |     });
553 | 
554 |     it('should handle multi-line output correctly when showColor is false', async () => {
555 |       await simulateExecution(
556 |         'ls --color=auto',
557 |         (pty) => {
558 |           pty.onData.mock.calls[0][0](
559 |             'line 1\n\u001b[32mline 2\u001b[0m\nline 3',
560 |           );
561 |           pty.onExit.mock.calls[0][0]({ exitCode: 0, signal: null });
562 |         },
563 |         {
564 |           ...shellExecutionConfig,
565 |           showColor: false,
566 |           disableDynamicLineTrimming: true,
567 |         },
568 |       );
569 | 
570 |       const expected = createExpectedAnsiOutput(['line 1', 'line 2', 'line 3']);
571 | 
572 |       expect(onOutputEventMock).toHaveBeenCalledWith(
573 |         expect.objectContaining({
574 |           type: 'data',
575 |           chunk: expected,
576 |         }),
577 |       );
578 |     });
579 |   });
580 | });
581 | 
582 | describe('ShellExecutionService child_process fallback', () => {
583 |   let mockChildProcess: EventEmitter & Partial<ChildProcess>;
584 |   let onOutputEventMock: Mock<(event: ShellOutputEvent) => void>;
585 | 
586 |   beforeEach(() => {
587 |     vi.clearAllMocks();
588 | 
589 |     mockIsBinary.mockReturnValue(false);
590 |     mockPlatform.mockReturnValue('linux');
591 |     mockGetPty.mockResolvedValue(null);
592 | 
593 |     onOutputEventMock = vi.fn();
594 | 
595 |     mockChildProcess = new EventEmitter() as EventEmitter &
596 |       Partial<ChildProcess>;
597 |     mockChildProcess.stdout = new EventEmitter() as Readable;
598 |     mockChildProcess.stderr = new EventEmitter() as Readable;
599 |     mockChildProcess.kill = vi.fn();
600 | 
601 |     Object.defineProperty(mockChildProcess, 'pid', {
602 |       value: 12345,
603 |       configurable: true,
604 |     });
605 | 
606 |     mockCpSpawn.mockReturnValue(mockChildProcess);
607 |   });
608 | 
609 |   // Helper function to run a standard execution simulation
610 |   const simulateExecution = async (
611 |     command: string,
612 |     simulation: (cp: typeof mockChildProcess, ac: AbortController) => void,
613 |   ) => {
614 |     const abortController = new AbortController();
615 |     const handle = await ShellExecutionService.execute(
616 |       command,
617 |       '/test/dir',
618 |       onOutputEventMock,
[TRUNCATED]
```

src/services/shellExecutionService.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import stripAnsi from 'strip-ansi';
8 | import type { PtyImplementation } from '../utils/getPty.js';
9 | import { getPty } from '../utils/getPty.js';
10 | import { spawn as cpSpawn } from 'node:child_process';
11 | import { TextDecoder } from 'node:util';
12 | import os from 'node:os';
13 | import type { IPty } from '@lydell/node-pty';
14 | import { getCachedEncodingForBuffer } from '../utils/systemEncoding.js';
15 | import { isBinary } from '../utils/textUtils.js';
16 | import pkg from '@xterm/headless';
17 | import {
18 |   serializeTerminalToObject,
19 |   type AnsiOutput,
20 | } from '../utils/terminalSerializer.js';
21 | const { Terminal } = pkg;
22 | 
23 | const SIGKILL_TIMEOUT_MS = 200;
24 | const MAX_CHILD_PROCESS_BUFFER_SIZE = 16 * 1024 * 1024; // 16MB
25 | 
26 | /** A structured result from a shell command execution. */
27 | export interface ShellExecutionResult {
28 |   /** The raw, unprocessed output buffer. */
29 |   rawOutput: Buffer;
30 |   /** The combined, decoded output as a string. */
31 |   output: string;
32 |   /** The process exit code, or null if terminated by a signal. */
33 |   exitCode: number | null;
34 |   /** The signal that terminated the process, if any. */
35 |   signal: number | null;
36 |   /** An error object if the process failed to spawn. */
37 |   error: Error | null;
38 |   /** A boolean indicating if the command was aborted by the user. */
39 |   aborted: boolean;
40 |   /** The process ID of the spawned shell. */
41 |   pid: number | undefined;
42 |   /** The method used to execute the shell command. */
43 |   executionMethod: 'lydell-node-pty' | 'node-pty' | 'child_process' | 'none';
44 | }
45 | 
46 | /** A handle for an ongoing shell execution. */
47 | export interface ShellExecutionHandle {
48 |   /** The process ID of the spawned shell. */
49 |   pid: number | undefined;
50 |   /** A promise that resolves with the complete execution result. */
51 |   result: Promise<ShellExecutionResult>;
52 | }
53 | 
54 | export interface ShellExecutionConfig {
55 |   terminalWidth?: number;
56 |   terminalHeight?: number;
57 |   pager?: string;
58 |   showColor?: boolean;
59 |   defaultFg?: string;
60 |   defaultBg?: string;
61 |   // Used for testing
62 |   disableDynamicLineTrimming?: boolean;
63 | }
64 | 
65 | /**
66 |  * Describes a structured event emitted during shell command execution.
67 |  */
68 | export type ShellOutputEvent =
69 |   | {
70 |       /** The event contains a chunk of output data. */
71 |       type: 'data';
72 |       /** The decoded string chunk. */
73 |       chunk: string | AnsiOutput;
74 |     }
75 |   | {
76 |       /** Signals that the output stream has been identified as binary. */
77 |       type: 'binary_detected';
78 |     }
79 |   | {
80 |       /** Provides progress updates for a binary stream. */
81 |       type: 'binary_progress';
82 |       /** The total number of bytes received so far. */
83 |       bytesReceived: number;
84 |     };
85 | 
86 | interface ActivePty {
87 |   ptyProcess: IPty;
88 |   headlessTerminal: pkg.Terminal;
89 | }
90 | 
91 | const getFullBufferText = (terminal: pkg.Terminal): string => {
92 |   const buffer = terminal.buffer.active;
93 |   const lines: string[] = [];
94 |   for (let i = 0; i < buffer.length; i++) {
95 |     const line = buffer.getLine(i);
96 |     const lineContent = line ? line.translateToString() : '';
97 |     lines.push(lineContent);
98 |   }
99 |   return lines.join('\n').trimEnd();
100 | };
101 | 
102 | /**
103 |  * A centralized service for executing shell commands with robust process
104 |  * management, cross-platform compatibility, and streaming output capabilities.
105 |  *
106 |  */
107 | 
108 | export class ShellExecutionService {
109 |   private static activePtys = new Map<number, ActivePty>();
110 |   /**
111 |    * Executes a shell command using `node-pty`, capturing all output and lifecycle events.
112 |    *
113 |    * @param commandToExecute The exact command string to run.
114 |    * @param cwd The working directory to execute the command in.
115 |    * @param onOutputEvent A callback for streaming structured events about the execution, including data chunks and status updates.
116 |    * @param abortSignal An AbortSignal to terminate the process and its children.
117 |    * @returns An object containing the process ID (pid) and a promise that
118 |    *          resolves with the complete execution result.
119 |    */
120 |   static async execute(
121 |     commandToExecute: string,
122 |     cwd: string,
123 |     onOutputEvent: (event: ShellOutputEvent) => void,
124 |     abortSignal: AbortSignal,
125 |     shouldUseNodePty: boolean,
126 |     shellExecutionConfig: ShellExecutionConfig,
127 |   ): Promise<ShellExecutionHandle> {
128 |     if (shouldUseNodePty) {
129 |       const ptyInfo = await getPty();
130 |       if (ptyInfo) {
131 |         try {
132 |           return this.executeWithPty(
133 |             commandToExecute,
134 |             cwd,
135 |             onOutputEvent,
136 |             abortSignal,
137 |             shellExecutionConfig,
138 |             ptyInfo,
139 |           );
140 |         } catch (_e) {
141 |           // Fallback to child_process
142 |         }
143 |       }
144 |     }
145 | 
146 |     return this.childProcessFallback(
147 |       commandToExecute,
148 |       cwd,
149 |       onOutputEvent,
150 |       abortSignal,
151 |     );
152 |   }
153 | 
154 |   private static appendAndTruncate(
155 |     currentBuffer: string,
156 |     chunk: string,
157 |     maxSize: number,
158 |   ): { newBuffer: string; truncated: boolean } {
159 |     const chunkLength = chunk.length;
160 |     const currentLength = currentBuffer.length;
161 |     const newTotalLength = currentLength + chunkLength;
162 | 
163 |     if (newTotalLength <= maxSize) {
164 |       return { newBuffer: currentBuffer + chunk, truncated: false };
165 |     }
166 | 
167 |     // Truncation is needed.
168 |     if (chunkLength >= maxSize) {
169 |       // The new chunk is larger than or equal to the max buffer size.
170 |       // The new buffer will be the tail of the new chunk.
171 |       return {
172 |         newBuffer: chunk.substring(chunkLength - maxSize),
173 |         truncated: true,
174 |       };
175 |     }
176 | 
177 |     // The combined buffer exceeds the max size, but the new chunk is smaller than it.
178 |     // We need to truncate the current buffer from the beginning to make space.
179 |     const charsToTrim = newTotalLength - maxSize;
180 |     const truncatedBuffer = currentBuffer.substring(charsToTrim);
181 |     return { newBuffer: truncatedBuffer + chunk, truncated: true };
182 |   }
183 | 
184 |   private static childProcessFallback(
185 |     commandToExecute: string,
186 |     cwd: string,
187 |     onOutputEvent: (event: ShellOutputEvent) => void,
188 |     abortSignal: AbortSignal,
189 |   ): ShellExecutionHandle {
190 |     try {
191 |       const isWindows = os.platform() === 'win32';
192 | 
193 |       const child = cpSpawn(commandToExecute, [], {
194 |         cwd,
195 |         stdio: ['ignore', 'pipe', 'pipe'],
196 |         windowsVerbatimArguments: true,
197 |         shell: isWindows ? true : 'bash',
198 |         detached: !isWindows,
199 |         env: {
200 |           ...process.env,
201 |           GEMINI_CLI: '1',
202 |           TERM: 'xterm-256color',
203 |           PAGER: 'cat',
204 |         },
205 |       });
206 | 
207 |       const result = new Promise<ShellExecutionResult>((resolve) => {
208 |         let stdoutDecoder: TextDecoder | null = null;
209 |         let stderrDecoder: TextDecoder | null = null;
210 | 
211 |         let stdout = '';
212 |         let stderr = '';
213 |         let stdoutTruncated = false;
214 |         let stderrTruncated = false;
215 |         const outputChunks: Buffer[] = [];
216 |         let error: Error | null = null;
217 |         let exited = false;
218 | 
219 |         let isStreamingRawContent = true;
220 |         const MAX_SNIFF_SIZE = 4096;
221 |         let sniffedBytes = 0;
222 | 
223 |         const handleOutput = (data: Buffer, stream: 'stdout' | 'stderr') => {
224 |           if (!stdoutDecoder || !stderrDecoder) {
225 |             const encoding = getCachedEncodingForBuffer(data);
226 |             try {
227 |               stdoutDecoder = new TextDecoder(encoding);
228 |               stderrDecoder = new TextDecoder(encoding);
229 |             } catch {
230 |               stdoutDecoder = new TextDecoder('utf-8');
231 |               stderrDecoder = new TextDecoder('utf-8');
232 |             }
233 |           }
234 | 
235 |           outputChunks.push(data);
236 | 
237 |           if (isStreamingRawContent && sniffedBytes < MAX_SNIFF_SIZE) {
238 |             const sniffBuffer = Buffer.concat(outputChunks.slice(0, 20));
239 |             sniffedBytes = sniffBuffer.length;
240 | 
241 |             if (isBinary(sniffBuffer)) {
242 |               isStreamingRawContent = false;
243 |             }
244 |           }
245 | 
246 |           if (isStreamingRawContent) {
247 |             const decoder = stream === 'stdout' ? stdoutDecoder : stderrDecoder;
248 |             const decodedChunk = decoder.decode(data, { stream: true });
249 | 
250 |             if (stream === 'stdout') {
251 |               const { newBuffer, truncated } = this.appendAndTruncate(
252 |                 stdout,
253 |                 decodedChunk,
254 |                 MAX_CHILD_PROCESS_BUFFER_SIZE,
255 |               );
256 |               stdout = newBuffer;
257 |               if (truncated) {
258 |                 stdoutTruncated = true;
259 |               }
260 |             } else {
261 |               const { newBuffer, truncated } = this.appendAndTruncate(
262 |                 stderr,
263 |                 decodedChunk,
264 |                 MAX_CHILD_PROCESS_BUFFER_SIZE,
265 |               );
266 |               stderr = newBuffer;
267 |               if (truncated) {
268 |                 stderrTruncated = true;
269 |               }
270 |             }
271 |           }
272 |         };
273 | 
274 |         const handleExit = (
275 |           code: number | null,
276 |           signal: NodeJS.Signals | null,
277 |         ) => {
278 |           const { finalBuffer } = cleanup();
279 |           // Ensure we don't add an extra newline if stdout already ends with one.
280 |           const separator = stdout.endsWith('\n') ? '' : '\n';
281 |           let combinedOutput =
282 |             stdout + (stderr ? (stdout ? separator : '') + stderr : '');
283 | 
284 |           if (stdoutTruncated || stderrTruncated) {
285 |             const truncationMessage = `\n[GEMINI_CLI_WARNING: Output truncated. The buffer is limited to ${
286 |               MAX_CHILD_PROCESS_BUFFER_SIZE / (1024 * 1024)
287 |             }MB.]`;
288 |             combinedOutput += truncationMessage;
289 |           }
290 | 
291 |           const finalStrippedOutput = stripAnsi(combinedOutput).trim();
292 | 
293 |           if (isStreamingRawContent) {
294 |             if (finalStrippedOutput) {
295 |               onOutputEvent({ type: 'data', chunk: finalStrippedOutput });
296 |             }
297 |           } else {
298 |             onOutputEvent({ type: 'binary_detected' });
299 |           }
300 | 
301 |           resolve({
302 |             rawOutput: finalBuffer,
303 |             output: finalStrippedOutput,
304 |             exitCode: code,
305 |             signal: signal ? os.constants.signals[signal] : null,
306 |             error,
307 |             aborted: abortSignal.aborted,
308 |             pid: undefined,
309 |             executionMethod: 'child_process',
310 |           });
311 |         };
312 | 
313 |         child.stdout.on('data', (data) => handleOutput(data, 'stdout'));
314 |         child.stderr.on('data', (data) => handleOutput(data, 'stderr'));
315 |         child.on('error', (err) => {
316 |           error = err;
317 |           handleExit(1, null);
318 |         });
319 | 
320 |         const abortHandler = async () => {
321 |           if (child.pid && !exited) {
322 |             if (isWindows) {
323 |               cpSpawn('taskkill', ['/pid', child.pid.toString(), '/f', '/t']);
324 |             } else {
325 |               try {
326 |                 process.kill(-child.pid, 'SIGTERM');
327 |                 await new Promise((res) => setTimeout(res, SIGKILL_TIMEOUT_MS));
328 |                 if (!exited) {
329 |                   process.kill(-child.pid, 'SIGKILL');
330 |                 }
331 |               } catch (_e) {
332 |                 if (!exited) child.kill('SIGKILL');
333 |               }
334 |             }
335 |           }
336 |         };
337 | 
338 |         abortSignal.addEventListener('abort', abortHandler, { once: true });
339 | 
340 |         child.on('exit', (code, signal) => {
341 |           if (child.pid) {
342 |             this.activePtys.delete(child.pid);
343 |           }
344 |           handleExit(code, signal);
345 |         });
346 | 
347 |         function cleanup() {
348 |           exited = true;
349 |           abortSignal.removeEventListener('abort', abortHandler);
350 |           if (stdoutDecoder) {
351 |             const remaining = stdoutDecoder.decode();
352 |             if (remaining) {
353 |               stdout += remaining;
354 |             }
355 |           }
356 |           if (stderrDecoder) {
357 |             const remaining = stderrDecoder.decode();
358 |             if (remaining) {
359 |               stderr += remaining;
360 |             }
361 |           }
362 | 
363 |           const finalBuffer = Buffer.concat(outputChunks);
364 | 
365 |           return { stdout, stderr, finalBuffer };
366 |         }
367 |       });
368 | 
369 |       return { pid: undefined, result };
370 |     } catch (e) {
371 |       const error = e as Error;
372 |       return {
373 |         pid: undefined,
374 |         result: Promise.resolve({
375 |           error,
376 |           rawOutput: Buffer.from(''),
377 |           output: '',
378 |           exitCode: 1,
379 |           signal: null,
380 |           aborted: false,
381 |           pid: undefined,
382 |           executionMethod: 'none',
383 |         }),
384 |       };
385 |     }
386 |   }
387 | 
388 |   private static executeWithPty(
389 |     commandToExecute: string,
390 |     cwd: string,
391 |     onOutputEvent: (event: ShellOutputEvent) => void,
392 |     abortSignal: AbortSignal,
393 |     shellExecutionConfig: ShellExecutionConfig,
394 |     ptyInfo: PtyImplementation,
395 |   ): ShellExecutionHandle {
396 |     if (!ptyInfo) {
397 |       // This should not happen, but as a safeguard...
398 |       throw new Error('PTY implementation not found');
399 |     }
400 |     try {
401 |       const cols = shellExecutionConfig.terminalWidth ?? 80;
402 |       const rows = shellExecutionConfig.terminalHeight ?? 30;
403 |       const isWindows = os.platform() === 'win32';
404 |       const shell = isWindows ? 'cmd.exe' : 'bash';
405 |       const args = isWindows
406 |         ? `/c ${commandToExecute}`
407 |         : ['-c', commandToExecute];
408 | 
409 |       const ptyProcess = ptyInfo.module.spawn(shell, args, {
410 |         cwd,
411 |         name: 'xterm',
412 |         cols,
413 |         rows,
414 |         env: {
415 |           ...process.env,
416 |           GEMINI_CLI: '1',
417 |           TERM: 'xterm-256color',
418 |           PAGER: shellExecutionConfig.pager ?? 'cat',
419 |         },
420 |         handleFlowControl: true,
421 |       });
422 | 
423 |       const result = new Promise<ShellExecutionResult>((resolve) => {
424 |         const headlessTerminal = new Terminal({
425 |           allowProposedApi: true,
426 |           cols,
427 |           rows,
428 |         });
429 |         headlessTerminal.scrollToTop();
430 | 
431 |         this.activePtys.set(ptyProcess.pid, { ptyProcess, headlessTerminal });
432 | 
433 |         let processingChain = Promise.resolve();
434 |         let decoder: TextDecoder | null = null;
435 |         let output: string | AnsiOutput | null = null;
436 |         const outputChunks: Buffer[] = [];
437 |         const error: Error | null = null;
438 |         let exited = false;
439 | 
440 |         let isStreamingRawContent = true;
441 |         const MAX_SNIFF_SIZE = 4096;
442 |         let sniffedBytes = 0;
443 |         let isWriting = false;
444 |         let hasStartedOutput = false;
445 |         let renderTimeout: NodeJS.Timeout | null = null;
446 | 
447 |         const renderFn = () => {
448 |           renderTimeout = null;
449 | 
450 |           if (!isStreamingRawContent) {
451 |             return;
452 |           }
453 | 
454 |           if (!shellExecutionConfig.disableDynamicLineTrimming) {
455 |             if (!hasStartedOutput) {
456 |               const bufferText = getFullBufferText(headlessTerminal);
457 |               if (bufferText.trim().length === 0) {
458 |                 return;
459 |               }
460 |               hasStartedOutput = true;
461 |             }
462 |           }
463 | 
464 |           const buffer = headlessTerminal.buffer.active;
465 |           let newOutput: AnsiOutput;
466 |           if (shellExecutionConfig.showColor) {
467 |             newOutput = serializeTerminalToObject(headlessTerminal);
468 |           } else {
469 |             const lines: AnsiOutput = [];
470 |             for (let y = 0; y < headlessTerminal.rows; y++) {
471 |               const line = buffer.getLine(buffer.viewportY + y);
472 |               const lineContent = line ? line.translateToString(true) : '';
473 |               lines.push([
474 |                 {
475 |                   text: lineContent,
476 |                   bold: false,
477 |                   italic: false,
478 |                   underline: false,
479 |                   dim: false,
480 |                   inverse: false,
481 |                   fg: '',
482 |                   bg: '',
483 |                 },
484 |               ]);
485 |             }
486 |             newOutput = lines;
487 |           }
488 | 
489 |           let lastNonEmptyLine = -1;
490 |           for (let i = newOutput.length - 1; i >= 0; i--) {
491 |             const line = newOutput[i];
492 |             if (
493 |               line
494 |                 .map((segment) => segment.text)
495 |                 .join('')
496 |                 .trim().length > 0
497 |             ) {
498 |               lastNonEmptyLine = i;
499 |               break;
500 |             }
501 |           }
502 | 
503 |           if (buffer.cursorY > lastNonEmptyLine) {
504 |             lastNonEmptyLine = buffer.cursorY;
505 |           }
506 | 
507 |           const trimmedOutput = newOutput.slice(0, lastNonEmptyLine + 1);
508 | 
509 |           const finalOutput = shellExecutionConfig.disableDynamicLineTrimming
510 |             ? newOutput
511 |             : trimmedOutput;
512 | 
513 |           // Using stringify for a quick deep comparison.
514 |           if (JSON.stringify(output) !== JSON.stringify(finalOutput)) {
515 |             output = finalOutput;
516 |             onOutputEvent({
517 |               type: 'data',
518 |               chunk: finalOutput,
519 |             });
520 |           }
521 |         };
522 | 
523 |         const render = (finalRender = false) => {
524 |           if (finalRender) {
525 |             if (renderTimeout) {
526 |               clearTimeout(renderTimeout);
527 |             }
528 |             renderFn();
529 |             return;
530 |           }
531 | 
532 |           if (renderTimeout) {
533 |             return;
534 |           }
535 | 
536 |           renderTimeout = setTimeout(() => {
537 |             renderFn();
538 |             renderTimeout = null;
539 |           }, 68);
540 |         };
541 | 
542 |         headlessTerminal.onScroll(() => {
543 |           if (!isWriting) {
544 |             render();
545 |           }
546 |         });
547 | 
548 |         const handleOutput = (data: Buffer) => {
549 |           processingChain = processingChain.then(
550 |             () =>
551 |               new Promise<void>((resolve) => {
552 |                 if (!decoder) {
553 |                   const encoding = getCachedEncodingForBuffer(data);
554 |                   try {
555 |                     decoder = new TextDecoder(encoding);
556 |                   } catch {
557 |                     decoder = new TextDecoder('utf-8');
558 |                   }
559 |                 }
560 | 
561 |                 outputChunks.push(data);
562 | 
563 |                 if (isStreamingRawContent && sniffedBytes < MAX_SNIFF_SIZE) {
564 |                   const sniffBuffer = Buffer.concat(outputChunks.slice(0, 20));
565 |                   sniffedBytes = sniffBuffer.length;
566 | 
567 |                   if (isBinary(sniffBuffer)) {
568 |                     isStreamingRawContent = false;
569 |                     onOutputEvent({ type: 'binary_detected' });
570 |                   }
571 |                 }
572 | 
573 |                 if (isStreamingRawContent) {
574 |                   const decodedChunk = decoder.decode(data, { stream: true });
575 |                   if (decodedChunk.length === 0) {
576 |                     resolve();
577 |                     return;
578 |                   }
579 |                   isWriting = true;
580 |                   headlessTerminal.write(decodedChunk, () => {
581 |                     render();
582 |                     isWriting = false;
583 |                     resolve();
584 |                   });
585 |                 } else {
586 |                   const totalBytes = outputChunks.reduce(
587 |                     (sum, chunk) => sum + chunk.length,
588 |                     0,
589 |                   );
590 |                   onOutputEvent({
591 |                     type: 'binary_progress',
592 |                     bytesReceived: totalBytes,
593 |                   });
594 |                   resolve();
595 |                 }
596 |               }),
597 |           );
598 |         };
599 | 
600 |         ptyProcess.onData((data: string) => {
601 |           const bufferData = Buffer.from(data, 'utf-8');
602 |           handleOutput(bufferData);
603 |         });
604 | 
605 |         ptyProcess.onExit(
606 |           ({ exitCode, signal }: { exitCode: number; signal?: number }) => {
607 |             exited = true;
608 |             abortSignal.removeEventListener('abort', abortHandler);
609 |             this.activePtys.delete(ptyProcess.pid);
610 | 
611 |             const finalize = () => {
612 |               render(true);
613 |               const finalBuffer = Buffer.concat(outputChunks);
614 | 
615 |               resolve({
616 |                 rawOutput: finalBuffer,
617 |                 output: getFullBufferText(headlessTerminal),
618 |                 exitCode,
619 |                 signal: signal ?? null,
620 |                 error,
621 |                 aborted: abortSignal.aborted,
622 |                 pid: ptyProcess.pid,
623 |                 executionMethod:
624 |                   (ptyInfo?.name as 'node-pty' | 'lydell-node-pty') ??
625 |                   'node-pty',
626 |               });
627 |             };
628 | 
629 |             if (abortSignal.aborted) {
630 |               finalize();
631 |               return;
632 |             }
633 | 
634 |             const processingComplete = processingChain.then(() => 'processed');
635 |             const abortFired = new Promise<'aborted'>((res) => {
636 |               if (abortSignal.aborted) {
637 |                 res('aborted');
638 |                 return;
639 |               }
640 |               abortSignal.addEventListener('abort', () => res('aborted'), {
641 |                 once: true,
642 |               });
643 |             });
644 | 
645 |             Promise.race([processingComplete, abortFired]).then(() => {
646 |               finalize();
647 |             });
648 |           },
649 |         );
650 | 
651 |         const abortHandler = async () => {
652 |           if (ptyProcess.pid && !exited) {
653 |             if (os.platform() === 'win32') {
654 |               ptyProcess.kill();
655 |             } else {
656 |               try {
657 |                 // Kill the entire process group
658 |                 process.kill(-ptyProcess.pid, 'SIGTERM');
659 |                 await new Promise((res) => setTimeout(res, SIGKILL_TIMEOUT_MS));
660 |                 if (!exited) {
661 |                   process.kill(-ptyProcess.pid, 'SIGKILL');
[TRUNCATED]
```

src/telemetry/activity-detector.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
8 | import {
9 |   ActivityDetector,
10 |   getActivityDetector,
11 |   recordUserActivity,
12 |   isUserActive,
13 | } from './activity-detector.js';
14 | 
15 | describe('ActivityDetector', () => {
16 |   let detector: ActivityDetector;
17 | 
18 |   beforeEach(() => {
19 |     detector = new ActivityDetector(1000); // 1 second idle threshold for testing
20 |   });
21 | 
22 |   describe('constructor', () => {
23 |     it('should initialize with default idle threshold', () => {
24 |       const defaultDetector = new ActivityDetector();
25 |       expect(defaultDetector).toBeInstanceOf(ActivityDetector);
26 |     });
27 | 
28 |     it('should initialize with custom idle threshold', () => {
29 |       const customDetector = new ActivityDetector(5000);
30 |       expect(customDetector).toBeInstanceOf(ActivityDetector);
31 |     });
32 |   });
33 | 
34 |   describe('recordActivity', () => {
35 |     beforeEach(() => {
36 |       vi.useFakeTimers();
37 |     });
38 |     afterEach(() => {
39 |       vi.useRealTimers();
40 |     });
41 |     it('should update last activity time', () => {
42 |       const beforeTime = detector.getLastActivityTime();
43 |       vi.advanceTimersByTime(100);
44 | 
45 |       detector.recordActivity();
46 |       const afterTime = detector.getLastActivityTime();
47 | 
48 |       expect(afterTime).toBeGreaterThan(beforeTime);
49 |     });
50 |   });
51 | 
52 |   describe('isUserActive', () => {
53 |     beforeEach(() => {
54 |       vi.useFakeTimers();
55 |     });
56 |     afterEach(() => {
57 |       vi.useRealTimers();
58 |     });
59 |     it('should return true immediately after construction', () => {
60 |       expect(detector.isUserActive()).toBe(true);
61 |     });
62 | 
63 |     it('should return true within idle threshold', () => {
64 |       detector.recordActivity();
65 |       expect(detector.isUserActive()).toBe(true);
66 |     });
67 | 
68 |     it('should return false after idle threshold', () => {
69 |       // Advance time beyond idle threshold
70 |       vi.advanceTimersByTime(2000); // 2 seconds, threshold is 1 second
71 | 
72 |       expect(detector.isUserActive()).toBe(false);
73 |     });
74 | 
75 |     it('should return true again after recording new activity', () => {
76 |       // Go idle
77 |       vi.advanceTimersByTime(2000);
78 |       expect(detector.isUserActive()).toBe(false);
79 | 
80 |       // Record new activity
81 |       detector.recordActivity();
82 |       expect(detector.isUserActive()).toBe(true);
83 |     });
84 |   });
85 | 
86 |   describe('getTimeSinceLastActivity', () => {
87 |     beforeEach(() => {
88 |       vi.useFakeTimers();
89 |     });
90 |     afterEach(() => {
91 |       vi.useRealTimers();
92 |     });
93 |     it('should return time elapsed since last activity', () => {
94 |       detector.recordActivity();
95 |       vi.advanceTimersByTime(500);
96 | 
97 |       const timeSince = detector.getTimeSinceLastActivity();
98 |       expect(timeSince).toBe(500);
99 |     });
100 |   });
101 | 
102 |   describe('getLastActivityTime', () => {
103 |     it('should return the timestamp of last activity', () => {
104 |       const before = Date.now();
105 |       detector.recordActivity();
106 |       const activityTime = detector.getLastActivityTime();
107 |       const after = Date.now();
108 | 
109 |       expect(activityTime).toBeGreaterThanOrEqual(before);
110 |       expect(activityTime).toBeLessThanOrEqual(after);
111 |     });
112 |   });
113 | });
114 | 
115 | describe('Global Activity Detector Functions', () => {
116 |   describe('global instance', () => {
117 |     it('should expose a global ActivityDetector via getActivityDetector', () => {
118 |       const detector = getActivityDetector();
119 |       expect(detector).toBeInstanceOf(ActivityDetector);
120 |     });
121 |   });
122 | 
123 |   describe('getActivityDetector', () => {
124 |     it('should always return the global instance', () => {
125 |       const detector = getActivityDetector();
126 |       const detectorAgain = getActivityDetector();
127 |       expect(detectorAgain).toBe(detector);
128 |     });
129 |   });
130 | 
131 |   describe('recordUserActivity', () => {
132 |     beforeEach(() => {
133 |       vi.useFakeTimers();
134 |     });
135 |     afterEach(() => {
136 |       vi.useRealTimers();
137 |     });
138 |     it('should record activity on existing detector', () => {
139 |       const detector = getActivityDetector()!;
140 |       const beforeTime = detector.getLastActivityTime();
141 |       vi.advanceTimersByTime(100);
142 | 
143 |       recordUserActivity();
144 | 
145 |       const afterTime = detector.getLastActivityTime();
146 |       expect(afterTime).toBeGreaterThan(beforeTime);
147 |     });
148 |   });
149 | 
150 |   describe('isUserActive', () => {
151 |     beforeEach(() => {
152 |       vi.useFakeTimers();
153 |     });
154 |     afterEach(() => {
155 |       vi.useRealTimers();
156 |     });
157 |     it('should reflect global detector state', () => {
158 |       expect(isUserActive()).toBe(true);
159 |       // Default idle threshold is 30s; advance beyond it
160 |       vi.advanceTimersByTime(31000);
161 |       expect(isUserActive()).toBe(false);
162 |     });
163 |   });
164 | });
```

src/telemetry/activity-detector.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Tracks user activity state to determine when memory monitoring should be active
9 |  */
10 | export class ActivityDetector {
11 |   private lastActivityTime: number = Date.now();
12 |   private readonly idleThresholdMs: number;
13 | 
14 |   constructor(idleThresholdMs: number = 30000) {
15 |     this.idleThresholdMs = idleThresholdMs;
16 |   }
17 | 
18 |   /**
19 |    * Record user activity (called by CLI when user types, adds messages, etc.)
20 |    */
21 |   recordActivity(): void {
22 |     this.lastActivityTime = Date.now();
23 |   }
24 | 
25 |   /**
26 |    * Check if user is currently active (activity within idle threshold)
27 |    */
28 |   isUserActive(): boolean {
29 |     const timeSinceActivity = Date.now() - this.lastActivityTime;
30 |     return timeSinceActivity < this.idleThresholdMs;
31 |   }
32 | 
33 |   /**
34 |    * Get time since last activity in milliseconds
35 |    */
36 |   getTimeSinceLastActivity(): number {
37 |     return Date.now() - this.lastActivityTime;
38 |   }
39 | 
40 |   /**
41 |    * Get last activity timestamp
42 |    */
43 |   getLastActivityTime(): number {
44 |     return this.lastActivityTime;
45 |   }
46 | }
47 | 
48 | // Global activity detector instance (eagerly created with default threshold)
49 | const globalActivityDetector: ActivityDetector = new ActivityDetector();
50 | 
51 | /**
52 |  * Get global activity detector instance
53 |  */
54 | export function getActivityDetector(): ActivityDetector {
55 |   return globalActivityDetector;
56 | }
57 | 
58 | /**
59 |  * Record user activity (convenience function for CLI to call)
60 |  */
61 | export function recordUserActivity(): void {
62 |   globalActivityDetector.recordActivity();
63 | }
64 | 
65 | /**
66 |  * Check if user is currently active (convenience function)
67 |  */
68 | export function isUserActive(): boolean {
69 |   return globalActivityDetector.isUserActive();
70 | }
```

src/telemetry/activity-types.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Types of user activities that can be tracked
9 |  */
10 | export enum ActivityType {
11 |   USER_INPUT_START = 'user_input_start',
12 |   USER_INPUT_END = 'user_input_end',
13 |   MESSAGE_ADDED = 'message_added',
14 |   TOOL_CALL_SCHEDULED = 'tool_call_scheduled',
15 |   TOOL_CALL_COMPLETED = 'tool_call_completed',
16 |   STREAM_START = 'stream_start',
17 |   STREAM_END = 'stream_end',
18 |   HISTORY_UPDATED = 'history_updated',
19 |   MANUAL_TRIGGER = 'manual_trigger',
20 | }
```

src/telemetry/config.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import {
9 |   parseBooleanEnvFlag,
10 |   parseTelemetryTargetValue,
11 |   resolveTelemetrySettings,
12 | } from './config.js';
13 | import { TelemetryTarget } from './index.js';
14 | 
15 | describe('telemetry/config helpers', () => {
16 |   describe('parseBooleanEnvFlag', () => {
17 |     it('returns undefined for undefined', () => {
18 |       expect(parseBooleanEnvFlag(undefined)).toBeUndefined();
19 |     });
20 | 
21 |     it('parses true values', () => {
22 |       expect(parseBooleanEnvFlag('true')).toBe(true);
23 |       expect(parseBooleanEnvFlag('1')).toBe(true);
24 |     });
25 | 
26 |     it('parses false/other values as false', () => {
27 |       expect(parseBooleanEnvFlag('false')).toBe(false);
28 |       expect(parseBooleanEnvFlag('0')).toBe(false);
29 |       expect(parseBooleanEnvFlag('TRUE')).toBe(false);
30 |       expect(parseBooleanEnvFlag('random')).toBe(false);
31 |       expect(parseBooleanEnvFlag('')).toBe(false);
32 |     });
33 |   });
34 | 
35 |   describe('parseTelemetryTargetValue', () => {
36 |     it('parses string values', () => {
37 |       expect(parseTelemetryTargetValue('local')).toBe(TelemetryTarget.LOCAL);
38 |       expect(parseTelemetryTargetValue('gcp')).toBe(TelemetryTarget.GCP);
39 |     });
40 | 
41 |     it('accepts enum values', () => {
42 |       expect(parseTelemetryTargetValue(TelemetryTarget.LOCAL)).toBe(
43 |         TelemetryTarget.LOCAL,
44 |       );
45 |       expect(parseTelemetryTargetValue(TelemetryTarget.GCP)).toBe(
46 |         TelemetryTarget.GCP,
47 |       );
48 |     });
49 | 
50 |     it('returns undefined for unknown', () => {
51 |       expect(parseTelemetryTargetValue('other')).toBeUndefined();
52 |       expect(parseTelemetryTargetValue(undefined)).toBeUndefined();
53 |     });
54 |   });
55 | 
56 |   describe('resolveTelemetrySettings', () => {
57 |     it('falls back to settings when no argv/env provided', async () => {
58 |       const settings = {
59 |         enabled: false,
60 |         target: TelemetryTarget.LOCAL,
61 |         otlpEndpoint: 'http://localhost:4317',
62 |         otlpProtocol: 'grpc' as const,
63 |         logPrompts: false,
64 |         outfile: 'settings.log',
65 |         useCollector: false,
66 |       };
67 |       const resolved = await resolveTelemetrySettings({ settings });
68 |       expect(resolved).toEqual(settings);
69 |     });
70 | 
71 |     it('uses env over settings and argv over env', async () => {
72 |       const settings = {
73 |         enabled: false,
74 |         target: TelemetryTarget.LOCAL,
75 |         otlpEndpoint: 'http://settings:4317',
76 |         otlpProtocol: 'grpc' as const,
77 |         logPrompts: false,
78 |         outfile: 'settings.log',
79 |         useCollector: false,
80 |       };
81 |       const env = {
82 |         GEMINI_TELEMETRY_ENABLED: '1',
83 |         GEMINI_TELEMETRY_TARGET: 'gcp',
84 |         GEMINI_TELEMETRY_OTLP_ENDPOINT: 'http://env:4317',
85 |         GEMINI_TELEMETRY_OTLP_PROTOCOL: 'http',
86 |         GEMINI_TELEMETRY_LOG_PROMPTS: 'true',
87 |         GEMINI_TELEMETRY_OUTFILE: 'env.log',
88 |         GEMINI_TELEMETRY_USE_COLLECTOR: 'true',
89 |       } as Record<string, string>;
90 |       const argv = {
91 |         telemetry: false,
92 |         telemetryTarget: 'local',
93 |         telemetryOtlpEndpoint: 'http://argv:4317',
94 |         telemetryOtlpProtocol: 'grpc',
95 |         telemetryLogPrompts: false,
96 |         telemetryOutfile: 'argv.log',
97 |       };
98 | 
99 |       const resolvedEnv = await resolveTelemetrySettings({ env, settings });
100 |       expect(resolvedEnv).toEqual({
101 |         enabled: true,
102 |         target: TelemetryTarget.GCP,
103 |         otlpEndpoint: 'http://env:4317',
104 |         otlpProtocol: 'http',
105 |         logPrompts: true,
106 |         outfile: 'env.log',
107 |         useCollector: true,
108 |       });
109 | 
110 |       const resolvedArgv = await resolveTelemetrySettings({
111 |         argv,
112 |         env,
113 |         settings,
114 |       });
115 |       expect(resolvedArgv).toEqual({
116 |         enabled: false,
117 |         target: TelemetryTarget.LOCAL,
118 |         otlpEndpoint: 'http://argv:4317',
119 |         otlpProtocol: 'grpc',
120 |         logPrompts: false,
121 |         outfile: 'argv.log',
122 |         useCollector: true, // from env as no argv option
123 |       });
124 |     });
125 | 
126 |     it('falls back to OTEL_EXPORTER_OTLP_ENDPOINT when GEMINI var is missing', async () => {
127 |       const settings = {};
128 |       const env = {
129 |         OTEL_EXPORTER_OTLP_ENDPOINT: 'http://otel:4317',
130 |       } as Record<string, string>;
131 |       const resolved = await resolveTelemetrySettings({ env, settings });
132 |       expect(resolved.otlpEndpoint).toBe('http://otel:4317');
133 |     });
134 | 
135 |     it('throws on unknown protocol values', async () => {
136 |       const env = { GEMINI_TELEMETRY_OTLP_PROTOCOL: 'unknown' } as Record<
137 |         string,
138 |         string
139 |       >;
140 |       await expect(resolveTelemetrySettings({ env })).rejects.toThrow(
141 |         /Invalid telemetry OTLP protocol/i,
142 |       );
143 |     });
144 | 
145 |     it('throws on unknown target values', async () => {
146 |       const env = { GEMINI_TELEMETRY_TARGET: 'unknown' } as Record<
147 |         string,
148 |         string
149 |       >;
150 |       await expect(resolveTelemetrySettings({ env })).rejects.toThrow(
151 |         /Invalid telemetry target/i,
152 |       );
153 |     });
154 |   });
155 | });
```

src/telemetry/config.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { TelemetrySettings } from '../config/config.js';
8 | import { FatalConfigError } from '../utils/errors.js';
9 | import { TelemetryTarget } from './index.js';
10 | 
11 | /**
12 |  * Parse a boolean environment flag. Accepts 'true'/'1' as true.
13 |  */
14 | export function parseBooleanEnvFlag(
15 |   value: string | undefined,
16 | ): boolean | undefined {
17 |   if (value === undefined) return undefined;
18 |   return value === 'true' || value === '1';
19 | }
20 | 
21 | /**
22 |  * Normalize a telemetry target value into TelemetryTarget or undefined.
23 |  */
24 | export function parseTelemetryTargetValue(
25 |   value: string | TelemetryTarget | undefined,
26 | ): TelemetryTarget | undefined {
27 |   if (value === undefined) return undefined;
28 |   if (value === TelemetryTarget.LOCAL || value === 'local') {
29 |     return TelemetryTarget.LOCAL;
30 |   }
31 |   if (value === TelemetryTarget.GCP || value === 'gcp') {
32 |     return TelemetryTarget.GCP;
33 |   }
34 |   return undefined;
35 | }
36 | 
37 | export interface TelemetryArgOverrides {
38 |   telemetry?: boolean;
39 |   telemetryTarget?: string | TelemetryTarget;
40 |   telemetryOtlpEndpoint?: string;
41 |   telemetryOtlpProtocol?: string;
42 |   telemetryLogPrompts?: boolean;
43 |   telemetryOutfile?: string;
44 | }
45 | 
46 | /**
47 |  * Build TelemetrySettings by resolving from argv (highest), env, then settings.
48 |  */
49 | export async function resolveTelemetrySettings(options: {
50 |   argv?: TelemetryArgOverrides;
51 |   env?: Record<string, string | undefined>;
52 |   settings?: TelemetrySettings;
53 | }): Promise<TelemetrySettings> {
54 |   const argv = options.argv ?? {};
55 |   const env = options.env ?? {};
56 |   const settings = options.settings ?? {};
57 | 
58 |   const enabled =
59 |     argv.telemetry ??
60 |     parseBooleanEnvFlag(env['GEMINI_TELEMETRY_ENABLED']) ??
61 |     settings.enabled;
62 | 
63 |   const rawTarget =
64 |     (argv.telemetryTarget as string | TelemetryTarget | undefined) ??
65 |     env['GEMINI_TELEMETRY_TARGET'] ??
66 |     (settings.target as string | TelemetryTarget | undefined);
67 |   const target = parseTelemetryTargetValue(rawTarget);
68 |   if (rawTarget !== undefined && target === undefined) {
69 |     throw new FatalConfigError(
70 |       `Invalid telemetry target: ${String(
71 |         rawTarget,
72 |       )}. Valid values are: local, gcp`,
73 |     );
74 |   }
75 | 
76 |   const otlpEndpoint =
77 |     argv.telemetryOtlpEndpoint ??
78 |     env['GEMINI_TELEMETRY_OTLP_ENDPOINT'] ??
79 |     env['OTEL_EXPORTER_OTLP_ENDPOINT'] ??
80 |     settings.otlpEndpoint;
81 | 
82 |   const rawProtocol =
83 |     (argv.telemetryOtlpProtocol as string | undefined) ??
84 |     env['GEMINI_TELEMETRY_OTLP_PROTOCOL'] ??
85 |     settings.otlpProtocol;
86 |   const otlpProtocol = (['grpc', 'http'] as const).find(
87 |     (p) => p === rawProtocol,
88 |   );
89 |   if (rawProtocol !== undefined && otlpProtocol === undefined) {
90 |     throw new FatalConfigError(
91 |       `Invalid telemetry OTLP protocol: ${String(
92 |         rawProtocol,
93 |       )}. Valid values are: grpc, http`,
94 |     );
95 |   }
96 | 
97 |   const logPrompts =
98 |     argv.telemetryLogPrompts ??
99 |     parseBooleanEnvFlag(env['GEMINI_TELEMETRY_LOG_PROMPTS']) ??
100 |     settings.logPrompts;
101 | 
102 |   const outfile =
103 |     argv.telemetryOutfile ??
104 |     env['GEMINI_TELEMETRY_OUTFILE'] ??
105 |     settings.outfile;
106 | 
107 |   const useCollector =
108 |     parseBooleanEnvFlag(env['GEMINI_TELEMETRY_USE_COLLECTOR']) ??
109 |     settings.useCollector;
110 | 
111 |   return {
112 |     enabled,
113 |     target,
114 |     otlpEndpoint,
115 |     otlpProtocol,
116 |     logPrompts,
117 |     outfile,
118 |     useCollector,
119 |   };
120 | }
```

src/telemetry/constants.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export const SERVICE_NAME = 'gemini-cli';
```

src/telemetry/file-exporters.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs';
8 | import type { ExportResult } from '@opentelemetry/core';
9 | import { ExportResultCode } from '@opentelemetry/core';
10 | import type { ReadableSpan, SpanExporter } from '@opentelemetry/sdk-trace-base';
11 | import type {
12 |   ReadableLogRecord,
13 |   LogRecordExporter,
14 | } from '@opentelemetry/sdk-logs';
15 | import type {
16 |   ResourceMetrics,
17 |   PushMetricExporter,
18 | } from '@opentelemetry/sdk-metrics';
19 | import { AggregationTemporality } from '@opentelemetry/sdk-metrics';
20 | 
21 | class FileExporter {
22 |   protected writeStream: fs.WriteStream;
23 | 
24 |   constructor(filePath: string) {
25 |     this.writeStream = fs.createWriteStream(filePath, { flags: 'a' });
26 |   }
27 | 
28 |   protected serialize(data: unknown): string {
29 |     return JSON.stringify(data, null, 2) + '\n';
30 |   }
31 | 
32 |   shutdown(): Promise<void> {
33 |     return new Promise((resolve) => {
34 |       this.writeStream.end(resolve);
35 |     });
36 |   }
37 | }
38 | 
39 | export class FileSpanExporter extends FileExporter implements SpanExporter {
40 |   export(
41 |     spans: ReadableSpan[],
42 |     resultCallback: (result: ExportResult) => void,
43 |   ): void {
44 |     const data = spans.map((span) => this.serialize(span)).join('');
45 |     this.writeStream.write(data, (err) => {
46 |       resultCallback({
47 |         code: err ? ExportResultCode.FAILED : ExportResultCode.SUCCESS,
48 |         error: err || undefined,
49 |       });
50 |     });
51 |   }
52 | }
53 | 
54 | export class FileLogExporter extends FileExporter implements LogRecordExporter {
55 |   export(
56 |     logs: ReadableLogRecord[],
57 |     resultCallback: (result: ExportResult) => void,
58 |   ): void {
59 |     const data = logs.map((log) => this.serialize(log)).join('');
60 |     this.writeStream.write(data, (err) => {
61 |       resultCallback({
62 |         code: err ? ExportResultCode.FAILED : ExportResultCode.SUCCESS,
63 |         error: err || undefined,
64 |       });
65 |     });
66 |   }
67 | }
68 | 
69 | export class FileMetricExporter
70 |   extends FileExporter
71 |   implements PushMetricExporter
72 | {
73 |   export(
74 |     metrics: ResourceMetrics,
75 |     resultCallback: (result: ExportResult) => void,
76 |   ): void {
77 |     const data = this.serialize(metrics);
78 |     this.writeStream.write(data, (err) => {
79 |       resultCallback({
80 |         code: err ? ExportResultCode.FAILED : ExportResultCode.SUCCESS,
81 |         error: err || undefined,
82 |       });
83 |     });
84 |   }
85 | 
86 |   getPreferredAggregationTemporality(): AggregationTemporality {
87 |     return AggregationTemporality.CUMULATIVE;
88 |   }
89 | 
90 |   async forceFlush(): Promise<void> {
91 |     return Promise.resolve();
92 |   }
93 | }
```

src/telemetry/gcp-exporters.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach } from 'vitest';
8 | import { ExportResultCode } from '@opentelemetry/core';
9 | import type { ReadableLogRecord } from '@opentelemetry/sdk-logs';
10 | import {
11 |   GcpTraceExporter,
12 |   GcpMetricExporter,
13 |   GcpLogExporter,
14 | } from './gcp-exporters.js';
15 | 
16 | const mockLogEntry = { test: 'entry' };
17 | const mockLogWrite = vi.fn().mockResolvedValue(undefined);
18 | const mockLog = {
19 |   entry: vi.fn().mockReturnValue(mockLogEntry),
20 |   write: mockLogWrite,
21 | };
22 | const mockLogging = {
23 |   projectId: 'test-project',
24 |   log: vi.fn().mockReturnValue(mockLog),
25 | };
26 | 
27 | vi.mock('@google-cloud/opentelemetry-cloud-trace-exporter', () => ({
28 |   TraceExporter: vi.fn().mockImplementation(() => ({
29 |     export: vi.fn(),
30 |     shutdown: vi.fn(),
31 |     forceFlush: vi.fn(),
32 |   })),
33 | }));
34 | 
35 | vi.mock('@google-cloud/opentelemetry-cloud-monitoring-exporter', () => ({
36 |   MetricExporter: vi.fn().mockImplementation(() => ({
37 |     export: vi.fn(),
38 |     shutdown: vi.fn(),
39 |     forceFlush: vi.fn(),
40 |   })),
41 | }));
42 | 
43 | vi.mock('@google-cloud/logging', () => ({
44 |   Logging: vi.fn().mockImplementation(() => mockLogging),
45 | }));
46 | 
47 | describe('GCP Exporters', () => {
48 |   describe('GcpTraceExporter', () => {
49 |     it('should create a trace exporter with correct configuration', () => {
50 |       const exporter = new GcpTraceExporter('test-project');
51 |       expect(exporter).toBeDefined();
52 |     });
53 | 
54 |     it('should create a trace exporter without project ID', () => {
55 |       const exporter = new GcpTraceExporter();
56 |       expect(exporter).toBeDefined();
57 |     });
58 |   });
59 | 
60 |   describe('GcpMetricExporter', () => {
61 |     it('should create a metric exporter with correct configuration', () => {
62 |       const exporter = new GcpMetricExporter('test-project');
63 |       expect(exporter).toBeDefined();
64 |     });
65 | 
66 |     it('should create a metric exporter without project ID', () => {
67 |       const exporter = new GcpMetricExporter();
68 |       expect(exporter).toBeDefined();
69 |     });
70 |   });
71 | 
72 |   describe('GcpLogExporter', () => {
73 |     let exporter: GcpLogExporter;
74 | 
75 |     beforeEach(() => {
76 |       vi.clearAllMocks();
77 |       mockLogWrite.mockResolvedValue(undefined);
78 |       mockLog.entry.mockReturnValue(mockLogEntry);
79 |       exporter = new GcpLogExporter('test-project');
80 |     });
81 | 
82 |     describe('constructor', () => {
83 |       it('should create a log exporter with project ID', () => {
84 |         expect(exporter).toBeDefined();
85 |         expect(mockLogging.log).toHaveBeenCalledWith('gemini_cli');
86 |       });
87 | 
88 |       it('should create a log exporter without project ID', () => {
89 |         const exporterNoProject = new GcpLogExporter();
90 |         expect(exporterNoProject).toBeDefined();
91 |       });
92 |     });
93 | 
94 |     describe('export', () => {
95 |       it('should export logs successfully', async () => {
96 |         const mockLogRecords: ReadableLogRecord[] = [
97 |           {
98 |             hrTime: [1234567890, 123456789],
99 |             hrTimeObserved: [1234567890, 123456789],
100 |             severityNumber: 9,
101 |             severityText: 'INFO',
102 |             body: 'Test log message',
103 |             attributes: {
104 |               'session.id': 'test-session',
105 |               'custom.attribute': 'value',
106 |             },
107 |             resource: {
108 |               attributes: {
109 |                 'service.name': 'test-service',
110 |               },
111 |             },
112 |           } as unknown as ReadableLogRecord,
113 |         ];
114 | 
115 |         const callback = vi.fn();
116 | 
117 |         exporter.export(mockLogRecords, callback);
118 | 
119 |         await new Promise((resolve) => setTimeout(resolve, 0));
120 | 
121 |         expect(mockLog.entry).toHaveBeenCalledWith(
122 |           expect.objectContaining({
123 |             severity: 'INFO',
124 |             timestamp: expect.any(Date),
125 |             resource: {
126 |               type: 'global',
127 |               labels: {
128 |                 project_id: 'test-project',
129 |               },
130 |             },
131 |           }),
132 |           expect.objectContaining({
133 |             message: 'Test log message',
134 |             session_id: 'test-session',
135 |             'custom.attribute': 'value',
136 |             'service.name': 'test-service',
137 |           }),
138 |         );
139 | 
140 |         expect(mockLog.write).toHaveBeenCalledWith([mockLogEntry]);
141 |         expect(callback).toHaveBeenCalledWith({
142 |           code: ExportResultCode.SUCCESS,
143 |         });
144 |       });
145 | 
146 |       it('should handle export failures', async () => {
147 |         const mockLogRecords: ReadableLogRecord[] = [
148 |           {
149 |             hrTime: [1234567890, 123456789],
150 |             hrTimeObserved: [1234567890, 123456789],
151 |             body: 'Test log message',
152 |           } as unknown as ReadableLogRecord,
153 |         ];
154 | 
155 |         const error = new Error('Write failed');
156 |         mockLogWrite.mockRejectedValueOnce(error);
157 | 
158 |         const callback = vi.fn();
159 | 
160 |         exporter.export(mockLogRecords, callback);
161 | 
162 |         await new Promise((resolve) => setTimeout(resolve, 0));
163 | 
164 |         expect(callback).toHaveBeenCalledWith({
165 |           code: ExportResultCode.FAILED,
166 |           error,
167 |         });
168 |       });
169 | 
170 |       it('should handle synchronous errors', () => {
171 |         const mockLogRecords: ReadableLogRecord[] = [
172 |           {
173 |             hrTime: [1234567890, 123456789],
174 |             hrTimeObserved: [1234567890, 123456789],
175 |             body: 'Test log message',
176 |           } as unknown as ReadableLogRecord,
177 |         ];
178 | 
179 |         mockLog.entry.mockImplementation(() => {
180 |           throw new Error('Entry creation failed');
181 |         });
182 | 
183 |         const callback = vi.fn();
184 | 
185 |         exporter.export(mockLogRecords, callback);
186 | 
187 |         expect(callback).toHaveBeenCalledWith({
188 |           code: ExportResultCode.FAILED,
189 |           error: expect.any(Error),
190 |         });
191 |       });
192 |     });
193 | 
194 |     describe('severity mapping', () => {
195 |       it('should map OpenTelemetry severity numbers to Cloud Logging levels', () => {
196 |         const testCases = [
197 |           { severityNumber: undefined, expected: 'DEFAULT' },
198 |           { severityNumber: 1, expected: 'DEFAULT' },
199 |           { severityNumber: 5, expected: 'DEBUG' },
200 |           { severityNumber: 9, expected: 'INFO' },
201 |           { severityNumber: 13, expected: 'WARNING' },
202 |           { severityNumber: 17, expected: 'ERROR' },
203 |           { severityNumber: 21, expected: 'CRITICAL' },
204 |           { severityNumber: 25, expected: 'CRITICAL' },
205 |         ];
206 | 
207 |         testCases.forEach(({ severityNumber, expected }) => {
208 |           const mockLogRecords: ReadableLogRecord[] = [
209 |             {
210 |               hrTime: [1234567890, 123456789],
211 |               hrTimeObserved: [1234567890, 123456789],
212 |               severityNumber,
213 |               body: 'Test message',
214 |             } as unknown as ReadableLogRecord,
215 |           ];
216 | 
217 |           const callback = vi.fn();
218 |           exporter.export(mockLogRecords, callback);
219 | 
220 |           expect(mockLog.entry).toHaveBeenCalledWith(
221 |             expect.objectContaining({
222 |               severity: expected,
223 |             }),
224 |             expect.any(Object),
225 |           );
226 | 
227 |           mockLog.entry.mockClear();
228 |         });
229 |       });
230 |     });
231 | 
232 |     describe('forceFlush', () => {
233 |       it('should resolve immediately when no pending writes exist', async () => {
234 |         await expect(exporter.forceFlush()).resolves.toBeUndefined();
235 |       });
236 | 
237 |       it('should wait for pending writes to complete', async () => {
238 |         const mockLogRecords: ReadableLogRecord[] = [
239 |           {
240 |             hrTime: [1234567890, 123456789],
241 |             hrTimeObserved: [1234567890, 123456789],
242 |             body: 'Test log message',
243 |           } as unknown as ReadableLogRecord,
244 |         ];
245 | 
246 |         let resolveWrite: () => void;
247 |         const writePromise = new Promise<void>((resolve) => {
248 |           resolveWrite = resolve;
249 |         });
250 |         mockLogWrite.mockReturnValueOnce(writePromise);
251 | 
252 |         const callback = vi.fn();
253 | 
254 |         exporter.export(mockLogRecords, callback);
255 |         const flushPromise = exporter.forceFlush();
256 | 
257 |         await new Promise((resolve) => setTimeout(resolve, 1));
258 | 
259 |         resolveWrite!();
260 |         await writePromise;
261 | 
262 |         await expect(flushPromise).resolves.toBeUndefined();
263 |       });
264 | 
265 |       it('should handle multiple pending writes', async () => {
266 |         const mockLogRecords1: ReadableLogRecord[] = [
267 |           {
268 |             hrTime: [1234567890, 123456789],
269 |             hrTimeObserved: [1234567890, 123456789],
270 |             body: 'Test log message 1',
271 |           } as unknown as ReadableLogRecord,
272 |         ];
273 | 
274 |         const mockLogRecords2: ReadableLogRecord[] = [
275 |           {
276 |             hrTime: [1234567890, 123456789],
277 |             hrTimeObserved: [1234567890, 123456789],
278 |             body: 'Test log message 2',
279 |           } as unknown as ReadableLogRecord,
280 |         ];
281 | 
282 |         let resolveWrite1: () => void;
283 |         let resolveWrite2: () => void;
284 |         const writePromise1 = new Promise<void>((resolve) => {
285 |           resolveWrite1 = resolve;
286 |         });
287 |         const writePromise2 = new Promise<void>((resolve) => {
288 |           resolveWrite2 = resolve;
289 |         });
290 | 
291 |         mockLogWrite
292 |           .mockReturnValueOnce(writePromise1)
293 |           .mockReturnValueOnce(writePromise2);
294 | 
295 |         const callback = vi.fn();
296 | 
297 |         exporter.export(mockLogRecords1, callback);
298 |         exporter.export(mockLogRecords2, callback);
299 | 
300 |         const flushPromise = exporter.forceFlush();
301 | 
302 |         resolveWrite1!();
303 |         await writePromise1;
304 | 
305 |         resolveWrite2!();
306 |         await writePromise2;
307 | 
308 |         await expect(flushPromise).resolves.toBeUndefined();
309 |       });
310 | 
311 |       it('should handle write failures gracefully', async () => {
312 |         const mockLogRecords: ReadableLogRecord[] = [
313 |           {
314 |             hrTime: [1234567890, 123456789],
315 |             hrTimeObserved: [1234567890, 123456789],
316 |             body: 'Test log message',
317 |           } as unknown as ReadableLogRecord,
318 |         ];
319 | 
320 |         const error = new Error('Write failed');
321 |         mockLogWrite.mockRejectedValueOnce(error);
322 | 
323 |         const callback = vi.fn();
324 | 
325 |         exporter.export(mockLogRecords, callback);
326 | 
327 |         await expect(exporter.forceFlush()).resolves.toBeUndefined();
328 | 
329 |         await new Promise((resolve) => setTimeout(resolve, 10));
330 |         expect(callback).toHaveBeenCalledWith({
331 |           code: ExportResultCode.FAILED,
332 |           error,
333 |         });
334 |       });
335 |     });
336 | 
337 |     describe('shutdown', () => {
338 |       it('should call forceFlush', async () => {
339 |         const forceFlushSpy = vi.spyOn(exporter, 'forceFlush');
340 | 
341 |         await exporter.shutdown();
342 | 
343 |         expect(forceFlushSpy).toHaveBeenCalled();
344 |       });
345 | 
346 |       it('should handle shutdown gracefully', async () => {
347 |         const forceFlushSpy = vi.spyOn(exporter, 'forceFlush');
348 | 
349 |         await expect(exporter.shutdown()).resolves.toBeUndefined();
350 |         expect(forceFlushSpy).toHaveBeenCalled();
351 |       });
352 |       it('should wait for pending writes before shutting down', async () => {
353 |         const mockLogRecords: ReadableLogRecord[] = [
354 |           {
355 |             hrTime: [1234567890, 123456789],
356 |             hrTimeObserved: [1234567890, 123456789],
357 |             body: 'Test log message',
358 |           } as unknown as ReadableLogRecord,
359 |         ];
360 | 
361 |         let resolveWrite: () => void;
362 |         const writePromise = new Promise<void>((resolve) => {
363 |           resolveWrite = resolve;
364 |         });
365 |         mockLogWrite.mockReturnValueOnce(writePromise);
366 | 
367 |         const callback = vi.fn();
368 | 
369 |         exporter.export(mockLogRecords, callback);
370 |         const shutdownPromise = exporter.shutdown();
371 | 
372 |         await new Promise((resolve) => setTimeout(resolve, 1));
373 | 
374 |         resolveWrite!();
375 |         await writePromise;
376 | 
377 |         await expect(shutdownPromise).resolves.toBeUndefined();
378 |       });
379 | 
380 |       it('should clear pending writes array after shutdown', async () => {
381 |         const mockLogRecords: ReadableLogRecord[] = [
382 |           {
383 |             hrTime: [1234567890, 123456789],
384 |             hrTimeObserved: [1234567890, 123456789],
385 |             body: 'Test log message',
386 |           } as unknown as ReadableLogRecord,
387 |         ];
388 | 
389 |         const callback = vi.fn();
390 | 
391 |         exporter.export(mockLogRecords, callback);
392 | 
393 |         await new Promise((resolve) => setTimeout(resolve, 10));
394 | 
395 |         await exporter.shutdown();
396 | 
397 |         const start = Date.now();
398 |         await exporter.forceFlush();
399 |         const elapsed = Date.now() - start;
400 | 
401 |         expect(elapsed).toBeLessThan(50);
402 |       });
403 |     });
404 |   });
405 | });
```

src/telemetry/gcp-exporters.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { TraceExporter } from '@google-cloud/opentelemetry-cloud-trace-exporter';
8 | import { MetricExporter } from '@google-cloud/opentelemetry-cloud-monitoring-exporter';
9 | import { Logging } from '@google-cloud/logging';
10 | import type { Log } from '@google-cloud/logging';
11 | import { hrTimeToMilliseconds } from '@opentelemetry/core';
12 | import type { ExportResult } from '@opentelemetry/core';
13 | import { ExportResultCode } from '@opentelemetry/core';
14 | import type {
15 |   ReadableLogRecord,
16 |   LogRecordExporter,
17 | } from '@opentelemetry/sdk-logs';
18 | 
19 | /**
20 |  * Google Cloud Trace exporter that extends the official trace exporter
21 |  */
22 | export class GcpTraceExporter extends TraceExporter {
23 |   constructor(projectId?: string) {
24 |     super({
25 |       projectId,
26 |       resourceFilter: /^gcp\./,
27 |     });
28 |   }
29 | }
30 | 
31 | /**
32 |  * Google Cloud Monitoring exporter that extends the official metrics exporter
33 |  */
34 | export class GcpMetricExporter extends MetricExporter {
35 |   constructor(projectId?: string) {
36 |     super({
37 |       projectId,
38 |       prefix: 'custom.googleapis.com/gemini_cli',
39 |     });
40 |   }
41 | }
42 | 
43 | /**
44 |  * Google Cloud Logging exporter that uses the Cloud Logging client
45 |  */
46 | export class GcpLogExporter implements LogRecordExporter {
47 |   private logging: Logging;
48 |   private log: Log;
49 |   private pendingWrites: Array<Promise<void>> = [];
50 | 
51 |   constructor(projectId?: string) {
52 |     this.logging = new Logging({ projectId });
53 |     this.log = this.logging.log('gemini_cli');
54 |   }
55 | 
56 |   export(
57 |     logs: ReadableLogRecord[],
58 |     resultCallback: (result: ExportResult) => void,
59 |   ): void {
60 |     try {
61 |       const entries = logs.map((log) => {
62 |         const entry = this.log.entry(
63 |           {
64 |             severity: this.mapSeverityToCloudLogging(log.severityNumber),
65 |             timestamp: new Date(hrTimeToMilliseconds(log.hrTime)),
66 |             resource: {
67 |               type: 'global',
68 |               labels: {
69 |                 project_id: this.logging.projectId,
70 |               },
71 |             },
72 |           },
73 |           {
74 |             session_id: log.attributes?.['session.id'],
75 |             ...log.attributes,
76 |             ...log.resource?.attributes,
77 |             message: log.body,
78 |           },
79 |         );
80 |         return entry;
81 |       });
82 | 
83 |       const writePromise = this.log
84 |         .write(entries)
85 |         .then(() => {
86 |           resultCallback({ code: ExportResultCode.SUCCESS });
87 |         })
88 |         .catch((error: Error) => {
89 |           resultCallback({
90 |             code: ExportResultCode.FAILED,
91 |             error,
92 |           });
93 |         })
94 |         .finally(() => {
95 |           const index = this.pendingWrites.indexOf(writePromise);
96 |           if (index > -1) {
97 |             this.pendingWrites.splice(index, 1);
98 |           }
99 |         });
100 |       this.pendingWrites.push(writePromise);
101 |     } catch (error) {
102 |       resultCallback({
103 |         code: ExportResultCode.FAILED,
104 |         error: error as Error,
105 |       });
106 |     }
107 |   }
108 | 
109 |   async forceFlush(): Promise<void> {
110 |     if (this.pendingWrites.length > 0) {
111 |       await Promise.all(this.pendingWrites);
112 |     }
113 |   }
114 | 
115 |   async shutdown(): Promise<void> {
116 |     await this.forceFlush();
117 |     this.pendingWrites = [];
118 |   }
119 | 
120 |   private mapSeverityToCloudLogging(severityNumber?: number): string {
121 |     if (!severityNumber) return 'DEFAULT';
122 | 
123 |     // Map OpenTelemetry severity numbers to Cloud Logging severity levels
124 |     // https://opentelemetry.io/docs/specs/otel/logs/data-model/#field-severitynumber
125 |     if (severityNumber >= 21) return 'CRITICAL';
126 |     if (severityNumber >= 17) return 'ERROR';
127 |     if (severityNumber >= 13) return 'WARNING';
128 |     if (severityNumber >= 9) return 'INFO';
129 |     if (severityNumber >= 5) return 'DEBUG';
130 |     return 'DEFAULT';
131 |   }
132 | }
```

src/telemetry/high-water-mark-tracker.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, vi } from 'vitest';
8 | import { HighWaterMarkTracker } from './high-water-mark-tracker.js';
9 | 
10 | describe('HighWaterMarkTracker', () => {
11 |   let tracker: HighWaterMarkTracker;
12 | 
13 |   beforeEach(() => {
14 |     tracker = new HighWaterMarkTracker(5); // 5% threshold
15 |   });
16 | 
17 |   describe('constructor', () => {
18 |     it('should initialize with default values', () => {
19 |       const defaultTracker = new HighWaterMarkTracker();
20 |       expect(defaultTracker).toBeInstanceOf(HighWaterMarkTracker);
21 |     });
22 | 
23 |     it('should initialize with custom values', () => {
24 |       const customTracker = new HighWaterMarkTracker(10);
25 |       expect(customTracker).toBeInstanceOf(HighWaterMarkTracker);
26 |     });
27 | 
28 |     it('should throw on negative threshold', () => {
29 |       expect(() => new HighWaterMarkTracker(-1)).toThrow(
30 |         'growthThresholdPercent must be non-negative.',
31 |       );
32 |     });
33 |   });
34 | 
35 |   describe('shouldRecordMetric', () => {
36 |     it('should return true for first measurement', () => {
37 |       const result = tracker.shouldRecordMetric('heap_used', 1000000);
38 |       expect(result).toBe(true);
39 |     });
40 | 
41 |     it('should return false for small increases', () => {
42 |       // Set initial high-water mark
43 |       tracker.shouldRecordMetric('heap_used', 1000000);
44 | 
45 |       // Small increase (less than 5%)
46 |       const result = tracker.shouldRecordMetric('heap_used', 1030000); // 3% increase
47 |       expect(result).toBe(false);
48 |     });
49 | 
50 |     it('should return true for significant increases', () => {
51 |       // Set initial high-water mark
52 |       tracker.shouldRecordMetric('heap_used', 1000000);
53 | 
54 |       // Add several readings to build up smoothing window
55 |       tracker.shouldRecordMetric('heap_used', 1100000); // 10% increase
56 |       tracker.shouldRecordMetric('heap_used', 1150000); // Additional growth
57 |       const result = tracker.shouldRecordMetric('heap_used', 1200000); // Sustained growth
58 |       expect(result).toBe(true);
59 |     });
60 | 
61 |     it('should handle decreasing values correctly', () => {
62 |       // Set initial high-water mark
63 |       tracker.shouldRecordMetric('heap_used', 1000000);
64 | 
65 |       // Decrease (should not trigger)
66 |       const result = tracker.shouldRecordMetric('heap_used', 900000); // 10% decrease
67 |       expect(result).toBe(false);
68 |     });
69 | 
70 |     it('should update high-water mark when threshold exceeded', () => {
71 |       tracker.shouldRecordMetric('heap_used', 1000000);
72 | 
73 |       const beforeMark = tracker.getHighWaterMark('heap_used');
74 | 
75 |       // Create sustained growth pattern to trigger update
76 |       tracker.shouldRecordMetric('heap_used', 1100000);
77 |       tracker.shouldRecordMetric('heap_used', 1150000);
78 |       tracker.shouldRecordMetric('heap_used', 1200000);
79 | 
80 |       const afterMark = tracker.getHighWaterMark('heap_used');
81 | 
82 |       expect(afterMark).toBeGreaterThan(beforeMark);
83 |     });
84 | 
85 |     it('should handle multiple metric types independently', () => {
86 |       tracker.shouldRecordMetric('heap_used', 1000000);
87 |       tracker.shouldRecordMetric('rss', 2000000);
88 | 
89 |       expect(tracker.getHighWaterMark('heap_used')).toBeGreaterThan(0);
90 |       expect(tracker.getHighWaterMark('rss')).toBeGreaterThan(0);
91 |       expect(tracker.getHighWaterMark('heap_used')).not.toBe(
92 |         tracker.getHighWaterMark('rss'),
93 |       );
94 |     });
95 |   });
96 | 
97 |   describe('smoothing functionality', () => {
98 |     it('should reduce noise from garbage collection spikes', () => {
99 |       // Establish baseline
100 |       tracker.shouldRecordMetric('heap_used', 1000000);
101 |       tracker.shouldRecordMetric('heap_used', 1000000);
102 |       tracker.shouldRecordMetric('heap_used', 1000000);
103 | 
104 |       // Single spike (should be smoothed out)
105 |       const result = tracker.shouldRecordMetric('heap_used', 2000000);
106 | 
107 |       // With the new responsive algorithm, large spikes do trigger
108 |       expect(result).toBe(true);
109 |     });
110 | 
111 |     it('should eventually respond to sustained growth', () => {
112 |       // Establish baseline
113 |       tracker.shouldRecordMetric('heap_used', 1000000);
114 | 
115 |       // Sustained growth pattern
116 |       tracker.shouldRecordMetric('heap_used', 1100000);
117 |       tracker.shouldRecordMetric('heap_used', 1150000);
118 |       const result = tracker.shouldRecordMetric('heap_used', 1200000);
119 | 
120 |       expect(result).toBe(true);
121 |     });
122 |   });
123 | 
124 |   describe('getHighWaterMark', () => {
125 |     it('should return 0 for unknown metric types', () => {
126 |       const mark = tracker.getHighWaterMark('unknown_metric');
127 |       expect(mark).toBe(0);
128 |     });
129 | 
130 |     it('should return correct value for known metric types', () => {
131 |       tracker.shouldRecordMetric('heap_used', 1000000);
132 |       const mark = tracker.getHighWaterMark('heap_used');
133 |       expect(mark).toBeGreaterThan(0);
134 |     });
135 |   });
136 | 
137 |   describe('getAllHighWaterMarks', () => {
138 |     it('should return empty object initially', () => {
139 |       const marks = tracker.getAllHighWaterMarks();
140 |       expect(marks).toEqual({});
141 |     });
142 | 
143 |     it('should return all recorded marks', () => {
144 |       tracker.shouldRecordMetric('heap_used', 1000000);
145 |       tracker.shouldRecordMetric('rss', 2000000);
146 | 
147 |       const marks = tracker.getAllHighWaterMarks();
148 |       expect(Object.keys(marks)).toHaveLength(2);
149 |       expect(marks['heap_used']).toBeGreaterThan(0);
150 |       expect(marks['rss']).toBeGreaterThan(0);
151 |     });
152 |   });
153 | 
154 |   describe('resetHighWaterMark', () => {
155 |     it('should reset specific metric type', () => {
156 |       tracker.shouldRecordMetric('heap_used', 1000000);
157 |       tracker.shouldRecordMetric('rss', 2000000);
158 | 
159 |       tracker.resetHighWaterMark('heap_used');
160 | 
161 |       expect(tracker.getHighWaterMark('heap_used')).toBe(0);
162 |       expect(tracker.getHighWaterMark('rss')).toBeGreaterThan(0);
163 |     });
164 |   });
165 | 
166 |   describe('resetAllHighWaterMarks', () => {
167 |     it('should reset all metrics', () => {
168 |       tracker.shouldRecordMetric('heap_used', 1000000);
169 |       tracker.shouldRecordMetric('rss', 2000000);
170 | 
171 |       tracker.resetAllHighWaterMarks();
172 | 
173 |       expect(tracker.getHighWaterMark('heap_used')).toBe(0);
174 |       expect(tracker.getHighWaterMark('rss')).toBe(0);
175 |       expect(tracker.getAllHighWaterMarks()).toEqual({});
176 |     });
177 |   });
178 | 
179 |   describe('time-based cleanup', () => {
180 |     it('should clean up old readings', () => {
181 |       vi.useFakeTimers();
182 | 
183 |       // Add readings
184 |       tracker.shouldRecordMetric('heap_used', 1000000);
185 | 
186 |       // Advance time significantly
187 |       vi.advanceTimersByTime(15000); // 15 seconds
188 | 
189 |       // Explicit cleanup should remove stale entries when age exceeded
190 |       tracker.cleanup(10000); // 10 seconds
191 | 
192 |       // Entry should be removed
193 |       expect(tracker.getHighWaterMark('heap_used')).toBe(0);
194 | 
195 |       vi.useRealTimers();
196 |     });
197 |   });
198 | });
```

src/telemetry/high-water-mark-tracker.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * High-water mark tracker for memory metrics
9 |  * Only triggers when memory usage increases by a significant threshold
10 |  */
11 | export class HighWaterMarkTracker {
12 |   private waterMarks: Map<string, number> = new Map();
13 |   private lastUpdateTimes: Map<string, number> = new Map();
14 |   private readonly growthThresholdPercent: number;
15 | 
16 |   constructor(growthThresholdPercent: number = 5) {
17 |     if (growthThresholdPercent < 0) {
18 |       throw new Error('growthThresholdPercent must be non-negative.');
19 |     }
20 |     this.growthThresholdPercent = growthThresholdPercent;
21 |   }
22 | 
23 |   /**
24 |    * Check if current value represents a new high-water mark that should trigger recording
25 |    * @param metricType - Type of metric (e.g., 'heap_used', 'rss')
26 |    * @param currentValue - Current memory value in bytes
27 |    * @returns true if this value should trigger a recording
28 |    */
29 |   shouldRecordMetric(metricType: string, currentValue: number): boolean {
30 |     const now = Date.now();
31 |     // Track last seen time for cleanup regardless of whether we record
32 |     this.lastUpdateTimes.set(metricType, now);
33 |     // Get current high-water mark
34 |     const currentWaterMark = this.waterMarks.get(metricType) || 0;
35 | 
36 |     // For first measurement, always record
37 |     if (currentWaterMark === 0) {
38 |       this.waterMarks.set(metricType, currentValue);
39 |       this.lastUpdateTimes.set(metricType, now);
40 |       return true;
41 |     }
42 | 
43 |     // Check if current value exceeds threshold
44 |     const thresholdValue =
45 |       currentWaterMark * (1 + this.growthThresholdPercent / 100);
46 | 
47 |     if (currentValue > thresholdValue) {
48 |       // Update high-water mark
49 |       this.waterMarks.set(metricType, currentValue);
50 |       this.lastUpdateTimes.set(metricType, now);
51 |       return true;
52 |     }
53 | 
54 |     return false;
55 |   }
56 | 
57 |   /**
58 |    * Get current high-water mark for a metric type
59 |    */
60 |   getHighWaterMark(metricType: string): number {
61 |     return this.waterMarks.get(metricType) || 0;
62 |   }
63 | 
64 |   /**
65 |    * Get all high-water marks
66 |    */
67 |   getAllHighWaterMarks(): Record<string, number> {
68 |     return Object.fromEntries(this.waterMarks);
69 |   }
70 | 
71 |   /**
72 |    * Reset high-water mark for a specific metric type
73 |    */
74 |   resetHighWaterMark(metricType: string): void {
75 |     this.waterMarks.delete(metricType);
76 |     this.lastUpdateTimes.delete(metricType);
77 |   }
78 | 
79 |   /**
80 |    * Reset all high-water marks
81 |    */
82 |   resetAllHighWaterMarks(): void {
83 |     this.waterMarks.clear();
84 |     this.lastUpdateTimes.clear();
85 |   }
86 | 
87 |   /**
88 |    * Remove stale entries to avoid unbounded growth if metric types are variable.
89 |    * Entries not updated within maxAgeMs will be removed.
90 |    */
91 |   cleanup(maxAgeMs: number = 3600000): void {
92 |     const cutoffTime = Date.now() - maxAgeMs;
93 |     for (const [metricType, lastTime] of this.lastUpdateTimes.entries()) {
94 |       if (lastTime < cutoffTime) {
95 |         this.lastUpdateTimes.delete(metricType);
96 |         this.waterMarks.delete(metricType);
97 |       }
98 |     }
99 |   }
100 | }
```

src/telemetry/index.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export enum TelemetryTarget {
8 |   GCP = 'gcp',
9 |   LOCAL = 'local',
10 | }
11 | 
12 | const DEFAULT_TELEMETRY_TARGET = TelemetryTarget.LOCAL;
13 | const DEFAULT_OTLP_ENDPOINT = 'http://localhost:4317';
14 | 
15 | export { DEFAULT_TELEMETRY_TARGET, DEFAULT_OTLP_ENDPOINT };
16 | export {
17 |   initializeTelemetry,
18 |   shutdownTelemetry,
19 |   isTelemetrySdkInitialized,
20 | } from './sdk.js';
21 | export {
22 |   resolveTelemetrySettings,
23 |   parseBooleanEnvFlag,
24 |   parseTelemetryTargetValue,
25 | } from './config.js';
26 | export {
27 |   GcpTraceExporter,
28 |   GcpMetricExporter,
29 |   GcpLogExporter,
30 | } from './gcp-exporters.js';
31 | export {
32 |   logCliConfiguration,
33 |   logUserPrompt,
34 |   logToolCall,
35 |   logApiRequest,
36 |   logApiError,
37 |   logApiResponse,
38 |   logFlashFallback,
39 |   logSlashCommand,
40 |   logConversationFinishedEvent,
41 |   logKittySequenceOverflow,
42 |   logChatCompression,
43 |   logToolOutputTruncated,
44 |   logExtensionEnable,
45 |   logExtensionInstallEvent,
46 |   logExtensionUninstall,
47 |   logExtensionUpdateEvent,
48 |   logWebFetchFallbackAttempt,
49 | } from './loggers.js';
50 | export type { SlashCommandEvent, ChatCompressionEvent } from './types.js';
51 | export {
52 |   SlashCommandStatus,
53 |   EndSessionEvent,
54 |   UserPromptEvent,
55 |   ApiRequestEvent,
56 |   ApiErrorEvent,
57 |   ApiResponseEvent,
58 |   FlashFallbackEvent,
59 |   StartSessionEvent,
60 |   ToolCallEvent,
61 |   ConversationFinishedEvent,
62 |   KittySequenceOverflowEvent,
63 |   ToolOutputTruncatedEvent,
64 |   WebFetchFallbackAttemptEvent,
65 | } from './types.js';
66 | export { makeSlashCommandEvent, makeChatCompressionEvent } from './types.js';
67 | export type { TelemetryEvent } from './types.js';
68 | export { SpanStatusCode, ValueType } from '@opentelemetry/api';
69 | export { SemanticAttributes } from '@opentelemetry/semantic-conventions';
70 | export * from './uiTelemetry.js';
71 | export {
72 |   MemoryMonitor,
73 |   initializeMemoryMonitor,
74 |   getMemoryMonitor,
75 |   recordCurrentMemoryUsage,
76 |   startGlobalMemoryMonitoring,
77 |   stopGlobalMemoryMonitoring,
78 | } from './memory-monitor.js';
79 | export type { MemorySnapshot, ProcessMetrics } from './memory-monitor.js';
80 | export { HighWaterMarkTracker } from './high-water-mark-tracker.js';
81 | export { RateLimiter } from './rate-limiter.js';
82 | export { ActivityType } from './activity-types.js';
83 | export {
84 |   ActivityDetector,
85 |   getActivityDetector,
86 |   recordUserActivity,
87 |   isUserActive,
88 | } from './activity-detector.js';
89 | export {
90 |   // Core metrics functions
91 |   recordToolCallMetrics,
92 |   recordTokenUsageMetrics,
93 |   recordApiResponseMetrics,
94 |   recordApiErrorMetrics,
95 |   recordFileOperationMetric,
96 |   recordInvalidChunk,
97 |   recordContentRetry,
98 |   recordContentRetryFailure,
99 |   recordModelRoutingMetrics,
100 |   // Custom metrics for token usage and API responses
101 |   recordCustomTokenUsageMetrics,
102 |   recordCustomApiResponseMetrics,
103 |   // OpenTelemetry GenAI semantic convention for token usage and operation duration
104 |   recordGenAiClientTokenUsage,
105 |   recordGenAiClientOperationDuration,
106 |   getConventionAttributes,
107 |   // Performance monitoring functions
108 |   recordStartupPerformance,
109 |   recordMemoryUsage,
110 |   recordCpuUsage,
111 |   recordToolQueueDepth,
112 |   recordToolExecutionBreakdown,
113 |   recordTokenEfficiency,
114 |   recordApiRequestBreakdown,
115 |   recordPerformanceScore,
116 |   recordPerformanceRegression,
117 |   recordBaselineComparison,
118 |   isPerformanceMonitoringActive,
119 |   recordFlickerFrame,
120 |   // Performance monitoring types
121 |   PerformanceMetricType,
122 |   MemoryMetricType,
123 |   ToolExecutionPhase,
124 |   ApiRequestPhase,
125 |   FileOperation,
126 |   // OpenTelemetry Semantic Convention types
127 |   GenAiOperationName,
128 |   GenAiProviderName,
129 |   GenAiTokenType,
130 | } from './metrics.js';
```

src/telemetry/integration.test.circular.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Integration test to verify circular reference handling with proxy agents
9 |  */
10 | 
11 | import { describe, it, expect } from 'vitest';
12 | import { ClearcutLogger } from './clearcut-logger/clearcut-logger.js';
13 | import type { Config } from '../config/config.js';
14 | 
15 | describe('Circular Reference Integration Test', () => {
16 |   it('should handle HttpsProxyAgent-like circular references in clearcut logging', () => {
17 |     // Create a mock config with proxy
18 |     const mockConfig = {
19 |       getTelemetryEnabled: () => true,
20 |       getUsageStatisticsEnabled: () => true,
21 |       getSessionId: () => 'test-session',
22 |       getModel: () => 'test-model',
23 |       getEmbeddingModel: () => 'test-embedding',
24 |       getDebugMode: () => false,
25 |       getProxy: () => 'http://proxy.example.com:8080',
26 |     } as unknown as Config;
27 | 
28 |     // Simulate the structure that causes the circular reference error
29 |     // eslint-disable-next-line @typescript-eslint/no-explicit-any
30 |     const proxyAgentLike: any = {
31 |       sockets: {},
32 |       options: { proxy: 'http://proxy.example.com:8080' },
33 |     };
34 | 
35 |     // eslint-disable-next-line @typescript-eslint/no-explicit-any
36 |     const socketLike: any = {
37 |       _httpMessage: {
38 |         agent: proxyAgentLike,
39 |         socket: null,
40 |       },
41 |     };
42 | 
43 |     socketLike._httpMessage.socket = socketLike; // Create circular reference
44 |     proxyAgentLike.sockets['cloudcode-pa.googleapis.com:443'] = [socketLike];
45 | 
46 |     // Create an event that would contain this circular structure
47 |     const problematicEvent = {
48 |       error: new Error('Network error'),
49 |       function_args: {
50 |         filePath: '/test/file.txt',
51 |         httpAgent: proxyAgentLike, // This would cause the circular reference
52 |       },
53 |     };
54 | 
55 |     // Test that ClearcutLogger can handle this
56 |     const logger = ClearcutLogger.getInstance(mockConfig);
57 | 
58 |     expect(() => {
59 |       // eslint-disable-next-line @typescript-eslint/no-explicit-any
60 |       logger?.enqueueLogEvent(problematicEvent as any);
61 |     }).not.toThrow();
62 |   });
63 | });
```

src/telemetry/loggers.test.circular.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Test to verify circular reference handling in telemetry logging
9 |  */
10 | 
11 | import { describe, it, expect } from 'vitest';
12 | import { logToolCall } from './loggers.js';
13 | import { ToolCallEvent } from './types.js';
14 | import type { Config } from '../config/config.js';
15 | import type { CompletedToolCall } from '../core/coreToolScheduler.js';
16 | import type {
17 |   ToolCallRequestInfo,
18 |   ToolCallResponseInfo,
19 | } from '../core/turn.js';
20 | import { MockTool } from '../test-utils/mock-tool.js';
21 | 
22 | describe('Circular Reference Handling', () => {
23 |   it('should handle circular references in tool function arguments', () => {
24 |     // Create a mock config
25 |     const mockConfig = {
26 |       getTelemetryEnabled: () => true,
27 |       getUsageStatisticsEnabled: () => true,
28 |       getSessionId: () => 'test-session',
29 |       getModel: () => 'test-model',
30 |       getEmbeddingModel: () => 'test-embedding',
31 |       getDebugMode: () => false,
32 |     } as unknown as Config;
33 | 
34 |     // Create an object with circular references (similar to HttpsProxyAgent)
35 |     // eslint-disable-next-line @typescript-eslint/no-explicit-any
36 |     const circularObject: any = {
37 |       sockets: {},
38 |       agent: null,
39 |     };
40 |     circularObject.agent = circularObject; // Create circular reference
41 |     circularObject.sockets['test-host'] = [
42 |       { _httpMessage: { agent: circularObject } },
43 |     ];
44 | 
45 |     // Create a mock CompletedToolCall with circular references in function_args
46 |     const mockRequest: ToolCallRequestInfo = {
47 |       callId: 'test-call-id',
48 |       name: 'ReadFile',
49 |       args: circularObject, // This would cause the original error
50 |       isClientInitiated: false,
51 |       prompt_id: 'test-prompt-id',
52 |     };
53 | 
54 |     const mockResponse: ToolCallResponseInfo = {
55 |       callId: 'test-call-id',
56 |       responseParts: [{ text: 'test result' }],
57 |       resultDisplay: undefined,
58 |       error: undefined, // undefined means success
59 |       errorType: undefined,
60 |     };
61 | 
62 |     const tool = new MockTool({ name: 'mock-tool' });
63 |     const mockCompletedToolCall: CompletedToolCall = {
64 |       status: 'success',
65 |       request: mockRequest,
66 |       response: mockResponse,
67 |       tool,
68 |       invocation: tool.build({}),
69 |       durationMs: 100,
70 |     };
71 | 
72 |     // Create a tool call event with circular references in function_args
73 |     const event = new ToolCallEvent(mockCompletedToolCall);
74 | 
75 |     // This should not throw an error
76 |     expect(() => {
77 |       logToolCall(mockConfig, event);
78 |     }).not.toThrow();
79 |   });
80 | 
81 |   it('should handle normal objects without circular references', () => {
82 |     const mockConfig = {
83 |       getTelemetryEnabled: () => true,
84 |       getUsageStatisticsEnabled: () => true,
85 |       getSessionId: () => 'test-session',
86 |       getModel: () => 'test-model',
87 |       getEmbeddingModel: () => 'test-embedding',
88 |       getDebugMode: () => false,
89 |     } as unknown as Config;
90 | 
91 |     const normalObject = {
92 |       filePath: '/test/path',
93 |       options: { encoding: 'utf8' },
94 |     };
95 | 
96 |     const mockRequest: ToolCallRequestInfo = {
97 |       callId: 'test-call-id',
98 |       name: 'ReadFile',
99 |       args: normalObject,
100 |       isClientInitiated: false,
101 |       prompt_id: 'test-prompt-id',
102 |     };
103 | 
104 |     const mockResponse: ToolCallResponseInfo = {
105 |       callId: 'test-call-id',
106 |       responseParts: [{ text: 'test result' }],
107 |       resultDisplay: undefined,
108 |       error: undefined, // undefined means success
109 |       errorType: undefined,
110 |     };
111 | 
112 |     const tool = new MockTool({ name: 'mock-tool' });
113 |     const mockCompletedToolCall: CompletedToolCall = {
114 |       status: 'success',
115 |       request: mockRequest,
116 |       response: mockResponse,
117 |       tool,
118 |       invocation: tool.build({}),
119 |       durationMs: 100,
120 |     };
121 | 
122 |     const event = new ToolCallEvent(mockCompletedToolCall);
123 | 
124 |     expect(() => {
125 |       logToolCall(mockConfig, event);
126 |     }).not.toThrow();
127 |   });
128 | });
```

src/telemetry/loggers.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   AnyToolInvocation,
9 |   CompletedToolCall,
10 |   ContentGeneratorConfig,
11 |   ErroredToolCall,
12 | } from '../index.js';
13 | import {
14 |   AuthType,
15 |   EditTool,
16 |   GeminiClient,
17 |   ToolConfirmationOutcome,
18 |   ToolErrorType,
19 |   ToolRegistry,
20 | } from '../index.js';
21 | import { OutputFormat } from '../output/types.js';
22 | import { logs } from '@opentelemetry/api-logs';
23 | import { SemanticAttributes } from '@opentelemetry/semantic-conventions';
24 | import type { Config } from '../config/config.js';
25 | import {
26 |   logApiRequest,
27 |   logApiResponse,
28 |   logCliConfiguration,
29 |   logUserPrompt,
30 |   logToolCall,
31 |   logFlashFallback,
32 |   logChatCompression,
33 |   logMalformedJsonResponse,
34 |   logFileOperation,
35 |   logRipgrepFallback,
36 |   logToolOutputTruncated,
37 |   logModelRouting,
38 |   logExtensionEnable,
39 |   logExtensionDisable,
40 |   logExtensionInstallEvent,
41 |   logExtensionUninstall,
42 |   logAgentStart,
43 |   logAgentFinish,
44 |   logWebFetchFallbackAttempt,
45 |   logExtensionUpdateEvent,
46 | } from './loggers.js';
47 | import { ToolCallDecision } from './tool-call-decision.js';
48 | import {
49 |   EVENT_API_REQUEST,
50 |   EVENT_API_RESPONSE,
51 |   EVENT_CLI_CONFIG,
52 |   EVENT_TOOL_CALL,
53 |   EVENT_USER_PROMPT,
54 |   EVENT_FLASH_FALLBACK,
55 |   EVENT_MALFORMED_JSON_RESPONSE,
56 |   EVENT_FILE_OPERATION,
57 |   EVENT_RIPGREP_FALLBACK,
58 |   EVENT_MODEL_ROUTING,
59 |   EVENT_EXTENSION_ENABLE,
60 |   EVENT_EXTENSION_DISABLE,
61 |   EVENT_EXTENSION_INSTALL,
62 |   EVENT_EXTENSION_UNINSTALL,
63 |   EVENT_TOOL_OUTPUT_TRUNCATED,
64 |   EVENT_AGENT_START,
65 |   EVENT_AGENT_FINISH,
66 |   EVENT_WEB_FETCH_FALLBACK_ATTEMPT,
67 |   ApiRequestEvent,
68 |   ApiResponseEvent,
69 |   StartSessionEvent,
70 |   ToolCallEvent,
71 |   UserPromptEvent,
72 |   FlashFallbackEvent,
73 |   RipgrepFallbackEvent,
74 |   MalformedJsonResponseEvent,
75 |   makeChatCompressionEvent,
76 |   FileOperationEvent,
77 |   ToolOutputTruncatedEvent,
78 |   ModelRoutingEvent,
79 |   ExtensionEnableEvent,
80 |   ExtensionDisableEvent,
81 |   ExtensionInstallEvent,
82 |   ExtensionUninstallEvent,
83 |   AgentStartEvent,
84 |   AgentFinishEvent,
85 |   WebFetchFallbackAttemptEvent,
86 |   ExtensionUpdateEvent,
87 |   EVENT_EXTENSION_UPDATE,
88 | } from './types.js';
89 | import * as metrics from './metrics.js';
90 | import {
91 |   FileOperation,
92 |   GenAiOperationName,
93 |   GenAiProviderName,
94 | } from './metrics.js';
95 | import * as sdk from './sdk.js';
96 | import { vi, describe, beforeEach, it, expect, afterEach } from 'vitest';
97 | import type {
98 |   CallableTool,
99 |   GenerateContentResponseUsageMetadata,
100 | } from '@google/genai';
101 | import { DiscoveredMCPTool } from '../tools/mcp-tool.js';
102 | import * as uiTelemetry from './uiTelemetry.js';
103 | import { makeFakeConfig } from '../test-utils/config.js';
104 | import { ClearcutLogger } from './clearcut-logger/clearcut-logger.js';
105 | import { UserAccountManager } from '../utils/userAccountManager.js';
106 | import { InstallationManager } from '../utils/installationManager.js';
107 | import { AgentTerminateMode } from '../agents/types.js';
108 | 
109 | describe('loggers', () => {
110 |   const mockLogger = {
111 |     emit: vi.fn(),
112 |   };
113 |   const mockUiEvent = {
114 |     addEvent: vi.fn(),
115 |   };
116 | 
117 |   beforeEach(() => {
118 |     vi.clearAllMocks();
119 |     vi.spyOn(sdk, 'isTelemetrySdkInitialized').mockReturnValue(true);
120 |     vi.spyOn(logs, 'getLogger').mockReturnValue(mockLogger);
121 |     vi.spyOn(uiTelemetry.uiTelemetryService, 'addEvent').mockImplementation(
122 |       mockUiEvent.addEvent,
123 |     );
124 |     vi.spyOn(
125 |       UserAccountManager.prototype,
126 |       'getCachedGoogleAccount',
127 |     ).mockReturnValue('test-user@example.com');
128 |     vi.spyOn(
129 |       InstallationManager.prototype,
130 |       'getInstallationId',
131 |     ).mockReturnValue('test-installation-id');
132 |     vi.useFakeTimers();
133 |     vi.setSystemTime(new Date('2025-01-01T00:00:00.000Z'));
134 |   });
135 | 
136 |   describe('logChatCompression', () => {
137 |     beforeEach(() => {
138 |       vi.spyOn(metrics, 'recordChatCompressionMetrics');
139 |       vi.spyOn(ClearcutLogger.prototype, 'logChatCompressionEvent');
140 |     });
141 | 
142 |     it('logs the chat compression event to Clearcut', () => {
143 |       const mockConfig = makeFakeConfig();
144 | 
145 |       const event = makeChatCompressionEvent({
146 |         tokens_before: 9001,
147 |         tokens_after: 9000,
148 |       });
149 | 
150 |       logChatCompression(mockConfig, event);
151 | 
152 |       expect(
153 |         ClearcutLogger.prototype.logChatCompressionEvent,
154 |       ).toHaveBeenCalledWith(event);
155 |     });
156 | 
157 |     it('records the chat compression event to OTEL', () => {
158 |       const mockConfig = makeFakeConfig();
159 | 
160 |       logChatCompression(
161 |         mockConfig,
162 |         makeChatCompressionEvent({
163 |           tokens_before: 9001,
164 |           tokens_after: 9000,
165 |         }),
166 |       );
167 | 
168 |       expect(metrics.recordChatCompressionMetrics).toHaveBeenCalledWith(
169 |         mockConfig,
170 |         { tokens_before: 9001, tokens_after: 9000 },
171 |       );
172 |     });
173 |   });
174 | 
175 |   describe('logCliConfiguration', () => {
176 |     it('should log the cli configuration', () => {
177 |       const mockConfig = {
178 |         getSessionId: () => 'test-session-id',
179 |         getModel: () => 'test-model',
180 |         getEmbeddingModel: () => 'test-embedding-model',
181 |         getSandbox: () => true,
182 |         getCoreTools: () => ['ls', 'read-file'],
183 |         getApprovalMode: () => 'default',
184 |         getContentGeneratorConfig: () => ({
185 |           model: 'test-model',
186 |           apiKey: 'test-api-key',
187 |           authType: AuthType.USE_VERTEX_AI,
188 |         }),
189 |         getTelemetryEnabled: () => true,
190 |         getUsageStatisticsEnabled: () => true,
191 |         getTelemetryLogPromptsEnabled: () => true,
192 |         getFileFilteringRespectGitIgnore: () => true,
193 |         getFileFilteringAllowBuildArtifacts: () => false,
194 |         getDebugMode: () => true,
195 |         getMcpServers: () => ({
196 |           'test-server': {
197 |             command: 'test-command',
198 |           },
199 |         }),
200 |         getQuestion: () => 'test-question',
201 |         getTargetDir: () => 'target-dir',
202 |         getProxy: () => 'http://test.proxy.com:8080',
203 |         getOutputFormat: () => OutputFormat.JSON,
204 |       } as unknown as Config;
205 | 
206 |       const startSessionEvent = new StartSessionEvent(mockConfig);
207 |       logCliConfiguration(mockConfig, startSessionEvent);
208 | 
209 |       expect(mockLogger.emit).toHaveBeenCalledWith({
210 |         body: 'CLI configuration loaded.',
211 |         attributes: {
212 |           'session.id': 'test-session-id',
213 |           'user.email': 'test-user@example.com',
214 |           'installation.id': 'test-installation-id',
215 |           'event.name': EVENT_CLI_CONFIG,
216 |           'event.timestamp': '2025-01-01T00:00:00.000Z',
217 |           model: 'test-model',
218 |           embedding_model: 'test-embedding-model',
219 |           sandbox_enabled: true,
220 |           core_tools_enabled: 'ls,read-file',
221 |           approval_mode: 'default',
222 |           api_key_enabled: true,
223 |           vertex_ai_enabled: true,
224 |           log_user_prompts_enabled: true,
225 |           file_filtering_respect_git_ignore: true,
226 |           debug_mode: true,
227 |           mcp_servers: 'test-server',
228 |           mcp_servers_count: 1,
229 |           mcp_tools: undefined,
230 |           mcp_tools_count: undefined,
231 |           output_format: 'json',
232 |         },
233 |       });
234 |     });
235 |   });
236 | 
237 |   describe('logUserPrompt', () => {
238 |     const mockConfig = {
239 |       getSessionId: () => 'test-session-id',
240 |       getTelemetryEnabled: () => true,
241 |       getTelemetryLogPromptsEnabled: () => true,
242 |       getUsageStatisticsEnabled: () => true,
243 |     } as unknown as Config;
244 | 
245 |     it('should log a user prompt', () => {
246 |       const event = new UserPromptEvent(
247 |         11,
248 |         'prompt-id-8',
249 |         AuthType.USE_VERTEX_AI,
250 |         'test-prompt',
251 |       );
252 | 
253 |       logUserPrompt(mockConfig, event);
254 | 
255 |       expect(mockLogger.emit).toHaveBeenCalledWith({
256 |         body: 'User prompt. Length: 11.',
257 |         attributes: {
258 |           'session.id': 'test-session-id',
259 |           'user.email': 'test-user@example.com',
260 |           'installation.id': 'test-installation-id',
261 |           'event.name': EVENT_USER_PROMPT,
262 |           'event.timestamp': '2025-01-01T00:00:00.000Z',
263 |           prompt_length: 11,
264 |           prompt: 'test-prompt',
265 |           prompt_id: 'prompt-id-8',
266 |           auth_type: 'vertex-ai',
267 |         },
268 |       });
269 |     });
270 | 
271 |     it('should not log prompt if disabled', () => {
272 |       const mockConfig = {
273 |         getSessionId: () => 'test-session-id',
274 |         getTelemetryEnabled: () => true,
275 |         getTelemetryLogPromptsEnabled: () => false,
276 |         getTargetDir: () => 'target-dir',
277 |         getUsageStatisticsEnabled: () => true,
278 |       } as unknown as Config;
279 |       const event = new UserPromptEvent(
280 |         11,
281 |         'prompt-id-9',
282 |         AuthType.CLOUD_SHELL,
283 |         'test-prompt',
284 |       );
285 | 
286 |       logUserPrompt(mockConfig, event);
287 | 
288 |       expect(mockLogger.emit).toHaveBeenCalledWith({
289 |         body: 'User prompt. Length: 11.',
290 |         attributes: {
291 |           'session.id': 'test-session-id',
292 |           'user.email': 'test-user@example.com',
293 |           'installation.id': 'test-installation-id',
294 |           'event.name': EVENT_USER_PROMPT,
295 |           'event.timestamp': '2025-01-01T00:00:00.000Z',
296 |           prompt_length: 11,
297 |           prompt_id: 'prompt-id-9',
298 |           auth_type: 'cloud-shell',
299 |         },
300 |       });
301 |     });
302 |   });
303 | 
304 |   describe('logApiResponse', () => {
305 |     const mockConfig = {
306 |       getSessionId: () => 'test-session-id',
307 |       getTargetDir: () => 'target-dir',
308 |       getUsageStatisticsEnabled: () => true,
309 |       getTelemetryEnabled: () => true,
310 |       getTelemetryLogPromptsEnabled: () => true,
311 |     } as Config;
312 | 
313 |     const mockMetrics = {
314 |       recordApiResponseMetrics: vi.fn(),
315 |       recordTokenUsageMetrics: vi.fn(),
316 |       getConventionAttributes: vi.fn(() => ({
317 |         'gen_ai.operation.name': GenAiOperationName.GENERATE_CONTENT,
318 |         'gen_ai.provider.name': GenAiProviderName.GCP_VERTEX_AI,
319 |         'gen_ai.request.model': 'test-model',
320 |         'gen_ai.response.model': 'test-model',
321 |       })),
322 |     };
323 | 
324 |     beforeEach(() => {
325 |       vi.spyOn(metrics, 'recordApiResponseMetrics').mockImplementation(
326 |         mockMetrics.recordApiResponseMetrics,
327 |       );
328 |       vi.spyOn(metrics, 'recordTokenUsageMetrics').mockImplementation(
329 |         mockMetrics.recordTokenUsageMetrics,
330 |       );
331 |       vi.spyOn(metrics, 'getConventionAttributes').mockImplementation(
332 |         mockMetrics.getConventionAttributes,
333 |       );
334 |     });
335 | 
336 |     it('should log an API response with all fields', () => {
337 |       const usageData: GenerateContentResponseUsageMetadata = {
338 |         promptTokenCount: 17,
339 |         candidatesTokenCount: 50,
340 |         cachedContentTokenCount: 10,
341 |         thoughtsTokenCount: 5,
342 |         toolUsePromptTokenCount: 2,
343 |       };
344 |       const event = new ApiResponseEvent(
345 |         'test-model',
346 |         100,
347 |         'prompt-id-1',
348 |         AuthType.LOGIN_WITH_GOOGLE,
349 |         usageData,
350 |         'test-response',
351 |       );
352 | 
353 |       logApiResponse(mockConfig, event);
354 | 
355 |       expect(mockLogger.emit).toHaveBeenCalledWith({
356 |         body: 'API response from test-model. Status: 200. Duration: 100ms.',
357 |         attributes: {
358 |           'session.id': 'test-session-id',
359 |           'user.email': 'test-user@example.com',
360 |           'installation.id': 'test-installation-id',
361 |           'event.name': EVENT_API_RESPONSE,
362 |           'event.timestamp': '2025-01-01T00:00:00.000Z',
363 |           [SemanticAttributes.HTTP_STATUS_CODE]: 200,
364 |           model: 'test-model',
365 |           status_code: 200,
366 |           duration_ms: 100,
367 |           input_token_count: 17,
368 |           output_token_count: 50,
369 |           cached_content_token_count: 10,
370 |           thoughts_token_count: 5,
371 |           tool_token_count: 2,
372 |           total_token_count: 0,
373 |           response_text: 'test-response',
374 |           prompt_id: 'prompt-id-1',
375 |           auth_type: 'oauth-personal',
376 |         },
377 |       });
378 | 
379 |       expect(mockMetrics.recordApiResponseMetrics).toHaveBeenCalledWith(
380 |         mockConfig,
381 |         100,
382 |         {
383 |           model: 'test-model',
384 |           status_code: 200,
385 |           genAiAttributes: {
386 |             'gen_ai.operation.name': 'generate_content',
387 |             'gen_ai.provider.name': 'gcp.vertex_ai',
388 |             'gen_ai.request.model': 'test-model',
389 |             'gen_ai.response.model': 'test-model',
390 |           },
391 |         },
392 |       );
393 | 
394 |       // Verify token usage calls for all token types
395 |       expect(mockMetrics.recordTokenUsageMetrics).toHaveBeenCalledWith(
396 |         mockConfig,
397 |         17,
398 |         {
399 |           model: 'test-model',
400 |           type: 'input',
401 |           genAiAttributes: {
402 |             'gen_ai.operation.name': 'generate_content',
403 |             'gen_ai.provider.name': 'gcp.vertex_ai',
404 |             'gen_ai.request.model': 'test-model',
405 |             'gen_ai.response.model': 'test-model',
406 |           },
407 |         },
408 |       );
409 | 
410 |       expect(mockMetrics.recordTokenUsageMetrics).toHaveBeenCalledWith(
411 |         mockConfig,
412 |         50,
413 |         {
414 |           model: 'test-model',
415 |           type: 'output',
416 |           genAiAttributes: {
417 |             'gen_ai.operation.name': 'generate_content',
418 |             'gen_ai.provider.name': 'gcp.vertex_ai',
419 |             'gen_ai.request.model': 'test-model',
420 |             'gen_ai.response.model': 'test-model',
421 |           },
422 |         },
423 |       );
424 | 
425 |       expect(mockUiEvent.addEvent).toHaveBeenCalledWith({
426 |         ...event,
427 |         'event.name': EVENT_API_RESPONSE,
428 |         'event.timestamp': '2025-01-01T00:00:00.000Z',
429 |       });
430 |     });
431 |   });
432 | 
433 |   describe('logApiRequest', () => {
434 |     const mockConfig = {
435 |       getSessionId: () => 'test-session-id',
436 |       getTargetDir: () => 'target-dir',
437 |       getUsageStatisticsEnabled: () => true,
438 |       getTelemetryEnabled: () => true,
439 |       getTelemetryLogPromptsEnabled: () => true,
440 |     } as Config;
441 | 
442 |     it('should log an API request with request_text', () => {
443 |       const event = new ApiRequestEvent(
444 |         'test-model',
445 |         'prompt-id-7',
446 |         'This is a test request',
447 |       );
448 | 
449 |       logApiRequest(mockConfig, event);
450 | 
451 |       expect(mockLogger.emit).toHaveBeenCalledWith({
452 |         body: 'API request to test-model.',
453 |         attributes: {
454 |           'session.id': 'test-session-id',
455 |           'user.email': 'test-user@example.com',
456 |           'installation.id': 'test-installation-id',
457 |           'event.name': EVENT_API_REQUEST,
458 |           'event.timestamp': '2025-01-01T00:00:00.000Z',
459 |           model: 'test-model',
460 |           request_text: 'This is a test request',
461 |           prompt_id: 'prompt-id-7',
462 |         },
463 |       });
464 |     });
465 | 
466 |     it('should log an API request without request_text', () => {
467 |       const event = new ApiRequestEvent('test-model', 'prompt-id-6');
468 | 
469 |       logApiRequest(mockConfig, event);
470 | 
471 |       expect(mockLogger.emit).toHaveBeenCalledWith({
472 |         body: 'API request to test-model.',
473 |         attributes: {
474 |           'session.id': 'test-session-id',
475 |           'user.email': 'test-user@example.com',
476 |           'installation.id': 'test-installation-id',
477 |           'event.name': EVENT_API_REQUEST,
478 |           'event.timestamp': '2025-01-01T00:00:00.000Z',
479 |           model: 'test-model',
480 |           prompt_id: 'prompt-id-6',
481 |         },
482 |       });
483 |     });
484 |   });
485 | 
486 |   describe('logFlashFallback', () => {
487 |     const mockConfig = {
488 |       getSessionId: () => 'test-session-id',
489 |       getUsageStatisticsEnabled: () => true,
490 |     } as unknown as Config;
491 | 
492 |     it('should log flash fallback event', () => {
493 |       const event = new FlashFallbackEvent(AuthType.USE_VERTEX_AI);
494 | 
495 |       logFlashFallback(mockConfig, event);
496 | 
497 |       expect(mockLogger.emit).toHaveBeenCalledWith({
498 |         body: 'Switching to flash as Fallback.',
499 |         attributes: {
500 |           'session.id': 'test-session-id',
501 |           'user.email': 'test-user@example.com',
502 |           'installation.id': 'test-installation-id',
503 |           'event.name': EVENT_FLASH_FALLBACK,
504 |           'event.timestamp': '2025-01-01T00:00:00.000Z',
505 |           auth_type: 'vertex-ai',
506 |         },
507 |       });
508 |     });
509 |   });
510 | 
511 |   describe('logRipgrepFallback', () => {
512 |     const mockConfig = {
513 |       getSessionId: () => 'test-session-id',
514 |       getUsageStatisticsEnabled: () => true,
515 |     } as unknown as Config;
516 | 
517 |     beforeEach(() => {
518 |       vi.spyOn(ClearcutLogger.prototype, 'logRipgrepFallbackEvent');
519 |     });
520 | 
521 |     it('should log ripgrep fallback event', () => {
522 |       const event = new RipgrepFallbackEvent();
523 | 
524 |       logRipgrepFallback(mockConfig, event);
525 | 
526 |       expect(
527 |         ClearcutLogger.prototype.logRipgrepFallbackEvent,
528 |       ).toHaveBeenCalled();
529 | 
530 |       const emittedEvent = mockLogger.emit.mock.calls[0][0];
531 |       expect(emittedEvent.body).toBe('Switching to grep as fallback.');
532 |       expect(emittedEvent.attributes).toEqual(
533 |         expect.objectContaining({
534 |           'session.id': 'test-session-id',
535 |           'user.email': 'test-user@example.com',
536 |           'installation.id': 'test-installation-id',
537 |           'event.name': EVENT_RIPGREP_FALLBACK,
538 |           error: undefined,
539 |         }),
540 |       );
541 |     });
542 | 
543 |     it('should log ripgrep fallback event with an error', () => {
544 |       const event = new RipgrepFallbackEvent('rg not found');
545 | 
546 |       logRipgrepFallback(mockConfig, event);
547 | 
548 |       expect(
549 |         ClearcutLogger.prototype.logRipgrepFallbackEvent,
550 |       ).toHaveBeenCalled();
551 | 
552 |       const emittedEvent = mockLogger.emit.mock.calls[0][0];
553 |       expect(emittedEvent.body).toBe('Switching to grep as fallback.');
554 |       expect(emittedEvent.attributes).toEqual(
555 |         expect.objectContaining({
556 |           'session.id': 'test-session-id',
557 |           'user.email': 'test-user@example.com',
558 |           'installation.id': 'test-installation-id',
559 |           'event.name': EVENT_RIPGREP_FALLBACK,
560 |           error: 'rg not found',
561 |         }),
562 |       );
563 |     });
564 |   });
565 | 
566 |   describe('logToolCall', () => {
567 |     const cfg1 = {
568 |       getSessionId: () => 'test-session-id',
569 |       getTargetDir: () => 'target-dir',
570 |       getGeminiClient: () => mockGeminiClient,
571 |     } as Config;
572 |     const cfg2 = {
573 |       getSessionId: () => 'test-session-id',
574 |       getTargetDir: () => 'target-dir',
575 |       getProxy: () => 'http://test.proxy.com:8080',
576 |       getContentGeneratorConfig: () =>
577 |         ({ model: 'test-model' }) as ContentGeneratorConfig,
578 |       getModel: () => 'test-model',
579 |       getEmbeddingModel: () => 'test-embedding-model',
580 |       getWorkingDir: () => 'test-working-dir',
581 |       getSandbox: () => true,
582 |       getCoreTools: () => ['ls', 'read-file'],
583 |       getApprovalMode: () => 'default',
584 |       getTelemetryLogPromptsEnabled: () => true,
585 |       getFileFilteringRespectGitIgnore: () => true,
586 |       getFileFilteringAllowBuildArtifacts: () => false,
587 |       getDebugMode: () => true,
588 |       getMcpServers: () => ({
589 |         'test-server': {
590 |           command: 'test-command',
591 |         },
592 |       }),
593 |       getQuestion: () => 'test-question',
594 |       getToolRegistry: () => new ToolRegistry(cfg1),
595 |       getFullContext: () => false,
596 |       getUserMemory: () => 'user-memory',
597 |     } as unknown as Config;
598 | 
599 |     const mockGeminiClient = new GeminiClient(cfg2);
600 |     const mockConfig = {
601 |       getSessionId: () => 'test-session-id',
602 |       getTargetDir: () => 'target-dir',
603 |       getGeminiClient: () => mockGeminiClient,
604 |       getUsageStatisticsEnabled: () => true,
605 |       getTelemetryEnabled: () => true,
606 |       getTelemetryLogPromptsEnabled: () => true,
607 |     } as Config;
608 | 
609 |     const mockMetrics = {
610 |       recordToolCallMetrics: vi.fn(),
611 |     };
612 | 
613 |     beforeEach(() => {
614 |       vi.spyOn(metrics, 'recordToolCallMetrics').mockImplementation(
615 |         mockMetrics.recordToolCallMetrics,
616 |       );
617 |       mockLogger.emit.mockReset();
618 |     });
619 | 
620 |     it('should log a tool call with all fields', () => {
621 |       const tool = new EditTool(mockConfig);
622 |       const call: CompletedToolCall = {
623 |         status: 'success',
624 |         request: {
625 |           name: 'test-function',
626 |           args: {
627 |             arg1: 'value1',
628 |             arg2: 2,
629 |           },
630 |           callId: 'test-call-id',
631 |           isClientInitiated: true,
632 |           prompt_id: 'prompt-id-1',
633 |         },
634 |         response: {
635 |           callId: 'test-call-id',
636 |           responseParts: [{ text: 'test-response' }],
637 |           resultDisplay: {
638 |             fileDiff: 'diff',
639 |             fileName: 'file.txt',
640 |             originalContent: 'old content',
641 |             newContent: 'new content',
642 |             diffStat: {
643 |               model_added_lines: 1,
644 |               model_removed_lines: 2,
645 |               model_added_chars: 3,
646 |               model_removed_chars: 4,
647 |               user_added_lines: 5,
648 |               user_removed_lines: 6,
649 |               user_added_chars: 7,
650 |               user_removed_chars: 8,
651 |             },
652 |           },
653 |           error: undefined,
654 |           errorType: undefined,
655 |           contentLength: 13,
656 |         },
657 |         tool,
658 |         invocation: {} as AnyToolInvocation,
659 |         durationMs: 100,
660 |         outcome: ToolConfirmationOutcome.ProceedOnce,
661 |       };
662 |       const event = new ToolCallEvent(call);
663 | 
664 |       logToolCall(mockConfig, event);
665 | 
666 |       expect(mockLogger.emit).toHaveBeenCalledWith({
[TRUNCATED]
```

src/telemetry/loggers.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { LogRecord } from '@opentelemetry/api-logs';
8 | import { logs } from '@opentelemetry/api-logs';
9 | import type { Config } from '../config/config.js';
10 | import { SERVICE_NAME } from './constants.js';
11 | import {
12 |   EVENT_API_ERROR,
13 |   EVENT_API_RESPONSE,
14 |   EVENT_TOOL_CALL,
15 | } from './types.js';
16 | import type {
17 |   ApiErrorEvent,
18 |   ApiRequestEvent,
19 |   ApiResponseEvent,
20 |   FileOperationEvent,
21 |   IdeConnectionEvent,
22 |   StartSessionEvent,
23 |   ToolCallEvent,
24 |   UserPromptEvent,
25 |   FlashFallbackEvent,
26 |   NextSpeakerCheckEvent,
27 |   LoopDetectedEvent,
28 |   LoopDetectionDisabledEvent,
29 |   SlashCommandEvent,
30 |   ConversationFinishedEvent,
31 |   KittySequenceOverflowEvent,
32 |   ChatCompressionEvent,
33 |   MalformedJsonResponseEvent,
34 |   InvalidChunkEvent,
35 |   ContentRetryEvent,
36 |   ContentRetryFailureEvent,
37 |   RipgrepFallbackEvent,
38 |   ToolOutputTruncatedEvent,
39 |   ModelRoutingEvent,
40 |   ExtensionDisableEvent,
41 |   ExtensionEnableEvent,
42 |   ExtensionUninstallEvent,
43 |   ExtensionInstallEvent,
44 |   ModelSlashCommandEvent,
45 |   SmartEditStrategyEvent,
46 |   SmartEditCorrectionEvent,
47 |   AgentStartEvent,
48 |   AgentFinishEvent,
49 |   WebFetchFallbackAttemptEvent,
50 |   ExtensionUpdateEvent,
51 | } from './types.js';
52 | import {
53 |   recordApiErrorMetrics,
54 |   recordToolCallMetrics,
55 |   recordChatCompressionMetrics,
56 |   recordFileOperationMetric,
57 |   recordInvalidChunk,
58 |   recordContentRetry,
59 |   recordContentRetryFailure,
60 |   recordModelRoutingMetrics,
61 |   recordModelSlashCommand,
62 |   getConventionAttributes,
63 |   recordTokenUsageMetrics,
64 |   recordApiResponseMetrics,
65 |   recordAgentRunMetrics,
66 | } from './metrics.js';
67 | import { isTelemetrySdkInitialized } from './sdk.js';
68 | import type { UiEvent } from './uiTelemetry.js';
69 | import { uiTelemetryService } from './uiTelemetry.js';
70 | import { ClearcutLogger } from './clearcut-logger/clearcut-logger.js';
71 | 
72 | export function logCliConfiguration(
73 |   config: Config,
74 |   event: StartSessionEvent,
75 | ): void {
76 |   ClearcutLogger.getInstance(config)?.logStartSessionEvent(event);
77 |   if (!isTelemetrySdkInitialized()) return;
78 | 
79 |   const logger = logs.getLogger(SERVICE_NAME);
80 |   const logRecord: LogRecord = {
81 |     body: event.toLogBody(),
82 |     attributes: event.toOpenTelemetryAttributes(config),
83 |   };
84 |   logger.emit(logRecord);
85 | }
86 | 
87 | export function logUserPrompt(config: Config, event: UserPromptEvent): void {
88 |   ClearcutLogger.getInstance(config)?.logNewPromptEvent(event);
89 |   if (!isTelemetrySdkInitialized()) return;
90 | 
91 |   const logger = logs.getLogger(SERVICE_NAME);
92 |   const logRecord: LogRecord = {
93 |     body: event.toLogBody(),
94 |     attributes: event.toOpenTelemetryAttributes(config),
95 |   };
96 |   logger.emit(logRecord);
97 | }
98 | 
99 | export function logToolCall(config: Config, event: ToolCallEvent): void {
100 |   const uiEvent = {
101 |     ...event,
102 |     'event.name': EVENT_TOOL_CALL,
103 |     'event.timestamp': new Date().toISOString(),
104 |   } as UiEvent;
105 |   uiTelemetryService.addEvent(uiEvent);
106 |   ClearcutLogger.getInstance(config)?.logToolCallEvent(event);
107 |   if (!isTelemetrySdkInitialized()) return;
108 | 
109 |   const logger = logs.getLogger(SERVICE_NAME);
110 |   const logRecord: LogRecord = {
111 |     body: event.toLogBody(),
112 |     attributes: event.toOpenTelemetryAttributes(config),
113 |   };
114 |   logger.emit(logRecord);
115 |   recordToolCallMetrics(config, event.duration_ms, {
116 |     function_name: event.function_name,
117 |     success: event.success,
118 |     decision: event.decision,
119 |     tool_type: event.tool_type,
120 |     ...(event.metadata
121 |       ? {
122 |           model_added_lines: event.metadata['model_added_lines'],
123 |           model_removed_lines: event.metadata['model_removed_lines'],
124 |           user_added_lines: event.metadata['user_added_lines'],
125 |           user_removed_lines: event.metadata['user_removed_lines'],
126 |         }
127 |       : {}),
128 |   });
129 | }
130 | 
131 | export function logToolOutputTruncated(
132 |   config: Config,
133 |   event: ToolOutputTruncatedEvent,
134 | ): void {
135 |   ClearcutLogger.getInstance(config)?.logToolOutputTruncatedEvent(event);
136 |   if (!isTelemetrySdkInitialized()) return;
137 | 
138 |   const logger = logs.getLogger(SERVICE_NAME);
139 |   const logRecord: LogRecord = {
140 |     body: event.toLogBody(),
141 |     attributes: event.toOpenTelemetryAttributes(config),
142 |   };
143 |   logger.emit(logRecord);
144 | }
145 | 
146 | export function logFileOperation(
147 |   config: Config,
148 |   event: FileOperationEvent,
149 | ): void {
150 |   ClearcutLogger.getInstance(config)?.logFileOperationEvent(event);
151 |   if (!isTelemetrySdkInitialized()) return;
152 | 
153 |   const logger = logs.getLogger(SERVICE_NAME);
154 |   const logRecord: LogRecord = {
155 |     body: event.toLogBody(),
156 |     attributes: event.toOpenTelemetryAttributes(config),
157 |   };
158 |   logger.emit(logRecord);
159 | 
160 |   recordFileOperationMetric(config, {
161 |     operation: event.operation,
162 |     lines: event.lines,
163 |     mimetype: event.mimetype,
164 |     extension: event.extension,
165 |     programming_language: event.programming_language,
166 |   });
167 | }
168 | 
169 | export function logApiRequest(config: Config, event: ApiRequestEvent): void {
170 |   ClearcutLogger.getInstance(config)?.logApiRequestEvent(event);
171 |   if (!isTelemetrySdkInitialized()) return;
172 | 
173 |   const logger = logs.getLogger(SERVICE_NAME);
174 |   const logRecord: LogRecord = {
175 |     body: event.toLogBody(),
176 |     attributes: event.toOpenTelemetryAttributes(config),
177 |   };
178 |   logger.emit(logRecord);
179 | }
180 | 
181 | export function logFlashFallback(
182 |   config: Config,
183 |   event: FlashFallbackEvent,
184 | ): void {
185 |   ClearcutLogger.getInstance(config)?.logFlashFallbackEvent();
186 |   if (!isTelemetrySdkInitialized()) return;
187 | 
188 |   const logger = logs.getLogger(SERVICE_NAME);
189 |   const logRecord: LogRecord = {
190 |     body: event.toLogBody(),
191 |     attributes: event.toOpenTelemetryAttributes(config),
192 |   };
193 |   logger.emit(logRecord);
194 | }
195 | 
196 | export function logRipgrepFallback(
197 |   config: Config,
198 |   event: RipgrepFallbackEvent,
199 | ): void {
200 |   ClearcutLogger.getInstance(config)?.logRipgrepFallbackEvent();
201 |   if (!isTelemetrySdkInitialized()) return;
202 | 
203 |   const logger = logs.getLogger(SERVICE_NAME);
204 |   const logRecord: LogRecord = {
205 |     body: event.toLogBody(),
206 |     attributes: event.toOpenTelemetryAttributes(config),
207 |   };
208 |   logger.emit(logRecord);
209 | }
210 | 
211 | export function logApiError(config: Config, event: ApiErrorEvent): void {
212 |   const uiEvent = {
213 |     ...event,
214 |     'event.name': EVENT_API_ERROR,
215 |     'event.timestamp': new Date().toISOString(),
216 |   } as UiEvent;
217 |   uiTelemetryService.addEvent(uiEvent);
218 |   ClearcutLogger.getInstance(config)?.logApiErrorEvent(event);
219 |   if (!isTelemetrySdkInitialized()) return;
220 | 
221 |   const logger = logs.getLogger(SERVICE_NAME);
222 |   const logRecord: LogRecord = {
223 |     body: event.toLogBody(),
224 |     attributes: event.toOpenTelemetryAttributes(config),
225 |   };
226 |   logger.emit(logRecord);
227 |   recordApiErrorMetrics(config, event.duration_ms, {
228 |     model: event.model,
229 |     status_code: event.status_code,
230 |     error_type: event.error_type,
231 |   });
232 | 
233 |   // Record GenAI operation duration for errors
234 |   const conventionAttributes = getConventionAttributes(event);
235 |   recordApiResponseMetrics(config, event.duration_ms, {
236 |     model: event.model,
237 |     status_code: event.status_code,
238 |     genAiAttributes: {
239 |       ...conventionAttributes,
240 |       'error.type': event.error_type || 'unknown',
241 |     },
242 |   });
243 | }
244 | 
245 | export function logApiResponse(config: Config, event: ApiResponseEvent): void {
246 |   const uiEvent = {
247 |     ...event,
248 |     'event.name': EVENT_API_RESPONSE,
249 |     'event.timestamp': new Date().toISOString(),
250 |   } as UiEvent;
251 |   uiTelemetryService.addEvent(uiEvent);
252 |   ClearcutLogger.getInstance(config)?.logApiResponseEvent(event);
253 |   if (!isTelemetrySdkInitialized()) return;
254 | 
255 |   const logger = logs.getLogger(SERVICE_NAME);
256 |   const logRecord: LogRecord = {
257 |     body: event.toLogBody(),
258 |     attributes: event.toOpenTelemetryAttributes(config),
259 |   };
260 |   logger.emit(logRecord);
261 | 
262 |   const conventionAttributes = getConventionAttributes(event);
263 | 
264 |   recordApiResponseMetrics(config, event.duration_ms, {
265 |     model: event.model,
266 |     status_code: event.status_code,
267 |     genAiAttributes: conventionAttributes,
268 |   });
269 | 
270 |   const tokenUsageData = [
271 |     { count: event.input_token_count, type: 'input' as const },
272 |     { count: event.output_token_count, type: 'output' as const },
273 |     { count: event.cached_content_token_count, type: 'cache' as const },
274 |     { count: event.thoughts_token_count, type: 'thought' as const },
275 |     { count: event.tool_token_count, type: 'tool' as const },
276 |   ];
277 | 
278 |   for (const { count, type } of tokenUsageData) {
279 |     recordTokenUsageMetrics(config, count, {
280 |       model: event.model,
281 |       type,
282 |       genAiAttributes: conventionAttributes,
283 |     });
284 |   }
285 | }
286 | 
287 | export function logLoopDetected(
288 |   config: Config,
289 |   event: LoopDetectedEvent,
290 | ): void {
291 |   ClearcutLogger.getInstance(config)?.logLoopDetectedEvent(event);
292 |   if (!isTelemetrySdkInitialized()) return;
293 | 
294 |   const logger = logs.getLogger(SERVICE_NAME);
295 |   const logRecord: LogRecord = {
296 |     body: event.toLogBody(),
297 |     attributes: event.toOpenTelemetryAttributes(config),
298 |   };
299 |   logger.emit(logRecord);
300 | }
301 | 
302 | export function logLoopDetectionDisabled(
303 |   config: Config,
304 |   event: LoopDetectionDisabledEvent,
305 | ): void {
306 |   ClearcutLogger.getInstance(config)?.logLoopDetectionDisabledEvent();
307 |   if (!isTelemetrySdkInitialized()) return;
308 | 
309 |   const logger = logs.getLogger(SERVICE_NAME);
310 |   const logRecord: LogRecord = {
311 |     body: event.toLogBody(),
312 |     attributes: event.toOpenTelemetryAttributes(config),
313 |   };
314 |   logger.emit(logRecord);
315 | }
316 | 
317 | export function logNextSpeakerCheck(
318 |   config: Config,
319 |   event: NextSpeakerCheckEvent,
320 | ): void {
321 |   ClearcutLogger.getInstance(config)?.logNextSpeakerCheck(event);
322 |   if (!isTelemetrySdkInitialized()) return;
323 | 
324 |   const logger = logs.getLogger(SERVICE_NAME);
325 |   const logRecord: LogRecord = {
326 |     body: event.toLogBody(),
327 |     attributes: event.toOpenTelemetryAttributes(config),
328 |   };
329 |   logger.emit(logRecord);
330 | }
331 | 
332 | export function logSlashCommand(
333 |   config: Config,
334 |   event: SlashCommandEvent,
335 | ): void {
336 |   ClearcutLogger.getInstance(config)?.logSlashCommandEvent(event);
337 |   if (!isTelemetrySdkInitialized()) return;
338 | 
339 |   const logger = logs.getLogger(SERVICE_NAME);
340 |   const logRecord: LogRecord = {
341 |     body: event.toLogBody(),
342 |     attributes: event.toOpenTelemetryAttributes(config),
343 |   };
344 |   logger.emit(logRecord);
345 | }
346 | 
347 | export function logIdeConnection(
348 |   config: Config,
349 |   event: IdeConnectionEvent,
350 | ): void {
351 |   ClearcutLogger.getInstance(config)?.logIdeConnectionEvent(event);
352 |   if (!isTelemetrySdkInitialized()) return;
353 | 
354 |   const logger = logs.getLogger(SERVICE_NAME);
355 |   const logRecord: LogRecord = {
356 |     body: event.toLogBody(),
357 |     attributes: event.toOpenTelemetryAttributes(config),
358 |   };
359 |   logger.emit(logRecord);
360 | }
361 | 
362 | export function logConversationFinishedEvent(
363 |   config: Config,
364 |   event: ConversationFinishedEvent,
365 | ): void {
366 |   ClearcutLogger.getInstance(config)?.logConversationFinishedEvent(event);
367 |   if (!isTelemetrySdkInitialized()) return;
368 | 
369 |   const logger = logs.getLogger(SERVICE_NAME);
370 |   const logRecord: LogRecord = {
371 |     body: event.toLogBody(),
372 |     attributes: event.toOpenTelemetryAttributes(config),
373 |   };
374 |   logger.emit(logRecord);
375 | }
376 | 
377 | export function logChatCompression(
378 |   config: Config,
379 |   event: ChatCompressionEvent,
380 | ): void {
381 |   ClearcutLogger.getInstance(config)?.logChatCompressionEvent(event);
382 | 
383 |   const logger = logs.getLogger(SERVICE_NAME);
384 |   const logRecord: LogRecord = {
385 |     body: event.toLogBody(),
386 |     attributes: event.toOpenTelemetryAttributes(config),
387 |   };
388 |   logger.emit(logRecord);
389 | 
390 |   recordChatCompressionMetrics(config, {
391 |     tokens_before: event.tokens_before,
392 |     tokens_after: event.tokens_after,
393 |   });
394 | }
395 | 
396 | export function logKittySequenceOverflow(
397 |   config: Config,
398 |   event: KittySequenceOverflowEvent,
399 | ): void {
400 |   ClearcutLogger.getInstance(config)?.logKittySequenceOverflowEvent(event);
401 |   if (!isTelemetrySdkInitialized()) return;
402 |   const logger = logs.getLogger(SERVICE_NAME);
403 |   const logRecord: LogRecord = {
404 |     body: event.toLogBody(),
405 |     attributes: event.toOpenTelemetryAttributes(config),
406 |   };
407 |   logger.emit(logRecord);
408 | }
409 | 
410 | export function logMalformedJsonResponse(
411 |   config: Config,
412 |   event: MalformedJsonResponseEvent,
413 | ): void {
414 |   ClearcutLogger.getInstance(config)?.logMalformedJsonResponseEvent(event);
415 |   if (!isTelemetrySdkInitialized()) return;
416 | 
417 |   const logger = logs.getLogger(SERVICE_NAME);
418 |   const logRecord: LogRecord = {
419 |     body: event.toLogBody(),
420 |     attributes: event.toOpenTelemetryAttributes(config),
421 |   };
422 |   logger.emit(logRecord);
423 | }
424 | 
425 | export function logInvalidChunk(
426 |   config: Config,
427 |   event: InvalidChunkEvent,
428 | ): void {
429 |   ClearcutLogger.getInstance(config)?.logInvalidChunkEvent(event);
430 |   if (!isTelemetrySdkInitialized()) return;
431 | 
432 |   const logger = logs.getLogger(SERVICE_NAME);
433 |   const logRecord: LogRecord = {
434 |     body: event.toLogBody(),
435 |     attributes: event.toOpenTelemetryAttributes(config),
436 |   };
437 |   logger.emit(logRecord);
438 |   recordInvalidChunk(config);
439 | }
440 | 
441 | export function logContentRetry(
442 |   config: Config,
443 |   event: ContentRetryEvent,
444 | ): void {
445 |   ClearcutLogger.getInstance(config)?.logContentRetryEvent(event);
446 |   if (!isTelemetrySdkInitialized()) return;
447 | 
448 |   const logger = logs.getLogger(SERVICE_NAME);
449 |   const logRecord: LogRecord = {
450 |     body: event.toLogBody(),
451 |     attributes: event.toOpenTelemetryAttributes(config),
452 |   };
453 |   logger.emit(logRecord);
454 |   recordContentRetry(config);
455 | }
456 | 
457 | export function logContentRetryFailure(
458 |   config: Config,
459 |   event: ContentRetryFailureEvent,
460 | ): void {
461 |   ClearcutLogger.getInstance(config)?.logContentRetryFailureEvent(event);
462 |   if (!isTelemetrySdkInitialized()) return;
463 | 
464 |   const logger = logs.getLogger(SERVICE_NAME);
465 |   const logRecord: LogRecord = {
466 |     body: event.toLogBody(),
467 |     attributes: event.toOpenTelemetryAttributes(config),
468 |   };
469 |   logger.emit(logRecord);
470 |   recordContentRetryFailure(config);
471 | }
472 | 
473 | export function logModelRouting(
474 |   config: Config,
475 |   event: ModelRoutingEvent,
476 | ): void {
477 |   ClearcutLogger.getInstance(config)?.logModelRoutingEvent(event);
478 |   if (!isTelemetrySdkInitialized()) return;
479 | 
480 |   const logger = logs.getLogger(SERVICE_NAME);
481 |   const logRecord: LogRecord = {
482 |     body: event.toLogBody(),
483 |     attributes: event.toOpenTelemetryAttributes(config),
484 |   };
485 |   logger.emit(logRecord);
486 |   recordModelRoutingMetrics(config, event);
487 | }
488 | 
489 | export function logModelSlashCommand(
490 |   config: Config,
491 |   event: ModelSlashCommandEvent,
492 | ): void {
493 |   ClearcutLogger.getInstance(config)?.logModelSlashCommandEvent(event);
494 |   if (!isTelemetrySdkInitialized()) return;
495 | 
496 |   const logger = logs.getLogger(SERVICE_NAME);
497 |   const logRecord: LogRecord = {
498 |     body: event.toLogBody(),
499 |     attributes: event.toOpenTelemetryAttributes(config),
500 |   };
501 |   logger.emit(logRecord);
502 |   recordModelSlashCommand(config, event);
503 | }
504 | 
505 | export function logExtensionInstallEvent(
506 |   config: Config,
507 |   event: ExtensionInstallEvent,
508 | ): void {
509 |   ClearcutLogger.getInstance(config)?.logExtensionInstallEvent(event);
510 |   if (!isTelemetrySdkInitialized()) return;
511 | 
512 |   const logger = logs.getLogger(SERVICE_NAME);
513 |   const logRecord: LogRecord = {
514 |     body: event.toLogBody(),
515 |     attributes: event.toOpenTelemetryAttributes(config),
516 |   };
517 |   logger.emit(logRecord);
518 | }
519 | 
520 | export function logExtensionUninstall(
521 |   config: Config,
522 |   event: ExtensionUninstallEvent,
523 | ): void {
524 |   ClearcutLogger.getInstance(config)?.logExtensionUninstallEvent(event);
525 |   if (!isTelemetrySdkInitialized()) return;
526 | 
527 |   const logger = logs.getLogger(SERVICE_NAME);
528 |   const logRecord: LogRecord = {
529 |     body: event.toLogBody(),
530 |     attributes: event.toOpenTelemetryAttributes(config),
531 |   };
532 |   logger.emit(logRecord);
533 | }
534 | 
535 | export function logExtensionUpdateEvent(
536 |   config: Config,
537 |   event: ExtensionUpdateEvent,
538 | ): void {
539 |   ClearcutLogger.getInstance(config)?.logExtensionUpdateEvent(event);
540 |   if (!isTelemetrySdkInitialized()) return;
541 | 
542 |   const logger = logs.getLogger(SERVICE_NAME);
543 |   const logRecord: LogRecord = {
544 |     body: event.toLogBody(),
545 |     attributes: event.toOpenTelemetryAttributes(config),
546 |   };
547 |   logger.emit(logRecord);
548 | }
549 | 
550 | export function logExtensionEnable(
551 |   config: Config,
552 |   event: ExtensionEnableEvent,
553 | ): void {
554 |   ClearcutLogger.getInstance(config)?.logExtensionEnableEvent(event);
555 |   if (!isTelemetrySdkInitialized()) return;
556 | 
557 |   const logger = logs.getLogger(SERVICE_NAME);
558 |   const logRecord: LogRecord = {
559 |     body: event.toLogBody(),
560 |     attributes: event.toOpenTelemetryAttributes(config),
561 |   };
562 |   logger.emit(logRecord);
563 | }
564 | 
565 | export function logExtensionDisable(
566 |   config: Config,
567 |   event: ExtensionDisableEvent,
568 | ): void {
569 |   ClearcutLogger.getInstance(config)?.logExtensionDisableEvent(event);
570 |   if (!isTelemetrySdkInitialized()) return;
571 | 
572 |   const logger = logs.getLogger(SERVICE_NAME);
573 |   const logRecord: LogRecord = {
574 |     body: event.toLogBody(),
575 |     attributes: event.toOpenTelemetryAttributes(config),
576 |   };
577 |   logger.emit(logRecord);
578 | }
579 | 
580 | export function logSmartEditStrategy(
581 |   config: Config,
582 |   event: SmartEditStrategyEvent,
583 | ): void {
584 |   ClearcutLogger.getInstance(config)?.logSmartEditStrategyEvent(event);
585 |   if (!isTelemetrySdkInitialized()) return;
586 | 
587 |   const logger = logs.getLogger(SERVICE_NAME);
588 |   const logRecord: LogRecord = {
589 |     body: event.toLogBody(),
590 |     attributes: event.toOpenTelemetryAttributes(config),
591 |   };
592 |   logger.emit(logRecord);
593 | }
594 | 
595 | export function logSmartEditCorrectionEvent(
596 |   config: Config,
597 |   event: SmartEditCorrectionEvent,
598 | ): void {
599 |   ClearcutLogger.getInstance(config)?.logSmartEditCorrectionEvent(event);
600 |   if (!isTelemetrySdkInitialized()) return;
601 | 
602 |   const logger = logs.getLogger(SERVICE_NAME);
603 |   const logRecord: LogRecord = {
604 |     body: event.toLogBody(),
605 |     attributes: event.toOpenTelemetryAttributes(config),
606 |   };
607 |   logger.emit(logRecord);
608 | }
609 | 
610 | export function logAgentStart(config: Config, event: AgentStartEvent): void {
611 |   ClearcutLogger.getInstance(config)?.logAgentStartEvent(event);
612 |   if (!isTelemetrySdkInitialized()) return;
613 | 
614 |   const logger = logs.getLogger(SERVICE_NAME);
615 |   const logRecord: LogRecord = {
616 |     body: event.toLogBody(),
617 |     attributes: event.toOpenTelemetryAttributes(config),
618 |   };
619 |   logger.emit(logRecord);
620 | }
621 | 
622 | export function logAgentFinish(config: Config, event: AgentFinishEvent): void {
623 |   ClearcutLogger.getInstance(config)?.logAgentFinishEvent(event);
624 |   if (!isTelemetrySdkInitialized()) return;
625 | 
626 |   const logger = logs.getLogger(SERVICE_NAME);
627 |   const logRecord: LogRecord = {
628 |     body: event.toLogBody(),
629 |     attributes: event.toOpenTelemetryAttributes(config),
630 |   };
631 |   logger.emit(logRecord);
632 | 
633 |   recordAgentRunMetrics(config, event);
634 | }
635 | 
636 | export function logWebFetchFallbackAttempt(
637 |   config: Config,
638 |   event: WebFetchFallbackAttemptEvent,
639 | ): void {
640 |   ClearcutLogger.getInstance(config)?.logWebFetchFallbackAttemptEvent(event);
641 |   if (!isTelemetrySdkInitialized()) return;
642 | 
643 |   const logger = logs.getLogger(SERVICE_NAME);
644 |   const logRecord: LogRecord = {
645 |     body: event.toLogBody(),
646 |     attributes: event.toOpenTelemetryAttributes(config),
647 |   };
648 |   logger.emit(logRecord);
649 | }
```

src/telemetry/memory-monitor.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
8 | import v8 from 'node:v8';
9 | import process from 'node:process';
10 | import {
11 |   MemoryMonitor,
12 |   initializeMemoryMonitor,
13 |   getMemoryMonitor,
14 |   recordCurrentMemoryUsage,
15 |   startGlobalMemoryMonitoring,
16 |   stopGlobalMemoryMonitoring,
17 |   _resetGlobalMemoryMonitorForTests,
18 | } from './memory-monitor.js';
19 | import type { Config } from '../config/config.js';
20 | import { recordMemoryUsage, isPerformanceMonitoringActive } from './metrics.js';
21 | import { HighWaterMarkTracker } from './high-water-mark-tracker.js';
22 | import { RateLimiter } from './rate-limiter.js';
23 | 
24 | // Mock dependencies
25 | vi.mock('./metrics.js', () => ({
26 |   recordMemoryUsage: vi.fn(),
27 |   isPerformanceMonitoringActive: vi.fn(),
28 |   MemoryMetricType: {
29 |     HEAP_USED: 'heap_used',
30 |     HEAP_TOTAL: 'heap_total',
31 |     EXTERNAL: 'external',
32 |     RSS: 'rss',
33 |   },
34 | }));
35 | 
36 | // Mock Node.js modules
37 | vi.mock('node:v8', () => ({
38 |   default: {
39 |     getHeapStatistics: vi.fn(),
40 |     getHeapSpaceStatistics: vi.fn(),
41 |   },
42 | }));
43 | 
44 | vi.mock('node:process', () => ({
45 |   default: {
46 |     memoryUsage: vi.fn(),
47 |     cpuUsage: vi.fn(),
48 |     uptime: vi.fn(),
49 |   },
50 | }));
51 | 
52 | const mockRecordMemoryUsage = vi.mocked(recordMemoryUsage);
53 | const mockIsPerformanceMonitoringActive = vi.mocked(
54 |   isPerformanceMonitoringActive,
55 | );
56 | const mockV8GetHeapStatistics = vi.mocked(v8.getHeapStatistics);
57 | const mockV8GetHeapSpaceStatistics = vi.mocked(v8.getHeapSpaceStatistics);
58 | const mockProcessMemoryUsage = vi.mocked(process.memoryUsage);
59 | const mockProcessCpuUsage = vi.mocked(process.cpuUsage);
60 | const mockProcessUptime = vi.mocked(process.uptime);
61 | 
62 | // Mock config object
63 | const mockConfig = {
64 |   getSessionId: () => 'test-session-id',
65 |   getTelemetryEnabled: () => true,
66 | } as unknown as Config;
67 | 
68 | // Test data
69 | const mockMemoryUsage = {
70 |   heapUsed: 15728640, // ~15MB
71 |   heapTotal: 31457280, // ~30MB
72 |   external: 2097152, // ~2MB
73 |   rss: 41943040, // ~40MB
74 |   arrayBuffers: 1048576, // ~1MB
75 | };
76 | 
77 | const mockHeapStatistics = {
78 |   heap_size_limit: 536870912, // ~512MB
79 |   total_heap_size: 31457280,
80 |   total_heap_size_executable: 4194304, // ~4MB
81 |   total_physical_size: 31457280,
82 |   total_available_size: 1000000000, // ~1GB
83 |   used_heap_size: 15728640,
84 |   malloced_memory: 8192,
85 |   peak_malloced_memory: 16384,
86 |   does_zap_garbage: 0 as v8.DoesZapCodeSpaceFlag,
87 |   number_of_native_contexts: 1,
88 |   number_of_detached_contexts: 0,
89 |   total_global_handles_size: 8192,
90 |   used_global_handles_size: 4096,
91 |   external_memory: 2097152,
92 | };
93 | 
94 | const mockHeapSpaceStatistics = [
95 |   {
96 |     space_name: 'new_space',
97 |     space_size: 8388608,
98 |     space_used_size: 4194304,
99 |     space_available_size: 4194304,
100 |     physical_space_size: 8388608,
101 |   },
102 |   {
103 |     space_name: 'old_space',
104 |     space_size: 16777216,
105 |     space_used_size: 8388608,
106 |     space_available_size: 8388608,
107 |     physical_space_size: 16777216,
108 |   },
109 | ];
110 | 
111 | const mockCpuUsage = {
112 |   user: 1000000, // 1 second
113 |   system: 500000, // 0.5 seconds
114 | };
115 | 
116 | describe('MemoryMonitor', () => {
117 |   beforeEach(() => {
118 |     vi.useFakeTimers();
119 |     vi.setSystemTime(new Date('2025-01-01T00:00:00.000Z'));
120 | 
121 |     // Setup default mocks
122 |     mockIsPerformanceMonitoringActive.mockReturnValue(true);
123 |     mockProcessMemoryUsage.mockReturnValue(mockMemoryUsage);
124 |     mockV8GetHeapStatistics.mockReturnValue(mockHeapStatistics);
125 |     mockV8GetHeapSpaceStatistics.mockReturnValue(mockHeapSpaceStatistics);
126 |     mockProcessCpuUsage.mockReturnValue(mockCpuUsage);
127 |     mockProcessUptime.mockReturnValue(123.456);
128 |   });
129 | 
130 |   afterEach(() => {
131 |     vi.restoreAllMocks();
132 |     vi.useRealTimers();
133 | 
134 |     _resetGlobalMemoryMonitorForTests();
135 |   });
136 | 
137 |   describe('MemoryMonitor Class', () => {
138 |     describe('constructor', () => {
139 |       it('should create a new MemoryMonitor instance without config to avoid multi-session attribution', () => {
140 |         const monitor = new MemoryMonitor();
141 |         expect(monitor).toBeInstanceOf(MemoryMonitor);
142 |       });
143 |     });
144 | 
145 |     describe('takeSnapshot', () => {
146 |       it('should take a memory snapshot and record metrics when performance monitoring is active', () => {
147 |         const monitor = new MemoryMonitor();
148 | 
149 |         const snapshot = monitor.takeSnapshot('test_context', mockConfig);
150 | 
151 |         expect(snapshot).toEqual({
152 |           timestamp: Date.now(),
153 |           heapUsed: mockMemoryUsage.heapUsed,
154 |           heapTotal: mockMemoryUsage.heapTotal,
155 |           external: mockMemoryUsage.external,
156 |           rss: mockMemoryUsage.rss,
157 |           arrayBuffers: mockMemoryUsage.arrayBuffers,
158 |           heapSizeLimit: mockHeapStatistics.heap_size_limit,
159 |         });
160 | 
161 |         // Verify metrics were recorded
162 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
163 |           mockConfig,
164 |           mockMemoryUsage.heapUsed,
165 |           {
166 |             memory_type: 'heap_used',
167 |             component: 'test_context',
168 |           },
169 |         );
170 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
171 |           mockConfig,
172 |           mockMemoryUsage.heapTotal,
173 |           {
174 |             memory_type: 'heap_total',
175 |             component: 'test_context',
176 |           },
177 |         );
178 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
179 |           mockConfig,
180 |           mockMemoryUsage.external,
181 |           {
182 |             memory_type: 'external',
183 |             component: 'test_context',
184 |           },
185 |         );
186 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
187 |           mockConfig,
188 |           mockMemoryUsage.rss,
189 |           {
190 |             memory_type: 'rss',
191 |             component: 'test_context',
192 |           },
193 |         );
194 |       });
195 | 
196 |       it('should not record metrics when performance monitoring is inactive', () => {
197 |         mockIsPerformanceMonitoringActive.mockReturnValue(false);
198 |         const monitor = new MemoryMonitor();
199 | 
200 |         const snapshot = monitor.takeSnapshot('test_context', mockConfig);
201 | 
202 |         expect(snapshot).toEqual({
203 |           timestamp: Date.now(),
204 |           heapUsed: mockMemoryUsage.heapUsed,
205 |           heapTotal: mockMemoryUsage.heapTotal,
206 |           external: mockMemoryUsage.external,
207 |           rss: mockMemoryUsage.rss,
208 |           arrayBuffers: mockMemoryUsage.arrayBuffers,
209 |           heapSizeLimit: mockHeapStatistics.heap_size_limit,
210 |         });
211 | 
212 |         // Verify no metrics were recorded
213 |         expect(mockRecordMemoryUsage).not.toHaveBeenCalled();
214 |       });
215 |     });
216 | 
217 |     describe('getCurrentMemoryUsage', () => {
218 |       it('should return current memory usage without recording metrics', () => {
219 |         const monitor = new MemoryMonitor();
220 | 
221 |         const usage = monitor.getCurrentMemoryUsage();
222 | 
223 |         expect(usage).toEqual({
224 |           timestamp: Date.now(),
225 |           heapUsed: mockMemoryUsage.heapUsed,
226 |           heapTotal: mockMemoryUsage.heapTotal,
227 |           external: mockMemoryUsage.external,
228 |           rss: mockMemoryUsage.rss,
229 |           arrayBuffers: mockMemoryUsage.arrayBuffers,
230 |           heapSizeLimit: mockHeapStatistics.heap_size_limit,
231 |         });
232 | 
233 |         // Verify no metrics were recorded
234 |         expect(mockRecordMemoryUsage).not.toHaveBeenCalled();
235 |       });
236 |     });
237 | 
238 |     describe('start and stop', () => {
239 |       it('should start and stop memory monitoring with proper lifecycle', () => {
240 |         const monitor = new MemoryMonitor();
241 |         const intervalMs = 1000;
242 | 
243 |         // Start monitoring
244 |         monitor.start(mockConfig, intervalMs);
245 | 
246 |         // Verify initial snapshot was taken
247 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
248 |           mockConfig,
249 |           mockMemoryUsage.heapUsed,
250 |           {
251 |             memory_type: 'heap_used',
252 |             component: 'monitoring_start',
253 |           },
254 |         );
255 | 
256 |         // Fast-forward time to trigger periodic snapshot
257 |         vi.advanceTimersByTime(intervalMs);
258 | 
259 |         // Verify monitoring_start snapshot was taken (multiple metrics)
260 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
261 |           mockConfig,
262 |           expect.any(Number),
263 |           {
264 |             memory_type: 'heap_used',
265 |             component: 'monitoring_start',
266 |           },
267 |         );
268 | 
269 |         // Stop monitoring
270 |         monitor.stop(mockConfig);
271 | 
272 |         // Verify final snapshot was taken
273 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
274 |           mockConfig,
275 |           mockMemoryUsage.heapUsed,
276 |           {
277 |             memory_type: 'heap_used',
278 |             component: 'monitoring_stop',
279 |           },
280 |         );
281 |       });
282 | 
283 |       it('should not start monitoring when performance monitoring is inactive', () => {
284 |         mockIsPerformanceMonitoringActive.mockReturnValue(false);
285 |         const monitor = new MemoryMonitor();
286 | 
287 |         monitor.start(mockConfig, 1000);
288 | 
289 |         // Verify no snapshots were taken
290 |         expect(mockRecordMemoryUsage).not.toHaveBeenCalled();
291 |       });
292 | 
293 |       it('should not start monitoring when already running', () => {
294 |         const monitor = new MemoryMonitor();
295 | 
296 |         // Start monitoring twice
297 |         monitor.start(mockConfig, 1000);
298 |         const initialCallCount = mockRecordMemoryUsage.mock.calls.length;
299 | 
300 |         monitor.start(mockConfig, 1000);
301 | 
302 |         // Verify no additional snapshots were taken
303 |         expect(mockRecordMemoryUsage).toHaveBeenCalledTimes(initialCallCount);
304 |       });
305 | 
306 |       it('should handle stop when not running', () => {
307 |         const monitor = new MemoryMonitor();
308 | 
309 |         // Should not throw error
310 |         expect(() => monitor.stop(mockConfig)).not.toThrow();
311 |       });
312 | 
313 |       it('should stop without taking final snapshot when no config provided', () => {
314 |         const monitor = new MemoryMonitor();
315 | 
316 |         monitor.start(mockConfig, 1000);
317 |         const callsBeforeStop = mockRecordMemoryUsage.mock.calls.length;
318 | 
319 |         monitor.stop(); // No config provided
320 | 
321 |         // Verify no final snapshot was taken
322 |         expect(mockRecordMemoryUsage).toHaveBeenCalledTimes(callsBeforeStop);
323 |       });
324 | 
325 |       it('should periodically cleanup tracker state to prevent growth', () => {
326 |         const trackerCleanupSpy = vi.spyOn(
327 |           HighWaterMarkTracker.prototype,
328 |           'cleanup',
329 |         );
330 |         const rateLimiterCleanupSpy = vi.spyOn(
331 |           RateLimiter.prototype,
332 |           'cleanup',
333 |         );
334 | 
335 |         const monitor = new MemoryMonitor();
336 |         monitor.start(mockConfig, 1000);
337 | 
338 |         trackerCleanupSpy.mockClear();
339 |         rateLimiterCleanupSpy.mockClear();
340 | 
341 |         // Advance timers beyond the cleanup interval (15 minutes) to trigger cleanup
342 |         vi.advanceTimersByTime(16 * 60 * 1000);
343 | 
344 |         expect(trackerCleanupSpy).toHaveBeenCalled();
345 |         expect(rateLimiterCleanupSpy).toHaveBeenCalled();
346 | 
347 |         monitor.stop(mockConfig);
348 | 
349 |         trackerCleanupSpy.mockRestore();
350 |         rateLimiterCleanupSpy.mockRestore();
351 |       });
352 |     });
353 | 
354 |     describe('getMemoryGrowth', () => {
355 |       it('should calculate memory growth between snapshots', () => {
356 |         const monitor = new MemoryMonitor();
357 | 
358 |         // Take initial snapshot
359 |         monitor.takeSnapshot('initial', mockConfig);
360 | 
361 |         // Change memory usage
362 |         const newMemoryUsage = {
363 |           ...mockMemoryUsage,
364 |           heapUsed: mockMemoryUsage.heapUsed + 1048576, // +1MB
365 |           rss: mockMemoryUsage.rss + 2097152, // +2MB
366 |         };
367 |         mockProcessMemoryUsage.mockReturnValue(newMemoryUsage);
368 | 
369 |         const growth = monitor.getMemoryGrowth();
370 | 
371 |         expect(growth).toEqual({
372 |           heapUsed: 1048576,
373 |           heapTotal: 0,
374 |           external: 0,
375 |           rss: 2097152,
376 |           arrayBuffers: 0,
377 |         });
378 |       });
379 | 
380 |       it('should return null when no previous snapshot exists', () => {
381 |         const monitor = new MemoryMonitor();
382 | 
383 |         const growth = monitor.getMemoryGrowth();
384 | 
385 |         expect(growth).toBeNull();
386 |       });
387 |     });
388 | 
389 |     describe('checkMemoryThreshold', () => {
390 |       it('should return true when memory usage exceeds threshold', () => {
391 |         const monitor = new MemoryMonitor();
392 |         const thresholdMB = 10; // 10MB threshold
393 | 
394 |         const exceeds = monitor.checkMemoryThreshold(thresholdMB);
395 | 
396 |         expect(exceeds).toBe(true); // heapUsed is ~15MB
397 |       });
398 | 
399 |       it('should return false when memory usage is below threshold', () => {
400 |         const monitor = new MemoryMonitor();
401 |         const thresholdMB = 20; // 20MB threshold
402 | 
403 |         const exceeds = monitor.checkMemoryThreshold(thresholdMB);
404 | 
405 |         expect(exceeds).toBe(false); // heapUsed is ~15MB
406 |       });
407 |     });
408 | 
409 |     describe('getMemoryUsageSummary', () => {
410 |       it('should return memory usage summary in MB with proper rounding', () => {
411 |         const monitor = new MemoryMonitor();
412 | 
413 |         const summary = monitor.getMemoryUsageSummary();
414 | 
415 |         expect(summary).toEqual({
416 |           heapUsedMB: 15.0, // 15728640 bytes = 15MB
417 |           heapTotalMB: 30.0, // 31457280 bytes = 30MB
418 |           externalMB: 2.0, // 2097152 bytes = 2MB
419 |           rssMB: 40.0, // 41943040 bytes = 40MB
420 |           heapSizeLimitMB: 512.0, // 536870912 bytes = 512MB
421 |         });
422 |       });
423 |     });
424 | 
425 |     describe('getHeapStatistics', () => {
426 |       it('should return V8 heap statistics', () => {
427 |         const monitor = new MemoryMonitor();
428 | 
429 |         const stats = monitor.getHeapStatistics();
430 | 
431 |         expect(stats).toBe(mockHeapStatistics);
432 |         expect(mockV8GetHeapStatistics).toHaveBeenCalled();
433 |       });
434 |     });
435 | 
436 |     describe('getHeapSpaceStatistics', () => {
437 |       it('should return V8 heap space statistics', () => {
438 |         const monitor = new MemoryMonitor();
439 | 
440 |         const stats = monitor.getHeapSpaceStatistics();
441 | 
442 |         expect(stats).toBe(mockHeapSpaceStatistics);
443 |         expect(mockV8GetHeapSpaceStatistics).toHaveBeenCalled();
444 |       });
445 |     });
446 | 
447 |     describe('getProcessMetrics', () => {
448 |       it('should return process CPU and memory metrics', () => {
449 |         const monitor = new MemoryMonitor();
450 | 
451 |         const metrics = monitor.getProcessMetrics();
452 | 
453 |         expect(metrics).toEqual({
454 |           cpuUsage: mockCpuUsage,
455 |           memoryUsage: mockMemoryUsage,
456 |           uptime: 123.456,
457 |         });
458 |       });
459 |     });
460 | 
461 |     describe('recordComponentMemoryUsage', () => {
462 |       it('should record memory usage for specific component', () => {
463 |         const monitor = new MemoryMonitor();
464 | 
465 |         const snapshot = monitor.recordComponentMemoryUsage(
466 |           mockConfig,
467 |           'test_component',
468 |         );
469 | 
470 |         expect(snapshot).toEqual({
471 |           timestamp: Date.now(),
472 |           heapUsed: mockMemoryUsage.heapUsed,
473 |           heapTotal: mockMemoryUsage.heapTotal,
474 |           external: mockMemoryUsage.external,
475 |           rss: mockMemoryUsage.rss,
476 |           arrayBuffers: mockMemoryUsage.arrayBuffers,
477 |           heapSizeLimit: mockHeapStatistics.heap_size_limit,
478 |         });
479 | 
480 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
481 |           mockConfig,
482 |           mockMemoryUsage.heapUsed,
483 |           {
484 |             memory_type: 'heap_used',
485 |             component: 'test_component',
486 |           },
487 |         );
488 |       });
489 | 
490 |       it('should record memory usage for component with operation', () => {
491 |         const monitor = new MemoryMonitor();
492 | 
493 |         monitor.recordComponentMemoryUsage(
494 |           mockConfig,
495 |           'test_component',
496 |           'test_operation',
497 |         );
498 | 
499 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
500 |           mockConfig,
501 |           mockMemoryUsage.heapUsed,
502 |           {
503 |             memory_type: 'heap_used',
504 |             component: 'test_component_test_operation',
505 |           },
506 |         );
507 |       });
508 |     });
509 | 
510 |     describe('destroy', () => {
511 |       it('should stop monitoring and cleanup resources', () => {
512 |         const monitor = new MemoryMonitor();
513 | 
514 |         monitor.start(mockConfig, 1000);
515 |         monitor.destroy();
516 | 
517 |         // Fast-forward time to ensure no more periodic snapshots
518 |         const callsBeforeDestroy = mockRecordMemoryUsage.mock.calls.length;
519 |         vi.advanceTimersByTime(2000);
520 | 
521 |         expect(mockRecordMemoryUsage).toHaveBeenCalledTimes(callsBeforeDestroy);
522 |       });
523 |     });
524 |   });
525 | 
526 |   describe('Global Memory Monitor Functions', () => {
527 |     describe('initializeMemoryMonitor', () => {
528 |       it('should create singleton instance', () => {
529 |         const monitor1 = initializeMemoryMonitor();
530 |         const monitor2 = initializeMemoryMonitor();
531 | 
532 |         expect(monitor1).toBe(monitor2);
533 |         expect(monitor1).toBeInstanceOf(MemoryMonitor);
534 |       });
535 |     });
536 | 
537 |     describe('getMemoryMonitor', () => {
538 |       it('should return null when not initialized', () => {
539 |         _resetGlobalMemoryMonitorForTests();
540 |         expect(getMemoryMonitor()).toBeNull();
541 |       });
542 | 
543 |       it('should return initialized monitor', () => {
544 |         const initialized = initializeMemoryMonitor();
545 |         const retrieved = getMemoryMonitor();
546 | 
547 |         expect(retrieved).toBe(initialized);
548 |       });
549 |     });
550 | 
551 |     describe('recordCurrentMemoryUsage', () => {
552 |       it('should initialize monitor and take snapshot', () => {
553 |         const snapshot = recordCurrentMemoryUsage(mockConfig, 'test_context');
554 | 
555 |         expect(snapshot).toEqual({
556 |           timestamp: Date.now(),
557 |           heapUsed: mockMemoryUsage.heapUsed,
558 |           heapTotal: mockMemoryUsage.heapTotal,
559 |           external: mockMemoryUsage.external,
560 |           rss: mockMemoryUsage.rss,
561 |           arrayBuffers: mockMemoryUsage.arrayBuffers,
562 |           heapSizeLimit: mockHeapStatistics.heap_size_limit,
563 |         });
564 | 
565 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
566 |           mockConfig,
567 |           mockMemoryUsage.heapUsed,
568 |           {
569 |             memory_type: 'heap_used',
570 |             component: 'test_context',
571 |           },
572 |         );
573 |       });
574 |     });
575 | 
576 |     describe('startGlobalMemoryMonitoring', () => {
577 |       it('should initialize and start global monitoring', () => {
578 |         startGlobalMemoryMonitoring(mockConfig, 1000);
579 | 
580 |         // Verify initial snapshot
581 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
582 |           mockConfig,
583 |           mockMemoryUsage.heapUsed,
584 |           {
585 |             memory_type: 'heap_used',
586 |             component: 'monitoring_start',
587 |           },
588 |         );
589 | 
590 |         // Fast-forward and verify monitoring snapshot
591 |         vi.advanceTimersByTime(1000);
592 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
593 |           mockConfig,
594 |           expect.any(Number),
595 |           {
596 |             memory_type: 'heap_used',
597 |             component: 'monitoring_start',
598 |           },
599 |         );
600 |       });
601 |     });
602 | 
603 |     describe('stopGlobalMemoryMonitoring', () => {
604 |       it('should stop global monitoring when monitor exists', () => {
605 |         startGlobalMemoryMonitoring(mockConfig, 1000);
606 |         stopGlobalMemoryMonitoring(mockConfig);
607 | 
608 |         // Verify final snapshot
609 |         expect(mockRecordMemoryUsage).toHaveBeenCalledWith(
610 |           mockConfig,
611 |           mockMemoryUsage.heapUsed,
612 |           {
613 |             memory_type: 'heap_used',
614 |             component: 'monitoring_stop',
615 |           },
616 |         );
617 | 
618 |         // Verify no more periodic snapshots
619 |         const callsAfterStop = mockRecordMemoryUsage.mock.calls.length;
620 |         vi.advanceTimersByTime(2000);
621 |         expect(mockRecordMemoryUsage.mock.calls.length).toBe(callsAfterStop);
622 |       });
623 | 
624 |       it('should handle stop when no global monitor exists', () => {
625 |         expect(() => stopGlobalMemoryMonitoring(mockConfig)).not.toThrow();
626 |       });
627 |     });
628 |   });
629 | 
630 |   describe('Error Scenarios', () => {
631 |     it('should handle process.memoryUsage() errors gracefully', () => {
632 |       mockProcessMemoryUsage.mockImplementation(() => {
633 |         throw new Error('Memory access error');
634 |       });
635 | 
636 |       const monitor = new MemoryMonitor();
637 | 
638 |       expect(() => monitor.getCurrentMemoryUsage()).toThrow(
639 |         'Memory access error',
640 |       );
641 |     });
642 | 
643 |     it('should handle v8.getHeapStatistics() errors gracefully', () => {
644 |       mockV8GetHeapStatistics.mockImplementation(() => {
645 |         throw new Error('Heap statistics error');
646 |       });
647 | 
648 |       const monitor = new MemoryMonitor();
649 | 
650 |       expect(() => monitor.getCurrentMemoryUsage()).toThrow(
651 |         'Heap statistics error',
652 |       );
653 |     });
654 | 
655 |     it('should handle metric recording errors gracefully', () => {
656 |       mockRecordMemoryUsage.mockImplementation(() => {
657 |         throw new Error('Metric recording error');
658 |       });
659 | 
660 |       const monitor = new MemoryMonitor();
661 | 
662 |       // Should propagate error if metric recording fails
663 |       expect(() => monitor.takeSnapshot('test', mockConfig)).toThrow(
664 |         'Metric recording error',
665 |       );
666 |     });
667 |   });
668 | });
```

src/telemetry/memory-monitor.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import v8 from 'node:v8';
8 | import process from 'node:process';
9 | import type { Config } from '../config/config.js';
10 | import { bytesToMB } from '../utils/formatters.js';
11 | import { isUserActive } from './activity-detector.js';
12 | import { HighWaterMarkTracker } from './high-water-mark-tracker.js';
13 | import {
14 |   recordMemoryUsage,
15 |   MemoryMetricType,
16 |   isPerformanceMonitoringActive,
17 | } from './metrics.js';
18 | import { RateLimiter } from './rate-limiter.js';
19 | 
20 | export interface MemorySnapshot {
21 |   timestamp: number;
22 |   heapUsed: number;
23 |   heapTotal: number;
24 |   external: number;
25 |   rss: number;
26 |   arrayBuffers: number;
27 |   heapSizeLimit: number;
28 | }
29 | 
30 | export interface ProcessMetrics {
31 |   cpuUsage: NodeJS.CpuUsage;
32 |   memoryUsage: NodeJS.MemoryUsage;
33 |   uptime: number;
34 | }
35 | 
36 | export class MemoryMonitor {
37 |   private intervalId: NodeJS.Timeout | null = null;
38 |   private isRunning = false;
39 |   private lastSnapshot: MemorySnapshot | null = null;
40 |   private monitoringInterval: number = 10000;
41 |   private highWaterMarkTracker: HighWaterMarkTracker;
42 |   private rateLimiter: RateLimiter;
43 |   private useEnhancedMonitoring: boolean = true;
44 |   private lastCleanupTimestamp: number = Date.now();
45 | 
46 |   private static readonly STATE_CLEANUP_INTERVAL_MS = 15 * 60 * 1000; // 15 minutes
47 |   private static readonly STATE_CLEANUP_MAX_AGE_MS = 60 * 60 * 1000; // 1 hour
48 | 
49 |   constructor() {
50 |     // No config stored to avoid multi-session attribution issues
51 |     this.highWaterMarkTracker = new HighWaterMarkTracker(5); // 5% threshold
52 |     this.rateLimiter = new RateLimiter(60000); // 1 minute minimum between recordings
53 |   }
54 | 
55 |   /**
56 |    * Start continuous memory monitoring
57 |    */
58 |   start(config: Config, intervalMs: number = 10000): void {
59 |     if (!isPerformanceMonitoringActive() || this.isRunning) {
60 |       return;
61 |     }
62 | 
63 |     this.monitoringInterval = intervalMs;
64 |     this.isRunning = true;
65 | 
66 |     // Take initial snapshot
67 |     this.takeSnapshot('monitoring_start', config);
68 | 
69 |     // Set up periodic monitoring with enhanced logic
70 |     this.intervalId = setInterval(() => {
71 |       this.checkAndRecordIfNeeded(config);
72 |     }, this.monitoringInterval).unref();
73 |   }
74 | 
75 |   /**
76 |    * Check if we should record memory metrics and do so if conditions are met
77 |    */
78 |   private checkAndRecordIfNeeded(config: Config): void {
79 |     this.performPeriodicCleanup();
80 | 
81 |     if (!this.useEnhancedMonitoring) {
82 |       // Fall back to original behavior
83 |       this.takeSnapshot('periodic', config);
84 |       return;
85 |     }
86 | 
87 |     // Only proceed if user is active
88 |     if (!isUserActive()) {
89 |       return;
90 |     }
91 | 
92 |     // Get current memory usage
93 |     const currentMemory = this.getCurrentMemoryUsage();
94 | 
95 |     // Check if RSS has grown significantly (5% threshold)
96 |     const shouldRecordRss = this.highWaterMarkTracker.shouldRecordMetric(
97 |       'rss',
98 |       currentMemory.rss,
99 |     );
100 |     const shouldRecordHeap = this.highWaterMarkTracker.shouldRecordMetric(
101 |       'heap_used',
102 |       currentMemory.heapUsed,
103 |     );
104 | 
105 |     // Also check rate limiting
106 |     const canRecordPeriodic = this.rateLimiter.shouldRecord('periodic_memory');
107 |     const canRecordHighWater = this.rateLimiter.shouldRecord(
108 |       'high_water_memory',
109 |       true,
110 |     ); // High priority
111 | 
112 |     // Record if we have significant growth and aren't rate limited
113 |     if ((shouldRecordRss || shouldRecordHeap) && canRecordHighWater) {
114 |       const context = shouldRecordRss ? 'rss_growth' : 'heap_growth';
115 |       this.takeSnapshot(context, config);
116 |     } else if (canRecordPeriodic) {
117 |       // Occasionally record even without growth for baseline tracking
118 |       this.takeSnapshotWithoutRecording('periodic_check', config);
119 |     }
120 |   }
121 | 
122 |   /**
123 |    * Periodically prune tracker state to avoid unbounded growth when keys change.
124 |    */
125 |   private performPeriodicCleanup(): void {
126 |     const now = Date.now();
127 |     if (
128 |       now - this.lastCleanupTimestamp <
129 |       MemoryMonitor.STATE_CLEANUP_INTERVAL_MS
130 |     ) {
131 |       return;
132 |     }
133 | 
134 |     this.lastCleanupTimestamp = now;
135 |     this.highWaterMarkTracker.cleanup(MemoryMonitor.STATE_CLEANUP_MAX_AGE_MS);
136 |     this.rateLimiter.cleanup(MemoryMonitor.STATE_CLEANUP_MAX_AGE_MS);
137 |   }
138 | 
139 |   /**
140 |    * Stop continuous memory monitoring
141 |    */
142 |   stop(config?: Config): void {
143 |     if (!this.isRunning) {
144 |       return;
145 |     }
146 | 
147 |     if (this.intervalId) {
148 |       clearInterval(this.intervalId);
149 |       this.intervalId = null;
150 |     }
151 | 
152 |     // Take final snapshot if config is provided
153 |     if (config) {
154 |       this.takeSnapshot('monitoring_stop', config);
155 |     }
156 |     this.isRunning = false;
157 |   }
158 | 
159 |   /**
160 |    * Take a memory snapshot and record metrics
161 |    */
162 |   takeSnapshot(context: string, config: Config): MemorySnapshot {
163 |     const memUsage = process.memoryUsage();
164 |     const heapStats = v8.getHeapStatistics();
165 | 
166 |     const snapshot: MemorySnapshot = {
167 |       timestamp: Date.now(),
168 |       heapUsed: memUsage.heapUsed,
169 |       heapTotal: memUsage.heapTotal,
170 |       external: memUsage.external,
171 |       rss: memUsage.rss,
172 |       arrayBuffers: memUsage.arrayBuffers,
173 |       heapSizeLimit: heapStats.heap_size_limit,
174 |     };
175 | 
176 |     // Record memory metrics if monitoring is active
177 |     if (isPerformanceMonitoringActive()) {
178 |       recordMemoryUsage(config, snapshot.heapUsed, {
179 |         memory_type: MemoryMetricType.HEAP_USED,
180 |         component: context,
181 |       });
182 |       recordMemoryUsage(config, snapshot.heapTotal, {
183 |         memory_type: MemoryMetricType.HEAP_TOTAL,
184 |         component: context,
185 |       });
186 |       recordMemoryUsage(config, snapshot.external, {
187 |         memory_type: MemoryMetricType.EXTERNAL,
188 |         component: context,
189 |       });
190 |       recordMemoryUsage(config, snapshot.rss, {
191 |         memory_type: MemoryMetricType.RSS,
192 |         component: context,
193 |       });
194 |     }
195 | 
196 |     this.lastSnapshot = snapshot;
197 |     return snapshot;
198 |   }
199 | 
200 |   /**
201 |    * Take a memory snapshot without recording metrics (for internal tracking)
202 |    */
203 |   private takeSnapshotWithoutRecording(
204 |     _context: string,
205 |     _config: Config,
206 |   ): MemorySnapshot {
207 |     const memUsage = process.memoryUsage();
208 |     const heapStats = v8.getHeapStatistics();
209 | 
210 |     const snapshot: MemorySnapshot = {
211 |       timestamp: Date.now(),
212 |       heapUsed: memUsage.heapUsed,
213 |       heapTotal: memUsage.heapTotal,
214 |       external: memUsage.external,
215 |       rss: memUsage.rss,
216 |       arrayBuffers: memUsage.arrayBuffers,
217 |       heapSizeLimit: heapStats.heap_size_limit,
218 |     };
219 | 
220 |     // Update internal tracking but don't record metrics
221 |     this.highWaterMarkTracker.shouldRecordMetric('rss', snapshot.rss);
222 |     this.highWaterMarkTracker.shouldRecordMetric(
223 |       'heap_used',
224 |       snapshot.heapUsed,
225 |     );
226 | 
227 |     this.lastSnapshot = snapshot;
228 |     return snapshot;
229 |   }
230 | 
231 |   /**
232 |    * Get current memory usage without recording metrics
233 |    */
234 |   getCurrentMemoryUsage(): MemorySnapshot {
235 |     const memUsage = process.memoryUsage();
236 |     const heapStats = v8.getHeapStatistics();
237 | 
238 |     return {
239 |       timestamp: Date.now(),
240 |       heapUsed: memUsage.heapUsed,
241 |       heapTotal: memUsage.heapTotal,
242 |       external: memUsage.external,
243 |       rss: memUsage.rss,
244 |       arrayBuffers: memUsage.arrayBuffers,
245 |       heapSizeLimit: heapStats.heap_size_limit,
246 |     };
247 |   }
248 | 
249 |   /**
250 |    * Get memory growth since last snapshot
251 |    */
252 |   getMemoryGrowth(): Partial<MemorySnapshot> | null {
253 |     if (!this.lastSnapshot) {
254 |       return null;
255 |     }
256 | 
257 |     const current = this.getCurrentMemoryUsage();
258 |     return {
259 |       heapUsed: current.heapUsed - this.lastSnapshot.heapUsed,
260 |       heapTotal: current.heapTotal - this.lastSnapshot.heapTotal,
261 |       external: current.external - this.lastSnapshot.external,
262 |       rss: current.rss - this.lastSnapshot.rss,
263 |       arrayBuffers: current.arrayBuffers - this.lastSnapshot.arrayBuffers,
264 |     };
265 |   }
266 | 
267 |   /**
268 |    * Get detailed heap statistics
269 |    */
270 |   getHeapStatistics(): v8.HeapInfo {
271 |     return v8.getHeapStatistics();
272 |   }
273 | 
274 |   /**
275 |    * Get heap space statistics
276 |    */
277 |   getHeapSpaceStatistics(): v8.HeapSpaceInfo[] {
278 |     return v8.getHeapSpaceStatistics();
279 |   }
280 | 
281 |   /**
282 |    * Get process CPU and memory metrics
283 |    */
284 |   getProcessMetrics(): ProcessMetrics {
285 |     return {
286 |       cpuUsage: process.cpuUsage(),
287 |       memoryUsage: process.memoryUsage(),
288 |       uptime: process.uptime(),
289 |     };
290 |   }
291 | 
292 |   /**
293 |    * Record memory usage for a specific component or operation
294 |    */
295 |   recordComponentMemoryUsage(
296 |     config: Config,
297 |     component: string,
298 |     operation?: string,
299 |   ): MemorySnapshot {
300 |     const snapshot = this.takeSnapshot(
301 |       operation ? `${component}_${operation}` : component,
302 |       config,
303 |     );
304 |     return snapshot;
305 |   }
306 | 
307 |   /**
308 |    * Check if memory usage exceeds threshold
309 |    */
310 |   checkMemoryThreshold(thresholdMB: number): boolean {
311 |     const current = this.getCurrentMemoryUsage();
312 |     const currentMB = bytesToMB(current.heapUsed);
313 |     return currentMB > thresholdMB;
314 |   }
315 | 
316 |   /**
317 |    * Get memory usage summary in MB
318 |    */
319 |   getMemoryUsageSummary(): {
320 |     heapUsedMB: number;
321 |     heapTotalMB: number;
322 |     externalMB: number;
323 |     rssMB: number;
324 |     heapSizeLimitMB: number;
325 |   } {
326 |     const current = this.getCurrentMemoryUsage();
327 |     return {
328 |       heapUsedMB: Math.round(bytesToMB(current.heapUsed) * 100) / 100,
329 |       heapTotalMB: Math.round(bytesToMB(current.heapTotal) * 100) / 100,
330 |       externalMB: Math.round(bytesToMB(current.external) * 100) / 100,
331 |       rssMB: Math.round(bytesToMB(current.rss) * 100) / 100,
332 |       heapSizeLimitMB: Math.round(bytesToMB(current.heapSizeLimit) * 100) / 100,
333 |     };
334 |   }
335 | 
336 |   /**
337 |    * Enable or disable enhanced monitoring features
338 |    */
339 |   setEnhancedMonitoring(enabled: boolean): void {
340 |     this.useEnhancedMonitoring = enabled;
341 |   }
342 | 
343 |   /**
344 |    * Get high-water mark statistics
345 |    */
346 |   getHighWaterMarkStats(): Record<string, number> {
347 |     return this.highWaterMarkTracker.getAllHighWaterMarks();
348 |   }
349 | 
350 |   /**
351 |    * Get rate limiting statistics
352 |    */
353 |   getRateLimitingStats(): {
354 |     totalMetrics: number;
355 |     oldestRecord: number;
356 |     newestRecord: number;
357 |     averageInterval: number;
358 |   } {
359 |     return this.rateLimiter.getStats();
360 |   }
361 | 
362 |   /**
363 |    * Force record memory metrics (bypasses rate limiting for critical events)
364 |    */
365 |   forceRecordMemory(
366 |     config: Config,
367 |     context: string = 'forced',
368 |   ): MemorySnapshot {
369 |     this.rateLimiter.forceRecord('forced_memory');
370 |     return this.takeSnapshot(context, config);
371 |   }
372 | 
373 |   /**
374 |    * Reset high-water marks (useful after memory optimizations)
375 |    */
376 |   resetHighWaterMarks(): void {
377 |     this.highWaterMarkTracker.resetAllHighWaterMarks();
378 |   }
379 | 
380 |   /**
381 |    * Cleanup resources
382 |    */
383 |   destroy(): void {
384 |     this.stop();
385 |     this.rateLimiter.reset();
386 |     this.highWaterMarkTracker.resetAllHighWaterMarks();
387 |   }
388 | }
389 | 
390 | // Singleton instance for global memory monitoring
391 | let globalMemoryMonitor: MemoryMonitor | null = null;
392 | 
393 | /**
394 |  * Initialize global memory monitor
395 |  */
396 | export function initializeMemoryMonitor(): MemoryMonitor {
397 |   if (!globalMemoryMonitor) {
398 |     globalMemoryMonitor = new MemoryMonitor();
399 |   }
400 |   return globalMemoryMonitor;
401 | }
402 | 
403 | /**
404 |  * Get global memory monitor instance
405 |  */
406 | export function getMemoryMonitor(): MemoryMonitor | null {
407 |   return globalMemoryMonitor;
408 | }
409 | 
410 | /**
411 |  * Record memory usage for current operation
412 |  */
413 | export function recordCurrentMemoryUsage(
414 |   config: Config,
415 |   context: string,
416 | ): MemorySnapshot {
417 |   const monitor = initializeMemoryMonitor();
418 |   return monitor.takeSnapshot(context, config);
419 | }
420 | 
421 | /**
422 |  * Start global memory monitoring
423 |  */
424 | export function startGlobalMemoryMonitoring(
425 |   config: Config,
426 |   intervalMs: number = 10000,
427 | ): void {
428 |   const monitor = initializeMemoryMonitor();
429 |   monitor.start(config, intervalMs);
430 | }
431 | 
432 | /**
433 |  * Stop global memory monitoring
434 |  */
435 | export function stopGlobalMemoryMonitoring(config?: Config): void {
436 |   if (globalMemoryMonitor) {
437 |     globalMemoryMonitor.stop(config);
438 |   }
439 | }
440 | 
441 | /**
442 |  * Reset the global memory monitor singleton (test-only helper).
443 |  */
444 | export function _resetGlobalMemoryMonitorForTests(): void {
445 |   if (globalMemoryMonitor) {
446 |     globalMemoryMonitor.destroy();
447 |   }
448 |   globalMemoryMonitor = null;
449 | }
```

src/telemetry/metrics.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, type Mock } from 'vitest';
8 | import type {
9 |   Counter,
10 |   Meter,
11 |   Attributes,
12 |   Context,
13 |   Histogram,
14 | } from '@opentelemetry/api';
15 | import type { Config } from '../config/config.js';
16 | import {
17 |   FileOperation,
18 |   MemoryMetricType,
19 |   ToolExecutionPhase,
20 |   ApiRequestPhase,
21 | } from './metrics.js';
22 | import { makeFakeConfig } from '../test-utils/config.js';
23 | import { ModelRoutingEvent, AgentFinishEvent } from './types.js';
24 | import { AgentTerminateMode } from '../agents/types.js';
25 | 
26 | const mockCounterAddFn: Mock<
27 |   (value: number, attributes?: Attributes, context?: Context) => void
28 | > = vi.fn();
29 | const mockHistogramRecordFn: Mock<
30 |   (value: number, attributes?: Attributes, context?: Context) => void
31 | > = vi.fn();
32 | 
33 | const mockCreateCounterFn: Mock<(name: string, options?: unknown) => Counter> =
34 |   vi.fn();
35 | const mockCreateHistogramFn: Mock<
36 |   (name: string, options?: unknown) => Histogram
37 | > = vi.fn();
38 | 
39 | const mockCounterInstance: Counter = {
40 |   add: mockCounterAddFn,
41 | } as Partial<Counter> as Counter;
42 | 
43 | const mockHistogramInstance: Histogram = {
44 |   record: mockHistogramRecordFn,
45 | } as Partial<Histogram> as Histogram;
46 | 
47 | const mockMeterInstance: Meter = {
48 |   createCounter: mockCreateCounterFn.mockReturnValue(mockCounterInstance),
49 |   createHistogram: mockCreateHistogramFn.mockReturnValue(mockHistogramInstance),
50 | } as Partial<Meter> as Meter;
51 | 
52 | function originalOtelMockFactory() {
53 |   return {
54 |     metrics: {
55 |       getMeter: vi.fn(),
56 |     },
57 |     ValueType: {
58 |       INT: 1,
59 |       DOUBLE: 2,
60 |     },
61 |     diag: {
62 |       setLogger: vi.fn(),
63 |       warn: vi.fn(),
64 |     },
65 |     DiagConsoleLogger: vi.fn(),
66 |     DiagLogLevel: {
67 |       NONE: 0,
68 |       INFO: 1,
69 |     },
70 |   } as const;
71 | }
72 | 
73 | vi.mock('@opentelemetry/api');
74 | vi.mock('./telemetryAttributes.js');
75 | 
76 | describe('Telemetry Metrics', () => {
77 |   let initializeMetricsModule: typeof import('./metrics.js').initializeMetrics;
78 |   let recordTokenUsageMetricsModule: typeof import('./metrics.js').recordTokenUsageMetrics;
79 |   let recordFileOperationMetricModule: typeof import('./metrics.js').recordFileOperationMetric;
80 |   let recordChatCompressionMetricsModule: typeof import('./metrics.js').recordChatCompressionMetrics;
81 |   let recordModelRoutingMetricsModule: typeof import('./metrics.js').recordModelRoutingMetrics;
82 |   let recordStartupPerformanceModule: typeof import('./metrics.js').recordStartupPerformance;
83 |   let recordMemoryUsageModule: typeof import('./metrics.js').recordMemoryUsage;
84 |   let recordCpuUsageModule: typeof import('./metrics.js').recordCpuUsage;
85 |   let recordToolQueueDepthModule: typeof import('./metrics.js').recordToolQueueDepth;
86 |   let recordToolExecutionBreakdownModule: typeof import('./metrics.js').recordToolExecutionBreakdown;
87 |   let recordTokenEfficiencyModule: typeof import('./metrics.js').recordTokenEfficiency;
88 |   let recordApiRequestBreakdownModule: typeof import('./metrics.js').recordApiRequestBreakdown;
89 |   let recordPerformanceScoreModule: typeof import('./metrics.js').recordPerformanceScore;
90 |   let recordPerformanceRegressionModule: typeof import('./metrics.js').recordPerformanceRegression;
91 |   let recordBaselineComparisonModule: typeof import('./metrics.js').recordBaselineComparison;
92 |   let recordGenAiClientTokenUsageModule: typeof import('./metrics.js').recordGenAiClientTokenUsage;
93 |   let recordGenAiClientOperationDurationModule: typeof import('./metrics.js').recordGenAiClientOperationDuration;
94 |   let recordFlickerFrameModule: typeof import('./metrics.js').recordFlickerFrame;
95 |   let recordAgentRunMetricsModule: typeof import('./metrics.js').recordAgentRunMetrics;
96 | 
97 |   beforeEach(async () => {
98 |     vi.resetModules();
99 |     vi.doMock('@opentelemetry/api', () => {
100 |       const actualApi = originalOtelMockFactory();
101 |       (actualApi.metrics.getMeter as Mock).mockReturnValue(mockMeterInstance);
102 |       return actualApi;
103 |     });
104 | 
105 |     const { getCommonAttributes } = await import('./telemetryAttributes.js');
106 |     (getCommonAttributes as Mock).mockReturnValue({
107 |       'session.id': 'test-session-id',
108 |       'installation.id': 'test-installation-id',
109 |       'user.email': 'test@example.com',
110 |     });
111 | 
112 |     const metricsJsModule = await import('./metrics.js');
113 |     initializeMetricsModule = metricsJsModule.initializeMetrics;
114 |     recordTokenUsageMetricsModule = metricsJsModule.recordTokenUsageMetrics;
115 |     recordFileOperationMetricModule = metricsJsModule.recordFileOperationMetric;
116 |     recordChatCompressionMetricsModule =
117 |       metricsJsModule.recordChatCompressionMetrics;
118 |     recordModelRoutingMetricsModule = metricsJsModule.recordModelRoutingMetrics;
119 |     recordStartupPerformanceModule = metricsJsModule.recordStartupPerformance;
120 |     recordMemoryUsageModule = metricsJsModule.recordMemoryUsage;
121 |     recordCpuUsageModule = metricsJsModule.recordCpuUsage;
122 |     recordToolQueueDepthModule = metricsJsModule.recordToolQueueDepth;
123 |     recordToolExecutionBreakdownModule =
124 |       metricsJsModule.recordToolExecutionBreakdown;
125 |     recordTokenEfficiencyModule = metricsJsModule.recordTokenEfficiency;
126 |     recordApiRequestBreakdownModule = metricsJsModule.recordApiRequestBreakdown;
127 |     recordPerformanceScoreModule = metricsJsModule.recordPerformanceScore;
128 |     recordPerformanceRegressionModule =
129 |       metricsJsModule.recordPerformanceRegression;
130 |     recordBaselineComparisonModule = metricsJsModule.recordBaselineComparison;
131 |     recordGenAiClientTokenUsageModule =
132 |       metricsJsModule.recordGenAiClientTokenUsage;
133 |     recordGenAiClientOperationDurationModule =
134 |       metricsJsModule.recordGenAiClientOperationDuration;
135 |     recordFlickerFrameModule = metricsJsModule.recordFlickerFrame;
136 |     recordAgentRunMetricsModule = metricsJsModule.recordAgentRunMetrics;
137 | 
138 |     const otelApiModule = await import('@opentelemetry/api');
139 | 
140 |     mockCounterAddFn.mockClear();
141 |     mockCreateCounterFn.mockClear();
142 |     mockCreateHistogramFn.mockClear();
143 |     mockHistogramRecordFn.mockClear();
144 |     (otelApiModule.metrics.getMeter as Mock).mockClear();
145 | 
146 |     (otelApiModule.metrics.getMeter as Mock).mockReturnValue(mockMeterInstance);
147 |     mockCreateCounterFn.mockReturnValue(mockCounterInstance);
148 |     mockCreateHistogramFn.mockReturnValue(mockHistogramInstance);
149 |   });
150 | 
151 |   describe('recordFlickerFrame', () => {
152 |     it('does not record metrics if not initialized', () => {
153 |       const config = makeFakeConfig({});
154 |       recordFlickerFrameModule(config);
155 |       expect(mockCounterAddFn).not.toHaveBeenCalled();
156 |     });
157 | 
158 |     it('records a flicker frame event when initialized', () => {
159 |       const config = makeFakeConfig({});
160 |       initializeMetricsModule(config);
161 |       recordFlickerFrameModule(config);
162 | 
163 |       // Called for session, then for flicker
164 |       expect(mockCounterAddFn).toHaveBeenCalledTimes(2);
165 |       expect(mockCounterAddFn).toHaveBeenNthCalledWith(2, 1, {
166 |         'session.id': 'test-session-id',
167 |         'installation.id': 'test-installation-id',
168 |         'user.email': 'test@example.com',
169 |       });
170 |     });
171 |   });
172 | 
173 |   describe('initializeMetrics', () => {
174 |     const mockConfig = {
175 |       getSessionId: () => 'test-session-id',
176 |       getTelemetryEnabled: () => true,
177 |     } as unknown as Config;
178 | 
179 |     it('should apply common attributes including email', () => {
180 |       initializeMetricsModule(mockConfig);
181 | 
182 |       expect(mockCounterAddFn).toHaveBeenCalledWith(1, {
183 |         'session.id': 'test-session-id',
184 |         'installation.id': 'test-installation-id',
185 |         'user.email': 'test@example.com',
186 |       });
187 |     });
188 |   });
189 | 
190 |   describe('recordChatCompressionMetrics', () => {
191 |     it('does not record metrics if not initialized', () => {
192 |       const lol = makeFakeConfig({});
193 | 
194 |       recordChatCompressionMetricsModule(lol, {
195 |         tokens_after: 100,
196 |         tokens_before: 200,
197 |       });
198 | 
199 |       expect(mockCounterAddFn).not.toHaveBeenCalled();
200 |     });
201 | 
202 |     it('records token compression with the correct attributes', () => {
203 |       const config = makeFakeConfig({});
204 |       initializeMetricsModule(config);
205 | 
206 |       recordChatCompressionMetricsModule(config, {
207 |         tokens_after: 100,
208 |         tokens_before: 200,
209 |       });
210 | 
211 |       expect(mockCounterAddFn).toHaveBeenCalledWith(1, {
212 |         'session.id': 'test-session-id',
213 |         'installation.id': 'test-installation-id',
214 |         'user.email': 'test@example.com',
215 |         tokens_after: 100,
216 |         tokens_before: 200,
217 |       });
218 |     });
219 |   });
220 | 
221 |   describe('recordTokenUsageMetrics', () => {
222 |     const mockConfig = {
223 |       getSessionId: () => 'test-session-id',
224 |       getTelemetryEnabled: () => true,
225 |     } as unknown as Config;
226 | 
227 |     it('should not record metrics if not initialized', () => {
228 |       recordTokenUsageMetricsModule(mockConfig, 100, {
229 |         model: 'gemini-pro',
230 |         type: 'input',
231 |       });
232 |       expect(mockCounterAddFn).not.toHaveBeenCalled();
233 |     });
234 | 
235 |     it('should record token usage with the correct attributes', () => {
236 |       initializeMetricsModule(mockConfig);
237 |       recordTokenUsageMetricsModule(mockConfig, 100, {
238 |         model: 'gemini-pro',
239 |         type: 'input',
240 |       });
241 |       expect(mockCounterAddFn).toHaveBeenCalledTimes(2);
242 |       expect(mockCounterAddFn).toHaveBeenNthCalledWith(1, 1, {
243 |         'session.id': 'test-session-id',
244 |         'installation.id': 'test-installation-id',
245 |         'user.email': 'test@example.com',
246 |       });
247 |       expect(mockCounterAddFn).toHaveBeenNthCalledWith(2, 100, {
248 |         'session.id': 'test-session-id',
249 |         'installation.id': 'test-installation-id',
250 |         'user.email': 'test@example.com',
251 |         model: 'gemini-pro',
252 |         type: 'input',
253 |       });
254 |     });
255 | 
256 |     it('should record token usage for different types', () => {
257 |       initializeMetricsModule(mockConfig);
258 |       mockCounterAddFn.mockClear();
259 | 
260 |       recordTokenUsageMetricsModule(mockConfig, 50, {
261 |         model: 'gemini-pro',
262 |         type: 'output',
263 |       });
264 |       expect(mockCounterAddFn).toHaveBeenCalledWith(50, {
265 |         'session.id': 'test-session-id',
266 |         'installation.id': 'test-installation-id',
267 |         'user.email': 'test@example.com',
268 |         model: 'gemini-pro',
269 |         type: 'output',
270 |       });
271 | 
272 |       recordTokenUsageMetricsModule(mockConfig, 25, {
273 |         model: 'gemini-pro',
274 |         type: 'thought',
275 |       });
276 |       expect(mockCounterAddFn).toHaveBeenCalledWith(25, {
277 |         'session.id': 'test-session-id',
278 |         'installation.id': 'test-installation-id',
279 |         'user.email': 'test@example.com',
280 |         model: 'gemini-pro',
281 |         type: 'thought',
282 |       });
283 | 
284 |       recordTokenUsageMetricsModule(mockConfig, 75, {
285 |         model: 'gemini-pro',
286 |         type: 'cache',
287 |       });
288 |       expect(mockCounterAddFn).toHaveBeenCalledWith(75, {
289 |         'session.id': 'test-session-id',
290 |         'installation.id': 'test-installation-id',
291 |         'user.email': 'test@example.com',
292 |         model: 'gemini-pro',
293 |         type: 'cache',
294 |       });
295 | 
296 |       recordTokenUsageMetricsModule(mockConfig, 125, {
297 |         model: 'gemini-pro',
298 |         type: 'tool',
299 |       });
300 |       expect(mockCounterAddFn).toHaveBeenCalledWith(125, {
301 |         'session.id': 'test-session-id',
302 |         'installation.id': 'test-installation-id',
303 |         'user.email': 'test@example.com',
304 |         model: 'gemini-pro',
305 |         type: 'tool',
306 |       });
307 |     });
308 | 
309 |     it('should handle different models', () => {
310 |       initializeMetricsModule(mockConfig);
311 |       mockCounterAddFn.mockClear();
312 | 
313 |       recordTokenUsageMetricsModule(mockConfig, 200, {
314 |         model: 'gemini-ultra',
315 |         type: 'input',
316 |       });
317 |       expect(mockCounterAddFn).toHaveBeenCalledWith(200, {
318 |         'session.id': 'test-session-id',
319 |         'installation.id': 'test-installation-id',
320 |         'user.email': 'test@example.com',
321 |         model: 'gemini-ultra',
322 |         type: 'input',
323 |       });
324 |     });
325 |   });
326 | 
327 |   describe('recordFileOperationMetric', () => {
328 |     const mockConfig = {
329 |       getSessionId: () => 'test-session-id',
330 |       getTelemetryEnabled: () => true,
331 |     } as unknown as Config;
332 | 
333 |     it('should not record metrics if not initialized', () => {
334 |       recordFileOperationMetricModule(mockConfig, {
335 |         operation: FileOperation.CREATE,
336 |         lines: 10,
337 |         mimetype: 'text/plain',
338 |         extension: 'txt',
339 |       });
340 |       expect(mockCounterAddFn).not.toHaveBeenCalled();
341 |     });
342 | 
343 |     it('should record file creation with all attributes', () => {
344 |       initializeMetricsModule(mockConfig);
345 |       recordFileOperationMetricModule(mockConfig, {
346 |         operation: FileOperation.CREATE,
347 |         lines: 10,
348 |         mimetype: 'text/plain',
349 |         extension: 'txt',
350 |       });
351 | 
352 |       expect(mockCounterAddFn).toHaveBeenCalledTimes(2);
353 |       expect(mockCounterAddFn).toHaveBeenNthCalledWith(1, 1, {
354 |         'session.id': 'test-session-id',
355 |         'installation.id': 'test-installation-id',
356 |         'user.email': 'test@example.com',
357 |       });
358 |       expect(mockCounterAddFn).toHaveBeenNthCalledWith(2, 1, {
359 |         'session.id': 'test-session-id',
360 |         'installation.id': 'test-installation-id',
361 |         'user.email': 'test@example.com',
362 |         operation: FileOperation.CREATE,
363 |         lines: 10,
364 |         mimetype: 'text/plain',
365 |         extension: 'txt',
366 |       });
367 |     });
368 | 
369 |     it('should record file read with minimal attributes', () => {
370 |       initializeMetricsModule(mockConfig);
371 |       mockCounterAddFn.mockClear();
372 | 
373 |       recordFileOperationMetricModule(mockConfig, {
374 |         operation: FileOperation.READ,
375 |       });
376 |       expect(mockCounterAddFn).toHaveBeenCalledWith(1, {
377 |         'session.id': 'test-session-id',
378 |         'installation.id': 'test-installation-id',
379 |         'user.email': 'test@example.com',
380 |         operation: FileOperation.READ,
381 |       });
382 |     });
383 | 
384 |     it('should record file update with some attributes', () => {
385 |       initializeMetricsModule(mockConfig);
386 |       mockCounterAddFn.mockClear();
387 | 
388 |       recordFileOperationMetricModule(mockConfig, {
389 |         operation: FileOperation.UPDATE,
390 |         mimetype: 'application/javascript',
391 |       });
392 |       expect(mockCounterAddFn).toHaveBeenCalledWith(1, {
393 |         'session.id': 'test-session-id',
394 |         'installation.id': 'test-installation-id',
395 |         'user.email': 'test@example.com',
396 |         operation: FileOperation.UPDATE,
397 |         mimetype: 'application/javascript',
398 |       });
399 |     });
400 | 
401 |     it('should record file operation without diffStat', () => {
402 |       initializeMetricsModule(mockConfig);
403 |       mockCounterAddFn.mockClear();
404 | 
405 |       recordFileOperationMetricModule(mockConfig, {
406 |         operation: FileOperation.UPDATE,
407 |       });
408 | 
409 |       expect(mockCounterAddFn).toHaveBeenCalledWith(1, {
410 |         'session.id': 'test-session-id',
411 |         'installation.id': 'test-installation-id',
412 |         'user.email': 'test@example.com',
413 |         operation: FileOperation.UPDATE,
414 |       });
415 |     });
416 | 
417 |     it('should record minimal file operation when optional parameters are undefined', () => {
418 |       initializeMetricsModule(mockConfig);
419 |       mockCounterAddFn.mockClear();
420 | 
421 |       recordFileOperationMetricModule(mockConfig, {
422 |         operation: FileOperation.UPDATE,
423 |         lines: 10,
424 |         mimetype: 'text/plain',
425 |         extension: 'txt',
426 |       });
427 | 
428 |       expect(mockCounterAddFn).toHaveBeenCalledWith(1, {
429 |         'session.id': 'test-session-id',
430 |         'installation.id': 'test-installation-id',
431 |         'user.email': 'test@example.com',
432 |         operation: FileOperation.UPDATE,
433 |         lines: 10,
434 |         mimetype: 'text/plain',
435 |         extension: 'txt',
436 |       });
437 |     });
438 | 
439 |     it('should not include diffStat attributes when diffStat is not provided', () => {
440 |       initializeMetricsModule(mockConfig);
441 |       mockCounterAddFn.mockClear();
442 | 
443 |       recordFileOperationMetricModule(mockConfig, {
444 |         operation: FileOperation.UPDATE,
445 |       });
446 | 
447 |       expect(mockCounterAddFn).toHaveBeenCalledWith(1, {
448 |         'session.id': 'test-session-id',
449 |         'installation.id': 'test-installation-id',
450 |         'user.email': 'test@example.com',
451 |         operation: FileOperation.UPDATE,
452 |       });
453 |     });
454 |   });
455 | 
456 |   describe('recordModelRoutingMetrics', () => {
457 |     const mockConfig = {
458 |       getSessionId: () => 'test-session-id',
459 |       getTelemetryEnabled: () => true,
460 |     } as unknown as Config;
461 | 
462 |     it('should not record metrics if not initialized', () => {
463 |       const event = new ModelRoutingEvent(
464 |         'gemini-pro',
465 |         'default',
466 |         100,
467 |         'test-reason',
468 |         false,
469 |         undefined,
470 |       );
471 |       recordModelRoutingMetricsModule(mockConfig, event);
472 |       expect(mockHistogramRecordFn).not.toHaveBeenCalled();
473 |       expect(mockCounterAddFn).not.toHaveBeenCalled();
474 |     });
475 | 
476 |     it('should record latency for a successful routing decision', () => {
477 |       initializeMetricsModule(mockConfig);
478 |       const event = new ModelRoutingEvent(
479 |         'gemini-pro',
480 |         'default',
481 |         150,
482 |         'test-reason',
483 |         false,
484 |         undefined,
485 |       );
486 |       recordModelRoutingMetricsModule(mockConfig, event);
487 | 
488 |       expect(mockHistogramRecordFn).toHaveBeenCalledWith(150, {
489 |         'session.id': 'test-session-id',
490 |         'installation.id': 'test-installation-id',
491 |         'user.email': 'test@example.com',
492 |         'routing.decision_model': 'gemini-pro',
493 |         'routing.decision_source': 'default',
494 |       });
495 |       // The session counter is called once on init
496 |       expect(mockCounterAddFn).toHaveBeenCalledTimes(1);
497 |     });
498 | 
499 |     it('should record latency and failure for a failed routing decision', () => {
500 |       initializeMetricsModule(mockConfig);
501 |       const event = new ModelRoutingEvent(
502 |         'gemini-pro',
503 |         'classifier',
504 |         200,
505 |         'test-reason',
506 |         true,
507 |         'test-error',
508 |       );
509 |       recordModelRoutingMetricsModule(mockConfig, event);
510 | 
511 |       expect(mockHistogramRecordFn).toHaveBeenCalledWith(200, {
512 |         'session.id': 'test-session-id',
513 |         'installation.id': 'test-installation-id',
514 |         'user.email': 'test@example.com',
515 |         'routing.decision_model': 'gemini-pro',
516 |         'routing.decision_source': 'classifier',
517 |       });
518 | 
519 |       expect(mockCounterAddFn).toHaveBeenCalledTimes(2);
520 |       expect(mockCounterAddFn).toHaveBeenNthCalledWith(2, 1, {
521 |         'session.id': 'test-session-id',
522 |         'installation.id': 'test-installation-id',
523 |         'user.email': 'test@example.com',
524 |         'routing.decision_source': 'classifier',
525 |         'routing.error_message': 'test-error',
526 |       });
527 |     });
528 |   });
529 | 
530 |   describe('recordAgentRunMetrics', () => {
531 |     const mockConfig = {
532 |       getSessionId: () => 'test-session-id',
533 |       getTelemetryEnabled: () => true,
534 |     } as unknown as Config;
535 | 
536 |     it('should not record metrics if not initialized', () => {
537 |       const event = new AgentFinishEvent(
538 |         'agent-123',
539 |         'TestAgent',
540 |         1000,
541 |         5,
542 |         AgentTerminateMode.GOAL,
543 |       );
544 |       recordAgentRunMetricsModule(mockConfig, event);
545 |       expect(mockCounterAddFn).not.toHaveBeenCalled();
546 |       expect(mockHistogramRecordFn).not.toHaveBeenCalled();
547 |     });
548 | 
549 |     it('should record agent run metrics', () => {
550 |       initializeMetricsModule(mockConfig);
551 |       mockCounterAddFn.mockClear();
552 |       mockHistogramRecordFn.mockClear();
553 | 
554 |       const event = new AgentFinishEvent(
555 |         'agent-123',
556 |         'TestAgent',
557 |         1000,
558 |         5,
559 |         AgentTerminateMode.GOAL,
560 |       );
561 |       recordAgentRunMetricsModule(mockConfig, event);
562 | 
563 |       // Verify agent run counter
564 |       expect(mockCounterAddFn).toHaveBeenCalledWith(1, {
565 |         'session.id': 'test-session-id',
566 |         'installation.id': 'test-installation-id',
567 |         'user.email': 'test@example.com',
568 |         agent_name: 'TestAgent',
569 |         terminate_reason: 'GOAL',
570 |       });
571 | 
572 |       // Verify agent duration histogram
573 |       expect(mockHistogramRecordFn).toHaveBeenCalledWith(1000, {
574 |         'session.id': 'test-session-id',
575 |         'installation.id': 'test-installation-id',
576 |         'user.email': 'test@example.com',
577 |         agent_name: 'TestAgent',
578 |       });
579 | 
580 |       // Verify agent turns histogram
581 |       expect(mockHistogramRecordFn).toHaveBeenCalledWith(5, {
582 |         'session.id': 'test-session-id',
583 |         'installation.id': 'test-installation-id',
584 |         'user.email': 'test@example.com',
585 |         agent_name: 'TestAgent',
586 |       });
587 |     });
588 |   });
589 | 
590 |   describe('OpenTelemetry GenAI Semantic Convention Metrics', () => {
591 |     const mockConfig = {
592 |       getSessionId: () => 'test-session-id',
593 |       getTelemetryEnabled: () => true,
594 |     } as unknown as Config;
595 | 
596 |     describe('recordGenAiClientTokenUsage', () => {
597 |       it('should not record metrics when not initialized', () => {
598 |         recordGenAiClientTokenUsageModule(mockConfig, 100, {
599 |           'gen_ai.operation.name': 'generate_content',
600 |           'gen_ai.provider.name': 'gcp.gen_ai',
601 |           'gen_ai.token.type': 'input',
602 |         });
603 | 
604 |         expect(mockHistogramRecordFn).not.toHaveBeenCalled();
605 |       });
606 | 
607 |       it('should record input token usage with correct attributes', () => {
608 |         initializeMetricsModule(mockConfig);
609 |         mockHistogramRecordFn.mockClear();
610 | 
611 |         recordGenAiClientTokenUsageModule(mockConfig, 150, {
612 |           'gen_ai.operation.name': 'generate_content',
613 |           'gen_ai.provider.name': 'gcp.gen_ai',
614 |           'gen_ai.token.type': 'input',
615 |           'gen_ai.request.model': 'gemini-2.0-flash',
616 |           'gen_ai.response.model': 'gemini-2.0-flash',
617 |         });
618 | 
619 |         expect(mockHistogramRecordFn).toHaveBeenCalledWith(150, {
620 |           'session.id': 'test-session-id',
621 |           'installation.id': 'test-installation-id',
622 |           'user.email': 'test@example.com',
623 |           'gen_ai.operation.name': 'generate_content',
624 |           'gen_ai.provider.name': 'gcp.gen_ai',
625 |           'gen_ai.token.type': 'input',
626 |           'gen_ai.request.model': 'gemini-2.0-flash',
627 |           'gen_ai.response.model': 'gemini-2.0-flash',
628 |         });
629 |       });
630 | 
631 |       it('should record output token usage with correct attributes', () => {
632 |         initializeMetricsModule(mockConfig);
633 |         mockHistogramRecordFn.mockClear();
634 | 
635 |         recordGenAiClientTokenUsageModule(mockConfig, 75, {
636 |           'gen_ai.operation.name': 'generate_content',
637 |           'gen_ai.provider.name': 'gcp.vertex_ai',
638 |           'gen_ai.token.type': 'output',
639 |           'gen_ai.request.model': 'gemini-pro',
640 |         });
641 | 
642 |         expect(mockHistogramRecordFn).toHaveBeenCalledWith(75, {
643 |           'session.id': 'test-session-id',
644 |           'installation.id': 'test-installation-id',
645 |           'user.email': 'test@example.com',
646 |           'gen_ai.operation.name': 'generate_content',
647 |           'gen_ai.provider.name': 'gcp.vertex_ai',
[TRUNCATED]
```

src/telemetry/metrics.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Attributes, Meter, Counter, Histogram } from '@opentelemetry/api';
8 | import { diag, metrics, ValueType } from '@opentelemetry/api';
9 | import { SERVICE_NAME } from './constants.js';
10 | import { EVENT_CHAT_COMPRESSION } from './types.js';
11 | import type { Config } from '../config/config.js';
12 | import type {
13 |   ModelRoutingEvent,
14 |   ModelSlashCommandEvent,
15 |   AgentFinishEvent,
16 | } from './types.js';
17 | import { AuthType } from '../core/contentGenerator.js';
18 | import { getCommonAttributes } from './telemetryAttributes.js';
19 | 
20 | const TOOL_CALL_COUNT = 'gemini_cli.tool.call.count';
21 | const TOOL_CALL_LATENCY = 'gemini_cli.tool.call.latency';
22 | const API_REQUEST_COUNT = 'gemini_cli.api.request.count';
23 | const API_REQUEST_LATENCY = 'gemini_cli.api.request.latency';
24 | const TOKEN_USAGE = 'gemini_cli.token.usage';
25 | const SESSION_COUNT = 'gemini_cli.session.count';
26 | const FILE_OPERATION_COUNT = 'gemini_cli.file.operation.count';
27 | const INVALID_CHUNK_COUNT = 'gemini_cli.chat.invalid_chunk.count';
28 | const CONTENT_RETRY_COUNT = 'gemini_cli.chat.content_retry.count';
29 | const CONTENT_RETRY_FAILURE_COUNT =
30 |   'gemini_cli.chat.content_retry_failure.count';
31 | const MODEL_ROUTING_LATENCY = 'gemini_cli.model_routing.latency';
32 | const MODEL_ROUTING_FAILURE_COUNT = 'gemini_cli.model_routing.failure.count';
33 | const MODEL_SLASH_COMMAND_CALL_COUNT =
34 |   'gemini_cli.slash_command.model.call_count';
35 | 
36 | // Agent Metrics
37 | const AGENT_RUN_COUNT = 'gemini_cli.agent.run.count';
38 | const AGENT_DURATION_MS = 'gemini_cli.agent.duration';
39 | const AGENT_TURNS = 'gemini_cli.agent.turns';
40 | 
41 | // OpenTelemetry GenAI Semantic Convention Metrics
42 | const GEN_AI_CLIENT_TOKEN_USAGE = 'gen_ai.client.token.usage';
43 | const GEN_AI_CLIENT_OPERATION_DURATION = 'gen_ai.client.operation.duration';
44 | 
45 | // Performance Monitoring Metrics
46 | const STARTUP_TIME = 'gemini_cli.startup.duration';
47 | const MEMORY_USAGE = 'gemini_cli.memory.usage';
48 | const CPU_USAGE = 'gemini_cli.cpu.usage';
49 | const TOOL_QUEUE_DEPTH = 'gemini_cli.tool.queue.depth';
50 | const TOOL_EXECUTION_BREAKDOWN = 'gemini_cli.tool.execution.breakdown';
51 | const TOKEN_EFFICIENCY = 'gemini_cli.token.efficiency';
52 | const API_REQUEST_BREAKDOWN = 'gemini_cli.api.request.breakdown';
53 | const PERFORMANCE_SCORE = 'gemini_cli.performance.score';
54 | const REGRESSION_DETECTION = 'gemini_cli.performance.regression';
55 | const REGRESSION_PERCENTAGE_CHANGE =
56 |   'gemini_cli.performance.regression.percentage_change';
57 | const BASELINE_COMPARISON = 'gemini_cli.performance.baseline.comparison';
58 | const FLICKER_FRAME_COUNT = 'gemini_cli.ui.flicker.count';
59 | 
60 | const baseMetricDefinition = {
61 |   getCommonAttributes,
62 | };
63 | 
64 | const COUNTER_DEFINITIONS = {
65 |   [TOOL_CALL_COUNT]: {
66 |     description: 'Counts tool calls, tagged by function name and success.',
67 |     valueType: ValueType.INT,
68 |     assign: (c: Counter) => (toolCallCounter = c),
69 |     attributes: {} as {
70 |       function_name: string;
71 |       success: boolean;
72 |       decision?: 'accept' | 'reject' | 'modify' | 'auto_accept';
73 |       tool_type?: 'native' | 'mcp';
74 |       // Optional diff statistics for file-modifying tools
75 |       model_added_lines?: number;
76 |       model_removed_lines?: number;
77 |       user_added_lines?: number;
78 |       user_removed_lines?: number;
79 |     },
80 |   },
81 |   [API_REQUEST_COUNT]: {
82 |     description: 'Counts API requests, tagged by model and status.',
83 |     valueType: ValueType.INT,
84 |     assign: (c: Counter) => (apiRequestCounter = c),
85 |     attributes: {} as {
86 |       model: string;
87 |       status_code?: number | string;
88 |       error_type?: string;
89 |     },
90 |   },
91 |   [TOKEN_USAGE]: {
92 |     description: 'Counts the total number of tokens used.',
93 |     valueType: ValueType.INT,
94 |     assign: (c: Counter) => (tokenUsageCounter = c),
95 |     attributes: {} as {
96 |       model: string;
97 |       type: 'input' | 'output' | 'thought' | 'cache' | 'tool';
98 |     },
99 |   },
100 |   [SESSION_COUNT]: {
101 |     description: 'Count of CLI sessions started.',
102 |     valueType: ValueType.INT,
103 |     assign: (c: Counter) => (sessionCounter = c),
104 |     attributes: {} as Record<string, never>,
105 |   },
106 |   [FILE_OPERATION_COUNT]: {
107 |     description: 'Counts file operations (create, read, update).',
108 |     valueType: ValueType.INT,
109 |     assign: (c: Counter) => (fileOperationCounter = c),
110 |     attributes: {} as {
111 |       operation: FileOperation;
112 |       lines?: number;
113 |       mimetype?: string;
114 |       extension?: string;
115 |       programming_language?: string;
116 |     },
117 |   },
118 |   [INVALID_CHUNK_COUNT]: {
119 |     description: 'Counts invalid chunks received from a stream.',
120 |     valueType: ValueType.INT,
121 |     assign: (c: Counter) => (invalidChunkCounter = c),
122 |     attributes: {} as Record<string, never>,
123 |   },
124 |   [CONTENT_RETRY_COUNT]: {
125 |     description: 'Counts retries due to content errors (e.g., empty stream).',
126 |     valueType: ValueType.INT,
127 |     assign: (c: Counter) => (contentRetryCounter = c),
128 |     attributes: {} as Record<string, never>,
129 |   },
130 |   [CONTENT_RETRY_FAILURE_COUNT]: {
131 |     description: 'Counts occurrences of all content retries failing.',
132 |     valueType: ValueType.INT,
133 |     assign: (c: Counter) => (contentRetryFailureCounter = c),
134 |     attributes: {} as Record<string, never>,
135 |   },
136 |   [MODEL_ROUTING_FAILURE_COUNT]: {
137 |     description: 'Counts model routing failures.',
138 |     valueType: ValueType.INT,
139 |     assign: (c: Counter) => (modelRoutingFailureCounter = c),
140 |     attributes: {} as {
141 |       'routing.decision_source': string;
142 |       'routing.error_message': string;
143 |     },
144 |   },
145 |   [MODEL_SLASH_COMMAND_CALL_COUNT]: {
146 |     description: 'Counts model slash command calls.',
147 |     valueType: ValueType.INT,
148 |     assign: (c: Counter) => (modelSlashCommandCallCounter = c),
149 |     attributes: {} as {
150 |       'slash_command.model.model_name': string;
151 |     },
152 |   },
153 |   [EVENT_CHAT_COMPRESSION]: {
154 |     description: 'Counts chat compression events.',
155 |     valueType: ValueType.INT,
156 |     assign: (c: Counter) => (chatCompressionCounter = c),
157 |     attributes: {} as {
158 |       tokens_before: number;
159 |       tokens_after: number;
160 |     },
161 |   },
162 |   [AGENT_RUN_COUNT]: {
163 |     description: 'Counts agent runs, tagged by name and termination reason.',
164 |     valueType: ValueType.INT,
165 |     assign: (c: Counter) => (agentRunCounter = c),
166 |     attributes: {} as {
167 |       agent_name: string;
168 |       terminate_reason: string;
169 |     },
170 |   },
171 |   [FLICKER_FRAME_COUNT]: {
172 |     description:
173 |       'Counts UI frames that flicker (render taller than the terminal).',
174 |     valueType: ValueType.INT,
175 |     assign: (c: Counter) => (flickerFrameCounter = c),
176 |     attributes: {} as Record<string, never>,
177 |   },
178 | } as const;
179 | 
180 | const HISTOGRAM_DEFINITIONS = {
181 |   [TOOL_CALL_LATENCY]: {
182 |     description: 'Latency of tool calls in milliseconds.',
183 |     unit: 'ms',
184 |     valueType: ValueType.INT,
185 |     assign: (h: Histogram) => (toolCallLatencyHistogram = h),
186 |     attributes: {} as {
187 |       function_name: string;
188 |     },
189 |   },
190 |   [API_REQUEST_LATENCY]: {
191 |     description: 'Latency of API requests in milliseconds.',
192 |     unit: 'ms',
193 |     valueType: ValueType.INT,
194 |     assign: (h: Histogram) => (apiRequestLatencyHistogram = h),
195 |     attributes: {} as {
196 |       model: string;
197 |     },
198 |   },
199 |   [MODEL_ROUTING_LATENCY]: {
200 |     description: 'Latency of model routing decisions in milliseconds.',
201 |     unit: 'ms',
202 |     valueType: ValueType.INT,
203 |     assign: (h: Histogram) => (modelRoutingLatencyHistogram = h),
204 |     attributes: {} as {
205 |       'routing.decision_model': string;
206 |       'routing.decision_source': string;
207 |     },
208 |   },
209 |   [AGENT_DURATION_MS]: {
210 |     description: 'Duration of agent runs in milliseconds.',
211 |     unit: 'ms',
212 |     valueType: ValueType.INT,
213 |     assign: (h: Histogram) => (agentDurationHistogram = h),
214 |     attributes: {} as {
215 |       agent_name: string;
216 |     },
217 |   },
218 |   [AGENT_TURNS]: {
219 |     description: 'Number of turns taken by agents.',
220 |     unit: 'turns',
221 |     valueType: ValueType.INT,
222 |     assign: (h: Histogram) => (agentTurnsHistogram = h),
223 |     attributes: {} as {
224 |       agent_name: string;
225 |     },
226 |   },
227 |   [GEN_AI_CLIENT_TOKEN_USAGE]: {
228 |     description: 'Number of input and output tokens used.',
229 |     unit: 'token',
230 |     valueType: ValueType.INT,
231 |     assign: (h: Histogram) => (genAiClientTokenUsageHistogram = h),
232 |     attributes: {} as {
233 |       'gen_ai.operation.name': string;
234 |       'gen_ai.provider.name': string;
235 |       'gen_ai.token.type': 'input' | 'output';
236 |       'gen_ai.request.model'?: string;
237 |       'gen_ai.response.model'?: string;
238 |       'server.address'?: string;
239 |       'server.port'?: number;
240 |     },
241 |   },
242 |   [GEN_AI_CLIENT_OPERATION_DURATION]: {
243 |     description: 'GenAI operation duration.',
244 |     unit: 's',
245 |     valueType: ValueType.DOUBLE,
246 |     assign: (h: Histogram) => (genAiClientOperationDurationHistogram = h),
247 |     attributes: {} as {
248 |       'gen_ai.operation.name': string;
249 |       'gen_ai.provider.name': string;
250 |       'gen_ai.request.model'?: string;
251 |       'gen_ai.response.model'?: string;
252 |       'server.address'?: string;
253 |       'server.port'?: number;
254 |       'error.type'?: string;
255 |     },
256 |   },
257 | } as const;
258 | 
259 | const PERFORMANCE_COUNTER_DEFINITIONS = {
260 |   [REGRESSION_DETECTION]: {
261 |     description: 'Performance regression detection events.',
262 |     valueType: ValueType.INT,
263 |     assign: (c: Counter) => (regressionDetectionCounter = c),
264 |     attributes: {} as {
265 |       metric: string;
266 |       severity: 'low' | 'medium' | 'high';
267 |       current_value: number;
268 |       baseline_value: number;
269 |     },
270 |   },
271 | } as const;
272 | 
273 | const PERFORMANCE_HISTOGRAM_DEFINITIONS = {
274 |   [STARTUP_TIME]: {
275 |     description:
276 |       'CLI startup time in milliseconds, broken down by initialization phase.',
277 |     unit: 'ms',
278 |     valueType: ValueType.DOUBLE,
279 |     assign: (h: Histogram) => (startupTimeHistogram = h),
280 |     attributes: {} as {
281 |       phase: string;
282 |       details?: Record<string, string | number | boolean>;
283 |     },
284 |   },
285 |   [MEMORY_USAGE]: {
286 |     description: 'Memory usage in bytes.',
287 |     unit: 'bytes',
288 |     valueType: ValueType.INT,
289 |     assign: (h: Histogram) => (memoryUsageGauge = h),
290 |     attributes: {} as {
291 |       memory_type: MemoryMetricType;
292 |       component?: string;
293 |     },
294 |   },
295 |   [CPU_USAGE]: {
296 |     description: 'CPU usage percentage.',
297 |     unit: 'percent',
298 |     valueType: ValueType.DOUBLE,
299 |     assign: (h: Histogram) => (cpuUsageGauge = h),
300 |     attributes: {} as {
301 |       component?: string;
302 |     },
303 |   },
304 |   [TOOL_QUEUE_DEPTH]: {
305 |     description: 'Number of tools in execution queue.',
306 |     unit: 'count',
307 |     valueType: ValueType.INT,
308 |     assign: (h: Histogram) => (toolQueueDepthGauge = h),
309 |     attributes: {} as Record<string, never>,
310 |   },
311 |   [TOOL_EXECUTION_BREAKDOWN]: {
312 |     description: 'Tool execution time breakdown by phase in milliseconds.',
313 |     unit: 'ms',
314 |     valueType: ValueType.INT,
315 |     assign: (h: Histogram) => (toolExecutionBreakdownHistogram = h),
316 |     attributes: {} as {
317 |       function_name: string;
318 |       phase: ToolExecutionPhase;
319 |     },
320 |   },
321 |   [TOKEN_EFFICIENCY]: {
322 |     description:
323 |       'Token efficiency metrics (tokens per operation, cache hit rate, etc.).',
324 |     unit: 'ratio',
325 |     valueType: ValueType.DOUBLE,
326 |     assign: (h: Histogram) => (tokenEfficiencyHistogram = h),
327 |     attributes: {} as {
328 |       model: string;
329 |       metric: string;
330 |       context?: string;
331 |     },
332 |   },
333 |   [API_REQUEST_BREAKDOWN]: {
334 |     description: 'API request time breakdown by phase in milliseconds.',
335 |     unit: 'ms',
336 |     valueType: ValueType.INT,
337 |     assign: (h: Histogram) => (apiRequestBreakdownHistogram = h),
338 |     attributes: {} as {
339 |       model: string;
340 |       phase: ApiRequestPhase;
341 |     },
342 |   },
343 |   [PERFORMANCE_SCORE]: {
344 |     description: 'Composite performance score (0-100).',
345 |     unit: 'score',
346 |     valueType: ValueType.DOUBLE,
347 |     assign: (h: Histogram) => (performanceScoreGauge = h),
348 |     attributes: {} as {
349 |       category: string;
350 |       baseline?: number;
351 |     },
352 |   },
353 |   [REGRESSION_PERCENTAGE_CHANGE]: {
354 |     description:
355 |       'Percentage change compared to baseline for detected regressions.',
356 |     unit: 'percent',
357 |     valueType: ValueType.DOUBLE,
358 |     assign: (h: Histogram) => (regressionPercentageChangeHistogram = h),
359 |     attributes: {} as {
360 |       metric: string;
361 |       severity: 'low' | 'medium' | 'high';
362 |       current_value: number;
363 |       baseline_value: number;
364 |     },
365 |   },
366 |   [BASELINE_COMPARISON]: {
367 |     description:
368 |       'Performance comparison to established baseline (percentage change).',
369 |     unit: 'percent',
370 |     valueType: ValueType.DOUBLE,
371 |     assign: (h: Histogram) => (baselineComparisonHistogram = h),
372 |     attributes: {} as {
373 |       metric: string;
374 |       category: string;
375 |       current_value: number;
376 |       baseline_value: number;
377 |     },
378 |   },
379 | } as const;
380 | 
381 | type AllMetricDefs = typeof COUNTER_DEFINITIONS &
382 |   typeof HISTOGRAM_DEFINITIONS &
383 |   typeof PERFORMANCE_COUNTER_DEFINITIONS &
384 |   typeof PERFORMANCE_HISTOGRAM_DEFINITIONS;
385 | 
386 | export type MetricDefinitions = {
387 |   [K in keyof AllMetricDefs]: {
388 |     attributes: AllMetricDefs[K]['attributes'];
389 |   };
390 | };
391 | 
392 | export enum FileOperation {
393 |   CREATE = 'create',
394 |   READ = 'read',
395 |   UPDATE = 'update',
396 | }
397 | 
398 | export enum PerformanceMetricType {
399 |   STARTUP = 'startup',
400 |   MEMORY = 'memory',
401 |   CPU = 'cpu',
402 |   TOOL_EXECUTION = 'tool_execution',
403 |   API_REQUEST = 'api_request',
404 |   TOKEN_EFFICIENCY = 'token_efficiency',
405 | }
406 | 
407 | export enum MemoryMetricType {
408 |   HEAP_USED = 'heap_used',
409 |   HEAP_TOTAL = 'heap_total',
410 |   EXTERNAL = 'external',
411 |   RSS = 'rss',
412 | }
413 | 
414 | export enum ToolExecutionPhase {
415 |   VALIDATION = 'validation',
416 |   PREPARATION = 'preparation',
417 |   EXECUTION = 'execution',
418 |   RESULT_PROCESSING = 'result_processing',
419 | }
420 | 
421 | export enum ApiRequestPhase {
422 |   REQUEST_PREPARATION = 'request_preparation',
423 |   NETWORK_LATENCY = 'network_latency',
424 |   RESPONSE_PROCESSING = 'response_processing',
425 |   TOKEN_PROCESSING = 'token_processing',
426 | }
427 | 
428 | export enum GenAiOperationName {
429 |   GENERATE_CONTENT = 'generate_content',
430 | }
431 | 
432 | export enum GenAiProviderName {
433 |   GCP_GEN_AI = 'gcp.gen_ai',
434 |   GCP_VERTEX_AI = 'gcp.vertex_ai',
435 | }
436 | 
437 | export enum GenAiTokenType {
438 |   INPUT = 'input',
439 |   OUTPUT = 'output',
440 | }
441 | 
442 | let cliMeter: Meter | undefined;
443 | let toolCallCounter: Counter | undefined;
444 | let toolCallLatencyHistogram: Histogram | undefined;
445 | let apiRequestCounter: Counter | undefined;
446 | let apiRequestLatencyHistogram: Histogram | undefined;
447 | let tokenUsageCounter: Counter | undefined;
448 | let sessionCounter: Counter | undefined;
449 | let fileOperationCounter: Counter | undefined;
450 | let chatCompressionCounter: Counter | undefined;
451 | let invalidChunkCounter: Counter | undefined;
452 | let contentRetryCounter: Counter | undefined;
453 | let contentRetryFailureCounter: Counter | undefined;
454 | let modelRoutingLatencyHistogram: Histogram | undefined;
455 | let modelRoutingFailureCounter: Counter | undefined;
456 | let modelSlashCommandCallCounter: Counter | undefined;
457 | let agentRunCounter: Counter | undefined;
458 | let agentDurationHistogram: Histogram | undefined;
459 | let agentTurnsHistogram: Histogram | undefined;
460 | let flickerFrameCounter: Counter | undefined;
461 | 
462 | // OpenTelemetry GenAI Semantic Convention Metrics
463 | let genAiClientTokenUsageHistogram: Histogram | undefined;
464 | let genAiClientOperationDurationHistogram: Histogram | undefined;
465 | 
466 | // Performance Monitoring Metrics
467 | let startupTimeHistogram: Histogram | undefined;
468 | let memoryUsageGauge: Histogram | undefined; // Using Histogram until ObservableGauge is available
469 | let cpuUsageGauge: Histogram | undefined;
470 | let toolQueueDepthGauge: Histogram | undefined;
471 | let toolExecutionBreakdownHistogram: Histogram | undefined;
472 | let tokenEfficiencyHistogram: Histogram | undefined;
473 | let apiRequestBreakdownHistogram: Histogram | undefined;
474 | let performanceScoreGauge: Histogram | undefined;
475 | let regressionDetectionCounter: Counter | undefined;
476 | let regressionPercentageChangeHistogram: Histogram | undefined;
477 | let baselineComparisonHistogram: Histogram | undefined;
478 | let isMetricsInitialized = false;
479 | let isPerformanceMonitoringEnabled = false;
480 | 
481 | export function getMeter(): Meter | undefined {
482 |   if (!cliMeter) {
483 |     cliMeter = metrics.getMeter(SERVICE_NAME);
484 |   }
485 |   return cliMeter;
486 | }
487 | 
488 | export function initializeMetrics(config: Config): void {
489 |   if (isMetricsInitialized) return;
490 | 
491 |   const meter = getMeter();
492 |   if (!meter) return;
493 | 
494 |   // Initialize core metrics
495 |   Object.entries(COUNTER_DEFINITIONS).forEach(
496 |     ([name, { description, valueType, assign }]) => {
497 |       assign(meter.createCounter(name, { description, valueType }));
498 |     },
499 |   );
500 | 
501 |   Object.entries(HISTOGRAM_DEFINITIONS).forEach(
502 |     ([name, { description, unit, valueType, assign }]) => {
503 |       assign(meter.createHistogram(name, { description, unit, valueType }));
504 |     },
505 |   );
506 | 
507 |   // Increment session counter after all metrics are initialized
508 |   sessionCounter?.add(1, baseMetricDefinition.getCommonAttributes(config));
509 | 
510 |   // Initialize performance monitoring metrics if enabled
511 |   initializePerformanceMonitoring(config);
512 | 
513 |   isMetricsInitialized = true;
514 | }
515 | 
516 | export function recordChatCompressionMetrics(
517 |   config: Config,
518 |   attributes: MetricDefinitions[typeof EVENT_CHAT_COMPRESSION]['attributes'],
519 | ) {
520 |   if (!chatCompressionCounter || !isMetricsInitialized) return;
521 |   chatCompressionCounter.add(1, {
522 |     ...baseMetricDefinition.getCommonAttributes(config),
523 |     ...attributes,
524 |   });
525 | }
526 | 
527 | export function recordToolCallMetrics(
528 |   config: Config,
529 |   durationMs: number,
530 |   attributes: MetricDefinitions[typeof TOOL_CALL_COUNT]['attributes'],
531 | ): void {
532 |   if (!toolCallCounter || !toolCallLatencyHistogram || !isMetricsInitialized)
533 |     return;
534 | 
535 |   const metricAttributes: Attributes = {
536 |     ...baseMetricDefinition.getCommonAttributes(config),
537 |     ...attributes,
538 |   };
539 |   toolCallCounter.add(1, metricAttributes);
540 |   toolCallLatencyHistogram.record(durationMs, {
541 |     ...baseMetricDefinition.getCommonAttributes(config),
542 |     function_name: attributes.function_name,
543 |   });
544 | }
545 | 
546 | export function recordCustomTokenUsageMetrics(
547 |   config: Config,
548 |   tokenCount: number,
549 |   attributes: MetricDefinitions[typeof TOKEN_USAGE]['attributes'],
550 | ): void {
551 |   if (!tokenUsageCounter || !isMetricsInitialized) return;
552 |   tokenUsageCounter.add(tokenCount, {
553 |     ...baseMetricDefinition.getCommonAttributes(config),
554 |     ...attributes,
555 |   });
556 | }
557 | 
558 | export function recordCustomApiResponseMetrics(
559 |   config: Config,
560 |   durationMs: number,
561 |   attributes: MetricDefinitions[typeof API_REQUEST_COUNT]['attributes'],
562 | ): void {
563 |   if (
564 |     !apiRequestCounter ||
565 |     !apiRequestLatencyHistogram ||
566 |     !isMetricsInitialized
567 |   )
568 |     return;
569 |   const metricAttributes: Attributes = {
570 |     ...baseMetricDefinition.getCommonAttributes(config),
571 |     model: attributes.model,
572 |     status_code: attributes.status_code ?? 'ok',
573 |   };
574 |   apiRequestCounter.add(1, metricAttributes);
575 |   apiRequestLatencyHistogram.record(durationMs, {
576 |     ...baseMetricDefinition.getCommonAttributes(config),
577 |     model: attributes.model,
578 |   });
579 | }
580 | 
581 | export function recordApiErrorMetrics(
582 |   config: Config,
583 |   durationMs: number,
584 |   attributes: MetricDefinitions[typeof API_REQUEST_COUNT]['attributes'],
585 | ): void {
586 |   if (
587 |     !apiRequestCounter ||
588 |     !apiRequestLatencyHistogram ||
589 |     !isMetricsInitialized
590 |   )
591 |     return;
592 |   const metricAttributes: Attributes = {
593 |     ...baseMetricDefinition.getCommonAttributes(config),
594 |     model: attributes.model,
595 |     status_code: attributes.status_code ?? 'error',
596 |     error_type: attributes.error_type ?? 'unknown',
597 |   };
598 |   apiRequestCounter.add(1, metricAttributes);
[TRUNCATED]
```

src/telemetry/rate-limiter.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, vi } from 'vitest';
8 | import { RateLimiter } from './rate-limiter.js';
9 | 
10 | describe('RateLimiter', () => {
11 |   let rateLimiter: RateLimiter;
12 | 
13 |   beforeEach(() => {
14 |     rateLimiter = new RateLimiter(1000); // 1 second interval for testing
15 |   });
16 | 
17 |   describe('constructor', () => {
18 |     it('should initialize with default interval', () => {
19 |       const defaultLimiter = new RateLimiter();
20 |       expect(defaultLimiter).toBeInstanceOf(RateLimiter);
21 |     });
22 | 
23 |     it('should initialize with custom interval', () => {
24 |       const customLimiter = new RateLimiter(5000);
25 |       expect(customLimiter).toBeInstanceOf(RateLimiter);
26 |     });
27 | 
28 |     it('should throw on negative interval', () => {
29 |       expect(() => new RateLimiter(-1)).toThrow(
30 |         'minIntervalMs must be non-negative.',
31 |       );
32 |     });
33 |   });
34 | 
35 |   describe('shouldRecord', () => {
36 |     it('should allow first recording', () => {
37 |       const result = rateLimiter.shouldRecord('test_metric');
38 |       expect(result).toBe(true);
39 |     });
40 | 
41 |     it('should block immediate subsequent recordings', () => {
42 |       rateLimiter.shouldRecord('test_metric'); // First call
43 |       const result = rateLimiter.shouldRecord('test_metric'); // Immediate second call
44 |       expect(result).toBe(false);
45 |     });
46 | 
47 |     it('should allow recording after interval', () => {
48 |       vi.useFakeTimers();
49 | 
50 |       rateLimiter.shouldRecord('test_metric'); // First call
51 | 
52 |       // Advance time past interval
53 |       vi.advanceTimersByTime(1500);
54 | 
55 |       const result = rateLimiter.shouldRecord('test_metric');
56 |       expect(result).toBe(true);
57 | 
58 |       vi.useRealTimers();
59 |     });
60 | 
61 |     it('should handle different metric keys independently', () => {
62 |       rateLimiter.shouldRecord('metric_a'); // First call for metric_a
63 | 
64 |       const resultA = rateLimiter.shouldRecord('metric_a'); // Second call for metric_a
65 |       const resultB = rateLimiter.shouldRecord('metric_b'); // First call for metric_b
66 | 
67 |       expect(resultA).toBe(false); // Should be blocked
68 |       expect(resultB).toBe(true); // Should be allowed
69 |     });
70 | 
71 |     it('should use shorter interval for high priority events', () => {
72 |       vi.useFakeTimers();
73 | 
74 |       rateLimiter.shouldRecord('test_metric', true); // High priority
75 | 
76 |       // Advance time by half the normal interval
77 |       vi.advanceTimersByTime(500);
78 | 
79 |       const result = rateLimiter.shouldRecord('test_metric', true);
80 |       expect(result).toBe(true); // Should be allowed due to high priority
81 | 
82 |       vi.useRealTimers();
83 |     });
84 | 
85 |     it('should still block high priority events if interval not met', () => {
86 |       vi.useFakeTimers();
87 | 
88 |       rateLimiter.shouldRecord('test_metric', true); // High priority
89 | 
90 |       // Advance time by less than half interval
91 |       vi.advanceTimersByTime(300);
92 | 
93 |       const result = rateLimiter.shouldRecord('test_metric', true);
94 |       expect(result).toBe(false); // Should still be blocked
95 | 
96 |       vi.useRealTimers();
97 |     });
98 |   });
99 | 
100 |   describe('forceRecord', () => {
101 |     it('should update last record time', () => {
102 |       const before = rateLimiter.getTimeUntilNextAllowed('test_metric');
103 | 
104 |       rateLimiter.forceRecord('test_metric');
105 | 
106 |       const after = rateLimiter.getTimeUntilNextAllowed('test_metric');
107 |       expect(after).toBeGreaterThan(before);
108 |     });
109 | 
110 |     it('should block subsequent recordings after force record', () => {
111 |       rateLimiter.forceRecord('test_metric');
112 | 
113 |       const result = rateLimiter.shouldRecord('test_metric');
114 |       expect(result).toBe(false);
115 |     });
116 |   });
117 | 
118 |   describe('getTimeUntilNextAllowed', () => {
119 |     it('should return 0 for new metric', () => {
120 |       const time = rateLimiter.getTimeUntilNextAllowed('new_metric');
121 |       expect(time).toBe(0);
122 |     });
123 | 
124 |     it('should return correct time after recording', () => {
125 |       vi.useFakeTimers();
126 | 
127 |       rateLimiter.shouldRecord('test_metric');
128 | 
129 |       // Advance time partially
130 |       vi.advanceTimersByTime(300);
131 | 
132 |       const timeRemaining = rateLimiter.getTimeUntilNextAllowed('test_metric');
133 |       expect(timeRemaining).toBeCloseTo(700, -1); // Approximately 700ms remaining
134 | 
135 |       vi.useRealTimers();
136 |     });
137 | 
138 |     it('should return 0 after interval has passed', () => {
139 |       vi.useFakeTimers();
140 | 
141 |       rateLimiter.shouldRecord('test_metric');
142 | 
143 |       // Advance time past interval
144 |       vi.advanceTimersByTime(1500);
145 | 
146 |       const timeRemaining = rateLimiter.getTimeUntilNextAllowed('test_metric');
147 |       expect(timeRemaining).toBe(0);
148 | 
149 |       vi.useRealTimers();
150 |     });
151 | 
152 |     it('should account for high priority interval', () => {
153 |       vi.useFakeTimers();
154 | 
155 |       rateLimiter.shouldRecord('hp_metric', true);
156 | 
157 |       // After 300ms, with 1000ms base interval, half rounded is 500ms
158 |       vi.advanceTimersByTime(300);
159 | 
160 |       const timeRemaining = rateLimiter.getTimeUntilNextAllowed(
161 |         'hp_metric',
162 |         true,
163 |       );
164 |       expect(timeRemaining).toBeCloseTo(200, -1);
165 | 
166 |       vi.useRealTimers();
167 |     });
168 |   });
169 | 
170 |   describe('getStats', () => {
171 |     it('should return empty stats initially', () => {
172 |       const stats = rateLimiter.getStats();
173 |       expect(stats).toEqual({
174 |         totalMetrics: 0,
175 |         oldestRecord: 0,
176 |         newestRecord: 0,
177 |         averageInterval: 0,
178 |       });
179 |     });
180 | 
181 |     it('should return correct stats after recordings', () => {
182 |       vi.useFakeTimers();
183 | 
184 |       rateLimiter.shouldRecord('metric_a');
185 |       vi.advanceTimersByTime(500);
186 |       rateLimiter.shouldRecord('metric_b');
187 |       vi.advanceTimersByTime(500);
188 |       rateLimiter.shouldRecord('metric_c');
189 | 
190 |       const stats = rateLimiter.getStats();
191 |       expect(stats.totalMetrics).toBe(3);
192 |       expect(stats.averageInterval).toBeCloseTo(500, -1);
193 | 
194 |       vi.useRealTimers();
195 |     });
196 | 
197 |     it('should handle single recording correctly', () => {
198 |       rateLimiter.shouldRecord('test_metric');
199 | 
200 |       const stats = rateLimiter.getStats();
201 |       expect(stats.totalMetrics).toBe(1);
202 |       expect(stats.averageInterval).toBe(0);
203 |     });
204 |   });
205 | 
206 |   describe('reset', () => {
207 |     it('should clear all rate limiting state', () => {
208 |       rateLimiter.shouldRecord('metric_a');
209 |       rateLimiter.shouldRecord('metric_b');
210 | 
211 |       rateLimiter.reset();
212 | 
213 |       const stats = rateLimiter.getStats();
214 |       expect(stats.totalMetrics).toBe(0);
215 | 
216 |       // Should allow immediate recording after reset
217 |       const result = rateLimiter.shouldRecord('metric_a');
218 |       expect(result).toBe(true);
219 |     });
220 |   });
221 | 
222 |   describe('cleanup', () => {
223 |     it('should remove old entries', () => {
224 |       vi.useFakeTimers();
225 | 
226 |       rateLimiter.shouldRecord('old_metric');
227 | 
228 |       // Advance time beyond cleanup threshold
229 |       vi.advanceTimersByTime(4000000); // More than 1 hour
230 | 
231 |       rateLimiter.cleanup(3600000); // 1 hour cleanup
232 | 
233 |       // Should allow immediate recording of old metric after cleanup
234 |       const result = rateLimiter.shouldRecord('old_metric');
235 |       expect(result).toBe(true);
236 | 
237 |       vi.useRealTimers();
238 |     });
239 | 
240 |     it('should preserve recent entries', () => {
241 |       vi.useFakeTimers();
242 | 
243 |       rateLimiter.shouldRecord('recent_metric');
244 | 
245 |       // Advance time but not beyond cleanup threshold
246 |       vi.advanceTimersByTime(1800000); // 30 minutes
247 | 
248 |       rateLimiter.cleanup(3600000); // 1 hour cleanup
249 | 
250 |       // Should no longer be rate limited after 30 minutes (way past 1 minute default interval)
251 |       const result = rateLimiter.shouldRecord('recent_metric');
252 |       expect(result).toBe(true);
253 | 
254 |       vi.useRealTimers();
255 |     });
256 | 
257 |     it('should use default cleanup age', () => {
258 |       vi.useFakeTimers();
259 | 
260 |       rateLimiter.shouldRecord('test_metric');
261 | 
262 |       // Advance time beyond default cleanup (1 hour)
263 |       vi.advanceTimersByTime(4000000);
264 | 
265 |       rateLimiter.cleanup(); // Use default age
266 | 
267 |       const result = rateLimiter.shouldRecord('test_metric');
268 |       expect(result).toBe(true);
269 | 
270 |       vi.useRealTimers();
271 |     });
272 |   });
273 | 
274 |   describe('edge cases', () => {
275 |     it('should handle zero interval', () => {
276 |       const zeroLimiter = new RateLimiter(0);
277 | 
278 |       zeroLimiter.shouldRecord('test_metric');
279 |       const result = zeroLimiter.shouldRecord('test_metric');
280 | 
281 |       expect(result).toBe(true); // Should allow with zero interval
282 |     });
283 | 
284 |     it('should handle very large intervals', () => {
285 |       const longLimiter = new RateLimiter(Number.MAX_SAFE_INTEGER);
286 | 
287 |       longLimiter.shouldRecord('test_metric');
288 |       const timeRemaining = longLimiter.getTimeUntilNextAllowed('test_metric');
289 | 
290 |       expect(timeRemaining).toBeGreaterThan(1000000);
291 |     });
292 |   });
293 | });
```

src/telemetry/rate-limiter.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Rate limiter to prevent excessive telemetry recording
9 |  * Ensures we don't send metrics more frequently than specified limits
10 |  */
11 | export class RateLimiter {
12 |   private lastRecordTimes: Map<string, number> = new Map();
13 |   private readonly minIntervalMs: number;
14 |   private static readonly HIGH_PRIORITY_DIVISOR = 2;
15 | 
16 |   constructor(minIntervalMs: number = 60000) {
17 |     if (minIntervalMs < 0) {
18 |       throw new Error('minIntervalMs must be non-negative.');
19 |     }
20 |     this.minIntervalMs = minIntervalMs;
21 |   }
22 | 
23 |   /**
24 |    * Check if we should record a metric based on rate limiting
25 |    * @param metricKey - Unique key for the metric type/context
26 |    * @param isHighPriority - If true, uses shorter interval for critical events
27 |    * @returns true if metric should be recorded
28 |    */
29 |   shouldRecord(metricKey: string, isHighPriority: boolean = false): boolean {
30 |     const now = Date.now();
31 |     const lastRecordTime = this.lastRecordTimes.get(metricKey) || 0;
32 | 
33 |     // Use shorter interval for high priority events (e.g., memory leaks)
34 |     const interval = isHighPriority
35 |       ? Math.round(this.minIntervalMs / RateLimiter.HIGH_PRIORITY_DIVISOR)
36 |       : this.minIntervalMs;
37 | 
38 |     if (now - lastRecordTime >= interval) {
39 |       this.lastRecordTimes.set(metricKey, now);
40 |       return true;
41 |     }
42 | 
43 |     return false;
44 |   }
45 | 
46 |   /**
47 |    * Force record a metric (bypasses rate limiting)
48 |    * Use sparingly for critical events
49 |    */
50 |   forceRecord(metricKey: string): void {
51 |     this.lastRecordTimes.set(metricKey, Date.now());
52 |   }
53 | 
54 |   /**
55 |    * Get time until next allowed recording for a metric
56 |    */
57 |   getTimeUntilNextAllowed(
58 |     metricKey: string,
59 |     isHighPriority: boolean = false,
60 |   ): number {
61 |     const now = Date.now();
62 |     const lastRecordTime = this.lastRecordTimes.get(metricKey) || 0;
63 |     const interval = isHighPriority
64 |       ? Math.round(this.minIntervalMs / RateLimiter.HIGH_PRIORITY_DIVISOR)
65 |       : this.minIntervalMs;
66 |     const nextAllowedTime = lastRecordTime + interval;
67 | 
68 |     return Math.max(0, nextAllowedTime - now);
69 |   }
70 | 
71 |   /**
72 |    * Get statistics about rate limiting
73 |    */
74 |   getStats(): {
75 |     totalMetrics: number;
76 |     oldestRecord: number;
77 |     newestRecord: number;
78 |     averageInterval: number;
79 |   } {
80 |     const recordTimes = Array.from(this.lastRecordTimes.values());
81 | 
82 |     if (recordTimes.length === 0) {
83 |       return {
84 |         totalMetrics: 0,
85 |         oldestRecord: 0,
86 |         newestRecord: 0,
87 |         averageInterval: 0,
88 |       };
89 |     }
90 | 
91 |     const oldest = Math.min(...recordTimes);
92 |     const newest = Math.max(...recordTimes);
93 |     const totalSpan = newest - oldest;
94 |     const averageInterval =
95 |       recordTimes.length > 1 ? totalSpan / (recordTimes.length - 1) : 0;
96 | 
97 |     return {
98 |       totalMetrics: recordTimes.length,
99 |       oldestRecord: oldest,
100 |       newestRecord: newest,
101 |       averageInterval,
102 |     };
103 |   }
104 | 
105 |   /**
106 |    * Clear all rate limiting state
107 |    */
108 |   reset(): void {
109 |     this.lastRecordTimes.clear();
110 |   }
111 | 
112 |   /**
113 |    * Remove old entries to prevent memory leaks
114 |    */
115 |   cleanup(maxAgeMs: number = 3600000): void {
116 |     const cutoffTime = Date.now() - maxAgeMs;
117 | 
118 |     for (const [key, time] of this.lastRecordTimes.entries()) {
119 |       if (time < cutoffTime) {
120 |         this.lastRecordTimes.delete(key);
121 |       }
122 |     }
123 |   }
124 | }
```

src/telemetry/sdk.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import type { Config } from '../config/config.js';
9 | import { initializeTelemetry, shutdownTelemetry } from './sdk.js';
10 | import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-grpc';
11 | import { OTLPLogExporter } from '@opentelemetry/exporter-logs-otlp-grpc';
12 | import { OTLPMetricExporter } from '@opentelemetry/exporter-metrics-otlp-grpc';
13 | import { OTLPTraceExporter as OTLPTraceExporterHttp } from '@opentelemetry/exporter-trace-otlp-http';
14 | import { OTLPLogExporter as OTLPLogExporterHttp } from '@opentelemetry/exporter-logs-otlp-http';
15 | import { OTLPMetricExporter as OTLPMetricExporterHttp } from '@opentelemetry/exporter-metrics-otlp-http';
16 | import { NodeSDK } from '@opentelemetry/sdk-node';
17 | import {
18 |   GcpTraceExporter,
19 |   GcpLogExporter,
20 |   GcpMetricExporter,
21 | } from './gcp-exporters.js';
22 | import { TelemetryTarget } from './index.js';
23 | 
24 | import * as os from 'node:os';
25 | import * as path from 'node:path';
26 | 
27 | vi.mock('@opentelemetry/exporter-trace-otlp-grpc');
28 | vi.mock('@opentelemetry/exporter-logs-otlp-grpc');
29 | vi.mock('@opentelemetry/exporter-metrics-otlp-grpc');
30 | vi.mock('@opentelemetry/exporter-trace-otlp-http');
31 | vi.mock('@opentelemetry/exporter-logs-otlp-http');
32 | vi.mock('@opentelemetry/exporter-metrics-otlp-http');
33 | vi.mock('@opentelemetry/sdk-node');
34 | vi.mock('./gcp-exporters.js');
35 | 
36 | describe('Telemetry SDK', () => {
37 |   let mockConfig: Config;
38 | 
39 |   beforeEach(() => {
40 |     vi.clearAllMocks();
41 |     mockConfig = {
42 |       getTelemetryEnabled: () => true,
43 |       getTelemetryOtlpEndpoint: () => 'http://localhost:4317',
44 |       getTelemetryOtlpProtocol: () => 'grpc',
45 |       getTelemetryTarget: () => 'local',
46 |       getTelemetryUseCollector: () => false,
47 |       getTelemetryOutfile: () => undefined,
48 |       getDebugMode: () => false,
49 |       getSessionId: () => 'test-session',
50 |     } as unknown as Config;
51 |   });
52 | 
53 |   afterEach(async () => {
54 |     await shutdownTelemetry(mockConfig);
55 |   });
56 | 
57 |   it('should use gRPC exporters when protocol is grpc', () => {
58 |     initializeTelemetry(mockConfig);
59 | 
60 |     expect(OTLPTraceExporter).toHaveBeenCalledWith({
61 |       url: 'http://localhost:4317',
62 |       compression: 'gzip',
63 |     });
64 |     expect(OTLPLogExporter).toHaveBeenCalledWith({
65 |       url: 'http://localhost:4317',
66 |       compression: 'gzip',
67 |     });
68 |     expect(OTLPMetricExporter).toHaveBeenCalledWith({
69 |       url: 'http://localhost:4317',
70 |       compression: 'gzip',
71 |     });
72 |     expect(NodeSDK.prototype.start).toHaveBeenCalled();
73 |   });
74 | 
75 |   it('should use HTTP exporters when protocol is http', () => {
76 |     vi.spyOn(mockConfig, 'getTelemetryEnabled').mockReturnValue(true);
77 |     vi.spyOn(mockConfig, 'getTelemetryOtlpProtocol').mockReturnValue('http');
78 |     vi.spyOn(mockConfig, 'getTelemetryOtlpEndpoint').mockReturnValue(
79 |       'http://localhost:4318',
80 |     );
81 | 
82 |     initializeTelemetry(mockConfig);
83 | 
84 |     expect(OTLPTraceExporterHttp).toHaveBeenCalledWith({
85 |       url: 'http://localhost:4318/',
86 |     });
87 |     expect(OTLPLogExporterHttp).toHaveBeenCalledWith({
88 |       url: 'http://localhost:4318/',
89 |     });
90 |     expect(OTLPMetricExporterHttp).toHaveBeenCalledWith({
91 |       url: 'http://localhost:4318/',
92 |     });
93 |     expect(NodeSDK.prototype.start).toHaveBeenCalled();
94 |   });
95 | 
96 |   it('should parse gRPC endpoint correctly', () => {
97 |     vi.spyOn(mockConfig, 'getTelemetryOtlpEndpoint').mockReturnValue(
98 |       'https://my-collector.com',
99 |     );
100 |     initializeTelemetry(mockConfig);
101 |     expect(OTLPTraceExporter).toHaveBeenCalledWith(
102 |       expect.objectContaining({ url: 'https://my-collector.com' }),
103 |     );
104 |   });
105 | 
106 |   it('should parse HTTP endpoint correctly', () => {
107 |     vi.spyOn(mockConfig, 'getTelemetryOtlpProtocol').mockReturnValue('http');
108 |     vi.spyOn(mockConfig, 'getTelemetryOtlpEndpoint').mockReturnValue(
109 |       'https://my-collector.com',
110 |     );
111 |     initializeTelemetry(mockConfig);
112 |     expect(OTLPTraceExporterHttp).toHaveBeenCalledWith(
113 |       expect.objectContaining({ url: 'https://my-collector.com/' }),
114 |     );
115 |   });
116 | 
117 |   it('should use direct GCP exporters when target is gcp, project ID is set, and useCollector is false', () => {
118 |     vi.spyOn(mockConfig, 'getTelemetryTarget').mockReturnValue(
119 |       TelemetryTarget.GCP,
120 |     );
121 |     vi.spyOn(mockConfig, 'getTelemetryUseCollector').mockReturnValue(false);
122 |     vi.spyOn(mockConfig, 'getTelemetryOtlpEndpoint').mockReturnValue('');
123 | 
124 |     const originalEnv = process.env['OTLP_GOOGLE_CLOUD_PROJECT'];
125 |     process.env['OTLP_GOOGLE_CLOUD_PROJECT'] = 'test-project';
126 | 
127 |     try {
128 |       initializeTelemetry(mockConfig);
129 | 
130 |       expect(GcpTraceExporter).toHaveBeenCalledWith('test-project');
131 |       expect(GcpLogExporter).toHaveBeenCalledWith('test-project');
132 |       expect(GcpMetricExporter).toHaveBeenCalledWith('test-project');
133 |       expect(NodeSDK.prototype.start).toHaveBeenCalled();
134 |     } finally {
135 |       if (originalEnv) {
136 |         process.env['OTLP_GOOGLE_CLOUD_PROJECT'] = originalEnv;
137 |       } else {
138 |         delete process.env['OTLP_GOOGLE_CLOUD_PROJECT'];
139 |       }
140 |     }
141 |   });
142 | 
143 |   it('should use OTLP exporters when target is gcp but useCollector is true', () => {
144 |     vi.spyOn(mockConfig, 'getTelemetryTarget').mockReturnValue(
145 |       TelemetryTarget.GCP,
146 |     );
147 |     vi.spyOn(mockConfig, 'getTelemetryUseCollector').mockReturnValue(true);
148 | 
149 |     initializeTelemetry(mockConfig);
150 | 
151 |     expect(OTLPTraceExporter).toHaveBeenCalledWith({
152 |       url: 'http://localhost:4317',
153 |       compression: 'gzip',
154 |     });
155 |     expect(OTLPLogExporter).toHaveBeenCalledWith({
156 |       url: 'http://localhost:4317',
157 |       compression: 'gzip',
158 |     });
159 |     expect(OTLPMetricExporter).toHaveBeenCalledWith({
160 |       url: 'http://localhost:4317',
161 |       compression: 'gzip',
162 |     });
163 |   });
164 | 
165 |   it('should not use GCP exporters when project ID environment variable is not set', () => {
166 |     vi.spyOn(mockConfig, 'getTelemetryTarget').mockReturnValue(
167 |       TelemetryTarget.GCP,
168 |     );
169 |     vi.spyOn(mockConfig, 'getTelemetryUseCollector').mockReturnValue(false);
170 |     vi.spyOn(mockConfig, 'getTelemetryOtlpEndpoint').mockReturnValue('');
171 | 
172 |     const originalOtlpEnv = process.env['OTLP_GOOGLE_CLOUD_PROJECT'];
173 |     const originalGoogleEnv = process.env['GOOGLE_CLOUD_PROJECT'];
174 |     delete process.env['OTLP_GOOGLE_CLOUD_PROJECT'];
175 |     delete process.env['GOOGLE_CLOUD_PROJECT'];
176 | 
177 |     try {
178 |       initializeTelemetry(mockConfig);
179 | 
180 |       expect(GcpTraceExporter).not.toHaveBeenCalled();
181 |       expect(GcpLogExporter).not.toHaveBeenCalled();
182 |       expect(GcpMetricExporter).not.toHaveBeenCalled();
183 |       expect(NodeSDK.prototype.start).toHaveBeenCalled();
184 |     } finally {
185 |       if (originalOtlpEnv) {
186 |         process.env['OTLP_GOOGLE_CLOUD_PROJECT'] = originalOtlpEnv;
187 |       }
188 |       if (originalGoogleEnv) {
189 |         process.env['GOOGLE_CLOUD_PROJECT'] = originalGoogleEnv;
190 |       }
191 |     }
192 |   });
193 | 
194 |   it('should use GOOGLE_CLOUD_PROJECT as fallback when OTLP_GOOGLE_CLOUD_PROJECT is not set', () => {
195 |     vi.spyOn(mockConfig, 'getTelemetryTarget').mockReturnValue(
196 |       TelemetryTarget.GCP,
197 |     );
198 |     vi.spyOn(mockConfig, 'getTelemetryUseCollector').mockReturnValue(false);
199 |     vi.spyOn(mockConfig, 'getTelemetryOtlpEndpoint').mockReturnValue('');
200 | 
201 |     const originalOtlpEnv = process.env['OTLP_GOOGLE_CLOUD_PROJECT'];
202 |     const originalGoogleEnv = process.env['GOOGLE_CLOUD_PROJECT'];
203 |     delete process.env['OTLP_GOOGLE_CLOUD_PROJECT'];
204 |     process.env['GOOGLE_CLOUD_PROJECT'] = 'fallback-project';
205 | 
206 |     try {
207 |       initializeTelemetry(mockConfig);
208 | 
209 |       expect(GcpTraceExporter).toHaveBeenCalledWith('fallback-project');
210 |       expect(GcpLogExporter).toHaveBeenCalledWith('fallback-project');
211 |       expect(GcpMetricExporter).toHaveBeenCalledWith('fallback-project');
212 |       expect(NodeSDK.prototype.start).toHaveBeenCalled();
213 |     } finally {
214 |       if (originalOtlpEnv) {
215 |         process.env['OTLP_GOOGLE_CLOUD_PROJECT'] = originalOtlpEnv;
216 |       }
217 |       if (originalGoogleEnv) {
218 |         process.env['GOOGLE_CLOUD_PROJECT'] = originalGoogleEnv;
219 |       } else {
220 |         delete process.env['GOOGLE_CLOUD_PROJECT'];
221 |       }
222 |     }
223 |   });
224 | 
225 |   it('should not use OTLP exporters when telemetryOutfile is set', () => {
226 |     vi.spyOn(mockConfig, 'getTelemetryOutfile').mockReturnValue(
227 |       path.join(os.tmpdir(), 'test.log'),
228 |     );
229 |     initializeTelemetry(mockConfig);
230 | 
231 |     expect(OTLPTraceExporter).not.toHaveBeenCalled();
232 |     expect(OTLPLogExporter).not.toHaveBeenCalled();
233 |     expect(OTLPMetricExporter).not.toHaveBeenCalled();
234 |     expect(OTLPTraceExporterHttp).not.toHaveBeenCalled();
235 |     expect(OTLPLogExporterHttp).not.toHaveBeenCalled();
236 |     expect(OTLPMetricExporterHttp).not.toHaveBeenCalled();
237 |     expect(NodeSDK.prototype.start).toHaveBeenCalled();
238 |   });
239 | });
```

src/telemetry/sdk.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { DiagConsoleLogger, DiagLogLevel, diag } from '@opentelemetry/api';
8 | import { OTLPTraceExporter } from '@opentelemetry/exporter-trace-otlp-grpc';
9 | import { OTLPLogExporter } from '@opentelemetry/exporter-logs-otlp-grpc';
10 | import { OTLPMetricExporter } from '@opentelemetry/exporter-metrics-otlp-grpc';
11 | import { OTLPTraceExporter as OTLPTraceExporterHttp } from '@opentelemetry/exporter-trace-otlp-http';
12 | import { OTLPLogExporter as OTLPLogExporterHttp } from '@opentelemetry/exporter-logs-otlp-http';
13 | import { OTLPMetricExporter as OTLPMetricExporterHttp } from '@opentelemetry/exporter-metrics-otlp-http';
14 | import { CompressionAlgorithm } from '@opentelemetry/otlp-exporter-base';
15 | import { NodeSDK } from '@opentelemetry/sdk-node';
16 | import { SemanticResourceAttributes } from '@opentelemetry/semantic-conventions';
17 | import { resourceFromAttributes } from '@opentelemetry/resources';
18 | import {
19 |   BatchSpanProcessor,
20 |   ConsoleSpanExporter,
21 | } from '@opentelemetry/sdk-trace-node';
22 | import {
23 |   BatchLogRecordProcessor,
24 |   ConsoleLogRecordExporter,
25 | } from '@opentelemetry/sdk-logs';
26 | import {
27 |   ConsoleMetricExporter,
28 |   PeriodicExportingMetricReader,
29 | } from '@opentelemetry/sdk-metrics';
30 | import { HttpInstrumentation } from '@opentelemetry/instrumentation-http';
31 | import type { Config } from '../config/config.js';
32 | import { SERVICE_NAME } from './constants.js';
33 | import { initializeMetrics } from './metrics.js';
34 | import { ClearcutLogger } from './clearcut-logger/clearcut-logger.js';
35 | import {
36 |   FileLogExporter,
37 |   FileMetricExporter,
38 |   FileSpanExporter,
39 | } from './file-exporters.js';
40 | import {
41 |   GcpTraceExporter,
42 |   GcpMetricExporter,
43 |   GcpLogExporter,
44 | } from './gcp-exporters.js';
45 | import { TelemetryTarget } from './index.js';
46 | 
47 | // For troubleshooting, set the log level to DiagLogLevel.DEBUG
48 | diag.setLogger(new DiagConsoleLogger(), DiagLogLevel.INFO);
49 | 
50 | let sdk: NodeSDK | undefined;
51 | let telemetryInitialized = false;
52 | 
53 | export function isTelemetrySdkInitialized(): boolean {
54 |   return telemetryInitialized;
55 | }
56 | 
57 | function parseOtlpEndpoint(
58 |   otlpEndpointSetting: string | undefined,
59 |   protocol: 'grpc' | 'http',
60 | ): string | undefined {
61 |   if (!otlpEndpointSetting) {
62 |     return undefined;
63 |   }
64 |   // Trim leading/trailing quotes that might come from env variables
65 |   const trimmedEndpoint = otlpEndpointSetting.replace(/^["']|["']$/g, '');
66 | 
67 |   try {
68 |     const url = new URL(trimmedEndpoint);
69 |     if (protocol === 'grpc') {
70 |       // OTLP gRPC exporters expect an endpoint in the format scheme://host:port
71 |       // The `origin` property provides this, stripping any path, query, or hash.
72 |       return url.origin;
73 |     }
74 |     // For http, use the full href.
75 |     return url.href;
76 |   } catch (error) {
77 |     diag.error('Invalid OTLP endpoint URL provided:', trimmedEndpoint, error);
78 |     return undefined;
79 |   }
80 | }
81 | 
82 | export function initializeTelemetry(config: Config): void {
83 |   if (telemetryInitialized || !config.getTelemetryEnabled()) {
84 |     return;
85 |   }
86 | 
87 |   const resource = resourceFromAttributes({
88 |     [SemanticResourceAttributes.SERVICE_NAME]: SERVICE_NAME,
89 |     [SemanticResourceAttributes.SERVICE_VERSION]: process.version,
90 |     'session.id': config.getSessionId(),
91 |   });
92 | 
93 |   const otlpEndpoint = config.getTelemetryOtlpEndpoint();
94 |   const otlpProtocol = config.getTelemetryOtlpProtocol();
95 |   const telemetryTarget = config.getTelemetryTarget();
96 |   const useCollector = config.getTelemetryUseCollector();
97 |   const parsedEndpoint = parseOtlpEndpoint(otlpEndpoint, otlpProtocol);
98 |   const telemetryOutfile = config.getTelemetryOutfile();
99 |   const useOtlp = !!parsedEndpoint && !telemetryOutfile;
100 | 
101 |   const gcpProjectId =
102 |     process.env['OTLP_GOOGLE_CLOUD_PROJECT'] ||
103 |     process.env['GOOGLE_CLOUD_PROJECT'];
104 |   const useDirectGcpExport =
105 |     telemetryTarget === TelemetryTarget.GCP && !!gcpProjectId && !useCollector;
106 | 
107 |   let spanExporter:
108 |     | OTLPTraceExporter
109 |     | OTLPTraceExporterHttp
110 |     | GcpTraceExporter
111 |     | FileSpanExporter
112 |     | ConsoleSpanExporter;
113 |   let logExporter:
114 |     | OTLPLogExporter
115 |     | OTLPLogExporterHttp
116 |     | GcpLogExporter
117 |     | FileLogExporter
118 |     | ConsoleLogRecordExporter;
119 |   let metricReader: PeriodicExportingMetricReader;
120 | 
121 |   if (useDirectGcpExport) {
122 |     spanExporter = new GcpTraceExporter(gcpProjectId);
123 |     logExporter = new GcpLogExporter(gcpProjectId);
124 |     metricReader = new PeriodicExportingMetricReader({
125 |       exporter: new GcpMetricExporter(gcpProjectId),
126 |       exportIntervalMillis: 30000,
127 |     });
128 |   } else if (useOtlp) {
129 |     if (otlpProtocol === 'http') {
130 |       spanExporter = new OTLPTraceExporterHttp({
131 |         url: parsedEndpoint,
132 |       });
133 |       logExporter = new OTLPLogExporterHttp({
134 |         url: parsedEndpoint,
135 |       });
136 |       metricReader = new PeriodicExportingMetricReader({
137 |         exporter: new OTLPMetricExporterHttp({
138 |           url: parsedEndpoint,
139 |         }),
140 |         exportIntervalMillis: 10000,
141 |       });
142 |     } else {
143 |       // grpc
144 |       spanExporter = new OTLPTraceExporter({
145 |         url: parsedEndpoint,
146 |         compression: CompressionAlgorithm.GZIP,
147 |       });
148 |       logExporter = new OTLPLogExporter({
149 |         url: parsedEndpoint,
150 |         compression: CompressionAlgorithm.GZIP,
151 |       });
152 |       metricReader = new PeriodicExportingMetricReader({
153 |         exporter: new OTLPMetricExporter({
154 |           url: parsedEndpoint,
155 |           compression: CompressionAlgorithm.GZIP,
156 |         }),
157 |         exportIntervalMillis: 10000,
158 |       });
159 |     }
160 |   } else if (telemetryOutfile) {
161 |     spanExporter = new FileSpanExporter(telemetryOutfile);
162 |     logExporter = new FileLogExporter(telemetryOutfile);
163 |     metricReader = new PeriodicExportingMetricReader({
164 |       exporter: new FileMetricExporter(telemetryOutfile),
165 |       exportIntervalMillis: 10000,
166 |     });
167 |   } else {
168 |     spanExporter = new ConsoleSpanExporter();
169 |     logExporter = new ConsoleLogRecordExporter();
170 |     metricReader = new PeriodicExportingMetricReader({
171 |       exporter: new ConsoleMetricExporter(),
172 |       exportIntervalMillis: 10000,
173 |     });
174 |   }
175 | 
176 |   sdk = new NodeSDK({
177 |     resource,
178 |     spanProcessors: [new BatchSpanProcessor(spanExporter)],
179 |     logRecordProcessors: [new BatchLogRecordProcessor(logExporter)],
180 |     metricReader,
181 |     instrumentations: [new HttpInstrumentation()],
182 |   });
183 | 
184 |   try {
185 |     sdk.start();
186 |     if (config.getDebugMode()) {
187 |       console.log('OpenTelemetry SDK started successfully.');
188 |     }
189 |     telemetryInitialized = true;
190 |     initializeMetrics(config);
191 |   } catch (error) {
192 |     console.error('Error starting OpenTelemetry SDK:', error);
193 |   }
194 | 
195 |   process.on('SIGTERM', () => {
196 |     shutdownTelemetry(config);
197 |   });
198 |   process.on('SIGINT', () => {
199 |     shutdownTelemetry(config);
200 |   });
201 |   process.on('exit', () => {
202 |     shutdownTelemetry(config);
203 |   });
204 | }
205 | 
206 | export async function shutdownTelemetry(config: Config): Promise<void> {
207 |   if (!telemetryInitialized || !sdk) {
208 |     return;
209 |   }
210 |   try {
211 |     ClearcutLogger.getInstance()?.shutdown();
212 |     await sdk.shutdown();
213 |     if (config.getDebugMode()) {
214 |       console.log('OpenTelemetry SDK shut down successfully.');
215 |     }
216 |   } catch (error) {
217 |     console.error('Error shutting down SDK:', error);
218 |   } finally {
219 |     telemetryInitialized = false;
220 |   }
221 | }
```

src/telemetry/telemetry-utils.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { getProgrammingLanguage } from './telemetry-utils.js';
9 | 
10 | describe('getProgrammingLanguage', () => {
11 |   it('should return the programming language when file_path is present', () => {
12 |     const args = { file_path: 'src/test.ts' };
13 |     const language = getProgrammingLanguage(args);
14 |     expect(language).toBe('TypeScript');
15 |   });
16 | 
17 |   it('should return the programming language when absolute_path is present', () => {
18 |     const args = { absolute_path: 'src/test.py' };
19 |     const language = getProgrammingLanguage(args);
20 |     expect(language).toBe('Python');
21 |   });
22 | 
23 |   it('should return the programming language when path is present', () => {
24 |     const args = { path: 'src/test.go' };
25 |     const language = getProgrammingLanguage(args);
26 |     expect(language).toBe('Go');
27 |   });
28 | 
29 |   it('should return undefined when no file path is present', () => {
30 |     const args = {};
31 |     const language = getProgrammingLanguage(args);
32 |     expect(language).toBeUndefined();
33 |   });
34 | 
35 |   it('should handle unknown file extensions gracefully', () => {
36 |     const args = { file_path: 'src/test.unknown' };
37 |     const language = getProgrammingLanguage(args);
38 |     expect(language).toBeUndefined();
39 |   });
40 | 
41 |   it('should handle files with no extension', () => {
42 |     const args = { file_path: 'src/test' };
43 |     const language = getProgrammingLanguage(args);
44 |     expect(language).toBeUndefined();
45 |   });
46 | });
```

src/telemetry/telemetry-utils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { getLanguageFromFilePath } from '../utils/language-detection.js';
8 | 
9 | export function getProgrammingLanguage(
10 |   args: Record<string, unknown>,
11 | ): string | undefined {
12 |   const filePath = args['file_path'] || args['path'] || args['absolute_path'];
13 |   if (typeof filePath === 'string') {
14 |     return getLanguageFromFilePath(filePath);
15 |   }
16 |   return undefined;
17 | }
```

src/telemetry/telemetry.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import {
9 |   initializeTelemetry,
10 |   shutdownTelemetry,
11 |   isTelemetrySdkInitialized,
12 | } from './sdk.js';
13 | import { Config } from '../config/config.js';
14 | import { NodeSDK } from '@opentelemetry/sdk-node';
15 | 
16 | vi.mock('@opentelemetry/sdk-node');
17 | vi.mock('../config/config.js');
18 | 
19 | describe('telemetry', () => {
20 |   let mockConfig: Config;
21 |   let mockNodeSdk: NodeSDK;
22 | 
23 |   beforeEach(() => {
24 |     vi.resetAllMocks();
25 | 
26 |     mockConfig = new Config({
27 |       sessionId: 'test-session-id',
28 |       model: 'test-model',
29 |       targetDir: '/test/dir',
30 |       debugMode: false,
31 |       cwd: '/test/dir',
32 |     });
33 |     vi.spyOn(mockConfig, 'getTelemetryEnabled').mockReturnValue(true);
34 |     vi.spyOn(mockConfig, 'getTelemetryOtlpEndpoint').mockReturnValue(
35 |       'http://localhost:4317',
36 |     );
37 |     vi.spyOn(mockConfig, 'getSessionId').mockReturnValue('test-session-id');
38 |     mockNodeSdk = {
39 |       start: vi.fn(),
40 |       shutdown: vi.fn().mockResolvedValue(undefined),
41 |     } as unknown as NodeSDK;
42 |     vi.mocked(NodeSDK).mockImplementation(() => mockNodeSdk);
43 |   });
44 | 
45 |   afterEach(async () => {
46 |     // Ensure we shut down telemetry even if a test fails.
47 |     if (isTelemetrySdkInitialized()) {
48 |       await shutdownTelemetry(mockConfig);
49 |     }
50 |   });
51 | 
52 |   it('should initialize the telemetry service', () => {
53 |     initializeTelemetry(mockConfig);
54 |     expect(NodeSDK).toHaveBeenCalled();
55 |     expect(mockNodeSdk.start).toHaveBeenCalled();
56 |   });
57 | 
58 |   it('should shutdown the telemetry service', async () => {
59 |     initializeTelemetry(mockConfig);
60 |     await shutdownTelemetry(mockConfig);
61 | 
62 |     expect(mockNodeSdk.shutdown).toHaveBeenCalled();
63 |   });
64 | });
```

src/telemetry/telemetryAttributes.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Attributes } from '@opentelemetry/api';
8 | import type { Config } from '../config/config.js';
9 | import { InstallationManager } from '../utils/installationManager.js';
10 | import { UserAccountManager } from '../utils/userAccountManager.js';
11 | 
12 | const userAccountManager = new UserAccountManager();
13 | const installationManager = new InstallationManager();
14 | 
15 | export function getCommonAttributes(config: Config): Attributes {
16 |   const email = userAccountManager.getCachedGoogleAccount();
17 |   return {
18 |     'session.id': config.getSessionId(),
19 |     'installation.id': installationManager.getInstallationId(),
20 |     ...(email && { 'user.email': email }),
21 |   };
22 | }
```

src/telemetry/tool-call-decision.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { ToolConfirmationOutcome } from '../tools/tools.js';
8 | 
9 | export enum ToolCallDecision {
10 |   ACCEPT = 'accept',
11 |   REJECT = 'reject',
12 |   MODIFY = 'modify',
13 |   AUTO_ACCEPT = 'auto_accept',
14 | }
15 | 
16 | export function getDecisionFromOutcome(
17 |   outcome: ToolConfirmationOutcome,
18 | ): ToolCallDecision {
19 |   switch (outcome) {
20 |     case ToolConfirmationOutcome.ProceedOnce:
21 |       return ToolCallDecision.ACCEPT;
22 |     case ToolConfirmationOutcome.ProceedAlways:
23 |     case ToolConfirmationOutcome.ProceedAlwaysServer:
24 |     case ToolConfirmationOutcome.ProceedAlwaysTool:
25 |       return ToolCallDecision.AUTO_ACCEPT;
26 |     case ToolConfirmationOutcome.ModifyWithEditor:
27 |       return ToolCallDecision.MODIFY;
28 |     case ToolConfirmationOutcome.Cancel:
29 |     default:
30 |       return ToolCallDecision.REJECT;
31 |   }
32 | }
```

src/telemetry/types.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { GenerateContentResponseUsageMetadata } from '@google/genai';
8 | import type { Config } from '../config/config.js';
9 | import type { ApprovalMode } from '../config/config.js';
10 | import type { CompletedToolCall } from '../core/coreToolScheduler.js';
11 | import { DiscoveredMCPTool } from '../tools/mcp-tool.js';
12 | import type { FileDiff } from '../tools/tools.js';
13 | import { AuthType } from '../core/contentGenerator.js';
14 | import type { LogAttributes } from '@opentelemetry/api-logs';
15 | import {
16 |   getDecisionFromOutcome,
17 |   ToolCallDecision,
18 | } from './tool-call-decision.js';
19 | import type { FileOperation } from './metrics.js';
20 | export { ToolCallDecision };
21 | import type { ToolRegistry } from '../tools/tool-registry.js';
22 | import type { OutputFormat } from '../output/types.js';
23 | import type { AgentTerminateMode } from '../agents/types.js';
24 | 
25 | import { getCommonAttributes } from './telemetryAttributes.js';
26 | import { SemanticAttributes } from '@opentelemetry/semantic-conventions';
27 | import { safeJsonStringify } from '../utils/safeJsonStringify.js';
28 | 
29 | export interface BaseTelemetryEvent {
30 |   'event.name': string;
31 |   /** Current timestamp in ISO 8601 format */
32 |   'event.timestamp': string;
33 | }
34 | 
35 | type CommonFields = keyof BaseTelemetryEvent;
36 | 
37 | export const EVENT_CLI_CONFIG = 'gemini_cli.config';
38 | export class StartSessionEvent implements BaseTelemetryEvent {
39 |   'event.name': 'cli_config';
40 |   'event.timestamp': string;
41 |   model: string;
42 |   embedding_model: string;
43 |   sandbox_enabled: boolean;
44 |   core_tools_enabled: string;
45 |   approval_mode: string;
46 |   api_key_enabled: boolean;
47 |   vertex_ai_enabled: boolean;
48 |   debug_enabled: boolean;
49 |   mcp_servers: string;
50 |   telemetry_enabled: boolean;
51 |   telemetry_log_user_prompts_enabled: boolean;
52 |   file_filtering_respect_git_ignore: boolean;
53 |   mcp_servers_count: number;
54 |   mcp_tools_count?: number;
55 |   mcp_tools?: string;
56 |   output_format: OutputFormat;
57 | 
58 |   constructor(config: Config, toolRegistry?: ToolRegistry) {
59 |     const generatorConfig = config.getContentGeneratorConfig();
60 |     const mcpServers = config.getMcpServers();
61 | 
62 |     let useGemini = false;
63 |     let useVertex = false;
64 |     if (generatorConfig && generatorConfig.authType) {
65 |       useGemini = generatorConfig.authType === AuthType.USE_GEMINI;
66 |       useVertex = generatorConfig.authType === AuthType.USE_VERTEX_AI;
67 |     }
68 | 
69 |     this['event.name'] = 'cli_config';
70 |     this['event.timestamp'] = new Date().toISOString();
71 |     this.model = config.getModel();
72 |     this.embedding_model = config.getEmbeddingModel();
73 |     this.sandbox_enabled =
74 |       typeof config.getSandbox() === 'string' || !!config.getSandbox();
75 |     this.core_tools_enabled = (config.getCoreTools() ?? []).join(',');
76 |     this.approval_mode = config.getApprovalMode();
77 |     this.api_key_enabled = useGemini || useVertex;
78 |     this.vertex_ai_enabled = useVertex;
79 |     this.debug_enabled = config.getDebugMode();
80 |     this.mcp_servers = mcpServers ? Object.keys(mcpServers).join(',') : '';
81 |     this.telemetry_enabled = config.getTelemetryEnabled();
82 |     this.telemetry_log_user_prompts_enabled =
83 |       config.getTelemetryLogPromptsEnabled();
84 |     this.file_filtering_respect_git_ignore =
85 |       config.getFileFilteringRespectGitIgnore();
86 |     this.mcp_servers_count = mcpServers ? Object.keys(mcpServers).length : 0;
87 |     this.output_format = config.getOutputFormat();
88 |     if (toolRegistry) {
89 |       const mcpTools = toolRegistry
90 |         .getAllTools()
91 |         .filter((tool) => tool instanceof DiscoveredMCPTool);
92 |       this.mcp_tools_count = mcpTools.length;
93 |       this.mcp_tools = mcpTools
94 |         .map((tool) => (tool as DiscoveredMCPTool).name)
95 |         .join(',');
96 |     }
97 |   }
98 | 
99 |   toOpenTelemetryAttributes(config: Config): LogAttributes {
100 |     return {
101 |       ...getCommonAttributes(config),
102 |       'event.name': EVENT_CLI_CONFIG,
103 |       'event.timestamp': this['event.timestamp'],
104 |       model: this.model,
105 |       embedding_model: this.embedding_model,
106 |       sandbox_enabled: this.sandbox_enabled,
107 |       core_tools_enabled: this.core_tools_enabled,
108 |       approval_mode: this.approval_mode,
109 |       api_key_enabled: this.api_key_enabled,
110 |       vertex_ai_enabled: this.vertex_ai_enabled,
111 |       log_user_prompts_enabled: this.telemetry_log_user_prompts_enabled,
112 |       file_filtering_respect_git_ignore: this.file_filtering_respect_git_ignore,
113 |       debug_mode: this.debug_enabled,
114 |       mcp_servers: this.mcp_servers,
115 |       mcp_servers_count: this.mcp_servers_count,
116 |       mcp_tools: this.mcp_tools,
117 |       mcp_tools_count: this.mcp_tools_count,
118 |       output_format: this.output_format,
119 |     };
120 |   }
121 | 
122 |   toLogBody(): string {
123 |     return 'CLI configuration loaded.';
124 |   }
125 | }
126 | 
127 | export class EndSessionEvent implements BaseTelemetryEvent {
128 |   'event.name': 'end_session';
129 |   'event.timestamp': string;
130 |   session_id?: string;
131 | 
132 |   constructor(config?: Config) {
133 |     this['event.name'] = 'end_session';
134 |     this['event.timestamp'] = new Date().toISOString();
135 |     this.session_id = config?.getSessionId();
136 |   }
137 | }
138 | 
139 | export const EVENT_USER_PROMPT = 'gemini_cli.user_prompt';
140 | export class UserPromptEvent implements BaseTelemetryEvent {
141 |   'event.name': 'user_prompt';
142 |   'event.timestamp': string;
143 |   prompt_length: number;
144 |   prompt_id: string;
145 |   auth_type?: string;
146 |   prompt?: string;
147 | 
148 |   constructor(
149 |     prompt_length: number,
150 |     prompt_Id: string,
151 |     auth_type?: string,
152 |     prompt?: string,
153 |   ) {
154 |     this['event.name'] = 'user_prompt';
155 |     this['event.timestamp'] = new Date().toISOString();
156 |     this.prompt_length = prompt_length;
157 |     this.prompt_id = prompt_Id;
158 |     this.auth_type = auth_type;
159 |     this.prompt = prompt;
160 |   }
161 | 
162 |   toOpenTelemetryAttributes(config: Config): LogAttributes {
163 |     const attributes: LogAttributes = {
164 |       ...getCommonAttributes(config),
165 |       'event.name': EVENT_USER_PROMPT,
166 |       'event.timestamp': this['event.timestamp'],
167 |       prompt_length: this.prompt_length,
168 |       prompt_id: this.prompt_id,
169 |     };
170 | 
171 |     if (this.auth_type) {
172 |       attributes['auth_type'] = this.auth_type;
173 |     }
174 | 
175 |     if (config.getTelemetryLogPromptsEnabled()) {
176 |       attributes['prompt'] = this.prompt;
177 |     }
178 |     return attributes;
179 |   }
180 | 
181 |   toLogBody(): string {
182 |     return `User prompt. Length: ${this.prompt_length}.`;
183 |   }
184 | }
185 | 
186 | export const EVENT_TOOL_CALL = 'gemini_cli.tool_call';
187 | export class ToolCallEvent implements BaseTelemetryEvent {
188 |   'event.name': 'tool_call';
189 |   'event.timestamp': string;
190 |   function_name: string;
191 |   function_args: Record<string, unknown>;
192 |   duration_ms: number;
193 |   success: boolean;
194 |   decision?: ToolCallDecision;
195 |   error?: string;
196 |   error_type?: string;
197 |   prompt_id: string;
198 |   tool_type: 'native' | 'mcp';
199 |   content_length?: number;
200 |   mcp_server_name?: string;
201 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
202 |   metadata?: { [key: string]: any };
203 | 
204 |   constructor(call: CompletedToolCall);
205 |   constructor(
206 |     call: undefined,
207 |     function_name: string,
208 |     function_args: Record<string, unknown>,
209 |     duration_ms: number,
210 |     success: boolean,
211 |     prompt_id: string,
212 |     tool_type: 'native' | 'mcp',
213 |     error?: string,
214 |   );
215 |   constructor(
216 |     call?: CompletedToolCall,
217 |     function_name?: string,
218 |     function_args?: Record<string, unknown>,
219 |     duration_ms?: number,
220 |     success?: boolean,
221 |     prompt_id?: string,
222 |     tool_type?: 'native' | 'mcp',
223 |     error?: string,
224 |   ) {
225 |     this['event.name'] = 'tool_call';
226 |     this['event.timestamp'] = new Date().toISOString();
227 | 
228 |     if (call) {
229 |       this.function_name = call.request.name;
230 |       this.function_args = call.request.args;
231 |       this.duration_ms = call.durationMs ?? 0;
232 |       this.success = call.status === 'success';
233 |       this.decision = call.outcome
234 |         ? getDecisionFromOutcome(call.outcome)
235 |         : undefined;
236 |       this.error = call.response.error?.message;
237 |       this.error_type = call.response.errorType;
238 |       this.prompt_id = call.request.prompt_id;
239 |       this.content_length = call.response.contentLength;
240 |       if (
241 |         typeof call.tool !== 'undefined' &&
242 |         call.tool instanceof DiscoveredMCPTool
243 |       ) {
244 |         this.tool_type = 'mcp';
245 |         this.mcp_server_name = call.tool.serverName;
246 |       } else {
247 |         this.tool_type = 'native';
248 |       }
249 | 
250 |       if (
251 |         call.status === 'success' &&
252 |         typeof call.response.resultDisplay === 'object' &&
253 |         call.response.resultDisplay !== null &&
254 |         'diffStat' in call.response.resultDisplay
255 |       ) {
256 |         const diffStat = (call.response.resultDisplay as FileDiff).diffStat;
257 |         if (diffStat) {
258 |           this.metadata = {
259 |             model_added_lines: diffStat.model_added_lines,
260 |             model_removed_lines: diffStat.model_removed_lines,
261 |             model_added_chars: diffStat.model_added_chars,
262 |             model_removed_chars: diffStat.model_removed_chars,
263 |             user_added_lines: diffStat.user_added_lines,
264 |             user_removed_lines: diffStat.user_removed_lines,
265 |             user_added_chars: diffStat.user_added_chars,
266 |             user_removed_chars: diffStat.user_removed_chars,
267 |           };
268 |         }
269 |       }
270 |     } else {
271 |       this.function_name = function_name!;
272 |       this.function_args = function_args!;
273 |       this.duration_ms = duration_ms!;
274 |       this.success = success!;
275 |       this.prompt_id = prompt_id!;
276 |       this.tool_type = tool_type!;
277 |       this.error = error;
278 |     }
279 |   }
280 | 
281 |   toOpenTelemetryAttributes(config: Config): LogAttributes {
282 |     const attributes: LogAttributes = {
283 |       ...getCommonAttributes(config),
284 |       'event.name': EVENT_TOOL_CALL,
285 |       'event.timestamp': this['event.timestamp'],
286 |       function_name: this.function_name,
287 |       function_args: safeJsonStringify(this.function_args, 2),
288 |       duration_ms: this.duration_ms,
289 |       success: this.success,
290 |       decision: this.decision,
291 |       prompt_id: this.prompt_id,
292 |       tool_type: this.tool_type,
293 |       content_length: this.content_length,
294 |       mcp_server_name: this.mcp_server_name,
295 |       metadata: this.metadata,
296 |     };
297 | 
298 |     if (this.error) {
299 |       attributes['error'] = this.error;
300 |       attributes['error.message'] = this.error;
301 |       if (this.error_type) {
302 |         attributes['error_type'] = this.error_type;
303 |         attributes['error.type'] = this.error_type;
304 |       }
305 |     }
306 |     return attributes;
307 |   }
308 | 
309 |   toLogBody(): string {
310 |     return `Tool call: ${this.function_name}${this.decision ? `. Decision: ${this.decision}` : ''}. Success: ${this.success}. Duration: ${this.duration_ms}ms.`;
311 |   }
312 | }
313 | 
314 | export const EVENT_API_REQUEST = 'gemini_cli.api_request';
315 | export class ApiRequestEvent implements BaseTelemetryEvent {
316 |   'event.name': 'api_request';
317 |   'event.timestamp': string;
318 |   model: string;
319 |   prompt_id: string;
320 |   request_text?: string;
321 | 
322 |   constructor(model: string, prompt_id: string, request_text?: string) {
323 |     this['event.name'] = 'api_request';
324 |     this['event.timestamp'] = new Date().toISOString();
325 |     this.model = model;
326 |     this.prompt_id = prompt_id;
327 |     this.request_text = request_text;
328 |   }
329 | 
330 |   toOpenTelemetryAttributes(config: Config): LogAttributes {
331 |     return {
332 |       ...getCommonAttributes(config),
333 |       'event.name': EVENT_API_REQUEST,
334 |       'event.timestamp': this['event.timestamp'],
335 |       model: this.model,
336 |       prompt_id: this.prompt_id,
337 |       request_text: this.request_text,
338 |     };
339 |   }
340 | 
341 |   toLogBody(): string {
342 |     return `API request to ${this.model}.`;
343 |   }
344 | }
345 | 
346 | export const EVENT_API_ERROR = 'gemini_cli.api_error';
347 | export class ApiErrorEvent implements BaseTelemetryEvent {
348 |   'event.name': 'api_error';
349 |   'event.timestamp': string;
350 |   model: string;
351 |   error: string;
352 |   error_type?: string;
353 |   status_code?: number | string;
354 |   duration_ms: number;
355 |   prompt_id: string;
356 |   auth_type?: string;
357 | 
358 |   constructor(
359 |     model: string,
360 |     error: string,
361 |     duration_ms: number,
362 |     prompt_id: string,
363 |     auth_type?: string,
364 |     error_type?: string,
365 |     status_code?: number | string,
366 |   ) {
367 |     this['event.name'] = 'api_error';
368 |     this['event.timestamp'] = new Date().toISOString();
369 |     this.model = model;
370 |     this.error = error;
371 |     this.error_type = error_type;
372 |     this.status_code = status_code;
373 |     this.duration_ms = duration_ms;
374 |     this.prompt_id = prompt_id;
375 |     this.auth_type = auth_type;
376 |   }
377 | 
378 |   toOpenTelemetryAttributes(config: Config): LogAttributes {
379 |     const attributes: LogAttributes = {
380 |       ...getCommonAttributes(config),
381 |       'event.name': EVENT_API_ERROR,
382 |       'event.timestamp': this['event.timestamp'],
383 |       ['error.message']: this.error,
384 |       model_name: this.model,
385 |       duration: this.duration_ms,
386 |       model: this.model,
387 |       error: this.error,
388 |       status_code: this.status_code,
389 |       duration_ms: this.duration_ms,
390 |       prompt_id: this.prompt_id,
391 |       auth_type: this.auth_type,
392 |     };
393 | 
394 |     if (this.error_type) {
395 |       attributes['error.type'] = this.error_type;
396 |     }
397 |     if (typeof this.status_code === 'number') {
398 |       attributes[SemanticAttributes.HTTP_STATUS_CODE] = this.status_code;
399 |     }
400 |     return attributes;
401 |   }
402 | 
403 |   toLogBody(): string {
404 |     return `API error for ${this.model}. Error: ${this.error}. Duration: ${this.duration_ms}ms.`;
405 |   }
406 | }
407 | 
408 | export const EVENT_API_RESPONSE = 'gemini_cli.api_response';
409 | export class ApiResponseEvent implements BaseTelemetryEvent {
410 |   'event.name': 'api_response';
411 |   'event.timestamp': string;
412 |   model: string;
413 |   status_code?: number | string;
414 |   duration_ms: number;
415 |   input_token_count: number;
416 |   output_token_count: number;
417 |   cached_content_token_count: number;
418 |   thoughts_token_count: number;
419 |   tool_token_count: number;
420 |   total_token_count: number;
421 |   response_text?: string;
422 |   prompt_id: string;
423 |   auth_type?: string;
424 | 
425 |   constructor(
426 |     model: string,
427 |     duration_ms: number,
428 |     prompt_id: string,
429 |     auth_type?: string,
430 |     usage_data?: GenerateContentResponseUsageMetadata,
431 |     response_text?: string,
432 |   ) {
433 |     this['event.name'] = 'api_response';
434 |     this['event.timestamp'] = new Date().toISOString();
435 |     this.model = model;
436 |     this.duration_ms = duration_ms;
437 |     this.status_code = 200;
438 |     this.input_token_count = usage_data?.promptTokenCount ?? 0;
439 |     this.output_token_count = usage_data?.candidatesTokenCount ?? 0;
440 |     this.cached_content_token_count = usage_data?.cachedContentTokenCount ?? 0;
441 |     this.thoughts_token_count = usage_data?.thoughtsTokenCount ?? 0;
442 |     this.tool_token_count = usage_data?.toolUsePromptTokenCount ?? 0;
443 |     this.total_token_count = usage_data?.totalTokenCount ?? 0;
444 |     this.response_text = response_text;
445 |     this.prompt_id = prompt_id;
446 |     this.auth_type = auth_type;
447 |   }
448 | 
449 |   toOpenTelemetryAttributes(config: Config): LogAttributes {
450 |     const attributes: LogAttributes = {
451 |       ...getCommonAttributes(config),
452 |       'event.name': EVENT_API_RESPONSE,
453 |       'event.timestamp': this['event.timestamp'],
454 |       model: this.model,
455 |       duration_ms: this.duration_ms,
456 |       input_token_count: this.input_token_count,
457 |       output_token_count: this.output_token_count,
458 |       cached_content_token_count: this.cached_content_token_count,
459 |       thoughts_token_count: this.thoughts_token_count,
460 |       tool_token_count: this.tool_token_count,
461 |       total_token_count: this.total_token_count,
462 |       prompt_id: this.prompt_id,
463 |       auth_type: this.auth_type,
464 |       status_code: this.status_code,
465 |     };
466 |     if (this.response_text) {
467 |       attributes['response_text'] = this.response_text;
468 |     }
469 |     if (this.status_code) {
470 |       if (typeof this.status_code === 'number') {
471 |         attributes[SemanticAttributes.HTTP_STATUS_CODE] = this.status_code;
472 |       }
473 |     }
474 |     return attributes;
475 |   }
476 | 
477 |   toLogBody(): string {
478 |     return `API response from ${this.model}. Status: ${this.status_code || 'N/A'}. Duration: ${this.duration_ms}ms.`;
479 |   }
480 | }
481 | 
482 | export const EVENT_FLASH_FALLBACK = 'gemini_cli.flash_fallback';
483 | export class FlashFallbackEvent implements BaseTelemetryEvent {
484 |   'event.name': 'flash_fallback';
485 |   'event.timestamp': string;
486 |   auth_type: string;
487 | 
488 |   constructor(auth_type: string) {
489 |     this['event.name'] = 'flash_fallback';
490 |     this['event.timestamp'] = new Date().toISOString();
491 |     this.auth_type = auth_type;
492 |   }
493 | 
494 |   toOpenTelemetryAttributes(config: Config): LogAttributes {
495 |     return {
496 |       ...getCommonAttributes(config),
497 |       'event.name': EVENT_FLASH_FALLBACK,
498 |       'event.timestamp': this['event.timestamp'],
499 |       auth_type: this.auth_type,
500 |     };
501 |   }
502 | 
503 |   toLogBody(): string {
504 |     return `Switching to flash as Fallback.`;
505 |   }
506 | }
507 | 
508 | export const EVENT_RIPGREP_FALLBACK = 'gemini_cli.ripgrep_fallback';
509 | export class RipgrepFallbackEvent implements BaseTelemetryEvent {
510 |   'event.name': 'ripgrep_fallback';
511 |   'event.timestamp': string;
512 | 
513 |   constructor(public error?: string) {
514 |     this['event.name'] = 'ripgrep_fallback';
515 |     this['event.timestamp'] = new Date().toISOString();
516 |   }
517 | 
518 |   toOpenTelemetryAttributes(config: Config): LogAttributes {
519 |     return {
520 |       ...getCommonAttributes(config),
521 |       'event.name': EVENT_RIPGREP_FALLBACK,
522 |       'event.timestamp': this['event.timestamp'],
523 |       error: this.error,
524 |     };
525 |   }
526 | 
527 |   toLogBody(): string {
528 |     return `Switching to grep as fallback.`;
529 |   }
530 | }
531 | 
532 | export enum LoopType {
533 |   CONSECUTIVE_IDENTICAL_TOOL_CALLS = 'consecutive_identical_tool_calls',
534 |   CHANTING_IDENTICAL_SENTENCES = 'chanting_identical_sentences',
535 |   LLM_DETECTED_LOOP = 'llm_detected_loop',
536 | }
537 | 
538 | export class LoopDetectedEvent implements BaseTelemetryEvent {
539 |   'event.name': 'loop_detected';
540 |   'event.timestamp': string;
541 |   loop_type: LoopType;
542 |   prompt_id: string;
543 | 
544 |   constructor(loop_type: LoopType, prompt_id: string) {
545 |     this['event.name'] = 'loop_detected';
546 |     this['event.timestamp'] = new Date().toISOString();
547 |     this.loop_type = loop_type;
548 |     this.prompt_id = prompt_id;
549 |   }
550 | 
551 |   toOpenTelemetryAttributes(config: Config): LogAttributes {
552 |     return {
553 |       ...getCommonAttributes(config),
554 |       'event.name': this['event.name'],
555 |       'event.timestamp': this['event.timestamp'],
556 |       loop_type: this.loop_type,
557 |       prompt_id: this.prompt_id,
[TRUNCATED]
```

src/telemetry/uiTelemetry.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach } from 'vitest';
8 | import { UiTelemetryService } from './uiTelemetry.js';
9 | import { ToolCallDecision } from './tool-call-decision.js';
10 | import type { ApiErrorEvent, ApiResponseEvent } from './types.js';
11 | import { ToolCallEvent } from './types.js';
12 | import {
13 |   EVENT_API_ERROR,
14 |   EVENT_API_RESPONSE,
15 |   EVENT_TOOL_CALL,
16 | } from './types.js';
17 | import type {
18 |   CompletedToolCall,
19 |   ErroredToolCall,
20 |   SuccessfulToolCall,
21 | } from '../core/coreToolScheduler.js';
22 | import { ToolErrorType } from '../tools/tool-error.js';
23 | import { ToolConfirmationOutcome } from '../tools/tools.js';
24 | import { MockTool } from '../test-utils/mock-tool.js';
25 | 
26 | const createFakeCompletedToolCall = (
27 |   name: string,
28 |   success: boolean,
29 |   duration = 100,
30 |   outcome?: ToolConfirmationOutcome,
31 |   error?: Error,
32 | ): CompletedToolCall => {
33 |   const request = {
34 |     callId: `call_${name}_${Date.now()}`,
35 |     name,
36 |     args: { foo: 'bar' },
37 |     isClientInitiated: false,
38 |     prompt_id: 'prompt-id-1',
39 |   };
40 |   const tool = new MockTool({ name });
41 | 
42 |   if (success) {
43 |     return {
44 |       status: 'success',
45 |       request,
46 |       tool,
47 |       invocation: tool.build({ param: 'test' }),
48 |       response: {
49 |         callId: request.callId,
50 |         responseParts: [
51 |           {
52 |             functionResponse: {
53 |               id: request.callId,
54 |               name,
55 |               response: { output: 'Success!' },
56 |             },
57 |           },
58 |         ],
59 |         error: undefined,
60 |         errorType: undefined,
61 |         resultDisplay: 'Success!',
62 |       },
63 |       durationMs: duration,
64 |       outcome,
65 |     } as SuccessfulToolCall;
66 |   } else {
67 |     return {
68 |       status: 'error',
69 |       request,
70 |       tool,
71 |       response: {
72 |         callId: request.callId,
73 |         responseParts: [
74 |           {
75 |             functionResponse: {
76 |               id: request.callId,
77 |               name,
78 |               response: { error: 'Tool failed' },
79 |             },
80 |           },
81 |         ],
82 |         error: error || new Error('Tool failed'),
83 |         errorType: ToolErrorType.UNKNOWN,
84 |         resultDisplay: 'Failure!',
85 |       },
86 |       durationMs: duration,
87 |       outcome,
88 |     } as ErroredToolCall;
89 |   }
90 | };
91 | 
92 | describe('UiTelemetryService', () => {
93 |   let service: UiTelemetryService;
94 | 
95 |   beforeEach(() => {
96 |     service = new UiTelemetryService();
97 |   });
98 | 
99 |   it('should have correct initial metrics', () => {
100 |     const metrics = service.getMetrics();
101 |     expect(metrics).toEqual({
102 |       models: {},
103 |       tools: {
104 |         totalCalls: 0,
105 |         totalSuccess: 0,
106 |         totalFail: 0,
107 |         totalDurationMs: 0,
108 |         totalDecisions: {
109 |           [ToolCallDecision.ACCEPT]: 0,
110 |           [ToolCallDecision.REJECT]: 0,
111 |           [ToolCallDecision.MODIFY]: 0,
112 |           [ToolCallDecision.AUTO_ACCEPT]: 0,
113 |         },
114 |         byName: {},
115 |       },
116 |       files: {
117 |         totalLinesAdded: 0,
118 |         totalLinesRemoved: 0,
119 |       },
120 |     });
121 |     expect(service.getLastPromptTokenCount()).toBe(0);
122 |   });
123 | 
124 |   it('should emit an update event when an event is added', () => {
125 |     const spy = vi.fn();
126 |     service.on('update', spy);
127 | 
128 |     const event = {
129 |       'event.name': EVENT_API_RESPONSE,
130 |       model: 'gemini-2.5-pro',
131 |       duration_ms: 500,
132 |       input_token_count: 10,
133 |       output_token_count: 20,
134 |       total_token_count: 30,
135 |       cached_content_token_count: 5,
136 |       thoughts_token_count: 2,
137 |       tool_token_count: 3,
138 |     } as ApiResponseEvent & { 'event.name': typeof EVENT_API_RESPONSE };
139 | 
140 |     service.addEvent(event);
141 | 
142 |     expect(spy).toHaveBeenCalledOnce();
143 |     const { metrics, lastPromptTokenCount } = spy.mock.calls[0][0];
144 |     expect(metrics).toBeDefined();
145 |     expect(lastPromptTokenCount).toBe(0);
146 |   });
147 | 
148 |   describe('API Response Event Processing', () => {
149 |     it('should process a single ApiResponseEvent', () => {
150 |       const event = {
151 |         'event.name': EVENT_API_RESPONSE,
152 |         model: 'gemini-2.5-pro',
153 |         duration_ms: 500,
154 |         input_token_count: 10,
155 |         output_token_count: 20,
156 |         total_token_count: 30,
157 |         cached_content_token_count: 5,
158 |         thoughts_token_count: 2,
159 |         tool_token_count: 3,
160 |       } as ApiResponseEvent & { 'event.name': typeof EVENT_API_RESPONSE };
161 | 
162 |       service.addEvent(event);
163 | 
164 |       const metrics = service.getMetrics();
165 |       expect(metrics.models['gemini-2.5-pro']).toEqual({
166 |         api: {
167 |           totalRequests: 1,
168 |           totalErrors: 0,
169 |           totalLatencyMs: 500,
170 |         },
171 |         tokens: {
172 |           prompt: 10,
173 |           candidates: 20,
174 |           total: 30,
175 |           cached: 5,
176 |           thoughts: 2,
177 |           tool: 3,
178 |         },
179 |       });
180 |       expect(service.getLastPromptTokenCount()).toBe(0);
181 |     });
182 | 
183 |     it('should aggregate multiple ApiResponseEvents for the same model', () => {
184 |       const event1 = {
185 |         'event.name': EVENT_API_RESPONSE,
186 |         model: 'gemini-2.5-pro',
187 |         duration_ms: 500,
188 |         input_token_count: 10,
189 |         output_token_count: 20,
190 |         total_token_count: 30,
191 |         cached_content_token_count: 5,
192 |         thoughts_token_count: 2,
193 |         tool_token_count: 3,
194 |       } as ApiResponseEvent & {
195 |         'event.name': typeof EVENT_API_RESPONSE;
196 |       };
197 |       const event2 = {
198 |         'event.name': EVENT_API_RESPONSE,
199 |         model: 'gemini-2.5-pro',
200 |         duration_ms: 600,
201 |         input_token_count: 15,
202 |         output_token_count: 25,
203 |         total_token_count: 40,
204 |         cached_content_token_count: 10,
205 |         thoughts_token_count: 4,
206 |         tool_token_count: 6,
207 |       } as ApiResponseEvent & {
208 |         'event.name': typeof EVENT_API_RESPONSE;
209 |       };
210 | 
211 |       service.addEvent(event1);
212 |       service.addEvent(event2);
213 | 
214 |       const metrics = service.getMetrics();
215 |       expect(metrics.models['gemini-2.5-pro']).toEqual({
216 |         api: {
217 |           totalRequests: 2,
218 |           totalErrors: 0,
219 |           totalLatencyMs: 1100,
220 |         },
221 |         tokens: {
222 |           prompt: 25,
223 |           candidates: 45,
224 |           total: 70,
225 |           cached: 15,
226 |           thoughts: 6,
227 |           tool: 9,
228 |         },
229 |       });
230 |       expect(service.getLastPromptTokenCount()).toBe(0);
231 |     });
232 | 
233 |     it('should handle ApiResponseEvents for different models', () => {
234 |       const event1 = {
235 |         'event.name': EVENT_API_RESPONSE,
236 |         model: 'gemini-2.5-pro',
237 |         duration_ms: 500,
238 |         input_token_count: 10,
239 |         output_token_count: 20,
240 |         total_token_count: 30,
241 |         cached_content_token_count: 5,
242 |         thoughts_token_count: 2,
243 |         tool_token_count: 3,
244 |       } as ApiResponseEvent & {
245 |         'event.name': typeof EVENT_API_RESPONSE;
246 |       };
247 |       const event2 = {
248 |         'event.name': EVENT_API_RESPONSE,
249 |         model: 'gemini-2.5-flash',
250 |         duration_ms: 1000,
251 |         input_token_count: 100,
252 |         output_token_count: 200,
253 |         total_token_count: 300,
254 |         cached_content_token_count: 50,
255 |         thoughts_token_count: 20,
256 |         tool_token_count: 30,
257 |       } as ApiResponseEvent & {
258 |         'event.name': typeof EVENT_API_RESPONSE;
259 |       };
260 | 
261 |       service.addEvent(event1);
262 |       service.addEvent(event2);
263 | 
264 |       const metrics = service.getMetrics();
265 |       expect(metrics.models['gemini-2.5-pro']).toBeDefined();
266 |       expect(metrics.models['gemini-2.5-flash']).toBeDefined();
267 |       expect(metrics.models['gemini-2.5-pro'].api.totalRequests).toBe(1);
268 |       expect(metrics.models['gemini-2.5-flash'].api.totalRequests).toBe(1);
269 |       expect(service.getLastPromptTokenCount()).toBe(0);
270 |     });
271 |   });
272 | 
273 |   describe('API Error Event Processing', () => {
274 |     it('should process a single ApiErrorEvent', () => {
275 |       const event = {
276 |         'event.name': EVENT_API_ERROR,
277 |         model: 'gemini-2.5-pro',
278 |         duration_ms: 300,
279 |         error: 'Something went wrong',
280 |       } as ApiErrorEvent & { 'event.name': typeof EVENT_API_ERROR };
281 | 
282 |       service.addEvent(event);
283 | 
284 |       const metrics = service.getMetrics();
285 |       expect(metrics.models['gemini-2.5-pro']).toEqual({
286 |         api: {
287 |           totalRequests: 1,
288 |           totalErrors: 1,
289 |           totalLatencyMs: 300,
290 |         },
291 |         tokens: {
292 |           prompt: 0,
293 |           candidates: 0,
294 |           total: 0,
295 |           cached: 0,
296 |           thoughts: 0,
297 |           tool: 0,
298 |         },
299 |       });
300 |     });
301 | 
302 |     it('should aggregate ApiErrorEvents and ApiResponseEvents', () => {
303 |       const responseEvent = {
304 |         'event.name': EVENT_API_RESPONSE,
305 |         model: 'gemini-2.5-pro',
306 |         duration_ms: 500,
307 |         input_token_count: 10,
308 |         output_token_count: 20,
309 |         total_token_count: 30,
310 |         cached_content_token_count: 5,
311 |         thoughts_token_count: 2,
312 |         tool_token_count: 3,
313 |       } as ApiResponseEvent & {
314 |         'event.name': typeof EVENT_API_RESPONSE;
315 |       };
316 |       const errorEvent = {
317 |         'event.name': EVENT_API_ERROR,
318 |         model: 'gemini-2.5-pro',
319 |         duration_ms: 300,
320 |         error: 'Something went wrong',
321 |       } as ApiErrorEvent & { 'event.name': typeof EVENT_API_ERROR };
322 | 
323 |       service.addEvent(responseEvent);
324 |       service.addEvent(errorEvent);
325 | 
326 |       const metrics = service.getMetrics();
327 |       expect(metrics.models['gemini-2.5-pro']).toEqual({
328 |         api: {
329 |           totalRequests: 2,
330 |           totalErrors: 1,
331 |           totalLatencyMs: 800,
332 |         },
333 |         tokens: {
334 |           prompt: 10,
335 |           candidates: 20,
336 |           total: 30,
337 |           cached: 5,
338 |           thoughts: 2,
339 |           tool: 3,
340 |         },
341 |       });
342 |     });
343 |   });
344 | 
345 |   describe('Tool Call Event Processing', () => {
346 |     it('should process a single successful ToolCallEvent', () => {
347 |       const toolCall = createFakeCompletedToolCall(
348 |         'test_tool',
349 |         true,
350 |         150,
351 |         ToolConfirmationOutcome.ProceedOnce,
352 |       );
353 |       service.addEvent({
354 |         ...structuredClone(new ToolCallEvent(toolCall)),
355 |         'event.name': EVENT_TOOL_CALL,
356 |       } as ToolCallEvent & { 'event.name': typeof EVENT_TOOL_CALL });
357 | 
358 |       const metrics = service.getMetrics();
359 |       const { tools } = metrics;
360 | 
361 |       expect(tools.totalCalls).toBe(1);
362 |       expect(tools.totalSuccess).toBe(1);
363 |       expect(tools.totalFail).toBe(0);
364 |       expect(tools.totalDurationMs).toBe(150);
365 |       expect(tools.totalDecisions[ToolCallDecision.ACCEPT]).toBe(1);
366 |       expect(tools.byName['test_tool']).toEqual({
367 |         count: 1,
368 |         success: 1,
369 |         fail: 0,
370 |         durationMs: 150,
371 |         decisions: {
372 |           [ToolCallDecision.ACCEPT]: 1,
373 |           [ToolCallDecision.REJECT]: 0,
374 |           [ToolCallDecision.MODIFY]: 0,
375 |           [ToolCallDecision.AUTO_ACCEPT]: 0,
376 |         },
377 |       });
378 |     });
379 | 
380 |     it('should process a single failed ToolCallEvent', () => {
381 |       const toolCall = createFakeCompletedToolCall(
382 |         'test_tool',
383 |         false,
384 |         200,
385 |         ToolConfirmationOutcome.Cancel,
386 |       );
387 |       service.addEvent({
388 |         ...structuredClone(new ToolCallEvent(toolCall)),
389 |         'event.name': EVENT_TOOL_CALL,
390 |       } as ToolCallEvent & { 'event.name': typeof EVENT_TOOL_CALL });
391 | 
392 |       const metrics = service.getMetrics();
393 |       const { tools } = metrics;
394 | 
395 |       expect(tools.totalCalls).toBe(1);
396 |       expect(tools.totalSuccess).toBe(0);
397 |       expect(tools.totalFail).toBe(1);
398 |       expect(tools.totalDurationMs).toBe(200);
399 |       expect(tools.totalDecisions[ToolCallDecision.REJECT]).toBe(1);
400 |       expect(tools.byName['test_tool']).toEqual({
401 |         count: 1,
402 |         success: 0,
403 |         fail: 1,
404 |         durationMs: 200,
405 |         decisions: {
406 |           [ToolCallDecision.ACCEPT]: 0,
407 |           [ToolCallDecision.REJECT]: 1,
408 |           [ToolCallDecision.MODIFY]: 0,
409 |           [ToolCallDecision.AUTO_ACCEPT]: 0,
410 |         },
411 |       });
412 |     });
413 | 
414 |     it('should process a ToolCallEvent with modify decision', () => {
415 |       const toolCall = createFakeCompletedToolCall(
416 |         'test_tool',
417 |         true,
418 |         250,
419 |         ToolConfirmationOutcome.ModifyWithEditor,
420 |       );
421 |       service.addEvent({
422 |         ...structuredClone(new ToolCallEvent(toolCall)),
423 |         'event.name': EVENT_TOOL_CALL,
424 |       } as ToolCallEvent & { 'event.name': typeof EVENT_TOOL_CALL });
425 | 
426 |       const metrics = service.getMetrics();
427 |       const { tools } = metrics;
428 | 
429 |       expect(tools.totalDecisions[ToolCallDecision.MODIFY]).toBe(1);
430 |       expect(tools.byName['test_tool'].decisions[ToolCallDecision.MODIFY]).toBe(
431 |         1,
432 |       );
433 |     });
434 | 
435 |     it('should process a ToolCallEvent without a decision', () => {
436 |       const toolCall = createFakeCompletedToolCall('test_tool', true, 100);
437 |       service.addEvent({
438 |         ...structuredClone(new ToolCallEvent(toolCall)),
439 |         'event.name': EVENT_TOOL_CALL,
440 |       } as ToolCallEvent & { 'event.name': typeof EVENT_TOOL_CALL });
441 | 
442 |       const metrics = service.getMetrics();
443 |       const { tools } = metrics;
444 | 
445 |       expect(tools.totalDecisions).toEqual({
446 |         [ToolCallDecision.ACCEPT]: 0,
447 |         [ToolCallDecision.REJECT]: 0,
448 |         [ToolCallDecision.MODIFY]: 0,
449 |         [ToolCallDecision.AUTO_ACCEPT]: 0,
450 |       });
451 |       expect(tools.byName['test_tool'].decisions).toEqual({
452 |         [ToolCallDecision.ACCEPT]: 0,
453 |         [ToolCallDecision.REJECT]: 0,
454 |         [ToolCallDecision.MODIFY]: 0,
455 |         [ToolCallDecision.AUTO_ACCEPT]: 0,
456 |       });
457 |     });
458 | 
459 |     it('should aggregate multiple ToolCallEvents for the same tool', () => {
460 |       const toolCall1 = createFakeCompletedToolCall(
461 |         'test_tool',
462 |         true,
463 |         100,
464 |         ToolConfirmationOutcome.ProceedOnce,
465 |       );
466 |       const toolCall2 = createFakeCompletedToolCall(
467 |         'test_tool',
468 |         false,
469 |         150,
470 |         ToolConfirmationOutcome.Cancel,
471 |       );
472 | 
473 |       service.addEvent({
474 |         ...structuredClone(new ToolCallEvent(toolCall1)),
475 |         'event.name': EVENT_TOOL_CALL,
476 |       } as ToolCallEvent & { 'event.name': typeof EVENT_TOOL_CALL });
477 |       service.addEvent({
478 |         ...structuredClone(new ToolCallEvent(toolCall2)),
479 |         'event.name': EVENT_TOOL_CALL,
480 |       } as ToolCallEvent & { 'event.name': typeof EVENT_TOOL_CALL });
481 | 
482 |       const metrics = service.getMetrics();
483 |       const { tools } = metrics;
484 | 
485 |       expect(tools.totalCalls).toBe(2);
486 |       expect(tools.totalSuccess).toBe(1);
487 |       expect(tools.totalFail).toBe(1);
488 |       expect(tools.totalDurationMs).toBe(250);
489 |       expect(tools.totalDecisions[ToolCallDecision.ACCEPT]).toBe(1);
490 |       expect(tools.totalDecisions[ToolCallDecision.REJECT]).toBe(1);
491 |       expect(tools.byName['test_tool']).toEqual({
492 |         count: 2,
493 |         success: 1,
494 |         fail: 1,
495 |         durationMs: 250,
496 |         decisions: {
497 |           [ToolCallDecision.ACCEPT]: 1,
498 |           [ToolCallDecision.REJECT]: 1,
499 |           [ToolCallDecision.MODIFY]: 0,
500 |           [ToolCallDecision.AUTO_ACCEPT]: 0,
501 |         },
502 |       });
503 |     });
504 | 
505 |     it('should handle ToolCallEvents for different tools', () => {
506 |       const toolCall1 = createFakeCompletedToolCall('tool_A', true, 100);
507 |       const toolCall2 = createFakeCompletedToolCall('tool_B', false, 200);
508 |       service.addEvent({
509 |         ...structuredClone(new ToolCallEvent(toolCall1)),
510 |         'event.name': EVENT_TOOL_CALL,
511 |       } as ToolCallEvent & { 'event.name': typeof EVENT_TOOL_CALL });
512 |       service.addEvent({
513 |         ...structuredClone(new ToolCallEvent(toolCall2)),
514 |         'event.name': EVENT_TOOL_CALL,
515 |       } as ToolCallEvent & { 'event.name': typeof EVENT_TOOL_CALL });
516 | 
517 |       const metrics = service.getMetrics();
518 |       const { tools } = metrics;
519 | 
520 |       expect(tools.totalCalls).toBe(2);
521 |       expect(tools.totalSuccess).toBe(1);
522 |       expect(tools.totalFail).toBe(1);
523 |       expect(tools.byName['tool_A']).toBeDefined();
524 |       expect(tools.byName['tool_B']).toBeDefined();
525 |       expect(tools.byName['tool_A'].count).toBe(1);
526 |       expect(tools.byName['tool_B'].count).toBe(1);
527 |     });
528 |   });
529 | 
530 |   describe('resetLastPromptTokenCount', () => {
531 |     it('should reset the last prompt token count to 0', () => {
532 |       // First, set up some initial token count
533 |       const event = {
534 |         'event.name': EVENT_API_RESPONSE,
535 |         model: 'gemini-2.5-pro',
536 |         duration_ms: 500,
537 |         input_token_count: 100,
538 |         output_token_count: 200,
539 |         total_token_count: 300,
540 |         cached_content_token_count: 50,
541 |         thoughts_token_count: 20,
542 |         tool_token_count: 30,
543 |       } as ApiResponseEvent & { 'event.name': typeof EVENT_API_RESPONSE };
544 | 
545 |       service.addEvent(event);
546 |       expect(service.getLastPromptTokenCount()).toBe(0);
547 | 
548 |       // Now reset the token count
549 |       service.setLastPromptTokenCount(0);
550 |       expect(service.getLastPromptTokenCount()).toBe(0);
551 |     });
552 | 
553 |     it('should emit an update event when resetLastPromptTokenCount is called', () => {
554 |       const spy = vi.fn();
555 |       service.on('update', spy);
556 | 
557 |       // Set up initial token count
558 |       const event = {
559 |         'event.name': EVENT_API_RESPONSE,
560 |         model: 'gemini-2.5-pro',
561 |         duration_ms: 500,
562 |         input_token_count: 100,
563 |         output_token_count: 200,
564 |         total_token_count: 300,
565 |         cached_content_token_count: 50,
566 |         thoughts_token_count: 20,
567 |         tool_token_count: 30,
568 |       } as ApiResponseEvent & { 'event.name': typeof EVENT_API_RESPONSE };
569 | 
570 |       service.addEvent(event);
571 |       spy.mockClear(); // Clear the spy to focus on the reset call
572 | 
573 |       service.setLastPromptTokenCount(0);
574 | 
575 |       expect(spy).toHaveBeenCalledOnce();
576 |       const { metrics, lastPromptTokenCount } = spy.mock.calls[0][0];
577 |       expect(metrics).toBeDefined();
578 |       expect(lastPromptTokenCount).toBe(0);
579 |     });
580 | 
581 |     it('should not affect other metrics when resetLastPromptTokenCount is called', () => {
582 |       // Set up initial state with some metrics
583 |       const event = {
584 |         'event.name': EVENT_API_RESPONSE,
585 |         model: 'gemini-2.5-pro',
586 |         duration_ms: 500,
587 |         input_token_count: 100,
588 |         output_token_count: 200,
589 |         total_token_count: 300,
590 |         cached_content_token_count: 50,
591 |         thoughts_token_count: 20,
592 |         tool_token_count: 30,
593 |       } as ApiResponseEvent & { 'event.name': typeof EVENT_API_RESPONSE };
594 | 
595 |       service.addEvent(event);
596 | 
597 |       const metricsBefore = service.getMetrics();
598 | 
599 |       service.setLastPromptTokenCount(0);
600 | 
601 |       const metricsAfter = service.getMetrics();
602 | 
603 |       // Metrics should be unchanged
604 |       expect(metricsAfter).toEqual(metricsBefore);
605 | 
606 |       // Only the last prompt token count should be reset
607 |       expect(service.getLastPromptTokenCount()).toBe(0);
608 |     });
609 | 
610 |     it('should work correctly when called multiple times', () => {
611 |       const spy = vi.fn();
612 |       service.on('update', spy);
613 | 
614 |       // Set up initial token count
615 |       const event = {
616 |         'event.name': EVENT_API_RESPONSE,
617 |         model: 'gemini-2.5-pro',
618 |         duration_ms: 500,
619 |         input_token_count: 100,
620 |         output_token_count: 200,
621 |         total_token_count: 300,
622 |         cached_content_token_count: 50,
623 |         thoughts_token_count: 20,
624 |         tool_token_count: 30,
625 |       } as ApiResponseEvent & { 'event.name': typeof EVENT_API_RESPONSE };
626 | 
627 |       service.addEvent(event);
628 |       expect(service.getLastPromptTokenCount()).toBe(0);
629 | 
630 |       // Reset once
[TRUNCATED]
```

src/telemetry/uiTelemetry.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { EventEmitter } from 'node:events';
8 | import {
9 |   EVENT_API_ERROR,
10 |   EVENT_API_RESPONSE,
11 |   EVENT_TOOL_CALL,
12 | } from './types.js';
13 | 
14 | import { ToolCallDecision } from './tool-call-decision.js';
15 | import type {
16 |   ApiErrorEvent,
17 |   ApiResponseEvent,
18 |   ToolCallEvent,
19 | } from './types.js';
20 | 
21 | export type UiEvent =
22 |   | (ApiResponseEvent & { 'event.name': typeof EVENT_API_RESPONSE })
23 |   | (ApiErrorEvent & { 'event.name': typeof EVENT_API_ERROR })
24 |   | (ToolCallEvent & { 'event.name': typeof EVENT_TOOL_CALL });
25 | 
26 | export interface ToolCallStats {
27 |   count: number;
28 |   success: number;
29 |   fail: number;
30 |   durationMs: number;
31 |   decisions: {
32 |     [ToolCallDecision.ACCEPT]: number;
33 |     [ToolCallDecision.REJECT]: number;
34 |     [ToolCallDecision.MODIFY]: number;
35 |     [ToolCallDecision.AUTO_ACCEPT]: number;
36 |   };
37 | }
38 | 
39 | export interface ModelMetrics {
40 |   api: {
41 |     totalRequests: number;
42 |     totalErrors: number;
43 |     totalLatencyMs: number;
44 |   };
45 |   tokens: {
46 |     prompt: number;
47 |     candidates: number;
48 |     total: number;
49 |     cached: number;
50 |     thoughts: number;
51 |     tool: number;
52 |   };
53 | }
54 | 
55 | export interface SessionMetrics {
56 |   models: Record<string, ModelMetrics>;
57 |   tools: {
58 |     totalCalls: number;
59 |     totalSuccess: number;
60 |     totalFail: number;
61 |     totalDurationMs: number;
62 |     totalDecisions: {
63 |       [ToolCallDecision.ACCEPT]: number;
64 |       [ToolCallDecision.REJECT]: number;
65 |       [ToolCallDecision.MODIFY]: number;
66 |       [ToolCallDecision.AUTO_ACCEPT]: number;
67 |     };
68 |     byName: Record<string, ToolCallStats>;
69 |   };
70 |   files: {
71 |     totalLinesAdded: number;
72 |     totalLinesRemoved: number;
73 |   };
74 | }
75 | 
76 | const createInitialModelMetrics = (): ModelMetrics => ({
77 |   api: {
78 |     totalRequests: 0,
79 |     totalErrors: 0,
80 |     totalLatencyMs: 0,
81 |   },
82 |   tokens: {
83 |     prompt: 0,
84 |     candidates: 0,
85 |     total: 0,
86 |     cached: 0,
87 |     thoughts: 0,
88 |     tool: 0,
89 |   },
90 | });
91 | 
92 | const createInitialMetrics = (): SessionMetrics => ({
93 |   models: {},
94 |   tools: {
95 |     totalCalls: 0,
96 |     totalSuccess: 0,
97 |     totalFail: 0,
98 |     totalDurationMs: 0,
99 |     totalDecisions: {
100 |       [ToolCallDecision.ACCEPT]: 0,
101 |       [ToolCallDecision.REJECT]: 0,
102 |       [ToolCallDecision.MODIFY]: 0,
103 |       [ToolCallDecision.AUTO_ACCEPT]: 0,
104 |     },
105 |     byName: {},
106 |   },
107 |   files: {
108 |     totalLinesAdded: 0,
109 |     totalLinesRemoved: 0,
110 |   },
111 | });
112 | 
113 | export class UiTelemetryService extends EventEmitter {
114 |   #metrics: SessionMetrics = createInitialMetrics();
115 |   #lastPromptTokenCount = 0;
116 | 
117 |   addEvent(event: UiEvent) {
118 |     switch (event['event.name']) {
119 |       case EVENT_API_RESPONSE:
120 |         this.processApiResponse(event);
121 |         break;
122 |       case EVENT_API_ERROR:
123 |         this.processApiError(event);
124 |         break;
125 |       case EVENT_TOOL_CALL:
126 |         this.processToolCall(event);
127 |         break;
128 |       default:
129 |         // We should not emit update for any other event metric.
130 |         return;
131 |     }
132 | 
133 |     this.emit('update', {
134 |       metrics: this.#metrics,
135 |       lastPromptTokenCount: this.#lastPromptTokenCount,
136 |     });
137 |   }
138 | 
139 |   getMetrics(): SessionMetrics {
140 |     return this.#metrics;
141 |   }
142 | 
143 |   getLastPromptTokenCount(): number {
144 |     return this.#lastPromptTokenCount;
145 |   }
146 | 
147 |   setLastPromptTokenCount(lastPromptTokenCount: number): void {
148 |     this.#lastPromptTokenCount = lastPromptTokenCount;
149 |     this.emit('update', {
150 |       metrics: this.#metrics,
151 |       lastPromptTokenCount: this.#lastPromptTokenCount,
152 |     });
153 |   }
154 | 
155 |   private getOrCreateModelMetrics(modelName: string): ModelMetrics {
156 |     if (!this.#metrics.models[modelName]) {
157 |       this.#metrics.models[modelName] = createInitialModelMetrics();
158 |     }
159 |     return this.#metrics.models[modelName];
160 |   }
161 | 
162 |   private processApiResponse(event: ApiResponseEvent) {
163 |     const modelMetrics = this.getOrCreateModelMetrics(event.model);
164 | 
165 |     modelMetrics.api.totalRequests++;
166 |     modelMetrics.api.totalLatencyMs += event.duration_ms;
167 | 
168 |     modelMetrics.tokens.prompt += event.input_token_count;
169 |     modelMetrics.tokens.candidates += event.output_token_count;
170 |     modelMetrics.tokens.total += event.total_token_count;
171 |     modelMetrics.tokens.cached += event.cached_content_token_count;
172 |     modelMetrics.tokens.thoughts += event.thoughts_token_count;
173 |     modelMetrics.tokens.tool += event.tool_token_count;
174 |   }
175 | 
176 |   private processApiError(event: ApiErrorEvent) {
177 |     const modelMetrics = this.getOrCreateModelMetrics(event.model);
178 |     modelMetrics.api.totalRequests++;
179 |     modelMetrics.api.totalErrors++;
180 |     modelMetrics.api.totalLatencyMs += event.duration_ms;
181 |   }
182 | 
183 |   private processToolCall(event: ToolCallEvent) {
184 |     const { tools, files } = this.#metrics;
185 |     tools.totalCalls++;
186 |     tools.totalDurationMs += event.duration_ms;
187 | 
188 |     if (event.success) {
189 |       tools.totalSuccess++;
190 |     } else {
191 |       tools.totalFail++;
192 |     }
193 | 
194 |     if (!tools.byName[event.function_name]) {
195 |       tools.byName[event.function_name] = {
196 |         count: 0,
197 |         success: 0,
198 |         fail: 0,
199 |         durationMs: 0,
200 |         decisions: {
201 |           [ToolCallDecision.ACCEPT]: 0,
202 |           [ToolCallDecision.REJECT]: 0,
203 |           [ToolCallDecision.MODIFY]: 0,
204 |           [ToolCallDecision.AUTO_ACCEPT]: 0,
205 |         },
206 |       };
207 |     }
208 | 
209 |     const toolStats = tools.byName[event.function_name];
210 |     toolStats.count++;
211 |     toolStats.durationMs += event.duration_ms;
212 |     if (event.success) {
213 |       toolStats.success++;
214 |     } else {
215 |       toolStats.fail++;
216 |     }
217 | 
218 |     if (event.decision) {
219 |       tools.totalDecisions[event.decision]++;
220 |       toolStats.decisions[event.decision]++;
221 |     }
222 | 
223 |     // Aggregate line count data from metadata
224 |     if (event.metadata) {
225 |       if (event.metadata['model_added_lines'] !== undefined) {
226 |         files.totalLinesAdded += event.metadata['model_added_lines'];
227 |       }
228 |       if (event.metadata['model_removed_lines'] !== undefined) {
229 |         files.totalLinesRemoved += event.metadata['model_removed_lines'];
230 |       }
231 |     }
232 |   }
233 | }
234 | 
235 | export const uiTelemetryService = new UiTelemetryService();
```

src/test-utils/config.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { ConfigParameters } from '../config/config.js';
8 | import { Config } from '../config/config.js';
9 | 
10 | /**
11 |  * Default parameters used for {@link FAKE_CONFIG}
12 |  */
13 | export const DEFAULT_CONFIG_PARAMETERS: ConfigParameters = {
14 |   usageStatisticsEnabled: true,
15 |   debugMode: false,
16 |   sessionId: 'test-session-id',
17 |   proxy: undefined,
18 |   model: 'gemini-9001-super-duper',
19 |   targetDir: '/',
20 |   cwd: '/',
21 | };
22 | 
23 | /**
24 |  * Produces a config.  Default paramters are set to
25 |  * {@link DEFAULT_CONFIG_PARAMETERS}, optionally, fields can be specified to
26 |  * override those defaults.
27 |  */
28 | export function makeFakeConfig(
29 |   config: Partial<ConfigParameters> = {
30 |     ...DEFAULT_CONFIG_PARAMETERS,
31 |   },
32 | ): Config {
33 |   return new Config({
34 |     ...DEFAULT_CONFIG_PARAMETERS,
35 |     ...config,
36 |   });
37 | }
```

src/test-utils/index.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export * from './mock-tool.js';
```

src/test-utils/mock-tool.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   ModifiableDeclarativeTool,
9 |   ModifyContext,
10 | } from '../tools/modifiable-tool.js';
11 | import type {
12 |   ToolCallConfirmationDetails,
13 |   ToolInvocation,
14 |   ToolResult,
15 | } from '../tools/tools.js';
16 | import {
17 |   BaseDeclarativeTool,
18 |   BaseToolInvocation,
19 |   Kind,
20 | } from '../tools/tools.js';
21 | 
22 | interface MockToolOptions {
23 |   name: string;
24 |   displayName?: string;
25 |   description?: string;
26 |   canUpdateOutput?: boolean;
27 |   isOutputMarkdown?: boolean;
28 |   shouldConfirmExecute?: (
29 |     params: { [key: string]: unknown },
30 |     signal: AbortSignal,
31 |   ) => Promise<ToolCallConfirmationDetails | false>;
32 |   execute?: (
33 |     params: { [key: string]: unknown },
34 |     signal?: AbortSignal,
35 |     updateOutput?: (output: string) => void,
36 |   ) => Promise<ToolResult>;
37 |   params?: object;
38 | }
39 | 
40 | class MockToolInvocation extends BaseToolInvocation<
41 |   { [key: string]: unknown },
42 |   ToolResult
43 | > {
44 |   constructor(
45 |     private readonly tool: MockTool,
46 |     params: { [key: string]: unknown },
47 |   ) {
48 |     super(params);
49 |   }
50 | 
51 |   execute(
52 |     signal: AbortSignal,
53 |     updateOutput?: (output: string) => void,
54 |   ): Promise<ToolResult> {
55 |     if (updateOutput) {
56 |       return this.tool.execute(this.params, signal, updateOutput);
57 |     } else {
58 |       return this.tool.execute(this.params);
59 |     }
60 |   }
61 | 
62 |   override shouldConfirmExecute(
63 |     abortSignal: AbortSignal,
64 |   ): Promise<ToolCallConfirmationDetails | false> {
65 |     return this.tool.shouldConfirmExecute(this.params, abortSignal);
66 |   }
67 | 
68 |   getDescription(): string {
69 |     return `A mock tool invocation for ${this.tool.name}`;
70 |   }
71 | }
72 | 
73 | /**
74 |  * A highly configurable mock tool for testing purposes.
75 |  */
76 | export class MockTool extends BaseDeclarativeTool<
77 |   { [key: string]: unknown },
78 |   ToolResult
79 | > {
80 |   shouldConfirmExecute: (
81 |     params: { [key: string]: unknown },
82 |     signal: AbortSignal,
83 |   ) => Promise<ToolCallConfirmationDetails | false>;
84 |   execute: (
85 |     params: { [key: string]: unknown },
86 |     signal?: AbortSignal,
87 |     updateOutput?: (output: string) => void,
88 |   ) => Promise<ToolResult>;
89 | 
90 |   constructor(options: MockToolOptions) {
91 |     super(
92 |       options.name,
93 |       options.displayName ?? options.name,
94 |       options.description ?? options.name,
95 |       Kind.Other,
96 |       options.params,
97 |       options.isOutputMarkdown ?? false,
98 |       options.canUpdateOutput ?? false,
99 |     );
100 | 
101 |     if (options.shouldConfirmExecute) {
102 |       this.shouldConfirmExecute = options.shouldConfirmExecute;
103 |     } else {
104 |       this.shouldConfirmExecute = () => Promise.resolve(false);
105 |     }
106 | 
107 |     if (options.execute) {
108 |       this.execute = options.execute;
109 |     } else {
110 |       this.execute = () =>
111 |         Promise.resolve({
112 |           llmContent: `Tool ${this.name} executed successfully.`,
113 |           returnDisplay: `Tool ${this.name} executed successfully.`,
114 |         });
115 |     }
116 |   }
117 | 
118 |   protected createInvocation(params: {
119 |     [key: string]: unknown;
120 |   }): ToolInvocation<{ [key: string]: unknown }, ToolResult> {
121 |     return new MockToolInvocation(this, params);
122 |   }
123 | }
124 | 
125 | export const MOCK_TOOL_SHOULD_CONFIRM_EXECUTE = () =>
126 |   Promise.resolve({
127 |     type: 'exec' as const,
128 |     title: 'Confirm mockTool',
129 |     command: 'mockTool',
130 |     rootCommand: 'mockTool',
131 |     onConfirm: async () => {},
132 |   });
133 | 
134 | export class MockModifiableToolInvocation extends BaseToolInvocation<
135 |   Record<string, unknown>,
136 |   ToolResult
137 | > {
138 |   constructor(
139 |     private readonly tool: MockModifiableTool,
140 |     params: Record<string, unknown>,
141 |   ) {
142 |     super(params);
143 |   }
144 | 
145 |   async execute(_abortSignal: AbortSignal): Promise<ToolResult> {
146 |     const result = this.tool.executeFn(this.params);
147 |     return (
148 |       result ?? {
149 |         llmContent: `Tool ${this.tool.name} executed successfully.`,
150 |         returnDisplay: `Tool ${this.tool.name} executed successfully.`,
151 |       }
152 |     );
153 |   }
154 | 
155 |   override async shouldConfirmExecute(
156 |     _abortSignal: AbortSignal,
157 |   ): Promise<ToolCallConfirmationDetails | false> {
158 |     if (this.tool.shouldConfirm) {
159 |       return {
160 |         type: 'edit',
161 |         title: 'Confirm Mock Tool',
162 |         fileName: 'test.txt',
163 |         filePath: 'test.txt',
164 |         fileDiff: 'diff',
165 |         originalContent: 'originalContent',
166 |         newContent: 'newContent',
167 |         onConfirm: async () => {},
168 |       };
169 |     }
170 |     return false;
171 |   }
172 | 
173 |   getDescription(): string {
174 |     return `A mock modifiable tool invocation for ${this.tool.name}`;
175 |   }
176 | }
177 | 
178 | /**
179 |  * Configurable mock modifiable tool for testing.
180 |  */
181 | export class MockModifiableTool
182 |   extends BaseDeclarativeTool<Record<string, unknown>, ToolResult>
183 |   implements ModifiableDeclarativeTool<Record<string, unknown>>
184 | {
185 |   // Should be overrided in test file. Functionality will be updated in follow
186 |   // up PR which has MockModifiableTool expect MockTool
187 |   executeFn: (params: Record<string, unknown>) => ToolResult | undefined = () =>
188 |     undefined;
189 |   shouldConfirm = true;
190 | 
191 |   constructor(name = 'mockModifiableTool') {
192 |     super(name, name, 'A mock modifiable tool for testing.', Kind.Other, {
193 |       type: 'object',
194 |       properties: { param: { type: 'string' } },
195 |     });
196 |   }
197 | 
198 |   getModifyContext(
199 |     _abortSignal: AbortSignal,
200 |   ): ModifyContext<Record<string, unknown>> {
201 |     return {
202 |       getFilePath: () => 'test.txt',
203 |       getCurrentContent: async () => 'old content',
204 |       getProposedContent: async () => 'new content',
205 |       createUpdatedParams: (
206 |         _oldContent: string,
207 |         modifiedProposedContent: string,
208 |         _originalParams: Record<string, unknown>,
209 |       ) => ({ newContent: modifiedProposedContent }),
210 |     };
211 |   }
212 | 
213 |   protected createInvocation(
214 |     params: Record<string, unknown>,
215 |   ): ToolInvocation<Record<string, unknown>, ToolResult> {
216 |     return new MockModifiableToolInvocation(this, params);
217 |   }
218 | }
```

src/test-utils/mockWorkspaceContext.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { vi } from 'vitest';
8 | import type { WorkspaceContext } from '../utils/workspaceContext.js';
9 | 
10 | /**
11 |  * Creates a mock WorkspaceContext for testing
12 |  * @param rootDir The root directory to use for the mock
13 |  * @param additionalDirs Optional additional directories to include in the workspace
14 |  * @returns A mock WorkspaceContext instance
15 |  */
16 | export function createMockWorkspaceContext(
17 |   rootDir: string,
18 |   additionalDirs: string[] = [],
19 | ): WorkspaceContext {
20 |   const allDirs = [rootDir, ...additionalDirs];
21 | 
22 |   const mockWorkspaceContext = {
23 |     addDirectory: vi.fn(),
24 |     getDirectories: vi.fn().mockReturnValue(allDirs),
25 |     isPathWithinWorkspace: vi
26 |       .fn()
27 |       .mockImplementation((path: string) =>
28 |         allDirs.some((dir) => path.startsWith(dir)),
29 |       ),
30 |   } as unknown as WorkspaceContext;
31 | 
32 |   return mockWorkspaceContext;
33 | }
```

src/tools/diffOptions.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, expect, it } from 'vitest';
8 | import { getDiffStat } from './diffOptions.js';
9 | 
10 | describe('getDiffStat', () => {
11 |   const fileName = 'test.txt';
12 | 
13 |   it('should return 0 for all stats when there are no changes', () => {
14 |     const oldStr = 'line1\nline2\n';
15 |     const aiStr = 'line1\nline2\n';
16 |     const userStr = 'line1\nline2\n';
17 |     const diffStat = getDiffStat(fileName, oldStr, aiStr, userStr);
18 |     expect(diffStat).toEqual({
19 |       model_added_lines: 0,
20 |       model_removed_lines: 0,
21 |       model_added_chars: 0,
22 |       model_removed_chars: 0,
23 |       user_added_lines: 0,
24 |       user_removed_lines: 0,
25 |       user_added_chars: 0,
26 |       user_removed_chars: 0,
27 |     });
28 |   });
29 | 
30 |   it('should correctly report model additions', () => {
31 |     const oldStr = 'line1\nline2\n';
32 |     const aiStr = 'line1\nline2\nline3\n';
33 |     const userStr = 'line1\nline2\nline3\n';
34 |     const diffStat = getDiffStat(fileName, oldStr, aiStr, userStr);
35 |     expect(diffStat).toEqual({
36 |       model_added_lines: 1,
37 |       model_removed_lines: 0,
38 |       model_added_chars: 5,
39 |       model_removed_chars: 0,
40 |       user_added_lines: 0,
41 |       user_removed_lines: 0,
42 |       user_added_chars: 0,
43 |       user_removed_chars: 0,
44 |     });
45 |   });
46 | 
47 |   it('should correctly report model removals', () => {
48 |     const oldStr = 'line1\nline2\nline3\n';
49 |     const aiStr = 'line1\nline3\n';
50 |     const userStr = 'line1\nline3\n';
51 |     const diffStat = getDiffStat(fileName, oldStr, aiStr, userStr);
52 |     expect(diffStat).toEqual({
53 |       model_added_lines: 0,
54 |       model_removed_lines: 1,
55 |       model_added_chars: 0,
56 |       model_removed_chars: 5,
57 |       user_added_lines: 0,
58 |       user_removed_lines: 0,
59 |       user_added_chars: 0,
60 |       user_removed_chars: 0,
61 |     });
62 |   });
63 | 
64 |   it('should correctly report model modifications', () => {
65 |     const oldStr = 'line1\nline2\nline3\n';
66 |     const aiStr = 'line1\nline_two\nline3\n';
67 |     const userStr = 'line1\nline_two\nline3\n';
68 |     const diffStat = getDiffStat(fileName, oldStr, aiStr, userStr);
69 |     expect(diffStat).toEqual({
70 |       model_added_lines: 1,
71 |       model_removed_lines: 1,
72 |       model_added_chars: 8,
73 |       model_removed_chars: 5,
74 |       user_added_lines: 0,
75 |       user_removed_lines: 0,
76 |       user_added_chars: 0,
77 |       user_removed_chars: 0,
78 |     });
79 |   });
80 | 
81 |   it('should correctly report user additions', () => {
82 |     const oldStr = 'line1\nline2\n';
83 |     const aiStr = 'line1\nline2\nline3\n';
84 |     const userStr = 'line1\nline2\nline3\nline4\n';
85 |     const diffStat = getDiffStat(fileName, oldStr, aiStr, userStr);
86 |     expect(diffStat).toEqual({
87 |       model_added_lines: 1,
88 |       model_removed_lines: 0,
89 |       model_added_chars: 5,
90 |       model_removed_chars: 0,
91 |       user_added_lines: 1,
92 |       user_removed_lines: 0,
93 |       user_added_chars: 5,
94 |       user_removed_chars: 0,
95 |     });
96 |   });
97 | 
98 |   it('should correctly report user removals', () => {
99 |     const oldStr = 'line1\nline2\n';
100 |     const aiStr = 'line1\nline2\nline3\n';
101 |     const userStr = 'line1\nline2\n';
102 |     const diffStat = getDiffStat(fileName, oldStr, aiStr, userStr);
103 |     expect(diffStat).toEqual({
104 |       model_added_lines: 1,
105 |       model_removed_lines: 0,
106 |       model_added_chars: 5,
107 |       model_removed_chars: 0,
108 |       user_added_lines: 0,
109 |       user_removed_lines: 1,
110 |       user_added_chars: 0,
111 |       user_removed_chars: 5,
112 |     });
113 |   });
114 | 
115 |   it('should correctly report user modifications', () => {
116 |     const oldStr = 'line1\nline2\n';
117 |     const aiStr = 'line1\nline2\nline3\n';
118 |     const userStr = 'line1\nline2\nline_three\n';
119 |     const diffStat = getDiffStat(fileName, oldStr, aiStr, userStr);
120 |     expect(diffStat).toEqual({
121 |       model_added_lines: 1,
122 |       model_removed_lines: 0,
123 |       model_added_chars: 5,
124 |       model_removed_chars: 0,
125 |       user_added_lines: 1,
126 |       user_removed_lines: 1,
127 |       user_added_chars: 10,
128 |       user_removed_chars: 5,
129 |     });
130 |   });
131 | 
132 |   it('should handle complex changes from both model and user', () => {
133 |     const oldStr = 'line1\nline2\nline3\nline4\n';
134 |     const aiStr = 'line_one\nline2\nline_three\nline4\n';
135 |     const userStr = 'line_one\nline_two\nline_three\nline4\nline5\n';
136 |     const diffStat = getDiffStat(fileName, oldStr, aiStr, userStr);
137 |     expect(diffStat).toEqual({
138 |       model_added_lines: 2,
139 |       model_removed_lines: 2,
140 |       model_added_chars: 18,
141 |       model_removed_chars: 10,
142 |       user_added_lines: 2,
143 |       user_removed_lines: 1,
144 |       user_added_chars: 13,
145 |       user_removed_chars: 5,
146 |     });
147 |   });
148 | 
149 |   it('should report a single line modification as one addition and one removal', () => {
150 |     const oldStr = 'hello world';
151 |     const aiStr = 'hello universe';
152 |     const userStr = 'hello universe';
153 |     const diffStat = getDiffStat(fileName, oldStr, aiStr, userStr);
154 |     expect(diffStat).toEqual({
155 |       model_added_lines: 1,
156 |       model_removed_lines: 1,
157 |       model_added_chars: 14,
158 |       model_removed_chars: 11,
159 |       user_added_lines: 0,
160 |       user_removed_lines: 0,
161 |       user_added_chars: 0,
162 |       user_removed_chars: 0,
163 |     });
164 |   });
165 | });
```

src/tools/diffOptions.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as Diff from 'diff';
8 | import type { DiffStat } from './tools.js';
9 | 
10 | export const DEFAULT_DIFF_OPTIONS: Diff.PatchOptions = {
11 |   context: 3,
12 |   ignoreWhitespace: true,
13 | };
14 | 
15 | export function getDiffStat(
16 |   fileName: string,
17 |   oldStr: string,
18 |   aiStr: string,
19 |   userStr: string,
20 | ): DiffStat {
21 |   const getStats = (patch: Diff.ParsedDiff) => {
22 |     let addedLines = 0;
23 |     let removedLines = 0;
24 |     let addedChars = 0;
25 |     let removedChars = 0;
26 | 
27 |     patch.hunks.forEach((hunk: Diff.Hunk) => {
28 |       hunk.lines.forEach((line: string) => {
29 |         if (line.startsWith('+')) {
30 |           addedLines++;
31 |           addedChars += line.length - 1;
32 |         } else if (line.startsWith('-')) {
33 |           removedLines++;
34 |           removedChars += line.length - 1;
35 |         }
36 |       });
37 |     });
38 |     return { addedLines, removedLines, addedChars, removedChars };
39 |   };
40 | 
41 |   const modelPatch = Diff.structuredPatch(
42 |     fileName,
43 |     fileName,
44 |     oldStr,
45 |     aiStr,
46 |     'Current',
47 |     'Proposed',
48 |     DEFAULT_DIFF_OPTIONS,
49 |   );
50 |   const modelStats = getStats(modelPatch);
51 | 
52 |   const userPatch = Diff.structuredPatch(
53 |     fileName,
54 |     fileName,
55 |     aiStr,
56 |     userStr,
57 |     'Proposed',
58 |     'User',
59 |     DEFAULT_DIFF_OPTIONS,
60 |   );
61 |   const userStats = getStats(userPatch);
62 | 
63 |   return {
64 |     model_added_lines: modelStats.addedLines,
65 |     model_removed_lines: modelStats.removedLines,
66 |     model_added_chars: modelStats.addedChars,
67 |     model_removed_chars: modelStats.removedChars,
68 |     user_added_lines: userStats.addedLines,
69 |     user_removed_lines: userStats.removedLines,
70 |     user_added_chars: userStats.addedChars,
71 |     user_removed_chars: userStats.removedChars,
72 |   };
73 | }
```

src/tools/edit.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /* eslint-disable @typescript-eslint/no-explicit-any */
8 | 
9 | const mockEnsureCorrectEdit = vi.hoisted(() => vi.fn());
10 | const mockGenerateJson = vi.hoisted(() => vi.fn());
11 | const mockOpenDiff = vi.hoisted(() => vi.fn());
12 | 
13 | import { IdeClient } from '../ide/ide-client.js';
14 | 
15 | vi.mock('../ide/ide-client.js', () => ({
16 |   IdeClient: {
17 |     getInstance: vi.fn(),
18 |   },
19 | }));
20 | 
21 | vi.mock('../utils/editCorrector.js', () => ({
22 |   ensureCorrectEdit: mockEnsureCorrectEdit,
23 | }));
24 | 
25 | vi.mock('../core/client.js', () => ({
26 |   GeminiClient: vi.fn().mockImplementation(() => ({
27 |     generateJson: mockGenerateJson,
28 |   })),
29 | }));
30 | 
31 | vi.mock('../utils/editor.js', () => ({
32 |   openDiff: mockOpenDiff,
33 | }));
34 | 
35 | vi.mock('../telemetry/loggers.js', () => ({
36 |   logFileOperation: vi.fn(),
37 | }));
38 | 
39 | import type { Mock } from 'vitest';
40 | import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
41 | import type { EditToolParams } from './edit.js';
42 | import { applyReplacement, EditTool } from './edit.js';
43 | import type { FileDiff } from './tools.js';
44 | import { ToolConfirmationOutcome } from './tools.js';
45 | import { ToolErrorType } from './tool-error.js';
46 | import path from 'node:path';
47 | import fs from 'node:fs';
48 | import os from 'node:os';
49 | import type { Config } from '../config/config.js';
50 | import { ApprovalMode } from '../config/config.js';
51 | import type { Content, Part, SchemaUnion } from '@google/genai';
52 | import { createMockWorkspaceContext } from '../test-utils/mockWorkspaceContext.js';
53 | import { StandardFileSystemService } from '../services/fileSystemService.js';
54 | 
55 | describe('EditTool', () => {
56 |   let tool: EditTool;
57 |   let tempDir: string;
58 |   let rootDir: string;
59 |   let mockConfig: Config;
60 |   let geminiClient: any;
61 |   let baseLlmClient: any;
62 | 
63 |   beforeEach(() => {
64 |     vi.restoreAllMocks();
65 |     tempDir = fs.mkdtempSync(path.join(os.tmpdir(), 'edit-tool-test-'));
66 |     rootDir = path.join(tempDir, 'root');
67 |     fs.mkdirSync(rootDir);
68 | 
69 |     geminiClient = {
70 |       generateJson: mockGenerateJson, // mockGenerateJson is already defined and hoisted
71 |     };
72 | 
73 |     baseLlmClient = {
74 |       generateJson: vi.fn(),
75 |     };
76 | 
77 |     mockConfig = {
78 |       getGeminiClient: vi.fn().mockReturnValue(geminiClient),
79 |       getBaseLlmClient: vi.fn().mockReturnValue(baseLlmClient),
80 |       getTargetDir: () => rootDir,
81 |       getApprovalMode: vi.fn(),
82 |       setApprovalMode: vi.fn(),
83 |       getWorkspaceContext: () => createMockWorkspaceContext(rootDir),
84 |       getFileSystemService: () => new StandardFileSystemService(),
85 |       getIdeMode: () => false,
86 |       // getGeminiConfig: () => ({ apiKey: 'test-api-key' }), // This was not a real Config method
87 |       // Add other properties/methods of Config if EditTool uses them
88 |       // Minimal other methods to satisfy Config type if needed by EditTool constructor or other direct uses:
89 |       getApiKey: () => 'test-api-key',
90 |       getModel: () => 'test-model',
91 |       getSandbox: () => false,
92 |       getDebugMode: () => false,
93 |       getQuestion: () => undefined,
94 |       getFullContext: () => false,
95 |       getToolDiscoveryCommand: () => undefined,
96 |       getToolCallCommand: () => undefined,
97 |       getMcpServerCommand: () => undefined,
98 |       getMcpServers: () => undefined,
99 |       getUserAgent: () => 'test-agent',
100 |       getUserMemory: () => '',
101 |       setUserMemory: vi.fn(),
102 |       getGeminiMdFileCount: () => 0,
103 |       setGeminiMdFileCount: vi.fn(),
104 |       getToolRegistry: () => ({}) as any, // Minimal mock for ToolRegistry
105 |     } as unknown as Config;
106 | 
107 |     // Reset mocks before each test
108 |     (mockConfig.getApprovalMode as Mock).mockClear();
109 |     // Default to not skipping confirmation
110 |     (mockConfig.getApprovalMode as Mock).mockReturnValue(ApprovalMode.DEFAULT);
111 | 
112 |     // Reset mocks and set default implementation for ensureCorrectEdit
113 |     mockEnsureCorrectEdit.mockReset();
114 |     mockEnsureCorrectEdit.mockImplementation(
115 |       async (_, currentContent, params) => {
116 |         let occurrences = 0;
117 |         if (params.old_string && currentContent) {
118 |           // Simple string counting for the mock
119 |           let index = currentContent.indexOf(params.old_string);
120 |           while (index !== -1) {
121 |             occurrences++;
122 |             index = currentContent.indexOf(params.old_string, index + 1);
123 |           }
124 |         } else if (params.old_string === '') {
125 |           occurrences = 0; // Creating a new file
126 |         }
127 |         return Promise.resolve({ params, occurrences });
128 |       },
129 |     );
130 | 
131 |     // Default mock for generateJson to return the snippet unchanged
132 |     mockGenerateJson.mockReset();
133 |     mockGenerateJson.mockImplementation(
134 |       async (contents: Content[], schema: SchemaUnion) => {
135 |         // The problematic_snippet is the last part of the user's content
136 |         const userContent = contents.find((c: Content) => c.role === 'user');
137 |         let promptText = '';
138 |         if (userContent && userContent.parts) {
139 |           promptText = userContent.parts
140 |             .filter((p: Part) => typeof (p as any).text === 'string')
141 |             .map((p: Part) => (p as any).text)
142 |             .join('\n');
143 |         }
144 |         const snippetMatch = promptText.match(
145 |           /Problematic target snippet:\n```\n([\s\S]*?)\n```/,
146 |         );
147 |         const problematicSnippet =
148 |           snippetMatch && snippetMatch[1] ? snippetMatch[1] : '';
149 | 
150 |         if (((schema as any).properties as any)?.corrected_target_snippet) {
151 |           return Promise.resolve({
152 |             corrected_target_snippet: problematicSnippet,
153 |           });
154 |         }
155 |         if (((schema as any).properties as any)?.corrected_new_string) {
156 |           // For new_string correction, we might need more sophisticated logic,
157 |           // but for now, returning original is a safe default if not specified by a test.
158 |           const originalNewStringMatch = promptText.match(
159 |             /original_new_string \(what was intended to replace original_old_string\):\n```\n([\s\S]*?)\n```/,
160 |           );
161 |           const originalNewString =
162 |             originalNewStringMatch && originalNewStringMatch[1]
163 |               ? originalNewStringMatch[1]
164 |               : '';
165 |           return Promise.resolve({ corrected_new_string: originalNewString });
166 |         }
167 |         return Promise.resolve({}); // Default empty object if schema doesn't match
168 |       },
169 |     );
170 | 
171 |     tool = new EditTool(mockConfig);
172 |   });
173 | 
174 |   afterEach(() => {
175 |     fs.rmSync(tempDir, { recursive: true, force: true });
176 |   });
177 | 
178 |   describe('applyReplacement', () => {
179 |     it('should return newString if isNewFile is true', () => {
180 |       expect(applyReplacement(null, 'old', 'new', true)).toBe('new');
181 |       expect(applyReplacement('existing', 'old', 'new', true)).toBe('new');
182 |     });
183 | 
184 |     it('should return newString if currentContent is null and oldString is empty (defensive)', () => {
185 |       expect(applyReplacement(null, '', 'new', false)).toBe('new');
186 |     });
187 | 
188 |     it('should return empty string if currentContent is null and oldString is not empty (defensive)', () => {
189 |       expect(applyReplacement(null, 'old', 'new', false)).toBe('');
190 |     });
191 | 
192 |     it('should replace oldString with newString in currentContent', () => {
193 |       expect(applyReplacement('hello old world old', 'old', 'new', false)).toBe(
194 |         'hello new world new',
195 |       );
196 |     });
197 | 
198 |     it('should return currentContent if oldString is empty and not a new file', () => {
199 |       expect(applyReplacement('hello world', '', 'new', false)).toBe(
200 |         'hello world',
201 |       );
202 |     });
203 | 
204 |     it('should treat $ literally and not as replacement pattern', () => {
205 |       const current = "price is $100 and pattern end is ' '";
206 |       const oldStr = 'price is $100';
207 |       const newStr = 'price is $200';
208 |       const result = applyReplacement(current, oldStr, newStr, false);
209 |       expect(result).toBe("price is $200 and pattern end is ' '");
210 |     });
211 | 
212 |     it("should treat $' literally and not as a replacement pattern", () => {
213 |       const current = 'foo';
214 |       const oldStr = 'foo';
215 |       const newStr = "bar$'baz";
216 |       const result = applyReplacement(current, oldStr, newStr, false);
217 |       expect(result).toBe("bar$'baz");
218 |     });
219 | 
220 |     it('should treat $& literally and not as a replacement pattern', () => {
221 |       const current = 'hello world';
222 |       const oldStr = 'hello';
223 |       const newStr = '$&-replacement';
224 |       const result = applyReplacement(current, oldStr, newStr, false);
225 |       expect(result).toBe('$&-replacement world');
226 |     });
227 | 
228 |     it('should treat $` literally and not as a replacement pattern', () => {
229 |       const current = 'prefix-middle-suffix';
230 |       const oldStr = 'middle';
231 |       const newStr = 'new$`content';
232 |       const result = applyReplacement(current, oldStr, newStr, false);
233 |       expect(result).toBe('prefix-new$`content-suffix');
234 |     });
235 | 
236 |     it('should treat $1, $2 capture groups literally', () => {
237 |       const current = 'test string';
238 |       const oldStr = 'test';
239 |       const newStr = '$1$2replacement';
240 |       const result = applyReplacement(current, oldStr, newStr, false);
241 |       expect(result).toBe('$1$2replacement string');
242 |     });
243 | 
244 |     it('should use replaceAll for normal strings without problematic $ sequences', () => {
245 |       const current = 'normal text replacement';
246 |       const oldStr = 'text';
247 |       const newStr = 'string';
248 |       const result = applyReplacement(current, oldStr, newStr, false);
249 |       expect(result).toBe('normal string replacement');
250 |     });
251 | 
252 |     it('should handle multiple occurrences with problematic $ sequences', () => {
253 |       const current = 'foo bar foo baz';
254 |       const oldStr = 'foo';
255 |       const newStr = "test$'end";
256 |       const result = applyReplacement(current, oldStr, newStr, false);
257 |       expect(result).toBe("test$'end bar test$'end baz");
258 |     });
259 | 
260 |     it('should handle complex regex patterns with $ at end', () => {
261 |       const current = "| select('match', '^[sv]d[a-z]$')";
262 |       const oldStr = "'^[sv]d[a-z]$'";
263 |       const newStr = "'^[sv]d[a-z]$' # updated";
264 |       const result = applyReplacement(current, oldStr, newStr, false);
265 |       expect(result).toBe("| select('match', '^[sv]d[a-z]$' # updated)");
266 |     });
267 | 
268 |     it('should handle empty replacement with problematic $ in newString', () => {
269 |       const current = 'test content';
270 |       const oldStr = 'nothing';
271 |       const newStr = "replacement$'text";
272 |       const result = applyReplacement(current, oldStr, newStr, false);
273 |       expect(result).toBe('test content'); // No replacement because oldStr not found
274 |     });
275 | 
276 |     it('should handle $$ (escaped dollar) correctly', () => {
277 |       const current = 'price value';
278 |       const oldStr = 'value';
279 |       const newStr = '$$100';
280 |       const result = applyReplacement(current, oldStr, newStr, false);
281 |       expect(result).toBe('price $$100');
282 |     });
283 |   });
284 | 
285 |   describe('validateToolParams', () => {
286 |     it('should return null for valid params', () => {
287 |       const params: EditToolParams = {
288 |         file_path: path.join(rootDir, 'test.txt'),
289 |         old_string: 'old',
290 |         new_string: 'new',
291 |       };
292 |       expect(tool.validateToolParams(params)).toBeNull();
293 |     });
294 | 
295 |     it('should return error for relative path', () => {
296 |       const params: EditToolParams = {
297 |         file_path: 'test.txt',
298 |         old_string: 'old',
299 |         new_string: 'new',
300 |       };
301 |       expect(tool.validateToolParams(params)).toMatch(
302 |         /File path must be absolute/,
303 |       );
304 |     });
305 | 
306 |     it('should return error for path outside root', () => {
307 |       const params: EditToolParams = {
308 |         file_path: path.join(tempDir, 'outside-root.txt'),
309 |         old_string: 'old',
310 |         new_string: 'new',
311 |       };
312 |       const error = tool.validateToolParams(params);
313 |       expect(error).toContain(
314 |         'File path must be within one of the workspace directories',
315 |       );
316 |     });
317 |   });
318 | 
319 |   describe('shouldConfirmExecute', () => {
320 |     const testFile = 'edit_me.txt';
321 |     let filePath: string;
322 | 
323 |     beforeEach(() => {
324 |       filePath = path.join(rootDir, testFile);
325 |     });
326 | 
327 |     it('should throw an error if params are invalid', async () => {
328 |       const params: EditToolParams = {
329 |         file_path: 'relative.txt',
330 |         old_string: 'old',
331 |         new_string: 'new',
332 |       };
333 |       expect(() => tool.build(params)).toThrow();
334 |     });
335 | 
336 |     it('should request confirmation for valid edit', async () => {
337 |       fs.writeFileSync(filePath, 'some old content here');
338 |       const params: EditToolParams = {
339 |         file_path: filePath,
340 |         old_string: 'old',
341 |         new_string: 'new',
342 |       };
343 |       // ensureCorrectEdit will be called by shouldConfirmExecute
344 |       mockEnsureCorrectEdit.mockResolvedValueOnce({ params, occurrences: 1 });
345 |       const invocation = tool.build(params);
346 |       const confirmation = await invocation.shouldConfirmExecute(
347 |         new AbortController().signal,
348 |       );
349 |       expect(confirmation).toEqual(
350 |         expect.objectContaining({
351 |           title: `Confirm Edit: ${testFile}`,
352 |           fileName: testFile,
353 |           fileDiff: expect.any(String),
354 |         }),
355 |       );
356 |     });
357 | 
358 |     it('should return false if old_string is not found (ensureCorrectEdit returns 0)', async () => {
359 |       fs.writeFileSync(filePath, 'some content here');
360 |       const params: EditToolParams = {
361 |         file_path: filePath,
362 |         old_string: 'not_found',
363 |         new_string: 'new',
364 |       };
365 |       mockEnsureCorrectEdit.mockResolvedValueOnce({ params, occurrences: 0 });
366 |       const invocation = tool.build(params);
367 |       const confirmation = await invocation.shouldConfirmExecute(
368 |         new AbortController().signal,
369 |       );
370 |       expect(confirmation).toBe(false);
371 |     });
372 | 
373 |     it('should return false if multiple occurrences of old_string are found (ensureCorrectEdit returns > 1)', async () => {
374 |       fs.writeFileSync(filePath, 'old old content here');
375 |       const params: EditToolParams = {
376 |         file_path: filePath,
377 |         old_string: 'old',
378 |         new_string: 'new',
379 |       };
380 |       mockEnsureCorrectEdit.mockResolvedValueOnce({ params, occurrences: 2 });
381 |       const invocation = tool.build(params);
382 |       const confirmation = await invocation.shouldConfirmExecute(
383 |         new AbortController().signal,
384 |       );
385 |       expect(confirmation).toBe(false);
386 |     });
387 | 
388 |     it('should request confirmation for creating a new file (empty old_string)', async () => {
389 |       const newFileName = 'new_file.txt';
390 |       const newFilePath = path.join(rootDir, newFileName);
391 |       const params: EditToolParams = {
392 |         file_path: newFilePath,
393 |         old_string: '',
394 |         new_string: 'new file content',
395 |       };
396 |       // ensureCorrectEdit might not be called if old_string is empty,
397 |       // as shouldConfirmExecute handles this for diff generation.
398 |       // If it is called, it should return 0 occurrences for a new file.
399 |       mockEnsureCorrectEdit.mockResolvedValueOnce({ params, occurrences: 0 });
400 |       const invocation = tool.build(params);
401 |       const confirmation = await invocation.shouldConfirmExecute(
402 |         new AbortController().signal,
403 |       );
404 |       expect(confirmation).toEqual(
405 |         expect.objectContaining({
406 |           title: `Confirm Edit: ${newFileName}`,
407 |           fileName: newFileName,
408 |           fileDiff: expect.any(String),
409 |         }),
410 |       );
411 |     });
412 | 
413 |     it('should use corrected params from ensureCorrectEdit for diff generation', async () => {
414 |       const originalContent = 'This is the original string to be replaced.';
415 |       const originalOldString = 'original string';
416 |       const originalNewString = 'new string';
417 | 
418 |       const correctedOldString = 'original string to be replaced'; // More specific
419 |       const correctedNewString = 'completely new string'; // Different replacement
420 |       const expectedFinalContent = 'This is the completely new string.';
421 | 
422 |       fs.writeFileSync(filePath, originalContent);
423 |       const params: EditToolParams = {
424 |         file_path: filePath,
425 |         old_string: originalOldString,
426 |         new_string: originalNewString,
427 |       };
428 | 
429 |       // The main beforeEach already calls mockEnsureCorrectEdit.mockReset()
430 |       // Set a specific mock for this test case
431 |       let mockCalled = false;
432 |       mockEnsureCorrectEdit.mockImplementationOnce(
433 |         async (_, content, p, client, baseClient) => {
434 |           mockCalled = true;
435 |           expect(content).toBe(originalContent);
436 |           expect(p).toBe(params);
437 |           expect(client).toBe(geminiClient);
438 |           expect(baseClient).toBe(baseLlmClient);
439 |           return {
440 |             params: {
441 |               file_path: filePath,
442 |               old_string: correctedOldString,
443 |               new_string: correctedNewString,
444 |             },
445 |             occurrences: 1,
446 |           };
447 |         },
448 |       );
449 |       const invocation = tool.build(params);
450 |       const confirmation = (await invocation.shouldConfirmExecute(
451 |         new AbortController().signal,
452 |       )) as FileDiff;
453 | 
454 |       expect(mockCalled).toBe(true); // Check if the mock implementation was run
455 |       // expect(mockEnsureCorrectEdit).toHaveBeenCalledWith(originalContent, params, expect.anything()); // Keep this commented for now
456 |       expect(confirmation).toEqual(
457 |         expect.objectContaining({
458 |           title: `Confirm Edit: ${testFile}`,
459 |           fileName: testFile,
460 |         }),
461 |       );
462 |       // Check that the diff is based on the corrected strings leading to the new state
463 |       expect(confirmation.fileDiff).toContain(`-${originalContent}`);
464 |       expect(confirmation.fileDiff).toContain(`+${expectedFinalContent}`);
465 | 
466 |       // Verify that applying the correctedOldString and correctedNewString to originalContent
467 |       // indeed produces the expectedFinalContent, which is what the diff should reflect.
468 |       const patchedContent = originalContent.replace(
469 |         correctedOldString, // This was the string identified by ensureCorrectEdit for replacement
470 |         correctedNewString, // This was the string identified by ensureCorrectEdit as the replacement
471 |       );
472 |       expect(patchedContent).toBe(expectedFinalContent);
473 |     });
474 | 
475 |     it('should rethrow calculateEdit errors when the abort signal is triggered', async () => {
476 |       const filePath = path.join(rootDir, 'abort-confirmation.txt');
477 |       const params: EditToolParams = {
478 |         file_path: filePath,
479 |         old_string: 'old',
480 |         new_string: 'new',
481 |       };
482 | 
483 |       const invocation = tool.build(params);
484 |       const abortController = new AbortController();
485 |       const abortError = new Error('Abort requested');
486 | 
487 |       const calculateSpy = vi
488 |         .spyOn(invocation as any, 'calculateEdit')
489 |         .mockImplementation(async () => {
490 |           if (!abortController.signal.aborted) {
491 |             abortController.abort();
492 |           }
493 |           throw abortError;
494 |         });
495 | 
496 |       await expect(
497 |         invocation.shouldConfirmExecute(abortController.signal),
498 |       ).rejects.toBe(abortError);
499 | 
500 |       calculateSpy.mockRestore();
501 |     });
502 |   });
503 | 
504 |   describe('execute', () => {
505 |     const testFile = 'execute_me.txt';
506 |     let filePath: string;
507 | 
508 |     beforeEach(() => {
509 |       filePath = path.join(rootDir, testFile);
510 |       // Default for execute tests, can be overridden
511 |       mockEnsureCorrectEdit.mockImplementation(async (_, content, params) => {
512 |         let occurrences = 0;
513 |         if (params.old_string && content) {
514 |           let index = content.indexOf(params.old_string);
515 |           while (index !== -1) {
516 |             occurrences++;
517 |             index = content.indexOf(params.old_string, index + 1);
518 |           }
519 |         } else if (params.old_string === '') {
520 |           occurrences = 0;
521 |         }
522 |         return { params, occurrences };
523 |       });
524 |     });
525 | 
526 |     it('should throw error if file path is not absolute', async () => {
527 |       const params: EditToolParams = {
528 |         file_path: 'relative.txt',
529 |         old_string: 'old',
530 |         new_string: 'new',
531 |       };
532 |       expect(() => tool.build(params)).toThrow(/File path must be absolute/);
533 |     });
534 | 
[TRUNCATED]
```

src/tools/edit.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs';
8 | import * as path from 'node:path';
9 | import * as Diff from 'diff';
10 | import type {
11 |   ToolCallConfirmationDetails,
12 |   ToolEditConfirmationDetails,
13 |   ToolInvocation,
14 |   ToolLocation,
15 |   ToolResult,
16 | } from './tools.js';
17 | import { BaseDeclarativeTool, Kind, ToolConfirmationOutcome } from './tools.js';
18 | import { ToolErrorType } from './tool-error.js';
19 | import { makeRelative, shortenPath } from '../utils/paths.js';
20 | import { isNodeError } from '../utils/errors.js';
21 | import type { Config } from '../config/config.js';
22 | import { ApprovalMode } from '../config/config.js';
23 | import { ensureCorrectEdit } from '../utils/editCorrector.js';
24 | import { DEFAULT_DIFF_OPTIONS, getDiffStat } from './diffOptions.js';
25 | import { ReadFileTool } from './read-file.js';
26 | import { logFileOperation } from '../telemetry/loggers.js';
27 | import { FileOperationEvent } from '../telemetry/types.js';
28 | import { FileOperation } from '../telemetry/metrics.js';
29 | import { getSpecificMimeType } from '../utils/fileUtils.js';
30 | import { getLanguageFromFilePath } from '../utils/language-detection.js';
31 | import type {
32 |   ModifiableDeclarativeTool,
33 |   ModifyContext,
34 | } from './modifiable-tool.js';
35 | import { IdeClient } from '../ide/ide-client.js';
36 | import { safeLiteralReplace } from '../utils/textUtils.js';
37 | 
38 | export function applyReplacement(
39 |   currentContent: string | null,
40 |   oldString: string,
41 |   newString: string,
42 |   isNewFile: boolean,
43 | ): string {
44 |   if (isNewFile) {
45 |     return newString;
46 |   }
47 |   if (currentContent === null) {
48 |     // Should not happen if not a new file, but defensively return empty or newString if oldString is also empty
49 |     return oldString === '' ? newString : '';
50 |   }
51 |   // If oldString is empty and it's not a new file, do not modify the content.
52 |   if (oldString === '' && !isNewFile) {
53 |     return currentContent;
54 |   }
55 | 
56 |   // Use intelligent replacement that handles $ sequences safely
57 |   return safeLiteralReplace(currentContent, oldString, newString);
58 | }
59 | 
60 | /**
61 |  * Parameters for the Edit tool
62 |  */
63 | export interface EditToolParams {
64 |   /**
65 |    * The absolute path to the file to modify
66 |    */
67 |   file_path: string;
68 | 
69 |   /**
70 |    * The text to replace
71 |    */
72 |   old_string: string;
73 | 
74 |   /**
75 |    * The text to replace it with
76 |    */
77 |   new_string: string;
78 | 
79 |   /**
80 |    * Number of replacements expected. Defaults to 1 if not specified.
81 |    * Use when you want to replace multiple occurrences.
82 |    */
83 |   expected_replacements?: number;
84 | 
85 |   /**
86 |    * Whether the edit was modified manually by the user.
87 |    */
88 |   modified_by_user?: boolean;
89 | 
90 |   /**
91 |    * Initially proposed content.
92 |    */
93 |   ai_proposed_content?: string;
94 | }
95 | 
96 | interface CalculatedEdit {
97 |   currentContent: string | null;
98 |   newContent: string;
99 |   occurrences: number;
100 |   error?: { display: string; raw: string; type: ToolErrorType };
101 |   isNewFile: boolean;
102 | }
103 | 
104 | class EditToolInvocation implements ToolInvocation<EditToolParams, ToolResult> {
105 |   constructor(
106 |     private readonly config: Config,
107 |     public params: EditToolParams,
108 |   ) {}
109 | 
110 |   toolLocations(): ToolLocation[] {
111 |     return [{ path: this.params.file_path }];
112 |   }
113 | 
114 |   /**
115 |    * Calculates the potential outcome of an edit operation.
116 |    * @param params Parameters for the edit operation
117 |    * @returns An object describing the potential edit outcome
118 |    * @throws File system errors if reading the file fails unexpectedly (e.g., permissions)
119 |    */
120 |   private async calculateEdit(
121 |     params: EditToolParams,
122 |     abortSignal: AbortSignal,
123 |   ): Promise<CalculatedEdit> {
124 |     const expectedReplacements = params.expected_replacements ?? 1;
125 |     let currentContent: string | null = null;
126 |     let fileExists = false;
127 |     let isNewFile = false;
128 |     let finalNewString = params.new_string;
129 |     let finalOldString = params.old_string;
130 |     let occurrences = 0;
131 |     let error:
132 |       | { display: string; raw: string; type: ToolErrorType }
133 |       | undefined = undefined;
134 | 
135 |     try {
136 |       currentContent = await this.config
137 |         .getFileSystemService()
138 |         .readTextFile(params.file_path);
139 |       // Normalize line endings to LF for consistent processing.
140 |       currentContent = currentContent.replace(/\r\n/g, '\n');
141 |       fileExists = true;
142 |     } catch (err: unknown) {
143 |       if (!isNodeError(err) || err.code !== 'ENOENT') {
144 |         // Rethrow unexpected FS errors (permissions, etc.)
145 |         throw err;
146 |       }
147 |       fileExists = false;
148 |     }
149 | 
150 |     if (params.old_string === '' && !fileExists) {
151 |       // Creating a new file
152 |       isNewFile = true;
153 |     } else if (!fileExists) {
154 |       // Trying to edit a nonexistent file (and old_string is not empty)
155 |       error = {
156 |         display: `File not found. Cannot apply edit. Use an empty old_string to create a new file.`,
157 |         raw: `File not found: ${params.file_path}`,
158 |         type: ToolErrorType.FILE_NOT_FOUND,
159 |       };
160 |     } else if (currentContent !== null) {
161 |       // Editing an existing file
162 |       const correctedEdit = await ensureCorrectEdit(
163 |         params.file_path,
164 |         currentContent,
165 |         params,
166 |         this.config.getGeminiClient(),
167 |         this.config.getBaseLlmClient(),
168 |         abortSignal,
169 |       );
170 |       finalOldString = correctedEdit.params.old_string;
171 |       finalNewString = correctedEdit.params.new_string;
172 |       occurrences = correctedEdit.occurrences;
173 | 
174 |       if (params.old_string === '') {
175 |         // Error: Trying to create a file that already exists
176 |         error = {
177 |           display: `Failed to edit. Attempted to create a file that already exists.`,
178 |           raw: `File already exists, cannot create: ${params.file_path}`,
179 |           type: ToolErrorType.ATTEMPT_TO_CREATE_EXISTING_FILE,
180 |         };
181 |       } else if (occurrences === 0) {
182 |         error = {
183 |           display: `Failed to edit, could not find the string to replace.`,
184 |           raw: `Failed to edit, 0 occurrences found for old_string in ${params.file_path}. No edits made. The exact text in old_string was not found. Ensure you're not escaping content incorrectly and check whitespace, indentation, and context. Use ${ReadFileTool.Name} tool to verify.`,
185 |           type: ToolErrorType.EDIT_NO_OCCURRENCE_FOUND,
186 |         };
187 |       } else if (occurrences !== expectedReplacements) {
188 |         const occurrenceTerm =
189 |           expectedReplacements === 1 ? 'occurrence' : 'occurrences';
190 | 
191 |         error = {
192 |           display: `Failed to edit, expected ${expectedReplacements} ${occurrenceTerm} but found ${occurrences}.`,
193 |           raw: `Failed to edit, Expected ${expectedReplacements} ${occurrenceTerm} but found ${occurrences} for old_string in file: ${params.file_path}`,
194 |           type: ToolErrorType.EDIT_EXPECTED_OCCURRENCE_MISMATCH,
195 |         };
196 |       } else if (finalOldString === finalNewString) {
197 |         error = {
198 |           display: `No changes to apply. The old_string and new_string are identical.`,
199 |           raw: `No changes to apply. The old_string and new_string are identical in file: ${params.file_path}`,
200 |           type: ToolErrorType.EDIT_NO_CHANGE,
201 |         };
202 |       }
203 |     } else {
204 |       // Should not happen if fileExists and no exception was thrown, but defensively:
205 |       error = {
206 |         display: `Failed to read content of file.`,
207 |         raw: `Failed to read content of existing file: ${params.file_path}`,
208 |         type: ToolErrorType.READ_CONTENT_FAILURE,
209 |       };
210 |     }
211 | 
212 |     const newContent = !error
213 |       ? applyReplacement(
214 |           currentContent,
215 |           finalOldString,
216 |           finalNewString,
217 |           isNewFile,
218 |         )
219 |       : (currentContent ?? '');
220 | 
221 |     if (!error && fileExists && currentContent === newContent) {
222 |       error = {
223 |         display:
224 |           'No changes to apply. The new content is identical to the current content.',
225 |         raw: `No changes to apply. The new content is identical to the current content in file: ${params.file_path}`,
226 |         type: ToolErrorType.EDIT_NO_CHANGE,
227 |       };
228 |     }
229 | 
230 |     return {
231 |       currentContent,
232 |       newContent,
233 |       occurrences,
234 |       error,
235 |       isNewFile,
236 |     };
237 |   }
238 | 
239 |   /**
240 |    * Handles the confirmation prompt for the Edit tool in the CLI.
241 |    * It needs to calculate the diff to show the user.
242 |    */
243 |   async shouldConfirmExecute(
244 |     abortSignal: AbortSignal,
245 |   ): Promise<ToolCallConfirmationDetails | false> {
246 |     if (this.config.getApprovalMode() === ApprovalMode.AUTO_EDIT) {
247 |       return false;
248 |     }
249 | 
250 |     let editData: CalculatedEdit;
251 |     try {
252 |       editData = await this.calculateEdit(this.params, abortSignal);
253 |     } catch (error) {
254 |       if (abortSignal.aborted) {
255 |         throw error;
256 |       }
257 |       const errorMsg = error instanceof Error ? error.message : String(error);
258 |       console.log(`Error preparing edit: ${errorMsg}`);
259 |       return false;
260 |     }
261 | 
262 |     if (editData.error) {
263 |       console.log(`Error: ${editData.error.display}`);
264 |       return false;
265 |     }
266 | 
267 |     const fileName = path.basename(this.params.file_path);
268 |     const fileDiff = Diff.createPatch(
269 |       fileName,
270 |       editData.currentContent ?? '',
271 |       editData.newContent,
272 |       'Current',
273 |       'Proposed',
274 |       DEFAULT_DIFF_OPTIONS,
275 |     );
276 |     const ideClient = await IdeClient.getInstance();
277 |     const ideConfirmation =
278 |       this.config.getIdeMode() && ideClient.isDiffingEnabled()
279 |         ? ideClient.openDiff(this.params.file_path, editData.newContent)
280 |         : undefined;
281 | 
282 |     const confirmationDetails: ToolEditConfirmationDetails = {
283 |       type: 'edit',
284 |       title: `Confirm Edit: ${shortenPath(makeRelative(this.params.file_path, this.config.getTargetDir()))}`,
285 |       fileName,
286 |       filePath: this.params.file_path,
287 |       fileDiff,
288 |       originalContent: editData.currentContent,
289 |       newContent: editData.newContent,
290 |       onConfirm: async (outcome: ToolConfirmationOutcome) => {
291 |         if (outcome === ToolConfirmationOutcome.ProceedAlways) {
292 |           this.config.setApprovalMode(ApprovalMode.AUTO_EDIT);
293 |         }
294 | 
295 |         if (ideConfirmation) {
296 |           const result = await ideConfirmation;
297 |           if (result.status === 'accepted' && result.content) {
298 |             // TODO(chrstn): See https://github.com/google-gemini/gemini-cli/pull/5618#discussion_r2255413084
299 |             // for info on a possible race condition where the file is modified on disk while being edited.
300 |             this.params.old_string = editData.currentContent ?? '';
301 |             this.params.new_string = result.content;
302 |           }
303 |         }
304 |       },
305 |       ideConfirmation,
306 |     };
307 |     return confirmationDetails;
308 |   }
309 | 
310 |   getDescription(): string {
311 |     const relativePath = makeRelative(
312 |       this.params.file_path,
313 |       this.config.getTargetDir(),
314 |     );
315 |     if (this.params.old_string === '') {
316 |       return `Create ${shortenPath(relativePath)}`;
317 |     }
318 | 
319 |     const oldStringSnippet =
320 |       this.params.old_string.split('\n')[0].substring(0, 30) +
321 |       (this.params.old_string.length > 30 ? '...' : '');
322 |     const newStringSnippet =
323 |       this.params.new_string.split('\n')[0].substring(0, 30) +
324 |       (this.params.new_string.length > 30 ? '...' : '');
325 | 
326 |     if (this.params.old_string === this.params.new_string) {
327 |       return `No file changes to ${shortenPath(relativePath)}`;
328 |     }
329 |     return `${shortenPath(relativePath)}: ${oldStringSnippet} => ${newStringSnippet}`;
330 |   }
331 | 
332 |   /**
333 |    * Executes the edit operation with the given parameters.
334 |    * @param params Parameters for the edit operation
335 |    * @returns Result of the edit operation
336 |    */
337 |   async execute(signal: AbortSignal): Promise<ToolResult> {
338 |     let editData: CalculatedEdit;
339 |     try {
340 |       editData = await this.calculateEdit(this.params, signal);
341 |     } catch (error) {
342 |       if (signal.aborted) {
343 |         throw error;
344 |       }
345 |       const errorMsg = error instanceof Error ? error.message : String(error);
346 |       return {
347 |         llmContent: `Error preparing edit: ${errorMsg}`,
348 |         returnDisplay: `Error preparing edit: ${errorMsg}`,
349 |         error: {
350 |           message: errorMsg,
351 |           type: ToolErrorType.EDIT_PREPARATION_FAILURE,
352 |         },
353 |       };
354 |     }
355 | 
356 |     if (editData.error) {
357 |       return {
358 |         llmContent: editData.error.raw,
359 |         returnDisplay: `Error: ${editData.error.display}`,
360 |         error: {
361 |           message: editData.error.raw,
362 |           type: editData.error.type,
363 |         },
364 |       };
365 |     }
366 | 
367 |     try {
368 |       this.ensureParentDirectoriesExist(this.params.file_path);
369 |       await this.config
370 |         .getFileSystemService()
371 |         .writeTextFile(this.params.file_path, editData.newContent);
372 | 
373 |       const fileName = path.basename(this.params.file_path);
374 |       const originallyProposedContent =
375 |         this.params.ai_proposed_content || editData.newContent;
376 |       const diffStat = getDiffStat(
377 |         fileName,
378 |         editData.currentContent ?? '',
379 |         originallyProposedContent,
380 |         editData.newContent,
381 |       );
382 | 
383 |       const fileDiff = Diff.createPatch(
384 |         fileName,
385 |         editData.currentContent ?? '', // Should not be null here if not isNewFile
386 |         editData.newContent,
387 |         'Current',
388 |         'Proposed',
389 |         DEFAULT_DIFF_OPTIONS,
390 |       );
391 |       const displayResult = {
392 |         fileDiff,
393 |         fileName,
394 |         originalContent: editData.currentContent,
395 |         newContent: editData.newContent,
396 |         diffStat,
397 |       };
398 | 
399 |       // Log file operation for telemetry (without diff_stat to avoid double-counting)
400 |       const mimetype = getSpecificMimeType(this.params.file_path);
401 |       const programmingLanguage = getLanguageFromFilePath(
402 |         this.params.file_path,
403 |       );
404 |       const extension = path.extname(this.params.file_path);
405 |       const operation = editData.isNewFile
406 |         ? FileOperation.CREATE
407 |         : FileOperation.UPDATE;
408 | 
409 |       logFileOperation(
410 |         this.config,
411 |         new FileOperationEvent(
412 |           EditTool.Name,
413 |           operation,
414 |           editData.newContent.split('\n').length,
415 |           mimetype,
416 |           extension,
417 |           programmingLanguage,
418 |         ),
419 |       );
420 | 
421 |       const llmSuccessMessageParts = [
422 |         editData.isNewFile
423 |           ? `Created new file: ${this.params.file_path} with provided content.`
424 |           : `Successfully modified file: ${this.params.file_path} (${editData.occurrences} replacements).`,
425 |       ];
426 |       if (this.params.modified_by_user) {
427 |         llmSuccessMessageParts.push(
428 |           `User modified the \`new_string\` content to be: ${this.params.new_string}.`,
429 |         );
430 |       }
431 | 
432 |       return {
433 |         llmContent: llmSuccessMessageParts.join(' '),
434 |         returnDisplay: displayResult,
435 |       };
436 |     } catch (error) {
437 |       const errorMsg = error instanceof Error ? error.message : String(error);
438 |       return {
439 |         llmContent: `Error executing edit: ${errorMsg}`,
440 |         returnDisplay: `Error writing file: ${errorMsg}`,
441 |         error: {
442 |           message: errorMsg,
443 |           type: ToolErrorType.FILE_WRITE_FAILURE,
444 |         },
445 |       };
446 |     }
447 |   }
448 | 
449 |   /**
450 |    * Creates parent directories if they don't exist
451 |    */
452 |   private ensureParentDirectoriesExist(filePath: string): void {
453 |     const dirName = path.dirname(filePath);
454 |     if (!fs.existsSync(dirName)) {
455 |       fs.mkdirSync(dirName, { recursive: true });
456 |     }
457 |   }
458 | }
459 | 
460 | /**
461 |  * Implementation of the Edit tool logic
462 |  */
463 | export class EditTool
464 |   extends BaseDeclarativeTool<EditToolParams, ToolResult>
465 |   implements ModifiableDeclarativeTool<EditToolParams>
466 | {
467 |   static readonly Name = 'replace';
468 |   constructor(private readonly config: Config) {
469 |     super(
470 |       EditTool.Name,
471 |       'Edit',
472 |       `Replaces text within a file. By default, replaces a single occurrence, but can replace multiple occurrences when \`expected_replacements\` is specified. This tool requires providing significant context around the change to ensure precise targeting. Always use the ${ReadFileTool.Name} tool to examine the file's current content before attempting a text replacement.
473 | 
474 |       The user has the ability to modify the \`new_string\` content. If modified, this will be stated in the response.
475 | 
476 | Expectation for required parameters:
477 | 1. \`file_path\` MUST be an absolute path; otherwise an error will be thrown.
478 | 2. \`old_string\` MUST be the exact literal text to replace (including all whitespace, indentation, newlines, and surrounding code etc.).
479 | 3. \`new_string\` MUST be the exact literal text to replace \`old_string\` with (also including all whitespace, indentation, newlines, and surrounding code etc.). Ensure the resulting code is correct and idiomatic.
480 | 4. NEVER escape \`old_string\` or \`new_string\`, that would break the exact literal text requirement.
481 | **Important:** If ANY of the above are not satisfied, the tool will fail. CRITICAL for \`old_string\`: Must uniquely identify the single instance to change. Include at least 3 lines of context BEFORE and AFTER the target text, matching whitespace and indentation precisely. If this string matches multiple locations, or does not match exactly, the tool will fail.
482 | **Multiple replacements:** Set \`expected_replacements\` to the number of occurrences you want to replace. The tool will replace ALL occurrences that match \`old_string\` exactly. Ensure the number of replacements matches your expectation.`,
483 |       Kind.Edit,
484 |       {
485 |         properties: {
486 |           file_path: {
487 |             description:
488 |               "The absolute path to the file to modify. Must start with '/'.",
489 |             type: 'string',
490 |           },
491 |           old_string: {
492 |             description:
493 |               'The exact literal text to replace, preferably unescaped. For single replacements (default), include at least 3 lines of context BEFORE and AFTER the target text, matching whitespace and indentation precisely. For multiple replacements, specify expected_replacements parameter. If this string is not the exact literal text (i.e. you escaped it) or does not match exactly, the tool will fail.',
494 |             type: 'string',
495 |           },
496 |           new_string: {
497 |             description:
498 |               'The exact literal text to replace `old_string` with, preferably unescaped. Provide the EXACT text. Ensure the resulting code is correct and idiomatic.',
499 |             type: 'string',
500 |           },
501 |           expected_replacements: {
502 |             type: 'number',
503 |             description:
504 |               'Number of replacements expected. Defaults to 1 if not specified. Use when you want to replace multiple occurrences.',
505 |             minimum: 1,
506 |           },
507 |         },
508 |         required: ['file_path', 'old_string', 'new_string'],
509 |         type: 'object',
510 |       },
511 |     );
512 |   }
513 | 
514 |   /**
515 |    * Validates the parameters for the Edit tool
516 |    * @param params Parameters to validate
517 |    * @returns Error message string or null if valid
518 |    */
519 |   protected override validateToolParamValues(
520 |     params: EditToolParams,
521 |   ): string | null {
522 |     if (!params.file_path) {
523 |       return "The 'file_path' parameter must be non-empty.";
524 |     }
525 | 
526 |     if (!path.isAbsolute(params.file_path)) {
527 |       return `File path must be absolute: ${params.file_path}`;
528 |     }
529 | 
530 |     const workspaceContext = this.config.getWorkspaceContext();
531 |     if (!workspaceContext.isPathWithinWorkspace(params.file_path)) {
532 |       const directories = workspaceContext.getDirectories();
533 |       return `File path must be within one of the workspace directories: ${directories.join(', ')}`;
[TRUNCATED]
```

src/tools/glob.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { GlobToolParams, GlobPath } from './glob.js';
8 | import { GlobTool, sortFileEntries } from './glob.js';
9 | import { partListUnionToString } from '../core/geminiRequest.js';
10 | import path from 'node:path';
11 | import fs from 'node:fs/promises';
12 | import os from 'node:os';
13 | import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
14 | import { FileDiscoveryService } from '../services/fileDiscoveryService.js';
15 | import type { Config } from '../config/config.js';
16 | import { createMockWorkspaceContext } from '../test-utils/mockWorkspaceContext.js';
17 | import { ToolErrorType } from './tool-error.js';
18 | import * as glob from 'glob';
19 | 
20 | vi.mock('glob', { spy: true });
21 | 
22 | describe('GlobTool', () => {
23 |   let tempRootDir: string; // This will be the rootDirectory for the GlobTool instance
24 |   let globTool: GlobTool;
25 |   const abortSignal = new AbortController().signal;
26 | 
27 |   // Mock config for testing
28 |   const mockConfig = {
29 |     getFileService: () => new FileDiscoveryService(tempRootDir),
30 |     getFileFilteringRespectGitIgnore: () => true,
31 |     getFileFilteringOptions: () => ({
32 |       respectGitIgnore: true,
33 |       respectGeminiIgnore: true,
34 |     }),
35 |     getTargetDir: () => tempRootDir,
36 |     getWorkspaceContext: () => createMockWorkspaceContext(tempRootDir),
37 |     getFileExclusions: () => ({
38 |       getGlobExcludes: () => [],
39 |     }),
40 |   } as unknown as Config;
41 | 
42 |   beforeEach(async () => {
43 |     // Create a unique root directory for each test run
44 |     tempRootDir = await fs.mkdtemp(path.join(os.tmpdir(), 'glob-tool-root-'));
45 |     await fs.writeFile(path.join(tempRootDir, '.git'), ''); // Fake git repo
46 |     globTool = new GlobTool(mockConfig);
47 | 
48 |     // Create some test files and directories within this root
49 |     // Top-level files
50 |     await fs.writeFile(path.join(tempRootDir, 'fileA.txt'), 'contentA');
51 |     await fs.writeFile(path.join(tempRootDir, 'FileB.TXT'), 'contentB'); // Different case for testing
52 | 
53 |     // Subdirectory and files within it
54 |     await fs.mkdir(path.join(tempRootDir, 'sub'));
55 |     await fs.writeFile(path.join(tempRootDir, 'sub', 'fileC.md'), 'contentC');
56 |     await fs.writeFile(path.join(tempRootDir, 'sub', 'FileD.MD'), 'contentD'); // Different case
57 | 
58 |     // Deeper subdirectory
59 |     await fs.mkdir(path.join(tempRootDir, 'sub', 'deep'));
60 |     await fs.writeFile(
61 |       path.join(tempRootDir, 'sub', 'deep', 'fileE.log'),
62 |       'contentE',
63 |     );
64 | 
65 |     // Files for mtime sorting test
66 |     await fs.writeFile(path.join(tempRootDir, 'older.sortme'), 'older_content');
67 |     // Ensure a noticeable difference in modification time
68 |     await new Promise((resolve) => setTimeout(resolve, 50));
69 |     await fs.writeFile(path.join(tempRootDir, 'newer.sortme'), 'newer_content');
70 |   });
71 | 
72 |   afterEach(async () => {
73 |     // Clean up the temporary root directory
74 |     await fs.rm(tempRootDir, { recursive: true, force: true });
75 |   });
76 | 
77 |   describe('execute', () => {
78 |     it('should find files matching a simple pattern in the root', async () => {
79 |       const params: GlobToolParams = { pattern: '*.txt' };
80 |       const invocation = globTool.build(params);
81 |       const result = await invocation.execute(abortSignal);
82 |       expect(result.llmContent).toContain('Found 2 file(s)');
83 |       expect(result.llmContent).toContain(path.join(tempRootDir, 'fileA.txt'));
84 |       expect(result.llmContent).toContain(path.join(tempRootDir, 'FileB.TXT'));
85 |       expect(result.returnDisplay).toBe('Found 2 matching file(s)');
86 |     });
87 | 
88 |     it('should find files case-sensitively when case_sensitive is true', async () => {
89 |       const params: GlobToolParams = { pattern: '*.txt', case_sensitive: true };
90 |       const invocation = globTool.build(params);
91 |       const result = await invocation.execute(abortSignal);
92 |       expect(result.llmContent).toContain('Found 1 file(s)');
93 |       expect(result.llmContent).toContain(path.join(tempRootDir, 'fileA.txt'));
94 |       expect(result.llmContent).not.toContain(
95 |         path.join(tempRootDir, 'FileB.TXT'),
96 |       );
97 |     });
98 | 
99 |     it('should find files case-insensitively by default (pattern: *.TXT)', async () => {
100 |       const params: GlobToolParams = { pattern: '*.TXT' };
101 |       const invocation = globTool.build(params);
102 |       const result = await invocation.execute(abortSignal);
103 |       expect(result.llmContent).toContain('Found 2 file(s)');
104 |       expect(result.llmContent).toContain(path.join(tempRootDir, 'fileA.txt'));
105 |       expect(result.llmContent).toContain(path.join(tempRootDir, 'FileB.TXT'));
106 |     });
107 | 
108 |     it('should find files case-insensitively when case_sensitive is false (pattern: *.TXT)', async () => {
109 |       const params: GlobToolParams = {
110 |         pattern: '*.TXT',
111 |         case_sensitive: false,
112 |       };
113 |       const invocation = globTool.build(params);
114 |       const result = await invocation.execute(abortSignal);
115 |       expect(result.llmContent).toContain('Found 2 file(s)');
116 |       expect(result.llmContent).toContain(path.join(tempRootDir, 'fileA.txt'));
117 |       expect(result.llmContent).toContain(path.join(tempRootDir, 'FileB.TXT'));
118 |     });
119 | 
120 |     it('should find files using a pattern that includes a subdirectory', async () => {
121 |       const params: GlobToolParams = { pattern: 'sub/*.md' };
122 |       const invocation = globTool.build(params);
123 |       const result = await invocation.execute(abortSignal);
124 |       expect(result.llmContent).toContain('Found 2 file(s)');
125 |       expect(result.llmContent).toContain(
126 |         path.join(tempRootDir, 'sub', 'fileC.md'),
127 |       );
128 |       expect(result.llmContent).toContain(
129 |         path.join(tempRootDir, 'sub', 'FileD.MD'),
130 |       );
131 |     });
132 | 
133 |     it('should find files in a specified relative path (relative to rootDir)', async () => {
134 |       const params: GlobToolParams = { pattern: '*.md', path: 'sub' };
135 |       const invocation = globTool.build(params);
136 |       const result = await invocation.execute(abortSignal);
137 |       expect(result.llmContent).toContain('Found 2 file(s)');
138 |       expect(result.llmContent).toContain(
139 |         path.join(tempRootDir, 'sub', 'fileC.md'),
140 |       );
141 |       expect(result.llmContent).toContain(
142 |         path.join(tempRootDir, 'sub', 'FileD.MD'),
143 |       );
144 |     });
145 | 
146 |     it('should find files using a deep globstar pattern (e.g., **/*.log)', async () => {
147 |       const params: GlobToolParams = { pattern: '**/*.log' };
148 |       const invocation = globTool.build(params);
149 |       const result = await invocation.execute(abortSignal);
150 |       expect(result.llmContent).toContain('Found 1 file(s)');
151 |       expect(result.llmContent).toContain(
152 |         path.join(tempRootDir, 'sub', 'deep', 'fileE.log'),
153 |       );
154 |     });
155 | 
156 |     it('should return "No files found" message when pattern matches nothing', async () => {
157 |       const params: GlobToolParams = { pattern: '*.nonexistent' };
158 |       const invocation = globTool.build(params);
159 |       const result = await invocation.execute(abortSignal);
160 |       expect(result.llmContent).toContain(
161 |         'No files found matching pattern "*.nonexistent"',
162 |       );
163 |       expect(result.returnDisplay).toBe('No files found');
164 |     });
165 | 
166 |     it('should find files with special characters in the name', async () => {
167 |       await fs.writeFile(path.join(tempRootDir, 'file[1].txt'), 'content');
168 |       const params: GlobToolParams = { pattern: 'file[1].txt' };
169 |       const invocation = globTool.build(params);
170 |       const result = await invocation.execute(abortSignal);
171 |       expect(result.llmContent).toContain('Found 1 file(s)');
172 |       expect(result.llmContent).toContain(
173 |         path.join(tempRootDir, 'file[1].txt'),
174 |       );
175 |     });
176 | 
177 |     it('should find files with special characters like [] and () in the path', async () => {
178 |       const filePath = path.join(
179 |         tempRootDir,
180 |         'src/app/[test]/(dashboard)/testing/components/code.tsx',
181 |       );
182 |       await fs.mkdir(path.dirname(filePath), { recursive: true });
183 |       await fs.writeFile(filePath, 'content');
184 | 
185 |       const params: GlobToolParams = {
186 |         pattern: 'src/app/[test]/(dashboard)/testing/components/code.tsx',
187 |       };
188 |       const invocation = globTool.build(params);
189 |       const result = await invocation.execute(abortSignal);
190 |       expect(result.llmContent).toContain('Found 1 file(s)');
191 |       expect(result.llmContent).toContain(filePath);
192 |     });
193 | 
194 |     it('should correctly sort files by modification time (newest first)', async () => {
195 |       const params: GlobToolParams = { pattern: '*.sortme' };
196 |       const invocation = globTool.build(params);
197 |       const result = await invocation.execute(abortSignal);
198 |       const llmContent = partListUnionToString(result.llmContent);
199 | 
200 |       expect(llmContent).toContain('Found 2 file(s)');
201 |       // Ensure llmContent is a string for TypeScript type checking
202 |       expect(typeof llmContent).toBe('string');
203 | 
204 |       const filesListed = llmContent
205 |         .trim()
206 |         .split(/\r?\n/)
207 |         .slice(1)
208 |         .map((line) => line.trim())
209 |         .filter(Boolean);
210 | 
211 |       expect(filesListed).toHaveLength(2);
212 |       expect(path.resolve(filesListed[0])).toBe(
213 |         path.resolve(tempRootDir, 'newer.sortme'),
214 |       );
215 |       expect(path.resolve(filesListed[1])).toBe(
216 |         path.resolve(tempRootDir, 'older.sortme'),
217 |       );
218 |     });
219 | 
220 |     it('should return a PATH_NOT_IN_WORKSPACE error if path is outside workspace', async () => {
221 |       // Bypassing validation to test execute method directly
222 |       vi.spyOn(globTool, 'validateToolParams').mockReturnValue(null);
223 |       const params: GlobToolParams = { pattern: '*.txt', path: '/etc' };
224 |       const invocation = globTool.build(params);
225 |       const result = await invocation.execute(abortSignal);
226 |       expect(result.error?.type).toBe(ToolErrorType.PATH_NOT_IN_WORKSPACE);
227 |       expect(result.returnDisplay).toBe('Path is not within workspace');
228 |     });
229 | 
230 |     it('should return a GLOB_EXECUTION_ERROR on glob failure', async () => {
231 |       vi.mocked(glob.glob).mockRejectedValue(new Error('Glob failed'));
232 |       const params: GlobToolParams = { pattern: '*.txt' };
233 |       const invocation = globTool.build(params);
234 |       const result = await invocation.execute(abortSignal);
235 |       expect(result.error?.type).toBe(ToolErrorType.GLOB_EXECUTION_ERROR);
236 |       expect(result.llmContent).toContain(
237 |         'Error during glob search operation: Glob failed',
238 |       );
239 |       // Reset glob.
240 |       vi.mocked(glob.glob).mockReset();
241 |     });
242 |   });
243 | 
244 |   describe('validateToolParams', () => {
245 |     it('should return null for valid parameters (pattern only)', () => {
246 |       const params: GlobToolParams = { pattern: '*.js' };
247 |       expect(globTool.validateToolParams(params)).toBeNull();
248 |     });
249 | 
250 |     it('should return null for valid parameters (pattern and path)', () => {
251 |       const params: GlobToolParams = { pattern: '*.js', path: 'sub' };
252 |       expect(globTool.validateToolParams(params)).toBeNull();
253 |     });
254 | 
255 |     it('should return null for valid parameters (pattern, path, and case_sensitive)', () => {
256 |       const params: GlobToolParams = {
257 |         pattern: '*.js',
258 |         path: 'sub',
259 |         case_sensitive: true,
260 |       };
261 |       expect(globTool.validateToolParams(params)).toBeNull();
262 |     });
263 | 
264 |     it('should return error if pattern is missing (schema validation)', () => {
265 |       // Need to correctly define this as an object without pattern
266 |       const params = { path: '.' };
267 |       // @ts-expect-error - We're intentionally creating invalid params for testing
268 |       expect(globTool.validateToolParams(params)).toBe(
269 |         `params must have required property 'pattern'`,
270 |       );
271 |     });
272 | 
273 |     it('should return error if pattern is an empty string', () => {
274 |       const params: GlobToolParams = { pattern: '' };
275 |       expect(globTool.validateToolParams(params)).toContain(
276 |         "The 'pattern' parameter cannot be empty.",
277 |       );
278 |     });
279 | 
280 |     it('should return error if pattern is only whitespace', () => {
281 |       const params: GlobToolParams = { pattern: '   ' };
282 |       expect(globTool.validateToolParams(params)).toContain(
283 |         "The 'pattern' parameter cannot be empty.",
284 |       );
285 |     });
286 | 
287 |     it('should return error if path is provided but is not a string (schema validation)', () => {
288 |       const params = {
289 |         pattern: '*.ts',
290 |         path: 123,
291 |       };
292 |       // @ts-expect-error - We're intentionally creating invalid params for testing
293 |       expect(globTool.validateToolParams(params)).toBe(
294 |         'params/path must be string',
295 |       );
296 |     });
297 | 
298 |     it('should return error if case_sensitive is provided but is not a boolean (schema validation)', () => {
299 |       const params = {
300 |         pattern: '*.ts',
301 |         case_sensitive: 'true',
302 |       };
303 |       // @ts-expect-error - We're intentionally creating invalid params for testing
304 |       expect(globTool.validateToolParams(params)).toBe(
305 |         'params/case_sensitive must be boolean',
306 |       );
307 |     });
308 | 
309 |     it("should return error if search path resolves outside the tool's root directory", () => {
310 |       // Create a globTool instance specifically for this test, with a deeper root
311 |       tempRootDir = path.join(tempRootDir, 'sub');
312 |       const specificGlobTool = new GlobTool(mockConfig);
313 |       // const params: GlobToolParams = { pattern: '*.txt', path: '..' }; // This line is unused and will be removed.
314 |       // This should be fine as tempRootDir is still within the original tempRootDir (the parent of deeperRootDir)
315 |       // Let's try to go further up.
316 |       const paramsOutside: GlobToolParams = {
317 |         pattern: '*.txt',
318 |         path: '../../../../../../../../../../tmp', // Definitely outside
319 |       };
320 |       expect(specificGlobTool.validateToolParams(paramsOutside)).toContain(
321 |         'resolves outside the allowed workspace directories',
322 |       );
323 |     });
324 | 
325 |     it('should return error if specified search path does not exist', async () => {
326 |       const params: GlobToolParams = {
327 |         pattern: '*.txt',
328 |         path: 'nonexistent_subdir',
329 |       };
330 |       expect(globTool.validateToolParams(params)).toContain(
331 |         'Search path does not exist',
332 |       );
333 |     });
334 | 
335 |     it('should return error if specified search path is a file, not a directory', async () => {
336 |       const params: GlobToolParams = { pattern: '*.txt', path: 'fileA.txt' };
337 |       expect(globTool.validateToolParams(params)).toContain(
338 |         'Search path is not a directory',
339 |       );
340 |     });
341 |   });
342 | 
343 |   describe('workspace boundary validation', () => {
344 |     it('should validate search paths are within workspace boundaries', () => {
345 |       const validPath = { pattern: '*.ts', path: 'sub' };
346 |       const invalidPath = { pattern: '*.ts', path: '../..' };
347 | 
348 |       expect(globTool.validateToolParams(validPath)).toBeNull();
349 |       expect(globTool.validateToolParams(invalidPath)).toContain(
350 |         'resolves outside the allowed workspace directories',
351 |       );
352 |     });
353 | 
354 |     it('should provide clear error messages when path is outside workspace', () => {
355 |       const invalidPath = { pattern: '*.ts', path: '/etc' };
356 |       const error = globTool.validateToolParams(invalidPath);
357 | 
358 |       expect(error).toContain(
359 |         'resolves outside the allowed workspace directories',
360 |       );
361 |       expect(error).toContain(tempRootDir);
362 |     });
363 | 
364 |     it('should work with paths in workspace subdirectories', async () => {
365 |       const params: GlobToolParams = { pattern: '*.md', path: 'sub' };
366 |       const invocation = globTool.build(params);
367 |       const result = await invocation.execute(abortSignal);
368 | 
369 |       expect(result.llmContent).toContain('Found 2 file(s)');
370 |       expect(result.llmContent).toContain('fileC.md');
371 |       expect(result.llmContent).toContain('FileD.MD');
372 |     });
373 |   });
374 | 
375 |   describe('ignore file handling', () => {
376 |     it('should respect .gitignore files by default', async () => {
377 |       await fs.writeFile(path.join(tempRootDir, '.gitignore'), '*.ignored.txt');
378 |       await fs.writeFile(
379 |         path.join(tempRootDir, 'a.ignored.txt'),
380 |         'ignored content',
381 |       );
382 |       await fs.writeFile(
383 |         path.join(tempRootDir, 'b.notignored.txt'),
384 |         'not ignored content',
385 |       );
386 | 
387 |       const params: GlobToolParams = { pattern: '*.txt' };
388 |       const invocation = globTool.build(params);
389 |       const result = await invocation.execute(abortSignal);
390 | 
391 |       expect(result.llmContent).toContain('Found 3 file(s)'); // fileA.txt, FileB.TXT, b.notignored.txt
392 |       expect(result.llmContent).not.toContain('a.ignored.txt');
393 |     });
394 | 
395 |     it('should respect .geminiignore files by default', async () => {
396 |       await fs.writeFile(
397 |         path.join(tempRootDir, '.geminiignore'),
398 |         '*.geminiignored.txt',
399 |       );
400 |       await fs.writeFile(
401 |         path.join(tempRootDir, 'a.geminiignored.txt'),
402 |         'ignored content',
403 |       );
404 |       await fs.writeFile(
405 |         path.join(tempRootDir, 'b.notignored.txt'),
406 |         'not ignored content',
407 |       );
408 | 
409 |       const params: GlobToolParams = { pattern: '*.txt' };
410 |       const invocation = globTool.build(params);
411 |       const result = await invocation.execute(abortSignal);
412 | 
413 |       expect(result.llmContent).toContain('Found 3 file(s)'); // fileA.txt, FileB.TXT, b.notignored.txt
414 |       expect(result.llmContent).not.toContain('a.geminiignored.txt');
415 |     });
416 | 
417 |     it('should not respect .gitignore when respect_git_ignore is false', async () => {
418 |       await fs.writeFile(path.join(tempRootDir, '.gitignore'), '*.ignored.txt');
419 |       await fs.writeFile(
420 |         path.join(tempRootDir, 'a.ignored.txt'),
421 |         'ignored content',
422 |       );
423 | 
424 |       const params: GlobToolParams = {
425 |         pattern: '*.txt',
426 |         respect_git_ignore: false,
427 |       };
428 |       const invocation = globTool.build(params);
429 |       const result = await invocation.execute(abortSignal);
430 | 
431 |       expect(result.llmContent).toContain('Found 3 file(s)'); // fileA.txt, FileB.TXT, a.ignored.txt
432 |       expect(result.llmContent).toContain('a.ignored.txt');
433 |     });
434 | 
435 |     it('should not respect .geminiignore when respect_gemini_ignore is false', async () => {
436 |       await fs.writeFile(
437 |         path.join(tempRootDir, '.geminiignore'),
438 |         '*.geminiignored.txt',
439 |       );
440 |       await fs.writeFile(
441 |         path.join(tempRootDir, 'a.geminiignored.txt'),
442 |         'ignored content',
443 |       );
444 | 
445 |       const params: GlobToolParams = {
446 |         pattern: '*.txt',
447 |         respect_gemini_ignore: false,
448 |       };
449 |       const invocation = globTool.build(params);
450 |       const result = await invocation.execute(abortSignal);
451 | 
452 |       expect(result.llmContent).toContain('Found 3 file(s)'); // fileA.txt, FileB.TXT, a.geminiignored.txt
453 |       expect(result.llmContent).toContain('a.geminiignored.txt');
454 |     });
455 |   });
456 | });
457 | 
458 | describe('sortFileEntries', () => {
459 |   const nowTimestamp = new Date('2024-01-15T12:00:00.000Z').getTime();
460 |   const oneDayInMs = 24 * 60 * 60 * 1000;
461 | 
462 |   const createFileEntry = (fullpath: string, mtimeDate: Date): GlobPath => ({
463 |     fullpath: () => fullpath,
464 |     mtimeMs: mtimeDate.getTime(),
465 |   });
466 | 
467 |   it('should sort a mix of recent and older files correctly', () => {
468 |     const recentTime1 = new Date(nowTimestamp - 1 * 60 * 60 * 1000); // 1 hour ago
469 |     const recentTime2 = new Date(nowTimestamp - 2 * 60 * 60 * 1000); // 2 hours ago
470 |     const olderTime1 = new Date(
471 |       nowTimestamp - (oneDayInMs + 1 * 60 * 60 * 1000),
472 |     ); // 25 hours ago
473 |     const olderTime2 = new Date(
474 |       nowTimestamp - (oneDayInMs + 2 * 60 * 60 * 1000),
475 |     ); // 26 hours ago
476 | 
477 |     const entries: GlobPath[] = [
478 |       createFileEntry('older_zebra.txt', olderTime2),
479 |       createFileEntry('recent_alpha.txt', recentTime1),
480 |       createFileEntry('older_apple.txt', olderTime1),
481 |       createFileEntry('recent_beta.txt', recentTime2),
482 |       createFileEntry('older_banana.txt', olderTime1), // Same mtime as apple
483 |     ];
484 | 
485 |     const sorted = sortFileEntries(entries, nowTimestamp, oneDayInMs);
486 |     const sortedPaths = sorted.map((e) => e.fullpath());
487 | 
488 |     expect(sortedPaths).toEqual([
489 |       'recent_alpha.txt', // Recent, newest
[TRUNCATED]
```

src/tools/glob.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import fs from 'node:fs';
8 | import path from 'node:path';
9 | import { glob, escape } from 'glob';
10 | import type { ToolInvocation, ToolResult } from './tools.js';
11 | import { BaseDeclarativeTool, BaseToolInvocation, Kind } from './tools.js';
12 | import { shortenPath, makeRelative } from '../utils/paths.js';
13 | import { type Config } from '../config/config.js';
14 | import { DEFAULT_FILE_FILTERING_OPTIONS } from '../config/constants.js';
15 | import { ToolErrorType } from './tool-error.js';
16 | import { GLOB_TOOL_NAME } from './tool-names.js';
17 | 
18 | // Subset of 'Path' interface provided by 'glob' that we can implement for testing
19 | export interface GlobPath {
20 |   fullpath(): string;
21 |   mtimeMs?: number;
22 | }
23 | 
24 | /**
25 |  * Sorts file entries based on recency and then alphabetically.
26 |  * Recent files (modified within recencyThresholdMs) are listed first, newest to oldest.
27 |  * Older files are listed after recent ones, sorted alphabetically by path.
28 |  */
29 | export function sortFileEntries(
30 |   entries: GlobPath[],
31 |   nowTimestamp: number,
32 |   recencyThresholdMs: number,
33 | ): GlobPath[] {
34 |   const sortedEntries = [...entries];
35 |   sortedEntries.sort((a, b) => {
36 |     const mtimeA = a.mtimeMs ?? 0;
37 |     const mtimeB = b.mtimeMs ?? 0;
38 |     const aIsRecent = nowTimestamp - mtimeA < recencyThresholdMs;
39 |     const bIsRecent = nowTimestamp - mtimeB < recencyThresholdMs;
40 | 
41 |     if (aIsRecent && bIsRecent) {
42 |       return mtimeB - mtimeA;
43 |     } else if (aIsRecent) {
44 |       return -1;
45 |     } else if (bIsRecent) {
46 |       return 1;
47 |     } else {
48 |       return a.fullpath().localeCompare(b.fullpath());
49 |     }
50 |   });
51 |   return sortedEntries;
52 | }
53 | 
54 | /**
55 |  * Parameters for the GlobTool
56 |  */
57 | export interface GlobToolParams {
58 |   /**
59 |    * The glob pattern to match files against
60 |    */
61 |   pattern: string;
62 | 
63 |   /**
64 |    * The directory to search in (optional, defaults to current directory)
65 |    */
66 |   path?: string;
67 | 
68 |   /**
69 |    * Whether the search should be case-sensitive (optional, defaults to false)
70 |    */
71 |   case_sensitive?: boolean;
72 | 
73 |   /**
74 |    * Whether to respect .gitignore patterns (optional, defaults to true)
75 |    */
76 |   respect_git_ignore?: boolean;
77 | 
78 |   /**
79 |    * Whether to respect .geminiignore patterns (optional, defaults to true)
80 |    */
81 |   respect_gemini_ignore?: boolean;
82 | }
83 | 
84 | class GlobToolInvocation extends BaseToolInvocation<
85 |   GlobToolParams,
86 |   ToolResult
87 | > {
88 |   constructor(
89 |     private config: Config,
90 |     params: GlobToolParams,
91 |   ) {
92 |     super(params);
93 |   }
94 | 
95 |   getDescription(): string {
96 |     let description = `'${this.params.pattern}'`;
97 |     if (this.params.path) {
98 |       const searchDir = path.resolve(
99 |         this.config.getTargetDir(),
100 |         this.params.path || '.',
101 |       );
102 |       const relativePath = makeRelative(searchDir, this.config.getTargetDir());
103 |       description += ` within ${shortenPath(relativePath)}`;
104 |     }
105 |     return description;
106 |   }
107 | 
108 |   async execute(signal: AbortSignal): Promise<ToolResult> {
109 |     try {
110 |       const workspaceContext = this.config.getWorkspaceContext();
111 |       const workspaceDirectories = workspaceContext.getDirectories();
112 | 
113 |       // If a specific path is provided, resolve it and check if it's within workspace
114 |       let searchDirectories: readonly string[];
115 |       if (this.params.path) {
116 |         const searchDirAbsolute = path.resolve(
117 |           this.config.getTargetDir(),
118 |           this.params.path,
119 |         );
120 |         if (!workspaceContext.isPathWithinWorkspace(searchDirAbsolute)) {
121 |           const rawError = `Error: Path "${this.params.path}" is not within any workspace directory`;
122 |           return {
123 |             llmContent: rawError,
124 |             returnDisplay: `Path is not within workspace`,
125 |             error: {
126 |               message: rawError,
127 |               type: ToolErrorType.PATH_NOT_IN_WORKSPACE,
128 |             },
129 |           };
130 |         }
131 |         searchDirectories = [searchDirAbsolute];
132 |       } else {
133 |         // Search across all workspace directories
134 |         searchDirectories = workspaceDirectories;
135 |       }
136 | 
137 |       // Get centralized file discovery service
138 |       const fileDiscovery = this.config.getFileService();
139 | 
140 |       // Collect entries from all search directories
141 |       const allEntries: GlobPath[] = [];
142 |       for (const searchDir of searchDirectories) {
143 |         let pattern = this.params.pattern;
144 |         const fullPath = path.join(searchDir, pattern);
145 |         if (fs.existsSync(fullPath)) {
146 |           pattern = escape(pattern);
147 |         }
148 | 
149 |         const entries = (await glob(pattern, {
150 |           cwd: searchDir,
151 |           withFileTypes: true,
152 |           nodir: true,
153 |           stat: true,
154 |           nocase: !this.params.case_sensitive,
155 |           dot: true,
156 |           ignore: this.config.getFileExclusions().getGlobExcludes(),
157 |           follow: false,
158 |           signal,
159 |         })) as GlobPath[];
160 | 
161 |         allEntries.push(...entries);
162 |       }
163 | 
164 |       const relativePaths = allEntries.map((p) =>
165 |         path.relative(this.config.getTargetDir(), p.fullpath()),
166 |       );
167 | 
168 |       const { filteredPaths, gitIgnoredCount, geminiIgnoredCount } =
169 |         fileDiscovery.filterFilesWithReport(relativePaths, {
170 |           respectGitIgnore:
171 |             this.params?.respect_git_ignore ??
172 |             this.config.getFileFilteringOptions().respectGitIgnore ??
173 |             DEFAULT_FILE_FILTERING_OPTIONS.respectGitIgnore,
174 |           respectGeminiIgnore:
175 |             this.params?.respect_gemini_ignore ??
176 |             this.config.getFileFilteringOptions().respectGeminiIgnore ??
177 |             DEFAULT_FILE_FILTERING_OPTIONS.respectGeminiIgnore,
178 |         });
179 | 
180 |       const filteredAbsolutePaths = new Set(
181 |         filteredPaths.map((p) => path.resolve(this.config.getTargetDir(), p)),
182 |       );
183 | 
184 |       const filteredEntries = allEntries.filter((entry) =>
185 |         filteredAbsolutePaths.has(entry.fullpath()),
186 |       );
187 | 
188 |       if (!filteredEntries || filteredEntries.length === 0) {
189 |         let message = `No files found matching pattern "${this.params.pattern}"`;
190 |         if (searchDirectories.length === 1) {
191 |           message += ` within ${searchDirectories[0]}`;
192 |         } else {
193 |           message += ` within ${searchDirectories.length} workspace directories`;
194 |         }
195 |         if (gitIgnoredCount > 0) {
196 |           message += ` (${gitIgnoredCount} files were git-ignored)`;
197 |         }
198 |         if (geminiIgnoredCount > 0) {
199 |           message += ` (${geminiIgnoredCount} files were gemini-ignored)`;
200 |         }
201 |         return {
202 |           llmContent: message,
203 |           returnDisplay: `No files found`,
204 |         };
205 |       }
206 | 
207 |       // Set filtering such that we first show the most recent files
208 |       const oneDayInMs = 24 * 60 * 60 * 1000;
209 |       const nowTimestamp = new Date().getTime();
210 | 
211 |       // Sort the filtered entries using the new helper function
212 |       const sortedEntries = sortFileEntries(
213 |         filteredEntries,
214 |         nowTimestamp,
215 |         oneDayInMs,
216 |       );
217 | 
218 |       const sortedAbsolutePaths = sortedEntries.map((entry) =>
219 |         entry.fullpath(),
220 |       );
221 |       const fileListDescription = sortedAbsolutePaths.join('\n');
222 |       const fileCount = sortedAbsolutePaths.length;
223 | 
224 |       let resultMessage = `Found ${fileCount} file(s) matching "${this.params.pattern}"`;
225 |       if (searchDirectories.length === 1) {
226 |         resultMessage += ` within ${searchDirectories[0]}`;
227 |       } else {
228 |         resultMessage += ` across ${searchDirectories.length} workspace directories`;
229 |       }
230 |       if (gitIgnoredCount > 0) {
231 |         resultMessage += ` (${gitIgnoredCount} additional files were git-ignored)`;
232 |       }
233 |       if (geminiIgnoredCount > 0) {
234 |         resultMessage += ` (${geminiIgnoredCount} additional files were gemini-ignored)`;
235 |       }
236 |       resultMessage += `, sorted by modification time (newest first):\n${fileListDescription}`;
237 | 
238 |       return {
239 |         llmContent: resultMessage,
240 |         returnDisplay: `Found ${fileCount} matching file(s)`,
241 |       };
242 |     } catch (error) {
243 |       const errorMessage =
244 |         error instanceof Error ? error.message : String(error);
245 |       console.error(`GlobLogic execute Error: ${errorMessage}`, error);
246 |       const rawError = `Error during glob search operation: ${errorMessage}`;
247 |       return {
248 |         llmContent: rawError,
249 |         returnDisplay: `Error: An unexpected error occurred.`,
250 |         error: {
251 |           message: rawError,
252 |           type: ToolErrorType.GLOB_EXECUTION_ERROR,
253 |         },
254 |       };
255 |     }
256 |   }
257 | }
258 | 
259 | /**
260 |  * Implementation of the Glob tool logic
261 |  */
262 | export class GlobTool extends BaseDeclarativeTool<GlobToolParams, ToolResult> {
263 |   static readonly Name = GLOB_TOOL_NAME;
264 | 
265 |   constructor(private config: Config) {
266 |     super(
267 |       GlobTool.Name,
268 |       'FindFiles',
269 |       'Efficiently finds files matching specific glob patterns (e.g., `src/**/*.ts`, `**/*.md`), returning absolute paths sorted by modification time (newest first). Ideal for quickly locating files based on their name or path structure, especially in large codebases.',
270 |       Kind.Search,
271 |       {
272 |         properties: {
273 |           pattern: {
274 |             description:
275 |               "The glob pattern to match against (e.g., '**/*.py', 'docs/*.md').",
276 |             type: 'string',
277 |           },
278 |           path: {
279 |             description:
280 |               'Optional: The absolute path to the directory to search within. If omitted, searches the root directory.',
281 |             type: 'string',
282 |           },
283 |           case_sensitive: {
284 |             description:
285 |               'Optional: Whether the search should be case-sensitive. Defaults to false.',
286 |             type: 'boolean',
287 |           },
288 |           respect_git_ignore: {
289 |             description:
290 |               'Optional: Whether to respect .gitignore patterns when finding files. Only available in git repositories. Defaults to true.',
291 |             type: 'boolean',
292 |           },
293 |           respect_gemini_ignore: {
294 |             description:
295 |               'Optional: Whether to respect .geminiignore patterns when finding files. Defaults to true.',
296 |             type: 'boolean',
297 |           },
298 |         },
299 |         required: ['pattern'],
300 |         type: 'object',
301 |       },
302 |     );
303 |   }
304 | 
305 |   /**
306 |    * Validates the parameters for the tool.
307 |    */
308 |   protected override validateToolParamValues(
309 |     params: GlobToolParams,
310 |   ): string | null {
311 |     const searchDirAbsolute = path.resolve(
312 |       this.config.getTargetDir(),
313 |       params.path || '.',
314 |     );
315 | 
316 |     const workspaceContext = this.config.getWorkspaceContext();
317 |     if (!workspaceContext.isPathWithinWorkspace(searchDirAbsolute)) {
318 |       const directories = workspaceContext.getDirectories();
319 |       return `Search path ("${searchDirAbsolute}") resolves outside the allowed workspace directories: ${directories.join(', ')}`;
320 |     }
321 | 
322 |     const targetDir = searchDirAbsolute || this.config.getTargetDir();
323 |     try {
324 |       if (!fs.existsSync(targetDir)) {
325 |         return `Search path does not exist ${targetDir}`;
326 |       }
327 |       if (!fs.statSync(targetDir).isDirectory()) {
328 |         return `Search path is not a directory: ${targetDir}`;
329 |       }
330 |     } catch (e: unknown) {
331 |       return `Error accessing search path: ${e}`;
332 |     }
333 | 
334 |     if (
335 |       !params.pattern ||
336 |       typeof params.pattern !== 'string' ||
337 |       params.pattern.trim() === ''
338 |     ) {
339 |       return "The 'pattern' parameter cannot be empty.";
340 |     }
341 | 
342 |     return null;
343 |   }
344 | 
345 |   protected createInvocation(
346 |     params: GlobToolParams,
347 |   ): ToolInvocation<GlobToolParams, ToolResult> {
348 |     return new GlobToolInvocation(this.config, params);
349 |   }
350 | }
```

src/tools/grep.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
8 | import type { GrepToolParams } from './grep.js';
9 | import { GrepTool } from './grep.js';
10 | import path from 'node:path';
11 | import fs from 'node:fs/promises';
12 | import os from 'node:os';
13 | import type { Config } from '../config/config.js';
14 | import { createMockWorkspaceContext } from '../test-utils/mockWorkspaceContext.js';
15 | import { ToolErrorType } from './tool-error.js';
16 | import * as glob from 'glob';
17 | 
18 | vi.mock('glob', { spy: true });
19 | 
20 | // Mock the child_process module to control grep/git grep behavior
21 | vi.mock('child_process', () => ({
22 |   spawn: vi.fn(() => ({
23 |     on: (event: string, cb: (...args: unknown[]) => void) => {
24 |       if (event === 'error' || event === 'close') {
25 |         // Simulate command not found or error for git grep and system grep
26 |         // to force it to fall back to JS implementation.
27 |         setTimeout(() => cb(1), 0); // cb(1) for error/close
28 |       }
29 |     },
30 |     stdout: { on: vi.fn() },
31 |     stderr: { on: vi.fn() },
32 |   })),
33 | }));
34 | 
35 | describe('GrepTool', () => {
36 |   let tempRootDir: string;
37 |   let grepTool: GrepTool;
38 |   const abortSignal = new AbortController().signal;
39 | 
40 |   const mockConfig = {
41 |     getTargetDir: () => tempRootDir,
42 |     getWorkspaceContext: () => createMockWorkspaceContext(tempRootDir),
43 |     getFileExclusions: () => ({
44 |       getGlobExcludes: () => [],
45 |     }),
46 |   } as unknown as Config;
47 | 
48 |   beforeEach(async () => {
49 |     tempRootDir = await fs.mkdtemp(path.join(os.tmpdir(), 'grep-tool-root-'));
50 |     grepTool = new GrepTool(mockConfig);
51 | 
52 |     // Create some test files and directories
53 |     await fs.writeFile(
54 |       path.join(tempRootDir, 'fileA.txt'),
55 |       'hello world\nsecond line with world',
56 |     );
57 |     await fs.writeFile(
58 |       path.join(tempRootDir, 'fileB.js'),
59 |       'const foo = "bar";\nfunction baz() { return "hello"; }',
60 |     );
61 |     await fs.mkdir(path.join(tempRootDir, 'sub'));
62 |     await fs.writeFile(
63 |       path.join(tempRootDir, 'sub', 'fileC.txt'),
64 |       'another world in sub dir',
65 |     );
66 |     await fs.writeFile(
67 |       path.join(tempRootDir, 'sub', 'fileD.md'),
68 |       '# Markdown file\nThis is a test.',
69 |     );
70 |   });
71 | 
72 |   afterEach(async () => {
73 |     await fs.rm(tempRootDir, { recursive: true, force: true });
74 |   });
75 | 
76 |   describe('validateToolParams', () => {
77 |     it('should return null for valid params (pattern only)', () => {
78 |       const params: GrepToolParams = { pattern: 'hello' };
79 |       expect(grepTool.validateToolParams(params)).toBeNull();
80 |     });
81 | 
82 |     it('should return null for valid params (pattern and path)', () => {
83 |       const params: GrepToolParams = { pattern: 'hello', path: '.' };
84 |       expect(grepTool.validateToolParams(params)).toBeNull();
85 |     });
86 | 
87 |     it('should return null for valid params (pattern, path, and include)', () => {
88 |       const params: GrepToolParams = {
89 |         pattern: 'hello',
90 |         path: '.',
91 |         include: '*.txt',
92 |       };
93 |       expect(grepTool.validateToolParams(params)).toBeNull();
94 |     });
95 | 
96 |     it('should return error if pattern is missing', () => {
97 |       const params = { path: '.' } as unknown as GrepToolParams;
98 |       expect(grepTool.validateToolParams(params)).toBe(
99 |         `params must have required property 'pattern'`,
100 |       );
101 |     });
102 | 
103 |     it('should return error for invalid regex pattern', () => {
104 |       const params: GrepToolParams = { pattern: '[[' };
105 |       expect(grepTool.validateToolParams(params)).toContain(
106 |         'Invalid regular expression pattern',
107 |       );
108 |     });
109 | 
110 |     it('should return error if path does not exist', () => {
111 |       const params: GrepToolParams = { pattern: 'hello', path: 'nonexistent' };
112 |       // Check for the core error message, as the full path might vary
113 |       expect(grepTool.validateToolParams(params)).toContain(
114 |         'Failed to access path stats for',
115 |       );
116 |       expect(grepTool.validateToolParams(params)).toContain('nonexistent');
117 |     });
118 | 
119 |     it('should return error if path is a file, not a directory', async () => {
120 |       const filePath = path.join(tempRootDir, 'fileA.txt');
121 |       const params: GrepToolParams = { pattern: 'hello', path: filePath };
122 |       expect(grepTool.validateToolParams(params)).toContain(
123 |         `Path is not a directory: ${filePath}`,
124 |       );
125 |     });
126 |   });
127 | 
128 |   describe('execute', () => {
129 |     it('should find matches for a simple pattern in all files', async () => {
130 |       const params: GrepToolParams = { pattern: 'world' };
131 |       const invocation = grepTool.build(params);
132 |       const result = await invocation.execute(abortSignal);
133 |       expect(result.llmContent).toContain(
134 |         'Found 3 matches for pattern "world" in the workspace directory',
135 |       );
136 |       expect(result.llmContent).toContain('File: fileA.txt');
137 |       expect(result.llmContent).toContain('L1: hello world');
138 |       expect(result.llmContent).toContain('L2: second line with world');
139 |       expect(result.llmContent).toContain(
140 |         `File: ${path.join('sub', 'fileC.txt')}`,
141 |       );
142 |       expect(result.llmContent).toContain('L1: another world in sub dir');
143 |       expect(result.returnDisplay).toBe('Found 3 matches');
144 |     });
145 | 
146 |     it('should find matches in a specific path', async () => {
147 |       const params: GrepToolParams = { pattern: 'world', path: 'sub' };
148 |       const invocation = grepTool.build(params);
149 |       const result = await invocation.execute(abortSignal);
150 |       expect(result.llmContent).toContain(
151 |         'Found 1 match for pattern "world" in path "sub"',
152 |       );
153 |       expect(result.llmContent).toContain('File: fileC.txt'); // Path relative to 'sub'
154 |       expect(result.llmContent).toContain('L1: another world in sub dir');
155 |       expect(result.returnDisplay).toBe('Found 1 match');
156 |     });
157 | 
158 |     it('should find matches with an include glob', async () => {
159 |       const params: GrepToolParams = { pattern: 'hello', include: '*.js' };
160 |       const invocation = grepTool.build(params);
161 |       const result = await invocation.execute(abortSignal);
162 |       expect(result.llmContent).toContain(
163 |         'Found 1 match for pattern "hello" in the workspace directory (filter: "*.js"):',
164 |       );
165 |       expect(result.llmContent).toContain('File: fileB.js');
166 |       expect(result.llmContent).toContain(
167 |         'L2: function baz() { return "hello"; }',
168 |       );
169 |       expect(result.returnDisplay).toBe('Found 1 match');
170 |     });
171 | 
172 |     it('should find matches with an include glob and path', async () => {
173 |       await fs.writeFile(
174 |         path.join(tempRootDir, 'sub', 'another.js'),
175 |         'const greeting = "hello";',
176 |       );
177 |       const params: GrepToolParams = {
178 |         pattern: 'hello',
179 |         path: 'sub',
180 |         include: '*.js',
181 |       };
182 |       const invocation = grepTool.build(params);
183 |       const result = await invocation.execute(abortSignal);
184 |       expect(result.llmContent).toContain(
185 |         'Found 1 match for pattern "hello" in path "sub" (filter: "*.js")',
186 |       );
187 |       expect(result.llmContent).toContain('File: another.js');
188 |       expect(result.llmContent).toContain('L1: const greeting = "hello";');
189 |       expect(result.returnDisplay).toBe('Found 1 match');
190 |     });
191 | 
192 |     it('should return "No matches found" when pattern does not exist', async () => {
193 |       const params: GrepToolParams = { pattern: 'nonexistentpattern' };
194 |       const invocation = grepTool.build(params);
195 |       const result = await invocation.execute(abortSignal);
196 |       expect(result.llmContent).toContain(
197 |         'No matches found for pattern "nonexistentpattern" in the workspace directory.',
198 |       );
199 |       expect(result.returnDisplay).toBe('No matches found');
200 |     });
201 | 
202 |     it('should handle regex special characters correctly', async () => {
203 |       const params: GrepToolParams = { pattern: 'foo.*bar' }; // Matches 'const foo = "bar";'
204 |       const invocation = grepTool.build(params);
205 |       const result = await invocation.execute(abortSignal);
206 |       expect(result.llmContent).toContain(
207 |         'Found 1 match for pattern "foo.*bar" in the workspace directory:',
208 |       );
209 |       expect(result.llmContent).toContain('File: fileB.js');
210 |       expect(result.llmContent).toContain('L1: const foo = "bar";');
211 |     });
212 | 
213 |     it('should be case-insensitive by default (JS fallback)', async () => {
214 |       const params: GrepToolParams = { pattern: 'HELLO' };
215 |       const invocation = grepTool.build(params);
216 |       const result = await invocation.execute(abortSignal);
217 |       expect(result.llmContent).toContain(
218 |         'Found 2 matches for pattern "HELLO" in the workspace directory:',
219 |       );
220 |       expect(result.llmContent).toContain('File: fileA.txt');
221 |       expect(result.llmContent).toContain('L1: hello world');
222 |       expect(result.llmContent).toContain('File: fileB.js');
223 |       expect(result.llmContent).toContain(
224 |         'L2: function baz() { return "hello"; }',
225 |       );
226 |     });
227 | 
228 |     it('should throw an error if params are invalid', async () => {
229 |       const params = { path: '.' } as unknown as GrepToolParams; // Invalid: pattern missing
230 |       expect(() => grepTool.build(params)).toThrow(
231 |         /params must have required property 'pattern'/,
232 |       );
233 |     });
234 | 
235 |     it('should return a GREP_EXECUTION_ERROR on failure', async () => {
236 |       vi.mocked(glob.globStream).mockRejectedValue(new Error('Glob failed'));
237 |       const params: GrepToolParams = { pattern: 'hello' };
238 |       const invocation = grepTool.build(params);
239 |       const result = await invocation.execute(abortSignal);
240 |       expect(result.error?.type).toBe(ToolErrorType.GREP_EXECUTION_ERROR);
241 |       vi.mocked(glob.globStream).mockReset();
242 |     });
243 |   });
244 | 
245 |   describe('multi-directory workspace', () => {
246 |     it('should search across all workspace directories when no path is specified', async () => {
247 |       // Create additional directory with test files
248 |       const secondDir = await fs.mkdtemp(
249 |         path.join(os.tmpdir(), 'grep-tool-second-'),
250 |       );
251 |       await fs.writeFile(
252 |         path.join(secondDir, 'other.txt'),
253 |         'hello from second directory\nworld in second',
254 |       );
255 |       await fs.writeFile(
256 |         path.join(secondDir, 'another.js'),
257 |         'function world() { return "test"; }',
258 |       );
259 | 
260 |       // Create a mock config with multiple directories
261 |       const multiDirConfig = {
262 |         getTargetDir: () => tempRootDir,
263 |         getWorkspaceContext: () =>
264 |           createMockWorkspaceContext(tempRootDir, [secondDir]),
265 |         getFileExclusions: () => ({
266 |           getGlobExcludes: () => [],
267 |         }),
268 |       } as unknown as Config;
269 | 
270 |       const multiDirGrepTool = new GrepTool(multiDirConfig);
271 |       const params: GrepToolParams = { pattern: 'world' };
272 |       const invocation = multiDirGrepTool.build(params);
273 |       const result = await invocation.execute(abortSignal);
274 | 
275 |       // Should find matches in both directories
276 |       expect(result.llmContent).toContain(
277 |         'Found 5 matches for pattern "world"',
278 |       );
279 | 
280 |       // Matches from first directory
281 |       expect(result.llmContent).toContain('fileA.txt');
282 |       expect(result.llmContent).toContain('L1: hello world');
283 |       expect(result.llmContent).toContain('L2: second line with world');
284 |       expect(result.llmContent).toContain('fileC.txt');
285 |       expect(result.llmContent).toContain('L1: another world in sub dir');
286 | 
287 |       // Matches from second directory (with directory name prefix)
288 |       const secondDirName = path.basename(secondDir);
289 |       expect(result.llmContent).toContain(
290 |         `File: ${path.join(secondDirName, 'other.txt')}`,
291 |       );
292 |       expect(result.llmContent).toContain('L2: world in second');
293 |       expect(result.llmContent).toContain(
294 |         `File: ${path.join(secondDirName, 'another.js')}`,
295 |       );
296 |       expect(result.llmContent).toContain('L1: function world()');
297 | 
298 |       // Clean up
299 |       await fs.rm(secondDir, { recursive: true, force: true });
300 |     });
301 | 
302 |     it('should search only specified path within workspace directories', async () => {
303 |       // Create additional directory
304 |       const secondDir = await fs.mkdtemp(
305 |         path.join(os.tmpdir(), 'grep-tool-second-'),
306 |       );
307 |       await fs.mkdir(path.join(secondDir, 'sub'));
308 |       await fs.writeFile(
309 |         path.join(secondDir, 'sub', 'test.txt'),
310 |         'hello from second sub directory',
311 |       );
312 | 
313 |       // Create a mock config with multiple directories
314 |       const multiDirConfig = {
315 |         getTargetDir: () => tempRootDir,
316 |         getWorkspaceContext: () =>
317 |           createMockWorkspaceContext(tempRootDir, [secondDir]),
318 |         getFileExclusions: () => ({
319 |           getGlobExcludes: () => [],
320 |         }),
321 |       } as unknown as Config;
322 | 
323 |       const multiDirGrepTool = new GrepTool(multiDirConfig);
324 | 
325 |       // Search only in the 'sub' directory of the first workspace
326 |       const params: GrepToolParams = { pattern: 'world', path: 'sub' };
327 |       const invocation = multiDirGrepTool.build(params);
328 |       const result = await invocation.execute(abortSignal);
329 | 
330 |       // Should only find matches in the specified sub directory
331 |       expect(result.llmContent).toContain(
332 |         'Found 1 match for pattern "world" in path "sub"',
333 |       );
334 |       expect(result.llmContent).toContain('File: fileC.txt');
335 |       expect(result.llmContent).toContain('L1: another world in sub dir');
336 | 
337 |       // Should not contain matches from second directory
338 |       expect(result.llmContent).not.toContain('test.txt');
339 | 
340 |       // Clean up
341 |       await fs.rm(secondDir, { recursive: true, force: true });
342 |     });
343 |   });
344 | 
345 |   describe('getDescription', () => {
346 |     it('should generate correct description with pattern only', () => {
347 |       const params: GrepToolParams = { pattern: 'testPattern' };
348 |       const invocation = grepTool.build(params);
349 |       expect(invocation.getDescription()).toBe("'testPattern'");
350 |     });
351 | 
352 |     it('should generate correct description with pattern and include', () => {
353 |       const params: GrepToolParams = {
354 |         pattern: 'testPattern',
355 |         include: '*.ts',
356 |       };
357 |       const invocation = grepTool.build(params);
358 |       expect(invocation.getDescription()).toBe("'testPattern' in *.ts");
359 |     });
360 | 
361 |     it('should generate correct description with pattern and path', async () => {
362 |       const dirPath = path.join(tempRootDir, 'src', 'app');
363 |       await fs.mkdir(dirPath, { recursive: true });
364 |       const params: GrepToolParams = {
365 |         pattern: 'testPattern',
366 |         path: path.join('src', 'app'),
367 |       };
368 |       const invocation = grepTool.build(params);
369 |       // The path will be relative to the tempRootDir, so we check for containment.
370 |       expect(invocation.getDescription()).toContain("'testPattern' within");
371 |       expect(invocation.getDescription()).toContain(path.join('src', 'app'));
372 |     });
373 | 
374 |     it('should indicate searching across all workspace directories when no path specified', () => {
375 |       // Create a mock config with multiple directories
376 |       const multiDirConfig = {
377 |         getTargetDir: () => tempRootDir,
378 |         getWorkspaceContext: () =>
379 |           createMockWorkspaceContext(tempRootDir, ['/another/dir']),
380 |         getFileExclusions: () => ({
381 |           getGlobExcludes: () => [],
382 |         }),
383 |       } as unknown as Config;
384 | 
385 |       const multiDirGrepTool = new GrepTool(multiDirConfig);
386 |       const params: GrepToolParams = { pattern: 'testPattern' };
387 |       const invocation = multiDirGrepTool.build(params);
388 |       expect(invocation.getDescription()).toBe(
389 |         "'testPattern' across all workspace directories",
390 |       );
391 |     });
392 | 
393 |     it('should generate correct description with pattern, include, and path', async () => {
394 |       const dirPath = path.join(tempRootDir, 'src', 'app');
395 |       await fs.mkdir(dirPath, { recursive: true });
396 |       const params: GrepToolParams = {
397 |         pattern: 'testPattern',
398 |         include: '*.ts',
399 |         path: path.join('src', 'app'),
400 |       };
401 |       const invocation = grepTool.build(params);
402 |       expect(invocation.getDescription()).toContain(
403 |         "'testPattern' in *.ts within",
404 |       );
405 |       expect(invocation.getDescription()).toContain(path.join('src', 'app'));
406 |     });
407 | 
408 |     it('should use ./ for root path in description', () => {
409 |       const params: GrepToolParams = { pattern: 'testPattern', path: '.' };
410 |       const invocation = grepTool.build(params);
411 |       expect(invocation.getDescription()).toBe("'testPattern' within ./");
412 |     });
413 |   });
414 | });
```

src/tools/grep.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import fs from 'node:fs';
8 | import fsPromises from 'node:fs/promises';
9 | import path from 'node:path';
10 | import { EOL } from 'node:os';
11 | import { spawn } from 'node:child_process';
12 | import { globStream } from 'glob';
13 | import type { ToolInvocation, ToolResult } from './tools.js';
14 | import { BaseDeclarativeTool, BaseToolInvocation, Kind } from './tools.js';
15 | import { makeRelative, shortenPath } from '../utils/paths.js';
16 | import { getErrorMessage, isNodeError } from '../utils/errors.js';
17 | import { isGitRepository } from '../utils/gitUtils.js';
18 | import type { Config } from '../config/config.js';
19 | import type { FileExclusions } from '../utils/ignorePatterns.js';
20 | import { ToolErrorType } from './tool-error.js';
21 | 
22 | // --- Interfaces ---
23 | 
24 | /**
25 |  * Parameters for the GrepTool
26 |  */
27 | export interface GrepToolParams {
28 |   /**
29 |    * The regular expression pattern to search for in file contents
30 |    */
31 |   pattern: string;
32 | 
33 |   /**
34 |    * The directory to search in (optional, defaults to current directory relative to root)
35 |    */
36 |   path?: string;
37 | 
38 |   /**
39 |    * File pattern to include in the search (e.g. "*.js", "*.{ts,tsx}")
40 |    */
41 |   include?: string;
42 | }
43 | 
44 | /**
45 |  * Result object for a single grep match
46 |  */
47 | interface GrepMatch {
48 |   filePath: string;
49 |   lineNumber: number;
50 |   line: string;
51 | }
52 | 
53 | class GrepToolInvocation extends BaseToolInvocation<
54 |   GrepToolParams,
55 |   ToolResult
56 | > {
57 |   private readonly fileExclusions: FileExclusions;
58 | 
59 |   constructor(
60 |     private readonly config: Config,
61 |     params: GrepToolParams,
62 |   ) {
63 |     super(params);
64 |     this.fileExclusions = config.getFileExclusions();
65 |   }
66 | 
67 |   /**
68 |    * Checks if a path is within the root directory and resolves it.
69 |    * @param relativePath Path relative to the root directory (or undefined for root).
70 |    * @returns The absolute path if valid and exists, or null if no path specified (to search all directories).
71 |    * @throws {Error} If path is outside root, doesn't exist, or isn't a directory.
72 |    */
73 |   private resolveAndValidatePath(relativePath?: string): string | null {
74 |     // If no path specified, return null to indicate searching all workspace directories
75 |     if (!relativePath) {
76 |       return null;
77 |     }
78 | 
79 |     const targetPath = path.resolve(this.config.getTargetDir(), relativePath);
80 | 
81 |     // Security Check: Ensure the resolved path is within workspace boundaries
82 |     const workspaceContext = this.config.getWorkspaceContext();
83 |     if (!workspaceContext.isPathWithinWorkspace(targetPath)) {
84 |       const directories = workspaceContext.getDirectories();
85 |       throw new Error(
86 |         `Path validation failed: Attempted path "${relativePath}" resolves outside the allowed workspace directories: ${directories.join(', ')}`,
87 |       );
88 |     }
89 | 
90 |     // Check existence and type after resolving
91 |     try {
92 |       const stats = fs.statSync(targetPath);
93 |       if (!stats.isDirectory()) {
94 |         throw new Error(`Path is not a directory: ${targetPath}`);
95 |       }
96 |     } catch (error: unknown) {
97 |       if (isNodeError(error) && error.code !== 'ENOENT') {
98 |         throw new Error(`Path does not exist: ${targetPath}`);
99 |       }
100 |       throw new Error(
101 |         `Failed to access path stats for ${targetPath}: ${error}`,
102 |       );
103 |     }
104 | 
105 |     return targetPath;
106 |   }
107 | 
108 |   async execute(signal: AbortSignal): Promise<ToolResult> {
109 |     try {
110 |       const workspaceContext = this.config.getWorkspaceContext();
111 |       const searchDirAbs = this.resolveAndValidatePath(this.params.path);
112 |       const searchDirDisplay = this.params.path || '.';
113 | 
114 |       // Determine which directories to search
115 |       let searchDirectories: readonly string[];
116 |       if (searchDirAbs === null) {
117 |         // No path specified - search all workspace directories
118 |         searchDirectories = workspaceContext.getDirectories();
119 |       } else {
120 |         // Specific path provided - search only that directory
121 |         searchDirectories = [searchDirAbs];
122 |       }
123 | 
124 |       // Collect matches from all search directories
125 |       let allMatches: GrepMatch[] = [];
126 |       for (const searchDir of searchDirectories) {
127 |         const matches = await this.performGrepSearch({
128 |           pattern: this.params.pattern,
129 |           path: searchDir,
130 |           include: this.params.include,
131 |           signal,
132 |         });
133 | 
134 |         // Add directory prefix if searching multiple directories
135 |         if (searchDirectories.length > 1) {
136 |           const dirName = path.basename(searchDir);
137 |           matches.forEach((match) => {
138 |             match.filePath = path.join(dirName, match.filePath);
139 |           });
140 |         }
141 | 
142 |         allMatches = allMatches.concat(matches);
143 |       }
144 | 
145 |       let searchLocationDescription: string;
146 |       if (searchDirAbs === null) {
147 |         const numDirs = workspaceContext.getDirectories().length;
148 |         searchLocationDescription =
149 |           numDirs > 1
150 |             ? `across ${numDirs} workspace directories`
151 |             : `in the workspace directory`;
152 |       } else {
153 |         searchLocationDescription = `in path "${searchDirDisplay}"`;
154 |       }
155 | 
156 |       if (allMatches.length === 0) {
157 |         const noMatchMsg = `No matches found for pattern "${this.params.pattern}" ${searchLocationDescription}${this.params.include ? ` (filter: "${this.params.include}")` : ''}.`;
158 |         return { llmContent: noMatchMsg, returnDisplay: `No matches found` };
159 |       }
160 | 
161 |       // Group matches by file
162 |       const matchesByFile = allMatches.reduce(
163 |         (acc, match) => {
164 |           const fileKey = match.filePath;
165 |           if (!acc[fileKey]) {
166 |             acc[fileKey] = [];
167 |           }
168 |           acc[fileKey].push(match);
169 |           acc[fileKey].sort((a, b) => a.lineNumber - b.lineNumber);
170 |           return acc;
171 |         },
172 |         {} as Record<string, GrepMatch[]>,
173 |       );
174 | 
175 |       const matchCount = allMatches.length;
176 |       const matchTerm = matchCount === 1 ? 'match' : 'matches';
177 | 
178 |       let llmContent = `Found ${matchCount} ${matchTerm} for pattern "${this.params.pattern}" ${searchLocationDescription}${this.params.include ? ` (filter: "${this.params.include}")` : ''}:
179 | ---
180 | `;
181 | 
182 |       for (const filePath in matchesByFile) {
183 |         llmContent += `File: ${filePath}\n`;
184 |         matchesByFile[filePath].forEach((match) => {
185 |           const trimmedLine = match.line.trim();
186 |           llmContent += `L${match.lineNumber}: ${trimmedLine}\n`;
187 |         });
188 |         llmContent += '---\n';
189 |       }
190 | 
191 |       return {
192 |         llmContent: llmContent.trim(),
193 |         returnDisplay: `Found ${matchCount} ${matchTerm}`,
194 |       };
195 |     } catch (error) {
196 |       console.error(`Error during GrepLogic execution: ${error}`);
197 |       const errorMessage = getErrorMessage(error);
198 |       return {
199 |         llmContent: `Error during grep search operation: ${errorMessage}`,
200 |         returnDisplay: `Error: ${errorMessage}`,
201 |         error: {
202 |           message: errorMessage,
203 |           type: ToolErrorType.GREP_EXECUTION_ERROR,
204 |         },
205 |       };
206 |     }
207 |   }
208 | 
209 |   /**
210 |    * Checks if a command is available in the system's PATH.
211 |    * @param {string} command The command name (e.g., 'git', 'grep').
212 |    * @returns {Promise<boolean>} True if the command is available, false otherwise.
213 |    */
214 |   private isCommandAvailable(command: string): Promise<boolean> {
215 |     return new Promise((resolve) => {
216 |       const checkCommand = process.platform === 'win32' ? 'where' : 'command';
217 |       const checkArgs =
218 |         process.platform === 'win32' ? [command] : ['-v', command];
219 |       try {
220 |         const child = spawn(checkCommand, checkArgs, {
221 |           stdio: 'ignore',
222 |           shell: process.platform === 'win32',
223 |         });
224 |         child.on('close', (code) => resolve(code === 0));
225 |         child.on('error', () => resolve(false));
226 |       } catch {
227 |         resolve(false);
228 |       }
229 |     });
230 |   }
231 | 
232 |   /**
233 |    * Parses the standard output of grep-like commands (git grep, system grep).
234 |    * Expects format: filePath:lineNumber:lineContent
235 |    * Handles colons within file paths and line content correctly.
236 |    * @param {string} output The raw stdout string.
237 |    * @param {string} basePath The absolute directory the search was run from, for relative paths.
238 |    * @returns {GrepMatch[]} Array of match objects.
239 |    */
240 |   private parseGrepOutput(output: string, basePath: string): GrepMatch[] {
241 |     const results: GrepMatch[] = [];
242 |     if (!output) return results;
243 | 
244 |     const lines = output.split(EOL); // Use OS-specific end-of-line
245 | 
246 |     for (const line of lines) {
247 |       if (!line.trim()) continue;
248 | 
249 |       // Find the index of the first colon.
250 |       const firstColonIndex = line.indexOf(':');
251 |       if (firstColonIndex === -1) continue; // Malformed
252 | 
253 |       // Find the index of the second colon, searching *after* the first one.
254 |       const secondColonIndex = line.indexOf(':', firstColonIndex + 1);
255 |       if (secondColonIndex === -1) continue; // Malformed
256 | 
257 |       // Extract parts based on the found colon indices
258 |       const filePathRaw = line.substring(0, firstColonIndex);
259 |       const lineNumberStr = line.substring(
260 |         firstColonIndex + 1,
261 |         secondColonIndex,
262 |       );
263 |       const lineContent = line.substring(secondColonIndex + 1);
264 | 
265 |       const lineNumber = parseInt(lineNumberStr, 10);
266 | 
267 |       if (!isNaN(lineNumber)) {
268 |         const absoluteFilePath = path.resolve(basePath, filePathRaw);
269 |         const relativeFilePath = path.relative(basePath, absoluteFilePath);
270 | 
271 |         results.push({
272 |           filePath: relativeFilePath || path.basename(absoluteFilePath),
273 |           lineNumber,
274 |           line: lineContent,
275 |         });
276 |       }
277 |     }
278 |     return results;
279 |   }
280 | 
281 |   /**
282 |    * Gets a description of the grep operation
283 |    * @returns A string describing the grep
284 |    */
285 |   getDescription(): string {
286 |     let description = `'${this.params.pattern}'`;
287 |     if (this.params.include) {
288 |       description += ` in ${this.params.include}`;
289 |     }
290 |     if (this.params.path) {
291 |       const resolvedPath = path.resolve(
292 |         this.config.getTargetDir(),
293 |         this.params.path,
294 |       );
295 |       if (
296 |         resolvedPath === this.config.getTargetDir() ||
297 |         this.params.path === '.'
298 |       ) {
299 |         description += ` within ./`;
300 |       } else {
301 |         const relativePath = makeRelative(
302 |           resolvedPath,
303 |           this.config.getTargetDir(),
304 |         );
305 |         description += ` within ${shortenPath(relativePath)}`;
306 |       }
307 |     } else {
308 |       // When no path is specified, indicate searching all workspace directories
309 |       const workspaceContext = this.config.getWorkspaceContext();
310 |       const directories = workspaceContext.getDirectories();
311 |       if (directories.length > 1) {
312 |         description += ` across all workspace directories`;
313 |       }
314 |     }
315 |     return description;
316 |   }
317 | 
318 |   /**
319 |    * Performs the actual search using the prioritized strategies.
320 |    * @param options Search options including pattern, absolute path, and include glob.
321 |    * @returns A promise resolving to an array of match objects.
322 |    */
323 |   private async performGrepSearch(options: {
324 |     pattern: string;
325 |     path: string; // Expects absolute path
326 |     include?: string;
327 |     signal: AbortSignal;
328 |   }): Promise<GrepMatch[]> {
329 |     const { pattern, path: absolutePath, include } = options;
330 |     let strategyUsed = 'none';
331 | 
332 |     try {
333 |       // --- Strategy 1: git grep ---
334 |       const isGit = isGitRepository(absolutePath);
335 |       const gitAvailable = isGit && (await this.isCommandAvailable('git'));
336 | 
337 |       if (gitAvailable) {
338 |         strategyUsed = 'git grep';
339 |         const gitArgs = [
340 |           'grep',
341 |           '--untracked',
342 |           '-n',
343 |           '-E',
344 |           '--ignore-case',
345 |           pattern,
346 |         ];
347 |         if (include) {
348 |           gitArgs.push('--', include);
349 |         }
350 | 
351 |         try {
352 |           const output = await new Promise<string>((resolve, reject) => {
353 |             const child = spawn('git', gitArgs, {
354 |               cwd: absolutePath,
355 |               windowsHide: true,
356 |             });
357 |             const stdoutChunks: Buffer[] = [];
358 |             const stderrChunks: Buffer[] = [];
359 | 
360 |             child.stdout.on('data', (chunk) => stdoutChunks.push(chunk));
361 |             child.stderr.on('data', (chunk) => stderrChunks.push(chunk));
362 |             child.on('error', (err) =>
363 |               reject(new Error(`Failed to start git grep: ${err.message}`)),
364 |             );
365 |             child.on('close', (code) => {
366 |               const stdoutData = Buffer.concat(stdoutChunks).toString('utf8');
367 |               const stderrData = Buffer.concat(stderrChunks).toString('utf8');
368 |               if (code === 0) resolve(stdoutData);
369 |               else if (code === 1)
370 |                 resolve(''); // No matches
371 |               else
372 |                 reject(
373 |                   new Error(`git grep exited with code ${code}: ${stderrData}`),
374 |                 );
375 |             });
376 |           });
377 |           return this.parseGrepOutput(output, absolutePath);
378 |         } catch (gitError: unknown) {
379 |           console.debug(
380 |             `GrepLogic: git grep failed: ${getErrorMessage(
381 |               gitError,
382 |             )}. Falling back...`,
383 |           );
384 |         }
385 |       }
386 | 
387 |       // --- Strategy 2: System grep ---
388 |       const grepAvailable = await this.isCommandAvailable('grep');
389 |       if (grepAvailable) {
390 |         strategyUsed = 'system grep';
391 |         const grepArgs = ['-r', '-n', '-H', '-E'];
392 |         // Extract directory names from exclusion patterns for grep --exclude-dir
393 |         const globExcludes = this.fileExclusions.getGlobExcludes();
394 |         const commonExcludes = globExcludes
395 |           .map((pattern) => {
396 |             let dir = pattern;
397 |             if (dir.startsWith('**/')) {
398 |               dir = dir.substring(3);
399 |             }
400 |             if (dir.endsWith('/**')) {
401 |               dir = dir.slice(0, -3);
402 |             } else if (dir.endsWith('/')) {
403 |               dir = dir.slice(0, -1);
404 |             }
405 | 
406 |             // Only consider patterns that are likely directories. This filters out file patterns.
407 |             if (dir && !dir.includes('/') && !dir.includes('*')) {
408 |               return dir;
409 |             }
410 |             return null;
411 |           })
412 |           .filter((dir): dir is string => !!dir);
413 |         commonExcludes.forEach((dir) => grepArgs.push(`--exclude-dir=${dir}`));
414 |         if (include) {
415 |           grepArgs.push(`--include=${include}`);
416 |         }
417 |         grepArgs.push(pattern);
418 |         grepArgs.push('.');
419 | 
420 |         try {
421 |           const output = await new Promise<string>((resolve, reject) => {
422 |             const child = spawn('grep', grepArgs, {
423 |               cwd: absolutePath,
424 |               windowsHide: true,
425 |             });
426 |             const stdoutChunks: Buffer[] = [];
427 |             const stderrChunks: Buffer[] = [];
428 | 
429 |             const onData = (chunk: Buffer) => stdoutChunks.push(chunk);
430 |             const onStderr = (chunk: Buffer) => {
431 |               const stderrStr = chunk.toString();
432 |               // Suppress common harmless stderr messages
433 |               if (
434 |                 !stderrStr.includes('Permission denied') &&
435 |                 !/grep:.*: Is a directory/i.test(stderrStr)
436 |               ) {
437 |                 stderrChunks.push(chunk);
438 |               }
439 |             };
440 |             const onError = (err: Error) => {
441 |               cleanup();
442 |               reject(new Error(`Failed to start system grep: ${err.message}`));
443 |             };
444 |             const onClose = (code: number | null) => {
445 |               const stdoutData = Buffer.concat(stdoutChunks).toString('utf8');
446 |               const stderrData = Buffer.concat(stderrChunks)
447 |                 .toString('utf8')
448 |                 .trim();
449 |               cleanup();
450 |               if (code === 0) resolve(stdoutData);
451 |               else if (code === 1)
452 |                 resolve(''); // No matches
453 |               else {
454 |                 if (stderrData)
455 |                   reject(
456 |                     new Error(
457 |                       `System grep exited with code ${code}: ${stderrData}`,
458 |                     ),
459 |                   );
460 |                 else resolve(''); // Exit code > 1 but no stderr, likely just suppressed errors
461 |               }
462 |             };
463 | 
464 |             const cleanup = () => {
465 |               child.stdout.removeListener('data', onData);
466 |               child.stderr.removeListener('data', onStderr);
467 |               child.removeListener('error', onError);
468 |               child.removeListener('close', onClose);
469 |               if (child.connected) {
470 |                 child.disconnect();
471 |               }
472 |             };
473 | 
474 |             child.stdout.on('data', onData);
475 |             child.stderr.on('data', onStderr);
476 |             child.on('error', onError);
477 |             child.on('close', onClose);
478 |           });
479 |           return this.parseGrepOutput(output, absolutePath);
480 |         } catch (grepError: unknown) {
481 |           console.debug(
482 |             `GrepLogic: System grep failed: ${getErrorMessage(
483 |               grepError,
484 |             )}. Falling back...`,
485 |           );
486 |         }
487 |       }
488 | 
489 |       // --- Strategy 3: Pure JavaScript Fallback ---
490 |       console.debug(
491 |         'GrepLogic: Falling back to JavaScript grep implementation.',
492 |       );
493 |       strategyUsed = 'javascript fallback';
494 |       const globPattern = include ? include : '**/*';
495 |       const ignorePatterns = this.fileExclusions.getGlobExcludes();
496 | 
497 |       const filesStream = globStream(globPattern, {
498 |         cwd: absolutePath,
499 |         dot: true,
500 |         ignore: ignorePatterns,
501 |         absolute: true,
502 |         nodir: true,
503 |         signal: options.signal,
504 |       });
505 | 
506 |       const regex = new RegExp(pattern, 'i');
507 |       const allMatches: GrepMatch[] = [];
508 | 
509 |       for await (const filePath of filesStream) {
510 |         const fileAbsolutePath = filePath as string;
511 |         try {
512 |           const content = await fsPromises.readFile(fileAbsolutePath, 'utf8');
513 |           const lines = content.split(/\r?\n/);
514 |           lines.forEach((line, index) => {
515 |             if (regex.test(line)) {
516 |               allMatches.push({
517 |                 filePath:
518 |                   path.relative(absolutePath, fileAbsolutePath) ||
519 |                   path.basename(fileAbsolutePath),
520 |                 lineNumber: index + 1,
521 |                 line,
522 |               });
523 |             }
524 |           });
525 |         } catch (readError: unknown) {
526 |           // Ignore errors like permission denied or file gone during read
527 |           if (!isNodeError(readError) || readError.code !== 'ENOENT') {
528 |             console.debug(
529 |               `GrepLogic: Could not read/process ${fileAbsolutePath}: ${getErrorMessage(
530 |                 readError,
531 |               )}`,
532 |             );
533 |           }
534 |         }
535 |       }
536 | 
537 |       return allMatches;
538 |     } catch (error: unknown) {
539 |       console.error(
540 |         `GrepLogic: Error in performGrepSearch (Strategy: ${strategyUsed}): ${getErrorMessage(
541 |           error,
542 |         )}`,
543 |       );
544 |       throw error; // Re-throw
545 |     }
546 |   }
547 | }
548 | 
549 | // --- GrepLogic Class ---
550 | 
551 | /**
552 |  * Implementation of the Grep tool logic (moved from CLI)
553 |  */
554 | export class GrepTool extends BaseDeclarativeTool<GrepToolParams, ToolResult> {
555 |   static readonly Name = 'search_file_content'; // Keep static name
556 | 
557 |   constructor(private readonly config: Config) {
558 |     super(
559 |       GrepTool.Name,
560 |       'SearchText',
561 |       'Searches for a regular expression pattern within the content of files in a specified directory (or current working directory). Can filter files by a glob pattern. Returns the lines containing matches, along with their file paths and line numbers.',
562 |       Kind.Search,
563 |       {
564 |         properties: {
565 |           pattern: {
566 |             description:
567 |               "The regular expression (regex) pattern to search for within file contents (e.g., 'function\\s+myFunction', 'import\\s+\\{.*\\}\\s+from\\s+.*').",
568 |             type: 'string',
569 |           },
570 |           path: {
571 |             description:
572 |               'Optional: The absolute path to the directory to search within. If omitted, searches the current working directory.',
573 |             type: 'string',
574 |           },
575 |           include: {
576 |             description:
577 |               "Optional: A glob pattern to filter which files are searched (e.g., '*.js', '*.{ts,tsx}', 'src/**'). If omitted, searches all files (respecting potential global ignores).",
578 |             type: 'string',
579 |           },
580 |         },
581 |         required: ['pattern'],
[TRUNCATED]
```

src/tools/ls.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
8 | import fs from 'node:fs/promises';
9 | import path from 'node:path';
10 | import os from 'node:os';
11 | import { LSTool } from './ls.js';
12 | import type { Config } from '../config/config.js';
13 | import { FileDiscoveryService } from '../services/fileDiscoveryService.js';
14 | import { ToolErrorType } from './tool-error.js';
15 | import { createMockWorkspaceContext } from '../test-utils/mockWorkspaceContext.js';
16 | 
17 | describe('LSTool', () => {
18 |   let lsTool: LSTool;
19 |   let tempRootDir: string;
20 |   let tempSecondaryDir: string;
21 |   let mockConfig: Config;
22 |   const abortSignal = new AbortController().signal;
23 | 
24 |   beforeEach(async () => {
25 |     tempRootDir = await fs.mkdtemp(path.join(os.tmpdir(), 'ls-tool-root-'));
26 |     tempSecondaryDir = await fs.mkdtemp(
27 |       path.join(os.tmpdir(), 'ls-tool-secondary-'),
28 |     );
29 | 
30 |     const mockWorkspaceContext = createMockWorkspaceContext(tempRootDir, [
31 |       tempSecondaryDir,
32 |     ]);
33 | 
34 |     mockConfig = {
35 |       getTargetDir: () => tempRootDir,
36 |       getWorkspaceContext: () => mockWorkspaceContext,
37 |       getFileService: () => new FileDiscoveryService(tempRootDir),
38 |       getFileFilteringOptions: () => ({
39 |         respectGitIgnore: true,
40 |         respectGeminiIgnore: true,
41 |       }),
42 |     } as unknown as Config;
43 | 
44 |     lsTool = new LSTool(mockConfig);
45 |   });
46 | 
47 |   afterEach(async () => {
48 |     await fs.rm(tempRootDir, { recursive: true, force: true });
49 |     await fs.rm(tempSecondaryDir, { recursive: true, force: true });
50 |   });
51 | 
52 |   describe('parameter validation', () => {
53 |     it('should accept valid absolute paths within workspace', async () => {
54 |       const testPath = path.join(tempRootDir, 'src');
55 |       await fs.mkdir(testPath);
56 | 
57 |       const invocation = lsTool.build({ path: testPath });
58 | 
59 |       expect(invocation).toBeDefined();
60 |     });
61 | 
62 |     it('should reject relative paths', () => {
63 |       expect(() => lsTool.build({ path: './src' })).toThrow(
64 |         'Path must be absolute: ./src',
65 |       );
66 |     });
67 | 
68 |     it('should reject paths outside workspace with clear error message', () => {
69 |       expect(() => lsTool.build({ path: '/etc/passwd' })).toThrow(
70 |         `Path must be within one of the workspace directories: ${tempRootDir}, ${tempSecondaryDir}`,
71 |       );
72 |     });
73 | 
74 |     it('should accept paths in secondary workspace directory', async () => {
75 |       const testPath = path.join(tempSecondaryDir, 'lib');
76 |       await fs.mkdir(testPath);
77 | 
78 |       const invocation = lsTool.build({ path: testPath });
79 | 
80 |       expect(invocation).toBeDefined();
81 |     });
82 |   });
83 | 
84 |   describe('execute', () => {
85 |     it('should list files in a directory', async () => {
86 |       await fs.writeFile(path.join(tempRootDir, 'file1.txt'), 'content1');
87 |       await fs.mkdir(path.join(tempRootDir, 'subdir'));
88 |       await fs.writeFile(
89 |         path.join(tempSecondaryDir, 'secondary-file.txt'),
90 |         'secondary',
91 |       );
92 | 
93 |       const invocation = lsTool.build({ path: tempRootDir });
94 |       const result = await invocation.execute(abortSignal);
95 | 
96 |       expect(result.llmContent).toContain('[DIR] subdir');
97 |       expect(result.llmContent).toContain('file1.txt');
98 |       expect(result.returnDisplay).toBe('Listed 2 item(s).');
99 |     });
100 | 
101 |     it('should list files from secondary workspace directory', async () => {
102 |       await fs.writeFile(path.join(tempRootDir, 'file1.txt'), 'content1');
103 |       await fs.mkdir(path.join(tempRootDir, 'subdir'));
104 |       await fs.writeFile(
105 |         path.join(tempSecondaryDir, 'secondary-file.txt'),
106 |         'secondary',
107 |       );
108 | 
109 |       const invocation = lsTool.build({ path: tempSecondaryDir });
110 |       const result = await invocation.execute(abortSignal);
111 | 
112 |       expect(result.llmContent).toContain('secondary-file.txt');
113 |       expect(result.returnDisplay).toBe('Listed 1 item(s).');
114 |     });
115 | 
116 |     it('should handle empty directories', async () => {
117 |       const emptyDir = path.join(tempRootDir, 'empty');
118 |       await fs.mkdir(emptyDir);
119 |       const invocation = lsTool.build({ path: emptyDir });
120 |       const result = await invocation.execute(abortSignal);
121 | 
122 |       expect(result.llmContent).toBe(`Directory ${emptyDir} is empty.`);
123 |       expect(result.returnDisplay).toBe('Directory is empty.');
124 |     });
125 | 
126 |     it('should respect ignore patterns', async () => {
127 |       await fs.writeFile(path.join(tempRootDir, 'file1.txt'), 'content1');
128 |       await fs.writeFile(path.join(tempRootDir, 'file2.log'), 'content1');
129 | 
130 |       const invocation = lsTool.build({
131 |         path: tempRootDir,
132 |         ignore: ['*.log'],
133 |       });
134 |       const result = await invocation.execute(abortSignal);
135 | 
136 |       expect(result.llmContent).toContain('file1.txt');
137 |       expect(result.llmContent).not.toContain('file2.log');
138 |       expect(result.returnDisplay).toBe('Listed 1 item(s).');
139 |     });
140 | 
141 |     it('should respect gitignore patterns', async () => {
142 |       await fs.writeFile(path.join(tempRootDir, 'file1.txt'), 'content1');
143 |       await fs.writeFile(path.join(tempRootDir, 'file2.log'), 'content1');
144 |       await fs.writeFile(path.join(tempRootDir, '.git'), '');
145 |       await fs.writeFile(path.join(tempRootDir, '.gitignore'), '*.log');
146 |       const invocation = lsTool.build({ path: tempRootDir });
147 |       const result = await invocation.execute(abortSignal);
148 | 
149 |       expect(result.llmContent).toContain('file1.txt');
150 |       expect(result.llmContent).not.toContain('file2.log');
151 |       // .git is always ignored by default.
152 |       expect(result.returnDisplay).toBe('Listed 2 item(s). (2 git-ignored)');
153 |     });
154 | 
155 |     it('should respect geminiignore patterns', async () => {
156 |       await fs.writeFile(path.join(tempRootDir, 'file1.txt'), 'content1');
157 |       await fs.writeFile(path.join(tempRootDir, 'file2.log'), 'content1');
158 |       await fs.writeFile(path.join(tempRootDir, '.geminiignore'), '*.log');
159 |       const invocation = lsTool.build({ path: tempRootDir });
160 |       const result = await invocation.execute(abortSignal);
161 | 
162 |       expect(result.llmContent).toContain('file1.txt');
163 |       expect(result.llmContent).not.toContain('file2.log');
164 |       expect(result.returnDisplay).toBe('Listed 2 item(s). (1 gemini-ignored)');
165 |     });
166 | 
167 |     it('should handle non-directory paths', async () => {
168 |       const testPath = path.join(tempRootDir, 'file1.txt');
169 |       await fs.writeFile(testPath, 'content1');
170 | 
171 |       const invocation = lsTool.build({ path: testPath });
172 |       const result = await invocation.execute(abortSignal);
173 | 
174 |       expect(result.llmContent).toContain('Path is not a directory');
175 |       expect(result.returnDisplay).toBe('Error: Path is not a directory.');
176 |       expect(result.error?.type).toBe(ToolErrorType.PATH_IS_NOT_A_DIRECTORY);
177 |     });
178 | 
179 |     it('should handle non-existent paths', async () => {
180 |       const testPath = path.join(tempRootDir, 'does-not-exist');
181 |       const invocation = lsTool.build({ path: testPath });
182 |       const result = await invocation.execute(abortSignal);
183 | 
184 |       expect(result.llmContent).toContain('Error listing directory');
185 |       expect(result.returnDisplay).toBe('Error: Failed to list directory.');
186 |       expect(result.error?.type).toBe(ToolErrorType.LS_EXECUTION_ERROR);
187 |     });
188 | 
189 |     it('should sort directories first, then files alphabetically', async () => {
190 |       await fs.writeFile(path.join(tempRootDir, 'a-file.txt'), 'content1');
191 |       await fs.writeFile(path.join(tempRootDir, 'b-file.txt'), 'content1');
192 |       await fs.mkdir(path.join(tempRootDir, 'x-dir'));
193 |       await fs.mkdir(path.join(tempRootDir, 'y-dir'));
194 | 
195 |       const invocation = lsTool.build({ path: tempRootDir });
196 |       const result = await invocation.execute(abortSignal);
197 | 
198 |       const lines = (
199 |         typeof result.llmContent === 'string' ? result.llmContent : ''
200 |       )
201 |         .split('\n')
202 |         .filter(Boolean);
203 |       const entries = lines.slice(1); // Skip header
204 | 
205 |       expect(entries[0]).toBe('[DIR] x-dir');
206 |       expect(entries[1]).toBe('[DIR] y-dir');
207 |       expect(entries[2]).toBe('a-file.txt');
208 |       expect(entries[3]).toBe('b-file.txt');
209 |     });
210 | 
211 |     it('should handle permission errors gracefully', async () => {
212 |       const restrictedDir = path.join(tempRootDir, 'restricted');
213 |       await fs.mkdir(restrictedDir);
214 | 
215 |       // To simulate a permission error in a cross-platform way,
216 |       // we mock fs.readdir to throw an error.
217 |       const error = new Error('EACCES: permission denied');
218 |       vi.spyOn(fs, 'readdir').mockRejectedValueOnce(error);
219 | 
220 |       const invocation = lsTool.build({ path: restrictedDir });
221 |       const result = await invocation.execute(abortSignal);
222 | 
223 |       expect(result.llmContent).toContain('Error listing directory');
224 |       expect(result.llmContent).toContain('permission denied');
225 |       expect(result.returnDisplay).toBe('Error: Failed to list directory.');
226 |       expect(result.error?.type).toBe(ToolErrorType.LS_EXECUTION_ERROR);
227 |     });
228 | 
229 |     it('should throw for invalid params at build time', () => {
230 |       expect(() => lsTool.build({ path: '../outside' })).toThrow(
231 |         'Path must be absolute: ../outside',
232 |       );
233 |     });
234 | 
235 |     it('should handle errors accessing individual files during listing', async () => {
236 |       await fs.writeFile(path.join(tempRootDir, 'file1.txt'), 'content1');
237 |       const problematicFile = path.join(tempRootDir, 'problematic.txt');
238 |       await fs.writeFile(problematicFile, 'content2');
239 | 
240 |       // To simulate an error on a single file in a cross-platform way,
241 |       // we mock fs.stat to throw for a specific file. This avoids
242 |       // platform-specific behavior with things like dangling symlinks.
243 |       const originalStat = fs.stat;
244 |       const statSpy = vi.spyOn(fs, 'stat').mockImplementation(async (p) => {
245 |         if (p.toString() === problematicFile) {
246 |           throw new Error('Simulated stat error');
247 |         }
248 |         return originalStat(p);
249 |       });
250 | 
251 |       // Spy on console.error to verify it's called
252 |       const consoleErrorSpy = vi
253 |         .spyOn(console, 'error')
254 |         .mockImplementation(() => {});
255 | 
256 |       const invocation = lsTool.build({ path: tempRootDir });
257 |       const result = await invocation.execute(abortSignal);
258 | 
259 |       // Should still list the other files
260 |       expect(result.llmContent).toContain('file1.txt');
261 |       expect(result.llmContent).not.toContain('problematic.txt');
262 |       expect(result.returnDisplay).toBe('Listed 1 item(s).');
263 | 
264 |       // Verify error was logged
265 |       expect(consoleErrorSpy).toHaveBeenCalledWith(
266 |         expect.stringMatching(/Error accessing.*problematic\.txt/s),
267 |       );
268 | 
269 |       statSpy.mockRestore();
270 |       consoleErrorSpy.mockRestore();
271 |     });
272 |   });
273 | 
274 |   describe('getDescription', () => {
275 |     it('should return shortened relative path', () => {
276 |       const deeplyNestedDir = path.join(tempRootDir, 'deeply', 'nested');
277 |       const params = {
278 |         path: path.join(deeplyNestedDir, 'directory'),
279 |       };
280 |       const invocation = lsTool.build(params);
281 |       const description = invocation.getDescription();
282 |       expect(description).toBe(path.join('deeply', 'nested', 'directory'));
283 |     });
284 | 
285 |     it('should handle paths in secondary workspace', () => {
286 |       const params = {
287 |         path: path.join(tempSecondaryDir, 'lib'),
288 |       };
289 |       const invocation = lsTool.build(params);
290 |       const description = invocation.getDescription();
291 |       const expected = path.relative(tempRootDir, params.path);
292 |       expect(description).toBe(expected);
293 |     });
294 |   });
295 | 
296 |   describe('workspace boundary validation', () => {
297 |     it('should accept paths in primary workspace directory', async () => {
298 |       const testPath = path.join(tempRootDir, 'src');
299 |       await fs.mkdir(testPath);
300 |       const params = { path: testPath };
301 |       expect(lsTool.build(params)).toBeDefined();
302 |     });
303 | 
304 |     it('should accept paths in secondary workspace directory', async () => {
305 |       const testPath = path.join(tempSecondaryDir, 'lib');
306 |       await fs.mkdir(testPath);
307 |       const params = { path: testPath };
308 |       expect(lsTool.build(params)).toBeDefined();
309 |     });
310 | 
311 |     it('should reject paths outside all workspace directories', () => {
312 |       const params = { path: '/etc/passwd' };
313 |       expect(() => lsTool.build(params)).toThrow(
314 |         'Path must be within one of the workspace directories',
315 |       );
316 |     });
317 | 
318 |     it('should list files from secondary workspace directory', async () => {
319 |       await fs.writeFile(
320 |         path.join(tempSecondaryDir, 'secondary-file.txt'),
321 |         'secondary',
322 |       );
323 | 
324 |       const invocation = lsTool.build({ path: tempSecondaryDir });
325 |       const result = await invocation.execute(abortSignal);
326 | 
327 |       expect(result.llmContent).toContain('secondary-file.txt');
328 |       expect(result.returnDisplay).toBe('Listed 1 item(s).');
329 |     });
330 |   });
331 | });
```

src/tools/ls.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import fs from 'node:fs/promises';
8 | import path from 'node:path';
9 | import type { ToolInvocation, ToolResult } from './tools.js';
10 | import { BaseDeclarativeTool, BaseToolInvocation, Kind } from './tools.js';
11 | import { makeRelative, shortenPath } from '../utils/paths.js';
12 | import type { Config } from '../config/config.js';
13 | import { DEFAULT_FILE_FILTERING_OPTIONS } from '../config/constants.js';
14 | import { ToolErrorType } from './tool-error.js';
15 | 
16 | /**
17 |  * Parameters for the LS tool
18 |  */
19 | export interface LSToolParams {
20 |   /**
21 |    * The absolute path to the directory to list
22 |    */
23 |   path: string;
24 | 
25 |   /**
26 |    * Array of glob patterns to ignore (optional)
27 |    */
28 |   ignore?: string[];
29 | 
30 |   /**
31 |    * Whether to respect .gitignore and .geminiignore patterns (optional, defaults to true)
32 |    */
33 |   file_filtering_options?: {
34 |     respect_git_ignore?: boolean;
35 |     respect_gemini_ignore?: boolean;
36 |   };
37 | }
38 | 
39 | /**
40 |  * File entry returned by LS tool
41 |  */
42 | export interface FileEntry {
43 |   /**
44 |    * Name of the file or directory
45 |    */
46 |   name: string;
47 | 
48 |   /**
49 |    * Absolute path to the file or directory
50 |    */
51 |   path: string;
52 | 
53 |   /**
54 |    * Whether this entry is a directory
55 |    */
56 |   isDirectory: boolean;
57 | 
58 |   /**
59 |    * Size of the file in bytes (0 for directories)
60 |    */
61 |   size: number;
62 | 
63 |   /**
64 |    * Last modified timestamp
65 |    */
66 |   modifiedTime: Date;
67 | }
68 | 
69 | class LSToolInvocation extends BaseToolInvocation<LSToolParams, ToolResult> {
70 |   constructor(
71 |     private readonly config: Config,
72 |     params: LSToolParams,
73 |   ) {
74 |     super(params);
75 |   }
76 | 
77 |   /**
78 |    * Checks if a filename matches any of the ignore patterns
79 |    * @param filename Filename to check
80 |    * @param patterns Array of glob patterns to check against
81 |    * @returns True if the filename should be ignored
82 |    */
83 |   private shouldIgnore(filename: string, patterns?: string[]): boolean {
84 |     if (!patterns || patterns.length === 0) {
85 |       return false;
86 |     }
87 |     for (const pattern of patterns) {
88 |       // Convert glob pattern to RegExp
89 |       const regexPattern = pattern
90 |         .replace(/[.+^${}()|[\]\\]/g, '\\$&')
91 |         .replace(/\*/g, '.*')
92 |         .replace(/\?/g, '.');
93 |       const regex = new RegExp(`^${regexPattern}$`);
94 |       if (regex.test(filename)) {
95 |         return true;
96 |       }
97 |     }
98 |     return false;
99 |   }
100 | 
101 |   /**
102 |    * Gets a description of the file reading operation
103 |    * @returns A string describing the file being read
104 |    */
105 |   getDescription(): string {
106 |     const relativePath = makeRelative(
107 |       this.params.path,
108 |       this.config.getTargetDir(),
109 |     );
110 |     return shortenPath(relativePath);
111 |   }
112 | 
113 |   // Helper for consistent error formatting
114 |   private errorResult(
115 |     llmContent: string,
116 |     returnDisplay: string,
117 |     type: ToolErrorType,
118 |   ): ToolResult {
119 |     return {
120 |       llmContent,
121 |       // Keep returnDisplay simpler in core logic
122 |       returnDisplay: `Error: ${returnDisplay}`,
123 |       error: {
124 |         message: llmContent,
125 |         type,
126 |       },
127 |     };
128 |   }
129 | 
130 |   /**
131 |    * Executes the LS operation with the given parameters
132 |    * @returns Result of the LS operation
133 |    */
134 |   async execute(_signal: AbortSignal): Promise<ToolResult> {
135 |     try {
136 |       const stats = await fs.stat(this.params.path);
137 |       if (!stats) {
138 |         // fs.statSync throws on non-existence, so this check might be redundant
139 |         // but keeping for clarity. Error message adjusted.
140 |         return this.errorResult(
141 |           `Error: Directory not found or inaccessible: ${this.params.path}`,
142 |           `Directory not found or inaccessible.`,
143 |           ToolErrorType.FILE_NOT_FOUND,
144 |         );
145 |       }
146 |       if (!stats.isDirectory()) {
147 |         return this.errorResult(
148 |           `Error: Path is not a directory: ${this.params.path}`,
149 |           `Path is not a directory.`,
150 |           ToolErrorType.PATH_IS_NOT_A_DIRECTORY,
151 |         );
152 |       }
153 | 
154 |       const files = await fs.readdir(this.params.path);
155 |       if (files.length === 0) {
156 |         // Changed error message to be more neutral for LLM
157 |         return {
158 |           llmContent: `Directory ${this.params.path} is empty.`,
159 |           returnDisplay: `Directory is empty.`,
160 |         };
161 |       }
162 | 
163 |       const relativePaths = files.map((file) =>
164 |         path.relative(
165 |           this.config.getTargetDir(),
166 |           path.join(this.params.path, file),
167 |         ),
168 |       );
169 | 
170 |       const fileDiscovery = this.config.getFileService();
171 |       const { filteredPaths, gitIgnoredCount, geminiIgnoredCount } =
172 |         fileDiscovery.filterFilesWithReport(relativePaths, {
173 |           respectGitIgnore:
174 |             this.params.file_filtering_options?.respect_git_ignore ??
175 |             this.config.getFileFilteringOptions().respectGitIgnore ??
176 |             DEFAULT_FILE_FILTERING_OPTIONS.respectGitIgnore,
177 |           respectGeminiIgnore:
178 |             this.params.file_filtering_options?.respect_gemini_ignore ??
179 |             this.config.getFileFilteringOptions().respectGeminiIgnore ??
180 |             DEFAULT_FILE_FILTERING_OPTIONS.respectGeminiIgnore,
181 |         });
182 | 
183 |       const entries = [];
184 |       for (const relativePath of filteredPaths) {
185 |         const fullPath = path.resolve(this.config.getTargetDir(), relativePath);
186 | 
187 |         if (this.shouldIgnore(path.basename(fullPath), this.params.ignore)) {
188 |           continue;
189 |         }
190 | 
191 |         try {
192 |           const stats = await fs.stat(fullPath);
193 |           const isDir = stats.isDirectory();
194 |           entries.push({
195 |             name: path.basename(fullPath),
196 |             path: fullPath,
197 |             isDirectory: isDir,
198 |             size: isDir ? 0 : stats.size,
199 |             modifiedTime: stats.mtime,
200 |           });
201 |         } catch (error) {
202 |           // Log error internally but don't fail the whole listing
203 |           console.error(`Error accessing ${fullPath}: ${error}`);
204 |         }
205 |       }
206 | 
207 |       // Sort entries (directories first, then alphabetically)
208 |       entries.sort((a, b) => {
209 |         if (a.isDirectory && !b.isDirectory) return -1;
210 |         if (!a.isDirectory && b.isDirectory) return 1;
211 |         return a.name.localeCompare(b.name);
212 |       });
213 | 
214 |       // Create formatted content for LLM
215 |       const directoryContent = entries
216 |         .map((entry) => `${entry.isDirectory ? '[DIR] ' : ''}${entry.name}`)
217 |         .join('\n');
218 | 
219 |       let resultMessage = `Directory listing for ${this.params.path}:\n${directoryContent}`;
220 |       const ignoredMessages = [];
221 |       if (gitIgnoredCount > 0) {
222 |         ignoredMessages.push(`${gitIgnoredCount} git-ignored`);
223 |       }
224 |       if (geminiIgnoredCount > 0) {
225 |         ignoredMessages.push(`${geminiIgnoredCount} gemini-ignored`);
226 |       }
227 |       if (ignoredMessages.length > 0) {
228 |         resultMessage += `\n\n(${ignoredMessages.join(', ')})`;
229 |       }
230 | 
231 |       let displayMessage = `Listed ${entries.length} item(s).`;
232 |       if (ignoredMessages.length > 0) {
233 |         displayMessage += ` (${ignoredMessages.join(', ')})`;
234 |       }
235 | 
236 |       return {
237 |         llmContent: resultMessage,
238 |         returnDisplay: displayMessage,
239 |       };
240 |     } catch (error) {
241 |       const errorMsg = `Error listing directory: ${error instanceof Error ? error.message : String(error)}`;
242 |       return this.errorResult(
243 |         errorMsg,
244 |         'Failed to list directory.',
245 |         ToolErrorType.LS_EXECUTION_ERROR,
246 |       );
247 |     }
248 |   }
249 | }
250 | 
251 | /**
252 |  * Implementation of the LS tool logic
253 |  */
254 | export class LSTool extends BaseDeclarativeTool<LSToolParams, ToolResult> {
255 |   static readonly Name = 'list_directory';
256 | 
257 |   constructor(private config: Config) {
258 |     super(
259 |       LSTool.Name,
260 |       'ReadFolder',
261 |       'Lists the names of files and subdirectories directly within a specified directory path. Can optionally ignore entries matching provided glob patterns.',
262 |       Kind.Search,
263 |       {
264 |         properties: {
265 |           path: {
266 |             description:
267 |               'The absolute path to the directory to list (must be absolute, not relative)',
268 |             type: 'string',
269 |           },
270 |           ignore: {
271 |             description: 'List of glob patterns to ignore',
272 |             items: {
273 |               type: 'string',
274 |             },
275 |             type: 'array',
276 |           },
277 |           file_filtering_options: {
278 |             description:
279 |               'Optional: Whether to respect ignore patterns from .gitignore or .geminiignore',
280 |             type: 'object',
281 |             properties: {
282 |               respect_git_ignore: {
283 |                 description:
284 |                   'Optional: Whether to respect .gitignore patterns when listing files. Only available in git repositories. Defaults to true.',
285 |                 type: 'boolean',
286 |               },
287 |               respect_gemini_ignore: {
288 |                 description:
289 |                   'Optional: Whether to respect .geminiignore patterns when listing files. Defaults to true.',
290 |                 type: 'boolean',
291 |               },
292 |             },
293 |           },
294 |         },
295 |         required: ['path'],
296 |         type: 'object',
297 |       },
298 |     );
299 |   }
300 | 
301 |   /**
302 |    * Validates the parameters for the tool
303 |    * @param params Parameters to validate
304 |    * @returns An error message string if invalid, null otherwise
305 |    */
306 |   protected override validateToolParamValues(
307 |     params: LSToolParams,
308 |   ): string | null {
309 |     if (!path.isAbsolute(params.path)) {
310 |       return `Path must be absolute: ${params.path}`;
311 |     }
312 | 
313 |     const workspaceContext = this.config.getWorkspaceContext();
314 |     if (!workspaceContext.isPathWithinWorkspace(params.path)) {
315 |       const directories = workspaceContext.getDirectories();
316 |       return `Path must be within one of the workspace directories: ${directories.join(
317 |         ', ',
318 |       )}`;
319 |     }
320 |     return null;
321 |   }
322 | 
323 |   protected createInvocation(
324 |     params: LSToolParams,
325 |   ): ToolInvocation<LSToolParams, ToolResult> {
326 |     return new LSToolInvocation(this.config, params);
327 |   }
328 | }
```

src/tools/mcp-client-manager.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { afterEach, describe, expect, it, vi } from 'vitest';
8 | import { McpClientManager } from './mcp-client-manager.js';
9 | import { McpClient } from './mcp-client.js';
10 | import type { ToolRegistry } from './tool-registry.js';
11 | import type { PromptRegistry } from '../prompts/prompt-registry.js';
12 | import type { WorkspaceContext } from '../utils/workspaceContext.js';
13 | import type { Config } from '../config/config.js';
14 | 
15 | vi.mock('./mcp-client.js', async () => {
16 |   const originalModule = await vi.importActual('./mcp-client.js');
17 |   return {
18 |     ...originalModule,
19 |     McpClient: vi.fn(),
20 |     populateMcpServerCommand: vi.fn(() => ({
21 |       'test-server': {},
22 |     })),
23 |   };
24 | });
25 | 
26 | describe('McpClientManager', () => {
27 |   afterEach(() => {
28 |     vi.restoreAllMocks();
29 |   });
30 | 
31 |   it('should discover tools from all servers', async () => {
32 |     const mockedMcpClient = {
33 |       connect: vi.fn(),
34 |       discover: vi.fn(),
35 |       disconnect: vi.fn(),
36 |       getStatus: vi.fn(),
37 |     };
38 |     vi.mocked(McpClient).mockReturnValue(
39 |       mockedMcpClient as unknown as McpClient,
40 |     );
41 |     const manager = new McpClientManager(
42 |       {
43 |         'test-server': {},
44 |       },
45 |       '',
46 |       {} as ToolRegistry,
47 |       {} as PromptRegistry,
48 |       false,
49 |       {} as WorkspaceContext,
50 |     );
51 |     await manager.discoverAllMcpTools({
52 |       isTrustedFolder: () => true,
53 |     } as unknown as Config);
54 |     expect(mockedMcpClient.connect).toHaveBeenCalledOnce();
55 |     expect(mockedMcpClient.discover).toHaveBeenCalledOnce();
56 |   });
57 | 
58 |   it('should not discover tools if folder is not trusted', async () => {
59 |     const mockedMcpClient = {
60 |       connect: vi.fn(),
61 |       discover: vi.fn(),
62 |       disconnect: vi.fn(),
63 |       getStatus: vi.fn(),
64 |     };
65 |     vi.mocked(McpClient).mockReturnValue(
66 |       mockedMcpClient as unknown as McpClient,
67 |     );
68 |     const manager = new McpClientManager(
69 |       {
70 |         'test-server': {},
71 |       },
72 |       '',
73 |       {} as ToolRegistry,
74 |       {} as PromptRegistry,
75 |       false,
76 |       {} as WorkspaceContext,
77 |     );
78 |     await manager.discoverAllMcpTools({
79 |       isTrustedFolder: () => false,
80 |     } as unknown as Config);
81 |     expect(mockedMcpClient.connect).not.toHaveBeenCalled();
82 |     expect(mockedMcpClient.discover).not.toHaveBeenCalled();
83 |   });
84 | });
```

src/tools/mcp-client-manager.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Config, MCPServerConfig } from '../config/config.js';
8 | import type { ToolRegistry } from './tool-registry.js';
9 | import type { PromptRegistry } from '../prompts/prompt-registry.js';
10 | import {
11 |   McpClient,
12 |   MCPDiscoveryState,
13 |   populateMcpServerCommand,
14 | } from './mcp-client.js';
15 | import { getErrorMessage } from '../utils/errors.js';
16 | import type { EventEmitter } from 'node:events';
17 | import type { WorkspaceContext } from '../utils/workspaceContext.js';
18 | 
19 | /**
20 |  * Manages the lifecycle of multiple MCP clients, including local child processes.
21 |  * This class is responsible for starting, stopping, and discovering tools from
22 |  * a collection of MCP servers defined in the configuration.
23 |  */
24 | export class McpClientManager {
25 |   private clients: Map<string, McpClient> = new Map();
26 |   private readonly mcpServers: Record<string, MCPServerConfig>;
27 |   private readonly mcpServerCommand: string | undefined;
28 |   private readonly toolRegistry: ToolRegistry;
29 |   private readonly promptRegistry: PromptRegistry;
30 |   private readonly debugMode: boolean;
31 |   private readonly workspaceContext: WorkspaceContext;
32 |   private discoveryState: MCPDiscoveryState = MCPDiscoveryState.NOT_STARTED;
33 |   private readonly eventEmitter?: EventEmitter;
34 | 
35 |   constructor(
36 |     mcpServers: Record<string, MCPServerConfig>,
37 |     mcpServerCommand: string | undefined,
38 |     toolRegistry: ToolRegistry,
39 |     promptRegistry: PromptRegistry,
40 |     debugMode: boolean,
41 |     workspaceContext: WorkspaceContext,
42 |     eventEmitter?: EventEmitter,
43 |   ) {
44 |     this.mcpServers = mcpServers;
45 |     this.mcpServerCommand = mcpServerCommand;
46 |     this.toolRegistry = toolRegistry;
47 |     this.promptRegistry = promptRegistry;
48 |     this.debugMode = debugMode;
49 |     this.workspaceContext = workspaceContext;
50 |     this.eventEmitter = eventEmitter;
51 |   }
52 | 
53 |   /**
54 |    * Initiates the tool discovery process for all configured MCP servers.
55 |    * It connects to each server, discovers its available tools, and registers
56 |    * them with the `ToolRegistry`.
57 |    */
58 |   async discoverAllMcpTools(cliConfig: Config): Promise<void> {
59 |     if (!cliConfig.isTrustedFolder()) {
60 |       return;
61 |     }
62 |     await this.stop();
63 | 
64 |     const servers = populateMcpServerCommand(
65 |       this.mcpServers,
66 |       this.mcpServerCommand,
67 |     );
68 | 
69 |     this.discoveryState = MCPDiscoveryState.IN_PROGRESS;
70 | 
71 |     this.eventEmitter?.emit('mcp-client-update', this.clients);
72 |     const discoveryPromises = Object.entries(servers).map(
73 |       async ([name, config]) => {
74 |         const client = new McpClient(
75 |           name,
76 |           config,
77 |           this.toolRegistry,
78 |           this.promptRegistry,
79 |           this.workspaceContext,
80 |           this.debugMode,
81 |         );
82 |         this.clients.set(name, client);
83 | 
84 |         this.eventEmitter?.emit('mcp-client-update', this.clients);
85 |         try {
86 |           await client.connect();
87 |           await client.discover(cliConfig);
88 |           this.eventEmitter?.emit('mcp-client-update', this.clients);
89 |         } catch (error) {
90 |           this.eventEmitter?.emit('mcp-client-update', this.clients);
91 |           // Log the error but don't let a single failed server stop the others
92 |           console.error(
93 |             `Error during discovery for server '${name}': ${getErrorMessage(
94 |               error,
95 |             )}`,
96 |           );
97 |         }
98 |       },
99 |     );
100 | 
101 |     await Promise.all(discoveryPromises);
102 |     this.discoveryState = MCPDiscoveryState.COMPLETED;
103 |   }
104 | 
105 |   /**
106 |    * Stops all running local MCP servers and closes all client connections.
107 |    * This is the cleanup method to be called on application exit.
108 |    */
109 |   async stop(): Promise<void> {
110 |     const disconnectionPromises = Array.from(this.clients.entries()).map(
111 |       async ([name, client]) => {
112 |         try {
113 |           await client.disconnect();
114 |         } catch (error) {
115 |           console.error(
116 |             `Error stopping client '${name}': ${getErrorMessage(error)}`,
117 |           );
118 |         }
119 |       },
120 |     );
121 | 
122 |     await Promise.all(disconnectionPromises);
123 |     this.clients.clear();
124 |   }
125 | 
126 |   getDiscoveryState(): MCPDiscoveryState {
127 |     return this.discoveryState;
128 |   }
129 | }
```

src/tools/mcp-client.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as GenAiLib from '@google/genai';
8 | import * as ClientLib from '@modelcontextprotocol/sdk/client/index.js';
9 | import { SSEClientTransport } from '@modelcontextprotocol/sdk/client/sse.js';
10 | import * as SdkClientStdioLib from '@modelcontextprotocol/sdk/client/stdio.js';
11 | import { StreamableHTTPClientTransport } from '@modelcontextprotocol/sdk/client/streamableHttp.js';
12 | import { afterEach, beforeEach, describe, expect, it, vi } from 'vitest';
13 | import { AuthProviderType, type Config } from '../config/config.js';
14 | import { GoogleCredentialProvider } from '../mcp/google-auth-provider.js';
15 | import { MCPOAuthProvider } from '../mcp/oauth-provider.js';
16 | import { MCPOAuthTokenStorage } from '../mcp/oauth-token-storage.js';
17 | import { OAuthUtils } from '../mcp/oauth-utils.js';
18 | import type { PromptRegistry } from '../prompts/prompt-registry.js';
19 | import { WorkspaceContext } from '../utils/workspaceContext.js';
20 | import {
21 |   connectToMcpServer,
22 |   createTransport,
23 |   hasNetworkTransport,
24 |   isEnabled,
25 |   McpClient,
26 |   populateMcpServerCommand,
27 | } from './mcp-client.js';
28 | import type { ToolRegistry } from './tool-registry.js';
29 | import * as fs from 'node:fs';
30 | import * as os from 'node:os';
31 | import * as path from 'node:path';
32 | 
33 | vi.mock('@modelcontextprotocol/sdk/client/stdio.js');
34 | vi.mock('@modelcontextprotocol/sdk/client/index.js');
35 | vi.mock('@google/genai');
36 | vi.mock('../mcp/oauth-provider.js');
37 | vi.mock('../mcp/oauth-token-storage.js');
38 | vi.mock('../mcp/oauth-utils.js');
39 | 
40 | describe('mcp-client', () => {
41 |   let workspaceContext: WorkspaceContext;
42 |   let testWorkspace: string;
43 | 
44 |   beforeEach(() => {
45 |     // create a tmp dir for this test
46 |     // Create a unique temporary directory for the workspace to avoid conflicts
47 |     testWorkspace = fs.mkdtempSync(
48 |       path.join(os.tmpdir(), 'gemini-agent-test-'),
49 |     );
50 |     workspaceContext = new WorkspaceContext(testWorkspace);
51 |   });
52 | 
53 |   afterEach(() => {
54 |     vi.restoreAllMocks();
55 |   });
56 | 
57 |   describe('McpClient', () => {
58 |     it('should discover tools', async () => {
59 |       const mockedClient = {
60 |         connect: vi.fn(),
61 |         discover: vi.fn(),
62 |         disconnect: vi.fn(),
63 |         getStatus: vi.fn(),
64 |         registerCapabilities: vi.fn(),
65 |         setRequestHandler: vi.fn(),
66 |         getServerCapabilities: vi.fn().mockReturnValue({ tools: {} }),
67 |       };
68 |       vi.mocked(ClientLib.Client).mockReturnValue(
69 |         mockedClient as unknown as ClientLib.Client,
70 |       );
71 |       vi.spyOn(SdkClientStdioLib, 'StdioClientTransport').mockReturnValue(
72 |         {} as SdkClientStdioLib.StdioClientTransport,
73 |       );
74 |       const mockedMcpToTool = vi.mocked(GenAiLib.mcpToTool).mockReturnValue({
75 |         tool: () => ({
76 |           functionDeclarations: [
77 |             {
78 |               name: 'testFunction',
79 |             },
80 |           ],
81 |         }),
82 |       } as unknown as GenAiLib.CallableTool);
83 |       const mockedToolRegistry = {
84 |         registerTool: vi.fn(),
85 |       } as unknown as ToolRegistry;
86 |       const client = new McpClient(
87 |         'test-server',
88 |         {
89 |           command: 'test-command',
90 |         },
91 |         mockedToolRegistry,
92 |         {} as PromptRegistry,
93 |         workspaceContext,
94 |         false,
95 |       );
96 |       await client.connect();
97 |       await client.discover({} as Config);
98 |       expect(mockedMcpToTool).toHaveBeenCalledOnce();
99 |     });
100 | 
101 |     it('should not skip tools even if a parameter is missing a type', async () => {
102 |       const consoleWarnSpy = vi
103 |         .spyOn(console, 'warn')
104 |         .mockImplementation(() => {});
105 |       const mockedClient = {
106 |         connect: vi.fn(),
107 |         discover: vi.fn(),
108 |         disconnect: vi.fn(),
109 |         getStatus: vi.fn(),
110 |         registerCapabilities: vi.fn(),
111 |         setRequestHandler: vi.fn(),
112 |         getServerCapabilities: vi.fn().mockReturnValue({ tools: {} }),
113 |         tool: vi.fn(),
114 |       };
115 |       vi.mocked(ClientLib.Client).mockReturnValue(
116 |         mockedClient as unknown as ClientLib.Client,
117 |       );
118 |       vi.spyOn(SdkClientStdioLib, 'StdioClientTransport').mockReturnValue(
119 |         {} as SdkClientStdioLib.StdioClientTransport,
120 |       );
121 |       vi.mocked(GenAiLib.mcpToTool).mockReturnValue({
122 |         tool: () =>
123 |           Promise.resolve({
124 |             functionDeclarations: [
125 |               {
126 |                 name: 'validTool',
127 |                 parametersJsonSchema: {
128 |                   type: 'object',
129 |                   properties: {
130 |                     param1: { type: 'string' },
131 |                   },
132 |                 },
133 |               },
134 |               {
135 |                 name: 'invalidTool',
136 |                 parametersJsonSchema: {
137 |                   type: 'object',
138 |                   properties: {
139 |                     param1: { description: 'a param with no type' },
140 |                   },
141 |                 },
142 |               },
143 |             ],
144 |           }),
145 |       } as unknown as GenAiLib.CallableTool);
146 |       const mockedToolRegistry = {
147 |         registerTool: vi.fn(),
148 |       } as unknown as ToolRegistry;
149 |       const client = new McpClient(
150 |         'test-server',
151 |         {
152 |           command: 'test-command',
153 |         },
154 |         mockedToolRegistry,
155 |         {} as PromptRegistry,
156 |         workspaceContext,
157 |         false,
158 |       );
159 |       await client.connect();
160 |       await client.discover({} as Config);
161 |       expect(mockedToolRegistry.registerTool).toHaveBeenCalledTimes(2);
162 |       expect(consoleWarnSpy).not.toHaveBeenCalled();
163 |       consoleWarnSpy.mockRestore();
164 |     });
165 | 
166 |     it('should handle errors when discovering prompts', async () => {
167 |       const consoleErrorSpy = vi
168 |         .spyOn(console, 'error')
169 |         .mockImplementation(() => {});
170 |       const mockedClient = {
171 |         connect: vi.fn(),
172 |         discover: vi.fn(),
173 |         disconnect: vi.fn(),
174 |         getStatus: vi.fn(),
175 |         registerCapabilities: vi.fn(),
176 |         setRequestHandler: vi.fn(),
177 |         getServerCapabilities: vi.fn().mockReturnValue({ prompts: {} }),
178 |         request: vi.fn().mockRejectedValue(new Error('Test error')),
179 |       };
180 |       vi.mocked(ClientLib.Client).mockReturnValue(
181 |         mockedClient as unknown as ClientLib.Client,
182 |       );
183 |       vi.spyOn(SdkClientStdioLib, 'StdioClientTransport').mockReturnValue(
184 |         {} as SdkClientStdioLib.StdioClientTransport,
185 |       );
186 |       vi.mocked(GenAiLib.mcpToTool).mockReturnValue({
187 |         tool: () => Promise.resolve({ functionDeclarations: [] }),
188 |       } as unknown as GenAiLib.CallableTool);
189 |       const client = new McpClient(
190 |         'test-server',
191 |         {
192 |           command: 'test-command',
193 |         },
194 |         {} as ToolRegistry,
195 |         {} as PromptRegistry,
196 |         workspaceContext,
197 |         false,
198 |       );
199 |       await client.connect();
200 |       await expect(client.discover({} as Config)).rejects.toThrow(
201 |         'No prompts or tools found on the server.',
202 |       );
203 |       expect(consoleErrorSpy).toHaveBeenCalledWith(
204 |         `Error discovering prompts from test-server: Test error`,
205 |       );
206 |       consoleErrorSpy.mockRestore();
207 |     });
208 | 
209 |     it('should not discover tools if server does not support them', async () => {
210 |       const mockedClient = {
211 |         connect: vi.fn(),
212 |         discover: vi.fn(),
213 |         disconnect: vi.fn(),
214 |         getStatus: vi.fn(),
215 |         registerCapabilities: vi.fn(),
216 |         setRequestHandler: vi.fn(),
217 |         getServerCapabilities: vi.fn().mockReturnValue({ prompts: {} }),
218 |         request: vi.fn().mockResolvedValue({ prompts: [] }),
219 |       };
220 |       vi.mocked(ClientLib.Client).mockReturnValue(
221 |         mockedClient as unknown as ClientLib.Client,
222 |       );
223 |       vi.spyOn(SdkClientStdioLib, 'StdioClientTransport').mockReturnValue(
224 |         {} as SdkClientStdioLib.StdioClientTransport,
225 |       );
226 |       const mockedMcpToTool = vi.mocked(GenAiLib.mcpToTool);
227 |       const mockedToolRegistry = {
228 |         registerTool: vi.fn(),
229 |       } as unknown as ToolRegistry;
230 |       const client = new McpClient(
231 |         'test-server',
232 |         {
233 |           command: 'test-command',
234 |         },
235 |         mockedToolRegistry,
236 |         {} as PromptRegistry,
237 |         workspaceContext,
238 |         false,
239 |       );
240 |       await client.connect();
241 |       await expect(client.discover({} as Config)).rejects.toThrow(
242 |         'No prompts or tools found on the server.',
243 |       );
244 |       expect(mockedMcpToTool).not.toHaveBeenCalled();
245 |     });
246 | 
247 |     it('should discover tools if server supports them', async () => {
248 |       const mockedClient = {
249 |         connect: vi.fn(),
250 |         discover: vi.fn(),
251 |         disconnect: vi.fn(),
252 |         getStatus: vi.fn(),
253 |         registerCapabilities: vi.fn(),
254 |         setRequestHandler: vi.fn(),
255 |         getServerCapabilities: vi.fn().mockReturnValue({ tools: {} }),
256 |         request: vi.fn().mockResolvedValue({ prompts: [] }),
257 |       };
258 |       vi.mocked(ClientLib.Client).mockReturnValue(
259 |         mockedClient as unknown as ClientLib.Client,
260 |       );
261 |       vi.spyOn(SdkClientStdioLib, 'StdioClientTransport').mockReturnValue(
262 |         {} as SdkClientStdioLib.StdioClientTransport,
263 |       );
264 |       const mockedMcpToTool = vi.mocked(GenAiLib.mcpToTool).mockReturnValue({
265 |         tool: () =>
266 |           Promise.resolve({
267 |             functionDeclarations: [
268 |               {
269 |                 name: 'testTool',
270 |                 description: 'A test tool',
271 |               },
272 |             ],
273 |           }),
274 |       } as unknown as GenAiLib.CallableTool);
275 |       const mockedToolRegistry = {
276 |         registerTool: vi.fn(),
277 |       } as unknown as ToolRegistry;
278 |       const client = new McpClient(
279 |         'test-server',
280 |         {
281 |           command: 'test-command',
282 |         },
283 |         mockedToolRegistry,
284 |         {} as PromptRegistry,
285 |         workspaceContext,
286 |         false,
287 |       );
288 |       await client.connect();
289 |       await client.discover({} as Config);
290 |       expect(mockedMcpToTool).toHaveBeenCalledOnce();
291 |       expect(mockedToolRegistry.registerTool).toHaveBeenCalledOnce();
292 |     });
293 |   });
294 |   describe('appendMcpServerCommand', () => {
295 |     it('should do nothing if no MCP servers or command are configured', () => {
296 |       const out = populateMcpServerCommand({}, undefined);
297 |       expect(out).toEqual({});
298 |     });
299 | 
300 |     it('should discover tools via mcpServerCommand', () => {
301 |       const commandString = 'command --arg1 value1';
302 |       const out = populateMcpServerCommand({}, commandString);
303 |       expect(out).toEqual({
304 |         mcp: {
305 |           command: 'command',
306 |           args: ['--arg1', 'value1'],
307 |         },
308 |       });
309 |     });
310 | 
311 |     it('should handle error if mcpServerCommand parsing fails', () => {
312 |       expect(() => populateMcpServerCommand({}, 'derp && herp')).toThrowError();
313 |     });
314 |   });
315 | 
316 |   describe('createTransport', () => {
317 |     describe('should connect via httpUrl', () => {
318 |       it('without headers', async () => {
319 |         const transport = await createTransport(
320 |           'test-server',
321 |           {
322 |             httpUrl: 'http://test-server',
323 |           },
324 |           false,
325 |         );
326 | 
327 |         expect(transport).toEqual(
328 |           new StreamableHTTPClientTransport(new URL('http://test-server'), {}),
329 |         );
330 |       });
331 | 
332 |       it('with headers', async () => {
333 |         const transport = await createTransport(
334 |           'test-server',
335 |           {
336 |             httpUrl: 'http://test-server',
337 |             headers: { Authorization: 'derp' },
338 |           },
339 |           false,
340 |         );
341 | 
342 |         expect(transport).toEqual(
343 |           new StreamableHTTPClientTransport(new URL('http://test-server'), {
344 |             requestInit: {
345 |               headers: { Authorization: 'derp' },
346 |             },
347 |           }),
348 |         );
349 |       });
350 |     });
351 | 
352 |     describe('should connect via url', () => {
353 |       it('without headers', async () => {
354 |         const transport = await createTransport(
355 |           'test-server',
356 |           {
357 |             url: 'http://test-server',
358 |           },
359 |           false,
360 |         );
361 |         expect(transport).toEqual(
362 |           new SSEClientTransport(new URL('http://test-server'), {}),
363 |         );
364 |       });
365 | 
366 |       it('with headers', async () => {
367 |         const transport = await createTransport(
368 |           'test-server',
369 |           {
370 |             url: 'http://test-server',
371 |             headers: { Authorization: 'derp' },
372 |           },
373 |           false,
374 |         );
375 | 
376 |         expect(transport).toEqual(
377 |           new SSEClientTransport(new URL('http://test-server'), {
378 |             requestInit: {
379 |               headers: { Authorization: 'derp' },
380 |             },
381 |           }),
382 |         );
383 |       });
384 |     });
385 | 
386 |     it('should connect via command', async () => {
387 |       const mockedTransport = vi
388 |         .spyOn(SdkClientStdioLib, 'StdioClientTransport')
389 |         .mockReturnValue({} as SdkClientStdioLib.StdioClientTransport);
390 | 
391 |       await createTransport(
392 |         'test-server',
393 |         {
394 |           command: 'test-command',
395 |           args: ['--foo', 'bar'],
396 |           env: { FOO: 'bar' },
397 |           cwd: 'test/cwd',
398 |         },
399 |         false,
400 |       );
401 | 
402 |       expect(mockedTransport).toHaveBeenCalledWith({
403 |         command: 'test-command',
404 |         args: ['--foo', 'bar'],
405 |         cwd: 'test/cwd',
406 |         env: { ...process.env, FOO: 'bar' },
407 |         stderr: 'pipe',
408 |       });
409 |     });
410 | 
411 |     describe('useGoogleCredentialProvider', () => {
412 |       it('should use GoogleCredentialProvider when specified', async () => {
413 |         const transport = await createTransport(
414 |           'test-server',
415 |           {
416 |             httpUrl: 'http://test.googleapis.com',
417 |             authProviderType: AuthProviderType.GOOGLE_CREDENTIALS,
418 |             oauth: {
419 |               scopes: ['scope1'],
420 |             },
421 |           },
422 |           false,
423 |         );
424 | 
425 |         expect(transport).toBeInstanceOf(StreamableHTTPClientTransport);
426 |         // eslint-disable-next-line @typescript-eslint/no-explicit-any
427 |         const authProvider = (transport as any)._authProvider;
428 |         expect(authProvider).toBeInstanceOf(GoogleCredentialProvider);
429 |       });
430 | 
431 |       it('should use GoogleCredentialProvider with SSE transport', async () => {
432 |         const transport = await createTransport(
433 |           'test-server',
434 |           {
435 |             url: 'http://test.googleapis.com',
436 |             authProviderType: AuthProviderType.GOOGLE_CREDENTIALS,
437 |             oauth: {
438 |               scopes: ['scope1'],
439 |             },
440 |           },
441 |           false,
442 |         );
443 | 
444 |         expect(transport).toBeInstanceOf(SSEClientTransport);
445 |         // eslint-disable-next-line @typescript-eslint/no-explicit-any
446 |         const authProvider = (transport as any)._authProvider;
447 |         expect(authProvider).toBeInstanceOf(GoogleCredentialProvider);
448 |       });
449 | 
450 |       it('should throw an error if no URL is provided with GoogleCredentialProvider', async () => {
451 |         await expect(
452 |           createTransport(
453 |             'test-server',
454 |             {
455 |               authProviderType: AuthProviderType.GOOGLE_CREDENTIALS,
456 |               oauth: {
457 |                 scopes: ['scope1'],
458 |               },
459 |             },
460 |             false,
461 |           ),
462 |         ).rejects.toThrow(
463 |           'URL must be provided in the config for Google Credentials provider',
464 |         );
465 |       });
466 |     });
467 |   });
468 |   describe('isEnabled', () => {
469 |     const funcDecl = { name: 'myTool' };
470 |     const serverName = 'myServer';
471 | 
472 |     it('should return true if no include or exclude lists are provided', () => {
473 |       const mcpServerConfig = {};
474 |       expect(isEnabled(funcDecl, serverName, mcpServerConfig)).toBe(true);
475 |     });
476 | 
477 |     it('should return false if the tool is in the exclude list', () => {
478 |       const mcpServerConfig = { excludeTools: ['myTool'] };
479 |       expect(isEnabled(funcDecl, serverName, mcpServerConfig)).toBe(false);
480 |     });
481 | 
482 |     it('should return true if the tool is in the include list', () => {
483 |       const mcpServerConfig = { includeTools: ['myTool'] };
484 |       expect(isEnabled(funcDecl, serverName, mcpServerConfig)).toBe(true);
485 |     });
486 | 
487 |     it('should return true if the tool is in the include list with parentheses', () => {
488 |       const mcpServerConfig = { includeTools: ['myTool()'] };
489 |       expect(isEnabled(funcDecl, serverName, mcpServerConfig)).toBe(true);
490 |     });
491 | 
492 |     it('should return false if the include list exists but does not contain the tool', () => {
493 |       const mcpServerConfig = { includeTools: ['anotherTool'] };
494 |       expect(isEnabled(funcDecl, serverName, mcpServerConfig)).toBe(false);
495 |     });
496 | 
497 |     it('should return false if the tool is in both the include and exclude lists', () => {
498 |       const mcpServerConfig = {
499 |         includeTools: ['myTool'],
500 |         excludeTools: ['myTool'],
501 |       };
502 |       expect(isEnabled(funcDecl, serverName, mcpServerConfig)).toBe(false);
503 |     });
504 | 
505 |     it('should return false if the function declaration has no name', () => {
506 |       const namelessFuncDecl = {};
507 |       const mcpServerConfig = {};
508 |       expect(isEnabled(namelessFuncDecl, serverName, mcpServerConfig)).toBe(
509 |         false,
510 |       );
511 |     });
512 |   });
513 | 
514 |   describe('hasNetworkTransport', () => {
515 |     it('should return true if only url is provided', () => {
516 |       const config = { url: 'http://example.com' };
517 |       expect(hasNetworkTransport(config)).toBe(true);
518 |     });
519 | 
520 |     it('should return true if only httpUrl is provided', () => {
521 |       const config = { httpUrl: 'http://example.com' };
522 |       expect(hasNetworkTransport(config)).toBe(true);
523 |     });
524 | 
525 |     it('should return true if both url and httpUrl are provided', () => {
526 |       const config = {
527 |         url: 'http://example.com/sse',
528 |         httpUrl: 'http://example.com/http',
529 |       };
530 |       expect(hasNetworkTransport(config)).toBe(true);
531 |     });
532 | 
533 |     it('should return false if neither url nor httpUrl is provided', () => {
534 |       const config = { command: 'do-something' };
535 |       expect(hasNetworkTransport(config)).toBe(false);
536 |     });
537 | 
538 |     it('should return false for an empty config object', () => {
539 |       const config = {};
540 |       expect(hasNetworkTransport(config)).toBe(false);
541 |     });
542 |   });
543 | });
544 | 
545 | describe('connectToMcpServer with OAuth', () => {
546 |   let mockedClient: ClientLib.Client;
547 |   let workspaceContext: WorkspaceContext;
548 |   let testWorkspace: string;
549 |   let mockAuthProvider: MCPOAuthProvider;
550 |   let mockTokenStorage: MCPOAuthTokenStorage;
551 | 
552 |   beforeEach(() => {
553 |     mockedClient = {
554 |       connect: vi.fn(),
555 |       close: vi.fn(),
556 |       registerCapabilities: vi.fn(),
557 |       setRequestHandler: vi.fn(),
558 |       onclose: vi.fn(),
559 |       notification: vi.fn(),
560 |     } as unknown as ClientLib.Client;
561 |     vi.mocked(ClientLib.Client).mockImplementation(() => mockedClient);
562 | 
563 |     testWorkspace = fs.mkdtempSync(
564 |       path.join(os.tmpdir(), 'gemini-agent-test-'),
565 |     );
566 |     workspaceContext = new WorkspaceContext(testWorkspace);
567 | 
568 |     vi.spyOn(console, 'log').mockImplementation(() => {});
569 |     vi.spyOn(console, 'warn').mockImplementation(() => {});
570 |     vi.spyOn(console, 'error').mockImplementation(() => {});
571 | 
572 |     mockTokenStorage = {
573 |       getCredentials: vi.fn().mockResolvedValue({ clientId: 'test-client' }),
574 |     } as unknown as MCPOAuthTokenStorage;
575 |     vi.mocked(MCPOAuthTokenStorage).mockReturnValue(mockTokenStorage);
576 |     mockAuthProvider = {
577 |       authenticate: vi.fn().mockResolvedValue(undefined),
578 |       getValidToken: vi.fn().mockResolvedValue('test-access-token'),
579 |       tokenStorage: mockTokenStorage,
580 |     } as unknown as MCPOAuthProvider;
581 |     vi.mocked(MCPOAuthProvider).mockReturnValue(mockAuthProvider);
582 |   });
583 | 
584 |   afterEach(() => {
585 |     vi.clearAllMocks();
586 |   });
587 | 
588 |   it('should handle automatic OAuth flow on 401 with www-authenticate header', async () => {
589 |     const serverUrl = 'http://test-server.com/';
590 |     const authUrl = 'http://auth.example.com/auth';
591 |     const tokenUrl = 'http://auth.example.com/token';
592 |     const wwwAuthHeader = `Bearer realm="test", resource_metadata="http://test-server.com/.well-known/oauth-protected-resource"`;
593 | 
594 |     vi.mocked(mockedClient.connect).mockRejectedValueOnce(
595 |       new Error(`401 Unauthorized\nwww-authenticate: ${wwwAuthHeader}`),
596 |     );
597 | 
598 |     vi.mocked(OAuthUtils.discoverOAuthConfig).mockResolvedValue({
599 |       authorizationUrl: authUrl,
600 |       tokenUrl,
601 |       scopes: ['test-scope'],
602 |     });
603 | 
604 |     // We need this to be an any type because we dig into its private state.
605 |     // eslint-disable-next-line @typescript-eslint/no-explicit-any
606 |     let capturedTransport: any;
607 |     vi.mocked(mockedClient.connect).mockImplementationOnce(
608 |       async (transport) => {
609 |         capturedTransport = transport;
610 |         return Promise.resolve();
611 |       },
612 |     );
613 | 
614 |     const client = await connectToMcpServer(
615 |       'test-server',
616 |       { httpUrl: serverUrl },
617 |       false,
618 |       workspaceContext,
619 |     );
620 | 
621 |     expect(client).toBe(mockedClient);
622 |     expect(mockedClient.connect).toHaveBeenCalledTimes(2);
623 |     expect(mockAuthProvider.authenticate).toHaveBeenCalledOnce();
624 | 
625 |     const authHeader =
626 |       capturedTransport._requestInit?.headers?.['Authorization'];
627 |     expect(authHeader).toBe('Bearer test-access-token');
628 |   });
629 | 
630 |   it('should discover oauth config if not in www-authenticate header', async () => {
631 |     const serverUrl = 'http://test-server.com';
632 |     const authUrl = 'http://auth.example.com/auth';
633 |     const tokenUrl = 'http://auth.example.com/token';
634 | 
635 |     vi.mocked(mockedClient.connect).mockRejectedValueOnce(
636 |       new Error('401 Unauthorized'),
637 |     );
638 | 
639 |     vi.mocked(OAuthUtils.discoverOAuthConfig).mockResolvedValue({
640 |       authorizationUrl: authUrl,
641 |       tokenUrl,
642 |       scopes: ['test-scope'],
643 |     });
[TRUNCATED]
```

src/tools/mcp-client.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { Client } from '@modelcontextprotocol/sdk/client/index.js';
8 | import type { SSEClientTransportOptions } from '@modelcontextprotocol/sdk/client/sse.js';
9 | import { SSEClientTransport } from '@modelcontextprotocol/sdk/client/sse.js';
10 | import { StdioClientTransport } from '@modelcontextprotocol/sdk/client/stdio.js';
11 | import type { StreamableHTTPClientTransportOptions } from '@modelcontextprotocol/sdk/client/streamableHttp.js';
12 | import { StreamableHTTPClientTransport } from '@modelcontextprotocol/sdk/client/streamableHttp.js';
13 | import type { Transport } from '@modelcontextprotocol/sdk/shared/transport.js';
14 | import type {
15 |   GetPromptResult,
16 |   Prompt,
17 | } from '@modelcontextprotocol/sdk/types.js';
18 | import {
19 |   GetPromptResultSchema,
20 |   ListPromptsResultSchema,
21 |   ListRootsRequestSchema,
22 | } from '@modelcontextprotocol/sdk/types.js';
23 | import { parse } from 'shell-quote';
24 | import type { Config, MCPServerConfig } from '../config/config.js';
25 | import { AuthProviderType } from '../config/config.js';
26 | import { GoogleCredentialProvider } from '../mcp/google-auth-provider.js';
27 | import { ServiceAccountImpersonationProvider } from '../mcp/sa-impersonation-provider.js';
28 | import { DiscoveredMCPTool } from './mcp-tool.js';
29 | 
30 | import type { FunctionDeclaration } from '@google/genai';
31 | import { mcpToTool } from '@google/genai';
32 | import { basename } from 'node:path';
33 | import { pathToFileURL } from 'node:url';
34 | import { MCPOAuthProvider } from '../mcp/oauth-provider.js';
35 | import { MCPOAuthTokenStorage } from '../mcp/oauth-token-storage.js';
36 | import { OAuthUtils } from '../mcp/oauth-utils.js';
37 | import type { PromptRegistry } from '../prompts/prompt-registry.js';
38 | import { getErrorMessage } from '../utils/errors.js';
39 | import type {
40 |   Unsubscribe,
41 |   WorkspaceContext,
42 | } from '../utils/workspaceContext.js';
43 | import type { ToolRegistry } from './tool-registry.js';
44 | 
45 | export const MCP_DEFAULT_TIMEOUT_MSEC = 10 * 60 * 1000; // default to 10 minutes
46 | 
47 | export type DiscoveredMCPPrompt = Prompt & {
48 |   serverName: string;
49 |   invoke: (params: Record<string, unknown>) => Promise<GetPromptResult>;
50 | };
51 | 
52 | /**
53 |  * Enum representing the connection status of an MCP server
54 |  */
55 | export enum MCPServerStatus {
56 |   /** Server is disconnected or experiencing errors */
57 |   DISCONNECTED = 'disconnected',
58 |   /** Server is actively disconnecting */
59 |   DISCONNECTING = 'disconnecting',
60 |   /** Server is in the process of connecting */
61 |   CONNECTING = 'connecting',
62 |   /** Server is connected and ready to use */
63 |   CONNECTED = 'connected',
64 | }
65 | 
66 | /**
67 |  * Enum representing the overall MCP discovery state
68 |  */
69 | export enum MCPDiscoveryState {
70 |   /** Discovery has not started yet */
71 |   NOT_STARTED = 'not_started',
72 |   /** Discovery is currently in progress */
73 |   IN_PROGRESS = 'in_progress',
74 |   /** Discovery has completed (with or without errors) */
75 |   COMPLETED = 'completed',
76 | }
77 | 
78 | /**
79 |  * A client for a single MCP server.
80 |  *
81 |  * This class is responsible for connecting to, discovering tools from, and
82 |  * managing the state of a single MCP server.
83 |  */
84 | export class McpClient {
85 |   private client: Client | undefined;
86 |   private transport: Transport | undefined;
87 |   private status: MCPServerStatus = MCPServerStatus.DISCONNECTED;
88 | 
89 |   constructor(
90 |     private readonly serverName: string,
91 |     private readonly serverConfig: MCPServerConfig,
92 |     private readonly toolRegistry: ToolRegistry,
93 |     private readonly promptRegistry: PromptRegistry,
94 |     private readonly workspaceContext: WorkspaceContext,
95 |     private readonly debugMode: boolean,
96 |   ) {}
97 | 
98 |   /**
99 |    * Connects to the MCP server.
100 |    */
101 |   async connect(): Promise<void> {
102 |     if (this.status !== MCPServerStatus.DISCONNECTED) {
103 |       throw new Error(
104 |         `Can only connect when the client is disconnected, current state is ${this.status}`,
105 |       );
106 |     }
107 |     this.updateStatus(MCPServerStatus.CONNECTING);
108 |     try {
109 |       this.client = await connectToMcpServer(
110 |         this.serverName,
111 |         this.serverConfig,
112 |         this.debugMode,
113 |         this.workspaceContext,
114 |       );
115 |       const originalOnError = this.client.onerror;
116 |       this.client.onerror = (error) => {
117 |         if (this.status !== MCPServerStatus.CONNECTED) {
118 |           return;
119 |         }
120 |         if (originalOnError) originalOnError(error);
121 |         console.error(`MCP ERROR (${this.serverName}):`, error.toString());
122 |         this.updateStatus(MCPServerStatus.DISCONNECTED);
123 |       };
124 |       this.updateStatus(MCPServerStatus.CONNECTED);
125 |     } catch (error) {
126 |       this.updateStatus(MCPServerStatus.DISCONNECTED);
127 |       throw error;
128 |     }
129 |   }
130 | 
131 |   /**
132 |    * Discovers tools and prompts from the MCP server.
133 |    */
134 |   async discover(cliConfig: Config): Promise<void> {
135 |     if (this.status !== MCPServerStatus.CONNECTED) {
136 |       throw new Error('Client is not connected.');
137 |     }
138 | 
139 |     const prompts = await this.discoverPrompts();
140 |     const tools = await this.discoverTools(cliConfig);
141 | 
142 |     if (prompts.length === 0 && tools.length === 0) {
143 |       throw new Error('No prompts or tools found on the server.');
144 |     }
145 | 
146 |     for (const tool of tools) {
147 |       this.toolRegistry.registerTool(tool);
148 |     }
149 |   }
150 | 
151 |   /**
152 |    * Disconnects from the MCP server.
153 |    */
154 |   async disconnect(): Promise<void> {
155 |     if (this.status !== MCPServerStatus.CONNECTED) {
156 |       return;
157 |     }
158 |     this.updateStatus(MCPServerStatus.DISCONNECTING);
159 |     const client = this.client;
160 |     this.client = undefined;
161 |     if (this.transport) {
162 |       await this.transport.close();
163 |     }
164 |     if (client) {
165 |       await client.close();
166 |     }
167 |     this.updateStatus(MCPServerStatus.DISCONNECTED);
168 |   }
169 | 
170 |   /**
171 |    * Returns the current status of the client.
172 |    */
173 |   getStatus(): MCPServerStatus {
174 |     return this.status;
175 |   }
176 | 
177 |   private updateStatus(status: MCPServerStatus): void {
178 |     this.status = status;
179 |     updateMCPServerStatus(this.serverName, status);
180 |   }
181 | 
182 |   private assertConnected(): void {
183 |     if (this.status !== MCPServerStatus.CONNECTED) {
184 |       throw new Error(
185 |         `Client is not connected, must connect before interacting with the server. Current state is ${this.status}`,
186 |       );
187 |     }
188 |   }
189 | 
190 |   private async discoverTools(cliConfig: Config): Promise<DiscoveredMCPTool[]> {
191 |     this.assertConnected();
192 |     return discoverTools(
193 |       this.serverName,
194 |       this.serverConfig,
195 |       this.client!,
196 |       cliConfig,
197 |     );
198 |   }
199 | 
200 |   private async discoverPrompts(): Promise<Prompt[]> {
201 |     this.assertConnected();
202 |     return discoverPrompts(this.serverName, this.client!, this.promptRegistry);
203 |   }
204 | }
205 | 
206 | /**
207 |  * Map to track the status of each MCP server within the core package
208 |  */
209 | const serverStatuses: Map<string, MCPServerStatus> = new Map();
210 | 
211 | /**
212 |  * Track the overall MCP discovery state
213 |  */
214 | let mcpDiscoveryState: MCPDiscoveryState = MCPDiscoveryState.NOT_STARTED;
215 | 
216 | /**
217 |  * Map to track which MCP servers have been discovered to require OAuth
218 |  */
219 | export const mcpServerRequiresOAuth: Map<string, boolean> = new Map();
220 | 
221 | /**
222 |  * Event listeners for MCP server status changes
223 |  */
224 | type StatusChangeListener = (
225 |   serverName: string,
226 |   status: MCPServerStatus,
227 | ) => void;
228 | const statusChangeListeners: StatusChangeListener[] = [];
229 | 
230 | /**
231 |  * Add a listener for MCP server status changes
232 |  */
233 | export function addMCPStatusChangeListener(
234 |   listener: StatusChangeListener,
235 | ): void {
236 |   statusChangeListeners.push(listener);
237 | }
238 | 
239 | /**
240 |  * Remove a listener for MCP server status changes
241 |  */
242 | export function removeMCPStatusChangeListener(
243 |   listener: StatusChangeListener,
244 | ): void {
245 |   const index = statusChangeListeners.indexOf(listener);
246 |   if (index !== -1) {
247 |     statusChangeListeners.splice(index, 1);
248 |   }
249 | }
250 | 
251 | /**
252 |  * Update the status of an MCP server
253 |  */
254 | export function updateMCPServerStatus(
255 |   serverName: string,
256 |   status: MCPServerStatus,
257 | ): void {
258 |   serverStatuses.set(serverName, status);
259 |   // Notify all listeners
260 |   for (const listener of statusChangeListeners) {
261 |     listener(serverName, status);
262 |   }
263 | }
264 | 
265 | /**
266 |  * Get the current status of an MCP server
267 |  */
268 | export function getMCPServerStatus(serverName: string): MCPServerStatus {
269 |   return serverStatuses.get(serverName) || MCPServerStatus.DISCONNECTED;
270 | }
271 | 
272 | /**
273 |  * Get all MCP server statuses
274 |  */
275 | export function getAllMCPServerStatuses(): Map<string, MCPServerStatus> {
276 |   return new Map(serverStatuses);
277 | }
278 | 
279 | /**
280 |  * Get the current MCP discovery state
281 |  */
282 | export function getMCPDiscoveryState(): MCPDiscoveryState {
283 |   return mcpDiscoveryState;
284 | }
285 | 
286 | /**
287 |  * Extract WWW-Authenticate header from error message string.
288 |  * This is a more robust approach than regex matching.
289 |  *
290 |  * @param errorString The error message string
291 |  * @returns The www-authenticate header value if found, null otherwise
292 |  */
293 | function extractWWWAuthenticateHeader(errorString: string): string | null {
294 |   // Try multiple patterns to extract the header
295 |   const patterns = [
296 |     /www-authenticate:\s*([^\n\r]+)/i,
297 |     /WWW-Authenticate:\s*([^\n\r]+)/i,
298 |     /"www-authenticate":\s*"([^"]+)"/i,
299 |     /'www-authenticate':\s*'([^']+)'/i,
300 |   ];
301 | 
302 |   for (const pattern of patterns) {
303 |     const match = errorString.match(pattern);
304 |     if (match) {
305 |       return match[1].trim();
306 |     }
307 |   }
308 | 
309 |   return null;
310 | }
311 | 
312 | /**
313 |  * Handle automatic OAuth discovery and authentication for a server.
314 |  *
315 |  * @param mcpServerName The name of the MCP server
316 |  * @param mcpServerConfig The MCP server configuration
317 |  * @param wwwAuthenticate The www-authenticate header value
318 |  * @returns True if OAuth was successfully configured and authenticated, false otherwise
319 |  */
320 | async function handleAutomaticOAuth(
321 |   mcpServerName: string,
322 |   mcpServerConfig: MCPServerConfig,
323 |   wwwAuthenticate: string,
324 | ): Promise<boolean> {
325 |   try {
326 |     console.log(`🔐 '${mcpServerName}' requires OAuth authentication`);
327 | 
328 |     // Always try to parse the resource metadata URI from the www-authenticate header
329 |     let oauthConfig;
330 |     const resourceMetadataUri =
331 |       OAuthUtils.parseWWWAuthenticateHeader(wwwAuthenticate);
332 |     if (resourceMetadataUri) {
333 |       oauthConfig = await OAuthUtils.discoverOAuthConfig(resourceMetadataUri);
334 |     } else if (hasNetworkTransport(mcpServerConfig)) {
335 |       // Fallback: try to discover OAuth config from the base URL
336 |       const serverUrl = new URL(
337 |         mcpServerConfig.httpUrl || mcpServerConfig.url!,
338 |       );
339 |       const baseUrl = `${serverUrl.protocol}//${serverUrl.host}`;
340 |       oauthConfig = await OAuthUtils.discoverOAuthConfig(baseUrl);
341 |     }
342 | 
343 |     if (!oauthConfig) {
344 |       console.error(
345 |         `❌ Could not configure OAuth for '${mcpServerName}' - please authenticate manually with /mcp auth ${mcpServerName}`,
346 |       );
347 |       return false;
348 |     }
349 | 
350 |     // OAuth configuration discovered - proceed with authentication
351 | 
352 |     // Create OAuth configuration for authentication
353 |     const oauthAuthConfig = {
354 |       enabled: true,
355 |       authorizationUrl: oauthConfig.authorizationUrl,
356 |       tokenUrl: oauthConfig.tokenUrl,
357 |       scopes: oauthConfig.scopes || [],
358 |     };
359 | 
360 |     // Perform OAuth authentication
361 |     // Pass the server URL for proper discovery
362 |     const serverUrl = mcpServerConfig.httpUrl || mcpServerConfig.url;
363 |     console.log(
364 |       `Starting OAuth authentication for server '${mcpServerName}'...`,
365 |     );
366 |     const authProvider = new MCPOAuthProvider(new MCPOAuthTokenStorage());
367 |     await authProvider.authenticate(mcpServerName, oauthAuthConfig, serverUrl);
368 | 
369 |     console.log(
370 |       `OAuth authentication successful for server '${mcpServerName}'`,
371 |     );
372 |     return true;
373 |   } catch (error) {
374 |     console.error(
375 |       `Failed to handle automatic OAuth for server '${mcpServerName}': ${getErrorMessage(error)}`,
376 |     );
377 |     return false;
378 |   }
379 | }
380 | 
381 | /**
382 |  * Create a transport with OAuth token for the given server configuration.
383 |  *
384 |  * @param mcpServerName The name of the MCP server
385 |  * @param mcpServerConfig The MCP server configuration
386 |  * @param accessToken The OAuth access token
387 |  * @returns The transport with OAuth token, or null if creation fails
388 |  */
389 | async function createTransportWithOAuth(
390 |   mcpServerName: string,
391 |   mcpServerConfig: MCPServerConfig,
392 |   accessToken: string,
393 | ): Promise<StreamableHTTPClientTransport | SSEClientTransport | null> {
394 |   try {
395 |     if (mcpServerConfig.httpUrl) {
396 |       // Create HTTP transport with OAuth token
397 |       const oauthTransportOptions: StreamableHTTPClientTransportOptions = {
398 |         requestInit: {
399 |           headers: {
400 |             ...mcpServerConfig.headers,
401 |             Authorization: `Bearer ${accessToken}`,
402 |           },
403 |         },
404 |       };
405 | 
406 |       return new StreamableHTTPClientTransport(
407 |         new URL(mcpServerConfig.httpUrl),
408 |         oauthTransportOptions,
409 |       );
410 |     } else if (mcpServerConfig.url) {
411 |       // Create SSE transport with OAuth token in Authorization header
412 |       return new SSEClientTransport(new URL(mcpServerConfig.url), {
413 |         requestInit: {
414 |           headers: {
415 |             ...mcpServerConfig.headers,
416 |             Authorization: `Bearer ${accessToken}`,
417 |           },
418 |         },
419 |       });
420 |     }
421 | 
422 |     return null;
423 |   } catch (error) {
424 |     console.error(
425 |       `Failed to create OAuth transport for server '${mcpServerName}': ${getErrorMessage(error)}`,
426 |     );
427 |     return null;
428 |   }
429 | }
430 | 
431 | /**
432 |  * Discovers tools from all configured MCP servers and registers them with the tool registry.
433 |  * It orchestrates the connection and discovery process for each server defined in the
434 |  * configuration, as well as any server specified via a command-line argument.
435 |  *
436 |  * @param mcpServers A record of named MCP server configurations.
437 |  * @param mcpServerCommand An optional command string for a dynamically specified MCP server.
438 |  * @param toolRegistry The central registry where discovered tools will be registered.
439 |  * @returns A promise that resolves when the discovery process has been attempted for all servers.
440 |  */
441 | 
442 | export async function discoverMcpTools(
443 |   mcpServers: Record<string, MCPServerConfig>,
444 |   mcpServerCommand: string | undefined,
445 |   toolRegistry: ToolRegistry,
446 |   promptRegistry: PromptRegistry,
447 |   debugMode: boolean,
448 |   workspaceContext: WorkspaceContext,
449 |   cliConfig: Config,
450 | ): Promise<void> {
451 |   mcpDiscoveryState = MCPDiscoveryState.IN_PROGRESS;
452 |   try {
453 |     mcpServers = populateMcpServerCommand(mcpServers, mcpServerCommand);
454 | 
455 |     const discoveryPromises = Object.entries(mcpServers).map(
456 |       ([mcpServerName, mcpServerConfig]) =>
457 |         connectAndDiscover(
458 |           mcpServerName,
459 |           mcpServerConfig,
460 |           toolRegistry,
461 |           promptRegistry,
462 |           debugMode,
463 |           workspaceContext,
464 |           cliConfig,
465 |         ),
466 |     );
467 |     await Promise.all(discoveryPromises);
468 |   } finally {
469 |     mcpDiscoveryState = MCPDiscoveryState.COMPLETED;
470 |   }
471 | }
472 | 
473 | /** Visible for Testing */
474 | export function populateMcpServerCommand(
475 |   mcpServers: Record<string, MCPServerConfig>,
476 |   mcpServerCommand: string | undefined,
477 | ): Record<string, MCPServerConfig> {
478 |   if (mcpServerCommand) {
479 |     const cmd = mcpServerCommand;
480 |     const args = parse(cmd, process.env) as string[];
481 |     if (args.some((arg) => typeof arg !== 'string')) {
482 |       throw new Error('failed to parse mcpServerCommand: ' + cmd);
483 |     }
484 |     // use generic server name 'mcp'
485 |     mcpServers['mcp'] = {
486 |       command: args[0],
487 |       args: args.slice(1),
488 |     };
489 |   }
490 |   return mcpServers;
491 | }
492 | 
493 | /**
494 |  * Connects to an MCP server and discovers available tools, registering them with the tool registry.
495 |  * This function handles the complete lifecycle of connecting to a server, discovering tools,
496 |  * and cleaning up resources if no tools are found.
497 |  *
498 |  * @param mcpServerName The name identifier for this MCP server
499 |  * @param mcpServerConfig Configuration object containing connection details
500 |  * @param toolRegistry The registry to register discovered tools with
501 |  * @returns Promise that resolves when discovery is complete
502 |  */
503 | export async function connectAndDiscover(
504 |   mcpServerName: string,
505 |   mcpServerConfig: MCPServerConfig,
506 |   toolRegistry: ToolRegistry,
507 |   promptRegistry: PromptRegistry,
508 |   debugMode: boolean,
509 |   workspaceContext: WorkspaceContext,
510 |   cliConfig: Config,
511 | ): Promise<void> {
512 |   updateMCPServerStatus(mcpServerName, MCPServerStatus.CONNECTING);
513 | 
514 |   let mcpClient: Client | undefined;
515 |   try {
516 |     mcpClient = await connectToMcpServer(
517 |       mcpServerName,
518 |       mcpServerConfig,
519 |       debugMode,
520 |       workspaceContext,
521 |     );
522 | 
523 |     mcpClient.onerror = (error) => {
524 |       console.error(`MCP ERROR (${mcpServerName}):`, error.toString());
525 |       updateMCPServerStatus(mcpServerName, MCPServerStatus.DISCONNECTED);
526 |     };
527 | 
528 |     // Attempt to discover both prompts and tools
529 |     const prompts = await discoverPrompts(
530 |       mcpServerName,
531 |       mcpClient,
532 |       promptRegistry,
533 |     );
534 |     const tools = await discoverTools(
535 |       mcpServerName,
536 |       mcpServerConfig,
537 |       mcpClient,
538 |       cliConfig,
539 |     );
540 | 
541 |     // If we have neither prompts nor tools, it's a failed discovery
542 |     if (prompts.length === 0 && tools.length === 0) {
543 |       throw new Error('No prompts or tools found on the server.');
544 |     }
545 | 
546 |     // If we found anything, the server is connected
547 |     updateMCPServerStatus(mcpServerName, MCPServerStatus.CONNECTED);
548 | 
549 |     // Register any discovered tools
550 |     for (const tool of tools) {
551 |       toolRegistry.registerTool(tool);
552 |     }
553 |   } catch (error) {
554 |     if (mcpClient) {
555 |       mcpClient.close();
556 |     }
557 |     console.error(
558 |       `Error connecting to MCP server '${mcpServerName}': ${getErrorMessage(
559 |         error,
560 |       )}`,
561 |     );
562 |     updateMCPServerStatus(mcpServerName, MCPServerStatus.DISCONNECTED);
563 |   }
564 | }
565 | 
566 | /**
567 |  * Discovers and sanitizes tools from a connected MCP client.
568 |  * It retrieves function declarations from the client, filters out disabled tools,
569 |  * generates valid names for them, and wraps them in `DiscoveredMCPTool` instances.
570 |  *
571 |  * @param mcpServerName The name of the MCP server.
572 |  * @param mcpServerConfig The configuration for the MCP server.
573 |  * @param mcpClient The active MCP client instance.
574 |  * @returns A promise that resolves to an array of discovered and enabled tools.
575 |  * @throws An error if no enabled tools are found or if the server provides invalid function declarations.
576 |  */
577 | export async function discoverTools(
578 |   mcpServerName: string,
579 |   mcpServerConfig: MCPServerConfig,
580 |   mcpClient: Client,
581 |   cliConfig: Config,
582 | ): Promise<DiscoveredMCPTool[]> {
583 |   try {
584 |     // Only request tools if the server supports them.
585 |     if (mcpClient.getServerCapabilities()?.tools == null) return [];
586 | 
587 |     const mcpCallableTool = mcpToTool(mcpClient, {
588 |       timeout: mcpServerConfig.timeout ?? MCP_DEFAULT_TIMEOUT_MSEC,
589 |     });
590 |     const tool = await mcpCallableTool.tool();
591 | 
592 |     if (!Array.isArray(tool.functionDeclarations)) {
593 |       // This is a valid case for a prompt-only server
594 |       return [];
595 |     }
596 | 
597 |     const discoveredTools: DiscoveredMCPTool[] = [];
598 |     for (const funcDecl of tool.functionDeclarations) {
599 |       try {
600 |         if (!isEnabled(funcDecl, mcpServerName, mcpServerConfig)) {
601 |           continue;
602 |         }
603 | 
604 |         discoveredTools.push(
605 |           new DiscoveredMCPTool(
606 |             mcpCallableTool,
607 |             mcpServerName,
608 |             funcDecl.name!,
609 |             funcDecl.description ?? '',
610 |             funcDecl.parametersJsonSchema ?? { type: 'object', properties: {} },
611 |             mcpServerConfig.trust,
612 |             undefined,
613 |             cliConfig,
614 |           ),
615 |         );
616 |       } catch (error) {
617 |         console.error(
[TRUNCATED]
```

src/tools/mcp-tool.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /* eslint-disable @typescript-eslint/no-explicit-any */
8 | import type { Mocked } from 'vitest';
9 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
10 | import { safeJsonStringify } from '../utils/safeJsonStringify.js';
11 | import { DiscoveredMCPTool, generateValidName } from './mcp-tool.js'; // Added getStringifiedResultForDisplay
12 | import type { ToolResult } from './tools.js';
13 | import { ToolConfirmationOutcome } from './tools.js'; // Added ToolConfirmationOutcome
14 | import type { CallableTool, Part } from '@google/genai';
15 | import { ToolErrorType } from './tool-error.js';
16 | 
17 | // Mock @google/genai mcpToTool and CallableTool
18 | // We only need to mock the parts of CallableTool that DiscoveredMCPTool uses.
19 | const mockCallTool = vi.fn();
20 | const mockToolMethod = vi.fn();
21 | 
22 | const mockCallableToolInstance: Mocked<CallableTool> = {
23 |   tool: mockToolMethod as any, // Not directly used by DiscoveredMCPTool instance methods
24 |   callTool: mockCallTool as any,
25 |   // Add other methods if DiscoveredMCPTool starts using them
26 | };
27 | 
28 | describe('generateValidName', () => {
29 |   it('should return a valid name for a simple function', () => {
30 |     expect(generateValidName('myFunction')).toBe('myFunction');
31 |   });
32 | 
33 |   it('should replace invalid characters with underscores', () => {
34 |     expect(generateValidName('invalid-name with spaces')).toBe(
35 |       'invalid-name_with_spaces',
36 |     );
37 |   });
38 | 
39 |   it('should truncate long names', () => {
40 |     expect(generateValidName('x'.repeat(80))).toBe(
41 |       'xxxxxxxxxxxxxxxxxxxxxxxxxxxx___xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx',
42 |     );
43 |   });
44 | 
45 |   it('should handle names with only invalid characters', () => {
46 |     expect(generateValidName('!@#$%^&*()')).toBe('__________');
47 |   });
48 | 
49 |   it('should handle names that are exactly 63 characters long', () => {
50 |     expect(generateValidName('a'.repeat(63)).length).toBe(63);
51 |   });
52 | 
53 |   it('should handle names that are exactly 64 characters long', () => {
54 |     expect(generateValidName('a'.repeat(64)).length).toBe(63);
55 |   });
56 | 
57 |   it('should handle names that are longer than 64 characters', () => {
58 |     expect(generateValidName('a'.repeat(80)).length).toBe(63);
59 |   });
60 | });
61 | 
62 | describe('DiscoveredMCPTool', () => {
63 |   const serverName = 'mock-mcp-server';
64 |   const serverToolName = 'actual-server-tool-name';
65 |   const baseDescription = 'A test MCP tool.';
66 |   const inputSchema: Record<string, unknown> = {
67 |     type: 'object' as const,
68 |     properties: { param: { type: 'string' } },
69 |     required: ['param'],
70 |   };
71 | 
72 |   let tool: DiscoveredMCPTool;
73 | 
74 |   beforeEach(() => {
75 |     mockCallTool.mockClear();
76 |     mockToolMethod.mockClear();
77 |     tool = new DiscoveredMCPTool(
78 |       mockCallableToolInstance,
79 |       serverName,
80 |       serverToolName,
81 |       baseDescription,
82 |       inputSchema,
83 |     );
84 |     // Clear allowlist before each relevant test, especially for shouldConfirmExecute
85 |     const invocation = tool.build({ param: 'mock' }) as any;
86 |     invocation.constructor.allowlist.clear();
87 |   });
88 | 
89 |   afterEach(() => {
90 |     vi.restoreAllMocks();
91 |   });
92 | 
93 |   describe('constructor', () => {
94 |     it('should set properties correctly', () => {
95 |       expect(tool.name).toBe(serverToolName);
96 |       expect(tool.schema.name).toBe(serverToolName);
97 |       expect(tool.schema.description).toBe(baseDescription);
98 |       expect(tool.schema.parameters).toBeUndefined();
99 |       expect(tool.schema.parametersJsonSchema).toEqual(inputSchema);
100 |       expect(tool.serverToolName).toBe(serverToolName);
101 |     });
102 |   });
103 | 
104 |   describe('execute', () => {
105 |     it('should call mcpTool.callTool with correct parameters and format display output', async () => {
106 |       const params = { param: 'testValue' };
107 |       const mockToolSuccessResultObject = {
108 |         success: true,
109 |         details: 'executed',
110 |       };
111 |       const mockFunctionResponseContent = [
112 |         {
113 |           type: 'text',
114 |           text: JSON.stringify(mockToolSuccessResultObject),
115 |         },
116 |       ];
117 |       const mockMcpToolResponseParts: Part[] = [
118 |         {
119 |           functionResponse: {
120 |             name: serverToolName,
121 |             response: { content: mockFunctionResponseContent },
122 |           },
123 |         },
124 |       ];
125 |       mockCallTool.mockResolvedValue(mockMcpToolResponseParts);
126 | 
127 |       const invocation = tool.build(params);
128 |       const toolResult: ToolResult = await invocation.execute(
129 |         new AbortController().signal,
130 |       );
131 | 
132 |       expect(mockCallTool).toHaveBeenCalledWith([
133 |         { name: serverToolName, args: params },
134 |       ]);
135 | 
136 |       const stringifiedResponseContent = JSON.stringify(
137 |         mockToolSuccessResultObject,
138 |       );
139 |       expect(toolResult.llmContent).toEqual([
140 |         { text: stringifiedResponseContent },
141 |       ]);
142 |       expect(toolResult.returnDisplay).toBe(stringifiedResponseContent);
143 |     });
144 | 
145 |     it('should handle empty result from getStringifiedResultForDisplay', async () => {
146 |       const params = { param: 'testValue' };
147 |       const mockMcpToolResponsePartsEmpty: Part[] = [];
148 |       mockCallTool.mockResolvedValue(mockMcpToolResponsePartsEmpty);
149 |       const invocation = tool.build(params);
150 |       const toolResult: ToolResult = await invocation.execute(
151 |         new AbortController().signal,
152 |       );
153 |       expect(toolResult.returnDisplay).toBe('```json\n[]\n```');
154 |       expect(toolResult.llmContent).toEqual([
155 |         { text: '[Error: Could not parse tool response]' },
156 |       ]);
157 |     });
158 | 
159 |     it('should propagate rejection if mcpTool.callTool rejects', async () => {
160 |       const params = { param: 'failCase' };
161 |       const expectedError = new Error('MCP call failed');
162 |       mockCallTool.mockRejectedValue(expectedError);
163 | 
164 |       const invocation = tool.build(params);
165 |       await expect(
166 |         invocation.execute(new AbortController().signal),
167 |       ).rejects.toThrow(expectedError);
168 |     });
169 | 
170 |     it.each([
171 |       { isErrorValue: true, description: 'true (bool)' },
172 |       { isErrorValue: 'true', description: '"true" (str)' },
173 |     ])(
174 |       'should return a structured error if MCP tool reports an error',
175 |       async ({ isErrorValue }) => {
176 |         const tool = new DiscoveredMCPTool(
177 |           mockCallableToolInstance,
178 |           serverName,
179 |           serverToolName,
180 |           baseDescription,
181 |           inputSchema,
182 |         );
183 |         const params = { param: 'isErrorTrueCase' };
184 |         const functionCall = {
185 |           name: serverToolName,
186 |           args: params,
187 |         };
188 | 
189 |         const errorResponse = { isError: isErrorValue };
190 |         const mockMcpToolResponseParts: Part[] = [
191 |           {
192 |             functionResponse: {
193 |               name: serverToolName,
194 |               response: { error: errorResponse },
195 |             },
196 |           },
197 |         ];
198 |         mockCallTool.mockResolvedValue(mockMcpToolResponseParts);
199 |         const expectedErrorMessage = `MCP tool '${
200 |           serverToolName
201 |         }' reported tool error for function call: ${safeJsonStringify(
202 |           functionCall,
203 |         )} with response: ${safeJsonStringify(mockMcpToolResponseParts)}`;
204 |         const invocation = tool.build(params);
205 |         const result = await invocation.execute(new AbortController().signal);
206 | 
207 |         expect(result.error?.type).toBe(ToolErrorType.MCP_TOOL_ERROR);
208 |         expect(result.llmContent).toBe(expectedErrorMessage);
209 |         expect(result.returnDisplay).toContain(
210 |           `Error: MCP tool '${serverToolName}' reported an error.`,
211 |         );
212 |       },
213 |     );
214 | 
215 |     it.each([
216 |       { isErrorValue: false, description: 'false (bool)' },
217 |       { isErrorValue: 'false', description: '"false" (str)' },
218 |     ])(
219 |       'should consider a ToolResult with isError ${description} to be a success',
220 |       async ({ isErrorValue }) => {
221 |         const tool = new DiscoveredMCPTool(
222 |           mockCallableToolInstance,
223 |           serverName,
224 |           serverToolName,
225 |           baseDescription,
226 |           inputSchema,
227 |         );
228 |         const params = { param: 'isErrorFalseCase' };
229 |         const mockToolSuccessResultObject = {
230 |           success: true,
231 |           details: 'executed',
232 |         };
233 |         const mockFunctionResponseContent = [
234 |           {
235 |             type: 'text',
236 |             text: JSON.stringify(mockToolSuccessResultObject),
237 |           },
238 |         ];
239 | 
240 |         const errorResponse = { isError: isErrorValue };
241 |         const mockMcpToolResponseParts: Part[] = [
242 |           {
243 |             functionResponse: {
244 |               name: serverToolName,
245 |               response: {
246 |                 error: errorResponse,
247 |                 content: mockFunctionResponseContent,
248 |               },
249 |             },
250 |           },
251 |         ];
252 |         mockCallTool.mockResolvedValue(mockMcpToolResponseParts);
253 | 
254 |         const invocation = tool.build(params);
255 |         const toolResult = await invocation.execute(
256 |           new AbortController().signal,
257 |         );
258 | 
259 |         const stringifiedResponseContent = JSON.stringify(
260 |           mockToolSuccessResultObject,
261 |         );
262 |         expect(toolResult.llmContent).toEqual([
263 |           { text: stringifiedResponseContent },
264 |         ]);
265 |         expect(toolResult.returnDisplay).toBe(stringifiedResponseContent);
266 |       },
267 |     );
268 | 
269 |     it('should handle a simple text response correctly', async () => {
270 |       const params = { param: 'test' };
271 |       const successMessage = 'This is a success message.';
272 | 
273 |       // Simulate the response from the GenAI SDK, which wraps the MCP
274 |       // response in a functionResponse Part.
275 |       const sdkResponse: Part[] = [
276 |         {
277 |           functionResponse: {
278 |             name: serverToolName,
279 |             response: {
280 |               // The `content` array contains MCP ContentBlocks.
281 |               content: [{ type: 'text', text: successMessage }],
282 |             },
283 |           },
284 |         },
285 |       ];
286 |       mockCallTool.mockResolvedValue(sdkResponse);
287 | 
288 |       const invocation = tool.build(params);
289 |       const toolResult = await invocation.execute(new AbortController().signal);
290 | 
291 |       // 1. Assert that the llmContent sent to the scheduler is a clean Part array.
292 |       expect(toolResult.llmContent).toEqual([{ text: successMessage }]);
293 | 
294 |       // 2. Assert that the display output is the simple text message.
295 |       expect(toolResult.returnDisplay).toBe(successMessage);
296 | 
297 |       // 3. Verify that the underlying callTool was made correctly.
298 |       expect(mockCallTool).toHaveBeenCalledWith([
299 |         { name: serverToolName, args: params },
300 |       ]);
301 |     });
302 | 
303 |     it('should handle an AudioBlock response', async () => {
304 |       const params = { param: 'play' };
305 |       const sdkResponse: Part[] = [
306 |         {
307 |           functionResponse: {
308 |             name: serverToolName,
309 |             response: {
310 |               content: [
311 |                 {
312 |                   type: 'audio',
313 |                   data: 'BASE64_AUDIO_DATA',
314 |                   mimeType: 'audio/mp3',
315 |                 },
316 |               ],
317 |             },
318 |           },
319 |         },
320 |       ];
321 |       mockCallTool.mockResolvedValue(sdkResponse);
322 | 
323 |       const invocation = tool.build(params);
324 |       const toolResult = await invocation.execute(new AbortController().signal);
325 | 
326 |       expect(toolResult.llmContent).toEqual([
327 |         {
328 |           text: `[Tool '${serverToolName}' provided the following audio data with mime-type: audio/mp3]`,
329 |         },
330 |         {
331 |           inlineData: {
332 |             mimeType: 'audio/mp3',
333 |             data: 'BASE64_AUDIO_DATA',
334 |           },
335 |         },
336 |       ]);
337 |       expect(toolResult.returnDisplay).toBe('[Audio: audio/mp3]');
338 |     });
339 | 
340 |     it('should handle a ResourceLinkBlock response', async () => {
341 |       const params = { param: 'get' };
342 |       const sdkResponse: Part[] = [
343 |         {
344 |           functionResponse: {
345 |             name: serverToolName,
346 |             response: {
347 |               content: [
348 |                 {
349 |                   type: 'resource_link',
350 |                   uri: 'file:///path/to/thing',
351 |                   name: 'resource-name',
352 |                   title: 'My Resource',
353 |                 },
354 |               ],
355 |             },
356 |           },
357 |         },
358 |       ];
359 |       mockCallTool.mockResolvedValue(sdkResponse);
360 | 
361 |       const invocation = tool.build(params);
362 |       const toolResult = await invocation.execute(new AbortController().signal);
363 | 
364 |       expect(toolResult.llmContent).toEqual([
365 |         {
366 |           text: 'Resource Link: My Resource at file:///path/to/thing',
367 |         },
368 |       ]);
369 |       expect(toolResult.returnDisplay).toBe(
370 |         '[Link to My Resource: file:///path/to/thing]',
371 |       );
372 |     });
373 | 
374 |     it('should handle an embedded text ResourceBlock response', async () => {
375 |       const params = { param: 'get' };
376 |       const sdkResponse: Part[] = [
377 |         {
378 |           functionResponse: {
379 |             name: serverToolName,
380 |             response: {
381 |               content: [
382 |                 {
383 |                   type: 'resource',
384 |                   resource: {
385 |                     uri: 'file:///path/to/text.txt',
386 |                     text: 'This is the text content.',
387 |                     mimeType: 'text/plain',
388 |                   },
389 |                 },
390 |               ],
391 |             },
392 |           },
393 |         },
394 |       ];
395 |       mockCallTool.mockResolvedValue(sdkResponse);
396 | 
397 |       const invocation = tool.build(params);
398 |       const toolResult = await invocation.execute(new AbortController().signal);
399 | 
400 |       expect(toolResult.llmContent).toEqual([
401 |         { text: 'This is the text content.' },
402 |       ]);
403 |       expect(toolResult.returnDisplay).toBe('This is the text content.');
404 |     });
405 | 
406 |     it('should handle an embedded binary ResourceBlock response', async () => {
407 |       const params = { param: 'get' };
408 |       const sdkResponse: Part[] = [
409 |         {
410 |           functionResponse: {
411 |             name: serverToolName,
412 |             response: {
413 |               content: [
414 |                 {
415 |                   type: 'resource',
416 |                   resource: {
417 |                     uri: 'file:///path/to/data.bin',
418 |                     blob: 'BASE64_BINARY_DATA',
419 |                     mimeType: 'application/octet-stream',
420 |                   },
421 |                 },
422 |               ],
423 |             },
424 |           },
425 |         },
426 |       ];
427 |       mockCallTool.mockResolvedValue(sdkResponse);
428 | 
429 |       const invocation = tool.build(params);
430 |       const toolResult = await invocation.execute(new AbortController().signal);
431 | 
432 |       expect(toolResult.llmContent).toEqual([
433 |         {
434 |           text: `[Tool '${serverToolName}' provided the following embedded resource with mime-type: application/octet-stream]`,
435 |         },
436 |         {
437 |           inlineData: {
438 |             mimeType: 'application/octet-stream',
439 |             data: 'BASE64_BINARY_DATA',
440 |           },
441 |         },
442 |       ]);
443 |       expect(toolResult.returnDisplay).toBe(
444 |         '[Embedded Resource: application/octet-stream]',
445 |       );
446 |     });
447 | 
448 |     it('should handle a mix of content block types', async () => {
449 |       const params = { param: 'complex' };
450 |       const sdkResponse: Part[] = [
451 |         {
452 |           functionResponse: {
453 |             name: serverToolName,
454 |             response: {
455 |               content: [
456 |                 { type: 'text', text: 'First part.' },
457 |                 {
458 |                   type: 'image',
459 |                   data: 'BASE64_IMAGE_DATA',
460 |                   mimeType: 'image/jpeg',
461 |                 },
462 |                 { type: 'text', text: 'Second part.' },
463 |               ],
464 |             },
465 |           },
466 |         },
467 |       ];
468 |       mockCallTool.mockResolvedValue(sdkResponse);
469 | 
470 |       const invocation = tool.build(params);
471 |       const toolResult = await invocation.execute(new AbortController().signal);
472 | 
473 |       expect(toolResult.llmContent).toEqual([
474 |         { text: 'First part.' },
475 |         {
476 |           text: `[Tool '${serverToolName}' provided the following image data with mime-type: image/jpeg]`,
477 |         },
478 |         {
479 |           inlineData: {
480 |             mimeType: 'image/jpeg',
481 |             data: 'BASE64_IMAGE_DATA',
482 |           },
483 |         },
484 |         { text: 'Second part.' },
485 |       ]);
486 |       expect(toolResult.returnDisplay).toBe(
487 |         'First part.\n[Image: image/jpeg]\nSecond part.',
488 |       );
489 |     });
490 | 
491 |     it('should ignore unknown content block types', async () => {
492 |       const params = { param: 'test' };
493 |       const sdkResponse: Part[] = [
494 |         {
495 |           functionResponse: {
496 |             name: serverToolName,
497 |             response: {
498 |               content: [
499 |                 { type: 'text', text: 'Valid part.' },
500 |                 { type: 'future_block', data: 'some-data' },
501 |               ],
502 |             },
503 |           },
504 |         },
505 |       ];
506 |       mockCallTool.mockResolvedValue(sdkResponse);
507 | 
508 |       const invocation = tool.build(params);
509 |       const toolResult = await invocation.execute(new AbortController().signal);
510 | 
511 |       expect(toolResult.llmContent).toEqual([{ text: 'Valid part.' }]);
512 |       expect(toolResult.returnDisplay).toBe(
513 |         'Valid part.\n[Unknown content type: future_block]',
514 |       );
515 |     });
516 | 
517 |     it('should handle a complex mix of content block types', async () => {
518 |       const params = { param: 'super-complex' };
519 |       const sdkResponse: Part[] = [
520 |         {
521 |           functionResponse: {
522 |             name: serverToolName,
523 |             response: {
524 |               content: [
525 |                 { type: 'text', text: 'Here is a resource.' },
526 |                 {
527 |                   type: 'resource_link',
528 |                   uri: 'file:///path/to/resource',
529 |                   name: 'resource-name',
530 |                   title: 'My Resource',
531 |                 },
532 |                 {
533 |                   type: 'resource',
534 |                   resource: {
535 |                     uri: 'file:///path/to/text.txt',
536 |                     text: 'Embedded text content.',
537 |                     mimeType: 'text/plain',
538 |                   },
539 |                 },
540 |                 {
541 |                   type: 'image',
542 |                   data: 'BASE64_IMAGE_DATA',
543 |                   mimeType: 'image/jpeg',
544 |                 },
545 |               ],
546 |             },
547 |           },
548 |         },
549 |       ];
550 |       mockCallTool.mockResolvedValue(sdkResponse);
551 | 
552 |       const invocation = tool.build(params);
553 |       const toolResult = await invocation.execute(new AbortController().signal);
554 | 
555 |       expect(toolResult.llmContent).toEqual([
556 |         { text: 'Here is a resource.' },
557 |         {
558 |           text: 'Resource Link: My Resource at file:///path/to/resource',
559 |         },
560 |         { text: 'Embedded text content.' },
561 |         {
562 |           text: `[Tool '${serverToolName}' provided the following image data with mime-type: image/jpeg]`,
563 |         },
564 |         {
565 |           inlineData: {
566 |             mimeType: 'image/jpeg',
567 |             data: 'BASE64_IMAGE_DATA',
568 |           },
569 |         },
570 |       ]);
571 |       expect(toolResult.returnDisplay).toBe(
572 |         'Here is a resource.\n[Link to My Resource: file:///path/to/resource]\nEmbedded text content.\n[Image: image/jpeg]',
573 |       );
574 |     });
575 | 
576 |     describe('AbortSignal support', () => {
577 |       it('should abort immediately if signal is already aborted', async () => {
578 |         const params = { param: 'test' };
579 |         const controller = new AbortController();
580 |         controller.abort();
581 | 
582 |         const invocation = tool.build(params);
583 | 
584 |         await expect(invocation.execute(controller.signal)).rejects.toThrow(
585 |           'Tool call aborted',
586 |         );
587 | 
588 |         // Tool should not be called if signal is already aborted
589 |         expect(mockCallTool).not.toHaveBeenCalled();
590 |       });
591 | 
592 |       it('should abort during tool execution', async () => {
593 |         const params = { param: 'test' };
594 |         const controller = new AbortController();
595 | 
596 |         // Mock a delayed response to simulate long-running tool
597 |         mockCallTool.mockImplementation(
598 |           () =>
599 |             new Promise((resolve) => {
600 |               setTimeout(() => {
601 |                 resolve([
602 |                   {
603 |                     functionResponse: {
604 |                       name: serverToolName,
605 |                       response: {
606 |                         content: [{ type: 'text', text: 'Success' }],
607 |                       },
608 |                     },
609 |                   },
610 |                 ]);
611 |               }, 1000);
612 |             }),
613 |         );
614 | 
615 |         const invocation = tool.build(params);
616 |         const promise = invocation.execute(controller.signal);
617 | 
618 |         // Abort after a short delay to simulate cancellation during execution
619 |         setTimeout(() => controller.abort(), 50);
620 | 
621 |         await expect(promise).rejects.toThrow('Tool call aborted');
622 |       });
623 | 
624 |       it('should complete successfully if not aborted', async () => {
625 |         const params = { param: 'test' };
626 |         const controller = new AbortController();
627 |         const successResponse = [
628 |           {
629 |             functionResponse: {
630 |               name: serverToolName,
631 |               response: {
632 |                 content: [{ type: 'text', text: 'Success' }],
633 |               },
634 |             },
635 |           },
636 |         ];
637 | 
638 |         mockCallTool.mockResolvedValue(successResponse);
639 | 
640 |         const invocation = tool.build(params);
641 |         const result = await invocation.execute(controller.signal);
642 | 
643 |         expect(result.llmContent).toEqual([{ text: 'Success' }]);
644 |         expect(result.returnDisplay).toBe('Success');
645 |         expect(mockCallTool).toHaveBeenCalledWith([
646 |           { name: serverToolName, args: params },
647 |         ]);
648 |       });
649 | 
650 |       it('should handle tool error even when abort signal is provided', async () => {
651 |         const params = { param: 'test' };
652 |         const controller = new AbortController();
653 |         const errorResponse = [
654 |           {
655 |             functionResponse: {
656 |               name: serverToolName,
657 |               response: { error: { isError: true } },
658 |             },
659 |           },
660 |         ];
661 | 
662 |         mockCallTool.mockResolvedValue(errorResponse);
663 | 
664 |         const invocation = tool.build(params);
665 |         const result = await invocation.execute(controller.signal);
666 | 
667 |         expect(result.error?.type).toBe(ToolErrorType.MCP_TOOL_ERROR);
668 |         expect(result.returnDisplay).toContain(
[TRUNCATED]
```

src/tools/mcp-tool.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { safeJsonStringify } from '../utils/safeJsonStringify.js';
8 | import type {
9 |   ToolCallConfirmationDetails,
10 |   ToolInvocation,
11 |   ToolMcpConfirmationDetails,
12 |   ToolResult,
13 | } from './tools.js';
14 | import {
15 |   BaseDeclarativeTool,
16 |   BaseToolInvocation,
17 |   Kind,
18 |   ToolConfirmationOutcome,
19 | } from './tools.js';
20 | import type { CallableTool, FunctionCall, Part } from '@google/genai';
21 | import { ToolErrorType } from './tool-error.js';
22 | import type { Config } from '../config/config.js';
23 | 
24 | type ToolParams = Record<string, unknown>;
25 | 
26 | // Discriminated union for MCP Content Blocks to ensure type safety.
27 | type McpTextBlock = {
28 |   type: 'text';
29 |   text: string;
30 | };
31 | 
32 | type McpMediaBlock = {
33 |   type: 'image' | 'audio';
34 |   mimeType: string;
35 |   data: string;
36 | };
37 | 
38 | type McpResourceBlock = {
39 |   type: 'resource';
40 |   resource: {
41 |     text?: string;
42 |     blob?: string;
43 |     mimeType?: string;
44 |   };
45 | };
46 | 
47 | type McpResourceLinkBlock = {
48 |   type: 'resource_link';
49 |   uri: string;
50 |   title?: string;
51 |   name?: string;
52 | };
53 | 
54 | type McpContentBlock =
55 |   | McpTextBlock
56 |   | McpMediaBlock
57 |   | McpResourceBlock
58 |   | McpResourceLinkBlock;
59 | 
60 | class DiscoveredMCPToolInvocation extends BaseToolInvocation<
61 |   ToolParams,
62 |   ToolResult
63 | > {
64 |   private static readonly allowlist: Set<string> = new Set();
65 | 
66 |   constructor(
67 |     private readonly mcpTool: CallableTool,
68 |     readonly serverName: string,
69 |     readonly serverToolName: string,
70 |     readonly displayName: string,
71 |     readonly trust?: boolean,
72 |     params: ToolParams = {},
73 |     private readonly cliConfig?: Config,
74 |   ) {
75 |     super(params);
76 |   }
77 | 
78 |   override async shouldConfirmExecute(
79 |     _abortSignal: AbortSignal,
80 |   ): Promise<ToolCallConfirmationDetails | false> {
81 |     const serverAllowListKey = this.serverName;
82 |     const toolAllowListKey = `${this.serverName}.${this.serverToolName}`;
83 | 
84 |     if (this.cliConfig?.isTrustedFolder() && this.trust) {
85 |       return false; // server is trusted, no confirmation needed
86 |     }
87 | 
88 |     if (
89 |       DiscoveredMCPToolInvocation.allowlist.has(serverAllowListKey) ||
90 |       DiscoveredMCPToolInvocation.allowlist.has(toolAllowListKey)
91 |     ) {
92 |       return false; // server and/or tool already allowlisted
93 |     }
94 | 
95 |     const confirmationDetails: ToolMcpConfirmationDetails = {
96 |       type: 'mcp',
97 |       title: 'Confirm MCP Tool Execution',
98 |       serverName: this.serverName,
99 |       toolName: this.serverToolName, // Display original tool name in confirmation
100 |       toolDisplayName: this.displayName, // Display global registry name exposed to model and user
101 |       onConfirm: async (outcome: ToolConfirmationOutcome) => {
102 |         if (outcome === ToolConfirmationOutcome.ProceedAlwaysServer) {
103 |           DiscoveredMCPToolInvocation.allowlist.add(serverAllowListKey);
104 |         } else if (outcome === ToolConfirmationOutcome.ProceedAlwaysTool) {
105 |           DiscoveredMCPToolInvocation.allowlist.add(toolAllowListKey);
106 |         }
107 |       },
108 |     };
109 |     return confirmationDetails;
110 |   }
111 | 
112 |   // Determine if the response contains tool errors
113 |   // This is needed because CallToolResults should return errors inside the response.
114 |   // ref: https://modelcontextprotocol.io/specification/2025-06-18/schema#calltoolresult
115 |   isMCPToolError(rawResponseParts: Part[]): boolean {
116 |     const functionResponse = rawResponseParts?.[0]?.functionResponse;
117 |     const response = functionResponse?.response;
118 | 
119 |     interface McpError {
120 |       isError?: boolean | string;
121 |     }
122 | 
123 |     if (response) {
124 |       const error = (response as { error?: McpError })?.error;
125 |       const isError = error?.isError;
126 | 
127 |       if (error && (isError === true || isError === 'true')) {
128 |         return true;
129 |       }
130 |     }
131 |     return false;
132 |   }
133 | 
134 |   async execute(signal: AbortSignal): Promise<ToolResult> {
135 |     const functionCalls: FunctionCall[] = [
136 |       {
137 |         name: this.serverToolName,
138 |         args: this.params,
139 |       },
140 |     ];
141 | 
142 |     // Race MCP tool call with abort signal to respect cancellation
143 |     const rawResponseParts = await new Promise<Part[]>((resolve, reject) => {
144 |       if (signal.aborted) {
145 |         const error = new Error('Tool call aborted');
146 |         error.name = 'AbortError';
147 |         reject(error);
148 |         return;
149 |       }
150 |       const onAbort = () => {
151 |         cleanup();
152 |         const error = new Error('Tool call aborted');
153 |         error.name = 'AbortError';
154 |         reject(error);
155 |       };
156 |       const cleanup = () => {
157 |         signal.removeEventListener('abort', onAbort);
158 |       };
159 |       signal.addEventListener('abort', onAbort, { once: true });
160 | 
161 |       this.mcpTool
162 |         .callTool(functionCalls)
163 |         .then((res) => {
164 |           cleanup();
165 |           resolve(res);
166 |         })
167 |         .catch((err) => {
168 |           cleanup();
169 |           reject(err);
170 |         });
171 |     });
172 | 
173 |     // Ensure the response is not an error
174 |     if (this.isMCPToolError(rawResponseParts)) {
175 |       const errorMessage = `MCP tool '${
176 |         this.serverToolName
177 |       }' reported tool error for function call: ${safeJsonStringify(
178 |         functionCalls[0],
179 |       )} with response: ${safeJsonStringify(rawResponseParts)}`;
180 |       return {
181 |         llmContent: errorMessage,
182 |         returnDisplay: `Error: MCP tool '${this.serverToolName}' reported an error.`,
183 |         error: {
184 |           message: errorMessage,
185 |           type: ToolErrorType.MCP_TOOL_ERROR,
186 |         },
187 |       };
188 |     }
189 | 
190 |     const transformedParts = transformMcpContentToParts(rawResponseParts);
191 | 
192 |     return {
193 |       llmContent: transformedParts,
194 |       returnDisplay: getStringifiedResultForDisplay(rawResponseParts),
195 |     };
196 |   }
197 | 
198 |   getDescription(): string {
199 |     return safeJsonStringify(this.params);
200 |   }
201 | }
202 | 
203 | export class DiscoveredMCPTool extends BaseDeclarativeTool<
204 |   ToolParams,
205 |   ToolResult
206 | > {
207 |   constructor(
208 |     private readonly mcpTool: CallableTool,
209 |     readonly serverName: string,
210 |     readonly serverToolName: string,
211 |     description: string,
212 |     override readonly parameterSchema: unknown,
213 |     readonly trust?: boolean,
214 |     nameOverride?: string,
215 |     private readonly cliConfig?: Config,
216 |   ) {
217 |     super(
218 |       nameOverride ?? generateValidName(serverToolName),
219 |       `${serverToolName} (${serverName} MCP Server)`,
220 |       description,
221 |       Kind.Other,
222 |       parameterSchema,
223 |       true, // isOutputMarkdown
224 |       false, // canUpdateOutput
225 |     );
226 |   }
227 | 
228 |   asFullyQualifiedTool(): DiscoveredMCPTool {
229 |     return new DiscoveredMCPTool(
230 |       this.mcpTool,
231 |       this.serverName,
232 |       this.serverToolName,
233 |       this.description,
234 |       this.parameterSchema,
235 |       this.trust,
236 |       `${this.serverName}__${this.serverToolName}`,
237 |       this.cliConfig,
238 |     );
239 |   }
240 | 
241 |   protected createInvocation(
242 |     params: ToolParams,
243 |   ): ToolInvocation<ToolParams, ToolResult> {
244 |     return new DiscoveredMCPToolInvocation(
245 |       this.mcpTool,
246 |       this.serverName,
247 |       this.serverToolName,
248 |       this.displayName,
249 |       this.trust,
250 |       params,
251 |       this.cliConfig,
252 |     );
253 |   }
254 | }
255 | 
256 | function transformTextBlock(block: McpTextBlock): Part {
257 |   return { text: block.text };
258 | }
259 | 
260 | function transformImageAudioBlock(
261 |   block: McpMediaBlock,
262 |   toolName: string,
263 | ): Part[] {
264 |   return [
265 |     {
266 |       text: `[Tool '${toolName}' provided the following ${
267 |         block.type
268 |       } data with mime-type: ${block.mimeType}]`,
269 |     },
270 |     {
271 |       inlineData: {
272 |         mimeType: block.mimeType,
273 |         data: block.data,
274 |       },
275 |     },
276 |   ];
277 | }
278 | 
279 | function transformResourceBlock(
280 |   block: McpResourceBlock,
281 |   toolName: string,
282 | ): Part | Part[] | null {
283 |   const resource = block.resource;
284 |   if (resource?.text) {
285 |     return { text: resource.text };
286 |   }
287 |   if (resource?.blob) {
288 |     const mimeType = resource.mimeType || 'application/octet-stream';
289 |     return [
290 |       {
291 |         text: `[Tool '${toolName}' provided the following embedded resource with mime-type: ${mimeType}]`,
292 |       },
293 |       {
294 |         inlineData: {
295 |           mimeType,
296 |           data: resource.blob,
297 |         },
298 |       },
299 |     ];
300 |   }
301 |   return null;
302 | }
303 | 
304 | function transformResourceLinkBlock(block: McpResourceLinkBlock): Part {
305 |   return {
306 |     text: `Resource Link: ${block.title || block.name} at ${block.uri}`,
307 |   };
308 | }
309 | 
310 | /**
311 |  * Transforms the raw MCP content blocks from the SDK response into a
312 |  * standard GenAI Part array.
313 |  * @param sdkResponse The raw Part[] array from `mcpTool.callTool()`.
314 |  * @returns A clean Part[] array ready for the scheduler.
315 |  */
316 | function transformMcpContentToParts(sdkResponse: Part[]): Part[] {
317 |   const funcResponse = sdkResponse?.[0]?.functionResponse;
318 |   const mcpContent = funcResponse?.response?.['content'] as McpContentBlock[];
319 |   const toolName = funcResponse?.name || 'unknown tool';
320 | 
321 |   if (!Array.isArray(mcpContent)) {
322 |     return [{ text: '[Error: Could not parse tool response]' }];
323 |   }
324 | 
325 |   const transformed = mcpContent.flatMap(
326 |     (block: McpContentBlock): Part | Part[] | null => {
327 |       switch (block.type) {
328 |         case 'text':
329 |           return transformTextBlock(block);
330 |         case 'image':
331 |         case 'audio':
332 |           return transformImageAudioBlock(block, toolName);
333 |         case 'resource':
334 |           return transformResourceBlock(block, toolName);
335 |         case 'resource_link':
336 |           return transformResourceLinkBlock(block);
337 |         default:
338 |           return null;
339 |       }
340 |     },
341 |   );
342 | 
343 |   return transformed.filter((part): part is Part => part !== null);
344 | }
345 | 
346 | /**
347 |  * Processes the raw response from the MCP tool to generate a clean,
348 |  * human-readable string for display in the CLI. It summarizes non-text
349 |  * content and presents text directly.
350 |  *
351 |  * @param rawResponse The raw Part[] array from the GenAI SDK.
352 |  * @returns A formatted string representing the tool's output.
353 |  */
354 | function getStringifiedResultForDisplay(rawResponse: Part[]): string {
355 |   const mcpContent = rawResponse?.[0]?.functionResponse?.response?.[
356 |     'content'
357 |   ] as McpContentBlock[];
358 | 
359 |   if (!Array.isArray(mcpContent)) {
360 |     return '```json\n' + JSON.stringify(rawResponse, null, 2) + '\n```';
361 |   }
362 | 
363 |   const displayParts = mcpContent.map((block: McpContentBlock): string => {
364 |     switch (block.type) {
365 |       case 'text':
366 |         return block.text;
367 |       case 'image':
368 |         return `[Image: ${block.mimeType}]`;
369 |       case 'audio':
370 |         return `[Audio: ${block.mimeType}]`;
371 |       case 'resource_link':
372 |         return `[Link to ${block.title || block.name}: ${block.uri}]`;
373 |       case 'resource':
374 |         if (block.resource?.text) {
375 |           return block.resource.text;
376 |         }
377 |         return `[Embedded Resource: ${
378 |           block.resource?.mimeType || 'unknown type'
379 |         }]`;
380 |       default:
381 |         return `[Unknown content type: ${(block as { type: string }).type}]`;
382 |     }
383 |   });
384 | 
385 |   return displayParts.join('\n');
386 | }
387 | 
388 | /** Visible for testing */
389 | export function generateValidName(name: string) {
390 |   // Replace invalid characters (based on 400 error message from Gemini API) with underscores
391 |   let validToolname = name.replace(/[^a-zA-Z0-9_.-]/g, '_');
392 | 
393 |   // If longer than 63 characters, replace middle with '___'
394 |   // (Gemini API says max length 64, but actual limit seems to be 63)
395 |   if (validToolname.length > 63) {
396 |     validToolname =
397 |       validToolname.slice(0, 28) + '___' + validToolname.slice(-32);
398 |   }
399 |   return validToolname;
400 | }
```

src/tools/memoryTool.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Mock } from 'vitest';
8 | import { vi, describe, it, expect, beforeEach, afterEach } from 'vitest';
9 | import {
10 |   MemoryTool,
11 |   setGeminiMdFilename,
12 |   getCurrentGeminiMdFilename,
13 |   getAllGeminiMdFilenames,
14 |   DEFAULT_CONTEXT_FILENAME,
15 | } from './memoryTool.js';
16 | import * as fs from 'node:fs/promises';
17 | import * as path from 'node:path';
18 | import * as os from 'node:os';
19 | import { ToolConfirmationOutcome } from './tools.js';
20 | import { ToolErrorType } from './tool-error.js';
21 | 
22 | // Mock dependencies
23 | vi.mock(import('node:fs/promises'), async (importOriginal) => {
24 |   const actual = await importOriginal();
25 |   return {
26 |     ...actual,
27 |     mkdir: vi.fn(),
28 |     readFile: vi.fn(),
29 |   };
30 | });
31 | 
32 | vi.mock('fs', () => ({
33 |   mkdirSync: vi.fn(),
34 | }));
35 | 
36 | vi.mock('os');
37 | 
38 | const MEMORY_SECTION_HEADER = '## Gemini Added Memories';
39 | 
40 | // Define a type for our fsAdapter to ensure consistency
41 | interface FsAdapter {
42 |   readFile: (path: string, encoding: 'utf-8') => Promise<string>;
43 |   writeFile: (path: string, data: string, encoding: 'utf-8') => Promise<void>;
44 |   mkdir: (
45 |     path: string,
46 |     options: { recursive: boolean },
47 |   ) => Promise<string | undefined>;
48 | }
49 | 
50 | describe('MemoryTool', () => {
51 |   const mockAbortSignal = new AbortController().signal;
52 | 
53 |   const mockFsAdapter: {
54 |     readFile: Mock<FsAdapter['readFile']>;
55 |     writeFile: Mock<FsAdapter['writeFile']>;
56 |     mkdir: Mock<FsAdapter['mkdir']>;
57 |   } = {
58 |     readFile: vi.fn(),
59 |     writeFile: vi.fn(),
60 |     mkdir: vi.fn(),
61 |   };
62 | 
63 |   beforeEach(() => {
64 |     vi.mocked(os.homedir).mockReturnValue(path.join('/mock', 'home'));
65 |     mockFsAdapter.readFile.mockReset();
66 |     mockFsAdapter.writeFile.mockReset().mockResolvedValue(undefined);
67 |     mockFsAdapter.mkdir
68 |       .mockReset()
69 |       .mockResolvedValue(undefined as string | undefined);
70 |   });
71 | 
72 |   afterEach(() => {
73 |     vi.restoreAllMocks();
74 |     // Reset GEMINI_MD_FILENAME to its original value after each test
75 |     setGeminiMdFilename(DEFAULT_CONTEXT_FILENAME);
76 |   });
77 | 
78 |   describe('setGeminiMdFilename', () => {
79 |     it('should update currentGeminiMdFilename when a valid new name is provided', () => {
80 |       const newName = 'CUSTOM_CONTEXT.md';
81 |       setGeminiMdFilename(newName);
82 |       expect(getCurrentGeminiMdFilename()).toBe(newName);
83 |     });
84 | 
85 |     it('should not update currentGeminiMdFilename if the new name is empty or whitespace', () => {
86 |       const initialName = getCurrentGeminiMdFilename(); // Get current before trying to change
87 |       setGeminiMdFilename('  ');
88 |       expect(getCurrentGeminiMdFilename()).toBe(initialName);
89 | 
90 |       setGeminiMdFilename('');
91 |       expect(getCurrentGeminiMdFilename()).toBe(initialName);
92 |     });
93 | 
94 |     it('should handle an array of filenames', () => {
95 |       const newNames = ['CUSTOM_CONTEXT.md', 'ANOTHER_CONTEXT.md'];
96 |       setGeminiMdFilename(newNames);
97 |       expect(getCurrentGeminiMdFilename()).toBe('CUSTOM_CONTEXT.md');
98 |       expect(getAllGeminiMdFilenames()).toEqual(newNames);
99 |     });
100 |   });
101 | 
102 |   describe('performAddMemoryEntry (static method)', () => {
103 |     let testFilePath: string;
104 | 
105 |     beforeEach(() => {
106 |       testFilePath = path.join(
107 |         os.homedir(),
108 |         '.gemini',
109 |         DEFAULT_CONTEXT_FILENAME,
110 |       );
111 |     });
112 | 
113 |     it('should create section and save a fact if file does not exist', async () => {
114 |       mockFsAdapter.readFile.mockRejectedValue({ code: 'ENOENT' }); // Simulate file not found
115 |       const fact = 'The sky is blue';
116 |       await MemoryTool.performAddMemoryEntry(fact, testFilePath, mockFsAdapter);
117 | 
118 |       expect(mockFsAdapter.mkdir).toHaveBeenCalledWith(
119 |         path.dirname(testFilePath),
120 |         {
121 |           recursive: true,
122 |         },
123 |       );
124 |       expect(mockFsAdapter.writeFile).toHaveBeenCalledOnce();
125 |       const writeFileCall = mockFsAdapter.writeFile.mock.calls[0];
126 |       expect(writeFileCall[0]).toBe(testFilePath);
127 |       const expectedContent = `${MEMORY_SECTION_HEADER}\n- ${fact}\n`;
128 |       expect(writeFileCall[1]).toBe(expectedContent);
129 |       expect(writeFileCall[2]).toBe('utf-8');
130 |     });
131 | 
132 |     it('should create section and save a fact if file is empty', async () => {
133 |       mockFsAdapter.readFile.mockResolvedValue(''); // Simulate empty file
134 |       const fact = 'The sky is blue';
135 |       await MemoryTool.performAddMemoryEntry(fact, testFilePath, mockFsAdapter);
136 |       const writeFileCall = mockFsAdapter.writeFile.mock.calls[0];
137 |       const expectedContent = `${MEMORY_SECTION_HEADER}\n- ${fact}\n`;
138 |       expect(writeFileCall[1]).toBe(expectedContent);
139 |     });
140 | 
141 |     it('should add a fact to an existing section', async () => {
142 |       const initialContent = `Some preamble.\n\n${MEMORY_SECTION_HEADER}\n- Existing fact 1\n`;
143 |       mockFsAdapter.readFile.mockResolvedValue(initialContent);
144 |       const fact = 'New fact 2';
145 |       await MemoryTool.performAddMemoryEntry(fact, testFilePath, mockFsAdapter);
146 | 
147 |       expect(mockFsAdapter.writeFile).toHaveBeenCalledOnce();
148 |       const writeFileCall = mockFsAdapter.writeFile.mock.calls[0];
149 |       const expectedContent = `Some preamble.\n\n${MEMORY_SECTION_HEADER}\n- Existing fact 1\n- ${fact}\n`;
150 |       expect(writeFileCall[1]).toBe(expectedContent);
151 |     });
152 | 
153 |     it('should add a fact to an existing empty section', async () => {
154 |       const initialContent = `Some preamble.\n\n${MEMORY_SECTION_HEADER}\n`; // Empty section
155 |       mockFsAdapter.readFile.mockResolvedValue(initialContent);
156 |       const fact = 'First fact in section';
157 |       await MemoryTool.performAddMemoryEntry(fact, testFilePath, mockFsAdapter);
158 | 
159 |       expect(mockFsAdapter.writeFile).toHaveBeenCalledOnce();
160 |       const writeFileCall = mockFsAdapter.writeFile.mock.calls[0];
161 |       const expectedContent = `Some preamble.\n\n${MEMORY_SECTION_HEADER}\n- ${fact}\n`;
162 |       expect(writeFileCall[1]).toBe(expectedContent);
163 |     });
164 | 
165 |     it('should add a fact when other ## sections exist and preserve spacing', async () => {
166 |       const initialContent = `${MEMORY_SECTION_HEADER}\n- Fact 1\n\n## Another Section\nSome other text.`;
167 |       mockFsAdapter.readFile.mockResolvedValue(initialContent);
168 |       const fact = 'Fact 2';
169 |       await MemoryTool.performAddMemoryEntry(fact, testFilePath, mockFsAdapter);
170 | 
171 |       expect(mockFsAdapter.writeFile).toHaveBeenCalledOnce();
172 |       const writeFileCall = mockFsAdapter.writeFile.mock.calls[0];
173 |       // Note: The implementation ensures a single newline at the end if content exists.
174 |       const expectedContent = `${MEMORY_SECTION_HEADER}\n- Fact 1\n- ${fact}\n\n## Another Section\nSome other text.\n`;
175 |       expect(writeFileCall[1]).toBe(expectedContent);
176 |     });
177 | 
178 |     it('should correctly trim and add a fact that starts with a dash', async () => {
179 |       mockFsAdapter.readFile.mockResolvedValue(`${MEMORY_SECTION_HEADER}\n`);
180 |       const fact = '- - My fact with dashes';
181 |       await MemoryTool.performAddMemoryEntry(fact, testFilePath, mockFsAdapter);
182 |       const writeFileCall = mockFsAdapter.writeFile.mock.calls[0];
183 |       const expectedContent = `${MEMORY_SECTION_HEADER}\n- My fact with dashes\n`;
184 |       expect(writeFileCall[1]).toBe(expectedContent);
185 |     });
186 | 
187 |     it('should handle error from fsAdapter.writeFile', async () => {
188 |       mockFsAdapter.readFile.mockResolvedValue('');
189 |       mockFsAdapter.writeFile.mockRejectedValue(new Error('Disk full'));
190 |       const fact = 'This will fail';
191 |       await expect(
192 |         MemoryTool.performAddMemoryEntry(fact, testFilePath, mockFsAdapter),
193 |       ).rejects.toThrow('[MemoryTool] Failed to add memory entry: Disk full');
194 |     });
195 |   });
196 | 
197 |   describe('execute (instance method)', () => {
198 |     let memoryTool: MemoryTool;
199 |     let performAddMemoryEntrySpy: Mock<typeof MemoryTool.performAddMemoryEntry>;
200 | 
201 |     beforeEach(() => {
202 |       memoryTool = new MemoryTool();
203 |       // Spy on the static method for these tests
204 |       performAddMemoryEntrySpy = vi
205 |         .spyOn(MemoryTool, 'performAddMemoryEntry')
206 |         .mockResolvedValue(undefined) as Mock<
207 |         typeof MemoryTool.performAddMemoryEntry
208 |       >;
209 |       // Cast needed as spyOn returns MockInstance
210 |     });
211 | 
212 |     it('should have correct name, displayName, description, and schema', () => {
213 |       expect(memoryTool.name).toBe('save_memory');
214 |       expect(memoryTool.displayName).toBe('Save Memory');
215 |       expect(memoryTool.description).toContain(
216 |         'Saves a specific piece of information',
217 |       );
218 |       expect(memoryTool.schema).toBeDefined();
219 |       expect(memoryTool.schema.name).toBe('save_memory');
220 |       expect(memoryTool.schema.parametersJsonSchema).toStrictEqual({
221 |         type: 'object',
222 |         properties: {
223 |           fact: {
224 |             type: 'string',
225 |             description:
226 |               'The specific fact or piece of information to remember. Should be a clear, self-contained statement.',
227 |           },
228 |         },
229 |         required: ['fact'],
230 |       });
231 |     });
232 | 
233 |     it('should call performAddMemoryEntry with correct parameters and return success', async () => {
234 |       const params = { fact: 'The sky is blue' };
235 |       const invocation = memoryTool.build(params);
236 |       const result = await invocation.execute(mockAbortSignal);
237 |       // Use getCurrentGeminiMdFilename for the default expectation before any setGeminiMdFilename calls in a test
238 |       const expectedFilePath = path.join(
239 |         os.homedir(),
240 |         '.gemini',
241 |         getCurrentGeminiMdFilename(), // This will be DEFAULT_CONTEXT_FILENAME unless changed by a test
242 |       );
243 | 
244 |       // For this test, we expect the actual fs methods to be passed
245 |       const expectedFsArgument = {
246 |         readFile: fs.readFile,
247 |         writeFile: fs.writeFile,
248 |         mkdir: fs.mkdir,
249 |       };
250 | 
251 |       expect(performAddMemoryEntrySpy).toHaveBeenCalledWith(
252 |         params.fact,
253 |         expectedFilePath,
254 |         expectedFsArgument,
255 |       );
256 |       const successMessage = `Okay, I've remembered that: "${params.fact}"`;
257 |       expect(result.llmContent).toBe(
258 |         JSON.stringify({ success: true, message: successMessage }),
259 |       );
260 |       expect(result.returnDisplay).toBe(successMessage);
261 |     });
262 | 
263 |     it('should return an error if fact is empty', async () => {
264 |       const params = { fact: ' ' }; // Empty fact
265 |       expect(memoryTool.validateToolParams(params)).toBe(
266 |         'Parameter "fact" must be a non-empty string.',
267 |       );
268 |       expect(() => memoryTool.build(params)).toThrow(
269 |         'Parameter "fact" must be a non-empty string.',
270 |       );
271 |     });
272 | 
273 |     it('should handle errors from performAddMemoryEntry', async () => {
274 |       const params = { fact: 'This will fail' };
275 |       const underlyingError = new Error(
276 |         '[MemoryTool] Failed to add memory entry: Disk full',
277 |       );
278 |       performAddMemoryEntrySpy.mockRejectedValue(underlyingError);
279 | 
280 |       const invocation = memoryTool.build(params);
281 |       const result = await invocation.execute(mockAbortSignal);
282 | 
283 |       expect(result.llmContent).toBe(
284 |         JSON.stringify({
285 |           success: false,
286 |           error: `Failed to save memory. Detail: ${underlyingError.message}`,
287 |         }),
288 |       );
289 |       expect(result.returnDisplay).toBe(
290 |         `Error saving memory: ${underlyingError.message}`,
291 |       );
292 |       expect(result.error?.type).toBe(
293 |         ToolErrorType.MEMORY_TOOL_EXECUTION_ERROR,
294 |       );
295 |     });
296 |   });
297 | 
298 |   describe('shouldConfirmExecute', () => {
299 |     let memoryTool: MemoryTool;
300 | 
301 |     beforeEach(() => {
302 |       memoryTool = new MemoryTool();
303 |       // Clear the allowlist before each test
304 |       const invocation = memoryTool.build({ fact: 'mock-fact' });
305 |       // eslint-disable-next-line @typescript-eslint/no-explicit-any
306 |       (invocation.constructor as any).allowlist.clear();
307 |       // Mock fs.readFile to return empty string (file doesn't exist)
308 |       vi.mocked(fs.readFile).mockResolvedValue('');
309 |     });
310 | 
311 |     it('should return confirmation details when memory file is not allowlisted', async () => {
312 |       const params = { fact: 'Test fact' };
313 |       const invocation = memoryTool.build(params);
314 |       const result = await invocation.shouldConfirmExecute(mockAbortSignal);
315 | 
316 |       expect(result).toBeDefined();
317 |       expect(result).not.toBe(false);
318 | 
319 |       if (result && result.type === 'edit') {
320 |         const expectedPath = path.join('~', '.gemini', 'GEMINI.md');
321 |         expect(result.title).toBe(`Confirm Memory Save: ${expectedPath}`);
322 |         expect(result.fileName).toContain(path.join('mock', 'home', '.gemini'));
323 |         expect(result.fileName).toContain('GEMINI.md');
324 |         expect(result.fileDiff).toContain('Index: GEMINI.md');
325 |         expect(result.fileDiff).toContain('+## Gemini Added Memories');
326 |         expect(result.fileDiff).toContain('+- Test fact');
327 |         expect(result.originalContent).toBe('');
328 |         expect(result.newContent).toContain('## Gemini Added Memories');
329 |         expect(result.newContent).toContain('- Test fact');
330 |       }
331 |     });
332 | 
333 |     it('should return false when memory file is already allowlisted', async () => {
334 |       const params = { fact: 'Test fact' };
335 |       const memoryFilePath = path.join(
336 |         os.homedir(),
337 |         '.gemini',
338 |         getCurrentGeminiMdFilename(),
339 |       );
340 | 
341 |       const invocation = memoryTool.build(params);
342 |       // Add the memory file to the allowlist
343 |       // eslint-disable-next-line @typescript-eslint/no-explicit-any
344 |       (invocation.constructor as any).allowlist.add(memoryFilePath);
345 | 
346 |       const result = await invocation.shouldConfirmExecute(mockAbortSignal);
347 | 
348 |       expect(result).toBe(false);
349 |     });
350 | 
351 |     it('should add memory file to allowlist when ProceedAlways is confirmed', async () => {
352 |       const params = { fact: 'Test fact' };
353 |       const memoryFilePath = path.join(
354 |         os.homedir(),
355 |         '.gemini',
356 |         getCurrentGeminiMdFilename(),
357 |       );
358 | 
359 |       const invocation = memoryTool.build(params);
360 |       const result = await invocation.shouldConfirmExecute(mockAbortSignal);
361 | 
362 |       expect(result).toBeDefined();
363 |       expect(result).not.toBe(false);
364 | 
365 |       if (result && result.type === 'edit') {
366 |         // Simulate the onConfirm callback
367 |         await result.onConfirm(ToolConfirmationOutcome.ProceedAlways);
368 | 
369 |         // Check that the memory file was added to the allowlist
370 |         expect(
371 |           // eslint-disable-next-line @typescript-eslint/no-explicit-any
372 |           (invocation.constructor as any).allowlist.has(memoryFilePath),
373 |         ).toBe(true);
374 |       }
375 |     });
376 | 
377 |     it('should not add memory file to allowlist when other outcomes are confirmed', async () => {
378 |       const params = { fact: 'Test fact' };
379 |       const memoryFilePath = path.join(
380 |         os.homedir(),
381 |         '.gemini',
382 |         getCurrentGeminiMdFilename(),
383 |       );
384 | 
385 |       const invocation = memoryTool.build(params);
386 |       const result = await invocation.shouldConfirmExecute(mockAbortSignal);
387 | 
388 |       expect(result).toBeDefined();
389 |       expect(result).not.toBe(false);
390 | 
391 |       if (result && result.type === 'edit') {
392 |         // Simulate the onConfirm callback with different outcomes
393 |         await result.onConfirm(ToolConfirmationOutcome.ProceedOnce);
394 |         // eslint-disable-next-line @typescript-eslint/no-explicit-any
395 |         const allowlist = (invocation.constructor as any).allowlist;
396 |         expect(allowlist.has(memoryFilePath)).toBe(false);
397 | 
398 |         await result.onConfirm(ToolConfirmationOutcome.Cancel);
399 |         expect(allowlist.has(memoryFilePath)).toBe(false);
400 |       }
401 |     });
402 | 
403 |     it('should handle existing memory file with content', async () => {
404 |       const params = { fact: 'New fact' };
405 |       const existingContent =
406 |         'Some existing content.\n\n## Gemini Added Memories\n- Old fact\n';
407 | 
408 |       // Mock fs.readFile to return existing content
409 |       vi.mocked(fs.readFile).mockResolvedValue(existingContent);
410 | 
411 |       const invocation = memoryTool.build(params);
412 |       const result = await invocation.shouldConfirmExecute(mockAbortSignal);
413 | 
414 |       expect(result).toBeDefined();
415 |       expect(result).not.toBe(false);
416 | 
417 |       if (result && result.type === 'edit') {
418 |         const expectedPath = path.join('~', '.gemini', 'GEMINI.md');
419 |         expect(result.title).toBe(`Confirm Memory Save: ${expectedPath}`);
420 |         expect(result.fileDiff).toContain('Index: GEMINI.md');
421 |         expect(result.fileDiff).toContain('+- New fact');
422 |         expect(result.originalContent).toBe(existingContent);
423 |         expect(result.newContent).toContain('- Old fact');
424 |         expect(result.newContent).toContain('- New fact');
425 |       }
426 |     });
427 |   });
428 | });
```

src/tools/memoryTool.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { ToolEditConfirmationDetails, ToolResult } from './tools.js';
8 | import {
9 |   BaseDeclarativeTool,
10 |   BaseToolInvocation,
11 |   Kind,
12 |   ToolConfirmationOutcome,
13 | } from './tools.js';
14 | import type { FunctionDeclaration } from '@google/genai';
15 | import * as fs from 'node:fs/promises';
16 | import * as path from 'node:path';
17 | import { Storage } from '../config/storage.js';
18 | import * as Diff from 'diff';
19 | import { DEFAULT_DIFF_OPTIONS } from './diffOptions.js';
20 | import { tildeifyPath } from '../utils/paths.js';
21 | import type {
22 |   ModifiableDeclarativeTool,
23 |   ModifyContext,
24 | } from './modifiable-tool.js';
25 | import { ToolErrorType } from './tool-error.js';
26 | 
27 | const memoryToolSchemaData: FunctionDeclaration = {
28 |   name: 'save_memory',
29 |   description:
30 |     'Saves a specific piece of information or fact to your long-term memory. Use this when the user explicitly asks you to remember something, or when they state a clear, concise fact that seems important to retain for future interactions.',
31 |   parametersJsonSchema: {
32 |     type: 'object',
33 |     properties: {
34 |       fact: {
35 |         type: 'string',
36 |         description:
37 |           'The specific fact or piece of information to remember. Should be a clear, self-contained statement.',
38 |       },
39 |     },
40 |     required: ['fact'],
41 |   },
42 | };
43 | 
44 | const memoryToolDescription = `
45 | Saves a specific piece of information or fact to your long-term memory.
46 | 
47 | Use this tool:
48 | 
49 | - When the user explicitly asks you to remember something (e.g., "Remember that I like pineapple on pizza", "Please save this: my cat's name is Whiskers").
50 | - When the user states a clear, concise fact about themselves, their preferences, or their environment that seems important for you to retain for future interactions to provide a more personalized and effective assistance.
51 | 
52 | Do NOT use this tool:
53 | 
54 | - To remember conversational context that is only relevant for the current session.
55 | - To save long, complex, or rambling pieces of text. The fact should be relatively short and to the point.
56 | - If you are unsure whether the information is a fact worth remembering long-term. If in doubt, you can ask the user, "Should I remember that for you?"
57 | 
58 | ## Parameters
59 | 
60 | - \`fact\` (string, required): The specific fact or piece of information to remember. This should be a clear, self-contained statement. For example, if the user says "My favorite color is blue", the fact would be "My favorite color is blue".
61 | `;
62 | 
63 | export const GEMINI_CONFIG_DIR = '.gemini';
64 | export const DEFAULT_CONTEXT_FILENAME = 'GEMINI.md';
65 | export const MEMORY_SECTION_HEADER = '## Gemini Added Memories';
66 | 
67 | // This variable will hold the currently configured filename for GEMINI.md context files.
68 | // It defaults to DEFAULT_CONTEXT_FILENAME but can be overridden by setGeminiMdFilename.
69 | let currentGeminiMdFilename: string | string[] = DEFAULT_CONTEXT_FILENAME;
70 | 
71 | export function setGeminiMdFilename(newFilename: string | string[]): void {
72 |   if (Array.isArray(newFilename)) {
73 |     if (newFilename.length > 0) {
74 |       currentGeminiMdFilename = newFilename.map((name) => name.trim());
75 |     }
76 |   } else if (newFilename && newFilename.trim() !== '') {
77 |     currentGeminiMdFilename = newFilename.trim();
78 |   }
79 | }
80 | 
81 | export function getCurrentGeminiMdFilename(): string {
82 |   if (Array.isArray(currentGeminiMdFilename)) {
83 |     return currentGeminiMdFilename[0];
84 |   }
85 |   return currentGeminiMdFilename;
86 | }
87 | 
88 | export function getAllGeminiMdFilenames(): string[] {
89 |   if (Array.isArray(currentGeminiMdFilename)) {
90 |     return currentGeminiMdFilename;
91 |   }
92 |   return [currentGeminiMdFilename];
93 | }
94 | 
95 | interface SaveMemoryParams {
96 |   fact: string;
97 |   modified_by_user?: boolean;
98 |   modified_content?: string;
99 | }
100 | 
101 | function getGlobalMemoryFilePath(): string {
102 |   return path.join(Storage.getGlobalGeminiDir(), getCurrentGeminiMdFilename());
103 | }
104 | 
105 | /**
106 |  * Ensures proper newline separation before appending content.
107 |  */
108 | function ensureNewlineSeparation(currentContent: string): string {
109 |   if (currentContent.length === 0) return '';
110 |   if (currentContent.endsWith('\n\n') || currentContent.endsWith('\r\n\r\n'))
111 |     return '';
112 |   if (currentContent.endsWith('\n') || currentContent.endsWith('\r\n'))
113 |     return '\n';
114 |   return '\n\n';
115 | }
116 | 
117 | /**
118 |  * Reads the current content of the memory file
119 |  */
120 | async function readMemoryFileContent(): Promise<string> {
121 |   try {
122 |     return await fs.readFile(getGlobalMemoryFilePath(), 'utf-8');
123 |   } catch (err) {
124 |     const error = err as Error & { code?: string };
125 |     if (!(error instanceof Error) || error.code !== 'ENOENT') throw err;
126 |     return '';
127 |   }
128 | }
129 | 
130 | /**
131 |  * Computes the new content that would result from adding a memory entry
132 |  */
133 | function computeNewContent(currentContent: string, fact: string): string {
134 |   let processedText = fact.trim();
135 |   processedText = processedText.replace(/^(-+\s*)+/, '').trim();
136 |   const newMemoryItem = `- ${processedText}`;
137 | 
138 |   const headerIndex = currentContent.indexOf(MEMORY_SECTION_HEADER);
139 | 
140 |   if (headerIndex === -1) {
141 |     // Header not found, append header and then the entry
142 |     const separator = ensureNewlineSeparation(currentContent);
143 |     return (
144 |       currentContent +
145 |       `${separator}${MEMORY_SECTION_HEADER}\n${newMemoryItem}\n`
146 |     );
147 |   } else {
148 |     // Header found, find where to insert the new memory entry
149 |     const startOfSectionContent = headerIndex + MEMORY_SECTION_HEADER.length;
150 |     let endOfSectionIndex = currentContent.indexOf(
151 |       '\n## ',
152 |       startOfSectionContent,
153 |     );
154 |     if (endOfSectionIndex === -1) {
155 |       endOfSectionIndex = currentContent.length; // End of file
156 |     }
157 | 
158 |     const beforeSectionMarker = currentContent
159 |       .substring(0, startOfSectionContent)
160 |       .trimEnd();
161 |     let sectionContent = currentContent
162 |       .substring(startOfSectionContent, endOfSectionIndex)
163 |       .trimEnd();
164 |     const afterSectionMarker = currentContent.substring(endOfSectionIndex);
165 | 
166 |     sectionContent += `\n${newMemoryItem}`;
167 |     return (
168 |       `${beforeSectionMarker}\n${sectionContent.trimStart()}\n${afterSectionMarker}`.trimEnd() +
169 |       '\n'
170 |     );
171 |   }
172 | }
173 | 
174 | class MemoryToolInvocation extends BaseToolInvocation<
175 |   SaveMemoryParams,
176 |   ToolResult
177 | > {
178 |   private static readonly allowlist: Set<string> = new Set();
179 | 
180 |   getDescription(): string {
181 |     const memoryFilePath = getGlobalMemoryFilePath();
182 |     return `in ${tildeifyPath(memoryFilePath)}`;
183 |   }
184 | 
185 |   override async shouldConfirmExecute(
186 |     _abortSignal: AbortSignal,
187 |   ): Promise<ToolEditConfirmationDetails | false> {
188 |     const memoryFilePath = getGlobalMemoryFilePath();
189 |     const allowlistKey = memoryFilePath;
190 | 
191 |     if (MemoryToolInvocation.allowlist.has(allowlistKey)) {
192 |       return false;
193 |     }
194 | 
195 |     const currentContent = await readMemoryFileContent();
196 |     const newContent = computeNewContent(currentContent, this.params.fact);
197 | 
198 |     const fileName = path.basename(memoryFilePath);
199 |     const fileDiff = Diff.createPatch(
200 |       fileName,
201 |       currentContent,
202 |       newContent,
203 |       'Current',
204 |       'Proposed',
205 |       DEFAULT_DIFF_OPTIONS,
206 |     );
207 | 
208 |     const confirmationDetails: ToolEditConfirmationDetails = {
209 |       type: 'edit',
210 |       title: `Confirm Memory Save: ${tildeifyPath(memoryFilePath)}`,
211 |       fileName: memoryFilePath,
212 |       filePath: memoryFilePath,
213 |       fileDiff,
214 |       originalContent: currentContent,
215 |       newContent,
216 |       onConfirm: async (outcome: ToolConfirmationOutcome) => {
217 |         if (outcome === ToolConfirmationOutcome.ProceedAlways) {
218 |           MemoryToolInvocation.allowlist.add(allowlistKey);
219 |         }
220 |       },
221 |     };
222 |     return confirmationDetails;
223 |   }
224 | 
225 |   async execute(_signal: AbortSignal): Promise<ToolResult> {
226 |     const { fact, modified_by_user, modified_content } = this.params;
227 | 
228 |     try {
229 |       if (modified_by_user && modified_content !== undefined) {
230 |         // User modified the content in external editor, write it directly
231 |         await fs.mkdir(path.dirname(getGlobalMemoryFilePath()), {
232 |           recursive: true,
233 |         });
234 |         await fs.writeFile(
235 |           getGlobalMemoryFilePath(),
236 |           modified_content,
237 |           'utf-8',
238 |         );
239 |         const successMessage = `Okay, I've updated the memory file with your modifications.`;
240 |         return {
241 |           llmContent: JSON.stringify({
242 |             success: true,
243 |             message: successMessage,
244 |           }),
245 |           returnDisplay: successMessage,
246 |         };
247 |       } else {
248 |         // Use the normal memory entry logic
249 |         await MemoryTool.performAddMemoryEntry(
250 |           fact,
251 |           getGlobalMemoryFilePath(),
252 |           {
253 |             readFile: fs.readFile,
254 |             writeFile: fs.writeFile,
255 |             mkdir: fs.mkdir,
256 |           },
257 |         );
258 |         const successMessage = `Okay, I've remembered that: "${fact}"`;
259 |         return {
260 |           llmContent: JSON.stringify({
261 |             success: true,
262 |             message: successMessage,
263 |           }),
264 |           returnDisplay: successMessage,
265 |         };
266 |       }
267 |     } catch (error) {
268 |       const errorMessage =
269 |         error instanceof Error ? error.message : String(error);
270 |       console.error(
271 |         `[MemoryTool] Error executing save_memory for fact "${fact}": ${errorMessage}`,
272 |       );
273 |       return {
274 |         llmContent: JSON.stringify({
275 |           success: false,
276 |           error: `Failed to save memory. Detail: ${errorMessage}`,
277 |         }),
278 |         returnDisplay: `Error saving memory: ${errorMessage}`,
279 |         error: {
280 |           message: errorMessage,
281 |           type: ToolErrorType.MEMORY_TOOL_EXECUTION_ERROR,
282 |         },
283 |       };
284 |     }
285 |   }
286 | }
287 | 
288 | export class MemoryTool
289 |   extends BaseDeclarativeTool<SaveMemoryParams, ToolResult>
290 |   implements ModifiableDeclarativeTool<SaveMemoryParams>
291 | {
292 |   static readonly Name: string = memoryToolSchemaData.name!;
293 |   constructor() {
294 |     super(
295 |       MemoryTool.Name,
296 |       'Save Memory',
297 |       memoryToolDescription,
298 |       Kind.Think,
299 |       memoryToolSchemaData.parametersJsonSchema as Record<string, unknown>,
300 |     );
301 |   }
302 | 
303 |   protected override validateToolParamValues(
304 |     params: SaveMemoryParams,
305 |   ): string | null {
306 |     if (params.fact.trim() === '') {
307 |       return 'Parameter "fact" must be a non-empty string.';
308 |     }
309 | 
310 |     return null;
311 |   }
312 | 
313 |   protected createInvocation(params: SaveMemoryParams) {
314 |     return new MemoryToolInvocation(params);
315 |   }
316 | 
317 |   static async performAddMemoryEntry(
318 |     text: string,
319 |     memoryFilePath: string,
320 |     fsAdapter: {
321 |       readFile: (path: string, encoding: 'utf-8') => Promise<string>;
322 |       writeFile: (
323 |         path: string,
324 |         data: string,
325 |         encoding: 'utf-8',
326 |       ) => Promise<void>;
327 |       mkdir: (
328 |         path: string,
329 |         options: { recursive: boolean },
330 |       ) => Promise<string | undefined>;
331 |     },
332 |   ): Promise<void> {
333 |     try {
334 |       await fsAdapter.mkdir(path.dirname(memoryFilePath), { recursive: true });
335 |       let currentContent = '';
336 |       try {
337 |         currentContent = await fsAdapter.readFile(memoryFilePath, 'utf-8');
338 |       } catch (_e) {
339 |         // File doesn't exist, which is fine. currentContent will be empty.
340 |       }
341 | 
342 |       const newContent = computeNewContent(currentContent, text);
343 | 
344 |       await fsAdapter.writeFile(memoryFilePath, newContent, 'utf-8');
345 |     } catch (error) {
346 |       console.error(
347 |         `[MemoryTool] Error adding memory entry to ${memoryFilePath}:`,
348 |         error,
349 |       );
350 |       throw new Error(
351 |         `[MemoryTool] Failed to add memory entry: ${error instanceof Error ? error.message : String(error)}`,
352 |       );
353 |     }
354 |   }
355 | 
356 |   getModifyContext(_abortSignal: AbortSignal): ModifyContext<SaveMemoryParams> {
357 |     return {
358 |       getFilePath: (_params: SaveMemoryParams) => getGlobalMemoryFilePath(),
359 |       getCurrentContent: async (_params: SaveMemoryParams): Promise<string> =>
360 |         readMemoryFileContent(),
361 |       getProposedContent: async (params: SaveMemoryParams): Promise<string> => {
362 |         const currentContent = await readMemoryFileContent();
363 |         return computeNewContent(currentContent, params.fact);
364 |       },
365 |       createUpdatedParams: (
366 |         _oldContent: string,
367 |         modifiedProposedContent: string,
368 |         originalParams: SaveMemoryParams,
369 |       ): SaveMemoryParams => ({
370 |         ...originalParams,
371 |         modified_by_user: true,
372 |         modified_content: modifiedProposedContent,
373 |       }),
374 |     };
375 |   }
376 | }
```

src/tools/message-bus-integration.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   beforeEach,
12 |   afterEach,
13 |   vi,
14 |   type Mock,
15 | } from 'vitest';
16 | import {
17 |   BaseToolInvocation,
18 |   BaseDeclarativeTool,
19 |   Kind,
20 |   type ToolResult,
21 | } from './tools.js';
22 | import { MessageBus } from '../confirmation-bus/message-bus.js';
23 | import { PolicyEngine } from '../policy/policy-engine.js';
24 | import {
25 |   MessageBusType,
26 |   type ToolConfirmationResponse,
27 | } from '../confirmation-bus/types.js';
28 | import { randomUUID } from 'node:crypto';
29 | 
30 | // Mock crypto module
31 | vi.mock('node:crypto', () => ({
32 |   randomUUID: vi.fn(),
33 | }));
34 | 
35 | interface TestParams {
36 |   testParam: string;
37 | }
38 | 
39 | interface TestResult extends ToolResult {
40 |   testValue: string;
41 | }
42 | 
43 | class TestToolInvocation extends BaseToolInvocation<TestParams, TestResult> {
44 |   getDescription(): string {
45 |     return `Test tool with param: ${this.params.testParam}`;
46 |   }
47 | 
48 |   async execute(): Promise<TestResult> {
49 |     return {
50 |       llmContent: `Executed with ${this.params.testParam}`,
51 |       returnDisplay: `Test result: ${this.params.testParam}`,
52 |       testValue: this.params.testParam,
53 |     };
54 |   }
55 | }
56 | 
57 | class TestTool extends BaseDeclarativeTool<TestParams, TestResult> {
58 |   constructor(messageBus?: MessageBus) {
59 |     super(
60 |       'test-tool',
61 |       'Test Tool',
62 |       'A test tool for message bus integration',
63 |       Kind.Other,
64 |       {
65 |         type: 'object',
66 |         properties: {
67 |           testParam: { type: 'string' },
68 |         },
69 |         required: ['testParam'],
70 |       },
71 |       true,
72 |       false,
73 |       messageBus,
74 |     );
75 |   }
76 | 
77 |   protected createInvocation(params: TestParams, messageBus?: MessageBus) {
78 |     return new TestToolInvocation(params, messageBus);
79 |   }
80 | }
81 | 
82 | describe('Message Bus Integration', () => {
83 |   let policyEngine: PolicyEngine;
84 |   let messageBus: MessageBus;
85 |   let mockUUID: Mock;
86 | 
87 |   beforeEach(() => {
88 |     vi.resetAllMocks();
89 |     policyEngine = new PolicyEngine();
90 |     messageBus = new MessageBus(policyEngine);
91 |     mockUUID = vi.mocked(randomUUID);
92 |     mockUUID.mockReturnValue('test-correlation-id');
93 |   });
94 | 
95 |   afterEach(() => {
96 |     vi.restoreAllMocks();
97 |   });
98 | 
99 |   describe('BaseToolInvocation with MessageBus', () => {
100 |     it('should use message bus for confirmation when available', async () => {
101 |       const tool = new TestTool(messageBus);
102 |       const invocation = tool.build({ testParam: 'test-value' });
103 | 
104 |       // Mock message bus publish and subscribe
105 |       const publishSpy = vi.spyOn(messageBus, 'publish');
106 |       const subscribeSpy = vi.spyOn(messageBus, 'subscribe');
107 |       const unsubscribeSpy = vi.spyOn(messageBus, 'unsubscribe');
108 | 
109 |       // Start confirmation process
110 |       const confirmationPromise = invocation.shouldConfirmExecute(
111 |         new AbortController().signal,
112 |       );
113 | 
114 |       // Verify confirmation request was published
115 |       expect(publishSpy).toHaveBeenCalledWith({
116 |         type: MessageBusType.TOOL_CONFIRMATION_REQUEST,
117 |         toolCall: {
118 |           name: 'TestToolInvocation',
119 |           args: { testParam: 'test-value' },
120 |         },
121 |         correlationId: 'test-correlation-id',
122 |       });
123 | 
124 |       // Verify subscription to response
125 |       expect(subscribeSpy).toHaveBeenCalledWith(
126 |         MessageBusType.TOOL_CONFIRMATION_RESPONSE,
127 |         expect.any(Function),
128 |       );
129 | 
130 |       // Simulate confirmation response
131 |       const responseHandler = subscribeSpy.mock.calls[0][1];
132 |       const response: ToolConfirmationResponse = {
133 |         type: MessageBusType.TOOL_CONFIRMATION_RESPONSE,
134 |         correlationId: 'test-correlation-id',
135 |         confirmed: true,
136 |       };
137 | 
138 |       responseHandler(response);
139 | 
140 |       const result = await confirmationPromise;
141 |       expect(result).toBe(false); // No further confirmation needed
142 |       expect(unsubscribeSpy).toHaveBeenCalled();
143 |     });
144 | 
145 |     it('should reject promise when confirmation is denied', async () => {
146 |       const tool = new TestTool(messageBus);
147 |       const invocation = tool.build({ testParam: 'test-value' });
148 | 
149 |       const subscribeSpy = vi.spyOn(messageBus, 'subscribe');
150 | 
151 |       const confirmationPromise = invocation.shouldConfirmExecute(
152 |         new AbortController().signal,
153 |       );
154 | 
155 |       // Simulate denial response
156 |       const responseHandler = subscribeSpy.mock.calls[0][1];
157 |       const response: ToolConfirmationResponse = {
158 |         type: MessageBusType.TOOL_CONFIRMATION_RESPONSE,
159 |         correlationId: 'test-correlation-id',
160 |         confirmed: false,
161 |       };
162 | 
163 |       responseHandler(response);
164 | 
165 |       // Should reject with error when denied
166 |       await expect(confirmationPromise).rejects.toThrow(
167 |         'Tool execution denied by policy',
168 |       );
169 |     });
170 | 
171 |     it('should handle timeout', async () => {
172 |       vi.useFakeTimers();
173 | 
174 |       const tool = new TestTool(messageBus);
175 |       const invocation = tool.build({ testParam: 'test-value' });
176 | 
177 |       const confirmationPromise = invocation.shouldConfirmExecute(
178 |         new AbortController().signal,
179 |       );
180 | 
181 |       // Fast-forward past timeout
182 |       vi.advanceTimersByTime(30000);
183 | 
184 |       const result = await confirmationPromise;
185 |       expect(result).toBe(false);
186 | 
187 |       vi.useRealTimers();
188 |     });
189 | 
190 |     it('should handle abort signal', async () => {
191 |       const tool = new TestTool(messageBus);
192 |       const invocation = tool.build({ testParam: 'test-value' });
193 | 
194 |       const abortController = new AbortController();
195 |       const confirmationPromise = invocation.shouldConfirmExecute(
196 |         abortController.signal,
197 |       );
198 | 
199 |       // Abort the operation
200 |       abortController.abort();
201 | 
202 |       await expect(confirmationPromise).rejects.toThrow(
203 |         'Tool confirmation aborted',
204 |       );
205 |     });
206 | 
207 |     it('should fall back to default behavior when no message bus', async () => {
208 |       const tool = new TestTool(); // No message bus
209 |       const invocation = tool.build({ testParam: 'test-value' });
210 | 
211 |       const result = await invocation.shouldConfirmExecute(
212 |         new AbortController().signal,
213 |       );
214 |       expect(result).toBe(false);
215 |     });
216 | 
217 |     it('should ignore responses with wrong correlation ID', async () => {
218 |       vi.useFakeTimers();
219 | 
220 |       const tool = new TestTool(messageBus);
221 |       const invocation = tool.build({ testParam: 'test-value' });
222 | 
223 |       const subscribeSpy = vi.spyOn(messageBus, 'subscribe');
224 |       const confirmationPromise = invocation.shouldConfirmExecute(
225 |         new AbortController().signal,
226 |       );
227 | 
228 |       // Send response with wrong correlation ID
229 |       const responseHandler = subscribeSpy.mock.calls[0][1];
230 |       const wrongResponse: ToolConfirmationResponse = {
231 |         type: MessageBusType.TOOL_CONFIRMATION_RESPONSE,
232 |         correlationId: 'wrong-id',
233 |         confirmed: true,
234 |       };
235 | 
236 |       responseHandler(wrongResponse);
237 | 
238 |       // Should timeout since correct response wasn't received
239 |       vi.advanceTimersByTime(30000);
240 |       const result = await confirmationPromise;
241 |       expect(result).toBe(false);
242 | 
243 |       vi.useRealTimers();
244 |     });
245 |   });
246 | 
247 |   describe('Backward Compatibility', () => {
248 |     it('should work with existing tools that do not use message bus', async () => {
249 |       const tool = new TestTool(); // No message bus
250 |       const invocation = tool.build({ testParam: 'test-value' });
251 | 
252 |       // Should execute normally
253 |       const result = await invocation.execute(new AbortController().signal);
254 |       expect(result.testValue).toBe('test-value');
255 |       expect(result.llmContent).toBe('Executed with test-value');
256 |     });
257 | 
258 |     it('should work with tools that have message bus but use default confirmation', async () => {
259 |       const tool = new TestTool(messageBus);
260 |       const invocation = tool.build({ testParam: 'test-value' });
261 | 
262 |       // Should execute normally even with message bus available
263 |       const result = await invocation.execute(new AbortController().signal);
264 |       expect(result.testValue).toBe('test-value');
265 |       expect(result.llmContent).toBe('Executed with test-value');
266 |     });
267 |   });
268 | 
269 |   describe('Error Handling', () => {
270 |     it('should handle message bus publish errors gracefully', async () => {
271 |       const tool = new TestTool(messageBus);
272 |       const invocation = tool.build({ testParam: 'test-value' });
273 | 
274 |       // Mock publish to throw error
275 |       vi.spyOn(messageBus, 'publish').mockImplementation(() => {
276 |         throw new Error('Message bus error');
277 |       });
278 | 
279 |       const result = await invocation.shouldConfirmExecute(
280 |         new AbortController().signal,
281 |       );
282 |       expect(result).toBe(false); // Should gracefully fall back
283 |     });
284 |   });
285 | });
```

src/tools/modifiable-tool.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { vi, describe, it, expect, beforeEach, afterEach } from 'vitest';
8 | import type {
9 |   ModifyContext,
10 |   ModifiableDeclarativeTool,
11 | } from './modifiable-tool.js';
12 | import {
13 |   modifyWithEditor,
14 |   isModifiableDeclarativeTool,
15 | } from './modifiable-tool.js';
16 | import type { EditorType } from '../utils/editor.js';
17 | import fs from 'node:fs';
18 | import fsp from 'node:fs/promises';
19 | import os from 'node:os';
20 | import * as path from 'node:path';
21 | 
22 | // Mock dependencies
23 | const mockOpenDiff = vi.hoisted(() => vi.fn());
24 | const mockCreatePatch = vi.hoisted(() => vi.fn());
25 | 
26 | vi.mock('../utils/editor.js', () => ({
27 |   openDiff: mockOpenDiff,
28 | }));
29 | 
30 | vi.mock('diff', () => ({
31 |   createPatch: mockCreatePatch,
32 | }));
33 | 
34 | interface TestParams {
35 |   filePath: string;
36 |   someOtherParam: string;
37 |   modifiedContent?: string;
38 | }
39 | 
40 | describe('modifyWithEditor', () => {
41 |   let testProjectDir: string;
42 |   let mockModifyContext: ModifyContext<TestParams>;
43 |   let mockParams: TestParams;
44 |   let currentContent: string;
45 |   let proposedContent: string;
46 |   let modifiedContent: string;
47 |   let abortSignal: AbortSignal;
48 | 
49 |   beforeEach(async () => {
50 |     vi.resetAllMocks();
51 | 
52 |     testProjectDir = await fsp.mkdtemp(
53 |       path.join(os.tmpdir(), 'modifiable-tool-test-'),
54 |     );
55 |     abortSignal = new AbortController().signal;
56 | 
57 |     currentContent = 'original content\nline 2\nline 3';
58 |     proposedContent = 'modified content\nline 2\nline 3';
59 |     modifiedContent = 'user modified content\nline 2\nline 3\nnew line';
60 |     mockParams = {
61 |       filePath: path.join(testProjectDir, 'test.txt'),
62 |       someOtherParam: 'value',
63 |     };
64 | 
65 |     mockModifyContext = {
66 |       getFilePath: vi.fn().mockReturnValue(mockParams.filePath),
67 |       getCurrentContent: vi.fn().mockResolvedValue(currentContent),
68 |       getProposedContent: vi.fn().mockResolvedValue(proposedContent),
69 |       createUpdatedParams: vi
70 |         .fn()
71 |         .mockImplementation((oldContent, modifiedContent, originalParams) => ({
72 |           ...originalParams,
73 |           modifiedContent,
74 |           oldContent,
75 |         })),
76 |     };
77 | 
78 |     mockOpenDiff.mockImplementation(async (_oldPath, newPath) => {
79 |       await fsp.writeFile(newPath, modifiedContent, 'utf8');
80 |     });
81 | 
82 |     mockCreatePatch.mockReturnValue('mock diff content');
83 |   });
84 | 
85 |   afterEach(async () => {
86 |     vi.restoreAllMocks();
87 |     await fsp.rm(testProjectDir, { recursive: true, force: true });
88 |     const diffDir = path.join(os.tmpdir(), 'gemini-cli-tool-modify-diffs');
89 |     await fsp.rm(diffDir, { recursive: true, force: true });
90 |   });
91 | 
92 |   describe('successful modification', () => {
93 |     it('should successfully modify content with VSCode editor', async () => {
94 |       const result = await modifyWithEditor(
95 |         mockParams,
96 |         mockModifyContext,
97 |         'vscode' as EditorType,
98 |         abortSignal,
99 |         vi.fn(),
100 |       );
101 | 
102 |       expect(mockModifyContext.getCurrentContent).toHaveBeenCalledWith(
103 |         mockParams,
104 |       );
105 |       expect(mockModifyContext.getProposedContent).toHaveBeenCalledWith(
106 |         mockParams,
107 |       );
108 |       expect(mockModifyContext.getFilePath).toHaveBeenCalledWith(mockParams);
109 | 
110 |       expect(mockOpenDiff).toHaveBeenCalledOnce();
111 |       const [oldFilePath, newFilePath] = mockOpenDiff.mock.calls[0];
112 | 
113 |       expect(mockModifyContext.createUpdatedParams).toHaveBeenCalledWith(
114 |         currentContent,
115 |         modifiedContent,
116 |         mockParams,
117 |       );
118 | 
119 |       expect(mockCreatePatch).toHaveBeenCalledWith(
120 |         path.basename(mockParams.filePath),
121 |         currentContent,
122 |         modifiedContent,
123 |         'Current',
124 |         'Proposed',
125 |         expect.objectContaining({
126 |           context: 3,
127 |           ignoreWhitespace: true,
128 |         }),
129 |       );
130 | 
131 |       // Check that temp files are deleted.
132 |       await expect(fsp.access(oldFilePath)).rejects.toThrow();
133 |       await expect(fsp.access(newFilePath)).rejects.toThrow();
134 | 
135 |       expect(result).toEqual({
136 |         updatedParams: {
137 |           ...mockParams,
138 |           modifiedContent,
139 |           oldContent: currentContent,
140 |         },
141 |         updatedDiff: 'mock diff content',
142 |       });
143 |     });
144 | 
145 |     it('should create temp directory if it does not exist', async () => {
146 |       const diffDir = path.join(os.tmpdir(), 'gemini-cli-tool-modify-diffs');
147 |       await fsp.rm(diffDir, { recursive: true, force: true }).catch(() => {});
148 | 
149 |       await modifyWithEditor(
150 |         mockParams,
151 |         mockModifyContext,
152 |         'vscode' as EditorType,
153 |         abortSignal,
154 |         vi.fn(),
155 |       );
156 | 
157 |       const stats = await fsp.stat(diffDir);
158 |       expect(stats.isDirectory()).toBe(true);
159 |     });
160 | 
161 |     it('should not create temp directory if it already exists', async () => {
162 |       const diffDir = path.join(os.tmpdir(), 'gemini-cli-tool-modify-diffs');
163 |       await fsp.mkdir(diffDir, { recursive: true });
164 | 
165 |       const mkdirSpy = vi.spyOn(fs, 'mkdirSync');
166 | 
167 |       await modifyWithEditor(
168 |         mockParams,
169 |         mockModifyContext,
170 |         'vscode' as EditorType,
171 |         abortSignal,
172 |         vi.fn(),
173 |       );
174 | 
175 |       expect(mkdirSpy).not.toHaveBeenCalled();
176 |       mkdirSpy.mockRestore();
177 |     });
178 |   });
179 | 
180 |   it('should handle missing old temp file gracefully', async () => {
181 |     mockOpenDiff.mockImplementation(async (oldPath, newPath) => {
182 |       await fsp.writeFile(newPath, modifiedContent, 'utf8');
183 |       await fsp.unlink(oldPath);
184 |     });
185 | 
186 |     const result = await modifyWithEditor(
187 |       mockParams,
188 |       mockModifyContext,
189 |       'vscode' as EditorType,
190 |       abortSignal,
191 |       vi.fn(),
192 |     );
193 | 
194 |     expect(mockCreatePatch).toHaveBeenCalledWith(
195 |       path.basename(mockParams.filePath),
196 |       '',
197 |       modifiedContent,
198 |       'Current',
199 |       'Proposed',
200 |       expect.objectContaining({
201 |         context: 3,
202 |         ignoreWhitespace: true,
203 |       }),
204 |     );
205 | 
206 |     expect(result.updatedParams).toBeDefined();
207 |     expect(result.updatedDiff).toBe('mock diff content');
208 |   });
209 | 
210 |   it('should handle missing new temp file gracefully', async () => {
211 |     mockOpenDiff.mockImplementation(async (_oldPath, newPath) => {
212 |       await fsp.unlink(newPath);
213 |     });
214 | 
215 |     const result = await modifyWithEditor(
216 |       mockParams,
217 |       mockModifyContext,
218 |       'vscode' as EditorType,
219 |       abortSignal,
220 |       vi.fn(),
221 |     );
222 | 
223 |     expect(mockCreatePatch).toHaveBeenCalledWith(
224 |       path.basename(mockParams.filePath),
225 |       currentContent,
226 |       '',
227 |       'Current',
228 |       'Proposed',
229 |       expect.objectContaining({
230 |         context: 3,
231 |         ignoreWhitespace: true,
232 |       }),
233 |     );
234 | 
235 |     expect(result.updatedParams).toBeDefined();
236 |     expect(result.updatedDiff).toBe('mock diff content');
237 |   });
238 | 
239 |   it('should clean up temp files even if editor fails', async () => {
240 |     const editorError = new Error('Editor failed to open');
241 |     mockOpenDiff.mockRejectedValue(editorError);
242 | 
243 |     const writeSpy = vi.spyOn(fs, 'writeFileSync');
244 | 
245 |     await expect(
246 |       modifyWithEditor(
247 |         mockParams,
248 |         mockModifyContext,
249 |         'vscode' as EditorType,
250 |         abortSignal,
251 |         vi.fn(),
252 |       ),
253 |     ).rejects.toThrow('Editor failed to open');
254 | 
255 |     expect(writeSpy).toHaveBeenCalledTimes(2);
256 |     const oldFilePath = writeSpy.mock.calls[0][0] as string;
257 |     const newFilePath = writeSpy.mock.calls[1][0] as string;
258 | 
259 |     await expect(fsp.access(oldFilePath)).rejects.toThrow();
260 |     await expect(fsp.access(newFilePath)).rejects.toThrow();
261 | 
262 |     writeSpy.mockRestore();
263 |   });
264 | 
265 |   it('should handle temp file cleanup errors gracefully', async () => {
266 |     const consoleErrorSpy = vi
267 |       .spyOn(console, 'error')
268 |       .mockImplementation(() => {});
269 |     vi.spyOn(fs, 'unlinkSync').mockImplementation(() => {
270 |       throw new Error('Failed to delete file');
271 |     });
272 | 
273 |     await modifyWithEditor(
274 |       mockParams,
275 |       mockModifyContext,
276 |       'vscode' as EditorType,
277 |       abortSignal,
278 |       vi.fn(),
279 |     );
280 | 
281 |     expect(consoleErrorSpy).toHaveBeenCalledTimes(2);
282 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
283 |       expect.stringContaining('Error deleting temp diff file:'),
284 |     );
285 | 
286 |     consoleErrorSpy.mockRestore();
287 |   });
288 | 
289 |   it('should create temp files with correct naming with extension', async () => {
290 |     const testFilePath = path.join(
291 |       testProjectDir,
292 |       'subfolder',
293 |       'test-file.txt',
294 |     );
295 |     mockModifyContext.getFilePath = vi.fn().mockReturnValue(testFilePath);
296 | 
297 |     await modifyWithEditor(
298 |       mockParams,
299 |       mockModifyContext,
300 |       'vscode' as EditorType,
301 |       abortSignal,
302 |       vi.fn(),
303 |     );
304 | 
305 |     expect(mockOpenDiff).toHaveBeenCalledOnce();
306 |     const [oldFilePath, newFilePath] = mockOpenDiff.mock.calls[0];
307 |     expect(oldFilePath).toMatch(/gemini-cli-modify-test-file-old-\d+\.txt$/);
308 |     expect(newFilePath).toMatch(/gemini-cli-modify-test-file-new-\d+\.txt$/);
309 | 
310 |     const diffDir = path.join(os.tmpdir(), 'gemini-cli-tool-modify-diffs');
311 |     expect(path.dirname(oldFilePath)).toBe(diffDir);
312 |     expect(path.dirname(newFilePath)).toBe(diffDir);
313 |   });
314 | 
315 |   it('should create temp files with correct naming without extension', async () => {
316 |     const testFilePath = path.join(testProjectDir, 'subfolder', 'test-file');
317 |     mockModifyContext.getFilePath = vi.fn().mockReturnValue(testFilePath);
318 | 
319 |     await modifyWithEditor(
320 |       mockParams,
321 |       mockModifyContext,
322 |       'vscode' as EditorType,
323 |       abortSignal,
324 |       vi.fn(),
325 |     );
326 | 
327 |     expect(mockOpenDiff).toHaveBeenCalledOnce();
328 |     const [oldFilePath, newFilePath] = mockOpenDiff.mock.calls[0];
329 |     expect(oldFilePath).toMatch(/gemini-cli-modify-test-file-old-\d+$/);
330 |     expect(newFilePath).toMatch(/gemini-cli-modify-test-file-new-\d+$/);
331 | 
332 |     const diffDir = path.join(os.tmpdir(), 'gemini-cli-tool-modify-diffs');
333 |     expect(path.dirname(oldFilePath)).toBe(diffDir);
334 |     expect(path.dirname(newFilePath)).toBe(diffDir);
335 |   });
336 | });
337 | 
338 | describe('isModifiableTool', () => {
339 |   it('should return true for objects with getModifyContext method', () => {
340 |     const mockTool = {
341 |       name: 'test-tool',
342 |       getModifyContext: vi.fn(),
343 |     } as unknown as ModifiableDeclarativeTool<TestParams>;
344 | 
345 |     expect(isModifiableDeclarativeTool(mockTool)).toBe(true);
346 |   });
347 | 
348 |   it('should return false for objects without getModifyContext method', () => {
349 |     const mockTool = {
350 |       name: 'test-tool',
351 |     } as unknown as ModifiableDeclarativeTool<TestParams>;
352 | 
353 |     expect(isModifiableDeclarativeTool(mockTool)).toBe(false);
354 |   });
355 | });
```

src/tools/modifiable-tool.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { EditorType } from '../utils/editor.js';
8 | import { openDiff } from '../utils/editor.js';
9 | import os from 'node:os';
10 | import path from 'node:path';
11 | import fs from 'node:fs';
12 | import * as Diff from 'diff';
13 | import { DEFAULT_DIFF_OPTIONS } from './diffOptions.js';
14 | import { isNodeError } from '../utils/errors.js';
15 | import type {
16 |   AnyDeclarativeTool,
17 |   DeclarativeTool,
18 |   ToolResult,
19 | } from './tools.js';
20 | 
21 | /**
22 |  * A declarative tool that supports a modify operation.
23 |  */
24 | export interface ModifiableDeclarativeTool<TParams extends object>
25 |   extends DeclarativeTool<TParams, ToolResult> {
26 |   getModifyContext(abortSignal: AbortSignal): ModifyContext<TParams>;
27 | }
28 | 
29 | export interface ModifyContext<ToolParams> {
30 |   getFilePath: (params: ToolParams) => string;
31 | 
32 |   getCurrentContent: (params: ToolParams) => Promise<string>;
33 | 
34 |   getProposedContent: (params: ToolParams) => Promise<string>;
35 | 
36 |   createUpdatedParams: (
37 |     oldContent: string,
38 |     modifiedProposedContent: string,
39 |     originalParams: ToolParams,
40 |   ) => ToolParams;
41 | }
42 | 
43 | export interface ModifyResult<ToolParams> {
44 |   updatedParams: ToolParams;
45 |   updatedDiff: string;
46 | }
47 | 
48 | /**
49 |  * Type guard to check if a declarative tool is modifiable.
50 |  */
51 | export function isModifiableDeclarativeTool(
52 |   tool: AnyDeclarativeTool,
53 | ): tool is ModifiableDeclarativeTool<object> {
54 |   return 'getModifyContext' in tool;
55 | }
56 | 
57 | function createTempFilesForModify(
58 |   currentContent: string,
59 |   proposedContent: string,
60 |   file_path: string,
61 | ): { oldPath: string; newPath: string } {
62 |   const tempDir = os.tmpdir();
63 |   const diffDir = path.join(tempDir, 'gemini-cli-tool-modify-diffs');
64 | 
65 |   if (!fs.existsSync(diffDir)) {
66 |     fs.mkdirSync(diffDir, { recursive: true });
67 |   }
68 | 
69 |   const ext = path.extname(file_path);
70 |   const fileName = path.basename(file_path, ext);
71 |   const timestamp = Date.now();
72 |   const tempOldPath = path.join(
73 |     diffDir,
74 |     `gemini-cli-modify-${fileName}-old-${timestamp}${ext}`,
75 |   );
76 |   const tempNewPath = path.join(
77 |     diffDir,
78 |     `gemini-cli-modify-${fileName}-new-${timestamp}${ext}`,
79 |   );
80 | 
81 |   fs.writeFileSync(tempOldPath, currentContent, 'utf8');
82 |   fs.writeFileSync(tempNewPath, proposedContent, 'utf8');
83 | 
84 |   return { oldPath: tempOldPath, newPath: tempNewPath };
85 | }
86 | 
87 | function getUpdatedParams<ToolParams>(
88 |   tmpOldPath: string,
89 |   tempNewPath: string,
90 |   originalParams: ToolParams,
91 |   modifyContext: ModifyContext<ToolParams>,
92 | ): { updatedParams: ToolParams; updatedDiff: string } {
93 |   let oldContent = '';
94 |   let newContent = '';
95 | 
96 |   try {
97 |     oldContent = fs.readFileSync(tmpOldPath, 'utf8');
98 |   } catch (err) {
99 |     if (!isNodeError(err) || err.code !== 'ENOENT') throw err;
100 |     oldContent = '';
101 |   }
102 | 
103 |   try {
104 |     newContent = fs.readFileSync(tempNewPath, 'utf8');
105 |   } catch (err) {
106 |     if (!isNodeError(err) || err.code !== 'ENOENT') throw err;
107 |     newContent = '';
108 |   }
109 | 
110 |   const updatedParams = modifyContext.createUpdatedParams(
111 |     oldContent,
112 |     newContent,
113 |     originalParams,
114 |   );
115 |   const updatedDiff = Diff.createPatch(
116 |     path.basename(modifyContext.getFilePath(originalParams)),
117 |     oldContent,
118 |     newContent,
119 |     'Current',
120 |     'Proposed',
121 |     DEFAULT_DIFF_OPTIONS,
122 |   );
123 | 
124 |   return { updatedParams, updatedDiff };
125 | }
126 | 
127 | function deleteTempFiles(oldPath: string, newPath: string): void {
128 |   try {
129 |     fs.unlinkSync(oldPath);
130 |   } catch {
131 |     console.error(`Error deleting temp diff file: ${oldPath}`);
132 |   }
133 | 
134 |   try {
135 |     fs.unlinkSync(newPath);
136 |   } catch {
137 |     console.error(`Error deleting temp diff file: ${newPath}`);
138 |   }
139 | }
140 | 
141 | /**
142 |  * Triggers an external editor for the user to modify the proposed content,
143 |  * and returns the updated tool parameters and the diff after the user has modified the proposed content.
144 |  */
145 | export async function modifyWithEditor<ToolParams>(
146 |   originalParams: ToolParams,
147 |   modifyContext: ModifyContext<ToolParams>,
148 |   editorType: EditorType,
149 |   _abortSignal: AbortSignal,
150 |   onEditorClose: () => void,
151 | ): Promise<ModifyResult<ToolParams>> {
152 |   const currentContent = await modifyContext.getCurrentContent(originalParams);
153 |   const proposedContent =
154 |     await modifyContext.getProposedContent(originalParams);
155 | 
156 |   const { oldPath, newPath } = createTempFilesForModify(
157 |     currentContent,
158 |     proposedContent,
159 |     modifyContext.getFilePath(originalParams),
160 |   );
161 | 
162 |   try {
163 |     await openDiff(oldPath, newPath, editorType, onEditorClose);
164 |     const result = getUpdatedParams(
165 |       oldPath,
166 |       newPath,
167 |       originalParams,
168 |       modifyContext,
169 |     );
170 | 
171 |     return result;
172 |   } finally {
173 |     deleteTempFiles(oldPath, newPath);
174 |   }
175 | }
```

src/tools/read-file.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
8 | import type { ReadFileToolParams } from './read-file.js';
9 | import { ReadFileTool } from './read-file.js';
10 | import { ToolErrorType } from './tool-error.js';
11 | import path from 'node:path';
12 | import os from 'node:os';
13 | import fs from 'node:fs';
14 | import fsp from 'node:fs/promises';
15 | import type { Config } from '../config/config.js';
16 | import { FileDiscoveryService } from '../services/fileDiscoveryService.js';
17 | import { StandardFileSystemService } from '../services/fileSystemService.js';
18 | import { createMockWorkspaceContext } from '../test-utils/mockWorkspaceContext.js';
19 | import type { ToolInvocation, ToolResult } from './tools.js';
20 | 
21 | vi.mock('../telemetry/loggers.js', () => ({
22 |   logFileOperation: vi.fn(),
23 | }));
24 | 
25 | describe('ReadFileTool', () => {
26 |   let tempRootDir: string;
27 |   let tool: ReadFileTool;
28 |   const abortSignal = new AbortController().signal;
29 | 
30 |   beforeEach(async () => {
31 |     // Create a unique temporary root directory for each test run
32 |     tempRootDir = await fsp.mkdtemp(
33 |       path.join(os.tmpdir(), 'read-file-tool-root-'),
34 |     );
35 | 
36 |     const mockConfigInstance = {
37 |       getFileService: () => new FileDiscoveryService(tempRootDir),
38 |       getFileSystemService: () => new StandardFileSystemService(),
39 |       getTargetDir: () => tempRootDir,
40 |       getWorkspaceContext: () => createMockWorkspaceContext(tempRootDir),
41 |       storage: {
42 |         getProjectTempDir: () => path.join(tempRootDir, '.temp'),
43 |       },
44 |     } as unknown as Config;
45 |     tool = new ReadFileTool(mockConfigInstance);
46 |   });
47 | 
48 |   afterEach(async () => {
49 |     // Clean up the temporary root directory
50 |     if (fs.existsSync(tempRootDir)) {
51 |       await fsp.rm(tempRootDir, { recursive: true, force: true });
52 |     }
53 |   });
54 | 
55 |   describe('build', () => {
56 |     it('should return an invocation for valid params (absolute path within root)', () => {
57 |       const params: ReadFileToolParams = {
58 |         absolute_path: path.join(tempRootDir, 'test.txt'),
59 |       };
60 |       const result = tool.build(params);
61 |       expect(typeof result).not.toBe('string');
62 |     });
63 | 
64 |     it('should throw error if file path is relative', () => {
65 |       const params: ReadFileToolParams = {
66 |         absolute_path: 'relative/path.txt',
67 |       };
68 |       expect(() => tool.build(params)).toThrow(
69 |         'File path must be absolute, but was relative: relative/path.txt. You must provide an absolute path.',
70 |       );
71 |     });
72 | 
73 |     it('should throw error if path is outside root', () => {
74 |       const params: ReadFileToolParams = {
75 |         absolute_path: '/outside/root.txt',
76 |       };
77 |       expect(() => tool.build(params)).toThrow(
78 |         /File path must be within one of the workspace directories/,
79 |       );
80 |     });
81 | 
82 |     it('should allow access to files in project temp directory', () => {
83 |       const tempDir = path.join(tempRootDir, '.temp');
84 |       const params: ReadFileToolParams = {
85 |         absolute_path: path.join(tempDir, 'temp-file.txt'),
86 |       };
87 |       const result = tool.build(params);
88 |       expect(typeof result).not.toBe('string');
89 |     });
90 | 
91 |     it('should show temp directory in error message when path is outside workspace and temp dir', () => {
92 |       const params: ReadFileToolParams = {
93 |         absolute_path: '/completely/outside/path.txt',
94 |       };
95 |       expect(() => tool.build(params)).toThrow(
96 |         /File path must be within one of the workspace directories.*or within the project temp directory/,
97 |       );
98 |     });
99 | 
100 |     it('should throw error if path is empty', () => {
101 |       const params: ReadFileToolParams = {
102 |         absolute_path: '',
103 |       };
104 |       expect(() => tool.build(params)).toThrow(
105 |         /The 'absolute_path' parameter must be non-empty./,
106 |       );
107 |     });
108 | 
109 |     it('should throw error if offset is negative', () => {
110 |       const params: ReadFileToolParams = {
111 |         absolute_path: path.join(tempRootDir, 'test.txt'),
112 |         offset: -1,
113 |       };
114 |       expect(() => tool.build(params)).toThrow(
115 |         'Offset must be a non-negative number',
116 |       );
117 |     });
118 | 
119 |     it('should throw error if limit is zero or negative', () => {
120 |       const params: ReadFileToolParams = {
121 |         absolute_path: path.join(tempRootDir, 'test.txt'),
122 |         limit: 0,
123 |       };
124 |       expect(() => tool.build(params)).toThrow(
125 |         'Limit must be a positive number',
126 |       );
127 |     });
128 |   });
129 | 
130 |   describe('getDescription', () => {
131 |     it('should return relative path without limit/offset', () => {
132 |       const subDir = path.join(tempRootDir, 'sub', 'dir');
133 |       const params: ReadFileToolParams = {
134 |         absolute_path: path.join(subDir, 'file.txt'),
135 |       };
136 |       const invocation = tool.build(params);
137 |       expect(typeof invocation).not.toBe('string');
138 |       expect(
139 |         (
140 |           invocation as ToolInvocation<ReadFileToolParams, ToolResult>
141 |         ).getDescription(),
142 |       ).toBe(path.join('sub', 'dir', 'file.txt'));
143 |     });
144 | 
145 |     it('should return shortened path when file path is deep', () => {
146 |       const deepPath = path.join(
147 |         tempRootDir,
148 |         'very',
149 |         'deep',
150 |         'directory',
151 |         'structure',
152 |         'that',
153 |         'exceeds',
154 |         'the',
155 |         'normal',
156 |         'limit',
157 |         'file.txt',
158 |       );
159 |       const params: ReadFileToolParams = { absolute_path: deepPath };
160 |       const invocation = tool.build(params);
161 |       expect(typeof invocation).not.toBe('string');
162 |       const desc = (
163 |         invocation as ToolInvocation<ReadFileToolParams, ToolResult>
164 |       ).getDescription();
165 |       expect(desc).toContain('...');
166 |       expect(desc).toContain('file.txt');
167 |     });
168 | 
169 |     it('should handle non-normalized file paths correctly', () => {
170 |       const subDir = path.join(tempRootDir, 'sub', 'dir');
171 |       const params: ReadFileToolParams = {
172 |         absolute_path: path.join(subDir, '..', 'dir', 'file.txt'),
173 |       };
174 |       const invocation = tool.build(params);
175 |       expect(typeof invocation).not.toBe('string');
176 |       expect(
177 |         (
178 |           invocation as ToolInvocation<ReadFileToolParams, ToolResult>
179 |         ).getDescription(),
180 |       ).toBe(path.join('sub', 'dir', 'file.txt'));
181 |     });
182 | 
183 |     it('should return . if path is the root directory', () => {
184 |       const params: ReadFileToolParams = { absolute_path: tempRootDir };
185 |       const invocation = tool.build(params);
186 |       expect(typeof invocation).not.toBe('string');
187 |       expect(
188 |         (
189 |           invocation as ToolInvocation<ReadFileToolParams, ToolResult>
190 |         ).getDescription(),
191 |       ).toBe('.');
192 |     });
193 |   });
194 | 
195 |   describe('execute', () => {
196 |     it('should return error if file does not exist', async () => {
197 |       const filePath = path.join(tempRootDir, 'nonexistent.txt');
198 |       const params: ReadFileToolParams = { absolute_path: filePath };
199 |       const invocation = tool.build(params) as ToolInvocation<
200 |         ReadFileToolParams,
201 |         ToolResult
202 |       >;
203 | 
204 |       const result = await invocation.execute(abortSignal);
205 |       expect(result).toEqual({
206 |         llmContent:
207 |           'Could not read file because no file was found at the specified path.',
208 |         returnDisplay: 'File not found.',
209 |         error: {
210 |           message: `File not found: ${filePath}`,
211 |           type: ToolErrorType.FILE_NOT_FOUND,
212 |         },
213 |       });
214 |     });
215 | 
216 |     it('should return success result for a text file', async () => {
217 |       const filePath = path.join(tempRootDir, 'textfile.txt');
218 |       const fileContent = 'This is a test file.';
219 |       await fsp.writeFile(filePath, fileContent, 'utf-8');
220 |       const params: ReadFileToolParams = { absolute_path: filePath };
221 |       const invocation = tool.build(params) as ToolInvocation<
222 |         ReadFileToolParams,
223 |         ToolResult
224 |       >;
225 | 
226 |       expect(await invocation.execute(abortSignal)).toEqual({
227 |         llmContent: fileContent,
228 |         returnDisplay: '',
229 |       });
230 |     });
231 | 
232 |     it('should return error if path is a directory', async () => {
233 |       const dirPath = path.join(tempRootDir, 'directory');
234 |       await fsp.mkdir(dirPath);
235 |       const params: ReadFileToolParams = { absolute_path: dirPath };
236 |       const invocation = tool.build(params) as ToolInvocation<
237 |         ReadFileToolParams,
238 |         ToolResult
239 |       >;
240 | 
241 |       const result = await invocation.execute(abortSignal);
242 |       expect(result).toEqual({
243 |         llmContent:
244 |           'Could not read file because the provided path is a directory, not a file.',
245 |         returnDisplay: 'Path is a directory.',
246 |         error: {
247 |           message: `Path is a directory, not a file: ${dirPath}`,
248 |           type: ToolErrorType.TARGET_IS_DIRECTORY,
249 |         },
250 |       });
251 |     });
252 | 
253 |     it('should return error for a file that is too large', async () => {
254 |       const filePath = path.join(tempRootDir, 'largefile.txt');
255 |       // 21MB of content exceeds 20MB limit
256 |       const largeContent = 'x'.repeat(21 * 1024 * 1024);
257 |       await fsp.writeFile(filePath, largeContent, 'utf-8');
258 |       const params: ReadFileToolParams = { absolute_path: filePath };
259 |       const invocation = tool.build(params) as ToolInvocation<
260 |         ReadFileToolParams,
261 |         ToolResult
262 |       >;
263 | 
264 |       const result = await invocation.execute(abortSignal);
265 |       expect(result).toHaveProperty('error');
266 |       expect(result.error?.type).toBe(ToolErrorType.FILE_TOO_LARGE);
267 |       expect(result.error?.message).toContain(
268 |         'File size exceeds the 20MB limit',
269 |       );
270 |     });
271 | 
272 |     it('should handle text file with lines exceeding maximum length', async () => {
273 |       const filePath = path.join(tempRootDir, 'longlines.txt');
274 |       const longLine = 'a'.repeat(2500); // Exceeds MAX_LINE_LENGTH_TEXT_FILE (2000)
275 |       const fileContent = `Short line\n${longLine}\nAnother short line`;
276 |       await fsp.writeFile(filePath, fileContent, 'utf-8');
277 |       const params: ReadFileToolParams = { absolute_path: filePath };
278 |       const invocation = tool.build(params) as ToolInvocation<
279 |         ReadFileToolParams,
280 |         ToolResult
281 |       >;
282 | 
283 |       const result = await invocation.execute(abortSignal);
284 |       expect(result.llmContent).toContain(
285 |         'IMPORTANT: The file content has been truncated',
286 |       );
287 |       expect(result.llmContent).toContain('--- FILE CONTENT (truncated) ---');
288 |       expect(result.returnDisplay).toContain('some lines were shortened');
289 |     });
290 | 
291 |     it('should handle image file and return appropriate content', async () => {
292 |       const imagePath = path.join(tempRootDir, 'image.png');
293 |       // Minimal PNG header
294 |       const pngHeader = Buffer.from([
295 |         0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a,
296 |       ]);
297 |       await fsp.writeFile(imagePath, pngHeader);
298 |       const params: ReadFileToolParams = { absolute_path: imagePath };
299 |       const invocation = tool.build(params) as ToolInvocation<
300 |         ReadFileToolParams,
301 |         ToolResult
302 |       >;
303 | 
304 |       const result = await invocation.execute(abortSignal);
305 |       expect(result.llmContent).toEqual({
306 |         inlineData: {
307 |           data: pngHeader.toString('base64'),
308 |           mimeType: 'image/png',
309 |         },
310 |       });
311 |       expect(result.returnDisplay).toBe('Read image file: image.png');
312 |     });
313 | 
314 |     it('should handle PDF file and return appropriate content', async () => {
315 |       const pdfPath = path.join(tempRootDir, 'document.pdf');
316 |       // Minimal PDF header
317 |       const pdfHeader = Buffer.from('%PDF-1.4');
318 |       await fsp.writeFile(pdfPath, pdfHeader);
319 |       const params: ReadFileToolParams = { absolute_path: pdfPath };
320 |       const invocation = tool.build(params) as ToolInvocation<
321 |         ReadFileToolParams,
322 |         ToolResult
323 |       >;
324 | 
325 |       const result = await invocation.execute(abortSignal);
326 |       expect(result.llmContent).toEqual({
327 |         inlineData: {
328 |           data: pdfHeader.toString('base64'),
329 |           mimeType: 'application/pdf',
330 |         },
331 |       });
332 |       expect(result.returnDisplay).toBe('Read pdf file: document.pdf');
333 |     });
334 | 
335 |     it('should handle binary file and skip content', async () => {
336 |       const binPath = path.join(tempRootDir, 'binary.bin');
337 |       // Binary data with null bytes
338 |       const binaryData = Buffer.from([0x00, 0xff, 0x00, 0xff]);
339 |       await fsp.writeFile(binPath, binaryData);
340 |       const params: ReadFileToolParams = { absolute_path: binPath };
341 |       const invocation = tool.build(params) as ToolInvocation<
342 |         ReadFileToolParams,
343 |         ToolResult
344 |       >;
345 | 
346 |       const result = await invocation.execute(abortSignal);
347 |       expect(result.llmContent).toBe(
348 |         'Cannot display content of binary file: binary.bin',
349 |       );
350 |       expect(result.returnDisplay).toBe('Skipped binary file: binary.bin');
351 |     });
352 | 
353 |     it('should handle SVG file as text', async () => {
354 |       const svgPath = path.join(tempRootDir, 'image.svg');
355 |       const svgContent = '<svg><circle cx="50" cy="50" r="40"/></svg>';
356 |       await fsp.writeFile(svgPath, svgContent, 'utf-8');
357 |       const params: ReadFileToolParams = { absolute_path: svgPath };
358 |       const invocation = tool.build(params) as ToolInvocation<
359 |         ReadFileToolParams,
360 |         ToolResult
361 |       >;
362 | 
363 |       const result = await invocation.execute(abortSignal);
364 |       expect(result.llmContent).toBe(svgContent);
365 |       expect(result.returnDisplay).toBe('Read SVG as text: image.svg');
366 |     });
367 | 
368 |     it('should handle large SVG file', async () => {
369 |       const svgPath = path.join(tempRootDir, 'large.svg');
370 |       // Create SVG content larger than 1MB
371 |       const largeContent = '<svg>' + 'x'.repeat(1024 * 1024 + 1) + '</svg>';
372 |       await fsp.writeFile(svgPath, largeContent, 'utf-8');
373 |       const params: ReadFileToolParams = { absolute_path: svgPath };
374 |       const invocation = tool.build(params) as ToolInvocation<
375 |         ReadFileToolParams,
376 |         ToolResult
377 |       >;
378 | 
379 |       const result = await invocation.execute(abortSignal);
380 |       expect(result.llmContent).toBe(
381 |         'Cannot display content of SVG file larger than 1MB: large.svg',
382 |       );
383 |       expect(result.returnDisplay).toBe(
384 |         'Skipped large SVG file (>1MB): large.svg',
385 |       );
386 |     });
387 | 
388 |     it('should handle empty file', async () => {
389 |       const emptyPath = path.join(tempRootDir, 'empty.txt');
390 |       await fsp.writeFile(emptyPath, '', 'utf-8');
391 |       const params: ReadFileToolParams = { absolute_path: emptyPath };
392 |       const invocation = tool.build(params) as ToolInvocation<
393 |         ReadFileToolParams,
394 |         ToolResult
395 |       >;
396 | 
397 |       const result = await invocation.execute(abortSignal);
398 |       expect(result.llmContent).toBe('');
399 |       expect(result.returnDisplay).toBe('');
400 |     });
401 | 
402 |     it('should support offset and limit for text files', async () => {
403 |       const filePath = path.join(tempRootDir, 'paginated.txt');
404 |       const lines = Array.from({ length: 20 }, (_, i) => `Line ${i + 1}`);
405 |       const fileContent = lines.join('\n');
406 |       await fsp.writeFile(filePath, fileContent, 'utf-8');
407 | 
408 |       const params: ReadFileToolParams = {
409 |         absolute_path: filePath,
410 |         offset: 5, // Start from line 6
411 |         limit: 3,
412 |       };
413 |       const invocation = tool.build(params) as ToolInvocation<
414 |         ReadFileToolParams,
415 |         ToolResult
416 |       >;
417 | 
418 |       const result = await invocation.execute(abortSignal);
419 |       expect(result.llmContent).toContain(
420 |         'IMPORTANT: The file content has been truncated',
421 |       );
422 |       expect(result.llmContent).toContain(
423 |         'Status: Showing lines 6-8 of 20 total lines',
424 |       );
425 |       expect(result.llmContent).toContain('Line 6');
426 |       expect(result.llmContent).toContain('Line 7');
427 |       expect(result.llmContent).toContain('Line 8');
428 |       expect(result.returnDisplay).toBe(
429 |         'Read lines 6-8 of 20 from paginated.txt',
430 |       );
431 |     });
432 | 
433 |     it('should successfully read files from project temp directory', async () => {
434 |       const tempDir = path.join(tempRootDir, '.temp');
435 |       await fsp.mkdir(tempDir, { recursive: true });
436 |       const tempFilePath = path.join(tempDir, 'temp-output.txt');
437 |       const tempFileContent = 'This is temporary output content';
438 |       await fsp.writeFile(tempFilePath, tempFileContent, 'utf-8');
439 | 
440 |       const params: ReadFileToolParams = { absolute_path: tempFilePath };
441 |       const invocation = tool.build(params) as ToolInvocation<
442 |         ReadFileToolParams,
443 |         ToolResult
444 |       >;
445 | 
446 |       const result = await invocation.execute(abortSignal);
447 |       expect(result.llmContent).toBe(tempFileContent);
448 |       expect(result.returnDisplay).toBe('');
449 |     });
450 | 
451 |     describe('with .geminiignore', () => {
452 |       beforeEach(async () => {
453 |         await fsp.writeFile(
454 |           path.join(tempRootDir, '.geminiignore'),
455 |           ['foo.*', 'ignored/'].join('\n'),
456 |         );
457 |       });
458 | 
459 |       it('should throw error if path is ignored by a .geminiignore pattern', async () => {
460 |         const ignoredFilePath = path.join(tempRootDir, 'foo.bar');
461 |         await fsp.writeFile(ignoredFilePath, 'content', 'utf-8');
462 |         const params: ReadFileToolParams = {
463 |           absolute_path: ignoredFilePath,
464 |         };
465 |         const expectedError = `File path '${ignoredFilePath}' is ignored by .geminiignore pattern(s).`;
466 |         expect(() => tool.build(params)).toThrow(expectedError);
467 |       });
468 | 
469 |       it('should throw error if file is in an ignored directory', async () => {
470 |         const ignoredDirPath = path.join(tempRootDir, 'ignored');
471 |         await fsp.mkdir(ignoredDirPath, { recursive: true });
472 |         const ignoredFilePath = path.join(ignoredDirPath, 'file.txt');
473 |         await fsp.writeFile(ignoredFilePath, 'content', 'utf-8');
474 |         const params: ReadFileToolParams = {
475 |           absolute_path: ignoredFilePath,
476 |         };
477 |         const expectedError = `File path '${ignoredFilePath}' is ignored by .geminiignore pattern(s).`;
478 |         expect(() => tool.build(params)).toThrow(expectedError);
479 |       });
480 | 
481 |       it('should allow reading non-ignored files', async () => {
482 |         const allowedFilePath = path.join(tempRootDir, 'allowed.txt');
483 |         await fsp.writeFile(allowedFilePath, 'content', 'utf-8');
484 |         const params: ReadFileToolParams = {
485 |           absolute_path: allowedFilePath,
486 |         };
487 |         const invocation = tool.build(params);
488 |         expect(typeof invocation).not.toBe('string');
489 |       });
490 |     });
491 |   });
492 | });
```

src/tools/read-file.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import path from 'node:path';
8 | import { makeRelative, shortenPath } from '../utils/paths.js';
9 | import type { ToolInvocation, ToolLocation, ToolResult } from './tools.js';
10 | import { BaseDeclarativeTool, BaseToolInvocation, Kind } from './tools.js';
11 | 
12 | import type { PartUnion } from '@google/genai';
13 | import {
14 |   processSingleFileContent,
15 |   getSpecificMimeType,
16 | } from '../utils/fileUtils.js';
17 | import type { Config } from '../config/config.js';
18 | import { FileOperation } from '../telemetry/metrics.js';
19 | import { getProgrammingLanguage } from '../telemetry/telemetry-utils.js';
20 | import { logFileOperation } from '../telemetry/loggers.js';
21 | import { FileOperationEvent } from '../telemetry/types.js';
22 | 
23 | /**
24 |  * Parameters for the ReadFile tool
25 |  */
26 | export interface ReadFileToolParams {
27 |   /**
28 |    * The absolute path to the file to read
29 |    */
30 |   absolute_path: string;
31 | 
32 |   /**
33 |    * The line number to start reading from (optional)
34 |    */
35 |   offset?: number;
36 | 
37 |   /**
38 |    * The number of lines to read (optional)
39 |    */
40 |   limit?: number;
41 | }
42 | 
43 | class ReadFileToolInvocation extends BaseToolInvocation<
44 |   ReadFileToolParams,
45 |   ToolResult
46 | > {
47 |   constructor(
48 |     private config: Config,
49 |     params: ReadFileToolParams,
50 |   ) {
51 |     super(params);
52 |   }
53 | 
54 |   getDescription(): string {
55 |     const relativePath = makeRelative(
56 |       this.params.absolute_path,
57 |       this.config.getTargetDir(),
58 |     );
59 |     return shortenPath(relativePath);
60 |   }
61 | 
62 |   override toolLocations(): ToolLocation[] {
63 |     return [{ path: this.params.absolute_path, line: this.params.offset }];
64 |   }
65 | 
66 |   async execute(): Promise<ToolResult> {
67 |     const result = await processSingleFileContent(
68 |       this.params.absolute_path,
69 |       this.config.getTargetDir(),
70 |       this.config.getFileSystemService(),
71 |       this.params.offset,
72 |       this.params.limit,
73 |     );
74 | 
75 |     if (result.error) {
76 |       return {
77 |         llmContent: result.llmContent,
78 |         returnDisplay: result.returnDisplay || 'Error reading file',
79 |         error: {
80 |           message: result.error,
81 |           type: result.errorType,
82 |         },
83 |       };
84 |     }
85 | 
86 |     let llmContent: PartUnion;
87 |     if (result.isTruncated) {
88 |       const [start, end] = result.linesShown!;
89 |       const total = result.originalLineCount!;
90 |       const nextOffset = this.params.offset
91 |         ? this.params.offset + end - start + 1
92 |         : end;
93 |       llmContent = `
94 | IMPORTANT: The file content has been truncated.
95 | Status: Showing lines ${start}-${end} of ${total} total lines.
96 | Action: To read more of the file, you can use the 'offset' and 'limit' parameters in a subsequent 'read_file' call. For example, to read the next section of the file, use offset: ${nextOffset}.
97 | 
98 | --- FILE CONTENT (truncated) ---
99 | ${result.llmContent}`;
100 |     } else {
101 |       llmContent = result.llmContent || '';
102 |     }
103 | 
104 |     const lines =
105 |       typeof result.llmContent === 'string'
106 |         ? result.llmContent.split('\n').length
107 |         : undefined;
108 |     const mimetype = getSpecificMimeType(this.params.absolute_path);
109 |     const programming_language = getProgrammingLanguage({
110 |       absolute_path: this.params.absolute_path,
111 |     });
112 |     logFileOperation(
113 |       this.config,
114 |       new FileOperationEvent(
115 |         ReadFileTool.Name,
116 |         FileOperation.READ,
117 |         lines,
118 |         mimetype,
119 |         path.extname(this.params.absolute_path),
120 |         programming_language,
121 |       ),
122 |     );
123 | 
124 |     return {
125 |       llmContent,
126 |       returnDisplay: result.returnDisplay || '',
127 |     };
128 |   }
129 | }
130 | 
131 | /**
132 |  * Implementation of the ReadFile tool logic
133 |  */
134 | export class ReadFileTool extends BaseDeclarativeTool<
135 |   ReadFileToolParams,
136 |   ToolResult
137 | > {
138 |   static readonly Name: string = 'read_file';
139 | 
140 |   constructor(private config: Config) {
141 |     super(
142 |       ReadFileTool.Name,
143 |       'ReadFile',
144 |       `Reads and returns the content of a specified file. If the file is large, the content will be truncated. The tool's response will clearly indicate if truncation has occurred and will provide details on how to read more of the file using the 'offset' and 'limit' parameters. Handles text, images (PNG, JPG, GIF, WEBP, SVG, BMP), and PDF files. For text files, it can read specific line ranges.`,
145 |       Kind.Read,
146 |       {
147 |         properties: {
148 |           absolute_path: {
149 |             description:
150 |               "The absolute path to the file to read (e.g., '/home/user/project/file.txt'). Relative paths are not supported. You must provide an absolute path.",
151 |             type: 'string',
152 |           },
153 |           offset: {
154 |             description:
155 |               "Optional: For text files, the 0-based line number to start reading from. Requires 'limit' to be set. Use for paginating through large files.",
156 |             type: 'number',
157 |           },
158 |           limit: {
159 |             description:
160 |               "Optional: For text files, maximum number of lines to read. Use with 'offset' to paginate through large files. If omitted, reads the entire file (if feasible, up to a default limit).",
161 |             type: 'number',
162 |           },
163 |         },
164 |         required: ['absolute_path'],
165 |         type: 'object',
166 |       },
167 |     );
168 |   }
169 | 
170 |   protected override validateToolParamValues(
171 |     params: ReadFileToolParams,
172 |   ): string | null {
173 |     const filePath = params.absolute_path;
174 |     if (params.absolute_path.trim() === '') {
175 |       return "The 'absolute_path' parameter must be non-empty.";
176 |     }
177 | 
178 |     if (!path.isAbsolute(filePath)) {
179 |       return `File path must be absolute, but was relative: ${filePath}. You must provide an absolute path.`;
180 |     }
181 | 
182 |     const workspaceContext = this.config.getWorkspaceContext();
183 |     const projectTempDir = this.config.storage.getProjectTempDir();
184 |     const resolvedFilePath = path.resolve(filePath);
185 |     const resolvedProjectTempDir = path.resolve(projectTempDir);
186 |     const isWithinTempDir =
187 |       resolvedFilePath.startsWith(resolvedProjectTempDir + path.sep) ||
188 |       resolvedFilePath === resolvedProjectTempDir;
189 | 
190 |     if (!workspaceContext.isPathWithinWorkspace(filePath) && !isWithinTempDir) {
191 |       const directories = workspaceContext.getDirectories();
192 |       return `File path must be within one of the workspace directories: ${directories.join(', ')} or within the project temp directory: ${projectTempDir}`;
193 |     }
194 |     if (params.offset !== undefined && params.offset < 0) {
195 |       return 'Offset must be a non-negative number';
196 |     }
197 |     if (params.limit !== undefined && params.limit <= 0) {
198 |       return 'Limit must be a positive number';
199 |     }
200 | 
201 |     const fileService = this.config.getFileService();
202 |     if (fileService.shouldGeminiIgnoreFile(params.absolute_path)) {
203 |       return `File path '${filePath}' is ignored by .geminiignore pattern(s).`;
204 |     }
205 | 
206 |     return null;
207 |   }
208 | 
209 |   protected createInvocation(
210 |     params: ReadFileToolParams,
211 |   ): ToolInvocation<ReadFileToolParams, ToolResult> {
212 |     return new ReadFileToolInvocation(this.config, params);
213 |   }
214 | }
```

src/tools/read-many-files.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { vi, describe, it, expect, beforeEach, afterEach } from 'vitest';
8 | import type { Mock } from 'vitest';
9 | import { mockControl } from '../__mocks__/fs/promises.js';
10 | import { ReadManyFilesTool } from './read-many-files.js';
11 | import { FileDiscoveryService } from '../services/fileDiscoveryService.js';
12 | import path from 'node:path';
13 | import fs from 'node:fs'; // Actual fs for setup
14 | import os from 'node:os';
15 | import type { Config } from '../config/config.js';
16 | import { WorkspaceContext } from '../utils/workspaceContext.js';
17 | import { StandardFileSystemService } from '../services/fileSystemService.js';
18 | import { ToolErrorType } from './tool-error.js';
19 | import {
20 |   COMMON_IGNORE_PATTERNS,
21 |   DEFAULT_FILE_EXCLUDES,
22 | } from '../utils/ignorePatterns.js';
23 | import * as glob from 'glob';
24 | 
25 | vi.mock('glob', { spy: true });
26 | 
27 | vi.mock('mime', () => {
28 |   const getType = (filename: string) => {
29 |     if (filename.endsWith('.ts') || filename.endsWith('.js')) {
30 |       return 'text/plain';
31 |     }
32 |     if (filename.endsWith('.png')) {
33 |       return 'image/png';
34 |     }
35 |     if (filename.endsWith('.pdf')) {
36 |       return 'application/pdf';
37 |     }
38 |     if (filename.endsWith('.mp3') || filename.endsWith('.wav')) {
39 |       return 'audio/mpeg';
40 |     }
41 |     if (filename.endsWith('.mp4') || filename.endsWith('.mov')) {
42 |       return 'video/mp4';
43 |     }
44 |     return false;
45 |   };
46 |   return {
47 |     default: {
48 |       getType,
49 |     },
50 |     getType,
51 |   };
52 | });
53 | 
54 | vi.mock('../telemetry/loggers.js', () => ({
55 |   logFileOperation: vi.fn(),
56 | }));
57 | 
58 | describe('ReadManyFilesTool', () => {
59 |   let tool: ReadManyFilesTool;
60 |   let tempRootDir: string;
61 |   let tempDirOutsideRoot: string;
62 |   let mockReadFileFn: Mock;
63 | 
64 |   beforeEach(async () => {
65 |     tempRootDir = fs.realpathSync(
66 |       fs.mkdtempSync(path.join(os.tmpdir(), 'read-many-files-root-')),
67 |     );
68 |     tempDirOutsideRoot = fs.realpathSync(
69 |       fs.mkdtempSync(path.join(os.tmpdir(), 'read-many-files-external-')),
70 |     );
71 |     fs.writeFileSync(path.join(tempRootDir, '.geminiignore'), 'foo.*');
72 |     const fileService = new FileDiscoveryService(tempRootDir);
73 |     const mockConfig = {
74 |       getFileService: () => fileService,
75 |       getFileSystemService: () => new StandardFileSystemService(),
76 | 
77 |       getFileFilteringOptions: () => ({
78 |         respectGitIgnore: true,
79 |         respectGeminiIgnore: true,
80 |       }),
81 |       getTargetDir: () => tempRootDir,
82 |       getWorkspaceDirs: () => [tempRootDir],
83 |       getWorkspaceContext: () => new WorkspaceContext(tempRootDir),
84 |       getFileExclusions: () => ({
85 |         getCoreIgnorePatterns: () => COMMON_IGNORE_PATTERNS,
86 |         getDefaultExcludePatterns: () => DEFAULT_FILE_EXCLUDES,
87 |         getGlobExcludes: () => COMMON_IGNORE_PATTERNS,
88 |         buildExcludePatterns: () => DEFAULT_FILE_EXCLUDES,
89 |         getReadManyFilesExcludes: () => DEFAULT_FILE_EXCLUDES,
90 |       }),
91 |     } as Partial<Config> as Config;
92 |     tool = new ReadManyFilesTool(mockConfig);
93 | 
94 |     mockReadFileFn = mockControl.mockReadFile;
95 |     mockReadFileFn.mockReset();
96 | 
97 |     mockReadFileFn.mockImplementation(
98 |       async (filePath: fs.PathLike, options?: Record<string, unknown>) => {
99 |         const fp =
100 |           typeof filePath === 'string'
101 |             ? filePath
102 |             : (filePath as Buffer).toString();
103 | 
104 |         if (fs.existsSync(fp)) {
105 |           const originalFs = await vi.importActual<typeof fs>('fs');
106 |           return originalFs.promises.readFile(fp, options);
107 |         }
108 | 
109 |         if (fp.endsWith('nonexistent-file.txt')) {
110 |           const err = new Error(
111 |             `ENOENT: no such file or directory, open '${fp}'`,
112 |           );
113 |           (err as NodeJS.ErrnoException).code = 'ENOENT';
114 |           throw err;
115 |         }
116 |         if (fp.endsWith('unreadable.txt')) {
117 |           const err = new Error(`EACCES: permission denied, open '${fp}'`);
118 |           (err as NodeJS.ErrnoException).code = 'EACCES';
119 |           throw err;
120 |         }
121 |         if (fp.endsWith('.png'))
122 |           return Buffer.from([0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a]); // PNG header
123 |         if (fp.endsWith('.pdf')) return Buffer.from('%PDF-1.4...'); // PDF start
124 |         if (fp.endsWith('binary.bin'))
125 |           return Buffer.from([0x00, 0x01, 0x02, 0x00, 0x03]);
126 | 
127 |         const err = new Error(
128 |           `ENOENT: no such file or directory, open '${fp}' (unmocked path)`,
129 |         );
130 |         (err as NodeJS.ErrnoException).code = 'ENOENT';
131 |         throw err;
132 |       },
133 |     );
134 |   });
135 | 
136 |   afterEach(() => {
137 |     if (fs.existsSync(tempRootDir)) {
138 |       fs.rmSync(tempRootDir, { recursive: true, force: true });
139 |     }
140 |     if (fs.existsSync(tempDirOutsideRoot)) {
141 |       fs.rmSync(tempDirOutsideRoot, { recursive: true, force: true });
142 |     }
143 |   });
144 | 
145 |   describe('build', () => {
146 |     it('should return an invocation for valid relative paths within root', () => {
147 |       const params = { paths: ['file1.txt', 'subdir/file2.txt'] };
148 |       const invocation = tool.build(params);
149 |       expect(invocation).toBeDefined();
150 |     });
151 | 
152 |     it('should return an invocation for valid glob patterns within root', () => {
153 |       const params = { paths: ['*.txt', 'subdir/**/*.js'] };
154 |       const invocation = tool.build(params);
155 |       expect(invocation).toBeDefined();
156 |     });
157 | 
158 |     it('should return an invocation for paths trying to escape the root (e.g., ../) as execute handles this', () => {
159 |       const params = { paths: ['../outside.txt'] };
160 |       const invocation = tool.build(params);
161 |       expect(invocation).toBeDefined();
162 |     });
163 | 
164 |     it('should return an invocation for absolute paths as execute handles this', () => {
165 |       const params = { paths: [path.join(tempDirOutsideRoot, 'absolute.txt')] };
166 |       const invocation = tool.build(params);
167 |       expect(invocation).toBeDefined();
168 |     });
169 | 
170 |     it('should throw error if paths array is empty', () => {
171 |       const params = { paths: [] };
172 |       expect(() => tool.build(params)).toThrow(
173 |         'params/paths must NOT have fewer than 1 items',
174 |       );
175 |     });
176 | 
177 |     it('should return an invocation for valid exclude and include patterns', () => {
178 |       const params = {
179 |         paths: ['src/**/*.ts'],
180 |         exclude: ['**/*.test.ts'],
181 |         include: ['src/utils/*.ts'],
182 |       };
183 |       const invocation = tool.build(params);
184 |       expect(invocation).toBeDefined();
185 |     });
186 | 
187 |     it('should throw error if paths array contains an empty string', () => {
188 |       const params = { paths: ['file1.txt', ''] };
189 |       expect(() => tool.build(params)).toThrow(
190 |         'params/paths/1 must NOT have fewer than 1 characters',
191 |       );
192 |     });
193 | 
194 |     it('should throw error if include array contains non-string elements', () => {
195 |       const params = {
196 |         paths: ['file1.txt'],
197 |         include: ['*.ts', 123] as string[],
198 |       };
199 |       expect(() => tool.build(params)).toThrow(
200 |         'params/include/1 must be string',
201 |       );
202 |     });
203 | 
204 |     it('should throw error if exclude array contains non-string elements', () => {
205 |       const params = {
206 |         paths: ['file1.txt'],
207 |         exclude: ['*.log', {}] as string[],
208 |       };
209 |       expect(() => tool.build(params)).toThrow(
210 |         'params/exclude/1 must be string',
211 |       );
212 |     });
213 |   });
214 | 
215 |   describe('execute', () => {
216 |     const createFile = (filePath: string, content = '') => {
217 |       const fullPath = path.join(tempRootDir, filePath);
218 |       fs.mkdirSync(path.dirname(fullPath), { recursive: true });
219 |       fs.writeFileSync(fullPath, content);
220 |     };
221 |     const createBinaryFile = (filePath: string, data: Uint8Array) => {
222 |       const fullPath = path.join(tempRootDir, filePath);
223 |       fs.mkdirSync(path.dirname(fullPath), { recursive: true });
224 |       fs.writeFileSync(fullPath, data);
225 |     };
226 | 
227 |     it('should read a single specified file', async () => {
228 |       createFile('file1.txt', 'Content of file1');
229 |       const params = { paths: ['file1.txt'] };
230 |       const invocation = tool.build(params);
231 |       const result = await invocation.execute(new AbortController().signal);
232 |       const expectedPath = path.join(tempRootDir, 'file1.txt');
233 |       expect(result.llmContent).toEqual([
234 |         `--- ${expectedPath} ---\n\nContent of file1\n\n`,
235 |         `\n--- End of content ---`,
236 |       ]);
237 |       expect(result.returnDisplay).toContain(
238 |         'Successfully read and concatenated content from **1 file(s)**',
239 |       );
240 |     });
241 | 
242 |     it('should read multiple specified files', async () => {
243 |       createFile('file1.txt', 'Content1');
244 |       createFile('subdir/file2.js', 'Content2');
245 |       const params = { paths: ['file1.txt', 'subdir/file2.js'] };
246 |       const invocation = tool.build(params);
247 |       const result = await invocation.execute(new AbortController().signal);
248 |       const content = result.llmContent as string[];
249 |       const expectedPath1 = path.join(tempRootDir, 'file1.txt');
250 |       const expectedPath2 = path.join(tempRootDir, 'subdir/file2.js');
251 |       expect(
252 |         content.some((c) =>
253 |           c.includes(`--- ${expectedPath1} ---\n\nContent1\n\n`),
254 |         ),
255 |       ).toBe(true);
256 |       expect(
257 |         content.some((c) =>
258 |           c.includes(`--- ${expectedPath2} ---\n\nContent2\n\n`),
259 |         ),
260 |       ).toBe(true);
261 |       expect(result.returnDisplay).toContain(
262 |         'Successfully read and concatenated content from **2 file(s)**',
263 |       );
264 |     });
265 | 
266 |     it('should handle glob patterns', async () => {
267 |       createFile('file.txt', 'Text file');
268 |       createFile('another.txt', 'Another text');
269 |       createFile('sub/data.json', '{}');
270 |       const params = { paths: ['*.txt'] };
271 |       const invocation = tool.build(params);
272 |       const result = await invocation.execute(new AbortController().signal);
273 |       const content = result.llmContent as string[];
274 |       const expectedPath1 = path.join(tempRootDir, 'file.txt');
275 |       const expectedPath2 = path.join(tempRootDir, 'another.txt');
276 |       expect(
277 |         content.some((c) =>
278 |           c.includes(`--- ${expectedPath1} ---\n\nText file\n\n`),
279 |         ),
280 |       ).toBe(true);
281 |       expect(
282 |         content.some((c) =>
283 |           c.includes(`--- ${expectedPath2} ---\n\nAnother text\n\n`),
284 |         ),
285 |       ).toBe(true);
286 |       expect(content.find((c) => c.includes('sub/data.json'))).toBeUndefined();
287 |       expect(result.returnDisplay).toContain(
288 |         'Successfully read and concatenated content from **2 file(s)**',
289 |       );
290 |     });
291 | 
292 |     it('should respect exclude patterns', async () => {
293 |       createFile('src/main.ts', 'Main content');
294 |       createFile('src/main.test.ts', 'Test content');
295 |       const params = { paths: ['src/**/*.ts'], exclude: ['**/*.test.ts'] };
296 |       const invocation = tool.build(params);
297 |       const result = await invocation.execute(new AbortController().signal);
298 |       const content = result.llmContent as string[];
299 |       const expectedPath = path.join(tempRootDir, 'src/main.ts');
300 |       expect(content).toEqual([
301 |         `--- ${expectedPath} ---\n\nMain content\n\n`,
302 |         `\n--- End of content ---`,
303 |       ]);
304 |       expect(
305 |         content.find((c) => c.includes('src/main.test.ts')),
306 |       ).toBeUndefined();
307 |       expect(result.returnDisplay).toContain(
308 |         'Successfully read and concatenated content from **1 file(s)**',
309 |       );
310 |     });
311 | 
312 |     it('should handle nonexistent specific files gracefully', async () => {
313 |       const params = { paths: ['nonexistent-file.txt'] };
314 |       const invocation = tool.build(params);
315 |       const result = await invocation.execute(new AbortController().signal);
316 |       expect(result.llmContent).toEqual([
317 |         'No files matching the criteria were found or all were skipped.',
318 |       ]);
319 |       expect(result.returnDisplay).toContain(
320 |         'No files were read and concatenated based on the criteria.',
321 |       );
322 |     });
323 | 
324 |     it('should use default excludes', async () => {
325 |       createFile('node_modules/some-lib/index.js', 'lib code');
326 |       createFile('src/app.js', 'app code');
327 |       const params = { paths: ['**/*.js'] };
328 |       const invocation = tool.build(params);
329 |       const result = await invocation.execute(new AbortController().signal);
330 |       const content = result.llmContent as string[];
331 |       const expectedPath = path.join(tempRootDir, 'src/app.js');
332 |       expect(content).toEqual([
333 |         `--- ${expectedPath} ---\n\napp code\n\n`,
334 |         `\n--- End of content ---`,
335 |       ]);
336 |       expect(
337 |         content.find((c) => c.includes('node_modules/some-lib/index.js')),
338 |       ).toBeUndefined();
339 |       expect(result.returnDisplay).toContain(
340 |         'Successfully read and concatenated content from **1 file(s)**',
341 |       );
342 |     });
343 | 
344 |     it('should NOT use default excludes if useDefaultExcludes is false', async () => {
345 |       createFile('node_modules/some-lib/index.js', 'lib code');
346 |       createFile('src/app.js', 'app code');
347 |       const params = { paths: ['**/*.js'], useDefaultExcludes: false };
348 |       const invocation = tool.build(params);
349 |       const result = await invocation.execute(new AbortController().signal);
350 |       const content = result.llmContent as string[];
351 |       const expectedPath1 = path.join(
352 |         tempRootDir,
353 |         'node_modules/some-lib/index.js',
354 |       );
355 |       const expectedPath2 = path.join(tempRootDir, 'src/app.js');
356 |       expect(
357 |         content.some((c) =>
358 |           c.includes(`--- ${expectedPath1} ---\n\nlib code\n\n`),
359 |         ),
360 |       ).toBe(true);
361 |       expect(
362 |         content.some((c) =>
363 |           c.includes(`--- ${expectedPath2} ---\n\napp code\n\n`),
364 |         ),
365 |       ).toBe(true);
366 |       expect(result.returnDisplay).toContain(
367 |         'Successfully read and concatenated content from **2 file(s)**',
368 |       );
369 |     });
370 | 
371 |     it('should include images as inlineData parts if explicitly requested by extension', async () => {
372 |       createBinaryFile(
373 |         'image.png',
374 |         Buffer.from([0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a]),
375 |       );
376 |       const params = { paths: ['*.png'] }; // Explicitly requesting .png
377 |       const invocation = tool.build(params);
378 |       const result = await invocation.execute(new AbortController().signal);
379 |       expect(result.llmContent).toEqual([
380 |         {
381 |           inlineData: {
382 |             data: Buffer.from([
383 |               0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a,
384 |             ]).toString('base64'),
385 |             mimeType: 'image/png',
386 |           },
387 |         },
388 |         '\n--- End of content ---',
389 |       ]);
390 |       expect(result.returnDisplay).toContain(
391 |         'Successfully read and concatenated content from **1 file(s)**',
392 |       );
393 |     });
394 | 
395 |     it('should include images as inlineData parts if explicitly requested by name', async () => {
396 |       createBinaryFile(
397 |         'myExactImage.png',
398 |         Buffer.from([0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a]),
399 |       );
400 |       const params = { paths: ['myExactImage.png'] }; // Explicitly requesting by full name
401 |       const invocation = tool.build(params);
402 |       const result = await invocation.execute(new AbortController().signal);
403 |       expect(result.llmContent).toEqual([
404 |         {
405 |           inlineData: {
406 |             data: Buffer.from([
407 |               0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a,
408 |             ]).toString('base64'),
409 |             mimeType: 'image/png',
410 |           },
411 |         },
412 |         '\n--- End of content ---',
413 |       ]);
414 |     });
415 | 
416 |     it('should skip PDF files if not explicitly requested by extension or name', async () => {
417 |       createBinaryFile('document.pdf', Buffer.from('%PDF-1.4...'));
418 |       createFile('notes.txt', 'text notes');
419 |       const params = { paths: ['*'] }; // Generic glob, not specific to .pdf
420 |       const invocation = tool.build(params);
421 |       const result = await invocation.execute(new AbortController().signal);
422 |       const content = result.llmContent as string[];
423 |       const expectedPath = path.join(tempRootDir, 'notes.txt');
424 |       expect(
425 |         content.some(
426 |           (c) =>
427 |             typeof c === 'string' &&
428 |             c.includes(`--- ${expectedPath} ---\n\ntext notes\n\n`),
429 |         ),
430 |       ).toBe(true);
431 |       expect(result.returnDisplay).toContain('**Skipped 1 item(s):**');
432 |       expect(result.returnDisplay).toContain(
433 |         '- `document.pdf` (Reason: asset file (image/pdf) was not explicitly requested by name or extension)',
434 |       );
435 |     });
436 | 
437 |     it('should include PDF files as inlineData parts if explicitly requested by extension', async () => {
438 |       createBinaryFile('important.pdf', Buffer.from('%PDF-1.4...'));
439 |       const params = { paths: ['*.pdf'] }; // Explicitly requesting .pdf files
440 |       const invocation = tool.build(params);
441 |       const result = await invocation.execute(new AbortController().signal);
442 |       expect(result.llmContent).toEqual([
443 |         {
444 |           inlineData: {
445 |             data: Buffer.from('%PDF-1.4...').toString('base64'),
446 |             mimeType: 'application/pdf',
447 |           },
448 |         },
449 |         '\n--- End of content ---',
450 |       ]);
451 |     });
452 | 
453 |     it('should include PDF files as inlineData parts if explicitly requested by name', async () => {
454 |       createBinaryFile('report-final.pdf', Buffer.from('%PDF-1.4...'));
455 |       const params = { paths: ['report-final.pdf'] };
456 |       const invocation = tool.build(params);
457 |       const result = await invocation.execute(new AbortController().signal);
458 |       expect(result.llmContent).toEqual([
459 |         {
460 |           inlineData: {
461 |             data: Buffer.from('%PDF-1.4...').toString('base64'),
462 |             mimeType: 'application/pdf',
463 |           },
464 |         },
465 |         '\n--- End of content ---',
466 |       ]);
467 |     });
468 | 
469 |     it('should return error if path is ignored by a .geminiignore pattern', async () => {
470 |       createFile('foo.bar', '');
471 |       createFile('bar.ts', '');
472 |       createFile('foo.quux', '');
473 |       const params = { paths: ['foo.bar', 'bar.ts', 'foo.quux'] };
474 |       const invocation = tool.build(params);
475 |       const result = await invocation.execute(new AbortController().signal);
476 |       expect(result.returnDisplay).not.toContain('foo.bar');
477 |       expect(result.returnDisplay).not.toContain('foo.quux');
478 |       expect(result.returnDisplay).toContain('bar.ts');
479 |     });
480 | 
481 |     it('should read files from multiple workspace directories', async () => {
482 |       const tempDir1 = fs.realpathSync(
483 |         fs.mkdtempSync(path.join(os.tmpdir(), 'multi-dir-1-')),
484 |       );
485 |       const tempDir2 = fs.realpathSync(
486 |         fs.mkdtempSync(path.join(os.tmpdir(), 'multi-dir-2-')),
487 |       );
488 |       const fileService = new FileDiscoveryService(tempDir1);
489 |       const mockConfig = {
490 |         getFileService: () => fileService,
491 |         getFileSystemService: () => new StandardFileSystemService(),
492 |         getFileFilteringOptions: () => ({
493 |           respectGitIgnore: true,
494 |           respectGeminiIgnore: true,
495 |         }),
496 |         getWorkspaceContext: () => new WorkspaceContext(tempDir1, [tempDir2]),
497 |         getTargetDir: () => tempDir1,
498 |         getFileExclusions: () => ({
499 |           getCoreIgnorePatterns: () => COMMON_IGNORE_PATTERNS,
500 |           getDefaultExcludePatterns: () => [],
501 |           getGlobExcludes: () => COMMON_IGNORE_PATTERNS,
502 |           buildExcludePatterns: () => [],
503 |           getReadManyFilesExcludes: () => [],
504 |         }),
505 |       } as Partial<Config> as Config;
506 |       tool = new ReadManyFilesTool(mockConfig);
507 | 
508 |       fs.writeFileSync(path.join(tempDir1, 'file1.txt'), 'Content1');
509 |       fs.writeFileSync(path.join(tempDir2, 'file2.txt'), 'Content2');
510 | 
511 |       const params = { paths: ['*.txt'] };
512 |       const invocation = tool.build(params);
513 |       const result = await invocation.execute(new AbortController().signal);
514 |       const content = result.llmContent as string[];
515 |       if (!Array.isArray(content)) {
516 |         throw new Error(`llmContent is not an array: ${content}`);
517 |       }
518 |       const expectedPath1 = path.join(tempDir1, 'file1.txt');
[TRUNCATED]
```

src/tools/read-many-files.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { ToolInvocation, ToolResult } from './tools.js';
8 | import { BaseDeclarativeTool, BaseToolInvocation, Kind } from './tools.js';
9 | import { getErrorMessage } from '../utils/errors.js';
10 | import * as fs from 'node:fs';
11 | import * as path from 'node:path';
12 | import { glob, escape } from 'glob';
13 | import type { ProcessedFileReadResult } from '../utils/fileUtils.js';
14 | import {
15 |   detectFileType,
16 |   processSingleFileContent,
17 |   DEFAULT_ENCODING,
18 |   getSpecificMimeType,
19 | } from '../utils/fileUtils.js';
20 | import type { PartListUnion } from '@google/genai';
21 | import {
22 |   type Config,
23 |   DEFAULT_FILE_FILTERING_OPTIONS,
24 | } from '../config/config.js';
25 | import { FileOperation } from '../telemetry/metrics.js';
26 | import { getProgrammingLanguage } from '../telemetry/telemetry-utils.js';
27 | import { logFileOperation } from '../telemetry/loggers.js';
28 | import { FileOperationEvent } from '../telemetry/types.js';
29 | import { ToolErrorType } from './tool-error.js';
30 | 
31 | /**
32 |  * Parameters for the ReadManyFilesTool.
33 |  */
34 | export interface ReadManyFilesParams {
35 |   /**
36 |    * An array of file paths or directory paths to search within.
37 |    * Paths are relative to the tool's configured target directory.
38 |    * Glob patterns can be used directly in these paths.
39 |    */
40 |   paths: string[];
41 | 
42 |   /**
43 |    * Optional. Glob patterns for files to include.
44 |    * These are effectively combined with the `paths`.
45 |    * Example: ["*.ts", "src/** /*.md"]
46 |    */
47 |   include?: string[];
48 | 
49 |   /**
50 |    * Optional. Glob patterns for files/directories to exclude.
51 |    * Applied as ignore patterns.
52 |    * Example: ["*.log", "dist/**"]
53 |    */
54 |   exclude?: string[];
55 | 
56 |   /**
57 |    * Optional. Search directories recursively.
58 |    * This is generally controlled by glob patterns (e.g., `**`).
59 |    * The glob implementation is recursive by default for `**`.
60 |    * For simplicity, we'll rely on `**` for recursion.
61 |    */
62 |   recursive?: boolean;
63 | 
64 |   /**
65 |    * Optional. Apply default exclusion patterns. Defaults to true.
66 |    */
67 |   useDefaultExcludes?: boolean;
68 | 
69 |   /**
70 |    * Whether to respect .gitignore and .geminiignore patterns (optional, defaults to true)
71 |    */
72 |   file_filtering_options?: {
73 |     respect_git_ignore?: boolean;
74 |     respect_gemini_ignore?: boolean;
75 |   };
76 | }
77 | 
78 | /**
79 |  * Result type for file processing operations
80 |  */
81 | type FileProcessingResult =
82 |   | {
83 |       success: true;
84 |       filePath: string;
85 |       relativePathForDisplay: string;
86 |       fileReadResult: ProcessedFileReadResult;
87 |       reason?: undefined;
88 |     }
89 |   | {
90 |       success: false;
91 |       filePath: string;
92 |       relativePathForDisplay: string;
93 |       fileReadResult?: undefined;
94 |       reason: string;
95 |     };
96 | 
97 | /**
98 |  * Creates the default exclusion patterns including dynamic patterns.
99 |  * This combines the shared patterns with dynamic patterns like GEMINI.md.
100 |  * TODO(adh): Consider making this configurable or extendable through a command line argument.
101 |  */
102 | function getDefaultExcludes(config?: Config): string[] {
103 |   return config?.getFileExclusions().getReadManyFilesExcludes() ?? [];
104 | }
105 | 
106 | const DEFAULT_OUTPUT_SEPARATOR_FORMAT = '--- {filePath} ---';
107 | const DEFAULT_OUTPUT_TERMINATOR = '\n--- End of content ---';
108 | 
109 | class ReadManyFilesToolInvocation extends BaseToolInvocation<
110 |   ReadManyFilesParams,
111 |   ToolResult
112 | > {
113 |   constructor(
114 |     private readonly config: Config,
115 |     params: ReadManyFilesParams,
116 |   ) {
117 |     super(params);
118 |   }
119 | 
120 |   getDescription(): string {
121 |     const allPatterns = [...this.params.paths, ...(this.params.include || [])];
122 |     const pathDesc = `using patterns: 
123 | ${allPatterns.join('`, `')}
124 |  (within target directory: 
125 | ${this.config.getTargetDir()}
126 | ) `;
127 | 
128 |     // Determine the final list of exclusion patterns exactly as in execute method
129 |     const paramExcludes = this.params.exclude || [];
130 |     const paramUseDefaultExcludes = this.params.useDefaultExcludes !== false;
131 |     const geminiIgnorePatterns = this.config
132 |       .getFileService()
133 |       .getGeminiIgnorePatterns();
134 |     const finalExclusionPatternsForDescription: string[] =
135 |       paramUseDefaultExcludes
136 |         ? [
137 |             ...getDefaultExcludes(this.config),
138 |             ...paramExcludes,
139 |             ...geminiIgnorePatterns,
140 |           ]
141 |         : [...paramExcludes, ...geminiIgnorePatterns];
142 | 
143 |     let excludeDesc = `Excluding: ${
144 |       finalExclusionPatternsForDescription.length > 0
145 |         ? `patterns like 
146 | ${finalExclusionPatternsForDescription
147 |   .slice(0, 2)
148 |   .join(
149 |     '`, `',
150 |   )}${finalExclusionPatternsForDescription.length > 2 ? '...`' : '`'}`
151 |         : 'none specified'
152 |     }`;
153 | 
154 |     // Add a note if .geminiignore patterns contributed to the final list of exclusions
155 |     if (geminiIgnorePatterns.length > 0) {
156 |       const geminiPatternsInEffect = geminiIgnorePatterns.filter((p) =>
157 |         finalExclusionPatternsForDescription.includes(p),
158 |       ).length;
159 |       if (geminiPatternsInEffect > 0) {
160 |         excludeDesc += ` (includes ${geminiPatternsInEffect} from .geminiignore)`;
161 |       }
162 |     }
163 | 
164 |     return `Will attempt to read and concatenate files ${pathDesc}. ${excludeDesc}. File encoding: ${DEFAULT_ENCODING}. Separator: "${DEFAULT_OUTPUT_SEPARATOR_FORMAT.replace(
165 |       '{filePath}',
166 |       'path/to/file.ext',
167 |     )}".`;
168 |   }
169 | 
170 |   async execute(signal: AbortSignal): Promise<ToolResult> {
171 |     const {
172 |       paths: inputPatterns,
173 |       include = [],
174 |       exclude = [],
175 |       useDefaultExcludes = true,
176 |     } = this.params;
177 | 
178 |     const filesToConsider = new Set<string>();
179 |     const skippedFiles: Array<{ path: string; reason: string }> = [];
180 |     const processedFilesRelativePaths: string[] = [];
181 |     const contentParts: PartListUnion = [];
182 | 
183 |     const effectiveExcludes = useDefaultExcludes
184 |       ? [...getDefaultExcludes(this.config), ...exclude]
185 |       : [...exclude];
186 | 
187 |     const searchPatterns = [...inputPatterns, ...include];
188 |     try {
189 |       const allEntries = new Set<string>();
190 |       const workspaceDirs = this.config.getWorkspaceContext().getDirectories();
191 | 
192 |       for (const dir of workspaceDirs) {
193 |         const processedPatterns = [];
194 |         for (const p of searchPatterns) {
195 |           const normalizedP = p.replace(/\\/g, '/');
196 |           const fullPath = path.join(dir, normalizedP);
197 |           if (fs.existsSync(fullPath)) {
198 |             processedPatterns.push(escape(normalizedP));
199 |           } else {
200 |             // The path does not exist or is not a file, so we treat it as a glob pattern.
201 |             processedPatterns.push(normalizedP);
202 |           }
203 |         }
204 | 
205 |         const entriesInDir = await glob(processedPatterns, {
206 |           cwd: dir,
207 |           ignore: effectiveExcludes,
208 |           nodir: true,
209 |           dot: true,
210 |           absolute: true,
211 |           nocase: true,
212 |           signal,
213 |         });
214 |         for (const entry of entriesInDir) {
215 |           allEntries.add(entry);
216 |         }
217 |       }
218 |       const relativeEntries = Array.from(allEntries).map((p) =>
219 |         path.relative(this.config.getTargetDir(), p),
220 |       );
221 | 
222 |       const fileDiscovery = this.config.getFileService();
223 |       const { filteredPaths, gitIgnoredCount, geminiIgnoredCount } =
224 |         fileDiscovery.filterFilesWithReport(relativeEntries, {
225 |           respectGitIgnore:
226 |             this.params.file_filtering_options?.respect_git_ignore ??
227 |             this.config.getFileFilteringOptions().respectGitIgnore ??
228 |             DEFAULT_FILE_FILTERING_OPTIONS.respectGitIgnore,
229 |           respectGeminiIgnore:
230 |             this.params.file_filtering_options?.respect_gemini_ignore ??
231 |             this.config.getFileFilteringOptions().respectGeminiIgnore ??
232 |             DEFAULT_FILE_FILTERING_OPTIONS.respectGeminiIgnore,
233 |         });
234 | 
235 |       for (const relativePath of filteredPaths) {
236 |         // Security check: ensure the glob library didn't return something outside the workspace.
237 | 
238 |         const fullPath = path.resolve(this.config.getTargetDir(), relativePath);
239 |         if (
240 |           !this.config.getWorkspaceContext().isPathWithinWorkspace(fullPath)
241 |         ) {
242 |           skippedFiles.push({
243 |             path: fullPath,
244 |             reason: `Security: Glob library returned path outside workspace. Path: ${fullPath}`,
245 |           });
246 |           continue;
247 |         }
248 |         filesToConsider.add(fullPath);
249 |       }
250 | 
251 |       // Add info about git-ignored files if any were filtered
252 |       if (gitIgnoredCount > 0) {
253 |         skippedFiles.push({
254 |           path: `${gitIgnoredCount} file(s)`,
255 |           reason: 'git ignored',
256 |         });
257 |       }
258 | 
259 |       // Add info about gemini-ignored files if any were filtered
260 |       if (geminiIgnoredCount > 0) {
261 |         skippedFiles.push({
262 |           path: `${geminiIgnoredCount} file(s)`,
263 |           reason: 'gemini ignored',
264 |         });
265 |       }
266 |     } catch (error) {
267 |       const errorMessage = `Error during file search: ${getErrorMessage(error)}`;
268 |       return {
269 |         llmContent: errorMessage,
270 |         returnDisplay: `## File Search Error\n\nAn error occurred while searching for files:\n\`\`\`\n${getErrorMessage(error)}\n\`\`\``,
271 |         error: {
272 |           message: errorMessage,
273 |           type: ToolErrorType.READ_MANY_FILES_SEARCH_ERROR,
274 |         },
275 |       };
276 |     }
277 | 
278 |     const sortedFiles = Array.from(filesToConsider).sort();
279 | 
280 |     const fileProcessingPromises = sortedFiles.map(
281 |       async (filePath): Promise<FileProcessingResult> => {
282 |         try {
283 |           const relativePathForDisplay = path
284 |             .relative(this.config.getTargetDir(), filePath)
285 |             .replace(/\\/g, '/');
286 | 
287 |           const fileType = await detectFileType(filePath);
288 | 
289 |           if (fileType === 'image' || fileType === 'pdf') {
290 |             const fileExtension = path.extname(filePath).toLowerCase();
291 |             const fileNameWithoutExtension = path.basename(
292 |               filePath,
293 |               fileExtension,
294 |             );
295 |             const requestedExplicitly = inputPatterns.some(
296 |               (pattern: string) =>
297 |                 pattern.toLowerCase().includes(fileExtension) ||
298 |                 pattern.includes(fileNameWithoutExtension),
299 |             );
300 | 
301 |             if (!requestedExplicitly) {
302 |               return {
303 |                 success: false,
304 |                 filePath,
305 |                 relativePathForDisplay,
306 |                 reason:
307 |                   'asset file (image/pdf) was not explicitly requested by name or extension',
308 |               };
309 |             }
310 |           }
311 | 
312 |           // Use processSingleFileContent for all file types now
313 |           const fileReadResult = await processSingleFileContent(
314 |             filePath,
315 |             this.config.getTargetDir(),
316 |             this.config.getFileSystemService(),
317 |           );
318 | 
319 |           if (fileReadResult.error) {
320 |             return {
321 |               success: false,
322 |               filePath,
323 |               relativePathForDisplay,
324 |               reason: `Read error: ${fileReadResult.error}`,
325 |             };
326 |           }
327 | 
328 |           return {
329 |             success: true,
330 |             filePath,
331 |             relativePathForDisplay,
332 |             fileReadResult,
333 |           };
334 |         } catch (error) {
335 |           const relativePathForDisplay = path
336 |             .relative(this.config.getTargetDir(), filePath)
337 |             .replace(/\\/g, '/');
338 | 
339 |           return {
340 |             success: false,
341 |             filePath,
342 |             relativePathForDisplay,
343 |             reason: `Unexpected error: ${error instanceof Error ? error.message : String(error)}`,
344 |           };
345 |         }
346 |       },
347 |     );
348 | 
349 |     const results = await Promise.allSettled(fileProcessingPromises);
350 | 
351 |     for (const result of results) {
352 |       if (result.status === 'fulfilled') {
353 |         const fileResult = result.value;
354 | 
355 |         if (!fileResult.success) {
356 |           // Handle skipped files (images/PDFs not requested or read errors)
357 |           skippedFiles.push({
358 |             path: fileResult.relativePathForDisplay,
359 |             reason: fileResult.reason,
360 |           });
361 |         } else {
362 |           // Handle successfully processed files
363 |           const { filePath, relativePathForDisplay, fileReadResult } =
364 |             fileResult;
365 | 
366 |           if (typeof fileReadResult.llmContent === 'string') {
367 |             const separator = DEFAULT_OUTPUT_SEPARATOR_FORMAT.replace(
368 |               '{filePath}',
369 |               filePath,
370 |             );
371 |             let fileContentForLlm = '';
372 |             if (fileReadResult.isTruncated) {
373 |               fileContentForLlm += `[WARNING: This file was truncated. To view the full content, use the 'read_file' tool on this specific file.]\n\n`;
374 |             }
375 |             fileContentForLlm += fileReadResult.llmContent;
376 |             contentParts.push(`${separator}\n\n${fileContentForLlm}\n\n`);
377 |           } else {
378 |             // This is a Part for image/pdf, which we don't add the separator to.
379 |             contentParts.push(fileReadResult.llmContent);
380 |           }
381 | 
382 |           processedFilesRelativePaths.push(relativePathForDisplay);
383 | 
384 |           const lines =
385 |             typeof fileReadResult.llmContent === 'string'
386 |               ? fileReadResult.llmContent.split('\n').length
387 |               : undefined;
388 |           const mimetype = getSpecificMimeType(filePath);
389 |           const programming_language = getProgrammingLanguage({
390 |             absolute_path: filePath,
391 |           });
392 |           logFileOperation(
393 |             this.config,
394 |             new FileOperationEvent(
395 |               ReadManyFilesTool.Name,
396 |               FileOperation.READ,
397 |               lines,
398 |               mimetype,
399 |               path.extname(filePath),
400 |               programming_language,
401 |             ),
402 |           );
403 |         }
404 |       } else {
405 |         // Handle Promise rejection (unexpected errors)
406 |         skippedFiles.push({
407 |           path: 'unknown',
408 |           reason: `Unexpected error: ${result.reason}`,
409 |         });
410 |       }
411 |     }
412 | 
413 |     let displayMessage = `### ReadManyFiles Result (Target Dir: \`${this.config.getTargetDir()}\`)\n\n`;
414 |     if (processedFilesRelativePaths.length > 0) {
415 |       displayMessage += `Successfully read and concatenated content from **${processedFilesRelativePaths.length} file(s)**.\n`;
416 |       if (processedFilesRelativePaths.length <= 10) {
417 |         displayMessage += `\n**Processed Files:**\n`;
418 |         processedFilesRelativePaths.forEach(
419 |           (p) => (displayMessage += `- \`${p}\`\n`),
420 |         );
421 |       } else {
422 |         displayMessage += `\n**Processed Files (first 10 shown):**\n`;
423 |         processedFilesRelativePaths
424 |           .slice(0, 10)
425 |           .forEach((p) => (displayMessage += `- \`${p}\`\n`));
426 |         displayMessage += `- ...and ${processedFilesRelativePaths.length - 10} more.\n`;
427 |       }
428 |     }
429 | 
430 |     if (skippedFiles.length > 0) {
431 |       if (processedFilesRelativePaths.length === 0) {
432 |         displayMessage += `No files were read and concatenated based on the criteria.\n`;
433 |       }
434 |       if (skippedFiles.length <= 5) {
435 |         displayMessage += `\n**Skipped ${skippedFiles.length} item(s):**\n`;
436 |       } else {
437 |         displayMessage += `\n**Skipped ${skippedFiles.length} item(s) (first 5 shown):**\n`;
438 |       }
439 |       skippedFiles
440 |         .slice(0, 5)
441 |         .forEach(
442 |           (f) => (displayMessage += `- \`${f.path}\` (Reason: ${f.reason})\n`),
443 |         );
444 |       if (skippedFiles.length > 5) {
445 |         displayMessage += `- ...and ${skippedFiles.length - 5} more.\n`;
446 |       }
447 |     } else if (
448 |       processedFilesRelativePaths.length === 0 &&
449 |       skippedFiles.length === 0
450 |     ) {
451 |       displayMessage += `No files were read and concatenated based on the criteria.\n`;
452 |     }
453 | 
454 |     if (contentParts.length > 0) {
455 |       contentParts.push(DEFAULT_OUTPUT_TERMINATOR);
456 |     } else {
457 |       contentParts.push(
458 |         'No files matching the criteria were found or all were skipped.',
459 |       );
460 |     }
461 |     return {
462 |       llmContent: contentParts,
463 |       returnDisplay: displayMessage.trim(),
464 |     };
465 |   }
466 | }
467 | 
468 | /**
469 |  * Tool implementation for finding and reading multiple text files from the local filesystem
470 |  * within a specified target directory. The content is concatenated.
471 |  * It is intended to run in an environment with access to the local file system (e.g., a Node.js backend).
472 |  */
473 | export class ReadManyFilesTool extends BaseDeclarativeTool<
474 |   ReadManyFilesParams,
475 |   ToolResult
476 | > {
477 |   static readonly Name: string = 'read_many_files';
478 | 
479 |   constructor(private config: Config) {
480 |     const parameterSchema = {
481 |       type: 'object',
482 |       properties: {
483 |         paths: {
484 |           type: 'array',
485 |           items: {
486 |             type: 'string',
487 |             minLength: 1,
488 |           },
489 |           minItems: 1,
490 |           description:
491 |             "Required. An array of glob patterns or paths relative to the tool's target directory. Examples: ['src/**/*.ts'], ['README.md', 'docs/']",
492 |         },
493 |         include: {
494 |           type: 'array',
495 |           items: {
496 |             type: 'string',
497 |             minLength: 1,
498 |           },
499 |           description:
500 |             'Optional. Additional glob patterns to include. These are merged with `paths`. Example: "*.test.ts" to specifically add test files if they were broadly excluded.',
501 |           default: [],
502 |         },
503 |         exclude: {
504 |           type: 'array',
505 |           items: {
506 |             type: 'string',
507 |             minLength: 1,
508 |           },
509 |           description:
510 |             'Optional. Glob patterns for files/directories to exclude. Added to default excludes if useDefaultExcludes is true. Example: "**/*.log", "temp/"',
511 |           default: [],
512 |         },
513 |         recursive: {
514 |           type: 'boolean',
515 |           description:
516 |             'Optional. Whether to search recursively (primarily controlled by `**` in glob patterns). Defaults to true.',
517 |           default: true,
518 |         },
519 |         useDefaultExcludes: {
520 |           type: 'boolean',
521 |           description:
522 |             'Optional. Whether to apply a list of default exclusion patterns (e.g., node_modules, .git, binary files). Defaults to true.',
523 |           default: true,
524 |         },
525 |         file_filtering_options: {
526 |           description:
527 |             'Whether to respect ignore patterns from .gitignore or .geminiignore',
528 |           type: 'object',
529 |           properties: {
530 |             respect_git_ignore: {
531 |               description:
532 |                 'Optional: Whether to respect .gitignore patterns when listing files. Only available in git repositories. Defaults to true.',
533 |               type: 'boolean',
534 |             },
535 |             respect_gemini_ignore: {
536 |               description:
537 |                 'Optional: Whether to respect .geminiignore patterns when listing files. Defaults to true.',
538 |               type: 'boolean',
539 |             },
540 |           },
541 |         },
542 |       },
543 |       required: ['paths'],
544 |     };
545 | 
546 |     super(
547 |       ReadManyFilesTool.Name,
548 |       'ReadManyFiles',
549 |       `Reads content from multiple files specified by paths or glob patterns within a configured target directory. For text files, it concatenates their content into a single string. It is primarily designed for text-based files. However, it can also process image (e.g., .png, .jpg) and PDF (.pdf) files if their file names or extensions are explicitly included in the 'paths' argument. For these explicitly requested non-text files, their data is read and included in a format suitable for model consumption (e.g., base64 encoded).
550 | 
551 | This tool is useful when you need to understand or analyze a collection of files, such as:
552 | - Getting an overview of a codebase or parts of it (e.g., all TypeScript files in the 'src' directory).
553 | - Finding where specific functionality is implemented if the user asks broad questions about code.
554 | - Reviewing documentation files (e.g., all Markdown files in the 'docs' directory).
555 | - Gathering context from multiple configuration files.
556 | - When the user asks to "read all files in X directory" or "show me the content of all Y files".
557 | 
558 | Use this tool when the user's query implies needing the content of several files simultaneously for context, analysis, or summarization. For text files, it uses default UTF-8 encoding and a '--- {filePath} ---' separator between file contents. The tool inserts a '--- End of content ---' after the last file. Ensure paths are relative to the target directory. Glob patterns like 'src/**/*.js' are supported. Avoid using for single files if a more specific single-file reading tool is available, unless the user specifically requests to process a list containing just one file via this tool. Other binary files (not explicitly requested as image/PDF) are generally skipped. Default excludes apply to common non-text files (except for explicitly requested images/PDFs) and large dependency directories unless 'useDefaultExcludes' is false.`,
559 |       Kind.Read,
560 |       parameterSchema,
561 |     );
562 |   }
563 | 
564 |   protected createInvocation(
565 |     params: ReadManyFilesParams,
566 |   ): ToolInvocation<ReadManyFilesParams, ToolResult> {
567 |     return new ReadManyFilesToolInvocation(this.config, params);
568 |   }
[TRUNCATED]
```

src/tools/ripGrep.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   beforeEach,
12 |   afterEach,
13 |   vi,
14 |   type Mock,
15 | } from 'vitest';
16 | import type { RipGrepToolParams } from './ripGrep.js';
17 | import { canUseRipgrep, RipGrepTool, ensureRgPath } from './ripGrep.js';
18 | import path from 'node:path';
19 | import fs from 'node:fs/promises';
20 | import os, { EOL } from 'node:os';
21 | import type { Config } from '../config/config.js';
22 | import { createMockWorkspaceContext } from '../test-utils/mockWorkspaceContext.js';
23 | import type { ChildProcess } from 'node:child_process';
24 | import { spawn } from 'node:child_process';
25 | import { downloadRipGrep } from '@joshua.litt/get-ripgrep';
26 | import { fileExists } from '../utils/fileUtils.js';
27 | 
28 | // Mock dependencies for canUseRipgrep
29 | vi.mock('@joshua.litt/get-ripgrep', () => ({
30 |   downloadRipGrep: vi.fn(),
31 | }));
32 | vi.mock('../utils/fileUtils.js', async (importOriginal) => {
33 |   const actual = await importOriginal<typeof import('../utils/fileUtils.js')>();
34 |   return {
35 |     ...actual,
36 |     fileExists: vi.fn(),
37 |   };
38 | });
39 | vi.mock('../config/storage.js', () => ({
40 |   Storage: {
41 |     getGlobalBinDir: vi.fn().mockReturnValue('/mock/bin/dir'),
42 |   },
43 | }));
44 | 
45 | // Mock child_process for ripgrep calls
46 | vi.mock('child_process', () => ({
47 |   spawn: vi.fn(),
48 | }));
49 | 
50 | const mockSpawn = vi.mocked(spawn);
51 | 
52 | describe('canUseRipgrep', () => {
53 |   beforeEach(() => {
54 |     vi.clearAllMocks();
55 |   });
56 | 
57 |   it('should return true if ripgrep already exists', async () => {
58 |     (fileExists as Mock).mockResolvedValue(true);
59 |     const result = await canUseRipgrep();
60 |     expect(result).toBe(true);
61 |     expect(fileExists).toHaveBeenCalledWith(path.join('/mock/bin/dir', 'rg'));
62 |     expect(downloadRipGrep).not.toHaveBeenCalled();
63 |   });
64 | 
65 |   it('should download ripgrep and return true if it does not exist initially', async () => {
66 |     (fileExists as Mock)
67 |       .mockResolvedValueOnce(false)
68 |       .mockResolvedValueOnce(true);
69 |     (downloadRipGrep as Mock).mockResolvedValue(undefined);
70 | 
71 |     const result = await canUseRipgrep();
72 | 
73 |     expect(result).toBe(true);
74 |     expect(fileExists).toHaveBeenCalledTimes(2);
75 |     expect(downloadRipGrep).toHaveBeenCalledWith('/mock/bin/dir');
76 |   });
77 | 
78 |   it('should return false if download fails and file does not exist', async () => {
79 |     (fileExists as Mock).mockResolvedValue(false);
80 |     (downloadRipGrep as Mock).mockResolvedValue(undefined);
81 | 
82 |     const result = await canUseRipgrep();
83 | 
84 |     expect(result).toBe(false);
85 |     expect(fileExists).toHaveBeenCalledTimes(2);
86 |     expect(downloadRipGrep).toHaveBeenCalledWith('/mock/bin/dir');
87 |   });
88 | 
89 |   it('should propagate errors from downloadRipGrep', async () => {
90 |     const error = new Error('Download failed');
91 |     (fileExists as Mock).mockResolvedValue(false);
92 |     (downloadRipGrep as Mock).mockRejectedValue(error);
93 | 
94 |     await expect(canUseRipgrep()).rejects.toThrow(error);
95 |     expect(fileExists).toHaveBeenCalledTimes(1);
96 |     expect(downloadRipGrep).toHaveBeenCalledWith('/mock/bin/dir');
97 |   });
98 | });
99 | 
100 | describe('ensureRgPath', () => {
101 |   beforeEach(() => {
102 |     vi.clearAllMocks();
103 |   });
104 | 
105 |   it('should return rg path if ripgrep already exists', async () => {
106 |     (fileExists as Mock).mockResolvedValue(true);
107 |     const rgPath = await ensureRgPath();
108 |     expect(rgPath).toBe(path.join('/mock/bin/dir', 'rg'));
109 |     expect(fileExists).toHaveBeenCalledOnce();
110 |     expect(downloadRipGrep).not.toHaveBeenCalled();
111 |   });
112 | 
113 |   it('should return rg path if ripgrep is downloaded successfully', async () => {
114 |     (fileExists as Mock)
115 |       .mockResolvedValueOnce(false)
116 |       .mockResolvedValueOnce(true);
117 |     (downloadRipGrep as Mock).mockResolvedValue(undefined);
118 |     const rgPath = await ensureRgPath();
119 |     expect(rgPath).toBe(path.join('/mock/bin/dir', 'rg'));
120 |     expect(downloadRipGrep).toHaveBeenCalledOnce();
121 |     expect(fileExists).toHaveBeenCalledTimes(2);
122 |   });
123 | 
124 |   it('should throw an error if ripgrep cannot be used after download attempt', async () => {
125 |     (fileExists as Mock).mockResolvedValue(false);
126 |     (downloadRipGrep as Mock).mockResolvedValue(undefined);
127 |     await expect(ensureRgPath()).rejects.toThrow('Cannot use ripgrep.');
128 |     expect(downloadRipGrep).toHaveBeenCalledOnce();
129 |     expect(fileExists).toHaveBeenCalledTimes(2);
130 |   });
131 | 
132 |   it('should propagate errors from downloadRipGrep', async () => {
133 |     const error = new Error('Download failed');
134 |     (fileExists as Mock).mockResolvedValue(false);
135 |     (downloadRipGrep as Mock).mockRejectedValue(error);
136 | 
137 |     await expect(ensureRgPath()).rejects.toThrow(error);
138 |     expect(fileExists).toHaveBeenCalledTimes(1);
139 |     expect(downloadRipGrep).toHaveBeenCalledWith('/mock/bin/dir');
140 |   });
141 | });
142 | 
143 | // Helper function to create mock spawn implementations
144 | function createMockSpawn(
145 |   options: {
146 |     outputData?: string;
147 |     exitCode?: number;
148 |     signal?: string;
149 |   } = {},
150 | ) {
151 |   const { outputData, exitCode = 0, signal } = options;
152 | 
153 |   return () => {
154 |     const mockProcess = {
155 |       stdout: {
156 |         on: vi.fn(),
157 |         removeListener: vi.fn(),
158 |       },
159 |       stderr: {
160 |         on: vi.fn(),
161 |         removeListener: vi.fn(),
162 |       },
163 |       on: vi.fn(),
164 |       removeListener: vi.fn(),
165 |       kill: vi.fn(),
166 |     };
167 | 
168 |     // Set up event listeners immediately
169 |     setTimeout(() => {
170 |       const stdoutDataHandler = mockProcess.stdout.on.mock.calls.find(
171 |         (call) => call[0] === 'data',
172 |       )?.[1];
173 | 
174 |       const closeHandler = mockProcess.on.mock.calls.find(
175 |         (call) => call[0] === 'close',
176 |       )?.[1];
177 | 
178 |       if (stdoutDataHandler && outputData) {
179 |         stdoutDataHandler(Buffer.from(outputData));
180 |       }
181 | 
182 |       if (closeHandler) {
183 |         closeHandler(exitCode, signal);
184 |       }
185 |     }, 0);
186 | 
187 |     return mockProcess as unknown as ChildProcess;
188 |   };
189 | }
190 | 
191 | describe('RipGrepTool', () => {
192 |   let tempRootDir: string;
193 |   let grepTool: RipGrepTool;
194 |   const abortSignal = new AbortController().signal;
195 | 
196 |   const mockConfig = {
197 |     getTargetDir: () => tempRootDir,
198 |     getWorkspaceContext: () => createMockWorkspaceContext(tempRootDir),
199 |     getDebugMode: () => false,
200 |   } as unknown as Config;
201 | 
202 |   beforeEach(async () => {
203 |     vi.clearAllMocks();
204 |     (downloadRipGrep as Mock).mockResolvedValue(undefined);
205 |     (fileExists as Mock).mockResolvedValue(true);
206 |     mockSpawn.mockClear();
207 |     tempRootDir = await fs.mkdtemp(path.join(os.tmpdir(), 'grep-tool-root-'));
208 |     grepTool = new RipGrepTool(mockConfig);
209 | 
210 |     // Create some test files and directories
211 |     await fs.writeFile(
212 |       path.join(tempRootDir, 'fileA.txt'),
213 |       'hello world\nsecond line with world',
214 |     );
215 |     await fs.writeFile(
216 |       path.join(tempRootDir, 'fileB.js'),
217 |       'const foo = "bar";\nfunction baz() { return "hello"; }',
218 |     );
219 |     await fs.mkdir(path.join(tempRootDir, 'sub'));
220 |     await fs.writeFile(
221 |       path.join(tempRootDir, 'sub', 'fileC.txt'),
222 |       'another world in sub dir',
223 |     );
224 |     await fs.writeFile(
225 |       path.join(tempRootDir, 'sub', 'fileD.md'),
226 |       '# Markdown file\nThis is a test.',
227 |     );
228 |   });
229 | 
230 |   afterEach(async () => {
231 |     await fs.rm(tempRootDir, { recursive: true, force: true });
232 |   });
233 | 
234 |   describe('validateToolParams', () => {
235 |     it('should return null for valid params (pattern only)', () => {
236 |       const params: RipGrepToolParams = { pattern: 'hello' };
237 |       expect(grepTool.validateToolParams(params)).toBeNull();
238 |     });
239 | 
240 |     it('should return null for valid params (pattern and path)', () => {
241 |       const params: RipGrepToolParams = { pattern: 'hello', path: '.' };
242 |       expect(grepTool.validateToolParams(params)).toBeNull();
243 |     });
244 | 
245 |     it('should return null for valid params (pattern, path, and include)', () => {
246 |       const params: RipGrepToolParams = {
247 |         pattern: 'hello',
248 |         path: '.',
249 |         include: '*.txt',
250 |       };
251 |       expect(grepTool.validateToolParams(params)).toBeNull();
252 |     });
253 | 
254 |     it('should return error if pattern is missing', () => {
255 |       const params = { path: '.' } as unknown as RipGrepToolParams;
256 |       expect(grepTool.validateToolParams(params)).toBe(
257 |         `params must have required property 'pattern'`,
258 |       );
259 |     });
260 | 
261 |     it('should return null for what would be an invalid regex pattern', () => {
262 |       const params: RipGrepToolParams = { pattern: '[[' };
263 |       expect(grepTool.validateToolParams(params)).toBeNull();
264 |     });
265 | 
266 |     it('should return error if path does not exist', () => {
267 |       const params: RipGrepToolParams = {
268 |         pattern: 'hello',
269 |         path: 'nonexistent',
270 |       };
271 |       // Check for the core error message, as the full path might vary
272 |       expect(grepTool.validateToolParams(params)).toContain(
273 |         'Failed to access path stats for',
274 |       );
275 |       expect(grepTool.validateToolParams(params)).toContain('nonexistent');
276 |     });
277 | 
278 |     it('should return error if path is a file, not a directory', async () => {
279 |       const filePath = path.join(tempRootDir, 'fileA.txt');
280 |       const params: RipGrepToolParams = { pattern: 'hello', path: filePath };
281 |       expect(grepTool.validateToolParams(params)).toContain(
282 |         `Path is not a directory: ${filePath}`,
283 |       );
284 |     });
285 |   });
286 | 
287 |   describe('execute', () => {
288 |     it('should find matches for a simple pattern in all files', async () => {
289 |       mockSpawn.mockImplementationOnce(
290 |         createMockSpawn({
291 |           outputData: `fileA.txt:1:hello world${EOL}fileA.txt:2:second line with world${EOL}sub/fileC.txt:1:another world in sub dir${EOL}`,
292 |           exitCode: 0,
293 |         }),
294 |       );
295 | 
296 |       const params: RipGrepToolParams = { pattern: 'world' };
297 |       const invocation = grepTool.build(params);
298 |       const result = await invocation.execute(abortSignal);
299 |       expect(result.llmContent).toContain(
300 |         'Found 3 matches for pattern "world" in the workspace directory',
301 |       );
302 |       expect(result.llmContent).toContain('File: fileA.txt');
303 |       expect(result.llmContent).toContain('L1: hello world');
304 |       expect(result.llmContent).toContain('L2: second line with world');
305 |       expect(result.llmContent).toContain(
306 |         `File: ${path.join('sub', 'fileC.txt')}`,
307 |       );
308 |       expect(result.llmContent).toContain('L1: another world in sub dir');
309 |       expect(result.returnDisplay).toBe('Found 3 matches');
310 |     });
311 | 
312 |     it('should find matches in a specific path', async () => {
313 |       // Setup specific mock for this test - searching in 'sub' should only return matches from that directory
314 |       mockSpawn.mockImplementationOnce(
315 |         createMockSpawn({
316 |           outputData: `fileC.txt:1:another world in sub dir${EOL}`,
317 |           exitCode: 0,
318 |         }),
319 |       );
320 | 
321 |       const params: RipGrepToolParams = { pattern: 'world', path: 'sub' };
322 |       const invocation = grepTool.build(params);
323 |       const result = await invocation.execute(abortSignal);
324 |       expect(result.llmContent).toContain(
325 |         'Found 1 match for pattern "world" in path "sub"',
326 |       );
327 |       expect(result.llmContent).toContain('File: fileC.txt'); // Path relative to 'sub'
328 |       expect(result.llmContent).toContain('L1: another world in sub dir');
329 |       expect(result.returnDisplay).toBe('Found 1 match');
330 |     });
331 | 
332 |     it('should find matches with an include glob', async () => {
333 |       // Setup specific mock for this test
334 |       mockSpawn.mockImplementationOnce(
335 |         createMockSpawn({
336 |           outputData: `fileB.js:2:function baz() { return "hello"; }${EOL}`,
337 |           exitCode: 0,
338 |         }),
339 |       );
340 | 
341 |       const params: RipGrepToolParams = { pattern: 'hello', include: '*.js' };
342 |       const invocation = grepTool.build(params);
343 |       const result = await invocation.execute(abortSignal);
344 |       expect(result.llmContent).toContain(
345 |         'Found 1 match for pattern "hello" in the workspace directory (filter: "*.js"):',
346 |       );
347 |       expect(result.llmContent).toContain('File: fileB.js');
348 |       expect(result.llmContent).toContain(
349 |         'L2: function baz() { return "hello"; }',
350 |       );
351 |       expect(result.returnDisplay).toBe('Found 1 match');
352 |     });
353 | 
354 |     it('should find matches with an include glob and path', async () => {
355 |       await fs.writeFile(
356 |         path.join(tempRootDir, 'sub', 'another.js'),
357 |         'const greeting = "hello";',
358 |       );
359 | 
360 |       // Setup specific mock for this test - searching for 'hello' in 'sub' with '*.js' filter
361 |       mockSpawn.mockImplementationOnce(() => {
362 |         const mockProcess = {
363 |           stdout: {
364 |             on: vi.fn(),
365 |             removeListener: vi.fn(),
366 |           },
367 |           stderr: {
368 |             on: vi.fn(),
369 |             removeListener: vi.fn(),
370 |           },
371 |           on: vi.fn(),
372 |           removeListener: vi.fn(),
373 |           kill: vi.fn(),
374 |         };
375 | 
376 |         setTimeout(() => {
377 |           const onData = mockProcess.stdout.on.mock.calls.find(
378 |             (call) => call[0] === 'data',
379 |           )?.[1];
380 |           const onClose = mockProcess.on.mock.calls.find(
381 |             (call) => call[0] === 'close',
382 |           )?.[1];
383 | 
384 |           if (onData) {
385 |             // Only return match from the .js file in sub directory
386 |             onData(Buffer.from(`another.js:1:const greeting = "hello";${EOL}`));
387 |           }
388 |           if (onClose) {
389 |             onClose(0);
390 |           }
391 |         }, 0);
392 | 
393 |         return mockProcess as unknown as ChildProcess;
394 |       });
395 | 
396 |       const params: RipGrepToolParams = {
397 |         pattern: 'hello',
398 |         path: 'sub',
399 |         include: '*.js',
400 |       };
401 |       const invocation = grepTool.build(params);
402 |       const result = await invocation.execute(abortSignal);
403 |       expect(result.llmContent).toContain(
404 |         'Found 1 match for pattern "hello" in path "sub" (filter: "*.js")',
405 |       );
406 |       expect(result.llmContent).toContain('File: another.js');
407 |       expect(result.llmContent).toContain('L1: const greeting = "hello";');
408 |       expect(result.returnDisplay).toBe('Found 1 match');
409 |     });
410 | 
411 |     it('should return "No matches found" when pattern does not exist', async () => {
412 |       // Setup specific mock for no matches
413 |       mockSpawn.mockImplementationOnce(
414 |         createMockSpawn({
415 |           exitCode: 1, // No matches found
416 |         }),
417 |       );
418 | 
419 |       const params: RipGrepToolParams = { pattern: 'nonexistentpattern' };
420 |       const invocation = grepTool.build(params);
421 |       const result = await invocation.execute(abortSignal);
422 |       expect(result.llmContent).toContain(
423 |         'No matches found for pattern "nonexistentpattern" in the workspace directory.',
424 |       );
425 |       expect(result.returnDisplay).toBe('No matches found');
426 |     });
427 | 
428 |     it('should return an error from ripgrep for invalid regex pattern', async () => {
429 |       mockSpawn.mockImplementationOnce(
430 |         createMockSpawn({
431 |           exitCode: 2,
432 |         }),
433 |       );
434 | 
435 |       const params: RipGrepToolParams = { pattern: '[[' };
436 |       const invocation = grepTool.build(params);
437 |       const result = await invocation.execute(abortSignal);
438 |       expect(result.llmContent).toContain('ripgrep exited with code 2');
439 |       expect(result.returnDisplay).toContain(
440 |         'Error: ripgrep exited with code 2',
441 |       );
442 |     });
443 | 
444 |     it('should handle regex special characters correctly', async () => {
445 |       // Setup specific mock for this test - regex pattern 'foo.*bar' should match 'const foo = "bar";'
446 |       mockSpawn.mockImplementationOnce(() => {
447 |         const mockProcess = {
448 |           stdout: {
449 |             on: vi.fn(),
450 |             removeListener: vi.fn(),
451 |           },
452 |           stderr: {
453 |             on: vi.fn(),
454 |             removeListener: vi.fn(),
455 |           },
456 |           on: vi.fn(),
457 |           removeListener: vi.fn(),
458 |           kill: vi.fn(),
459 |         };
460 | 
461 |         setTimeout(() => {
462 |           const onData = mockProcess.stdout.on.mock.calls.find(
463 |             (call) => call[0] === 'data',
464 |           )?.[1];
465 |           const onClose = mockProcess.on.mock.calls.find(
466 |             (call) => call[0] === 'close',
467 |           )?.[1];
468 | 
469 |           if (onData) {
470 |             // Return match for the regex pattern
471 |             onData(Buffer.from(`fileB.js:1:const foo = "bar";${EOL}`));
472 |           }
473 |           if (onClose) {
474 |             onClose(0);
475 |           }
476 |         }, 0);
477 | 
478 |         return mockProcess as unknown as ChildProcess;
479 |       });
480 | 
481 |       const params: RipGrepToolParams = { pattern: 'foo.*bar' }; // Matches 'const foo = "bar";'
482 |       const invocation = grepTool.build(params);
483 |       const result = await invocation.execute(abortSignal);
484 |       expect(result.llmContent).toContain(
485 |         'Found 1 match for pattern "foo.*bar" in the workspace directory:',
486 |       );
487 |       expect(result.llmContent).toContain('File: fileB.js');
488 |       expect(result.llmContent).toContain('L1: const foo = "bar";');
489 |     });
490 | 
491 |     it('should be case-insensitive by default (JS fallback)', async () => {
492 |       // Setup specific mock for this test - case insensitive search for 'HELLO'
493 |       mockSpawn.mockImplementationOnce(() => {
494 |         const mockProcess = {
495 |           stdout: {
496 |             on: vi.fn(),
497 |             removeListener: vi.fn(),
498 |           },
499 |           stderr: {
500 |             on: vi.fn(),
501 |             removeListener: vi.fn(),
502 |           },
503 |           on: vi.fn(),
504 |           removeListener: vi.fn(),
505 |           kill: vi.fn(),
506 |         };
507 | 
508 |         setTimeout(() => {
509 |           const onData = mockProcess.stdout.on.mock.calls.find(
510 |             (call) => call[0] === 'data',
511 |           )?.[1];
512 |           const onClose = mockProcess.on.mock.calls.find(
513 |             (call) => call[0] === 'close',
514 |           )?.[1];
515 | 
516 |           if (onData) {
517 |             // Return case-insensitive matches for 'HELLO'
518 |             onData(
519 |               Buffer.from(
520 |                 `fileA.txt:1:hello world${EOL}fileB.js:2:function baz() { return "hello"; }${EOL}`,
521 |               ),
522 |             );
523 |           }
524 |           if (onClose) {
525 |             onClose(0);
526 |           }
527 |         }, 0);
528 | 
529 |         return mockProcess as unknown as ChildProcess;
530 |       });
531 | 
532 |       const params: RipGrepToolParams = { pattern: 'HELLO' };
533 |       const invocation = grepTool.build(params);
534 |       const result = await invocation.execute(abortSignal);
535 |       expect(result.llmContent).toContain(
536 |         'Found 2 matches for pattern "HELLO" in the workspace directory:',
537 |       );
538 |       expect(result.llmContent).toContain('File: fileA.txt');
539 |       expect(result.llmContent).toContain('L1: hello world');
540 |       expect(result.llmContent).toContain('File: fileB.js');
541 |       expect(result.llmContent).toContain(
542 |         'L2: function baz() { return "hello"; }',
543 |       );
544 |     });
545 | 
546 |     it('should throw an error if params are invalid', async () => {
547 |       const params = { path: '.' } as unknown as RipGrepToolParams; // Invalid: pattern missing
548 |       expect(() => grepTool.build(params)).toThrow(
549 |         /params must have required property 'pattern'/,
550 |       );
551 |     });
552 | 
553 |     it('should throw an error if ripgrep is not available', async () => {
554 |       // Make ensureRgPath throw
555 |       (fileExists as Mock).mockResolvedValue(false);
556 |       (downloadRipGrep as Mock).mockResolvedValue(undefined);
557 | 
558 |       const params: RipGrepToolParams = { pattern: 'world' };
559 |       const invocation = grepTool.build(params);
560 | 
561 |       expect(await invocation.execute(abortSignal)).toStrictEqual({
562 |         llmContent: 'Error during grep search operation: Cannot use ripgrep.',
563 |         returnDisplay: 'Error: Cannot use ripgrep.',
564 |       });
565 |     });
566 |   });
567 | 
568 |   describe('multi-directory workspace', () => {
[TRUNCATED]
```

src/tools/ripGrep.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import fs from 'node:fs';
8 | import path from 'node:path';
9 | import { EOL } from 'node:os';
10 | import { spawn } from 'node:child_process';
11 | import { downloadRipGrep } from '@joshua.litt/get-ripgrep';
12 | import type { ToolInvocation, ToolResult } from './tools.js';
13 | import { BaseDeclarativeTool, BaseToolInvocation, Kind } from './tools.js';
14 | import { SchemaValidator } from '../utils/schemaValidator.js';
15 | import { makeRelative, shortenPath } from '../utils/paths.js';
16 | import { getErrorMessage, isNodeError } from '../utils/errors.js';
17 | import type { Config } from '../config/config.js';
18 | import { fileExists } from '../utils/fileUtils.js';
19 | import { Storage } from '../config/storage.js';
20 | 
21 | const DEFAULT_TOTAL_MAX_MATCHES = 20000;
22 | 
23 | function getRgPath(): string {
24 |   return path.join(Storage.getGlobalBinDir(), 'rg');
25 | }
26 | 
27 | /**
28 |  * Checks if `rg` exists, if not then attempt to download it.
29 |  */
30 | export async function canUseRipgrep(): Promise<boolean> {
31 |   if (await fileExists(getRgPath())) {
32 |     return true;
33 |   }
34 | 
35 |   await downloadRipGrep(Storage.getGlobalBinDir());
36 |   return await fileExists(getRgPath());
37 | }
38 | 
39 | /**
40 |  * Ensures `rg` is downloaded, or throws.
41 |  */
42 | export async function ensureRgPath(): Promise<string> {
43 |   if (await canUseRipgrep()) {
44 |     return getRgPath();
45 |   }
46 |   throw new Error('Cannot use ripgrep.');
47 | }
48 | 
49 | /**
50 |  * Parameters for the GrepTool
51 |  */
52 | export interface RipGrepToolParams {
53 |   /**
54 |    * The regular expression pattern to search for in file contents
55 |    */
56 |   pattern: string;
57 | 
58 |   /**
59 |    * The directory to search in (optional, defaults to current directory relative to root)
60 |    */
61 |   path?: string;
62 | 
63 |   /**
64 |    * File pattern to include in the search (e.g. "*.js", "*.{ts,tsx}")
65 |    */
66 |   include?: string;
67 | }
68 | 
69 | /**
70 |  * Result object for a single grep match
71 |  */
72 | interface GrepMatch {
73 |   filePath: string;
74 |   lineNumber: number;
75 |   line: string;
76 | }
77 | 
78 | class GrepToolInvocation extends BaseToolInvocation<
79 |   RipGrepToolParams,
80 |   ToolResult
81 | > {
82 |   constructor(
83 |     private readonly config: Config,
84 |     params: RipGrepToolParams,
85 |   ) {
86 |     super(params);
87 |   }
88 | 
89 |   /**
90 |    * Checks if a path is within the root directory and resolves it.
91 |    * @param relativePath Path relative to the root directory (or undefined for root).
92 |    * @returns The absolute path if valid and exists, or null if no path specified (to search all directories).
93 |    * @throws {Error} If path is outside root, doesn't exist, or isn't a directory.
94 |    */
95 |   private resolveAndValidatePath(relativePath?: string): string | null {
96 |     // If no path specified, return null to indicate searching all workspace directories
97 |     if (!relativePath) {
98 |       return null;
99 |     }
100 | 
101 |     const targetPath = path.resolve(this.config.getTargetDir(), relativePath);
102 | 
103 |     // Security Check: Ensure the resolved path is within workspace boundaries
104 |     const workspaceContext = this.config.getWorkspaceContext();
105 |     if (!workspaceContext.isPathWithinWorkspace(targetPath)) {
106 |       const directories = workspaceContext.getDirectories();
107 |       throw new Error(
108 |         `Path validation failed: Attempted path "${relativePath}" resolves outside the allowed workspace directories: ${directories.join(', ')}`,
109 |       );
110 |     }
111 | 
112 |     // Check existence and type after resolving
113 |     try {
114 |       const stats = fs.statSync(targetPath);
115 |       if (!stats.isDirectory()) {
116 |         throw new Error(`Path is not a directory: ${targetPath}`);
117 |       }
118 |     } catch (error: unknown) {
119 |       if (isNodeError(error) && error.code !== 'ENOENT') {
120 |         throw new Error(`Path does not exist: ${targetPath}`);
121 |       }
122 |       throw new Error(
123 |         `Failed to access path stats for ${targetPath}: ${error}`,
124 |       );
125 |     }
126 | 
127 |     return targetPath;
128 |   }
129 | 
130 |   async execute(signal: AbortSignal): Promise<ToolResult> {
131 |     try {
132 |       const workspaceContext = this.config.getWorkspaceContext();
133 |       const searchDirAbs = this.resolveAndValidatePath(this.params.path);
134 |       const searchDirDisplay = this.params.path || '.';
135 | 
136 |       // Determine which directories to search
137 |       let searchDirectories: readonly string[];
138 |       if (searchDirAbs === null) {
139 |         // No path specified - search all workspace directories
140 |         searchDirectories = workspaceContext.getDirectories();
141 |       } else {
142 |         // Specific path provided - search only that directory
143 |         searchDirectories = [searchDirAbs];
144 |       }
145 | 
146 |       let allMatches: GrepMatch[] = [];
147 |       const totalMaxMatches = DEFAULT_TOTAL_MAX_MATCHES;
148 | 
149 |       if (this.config.getDebugMode()) {
150 |         console.log(`[GrepTool] Total result limit: ${totalMaxMatches}`);
151 |       }
152 | 
153 |       for (const searchDir of searchDirectories) {
154 |         const searchResult = await this.performRipgrepSearch({
155 |           pattern: this.params.pattern,
156 |           path: searchDir,
157 |           include: this.params.include,
158 |           signal,
159 |         });
160 | 
161 |         if (searchDirectories.length > 1) {
162 |           const dirName = path.basename(searchDir);
163 |           searchResult.forEach((match) => {
164 |             match.filePath = path.join(dirName, match.filePath);
165 |           });
166 |         }
167 | 
168 |         allMatches = allMatches.concat(searchResult);
169 | 
170 |         if (allMatches.length >= totalMaxMatches) {
171 |           allMatches = allMatches.slice(0, totalMaxMatches);
172 |           break;
173 |         }
174 |       }
175 | 
176 |       let searchLocationDescription: string;
177 |       if (searchDirAbs === null) {
178 |         const numDirs = workspaceContext.getDirectories().length;
179 |         searchLocationDescription =
180 |           numDirs > 1
181 |             ? `across ${numDirs} workspace directories`
182 |             : `in the workspace directory`;
183 |       } else {
184 |         searchLocationDescription = `in path "${searchDirDisplay}"`;
185 |       }
186 | 
187 |       if (allMatches.length === 0) {
188 |         const noMatchMsg = `No matches found for pattern "${this.params.pattern}" ${searchLocationDescription}${this.params.include ? ` (filter: "${this.params.include}")` : ''}.`;
189 |         return { llmContent: noMatchMsg, returnDisplay: `No matches found` };
190 |       }
191 | 
192 |       const wasTruncated = allMatches.length >= totalMaxMatches;
193 | 
194 |       const matchesByFile = allMatches.reduce(
195 |         (acc, match) => {
196 |           const fileKey = match.filePath;
197 |           if (!acc[fileKey]) {
198 |             acc[fileKey] = [];
199 |           }
200 |           acc[fileKey].push(match);
201 |           acc[fileKey].sort((a, b) => a.lineNumber - b.lineNumber);
202 |           return acc;
203 |         },
204 |         {} as Record<string, GrepMatch[]>,
205 |       );
206 | 
207 |       const matchCount = allMatches.length;
208 |       const matchTerm = matchCount === 1 ? 'match' : 'matches';
209 | 
210 |       let llmContent = `Found ${matchCount} ${matchTerm} for pattern "${this.params.pattern}" ${searchLocationDescription}${this.params.include ? ` (filter: "${this.params.include}")` : ''}`;
211 | 
212 |       if (wasTruncated) {
213 |         llmContent += ` (results limited to ${totalMaxMatches} matches for performance)`;
214 |       }
215 | 
216 |       llmContent += `:\n---\n`;
217 | 
218 |       for (const filePath in matchesByFile) {
219 |         llmContent += `File: ${filePath}\n`;
220 |         matchesByFile[filePath].forEach((match) => {
221 |           const trimmedLine = match.line.trim();
222 |           llmContent += `L${match.lineNumber}: ${trimmedLine}\n`;
223 |         });
224 |         llmContent += '---\n';
225 |       }
226 | 
227 |       let displayMessage = `Found ${matchCount} ${matchTerm}`;
228 |       if (wasTruncated) {
229 |         displayMessage += ` (limited)`;
230 |       }
231 | 
232 |       return {
233 |         llmContent: llmContent.trim(),
234 |         returnDisplay: displayMessage,
235 |       };
236 |     } catch (error) {
237 |       console.error(`Error during GrepLogic execution: ${error}`);
238 |       const errorMessage = getErrorMessage(error);
239 |       return {
240 |         llmContent: `Error during grep search operation: ${errorMessage}`,
241 |         returnDisplay: `Error: ${errorMessage}`,
242 |       };
243 |     }
244 |   }
245 | 
246 |   private parseRipgrepOutput(output: string, basePath: string): GrepMatch[] {
247 |     const results: GrepMatch[] = [];
248 |     if (!output) return results;
249 | 
250 |     const lines = output.split(EOL);
251 | 
252 |     for (const line of lines) {
253 |       if (!line.trim()) continue;
254 | 
255 |       const firstColonIndex = line.indexOf(':');
256 |       if (firstColonIndex === -1) continue;
257 | 
258 |       const secondColonIndex = line.indexOf(':', firstColonIndex + 1);
259 |       if (secondColonIndex === -1) continue;
260 | 
261 |       const filePathRaw = line.substring(0, firstColonIndex);
262 |       const lineNumberStr = line.substring(
263 |         firstColonIndex + 1,
264 |         secondColonIndex,
265 |       );
266 |       const lineContent = line.substring(secondColonIndex + 1);
267 | 
268 |       const lineNumber = parseInt(lineNumberStr, 10);
269 | 
270 |       if (!isNaN(lineNumber)) {
271 |         const absoluteFilePath = path.resolve(basePath, filePathRaw);
272 |         const relativeFilePath = path.relative(basePath, absoluteFilePath);
273 | 
274 |         results.push({
275 |           filePath: relativeFilePath || path.basename(absoluteFilePath),
276 |           lineNumber,
277 |           line: lineContent,
278 |         });
279 |       }
280 |     }
281 |     return results;
282 |   }
283 | 
284 |   private async performRipgrepSearch(options: {
285 |     pattern: string;
286 |     path: string;
287 |     include?: string;
288 |     signal: AbortSignal;
289 |   }): Promise<GrepMatch[]> {
290 |     const { pattern, path: absolutePath, include } = options;
291 | 
292 |     const rgArgs = [
293 |       '--line-number',
294 |       '--no-heading',
295 |       '--with-filename',
296 |       '--ignore-case',
297 |       '--regexp',
298 |       pattern,
299 |     ];
300 | 
301 |     if (include) {
302 |       rgArgs.push('--glob', include);
303 |     }
304 | 
305 |     const excludes = [
306 |       '.git',
307 |       'node_modules',
308 |       'bower_components',
309 |       '*.log',
310 |       '*.tmp',
311 |       'build',
312 |       'dist',
313 |       'coverage',
314 |     ];
315 |     excludes.forEach((exclude) => {
316 |       rgArgs.push('--glob', `!${exclude}`);
317 |     });
318 | 
319 |     rgArgs.push('--threads', '4');
320 |     rgArgs.push(absolutePath);
321 | 
322 |     try {
323 |       const rgPath = await ensureRgPath();
324 |       const output = await new Promise<string>((resolve, reject) => {
325 |         const child = spawn(rgPath, rgArgs, {
326 |           windowsHide: true,
327 |         });
328 | 
329 |         const stdoutChunks: Buffer[] = [];
330 |         const stderrChunks: Buffer[] = [];
331 | 
332 |         const cleanup = () => {
333 |           if (options.signal.aborted) {
334 |             child.kill();
335 |           }
336 |         };
337 | 
338 |         options.signal.addEventListener('abort', cleanup, { once: true });
339 | 
340 |         child.stdout.on('data', (chunk) => stdoutChunks.push(chunk));
341 |         child.stderr.on('data', (chunk) => stderrChunks.push(chunk));
342 | 
343 |         child.on('error', (err) => {
344 |           options.signal.removeEventListener('abort', cleanup);
345 |           reject(
346 |             new Error(
347 |               `Failed to start ripgrep: ${err.message}. Please ensure @lvce-editor/ripgrep is properly installed.`,
348 |             ),
349 |           );
350 |         });
351 | 
352 |         child.on('close', (code) => {
353 |           options.signal.removeEventListener('abort', cleanup);
354 |           const stdoutData = Buffer.concat(stdoutChunks).toString('utf8');
355 |           const stderrData = Buffer.concat(stderrChunks).toString('utf8');
356 | 
357 |           if (code === 0) {
358 |             resolve(stdoutData);
359 |           } else if (code === 1) {
360 |             resolve(''); // No matches found
361 |           } else {
362 |             reject(
363 |               new Error(`ripgrep exited with code ${code}: ${stderrData}`),
364 |             );
365 |           }
366 |         });
367 |       });
368 | 
369 |       return this.parseRipgrepOutput(output, absolutePath);
370 |     } catch (error: unknown) {
371 |       console.error(`GrepLogic: ripgrep failed: ${getErrorMessage(error)}`);
372 |       throw error;
373 |     }
374 |   }
375 | 
376 |   /**
377 |    * Gets a description of the grep operation
378 |    * @param params Parameters for the grep operation
379 |    * @returns A string describing the grep
380 |    */
381 |   getDescription(): string {
382 |     let description = `'${this.params.pattern}'`;
383 |     if (this.params.include) {
384 |       description += ` in ${this.params.include}`;
385 |     }
386 |     if (this.params.path) {
387 |       const resolvedPath = path.resolve(
388 |         this.config.getTargetDir(),
389 |         this.params.path,
390 |       );
391 |       if (
392 |         resolvedPath === this.config.getTargetDir() ||
393 |         this.params.path === '.'
394 |       ) {
395 |         description += ` within ./`;
396 |       } else {
397 |         const relativePath = makeRelative(
398 |           resolvedPath,
399 |           this.config.getTargetDir(),
400 |         );
401 |         description += ` within ${shortenPath(relativePath)}`;
402 |       }
403 |     } else {
404 |       // When no path is specified, indicate searching all workspace directories
405 |       const workspaceContext = this.config.getWorkspaceContext();
406 |       const directories = workspaceContext.getDirectories();
407 |       if (directories.length > 1) {
408 |         description += ` across all workspace directories`;
409 |       }
410 |     }
411 |     return description;
412 |   }
413 | }
414 | 
415 | /**
416 |  * Implementation of the Grep tool logic (moved from CLI)
417 |  */
418 | export class RipGrepTool extends BaseDeclarativeTool<
419 |   RipGrepToolParams,
420 |   ToolResult
421 | > {
422 |   static readonly Name = 'search_file_content';
423 | 
424 |   constructor(private readonly config: Config) {
425 |     super(
426 |       RipGrepTool.Name,
427 |       'SearchText',
428 |       'Searches for a regular expression pattern within the content of files in a specified directory (or current working directory). Can filter files by a glob pattern. Returns the lines containing matches, along with their file paths and line numbers. Total results limited to 20,000 matches like VSCode.',
429 |       Kind.Search,
430 |       {
431 |         properties: {
432 |           pattern: {
433 |             description:
434 |               "The regular expression (regex) pattern to search for within file contents (e.g., 'function\\s+myFunction', 'import\\s+\\{.*\\}\\s+from\\s+.*').",
435 |             type: 'string',
436 |           },
437 |           path: {
438 |             description:
439 |               'Optional: The absolute path to the directory to search within. If omitted, searches the current working directory.',
440 |             type: 'string',
441 |           },
442 |           include: {
443 |             description:
444 |               "Optional: A glob pattern to filter which files are searched (e.g., '*.js', '*.{ts,tsx}', 'src/**'). If omitted, searches all files (respecting potential global ignores).",
445 |             type: 'string',
446 |           },
447 |         },
448 |         required: ['pattern'],
449 |         type: 'object',
450 |       },
451 |     );
452 |   }
453 | 
454 |   /**
455 |    * Checks if a path is within the root directory and resolves it.
456 |    * @param relativePath Path relative to the root directory (or undefined for root).
457 |    * @returns The absolute path if valid and exists, or null if no path specified (to search all directories).
458 |    * @throws {Error} If path is outside root, doesn't exist, or isn't a directory.
459 |    */
460 |   private resolveAndValidatePath(relativePath?: string): string | null {
461 |     // If no path specified, return null to indicate searching all workspace directories
462 |     if (!relativePath) {
463 |       return null;
464 |     }
465 | 
466 |     const targetPath = path.resolve(this.config.getTargetDir(), relativePath);
467 | 
468 |     // Security Check: Ensure the resolved path is within workspace boundaries
469 |     const workspaceContext = this.config.getWorkspaceContext();
470 |     if (!workspaceContext.isPathWithinWorkspace(targetPath)) {
471 |       const directories = workspaceContext.getDirectories();
472 |       throw new Error(
473 |         `Path validation failed: Attempted path "${relativePath}" resolves outside the allowed workspace directories: ${directories.join(', ')}`,
474 |       );
475 |     }
476 | 
477 |     // Check existence and type after resolving
478 |     try {
479 |       const stats = fs.statSync(targetPath);
480 |       if (!stats.isDirectory()) {
481 |         throw new Error(`Path is not a directory: ${targetPath}`);
482 |       }
483 |     } catch (error: unknown) {
484 |       if (isNodeError(error) && error.code !== 'ENOENT') {
485 |         throw new Error(`Path does not exist: ${targetPath}`);
486 |       }
487 |       throw new Error(
488 |         `Failed to access path stats for ${targetPath}: ${error}`,
489 |       );
490 |     }
491 | 
492 |     return targetPath;
493 |   }
494 | 
495 |   /**
496 |    * Validates the parameters for the tool
497 |    * @param params Parameters to validate
498 |    * @returns An error message string if invalid, null otherwise
499 |    */
500 |   override validateToolParams(params: RipGrepToolParams): string | null {
501 |     const errors = SchemaValidator.validate(
502 |       this.schema.parametersJsonSchema,
503 |       params,
504 |     );
505 |     if (errors) {
506 |       return errors;
507 |     }
508 | 
509 |     // Only validate path if one is provided
510 |     if (params.path) {
511 |       try {
512 |         this.resolveAndValidatePath(params.path);
513 |       } catch (error) {
514 |         return getErrorMessage(error);
515 |       }
516 |     }
517 | 
518 |     return null; // Parameters are valid
519 |   }
520 | 
521 |   protected createInvocation(
522 |     params: RipGrepToolParams,
523 |   ): ToolInvocation<RipGrepToolParams, ToolResult> {
524 |     return new GrepToolInvocation(this.config, params);
525 |   }
526 | }
```

src/tools/shell.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   vi,
9 |   describe,
10 |   it,
11 |   expect,
12 |   beforeEach,
13 |   afterEach,
14 |   type Mock,
15 | } from 'vitest';
16 | 
17 | const mockShellExecutionService = vi.hoisted(() => vi.fn());
18 | vi.mock('../services/shellExecutionService.js', () => ({
19 |   ShellExecutionService: { execute: mockShellExecutionService },
20 | }));
21 | vi.mock('fs');
22 | vi.mock('os');
23 | vi.mock('crypto');
24 | vi.mock('../utils/summarizer.js');
25 | 
26 | import { isCommandAllowed } from '../utils/shell-utils.js';
27 | import { ShellTool } from './shell.js';
28 | import { type Config } from '../config/config.js';
29 | import {
30 |   type ShellExecutionResult,
31 |   type ShellOutputEvent,
32 | } from '../services/shellExecutionService.js';
33 | import * as fs from 'node:fs';
34 | import * as os from 'node:os';
35 | import { EOL } from 'node:os';
36 | import * as path from 'node:path';
37 | import * as crypto from 'node:crypto';
38 | import * as summarizer from '../utils/summarizer.js';
39 | import { ToolErrorType } from './tool-error.js';
40 | import { ToolConfirmationOutcome } from './tools.js';
41 | import { OUTPUT_UPDATE_INTERVAL_MS } from './shell.js';
42 | import { createMockWorkspaceContext } from '../test-utils/mockWorkspaceContext.js';
43 | 
44 | describe('ShellTool', () => {
45 |   let shellTool: ShellTool;
46 |   let mockConfig: Config;
47 |   let mockShellOutputCallback: (event: ShellOutputEvent) => void;
48 |   let resolveExecutionPromise: (result: ShellExecutionResult) => void;
49 | 
50 |   beforeEach(() => {
51 |     vi.clearAllMocks();
52 | 
53 |     mockConfig = {
54 |       getCoreTools: vi.fn().mockReturnValue([]),
55 |       getExcludeTools: vi.fn().mockReturnValue([]),
56 |       getDebugMode: vi.fn().mockReturnValue(false),
57 |       getTargetDir: vi.fn().mockReturnValue('/test/dir'),
58 |       getSummarizeToolOutputConfig: vi.fn().mockReturnValue(undefined),
59 |       getWorkspaceContext: vi
60 |         .fn()
61 |         .mockReturnValue(createMockWorkspaceContext('/test/dir')),
62 |       getGeminiClient: vi.fn(),
63 |       getEnableInteractiveShell: vi.fn().mockReturnValue(false),
64 |       isInteractive: vi.fn().mockReturnValue(true),
65 |     } as unknown as Config;
66 | 
67 |     shellTool = new ShellTool(mockConfig);
68 | 
69 |     vi.mocked(os.platform).mockReturnValue('linux');
70 |     vi.mocked(os.tmpdir).mockReturnValue('/tmp');
71 |     (vi.mocked(crypto.randomBytes) as Mock).mockReturnValue(
72 |       Buffer.from('abcdef', 'hex'),
73 |     );
74 | 
75 |     // Capture the output callback to simulate streaming events from the service
76 |     mockShellExecutionService.mockImplementation((_cmd, _cwd, callback) => {
77 |       mockShellOutputCallback = callback;
78 |       return {
79 |         pid: 12345,
80 |         result: new Promise((resolve) => {
81 |           resolveExecutionPromise = resolve;
82 |         }),
83 |       };
84 |     });
85 |   });
86 | 
87 |   describe('isCommandAllowed', () => {
88 |     it('should allow a command if no restrictions are provided', () => {
89 |       (mockConfig.getCoreTools as Mock).mockReturnValue(undefined);
90 |       (mockConfig.getExcludeTools as Mock).mockReturnValue(undefined);
91 |       expect(isCommandAllowed('ls -l', mockConfig).allowed).toBe(true);
92 |     });
93 | 
94 |     it('should block a command with command substitution using $()', () => {
95 |       expect(isCommandAllowed('echo $(rm -rf /)', mockConfig).allowed).toBe(
96 |         false,
97 |       );
98 |     });
99 |   });
100 | 
101 |   describe('build', () => {
102 |     it('should return an invocation for a valid command', () => {
103 |       const invocation = shellTool.build({ command: 'ls -l' });
104 |       expect(invocation).toBeDefined();
105 |     });
106 | 
107 |     it('should throw an error for an empty command', () => {
108 |       expect(() => shellTool.build({ command: ' ' })).toThrow(
109 |         'Command cannot be empty.',
110 |       );
111 |     });
112 | 
113 |     it('should throw an error for a relative directory path', () => {
114 |       expect(() =>
115 |         shellTool.build({ command: 'ls', directory: 'rel/path' }),
116 |       ).toThrow('Directory must be an absolute path.');
117 |     });
118 | 
119 |     it('should throw an error for a directory outside the workspace', () => {
120 |       (mockConfig.getWorkspaceContext as Mock).mockReturnValue(
121 |         createMockWorkspaceContext('/test/dir', ['/another/workspace']),
122 |       );
123 |       expect(() =>
124 |         shellTool.build({ command: 'ls', directory: '/not/in/workspace' }),
125 |       ).toThrow(
126 |         "Directory '/not/in/workspace' is not within any of the registered workspace directories.",
127 |       );
128 |     });
129 | 
130 |     it('should return an invocation for a valid absolute directory path', () => {
131 |       (mockConfig.getWorkspaceContext as Mock).mockReturnValue(
132 |         createMockWorkspaceContext('/test/dir', ['/another/workspace']),
133 |       );
134 |       const invocation = shellTool.build({
135 |         command: 'ls',
136 |         directory: '/test/dir/subdir',
137 |       });
138 |       expect(invocation).toBeDefined();
139 |     });
140 |   });
141 | 
142 |   describe('execute', () => {
143 |     const mockAbortSignal = new AbortController().signal;
144 | 
145 |     const resolveShellExecution = (
146 |       result: Partial<ShellExecutionResult> = {},
147 |     ) => {
148 |       const fullResult: ShellExecutionResult = {
149 |         rawOutput: Buffer.from(result.output || ''),
150 |         output: 'Success',
151 |         exitCode: 0,
152 |         signal: null,
153 |         error: null,
154 |         aborted: false,
155 |         pid: 12345,
156 |         executionMethod: 'child_process',
157 |         ...result,
158 |       };
159 |       resolveExecutionPromise(fullResult);
160 |     };
161 | 
162 |     it('should wrap command on linux and parse pgrep output', async () => {
163 |       const invocation = shellTool.build({ command: 'my-command &' });
164 |       const promise = invocation.execute(mockAbortSignal);
165 |       resolveShellExecution({ pid: 54321 });
166 | 
167 |       vi.mocked(fs.existsSync).mockReturnValue(true);
168 |       vi.mocked(fs.readFileSync).mockReturnValue(`54321${EOL}54322${EOL}`); // Service PID and background PID
169 | 
170 |       const result = await promise;
171 | 
172 |       const tmpFile = path.join(os.tmpdir(), 'shell_pgrep_abcdef.tmp');
173 |       const wrappedCommand = `{ my-command & }; __code=$?; pgrep -g 0 >${tmpFile} 2>&1; exit $__code;`;
174 |       expect(mockShellExecutionService).toHaveBeenCalledWith(
175 |         wrappedCommand,
176 |         '/test/dir',
177 |         expect.any(Function),
178 |         mockAbortSignal,
179 |         false,
180 |         {},
181 |       );
182 |       expect(result.llmContent).toContain('Background PIDs: 54322');
183 |       expect(vi.mocked(fs.unlinkSync)).toHaveBeenCalledWith(tmpFile);
184 |     });
185 | 
186 |     it('should use the provided directory as cwd', async () => {
187 |       (mockConfig.getWorkspaceContext as Mock).mockReturnValue(
188 |         createMockWorkspaceContext('/test/dir'),
189 |       );
190 |       const invocation = shellTool.build({
191 |         command: 'ls',
192 |         directory: '/test/dir/subdir',
193 |       });
194 |       const promise = invocation.execute(mockAbortSignal);
195 |       resolveShellExecution();
196 |       await promise;
197 | 
198 |       const tmpFile = path.join(os.tmpdir(), 'shell_pgrep_abcdef.tmp');
199 |       const wrappedCommand = `{ ls; }; __code=$?; pgrep -g 0 >${tmpFile} 2>&1; exit $__code;`;
200 |       expect(mockShellExecutionService).toHaveBeenCalledWith(
201 |         wrappedCommand,
202 |         '/test/dir/subdir',
203 |         expect.any(Function),
204 |         mockAbortSignal,
205 |         false,
206 |         {},
207 |       );
208 |     });
209 | 
210 |     it('should not wrap command on windows', async () => {
211 |       vi.mocked(os.platform).mockReturnValue('win32');
212 |       const invocation = shellTool.build({ command: 'dir' });
213 |       const promise = invocation.execute(mockAbortSignal);
214 |       resolveShellExecution({
215 |         rawOutput: Buffer.from(''),
216 |         output: '',
217 |         exitCode: 0,
218 |         signal: null,
219 |         error: null,
220 |         aborted: false,
221 |         pid: 12345,
222 |         executionMethod: 'child_process',
223 |       });
224 |       await promise;
225 |       expect(mockShellExecutionService).toHaveBeenCalledWith(
226 |         'dir',
227 |         '/test/dir',
228 |         expect.any(Function),
229 |         mockAbortSignal,
230 |         false,
231 |         {},
232 |       );
233 |     });
234 | 
235 |     it('should format error messages correctly', async () => {
236 |       const error = new Error('wrapped command failed');
237 |       const invocation = shellTool.build({ command: 'user-command' });
238 |       const promise = invocation.execute(mockAbortSignal);
239 |       resolveShellExecution({
240 |         error,
241 |         exitCode: 1,
242 |         output: 'err',
243 |         rawOutput: Buffer.from('err'),
244 |         signal: null,
245 |         aborted: false,
246 |         pid: 12345,
247 |         executionMethod: 'child_process',
248 |       });
249 | 
250 |       const result = await promise;
251 |       expect(result.llmContent).toContain('Error: wrapped command failed');
252 |       expect(result.llmContent).not.toContain('pgrep');
253 |     });
254 | 
255 |     it('should return a SHELL_EXECUTE_ERROR for a command failure', async () => {
256 |       const error = new Error('command failed');
257 |       const invocation = shellTool.build({ command: 'user-command' });
258 |       const promise = invocation.execute(mockAbortSignal);
259 |       resolveShellExecution({
260 |         error,
261 |         exitCode: 1,
262 |       });
263 | 
264 |       const result = await promise;
265 | 
266 |       expect(result.error).toBeDefined();
267 |       expect(result.error?.type).toBe(ToolErrorType.SHELL_EXECUTE_ERROR);
268 |       expect(result.error?.message).toBe('command failed');
269 |     });
270 | 
271 |     it('should throw an error for invalid parameters', () => {
272 |       expect(() => shellTool.build({ command: '' })).toThrow(
273 |         'Command cannot be empty.',
274 |       );
275 |     });
276 | 
277 |     it('should throw an error for invalid directory', () => {
278 |       expect(() =>
279 |         shellTool.build({ command: 'ls', directory: 'nonexistent' }),
280 |       ).toThrow('Directory must be an absolute path.');
281 |     });
282 | 
283 |     it('should summarize output when configured', async () => {
284 |       (mockConfig.getSummarizeToolOutputConfig as Mock).mockReturnValue({
285 |         [shellTool.name]: { tokenBudget: 1000 },
286 |       });
287 |       vi.mocked(summarizer.summarizeToolOutput).mockResolvedValue(
288 |         'summarized output',
289 |       );
290 | 
291 |       const invocation = shellTool.build({ command: 'ls' });
292 |       const promise = invocation.execute(mockAbortSignal);
293 |       resolveExecutionPromise({
294 |         output: 'long output',
295 |         rawOutput: Buffer.from('long output'),
296 |         exitCode: 0,
297 |         signal: null,
298 |         error: null,
299 |         aborted: false,
300 |         pid: 12345,
301 |         executionMethod: 'child_process',
302 |       });
303 | 
304 |       const result = await promise;
305 | 
306 |       expect(summarizer.summarizeToolOutput).toHaveBeenCalledWith(
307 |         expect.any(String),
308 |         mockConfig.getGeminiClient(),
309 |         mockAbortSignal,
310 |         1000,
311 |       );
312 |       expect(result.llmContent).toBe('summarized output');
313 |       expect(result.returnDisplay).toBe('long output');
314 |     });
315 | 
316 |     it('should clean up the temp file on synchronous execution error', async () => {
317 |       const error = new Error('sync spawn error');
318 |       mockShellExecutionService.mockImplementation(() => {
319 |         throw error;
320 |       });
321 |       vi.mocked(fs.existsSync).mockReturnValue(true); // Pretend the file exists
322 | 
323 |       const invocation = shellTool.build({ command: 'a-command' });
324 |       await expect(invocation.execute(mockAbortSignal)).rejects.toThrow(error);
325 | 
326 |       const tmpFile = path.join(os.tmpdir(), 'shell_pgrep_abcdef.tmp');
327 |       expect(vi.mocked(fs.unlinkSync)).toHaveBeenCalledWith(tmpFile);
328 |     });
329 | 
330 |     describe('Streaming to `updateOutput`', () => {
331 |       let updateOutputMock: Mock;
332 |       beforeEach(() => {
333 |         vi.useFakeTimers({ toFake: ['Date'] });
334 |         updateOutputMock = vi.fn();
335 |       });
336 |       afterEach(() => {
337 |         vi.useRealTimers();
338 |       });
339 | 
340 |       it('should immediately show binary detection message and throttle progress', async () => {
341 |         const invocation = shellTool.build({ command: 'cat img' });
342 |         const promise = invocation.execute(mockAbortSignal, updateOutputMock);
343 | 
344 |         mockShellOutputCallback({ type: 'binary_detected' });
345 |         expect(updateOutputMock).toHaveBeenCalledOnce();
346 |         expect(updateOutputMock).toHaveBeenCalledWith(
347 |           '[Binary output detected. Halting stream...]',
348 |         );
349 | 
350 |         mockShellOutputCallback({
351 |           type: 'binary_progress',
352 |           bytesReceived: 1024,
353 |         });
354 |         expect(updateOutputMock).toHaveBeenCalledOnce();
355 | 
356 |         // Advance time past the throttle interval.
357 |         await vi.advanceTimersByTimeAsync(OUTPUT_UPDATE_INTERVAL_MS + 1);
358 | 
359 |         // Send a SECOND progress event. This one will trigger the flush.
360 |         mockShellOutputCallback({
361 |           type: 'binary_progress',
362 |           bytesReceived: 2048,
363 |         });
364 | 
365 |         // Now it should be called a second time with the latest progress.
366 |         expect(updateOutputMock).toHaveBeenCalledTimes(2);
367 |         expect(updateOutputMock).toHaveBeenLastCalledWith(
368 |           '[Receiving binary output... 2.0 KB received]',
369 |         );
370 | 
371 |         resolveExecutionPromise({
372 |           rawOutput: Buffer.from(''),
373 |           output: '',
374 |           exitCode: 0,
375 |           signal: null,
376 |           error: null,
377 |           aborted: false,
378 |           pid: 12345,
379 |           executionMethod: 'child_process',
380 |         });
381 |         await promise;
382 |       });
383 |     });
384 |   });
385 | 
386 |   describe('shouldConfirmExecute', () => {
387 |     it('should request confirmation for a new command and allowlist it on "Always"', async () => {
388 |       const params = { command: 'npm install' };
389 |       const invocation = shellTool.build(params);
390 |       const confirmation = await invocation.shouldConfirmExecute(
391 |         new AbortController().signal,
392 |       );
393 | 
394 |       expect(confirmation).not.toBe(false);
395 |       expect(confirmation && confirmation.type).toBe('exec');
396 | 
397 |       // eslint-disable-next-line @typescript-eslint/no-explicit-any
398 |       await (confirmation as any).onConfirm(
399 |         ToolConfirmationOutcome.ProceedAlways,
400 |       );
401 | 
402 |       // Should now be allowlisted
403 |       const secondInvocation = shellTool.build({ command: 'npm test' });
404 |       const secondConfirmation = await secondInvocation.shouldConfirmExecute(
405 |         new AbortController().signal,
406 |       );
407 |       expect(secondConfirmation).toBe(false);
408 |     });
409 | 
410 |     it('should throw an error if validation fails', () => {
411 |       expect(() => shellTool.build({ command: '' })).toThrow();
412 |     });
413 |   });
414 | 
415 |   describe('getDescription', () => {
416 |     it('should return the windows description when on windows', () => {
417 |       vi.mocked(os.platform).mockReturnValue('win32');
418 |       const shellTool = new ShellTool(mockConfig);
419 |       expect(shellTool.description).toMatchSnapshot();
420 |     });
421 | 
422 |     it('should return the non-windows description when not on windows', () => {
423 |       vi.mocked(os.platform).mockReturnValue('linux');
424 |       const shellTool = new ShellTool(mockConfig);
425 |       expect(shellTool.description).toMatchSnapshot();
426 |     });
427 |   });
428 | });
```

src/tools/shell.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import fs from 'node:fs';
8 | import path from 'node:path';
9 | import os, { EOL } from 'node:os';
10 | import crypto from 'node:crypto';
11 | import type { Config } from '../config/config.js';
12 | import { ToolErrorType } from './tool-error.js';
13 | import type {
14 |   ToolInvocation,
15 |   ToolResult,
16 |   ToolCallConfirmationDetails,
17 |   ToolExecuteConfirmationDetails,
18 | } from './tools.js';
19 | import {
20 |   BaseDeclarativeTool,
21 |   BaseToolInvocation,
22 |   ToolConfirmationOutcome,
23 |   Kind,
24 | } from './tools.js';
25 | import { ApprovalMode } from '../config/config.js';
26 | import { getErrorMessage } from '../utils/errors.js';
27 | import { summarizeToolOutput } from '../utils/summarizer.js';
28 | import type {
29 |   ShellExecutionConfig,
30 |   ShellOutputEvent,
31 | } from '../services/shellExecutionService.js';
32 | import { ShellExecutionService } from '../services/shellExecutionService.js';
33 | import { formatMemoryUsage } from '../utils/formatters.js';
34 | import type { AnsiOutput } from '../utils/terminalSerializer.js';
35 | import {
36 |   getCommandRoots,
37 |   isCommandAllowed,
38 |   SHELL_TOOL_NAMES,
39 |   stripShellWrapper,
40 | } from '../utils/shell-utils.js';
41 | 
42 | export const OUTPUT_UPDATE_INTERVAL_MS = 1000;
43 | 
44 | /**
45 |  * Parses the `--allowed-tools` flag to determine which sub-commands of the
46 |  * ShellTool are allowed. The flag can be provided multiple times.
47 |  *
48 |  * @param allowedTools The list of allowed tools from the config.
49 |  * @returns A Set of allowed sub-commands, or null if all commands are allowed.
50 |  *  - `null`: All sub-commands are allowed (e.g., --allowed-tools="ShellTool").
51 |  *  - `Set<string>`: A set of specifically allowed sub-commands (e.g., --allowed-tools="ShellTool(wc)" --allowed-tools="ShellTool(ls)").
52 |  *  - `Set<>` (empty): No sub-commands are allowed (e.g., --allowed-tools="ShellTool()").
53 |  */
54 | function parseAllowedSubcommands(
55 |   allowedTools: readonly string[],
56 | ): Set<string> | null {
57 |   const shellToolEntries = allowedTools.filter((tool) =>
58 |     SHELL_TOOL_NAMES.some((name) => tool.startsWith(name)),
59 |   );
60 | 
61 |   if (shellToolEntries.length === 0) {
62 |     return new Set(); // ShellTool not mentioned, so no subcommands are allowed.
63 |   }
64 | 
65 |   // If any entry is just "run_shell_command" or "ShellTool", all subcommands are allowed.
66 |   if (shellToolEntries.some((entry) => SHELL_TOOL_NAMES.includes(entry))) {
67 |     return null;
68 |   }
69 | 
70 |   const allSubcommands = new Set<string>();
71 |   const toolNamePattern = SHELL_TOOL_NAMES.join('|');
72 |   const regex = new RegExp(`^(${toolNamePattern})\\((.*)\\)$`);
73 | 
74 |   for (const entry of shellToolEntries) {
75 |     const match = entry.match(regex);
76 |     if (match) {
77 |       const subcommands = match[2];
78 |       if (subcommands) {
79 |         subcommands
80 |           .split(',')
81 |           .map((s) => s.trim())
82 |           .forEach((s) => s && allSubcommands.add(s));
83 |       }
84 |     }
85 |   }
86 | 
87 |   return allSubcommands;
88 | }
89 | 
90 | export interface ShellToolParams {
91 |   command: string;
92 |   description?: string;
93 |   directory?: string;
94 | }
95 | 
96 | export class ShellToolInvocation extends BaseToolInvocation<
97 |   ShellToolParams,
98 |   ToolResult
99 | > {
100 |   constructor(
101 |     private readonly config: Config,
102 |     params: ShellToolParams,
103 |     private readonly allowlist: Set<string>,
104 |   ) {
105 |     super(params);
106 |   }
107 | 
108 |   getDescription(): string {
109 |     let description = `${this.params.command}`;
110 |     // append optional [in directory]
111 |     // note description is needed even if validation fails due to absolute path
112 |     if (this.params.directory) {
113 |       description += ` [in ${this.params.directory}]`;
114 |     }
115 |     // append optional (description), replacing any line breaks with spaces
116 |     if (this.params.description) {
117 |       description += ` (${this.params.description.replace(/\n/g, ' ')})`;
118 |     }
119 |     return description;
120 |   }
121 | 
122 |   override async shouldConfirmExecute(
123 |     _abortSignal: AbortSignal,
124 |   ): Promise<ToolCallConfirmationDetails | false> {
125 |     const command = stripShellWrapper(this.params.command);
126 |     const rootCommands = [...new Set(getCommandRoots(command))];
127 | 
128 |     // In non-interactive mode, we need to prevent the tool from hanging while
129 |     // waiting for user input. If a tool is not fully allowed (e.g. via
130 |     // --allowed-tools="ShellTool(wc)"), we should throw an error instead of
131 |     // prompting for confirmation. This check is skipped in YOLO mode.
132 |     if (
133 |       !this.config.isInteractive() &&
134 |       this.config.getApprovalMode() !== ApprovalMode.YOLO
135 |     ) {
136 |       const allowed = this.config.getAllowedTools() || [];
137 |       const allowedSubcommands = parseAllowedSubcommands(allowed);
138 |       if (allowedSubcommands !== null) {
139 |         // Not all commands are allowed, so we need to check.
140 |         const allCommandsAllowed = rootCommands.every((cmd) =>
141 |           allowedSubcommands.has(cmd),
142 |         );
143 |         if (!allCommandsAllowed) {
144 |           throw new Error(
145 |             `Command "${command}" is not in the list of allowed tools for non-interactive mode.`,
146 |           );
147 |         }
148 |       }
149 |     }
150 | 
151 |     const commandsToConfirm = rootCommands.filter(
152 |       (command) => !this.allowlist.has(command),
153 |     );
154 | 
155 |     if (commandsToConfirm.length === 0) {
156 |       return false; // already approved and allowlisted
157 |     }
158 | 
159 |     const confirmationDetails: ToolExecuteConfirmationDetails = {
160 |       type: 'exec',
161 |       title: 'Confirm Shell Command',
162 |       command: this.params.command,
163 |       rootCommand: commandsToConfirm.join(', '),
164 |       onConfirm: async (outcome: ToolConfirmationOutcome) => {
165 |         if (outcome === ToolConfirmationOutcome.ProceedAlways) {
166 |           commandsToConfirm.forEach((command) => this.allowlist.add(command));
167 |         }
168 |       },
169 |     };
170 |     return confirmationDetails;
171 |   }
172 | 
173 |   async execute(
174 |     signal: AbortSignal,
175 |     updateOutput?: (output: string | AnsiOutput) => void,
176 |     shellExecutionConfig?: ShellExecutionConfig,
177 |     setPidCallback?: (pid: number) => void,
178 |   ): Promise<ToolResult> {
179 |     const strippedCommand = stripShellWrapper(this.params.command);
180 | 
181 |     if (signal.aborted) {
182 |       return {
183 |         llmContent: 'Command was cancelled by user before it could start.',
184 |         returnDisplay: 'Command cancelled by user.',
185 |       };
186 |     }
187 | 
188 |     const isWindows = os.platform() === 'win32';
189 |     const tempFileName = `shell_pgrep_${crypto
190 |       .randomBytes(6)
191 |       .toString('hex')}.tmp`;
192 |     const tempFilePath = path.join(os.tmpdir(), tempFileName);
193 | 
194 |     try {
195 |       // pgrep is not available on Windows, so we can't get background PIDs
196 |       const commandToExecute = isWindows
197 |         ? strippedCommand
198 |         : (() => {
199 |             // wrap command to append subprocess pids (via pgrep) to temporary file
200 |             let command = strippedCommand.trim();
201 |             if (!command.endsWith('&')) command += ';';
202 |             return `{ ${command} }; __code=$?; pgrep -g 0 >${tempFilePath} 2>&1; exit $__code;`;
203 |           })();
204 | 
205 |       const cwd = this.params.directory || this.config.getTargetDir();
206 | 
207 |       let cumulativeOutput: string | AnsiOutput = '';
208 |       let lastUpdateTime = Date.now();
209 |       let isBinaryStream = false;
210 | 
211 |       const { result: resultPromise, pid } =
212 |         await ShellExecutionService.execute(
213 |           commandToExecute,
214 |           cwd,
215 |           (event: ShellOutputEvent) => {
216 |             if (!updateOutput) {
217 |               return;
218 |             }
219 | 
220 |             let shouldUpdate = false;
221 | 
222 |             switch (event.type) {
223 |               case 'data':
224 |                 if (isBinaryStream) break;
225 |                 cumulativeOutput = event.chunk;
226 |                 shouldUpdate = true;
227 |                 break;
228 |               case 'binary_detected':
229 |                 isBinaryStream = true;
230 |                 cumulativeOutput =
231 |                   '[Binary output detected. Halting stream...]';
232 |                 shouldUpdate = true;
233 |                 break;
234 |               case 'binary_progress':
235 |                 isBinaryStream = true;
236 |                 cumulativeOutput = `[Receiving binary output... ${formatMemoryUsage(
237 |                   event.bytesReceived,
238 |                 )} received]`;
239 |                 if (Date.now() - lastUpdateTime > OUTPUT_UPDATE_INTERVAL_MS) {
240 |                   shouldUpdate = true;
241 |                 }
242 |                 break;
243 |               default: {
244 |                 throw new Error('An unhandled ShellOutputEvent was found.');
245 |               }
246 |             }
247 | 
248 |             if (shouldUpdate) {
249 |               updateOutput(cumulativeOutput);
250 |               lastUpdateTime = Date.now();
251 |             }
252 |           },
253 |           signal,
254 |           this.config.getEnableInteractiveShell(),
255 |           shellExecutionConfig ?? {},
256 |         );
257 | 
258 |       if (pid && setPidCallback) {
259 |         setPidCallback(pid);
260 |       }
261 | 
262 |       const result = await resultPromise;
263 | 
264 |       const backgroundPIDs: number[] = [];
265 |       if (os.platform() !== 'win32') {
266 |         if (fs.existsSync(tempFilePath)) {
267 |           const pgrepLines = fs
268 |             .readFileSync(tempFilePath, 'utf8')
269 |             .split(EOL)
270 |             .filter(Boolean);
271 |           for (const line of pgrepLines) {
272 |             if (!/^\d+$/.test(line)) {
273 |               console.error(`pgrep: ${line}`);
274 |             }
275 |             const pid = Number(line);
276 |             if (pid !== result.pid) {
277 |               backgroundPIDs.push(pid);
278 |             }
279 |           }
280 |         } else {
281 |           if (!signal.aborted) {
282 |             console.error('missing pgrep output');
283 |           }
284 |         }
285 |       }
286 | 
287 |       let llmContent = '';
288 |       if (result.aborted) {
289 |         llmContent = 'Command was cancelled by user before it could complete.';
290 |         if (result.output.trim()) {
291 |           llmContent += ` Below is the output before it was cancelled:\n${result.output}`;
292 |         } else {
293 |           llmContent += ' There was no output before it was cancelled.';
294 |         }
295 |       } else {
296 |         // Create a formatted error string for display, replacing the wrapper command
297 |         // with the user-facing command.
298 |         const finalError = result.error
299 |           ? result.error.message.replace(commandToExecute, this.params.command)
300 |           : '(none)';
301 | 
302 |         llmContent = [
303 |           `Command: ${this.params.command}`,
304 |           `Directory: ${this.params.directory || '(root)'}`,
305 |           `Output: ${result.output || '(empty)'}`,
306 |           `Error: ${finalError}`, // Use the cleaned error string.
307 |           `Exit Code: ${result.exitCode ?? '(none)'}`,
308 |           `Signal: ${result.signal ?? '(none)'}`,
309 |           `Background PIDs: ${
310 |             backgroundPIDs.length ? backgroundPIDs.join(', ') : '(none)'
311 |           }`,
312 |           `Process Group PGID: ${result.pid ?? '(none)'}`,
313 |         ].join('\n');
314 |       }
315 | 
316 |       let returnDisplayMessage = '';
317 |       if (this.config.getDebugMode()) {
318 |         returnDisplayMessage = llmContent;
319 |       } else {
320 |         if (result.output.trim()) {
321 |           returnDisplayMessage = result.output;
322 |         } else {
323 |           if (result.aborted) {
324 |             returnDisplayMessage = 'Command cancelled by user.';
325 |           } else if (result.signal) {
326 |             returnDisplayMessage = `Command terminated by signal: ${result.signal}`;
327 |           } else if (result.error) {
328 |             returnDisplayMessage = `Command failed: ${getErrorMessage(
329 |               result.error,
330 |             )}`;
331 |           } else if (result.exitCode !== null && result.exitCode !== 0) {
332 |             returnDisplayMessage = `Command exited with code: ${result.exitCode}`;
333 |           }
334 |           // If output is empty and command succeeded (code 0, no error/signal/abort),
335 |           // returnDisplayMessage will remain empty, which is fine.
336 |         }
337 |       }
338 | 
339 |       const summarizeConfig = this.config.getSummarizeToolOutputConfig();
340 |       const executionError = result.error
341 |         ? {
342 |             error: {
343 |               message: result.error.message,
344 |               type: ToolErrorType.SHELL_EXECUTE_ERROR,
345 |             },
346 |           }
347 |         : {};
348 |       if (summarizeConfig && summarizeConfig[ShellTool.Name]) {
349 |         const summary = await summarizeToolOutput(
350 |           llmContent,
351 |           this.config.getGeminiClient(),
352 |           signal,
353 |           summarizeConfig[ShellTool.Name].tokenBudget,
354 |         );
355 |         return {
356 |           llmContent: summary,
357 |           returnDisplay: returnDisplayMessage,
358 |           ...executionError,
359 |         };
360 |       }
361 | 
362 |       return {
363 |         llmContent,
364 |         returnDisplay: returnDisplayMessage,
365 |         ...executionError,
366 |       };
367 |     } finally {
368 |       if (fs.existsSync(tempFilePath)) {
369 |         fs.unlinkSync(tempFilePath);
370 |       }
371 |     }
372 |   }
373 | }
374 | 
375 | function getShellToolDescription(): string {
376 |   const returnedInfo = `
377 | 
378 |       The following information is returned:
379 | 
380 |       Command: Executed command.
381 |       Directory: Directory where command was executed, or \`(root)\`.
382 |       Stdout: Output on stdout stream. Can be \`(empty)\` or partial on error and for any unwaited background processes.
383 |       Stderr: Output on stderr stream. Can be \`(empty)\` or partial on error and for any unwaited background processes.
384 |       Error: Error or \`(none)\` if no error was reported for the subprocess.
385 |       Exit Code: Exit code or \`(none)\` if terminated by signal.
386 |       Signal: Signal number or \`(none)\` if no signal was received.
387 |       Background PIDs: List of background processes started or \`(none)\`.
388 |       Process Group PGID: Process group started or \`(none)\``;
389 | 
390 |   if (os.platform() === 'win32') {
391 |     return `This tool executes a given shell command as \`cmd.exe /c <command>\`. Command can start background processes using \`start /b\`.${returnedInfo}`;
392 |   } else {
393 |     return `This tool executes a given shell command as \`bash -c <command>\`. Command can start background processes using \`&\`. Command is executed as a subprocess that leads its own process group. Command process group can be terminated as \`kill -- -PGID\` or signaled as \`kill -s SIGNAL -- -PGID\`.${returnedInfo}`;
394 |   }
395 | }
396 | 
397 | function getCommandDescription(): string {
398 |   const cmd_substitution_warning =
399 |     '\n*** WARNING: Command substitution using $(), `` ` ``, <(), or >() is not allowed for security reasons.';
400 |   if (os.platform() === 'win32') {
401 |     return (
402 |       'Exact command to execute as `cmd.exe /c <command>`' +
403 |       cmd_substitution_warning
404 |     );
405 |   } else {
406 |     return (
407 |       'Exact bash command to execute as `bash -c <command>`' +
408 |       cmd_substitution_warning
409 |     );
410 |   }
411 | }
412 | 
413 | export class ShellTool extends BaseDeclarativeTool<
414 |   ShellToolParams,
415 |   ToolResult
416 | > {
417 |   static Name: string = 'run_shell_command';
418 |   private allowlist: Set<string> = new Set();
419 | 
420 |   constructor(private readonly config: Config) {
421 |     super(
422 |       ShellTool.Name,
423 |       'Shell',
424 |       getShellToolDescription(),
425 |       Kind.Execute,
426 |       {
427 |         type: 'object',
428 |         properties: {
429 |           command: {
430 |             type: 'string',
431 |             description: getCommandDescription(),
432 |           },
433 |           description: {
434 |             type: 'string',
435 |             description:
436 |               'Brief description of the command for the user. Be specific and concise. Ideally a single sentence. Can be up to 3 sentences for clarity. No line breaks.',
437 |           },
438 |           directory: {
439 |             type: 'string',
440 |             description:
441 |               '(OPTIONAL) The absolute path of the directory to run the command in. If not provided, the project root directory is used. Must be a directory within the workspace and must already exist.',
442 |           },
443 |         },
444 |         required: ['command'],
445 |       },
446 |       false, // output is not markdown
447 |       true, // output can be updated
448 |     );
449 |   }
450 | 
451 |   protected override validateToolParamValues(
452 |     params: ShellToolParams,
453 |   ): string | null {
454 |     const commandCheck = isCommandAllowed(params.command, this.config);
455 |     if (!commandCheck.allowed) {
456 |       if (!commandCheck.reason) {
457 |         console.error(
458 |           'Unexpected: isCommandAllowed returned false without a reason',
459 |         );
460 |         return `Command is not allowed: ${params.command}`;
461 |       }
462 |       return commandCheck.reason;
463 |     }
464 |     if (!params.command.trim()) {
465 |       return 'Command cannot be empty.';
466 |     }
467 |     if (getCommandRoots(params.command).length === 0) {
468 |       return 'Could not identify command root to obtain permission from user.';
469 |     }
470 |     if (params.directory) {
471 |       if (!path.isAbsolute(params.directory)) {
472 |         return 'Directory must be an absolute path.';
473 |       }
474 |       const workspaceDirs = this.config.getWorkspaceContext().getDirectories();
475 |       const isWithinWorkspace = workspaceDirs.some((wsDir) =>
476 |         params.directory!.startsWith(wsDir),
477 |       );
478 | 
479 |       if (!isWithinWorkspace) {
480 |         return `Directory '${params.directory}' is not within any of the registered workspace directories.`;
481 |       }
482 |     }
483 |     return null;
484 |   }
485 | 
486 |   protected createInvocation(
487 |     params: ShellToolParams,
488 |   ): ToolInvocation<ShellToolParams, ToolResult> {
489 |     return new ShellToolInvocation(this.config, params, this.allowlist);
490 |   }
491 | }
```

src/tools/smart-edit.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /* eslint-disable @typescript-eslint/no-explicit-any */
8 | 
9 | const mockFixLLMEditWithInstruction = vi.hoisted(() => vi.fn());
10 | const mockGenerateJson = vi.hoisted(() => vi.fn());
11 | const mockOpenDiff = vi.hoisted(() => vi.fn());
12 | 
13 | import { IdeClient } from '../ide/ide-client.js';
14 | 
15 | vi.mock('../ide/ide-client.js', () => ({
16 |   IdeClient: {
17 |     getInstance: vi.fn(),
18 |   },
19 | }));
20 | 
21 | vi.mock('../utils/llm-edit-fixer.js', () => ({
22 |   FixLLMEditWithInstruction: mockFixLLMEditWithInstruction,
23 | }));
24 | 
25 | vi.mock('../core/client.js', () => ({
26 |   GeminiClient: vi.fn().mockImplementation(() => ({
27 |     generateJson: mockGenerateJson,
28 |     getHistory: vi.fn().mockResolvedValue([]),
29 |   })),
30 | }));
31 | 
32 | vi.mock('../utils/editor.js', () => ({
33 |   openDiff: mockOpenDiff,
34 | }));
35 | 
36 | import {
37 |   describe,
38 |   it,
39 |   expect,
40 |   beforeEach,
41 |   afterEach,
42 |   vi,
43 |   type Mock,
44 | } from 'vitest';
45 | import {
46 |   SmartEditTool,
47 |   type EditToolParams,
48 |   calculateReplacement,
49 | } from './smart-edit.js';
50 | import { applyReplacement } from './edit.js';
51 | import { type FileDiff, ToolConfirmationOutcome } from './tools.js';
52 | import { ToolErrorType } from './tool-error.js';
53 | import path from 'node:path';
54 | import fs from 'node:fs';
55 | import os from 'node:os';
56 | import { ApprovalMode, type Config } from '../config/config.js';
57 | import { type Content, type Part, type SchemaUnion } from '@google/genai';
58 | import { createMockWorkspaceContext } from '../test-utils/mockWorkspaceContext.js';
59 | import { StandardFileSystemService } from '../services/fileSystemService.js';
60 | import type { BaseLlmClient } from '../core/baseLlmClient.js';
61 | 
62 | describe('SmartEditTool', () => {
63 |   let tool: SmartEditTool;
64 |   let tempDir: string;
65 |   let rootDir: string;
66 |   let mockConfig: Config;
67 |   let geminiClient: any;
68 |   let fileSystemService: StandardFileSystemService;
69 |   let baseLlmClient: BaseLlmClient;
70 | 
71 |   beforeEach(() => {
72 |     vi.restoreAllMocks();
73 |     tempDir = fs.mkdtempSync(path.join(os.tmpdir(), 'smart-edit-tool-test-'));
74 |     rootDir = path.join(tempDir, 'root');
75 |     fs.mkdirSync(rootDir);
76 | 
77 |     geminiClient = {
78 |       generateJson: mockGenerateJson,
79 |       getHistory: vi.fn().mockResolvedValue([]),
80 |     };
81 | 
82 |     baseLlmClient = {
83 |       generateJson: mockGenerateJson,
84 |     } as unknown as BaseLlmClient;
85 | 
86 |     fileSystemService = new StandardFileSystemService();
87 | 
88 |     mockConfig = {
89 |       getUsageStatisticsEnabled: vi.fn(() => true),
90 |       getSessionId: vi.fn(() => 'mock-session-id'),
91 |       getContentGeneratorConfig: vi.fn(() => ({ authType: 'mock' })),
92 |       getUseSmartEdit: vi.fn(() => false),
93 |       getUseModelRouter: vi.fn(() => false),
94 |       getProxy: vi.fn(() => undefined),
95 |       getGeminiClient: vi.fn().mockReturnValue(geminiClient),
96 |       getBaseLlmClient: vi.fn().mockReturnValue(baseLlmClient),
97 |       getTargetDir: () => rootDir,
98 |       getApprovalMode: vi.fn(),
99 |       setApprovalMode: vi.fn(),
100 |       getWorkspaceContext: () => createMockWorkspaceContext(rootDir),
101 |       getFileSystemService: () => fileSystemService,
102 |       getIdeMode: () => false,
103 |       getApiKey: () => 'test-api-key',
104 |       getModel: () => 'test-model',
105 |       getSandbox: () => false,
106 |       getDebugMode: () => false,
107 |       getQuestion: () => undefined,
108 |       getFullContext: () => false,
109 |       getToolDiscoveryCommand: () => undefined,
110 |       getToolCallCommand: () => undefined,
111 |       getMcpServerCommand: () => undefined,
112 |       getMcpServers: () => undefined,
113 |       getUserAgent: () => 'test-agent',
114 |       getUserMemory: () => '',
115 |       setUserMemory: vi.fn(),
116 |       getGeminiMdFileCount: () => 0,
117 |       setGeminiMdFileCount: vi.fn(),
118 |       getToolRegistry: () => ({}) as any,
119 |     } as unknown as Config;
120 | 
121 |     (mockConfig.getApprovalMode as Mock).mockClear();
122 |     (mockConfig.getApprovalMode as Mock).mockReturnValue(ApprovalMode.DEFAULT);
123 | 
124 |     mockFixLLMEditWithInstruction.mockReset();
125 |     mockFixLLMEditWithInstruction.mockResolvedValue({
126 |       noChangesRequired: false,
127 |       search: '',
128 |       replace: '',
129 |       explanation: 'LLM fix failed',
130 |     });
131 | 
132 |     mockGenerateJson.mockReset();
133 |     mockGenerateJson.mockImplementation(
134 |       async (contents: Content[], schema: SchemaUnion) => {
135 |         const userContent = contents.find((c: Content) => c.role === 'user');
136 |         let promptText = '';
137 |         if (userContent && userContent.parts) {
138 |           promptText = userContent.parts
139 |             .filter((p: Part) => typeof (p as any).text === 'string')
140 |             .map((p: Part) => (p as any).text)
141 |             .join('\n');
142 |         }
143 |         const snippetMatch = promptText.match(
144 |           /Problematic target snippet:\n```\n([\s\S]*?)\n```/,
145 |         );
146 |         const problematicSnippet =
147 |           snippetMatch && snippetMatch[1] ? snippetMatch[1] : '';
148 | 
149 |         if (((schema as any).properties as any)?.corrected_target_snippet) {
150 |           return Promise.resolve({
151 |             corrected_target_snippet: problematicSnippet,
152 |           });
153 |         }
154 |         if (((schema as any).properties as any)?.corrected_new_string) {
155 |           const originalNewStringMatch = promptText.match(
156 |             /original_new_string \(what was intended to replace original_old_string\):\n```\n([\s\S]*?)\n```/,
157 |           );
158 |           const originalNewString =
159 |             originalNewStringMatch && originalNewStringMatch[1]
160 |               ? originalNewStringMatch[1]
161 |               : '';
162 |           return Promise.resolve({ corrected_new_string: originalNewString });
163 |         }
164 |         return Promise.resolve({});
165 |       },
166 |     );
167 | 
168 |     tool = new SmartEditTool(mockConfig);
169 |   });
170 | 
171 |   afterEach(() => {
172 |     fs.rmSync(tempDir, { recursive: true, force: true });
173 |   });
174 | 
175 |   describe('applyReplacement', () => {
176 |     it('should return newString if isNewFile is true', () => {
177 |       expect(applyReplacement(null, 'old', 'new', true)).toBe('new');
178 |       expect(applyReplacement('existing', 'old', 'new', true)).toBe('new');
179 |     });
180 | 
181 |     it('should replace oldString with newString in currentContent', () => {
182 |       expect(applyReplacement('hello old world old', 'old', 'new', false)).toBe(
183 |         'hello new world new',
184 |       );
185 |     });
186 | 
187 |     it('should treat $ literally and not as replacement pattern', () => {
188 |       const current = 'regex end is $ and more';
189 |       const oldStr = 'regex end is $';
190 |       const newStr = 'regex end is $ and correct';
191 |       const result = applyReplacement(current, oldStr, newStr, false);
192 |       expect(result).toBe('regex end is $ and correct and more');
193 |     });
194 | 
195 |     it("should treat $' literally and not as a replacement pattern", () => {
196 |       const current = 'foo';
197 |       const oldStr = 'foo';
198 |       const newStr = "bar$'baz";
199 |       const result = applyReplacement(current, oldStr, newStr, false);
200 |       expect(result).toBe("bar$'baz");
201 |     });
202 |   });
203 | 
204 |   describe('calculateReplacement', () => {
205 |     const abortSignal = new AbortController().signal;
206 | 
207 |     it('should perform an exact replacement', async () => {
208 |       const content = 'hello world';
209 |       const result = await calculateReplacement(mockConfig, {
210 |         params: {
211 |           file_path: 'test.txt',
212 |           instruction: 'test',
213 |           old_string: 'world',
214 |           new_string: 'moon',
215 |         },
216 |         currentContent: content,
217 |         abortSignal,
218 |       });
219 |       expect(result.newContent).toBe('hello moon');
220 |       expect(result.occurrences).toBe(1);
221 |     });
222 | 
223 |     it('should perform a flexible, whitespace-insensitive replacement', async () => {
224 |       const content = '  hello\n    world\n';
225 |       const result = await calculateReplacement(mockConfig, {
226 |         params: {
227 |           file_path: 'test.txt',
228 |           instruction: 'test',
229 |           old_string: 'hello\nworld',
230 |           new_string: 'goodbye\nmoon',
231 |         },
232 |         currentContent: content,
233 |         abortSignal,
234 |       });
235 |       expect(result.newContent).toBe('  goodbye\n  moon\n');
236 |       expect(result.occurrences).toBe(1);
237 |     });
238 | 
239 |     it('should return 0 occurrences if no match is found', async () => {
240 |       const content = 'hello world';
241 |       const result = await calculateReplacement(mockConfig, {
242 |         params: {
243 |           file_path: 'test.txt',
244 |           instruction: 'test',
245 |           old_string: 'nomatch',
246 |           new_string: 'moon',
247 |         },
248 |         currentContent: content,
249 |         abortSignal,
250 |       });
251 |       expect(result.newContent).toBe(content);
252 |       expect(result.occurrences).toBe(0);
253 |     });
254 | 
255 |     it('should perform a regex-based replacement for flexible intra-line whitespace', async () => {
256 |       // This case would fail with the previous exact and line-trimming flexible logic
257 |       // because the whitespace *within* the line is different.
258 |       const content = '  function  myFunc( a, b ) {\n    return a + b;\n  }';
259 |       const result = await calculateReplacement(mockConfig, {
260 |         params: {
261 |           file_path: 'test.js',
262 |           instruction: 'test',
263 |           old_string: 'function myFunc(a, b) {', // Note the normalized whitespace
264 |           new_string: 'const yourFunc = (a, b) => {',
265 |         },
266 |         currentContent: content,
267 |         abortSignal,
268 |       });
269 | 
270 |       // The indentation from the original line should be preserved and applied to the new string.
271 |       const expectedContent =
272 |         '  const yourFunc = (a, b) => {\n    return a + b;\n  }';
273 |       expect(result.newContent).toBe(expectedContent);
274 |       expect(result.occurrences).toBe(1);
275 |     });
276 |   });
277 | 
278 |   describe('validateToolParams', () => {
279 |     it('should return null for valid params', () => {
280 |       const params: EditToolParams = {
281 |         file_path: path.join(rootDir, 'test.txt'),
282 |         instruction: 'An instruction',
283 |         old_string: 'old',
284 |         new_string: 'new',
285 |       };
286 |       expect(tool.validateToolParams(params)).toBeNull();
287 |     });
288 | 
289 |     it('should return an error if path is outside the workspace', () => {
290 |       const params: EditToolParams = {
291 |         file_path: path.join(os.tmpdir(), 'outside.txt'),
292 |         instruction: 'An instruction',
293 |         old_string: 'old',
294 |         new_string: 'new',
295 |       };
296 |       expect(tool.validateToolParams(params)).toMatch(
297 |         /must be within one of the workspace directories/,
298 |       );
299 |     });
300 |   });
301 | 
302 |   describe('execute', () => {
303 |     const testFile = 'execute_me.txt';
304 |     let filePath: string;
305 | 
306 |     beforeEach(() => {
307 |       filePath = path.join(rootDir, testFile);
308 |     });
309 | 
310 |     it('should reject when calculateEdit fails after an abort signal', async () => {
311 |       const params: EditToolParams = {
312 |         file_path: path.join(rootDir, 'abort-execute.txt'),
313 |         instruction: 'Abort during execute',
314 |         old_string: 'old',
315 |         new_string: 'new',
316 |       };
317 | 
318 |       const invocation = tool.build(params);
319 |       const abortController = new AbortController();
320 |       const abortError = new Error(
321 |         'Abort requested during smart edit execution',
322 |       );
323 | 
324 |       const calculateSpy = vi
325 |         .spyOn(invocation as any, 'calculateEdit')
326 |         .mockImplementation(async () => {
327 |           if (!abortController.signal.aborted) {
328 |             abortController.abort();
329 |           }
330 |           throw abortError;
331 |         });
332 | 
333 |       await expect(invocation.execute(abortController.signal)).rejects.toBe(
334 |         abortError,
335 |       );
336 | 
337 |       calculateSpy.mockRestore();
338 |     });
339 | 
340 |     it('should edit an existing file and return diff with fileName', async () => {
341 |       const initialContent = 'This is some old text.';
342 |       const newContent = 'This is some new text.';
343 |       fs.writeFileSync(filePath, initialContent, 'utf8');
344 |       const params: EditToolParams = {
345 |         file_path: filePath,
346 |         instruction: 'Replace old with new',
347 |         old_string: 'old',
348 |         new_string: 'new',
349 |       };
350 | 
351 |       const invocation = tool.build(params);
352 |       const result = await invocation.execute(new AbortController().signal);
353 | 
354 |       expect(result.llmContent).toMatch(/Successfully modified file/);
355 |       expect(fs.readFileSync(filePath, 'utf8')).toBe(newContent);
356 |       const display = result.returnDisplay as FileDiff;
357 |       expect(display.fileDiff).toMatch(initialContent);
358 |       expect(display.fileDiff).toMatch(newContent);
359 |       expect(display.fileName).toBe(testFile);
360 |     });
361 | 
362 |     it('should return error if old_string is not found in file', async () => {
363 |       fs.writeFileSync(filePath, 'Some content.', 'utf8');
364 |       const params: EditToolParams = {
365 |         file_path: filePath,
366 |         instruction: 'Replace non-existent text',
367 |         old_string: 'nonexistent',
368 |         new_string: 'replacement',
369 |       };
370 |       const invocation = tool.build(params);
371 |       const result = await invocation.execute(new AbortController().signal);
372 |       expect(result.llmContent).toMatch(/0 occurrences found for old_string/);
373 |       expect(result.returnDisplay).toMatch(
374 |         /Failed to edit, could not find the string to replace./,
375 |       );
376 |       expect(mockFixLLMEditWithInstruction).toHaveBeenCalled();
377 |     });
378 | 
379 |     it('should succeed if FixLLMEditWithInstruction corrects the params', async () => {
380 |       const initialContent = 'This is some original text.';
381 |       const finalContent = 'This is some brand new text.';
382 |       fs.writeFileSync(filePath, initialContent, 'utf8');
383 |       const params: EditToolParams = {
384 |         file_path: filePath,
385 |         instruction: 'Replace original with brand new',
386 |         old_string: 'wrong text', // This will fail first
387 |         new_string: 'brand new text',
388 |       };
389 | 
390 |       mockFixLLMEditWithInstruction.mockResolvedValueOnce({
391 |         noChangesRequired: false,
392 |         search: 'original text', // The corrected search string
393 |         replace: 'brand new text',
394 |         explanation: 'Corrected the search string to match the file content.',
395 |       });
396 | 
397 |       const invocation = tool.build(params);
398 |       const result = await invocation.execute(new AbortController().signal);
399 | 
400 |       expect(result.error).toBeUndefined();
401 |       expect(result.llmContent).toMatch(/Successfully modified file/);
402 |       expect(fs.readFileSync(filePath, 'utf8')).toBe(finalContent);
403 |       expect(mockFixLLMEditWithInstruction).toHaveBeenCalledTimes(1);
404 |     });
405 | 
406 |     it('should preserve CRLF line endings when editing a file', async () => {
407 |       const initialContent = 'line one\r\nline two\r\n';
408 |       const newContent = 'line one\r\nline three\r\n';
409 |       fs.writeFileSync(filePath, initialContent, 'utf8');
410 |       const params: EditToolParams = {
411 |         file_path: filePath,
412 |         instruction: 'Replace two with three',
413 |         old_string: 'line two',
414 |         new_string: 'line three',
415 |       };
416 | 
417 |       const invocation = tool.build(params);
418 |       await invocation.execute(new AbortController().signal);
419 | 
420 |       const finalContent = fs.readFileSync(filePath, 'utf8');
421 |       expect(finalContent).toBe(newContent);
422 |     });
423 | 
424 |     it('should create a new file with CRLF line endings if new_string has them', async () => {
425 |       const newContentWithCRLF = 'new line one\r\nnew line two\r\n';
426 |       const params: EditToolParams = {
427 |         file_path: filePath,
428 |         instruction: 'Create a new file',
429 |         old_string: '',
430 |         new_string: newContentWithCRLF,
431 |       };
432 | 
433 |       const invocation = tool.build(params);
434 |       await invocation.execute(new AbortController().signal);
435 | 
436 |       const finalContent = fs.readFileSync(filePath, 'utf8');
437 |       expect(finalContent).toBe(newContentWithCRLF);
438 |     });
439 | 
440 |     it('should return NO_CHANGE if FixLLMEditWithInstruction determines no changes are needed', async () => {
441 |       const initialContent = 'The price is $100.';
442 |       fs.writeFileSync(filePath, initialContent, 'utf8');
443 |       const params: EditToolParams = {
444 |         file_path: filePath,
445 |         instruction: 'Ensure the price is $100',
446 |         old_string: 'price is $50', // Incorrect old string
447 |         new_string: 'price is $100',
448 |       };
449 | 
450 |       mockFixLLMEditWithInstruction.mockResolvedValueOnce({
451 |         noChangesRequired: true,
452 |         search: '',
453 |         replace: '',
454 |         explanation: 'The price is already correctly set to $100.',
455 |       });
456 | 
457 |       const invocation = tool.build(params);
458 |       const result = await invocation.execute(new AbortController().signal);
459 | 
460 |       expect(result.error?.type).toBe(
461 |         ToolErrorType.EDIT_NO_CHANGE_LLM_JUDGEMENT,
462 |       );
463 |       expect(result.llmContent).toMatch(
464 |         /A secondary check by an LLM determined/,
465 |       );
466 |       expect(fs.readFileSync(filePath, 'utf8')).toBe(initialContent); // File is unchanged
467 |     });
468 |   });
469 | 
470 |   describe('self-correction with content refresh to pull in external edits', () => {
471 |     const testFile = 'test.txt';
472 |     let filePath: string;
473 | 
474 |     beforeEach(() => {
475 |       filePath = path.join(rootDir, testFile);
476 |     });
477 | 
478 |     it('should use refreshed file content for self-correction if file was modified externally', async () => {
479 |       const initialContent = 'This is the original content.';
480 |       const externallyModifiedContent =
481 |         'This is the externally modified content.';
482 |       fs.writeFileSync(filePath, initialContent, 'utf8');
483 | 
484 |       const params: EditToolParams = {
485 |         file_path: filePath,
486 |         instruction:
487 |           'Replace "externally modified content" with "externally modified string"',
488 |         old_string: 'externally modified content', // This will fail the first attempt, triggering self-correction.
489 |         new_string: 'externally modified string',
490 |       };
491 | 
492 |       // Spy on `readTextFile` to simulate an external file change between reads.
493 |       const readTextFileSpy = vi
494 |         .spyOn(fileSystemService, 'readTextFile')
495 |         .mockResolvedValueOnce(initialContent) // First call in `calculateEdit`
496 |         .mockResolvedValueOnce(externallyModifiedContent); // Second call in `attemptSelfCorrection`
497 | 
498 |       const invocation = tool.build(params);
499 |       await invocation.execute(new AbortController().signal);
500 | 
501 |       // Assert that the file was read twice (initial read, then re-read for hash comparison).
502 |       expect(readTextFileSpy).toHaveBeenCalledTimes(2);
503 | 
504 |       // Assert that the self-correction LLM was called with the updated content and a specific message.
505 |       expect(mockFixLLMEditWithInstruction).toHaveBeenCalledWith(
506 |         expect.any(String), // instruction
507 |         params.old_string,
508 |         params.new_string,
509 |         expect.stringContaining(
510 |           'However, the file has been modified by either the user or an external process',
511 |         ), // errorForLlmEditFixer
512 |         externallyModifiedContent, // The new content for correction
513 |         expect.any(Object), // baseLlmClient
514 |         expect.any(Object), // abortSignal
515 |       );
516 |     });
517 |   });
518 | 
519 |   describe('Error Scenarios', () => {
520 |     const testFile = 'error_test.txt';
521 |     let filePath: string;
522 | 
523 |     beforeEach(() => {
524 |       filePath = path.join(rootDir, testFile);
525 |     });
526 | 
527 |     it('should return FILE_NOT_FOUND error', async () => {
528 |       const params: EditToolParams = {
529 |         file_path: filePath,
530 |         instruction: 'test',
531 |         old_string: 'any',
532 |         new_string: 'new',
533 |       };
534 |       const invocation = tool.build(params);
535 |       const result = await invocation.execute(new AbortController().signal);
536 |       expect(result.error?.type).toBe(ToolErrorType.FILE_NOT_FOUND);
537 |     });
538 | 
539 |     it('should return ATTEMPT_TO_CREATE_EXISTING_FILE error', async () => {
540 |       fs.writeFileSync(filePath, 'existing content', 'utf8');
541 |       const params: EditToolParams = {
542 |         file_path: filePath,
543 |         instruction: 'test',
544 |         old_string: '',
545 |         new_string: 'new content',
546 |       };
547 |       const invocation = tool.build(params);
548 |       const result = await invocation.execute(new AbortController().signal);
549 |       expect(result.error?.type).toBe(
550 |         ToolErrorType.ATTEMPT_TO_CREATE_EXISTING_FILE,
551 |       );
552 |     });
553 | 
554 |     it('should return NO_OCCURRENCE_FOUND error', async () => {
555 |       fs.writeFileSync(filePath, 'content', 'utf8');
556 |       const params: EditToolParams = {
557 |         file_path: filePath,
558 |         instruction: 'test',
559 |         old_string: 'not-found',
[TRUNCATED]
```

src/tools/smart-edit.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs';
8 | import * as path from 'node:path';
9 | import * as crypto from 'node:crypto';
10 | import * as Diff from 'diff';
11 | import {
12 |   BaseDeclarativeTool,
13 |   Kind,
14 |   type ToolCallConfirmationDetails,
15 |   ToolConfirmationOutcome,
16 |   type ToolEditConfirmationDetails,
17 |   type ToolInvocation,
18 |   type ToolLocation,
19 |   type ToolResult,
20 |   type ToolResultDisplay,
21 | } from './tools.js';
22 | import { ToolErrorType } from './tool-error.js';
23 | import { makeRelative, shortenPath } from '../utils/paths.js';
24 | import { isNodeError } from '../utils/errors.js';
25 | import { type Config, ApprovalMode } from '../config/config.js';
26 | import { DEFAULT_DIFF_OPTIONS, getDiffStat } from './diffOptions.js';
27 | import { ReadFileTool } from './read-file.js';
28 | import {
29 |   type ModifiableDeclarativeTool,
30 |   type ModifyContext,
31 | } from './modifiable-tool.js';
32 | import { IdeClient } from '../ide/ide-client.js';
33 | import { FixLLMEditWithInstruction } from '../utils/llm-edit-fixer.js';
34 | import { applyReplacement } from './edit.js';
35 | import { safeLiteralReplace } from '../utils/textUtils.js';
36 | import { SmartEditStrategyEvent } from '../telemetry/types.js';
37 | import { logSmartEditStrategy } from '../telemetry/loggers.js';
38 | import { SmartEditCorrectionEvent } from '../telemetry/types.js';
39 | import { logSmartEditCorrectionEvent } from '../telemetry/loggers.js';
40 | 
41 | import { correctPath } from '../utils/pathCorrector.js';
42 | interface ReplacementContext {
43 |   params: EditToolParams;
44 |   currentContent: string;
45 |   abortSignal: AbortSignal;
46 | }
47 | 
48 | interface ReplacementResult {
49 |   newContent: string;
50 |   occurrences: number;
51 |   finalOldString: string;
52 |   finalNewString: string;
53 | }
54 | 
55 | /**
56 |  * Creates a SHA256 hash of the given content.
57 |  * @param content The string content to hash.
58 |  * @returns A hex-encoded hash string.
59 |  */
60 | function hashContent(content: string): string {
61 |   return crypto.createHash('sha256').update(content).digest('hex');
62 | }
63 | 
64 | function restoreTrailingNewline(
65 |   originalContent: string,
66 |   modifiedContent: string,
67 | ): string {
68 |   const hadTrailingNewline = originalContent.endsWith('\n');
69 |   if (hadTrailingNewline && !modifiedContent.endsWith('\n')) {
70 |     return modifiedContent + '\n';
71 |   } else if (!hadTrailingNewline && modifiedContent.endsWith('\n')) {
72 |     return modifiedContent.replace(/\n$/, '');
73 |   }
74 |   return modifiedContent;
75 | }
76 | 
77 | /**
78 |  * Escapes characters with special meaning in regular expressions.
79 |  * @param str The string to escape.
80 |  * @returns The escaped string.
81 |  */
82 | function escapeRegex(str: string): string {
83 |   return str.replace(/[.*+?^${}()|[\]\\]/g, '\\$&'); // $& means the whole matched string
84 | }
85 | 
86 | async function calculateExactReplacement(
87 |   context: ReplacementContext,
88 | ): Promise<ReplacementResult | null> {
89 |   const { currentContent, params } = context;
90 |   const { old_string, new_string } = params;
91 | 
92 |   const normalizedCode = currentContent;
93 |   const normalizedSearch = old_string.replace(/\r\n/g, '\n');
94 |   const normalizedReplace = new_string.replace(/\r\n/g, '\n');
95 | 
96 |   const exactOccurrences = normalizedCode.split(normalizedSearch).length - 1;
97 |   if (exactOccurrences > 0) {
98 |     let modifiedCode = safeLiteralReplace(
99 |       normalizedCode,
100 |       normalizedSearch,
101 |       normalizedReplace,
102 |     );
103 |     modifiedCode = restoreTrailingNewline(currentContent, modifiedCode);
104 |     return {
105 |       newContent: modifiedCode,
106 |       occurrences: exactOccurrences,
107 |       finalOldString: normalizedSearch,
108 |       finalNewString: normalizedReplace,
109 |     };
110 |   }
111 | 
112 |   return null;
113 | }
114 | 
115 | async function calculateFlexibleReplacement(
116 |   context: ReplacementContext,
117 | ): Promise<ReplacementResult | null> {
118 |   const { currentContent, params } = context;
119 |   const { old_string, new_string } = params;
120 | 
121 |   const normalizedCode = currentContent;
122 |   const normalizedSearch = old_string.replace(/\r\n/g, '\n');
123 |   const normalizedReplace = new_string.replace(/\r\n/g, '\n');
124 | 
125 |   const sourceLines = normalizedCode.match(/.*(?:\n|$)/g)?.slice(0, -1) ?? [];
126 |   const searchLinesStripped = normalizedSearch
127 |     .split('\n')
128 |     .map((line: string) => line.trim());
129 |   const replaceLines = normalizedReplace.split('\n');
130 | 
131 |   let flexibleOccurrences = 0;
132 |   let i = 0;
133 |   while (i <= sourceLines.length - searchLinesStripped.length) {
134 |     const window = sourceLines.slice(i, i + searchLinesStripped.length);
135 |     const windowStripped = window.map((line: string) => line.trim());
136 |     const isMatch = windowStripped.every(
137 |       (line: string, index: number) => line === searchLinesStripped[index],
138 |     );
139 | 
140 |     if (isMatch) {
141 |       flexibleOccurrences++;
142 |       const firstLineInMatch = window[0];
143 |       const indentationMatch = firstLineInMatch.match(/^(\s*)/);
144 |       const indentation = indentationMatch ? indentationMatch[1] : '';
145 |       const newBlockWithIndent = replaceLines.map(
146 |         (line: string) => `${indentation}${line}`,
147 |       );
148 |       sourceLines.splice(
149 |         i,
150 |         searchLinesStripped.length,
151 |         newBlockWithIndent.join('\n'),
152 |       );
153 |       i += replaceLines.length;
154 |     } else {
155 |       i++;
156 |     }
157 |   }
158 | 
159 |   if (flexibleOccurrences > 0) {
160 |     let modifiedCode = sourceLines.join('');
161 |     modifiedCode = restoreTrailingNewline(currentContent, modifiedCode);
162 |     return {
163 |       newContent: modifiedCode,
164 |       occurrences: flexibleOccurrences,
165 |       finalOldString: normalizedSearch,
166 |       finalNewString: normalizedReplace,
167 |     };
168 |   }
169 | 
170 |   return null;
171 | }
172 | 
173 | async function calculateRegexReplacement(
174 |   context: ReplacementContext,
175 | ): Promise<ReplacementResult | null> {
176 |   const { currentContent, params } = context;
177 |   const { old_string, new_string } = params;
178 | 
179 |   // Normalize line endings for consistent processing.
180 |   const normalizedSearch = old_string.replace(/\r\n/g, '\n');
181 |   const normalizedReplace = new_string.replace(/\r\n/g, '\n');
182 | 
183 |   // This logic is ported from your Python implementation.
184 |   // It builds a flexible, multi-line regex from a search string.
185 |   const delimiters = ['(', ')', ':', '[', ']', '{', '}', '>', '<', '='];
186 | 
187 |   let processedString = normalizedSearch;
188 |   for (const delim of delimiters) {
189 |     processedString = processedString.split(delim).join(` ${delim} `);
190 |   }
191 | 
192 |   // Split by any whitespace and remove empty strings.
193 |   const tokens = processedString.split(/\s+/).filter(Boolean);
194 | 
195 |   if (tokens.length === 0) {
196 |     return null;
197 |   }
198 | 
199 |   const escapedTokens = tokens.map(escapeRegex);
200 |   // Join tokens with `\s*` to allow for flexible whitespace between them.
201 |   const pattern = escapedTokens.join('\\s*');
202 | 
203 |   // The final pattern captures leading whitespace (indentation) and then matches the token pattern.
204 |   // 'm' flag enables multi-line mode, so '^' matches the start of any line.
205 |   const finalPattern = `^(\\s*)${pattern}`;
206 |   const flexibleRegex = new RegExp(finalPattern, 'm');
207 | 
208 |   const match = flexibleRegex.exec(currentContent);
209 | 
210 |   if (!match) {
211 |     return null;
212 |   }
213 | 
214 |   const indentation = match[1] || '';
215 |   const newLines = normalizedReplace.split('\n');
216 |   const newBlockWithIndent = newLines
217 |     .map((line) => `${indentation}${line}`)
218 |     .join('\n');
219 | 
220 |   // Use replace with the regex to substitute the matched content.
221 |   // Since the regex doesn't have the 'g' flag, it will only replace the first occurrence.
222 |   const modifiedCode = currentContent.replace(
223 |     flexibleRegex,
224 |     newBlockWithIndent,
225 |   );
226 | 
227 |   return {
228 |     newContent: restoreTrailingNewline(currentContent, modifiedCode),
229 |     occurrences: 1, // This method is designed to find and replace only the first occurrence.
230 |     finalOldString: normalizedSearch,
231 |     finalNewString: normalizedReplace,
232 |   };
233 | }
234 | 
235 | /**
236 |  * Detects the line ending style of a string.
237 |  * @param content The string content to analyze.
238 |  * @returns '\r\n' for Windows-style, '\n' for Unix-style.
239 |  */
240 | function detectLineEnding(content: string): '\r\n' | '\n' {
241 |   // If a Carriage Return is found, assume Windows-style endings.
242 |   // This is a simple but effective heuristic.
243 |   return content.includes('\r\n') ? '\r\n' : '\n';
244 | }
245 | 
246 | export async function calculateReplacement(
247 |   config: Config,
248 |   context: ReplacementContext,
249 | ): Promise<ReplacementResult> {
250 |   const { currentContent, params } = context;
251 |   const { old_string, new_string } = params;
252 |   const normalizedSearch = old_string.replace(/\r\n/g, '\n');
253 |   const normalizedReplace = new_string.replace(/\r\n/g, '\n');
254 | 
255 |   if (normalizedSearch === '') {
256 |     return {
257 |       newContent: currentContent,
258 |       occurrences: 0,
259 |       finalOldString: normalizedSearch,
260 |       finalNewString: normalizedReplace,
261 |     };
262 |   }
263 | 
264 |   const exactResult = await calculateExactReplacement(context);
265 |   if (exactResult) {
266 |     const event = new SmartEditStrategyEvent('exact');
267 |     logSmartEditStrategy(config, event);
268 |     return exactResult;
269 |   }
270 | 
271 |   const flexibleResult = await calculateFlexibleReplacement(context);
272 |   if (flexibleResult) {
273 |     const event = new SmartEditStrategyEvent('flexible');
274 |     logSmartEditStrategy(config, event);
275 |     return flexibleResult;
276 |   }
277 | 
278 |   const regexResult = await calculateRegexReplacement(context);
279 |   if (regexResult) {
280 |     const event = new SmartEditStrategyEvent('regex');
281 |     logSmartEditStrategy(config, event);
282 |     return regexResult;
283 |   }
284 | 
285 |   return {
286 |     newContent: currentContent,
287 |     occurrences: 0,
288 |     finalOldString: normalizedSearch,
289 |     finalNewString: normalizedReplace,
290 |   };
291 | }
292 | 
293 | export function getErrorReplaceResult(
294 |   params: EditToolParams,
295 |   occurrences: number,
296 |   expectedReplacements: number,
297 |   finalOldString: string,
298 |   finalNewString: string,
299 | ) {
300 |   let error: { display: string; raw: string; type: ToolErrorType } | undefined =
301 |     undefined;
302 |   if (occurrences === 0) {
303 |     error = {
304 |       display: `Failed to edit, could not find the string to replace.`,
305 |       raw: `Failed to edit, 0 occurrences found for old_string (${finalOldString}). Original old_string was (${params.old_string}) in ${params.file_path}. No edits made. The exact text in old_string was not found. Ensure you're not escaping content incorrectly and check whitespace, indentation, and context. Use ${ReadFileTool.Name} tool to verify.`,
306 |       type: ToolErrorType.EDIT_NO_OCCURRENCE_FOUND,
307 |     };
308 |   } else if (occurrences !== expectedReplacements) {
309 |     const occurrenceTerm =
310 |       expectedReplacements === 1 ? 'occurrence' : 'occurrences';
311 | 
312 |     error = {
313 |       display: `Failed to edit, expected ${expectedReplacements} ${occurrenceTerm} but found ${occurrences}.`,
314 |       raw: `Failed to edit, Expected ${expectedReplacements} ${occurrenceTerm} but found ${occurrences} for old_string in file: ${params.file_path}`,
315 |       type: ToolErrorType.EDIT_EXPECTED_OCCURRENCE_MISMATCH,
316 |     };
317 |   } else if (finalOldString === finalNewString) {
318 |     error = {
319 |       display: `No changes to apply. The old_string and new_string are identical.`,
320 |       raw: `No changes to apply. The old_string and new_string are identical in file: ${params.file_path}`,
321 |       type: ToolErrorType.EDIT_NO_CHANGE,
322 |     };
323 |   }
324 |   return error;
325 | }
326 | 
327 | /**
328 |  * Parameters for the Edit tool
329 |  */
330 | export interface EditToolParams {
331 |   /**
332 |    * The absolute path to the file to modify
333 |    */
334 |   file_path: string;
335 | 
336 |   /**
337 |    * The text to replace
338 |    */
339 |   old_string: string;
340 | 
341 |   /**
342 |    * The text to replace it with
343 |    */
344 |   new_string: string;
345 | 
346 |   /**
347 |    * The instruction for what needs to be done.
348 |    */
349 |   instruction: string;
350 | 
351 |   /**
352 |    * Whether the edit was modified manually by the user.
353 |    */
354 |   modified_by_user?: boolean;
355 | 
356 |   /**
357 |    * Initially proposed string.
358 |    */
359 |   ai_proposed_string?: string;
360 | }
361 | 
362 | interface CalculatedEdit {
363 |   currentContent: string | null;
364 |   newContent: string;
365 |   occurrences: number;
366 |   error?: { display: string; raw: string; type: ToolErrorType };
367 |   isNewFile: boolean;
368 |   originalLineEnding: '\r\n' | '\n';
369 | }
370 | 
371 | class EditToolInvocation implements ToolInvocation<EditToolParams, ToolResult> {
372 |   constructor(
373 |     private readonly config: Config,
374 |     public params: EditToolParams,
375 |   ) {}
376 | 
377 |   toolLocations(): ToolLocation[] {
378 |     return [{ path: this.params.file_path }];
379 |   }
380 | 
381 |   private async attemptSelfCorrection(
382 |     params: EditToolParams,
383 |     currentContent: string,
384 |     initialError: { display: string; raw: string; type: ToolErrorType },
385 |     abortSignal: AbortSignal,
386 |     originalLineEnding: '\r\n' | '\n',
387 |   ): Promise<CalculatedEdit> {
388 |     // In order to keep from clobbering edits made outside our system,
389 |     // check if the file has been modified since we first read it.
390 |     let errorForLlmEditFixer = initialError.raw;
391 |     let contentForLlmEditFixer = currentContent;
392 | 
393 |     const initialContentHash = hashContent(currentContent);
394 |     const onDiskContent = await this.config
395 |       .getFileSystemService()
396 |       .readTextFile(params.file_path);
397 |     const onDiskContentHash = hashContent(onDiskContent.replace(/\r\n/g, '\n'));
398 | 
399 |     if (initialContentHash !== onDiskContentHash) {
400 |       // The file has changed on disk since we first read it.
401 |       // Use the latest content for the correction attempt.
402 |       contentForLlmEditFixer = onDiskContent.replace(/\r\n/g, '\n');
403 |       errorForLlmEditFixer = `The initial edit attempt failed with the following error: "${initialError.raw}". However, the file has been modified by either the user or an external process since that edit attempt. The file content provided to you is the latest version. Please base your correction on this new content.`;
404 |     }
405 | 
406 |     const fixedEdit = await FixLLMEditWithInstruction(
407 |       params.instruction,
408 |       params.old_string,
409 |       params.new_string,
410 |       errorForLlmEditFixer,
411 |       contentForLlmEditFixer,
412 |       this.config.getBaseLlmClient(),
413 |       abortSignal,
414 |     );
415 | 
416 |     if (fixedEdit.noChangesRequired) {
417 |       return {
418 |         currentContent,
419 |         newContent: currentContent,
420 |         occurrences: 0,
421 |         isNewFile: false,
422 |         error: {
423 |           display: `No changes required. The file already meets the specified conditions.`,
424 |           raw: `A secondary check by an LLM determined that no changes were necessary to fulfill the instruction. Explanation: ${fixedEdit.explanation}. Original error with the parameters given: ${initialError.raw}`,
425 |           type: ToolErrorType.EDIT_NO_CHANGE_LLM_JUDGEMENT,
426 |         },
427 |         originalLineEnding,
428 |       };
429 |     }
430 | 
431 |     const secondAttemptResult = await calculateReplacement(this.config, {
432 |       params: {
433 |         ...params,
434 |         old_string: fixedEdit.search,
435 |         new_string: fixedEdit.replace,
436 |       },
437 |       currentContent: contentForLlmEditFixer,
438 |       abortSignal,
439 |     });
440 | 
441 |     const secondError = getErrorReplaceResult(
442 |       params,
443 |       secondAttemptResult.occurrences,
444 |       1, // expectedReplacements is always 1 for smart_edit
445 |       secondAttemptResult.finalOldString,
446 |       secondAttemptResult.finalNewString,
447 |     );
448 | 
449 |     if (secondError) {
450 |       // The fix failed, log failure and return the original error
451 |       const event = new SmartEditCorrectionEvent('failure');
452 |       logSmartEditCorrectionEvent(this.config, event);
453 | 
454 |       return {
455 |         currentContent: contentForLlmEditFixer,
456 |         newContent: currentContent,
457 |         occurrences: 0,
458 |         isNewFile: false,
459 |         error: initialError,
460 |         originalLineEnding,
461 |       };
462 |     }
463 | 
464 |     const event = new SmartEditCorrectionEvent('success');
465 |     logSmartEditCorrectionEvent(this.config, event);
466 | 
467 |     return {
468 |       currentContent: contentForLlmEditFixer,
469 |       newContent: secondAttemptResult.newContent,
470 |       occurrences: secondAttemptResult.occurrences,
471 |       isNewFile: false,
472 |       error: undefined,
473 |       originalLineEnding,
474 |     };
475 |   }
476 | 
477 |   /**
478 |    * Calculates the potential outcome of an edit operation.
479 |    * @param params Parameters for the edit operation
480 |    * @returns An object describing the potential edit outcome
481 |    * @throws File system errors if reading the file fails unexpectedly (e.g., permissions)
482 |    */
483 |   private async calculateEdit(
484 |     params: EditToolParams,
485 |     abortSignal: AbortSignal,
486 |   ): Promise<CalculatedEdit> {
487 |     const expectedReplacements = 1;
488 |     let currentContent: string | null = null;
489 |     let fileExists = false;
490 |     let originalLineEnding: '\r\n' | '\n' = '\n'; // Default for new files
491 | 
492 |     try {
493 |       currentContent = await this.config
494 |         .getFileSystemService()
495 |         .readTextFile(params.file_path);
496 |       originalLineEnding = detectLineEnding(currentContent);
497 |       currentContent = currentContent.replace(/\r\n/g, '\n');
498 |       fileExists = true;
499 |     } catch (err: unknown) {
500 |       if (!isNodeError(err) || err.code !== 'ENOENT') {
501 |         throw err;
502 |       }
503 |       fileExists = false;
504 |     }
505 | 
506 |     const isNewFile = params.old_string === '' && !fileExists;
507 | 
508 |     if (isNewFile) {
509 |       return {
510 |         currentContent,
511 |         newContent: params.new_string,
512 |         occurrences: 1,
513 |         isNewFile: true,
514 |         error: undefined,
515 |         originalLineEnding,
516 |       };
517 |     }
518 | 
519 |     // after this point, it's not a new file/edit
520 |     if (!fileExists) {
521 |       return {
522 |         currentContent,
523 |         newContent: '',
524 |         occurrences: 0,
525 |         isNewFile: false,
526 |         error: {
527 |           display: `File not found. Cannot apply edit. Use an empty old_string to create a new file.`,
528 |           raw: `File not found: ${params.file_path}`,
529 |           type: ToolErrorType.FILE_NOT_FOUND,
530 |         },
531 |         originalLineEnding,
532 |       };
533 |     }
534 | 
535 |     if (currentContent === null) {
536 |       return {
537 |         currentContent,
538 |         newContent: '',
539 |         occurrences: 0,
540 |         isNewFile: false,
541 |         error: {
542 |           display: `Failed to read content of file.`,
543 |           raw: `Failed to read content of existing file: ${params.file_path}`,
544 |           type: ToolErrorType.READ_CONTENT_FAILURE,
545 |         },
546 |         originalLineEnding,
547 |       };
548 |     }
549 | 
550 |     if (params.old_string === '') {
551 |       return {
552 |         currentContent,
553 |         newContent: currentContent,
554 |         occurrences: 0,
555 |         isNewFile: false,
556 |         error: {
557 |           display: `Failed to edit. Attempted to create a file that already exists.`,
558 |           raw: `File already exists, cannot create: ${params.file_path}`,
559 |           type: ToolErrorType.ATTEMPT_TO_CREATE_EXISTING_FILE,
560 |         },
561 |         originalLineEnding,
562 |       };
563 |     }
564 | 
565 |     const replacementResult = await calculateReplacement(this.config, {
566 |       params,
567 |       currentContent,
568 |       abortSignal,
569 |     });
570 | 
571 |     const initialError = getErrorReplaceResult(
572 |       params,
573 |       replacementResult.occurrences,
574 |       expectedReplacements,
575 |       replacementResult.finalOldString,
576 |       replacementResult.finalNewString,
577 |     );
578 | 
579 |     if (!initialError) {
580 |       return {
581 |         currentContent,
582 |         newContent: replacementResult.newContent,
583 |         occurrences: replacementResult.occurrences,
584 |         isNewFile: false,
585 |         error: undefined,
586 |         originalLineEnding,
587 |       };
588 |     }
589 | 
590 |     // If there was an error, try to self-correct.
591 |     return this.attemptSelfCorrection(
592 |       params,
593 |       currentContent,
594 |       initialError,
595 |       abortSignal,
596 |       originalLineEnding,
597 |     );
598 |   }
599 | 
600 |   /**
601 |    * Handles the confirmation prompt for the Edit tool in the CLI.
602 |    * It needs to calculate the diff to show the user.
603 |    */
604 |   async shouldConfirmExecute(
[TRUNCATED]
```

src/tools/tool-error.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * A type-safe enum for tool-related errors.
9 |  *
10 |  * Error types are categorized as:
11 |  * - Recoverable: LLM can self-correct (e.g., invalid params, file not found)
12 |  * - Fatal: System-level issues that prevent continued execution (e.g., disk full, critical I/O errors)
13 |  */
14 | export enum ToolErrorType {
15 |   // General Errors
16 |   INVALID_TOOL_PARAMS = 'invalid_tool_params',
17 |   UNKNOWN = 'unknown',
18 |   UNHANDLED_EXCEPTION = 'unhandled_exception',
19 |   TOOL_NOT_REGISTERED = 'tool_not_registered',
20 |   EXECUTION_FAILED = 'execution_failed',
21 | 
22 |   // File System Errors
23 |   FILE_NOT_FOUND = 'file_not_found',
24 |   FILE_WRITE_FAILURE = 'file_write_failure',
25 |   READ_CONTENT_FAILURE = 'read_content_failure',
26 |   ATTEMPT_TO_CREATE_EXISTING_FILE = 'attempt_to_create_existing_file',
27 |   FILE_TOO_LARGE = 'file_too_large',
28 |   PERMISSION_DENIED = 'permission_denied',
29 |   NO_SPACE_LEFT = 'no_space_left',
30 |   TARGET_IS_DIRECTORY = 'target_is_directory',
31 |   PATH_NOT_IN_WORKSPACE = 'path_not_in_workspace',
32 |   SEARCH_PATH_NOT_FOUND = 'search_path_not_found',
33 |   SEARCH_PATH_NOT_A_DIRECTORY = 'search_path_not_a_directory',
34 | 
35 |   // Edit-specific Errors
36 |   EDIT_PREPARATION_FAILURE = 'edit_preparation_failure',
37 |   EDIT_NO_OCCURRENCE_FOUND = 'edit_no_occurrence_found',
38 |   EDIT_EXPECTED_OCCURRENCE_MISMATCH = 'edit_expected_occurrence_mismatch',
39 |   EDIT_NO_CHANGE = 'edit_no_change',
40 |   EDIT_NO_CHANGE_LLM_JUDGEMENT = 'edit_no_change_llm_judgement',
41 | 
42 |   // Glob-specific Errors
43 |   GLOB_EXECUTION_ERROR = 'glob_execution_error',
44 | 
45 |   // Grep-specific Errors
46 |   GREP_EXECUTION_ERROR = 'grep_execution_error',
47 | 
48 |   // Ls-specific Errors
49 |   LS_EXECUTION_ERROR = 'ls_execution_error',
50 |   PATH_IS_NOT_A_DIRECTORY = 'path_is_not_a_directory',
51 | 
52 |   // MCP-specific Errors
53 |   MCP_TOOL_ERROR = 'mcp_tool_error',
54 | 
55 |   // Memory-specific Errors
56 |   MEMORY_TOOL_EXECUTION_ERROR = 'memory_tool_execution_error',
57 | 
58 |   // ReadManyFiles-specific Errors
59 |   READ_MANY_FILES_SEARCH_ERROR = 'read_many_files_search_error',
60 | 
61 |   // Shell errors
62 |   SHELL_EXECUTE_ERROR = 'shell_execute_error',
63 | 
64 |   // DiscoveredTool-specific Errors
65 |   DISCOVERED_TOOL_EXECUTION_ERROR = 'discovered_tool_execution_error',
66 | 
67 |   // WebFetch-specific Errors
68 |   WEB_FETCH_NO_URL_IN_PROMPT = 'web_fetch_no_url_in_prompt',
69 |   WEB_FETCH_FALLBACK_FAILED = 'web_fetch_fallback_failed',
70 |   WEB_FETCH_PROCESSING_ERROR = 'web_fetch_processing_error',
71 | 
72 |   // WebSearch-specific Errors
73 |   WEB_SEARCH_FAILED = 'web_search_failed',
74 | }
75 | 
76 | /**
77 |  * Determines if a tool error type should be treated as fatal.
78 |  *
79 |  * Fatal errors are system-level issues that indicate the environment is in a bad state
80 |  * and continued execution is unlikely to succeed. These include:
81 |  * - Disk space issues (NO_SPACE_LEFT)
82 |  *
83 |  * Non-fatal errors are issues the LLM can potentially recover from by:
84 |  * - Correcting invalid parameters (INVALID_TOOL_PARAMS)
85 |  * - Trying different files (FILE_NOT_FOUND)
86 |  * - Respecting security boundaries (PATH_NOT_IN_WORKSPACE, PERMISSION_DENIED)
87 |  * - Using different tools or approaches
88 |  *
89 |  * @param errorType - The tool error type to check
90 |  * @returns true if the error should cause the CLI to exit, false if it's recoverable
91 |  */
92 | export function isFatalToolError(errorType?: string): boolean {
93 |   if (!errorType) {
94 |     return false;
95 |   }
96 | 
97 |   const fatalErrors = new Set<string>([ToolErrorType.NO_SPACE_LEFT]);
98 | 
99 |   return fatalErrors.has(errorType);
100 | }
```

src/tools/tool-names.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | // Centralized constants for tool names.
8 | // This prevents circular dependencies that can occur when other modules (like agents)
9 | // need to reference a tool's name without importing the tool's implementation.
10 | 
11 | export const GLOB_TOOL_NAME = 'glob';
12 | export const WRITE_TODOS_TOOL_NAME = 'write_todos';
13 | export const WRITE_FILE_TOOL_NAME = 'write_file';
14 | export const WEB_SEARCH_TOOL_NAME = 'google_web_search';
15 | 
16 | // TODO: Migrate other tool names here to follow this pattern and prevent future circular dependencies.
17 | // Candidates for migration:
18 | // - LSTool ('list_directory')
19 | // - ReadFileTool ('read_file')
20 | // - GrepTool ('search_file_content')
```

src/tools/tool-registry.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /* eslint-disable @typescript-eslint/no-explicit-any */
8 | import type { Mocked } from 'vitest';
9 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
10 | import type { ConfigParameters } from '../config/config.js';
11 | import { Config, ApprovalMode } from '../config/config.js';
12 | import { ToolRegistry, DiscoveredTool } from './tool-registry.js';
13 | import { DiscoveredMCPTool } from './mcp-tool.js';
14 | import type { FunctionDeclaration, CallableTool } from '@google/genai';
15 | import { mcpToTool } from '@google/genai';
16 | import { spawn } from 'node:child_process';
17 | 
18 | import fs from 'node:fs';
19 | import { MockTool } from '../test-utils/mock-tool.js';
20 | 
21 | import { McpClientManager } from './mcp-client-manager.js';
22 | import { ToolErrorType } from './tool-error.js';
23 | 
24 | vi.mock('node:fs');
25 | 
26 | // Mock ./mcp-client.js to control its behavior within tool-registry tests
27 | vi.mock('./mcp-client.js', async () => {
28 |   const originalModule = await vi.importActual('./mcp-client.js');
29 |   return {
30 |     ...originalModule,
31 |   };
32 | });
33 | 
34 | // Mock node:child_process
35 | vi.mock('node:child_process', async () => {
36 |   const actual = await vi.importActual('node:child_process');
37 |   return {
38 |     ...actual,
39 |     execSync: vi.fn(),
40 |     spawn: vi.fn(),
41 |   };
42 | });
43 | 
44 | // Mock MCP SDK Client and Transports
45 | const mockMcpClientConnect = vi.fn();
46 | const mockMcpClientOnError = vi.fn();
47 | const mockStdioTransportClose = vi.fn();
48 | const mockSseTransportClose = vi.fn();
49 | 
50 | vi.mock('@modelcontextprotocol/sdk/client/index.js', () => {
51 |   const MockClient = vi.fn().mockImplementation(() => ({
52 |     connect: mockMcpClientConnect,
53 |     set onerror(handler: any) {
54 |       mockMcpClientOnError(handler);
55 |     },
56 |   }));
57 |   return { Client: MockClient };
58 | });
59 | 
60 | vi.mock('@modelcontextprotocol/sdk/client/stdio.js', () => {
61 |   const MockStdioClientTransport = vi.fn().mockImplementation(() => ({
62 |     stderr: {
63 |       on: vi.fn(),
64 |     },
65 |     close: mockStdioTransportClose,
66 |   }));
67 |   return { StdioClientTransport: MockStdioClientTransport };
68 | });
69 | 
70 | vi.mock('@modelcontextprotocol/sdk/client/sse.js', () => {
71 |   const MockSSEClientTransport = vi.fn().mockImplementation(() => ({
72 |     close: mockSseTransportClose,
73 |   }));
74 |   return { SSEClientTransport: MockSSEClientTransport };
75 | });
76 | 
77 | // Mock @google/genai mcpToTool
78 | vi.mock('@google/genai', async () => {
79 |   const actualGenai =
80 |     await vi.importActual<typeof import('@google/genai')>('@google/genai');
81 |   return {
82 |     ...actualGenai,
83 |     mcpToTool: vi.fn().mockImplementation(() => ({
84 |       tool: vi.fn().mockResolvedValue({ functionDeclarations: [] }),
85 |       callTool: vi.fn(),
86 |     })),
87 |   };
88 | });
89 | 
90 | // Helper to create a mock CallableTool for specific test needs
91 | const createMockCallableTool = (
92 |   toolDeclarations: FunctionDeclaration[],
93 | ): Mocked<CallableTool> => ({
94 |   tool: vi.fn().mockResolvedValue({ functionDeclarations: toolDeclarations }),
95 |   callTool: vi.fn(),
96 | });
97 | 
98 | const baseConfigParams: ConfigParameters = {
99 |   cwd: '/tmp',
100 |   model: 'test-model',
101 |   embeddingModel: 'test-embedding-model',
102 |   sandbox: undefined,
103 |   targetDir: '/test/dir',
104 |   debugMode: false,
105 |   userMemory: '',
106 |   geminiMdFileCount: 0,
107 |   approvalMode: ApprovalMode.DEFAULT,
108 |   sessionId: 'test-session-id',
109 | };
110 | 
111 | describe('ToolRegistry', () => {
112 |   let config: Config;
113 |   let toolRegistry: ToolRegistry;
114 |   let mockConfigGetToolDiscoveryCommand: ReturnType<typeof vi.spyOn>;
115 | 
116 |   beforeEach(() => {
117 |     vi.mocked(fs.existsSync).mockReturnValue(true);
118 |     vi.mocked(fs.statSync).mockReturnValue({
119 |       isDirectory: () => true,
120 |     } as fs.Stats);
121 |     config = new Config(baseConfigParams);
122 |     toolRegistry = new ToolRegistry(config);
123 |     vi.spyOn(console, 'warn').mockImplementation(() => {});
124 |     vi.spyOn(console, 'error').mockImplementation(() => {});
125 |     vi.spyOn(console, 'debug').mockImplementation(() => {});
126 |     vi.spyOn(console, 'log').mockImplementation(() => {});
127 | 
128 |     mockMcpClientConnect.mockReset().mockResolvedValue(undefined);
129 |     mockStdioTransportClose.mockReset();
130 |     mockSseTransportClose.mockReset();
131 |     vi.mocked(mcpToTool).mockClear();
132 |     vi.mocked(mcpToTool).mockReturnValue(createMockCallableTool([]));
133 | 
134 |     mockConfigGetToolDiscoveryCommand = vi.spyOn(
135 |       config,
136 |       'getToolDiscoveryCommand',
137 |     );
138 |     vi.spyOn(config, 'getMcpServers');
139 |     vi.spyOn(config, 'getMcpServerCommand');
140 |     vi.spyOn(config, 'getPromptRegistry').mockReturnValue({
141 |       clear: vi.fn(),
142 |       removePromptsByServer: vi.fn(),
143 |     } as any);
144 |   });
145 | 
146 |   afterEach(() => {
147 |     vi.restoreAllMocks();
148 |   });
149 | 
150 |   describe('registerTool', () => {
151 |     it('should register a new tool', () => {
152 |       const tool = new MockTool({ name: 'mock-tool' });
153 |       toolRegistry.registerTool(tool);
154 |       expect(toolRegistry.getTool('mock-tool')).toBe(tool);
155 |     });
156 |   });
157 | 
158 |   describe('getAllTools', () => {
159 |     it('should return all registered tools sorted alphabetically by displayName', () => {
160 |       // Register tools with displayNames in non-alphabetical order
161 |       const toolC = new MockTool({ name: 'c-tool', displayName: 'Tool C' });
162 |       const toolA = new MockTool({ name: 'a-tool', displayName: 'Tool A' });
163 |       const toolB = new MockTool({ name: 'b-tool', displayName: 'Tool B' });
164 | 
165 |       toolRegistry.registerTool(toolC);
166 |       toolRegistry.registerTool(toolA);
167 |       toolRegistry.registerTool(toolB);
168 | 
169 |       const allTools = toolRegistry.getAllTools();
170 |       const displayNames = allTools.map((t) => t.displayName);
171 | 
172 |       // Assert that the returned array is sorted by displayName
173 |       expect(displayNames).toEqual(['Tool A', 'Tool B', 'Tool C']);
174 |     });
175 |   });
176 | 
177 |   describe('getAllToolNames', () => {
178 |     it('should return all registered tool names', () => {
179 |       // Register tools with displayNames in non-alphabetical order
180 |       const toolC = new MockTool({ name: 'c-tool', displayName: 'Tool C' });
181 |       const toolA = new MockTool({ name: 'a-tool', displayName: 'Tool A' });
182 |       const toolB = new MockTool({ name: 'b-tool', displayName: 'Tool B' });
183 | 
184 |       toolRegistry.registerTool(toolC);
185 |       toolRegistry.registerTool(toolA);
186 |       toolRegistry.registerTool(toolB);
187 | 
188 |       const toolNames = toolRegistry.getAllToolNames();
189 | 
190 |       // Assert that the returned array contains all tool names
191 |       expect(toolNames).toEqual(['c-tool', 'a-tool', 'b-tool']);
192 |     });
193 |   });
194 | 
195 |   describe('getToolsByServer', () => {
196 |     it('should return an empty array if no tools match the server name', () => {
197 |       toolRegistry.registerTool(new MockTool({ name: 'mock-tool' }));
198 |       expect(toolRegistry.getToolsByServer('any-mcp-server')).toEqual([]);
199 |     });
200 | 
201 |     it('should return only tools matching the server name, sorted by name', async () => {
202 |       const server1Name = 'mcp-server-uno';
203 |       const server2Name = 'mcp-server-dos';
204 |       const mockCallable = {} as CallableTool;
205 |       const mcpTool1_c = new DiscoveredMCPTool(
206 |         mockCallable,
207 |         server1Name,
208 |         'zebra-tool',
209 |         'd1',
210 |         {},
211 |       );
212 |       const mcpTool1_a = new DiscoveredMCPTool(
213 |         mockCallable,
214 |         server1Name,
215 |         'apple-tool',
216 |         'd2',
217 |         {},
218 |       );
219 |       const mcpTool1_b = new DiscoveredMCPTool(
220 |         mockCallable,
221 |         server1Name,
222 |         'banana-tool',
223 |         'd3',
224 |         {},
225 |       );
226 | 
227 |       const mcpTool2 = new DiscoveredMCPTool(
228 |         mockCallable,
229 |         server2Name,
230 |         'tool-on-server2',
231 |         'd4',
232 |         {},
233 |       );
234 |       const nonMcpTool = new MockTool({ name: 'regular-tool' });
235 | 
236 |       toolRegistry.registerTool(mcpTool1_c);
237 |       toolRegistry.registerTool(mcpTool1_a);
238 |       toolRegistry.registerTool(mcpTool1_b);
239 |       toolRegistry.registerTool(mcpTool2);
240 |       toolRegistry.registerTool(nonMcpTool);
241 | 
242 |       const toolsFromServer1 = toolRegistry.getToolsByServer(server1Name);
243 |       const toolNames = toolsFromServer1.map((t) => t.name);
244 | 
245 |       // Assert that the array has the correct tools and is sorted by name
246 |       expect(toolsFromServer1).toHaveLength(3);
247 |       expect(toolNames).toEqual(['apple-tool', 'banana-tool', 'zebra-tool']);
248 | 
249 |       // Assert that all returned tools are indeed from the correct server
250 |       for (const tool of toolsFromServer1) {
251 |         expect((tool as DiscoveredMCPTool).serverName).toBe(server1Name);
252 |       }
253 | 
254 |       // Assert that the other server's tools are returned correctly
255 |       const toolsFromServer2 = toolRegistry.getToolsByServer(server2Name);
256 |       expect(toolsFromServer2).toHaveLength(1);
257 |       expect(toolsFromServer2[0].name).toBe(mcpTool2.name);
258 |     });
259 |   });
260 | 
261 |   describe('discoverTools', () => {
262 |     it('should will preserve tool parametersJsonSchema during discovery from command', async () => {
263 |       const discoveryCommand = 'my-discovery-command';
264 |       mockConfigGetToolDiscoveryCommand.mockReturnValue(discoveryCommand);
265 | 
266 |       const unsanitizedToolDeclaration: FunctionDeclaration = {
267 |         name: 'tool-with-bad-format',
268 |         description: 'A tool with an invalid format property',
269 |         parametersJsonSchema: {
270 |           type: 'object',
271 |           properties: {
272 |             some_string: {
273 |               type: 'string',
274 |               format: 'uuid', // This is an unsupported format
275 |             },
276 |           },
277 |         },
278 |       };
279 | 
280 |       const mockSpawn = vi.mocked(spawn);
281 |       const mockChildProcess = {
282 |         stdout: { on: vi.fn() },
283 |         stderr: { on: vi.fn() },
284 |         on: vi.fn(),
285 |       };
286 |       mockSpawn.mockReturnValue(mockChildProcess as any);
287 | 
288 |       // Simulate stdout data
289 |       mockChildProcess.stdout.on.mockImplementation((event, callback) => {
290 |         if (event === 'data') {
291 |           callback(
292 |             Buffer.from(
293 |               JSON.stringify([
294 |                 { function_declarations: [unsanitizedToolDeclaration] },
295 |               ]),
296 |             ),
297 |           );
298 |         }
299 |         return mockChildProcess as any;
300 |       });
301 | 
302 |       // Simulate process close
303 |       mockChildProcess.on.mockImplementation((event, callback) => {
304 |         if (event === 'close') {
305 |           callback(0);
306 |         }
307 |         return mockChildProcess as any;
308 |       });
309 | 
310 |       await toolRegistry.discoverAllTools();
311 | 
312 |       const discoveredTool = toolRegistry.getTool('tool-with-bad-format');
313 |       expect(discoveredTool).toBeDefined();
314 | 
315 |       const registeredParams = (discoveredTool as DiscoveredTool).schema
316 |         .parametersJsonSchema;
317 |       expect(registeredParams).toStrictEqual({
318 |         type: 'object',
319 |         properties: {
320 |           some_string: {
321 |             type: 'string',
322 |             format: 'uuid',
323 |           },
324 |         },
325 |       });
326 |     });
327 | 
328 |     it('should return a DISCOVERED_TOOL_EXECUTION_ERROR on tool failure', async () => {
329 |       const discoveryCommand = 'my-discovery-command';
330 |       mockConfigGetToolDiscoveryCommand.mockReturnValue(discoveryCommand);
331 |       vi.spyOn(config, 'getToolCallCommand').mockReturnValue('my-call-command');
332 | 
333 |       const toolDeclaration: FunctionDeclaration = {
334 |         name: 'failing-tool',
335 |         description: 'A tool that fails',
336 |         parametersJsonSchema: {
337 |           type: 'object',
338 |           properties: {},
339 |         },
340 |       };
341 | 
342 |       const mockSpawn = vi.mocked(spawn);
343 |       // --- Discovery Mock ---
344 |       const discoveryProcess = {
345 |         stdout: { on: vi.fn(), removeListener: vi.fn() },
346 |         stderr: { on: vi.fn(), removeListener: vi.fn() },
347 |         on: vi.fn(),
348 |       };
349 |       mockSpawn.mockReturnValueOnce(discoveryProcess as any);
350 | 
351 |       discoveryProcess.stdout.on.mockImplementation((event, callback) => {
352 |         if (event === 'data') {
353 |           callback(
354 |             Buffer.from(
355 |               JSON.stringify([{ functionDeclarations: [toolDeclaration] }]),
356 |             ),
357 |           );
358 |         }
359 |       });
360 |       discoveryProcess.on.mockImplementation((event, callback) => {
361 |         if (event === 'close') {
362 |           callback(0);
363 |         }
364 |       });
365 | 
366 |       await toolRegistry.discoverAllTools();
367 |       const discoveredTool = toolRegistry.getTool('failing-tool');
368 |       expect(discoveredTool).toBeDefined();
369 | 
370 |       // --- Execution Mock ---
371 |       const executionProcess = {
372 |         stdout: { on: vi.fn(), removeListener: vi.fn() },
373 |         stderr: { on: vi.fn(), removeListener: vi.fn() },
374 |         stdin: { write: vi.fn(), end: vi.fn() },
375 |         on: vi.fn(),
376 |         connected: true,
377 |         disconnect: vi.fn(),
378 |         removeListener: vi.fn(),
379 |       };
380 |       mockSpawn.mockReturnValueOnce(executionProcess as any);
381 | 
382 |       executionProcess.stderr.on.mockImplementation((event, callback) => {
383 |         if (event === 'data') {
384 |           callback(Buffer.from('Something went wrong'));
385 |         }
386 |       });
387 |       executionProcess.on.mockImplementation((event, callback) => {
388 |         if (event === 'close') {
389 |           callback(1); // Non-zero exit code
390 |         }
391 |       });
392 | 
393 |       const invocation = (discoveredTool as DiscoveredTool).build({});
394 |       const result = await invocation.execute(new AbortController().signal);
395 | 
396 |       expect(result.error?.type).toBe(
397 |         ToolErrorType.DISCOVERED_TOOL_EXECUTION_ERROR,
398 |       );
399 |       expect(result.llmContent).toContain('Stderr: Something went wrong');
400 |       expect(result.llmContent).toContain('Exit Code: 1');
401 |     });
402 | 
403 |     it('should discover tools using MCP servers defined in getMcpServers', async () => {
404 |       const discoverSpy = vi.spyOn(
405 |         McpClientManager.prototype,
406 |         'discoverAllMcpTools',
407 |       );
408 |       mockConfigGetToolDiscoveryCommand.mockReturnValue(undefined);
409 |       vi.spyOn(config, 'getMcpServerCommand').mockReturnValue(undefined);
410 |       const mcpServerConfigVal = {
411 |         'my-mcp-server': {
412 |           command: 'mcp-server-cmd',
413 |           args: ['--port', '1234'],
414 |           trust: true,
415 |         },
416 |       };
417 |       vi.spyOn(config, 'getMcpServers').mockReturnValue(mcpServerConfigVal);
418 | 
419 |       await toolRegistry.discoverAllTools();
420 | 
421 |       expect(discoverSpy).toHaveBeenCalled();
422 |     });
423 |   });
424 | 
425 |   describe('DiscoveredToolInvocation', () => {
426 |     it('should return the stringified params from getDescription', () => {
427 |       const tool = new DiscoveredTool(config, 'test-tool', 'A test tool', {});
428 |       const params = { param: 'testValue' };
429 |       const invocation = tool.build(params);
430 |       const description = invocation.getDescription();
431 |       expect(description).toBe(JSON.stringify(params));
432 |     });
433 |   });
434 | });
```

src/tools/tool-registry.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { FunctionDeclaration } from '@google/genai';
8 | import type {
9 |   AnyDeclarativeTool,
10 |   ToolResult,
11 |   ToolInvocation,
12 | } from './tools.js';
13 | import { Kind, BaseDeclarativeTool, BaseToolInvocation } from './tools.js';
14 | import type { Config } from '../config/config.js';
15 | import { spawn } from 'node:child_process';
16 | import { StringDecoder } from 'node:string_decoder';
17 | import { connectAndDiscover } from './mcp-client.js';
18 | import { McpClientManager } from './mcp-client-manager.js';
19 | import { DiscoveredMCPTool } from './mcp-tool.js';
20 | import { parse } from 'shell-quote';
21 | import { ToolErrorType } from './tool-error.js';
22 | import { safeJsonStringify } from '../utils/safeJsonStringify.js';
23 | import type { EventEmitter } from 'node:events';
24 | 
25 | type ToolParams = Record<string, unknown>;
26 | 
27 | class DiscoveredToolInvocation extends BaseToolInvocation<
28 |   ToolParams,
29 |   ToolResult
30 | > {
31 |   constructor(
32 |     private readonly config: Config,
33 |     private readonly toolName: string,
34 |     params: ToolParams,
35 |   ) {
36 |     super(params);
37 |   }
38 | 
39 |   getDescription(): string {
40 |     return safeJsonStringify(this.params);
41 |   }
42 | 
43 |   async execute(
44 |     _signal: AbortSignal,
45 |     _updateOutput?: (output: string) => void,
46 |   ): Promise<ToolResult> {
47 |     const callCommand = this.config.getToolCallCommand()!;
48 |     const child = spawn(callCommand, [this.toolName]);
49 |     child.stdin.write(JSON.stringify(this.params));
50 |     child.stdin.end();
51 | 
52 |     let stdout = '';
53 |     let stderr = '';
54 |     let error: Error | null = null;
55 |     let code: number | null = null;
56 |     let signal: NodeJS.Signals | null = null;
57 | 
58 |     await new Promise<void>((resolve) => {
59 |       const onStdout = (data: Buffer) => {
60 |         stdout += data?.toString();
61 |       };
62 | 
63 |       const onStderr = (data: Buffer) => {
64 |         stderr += data?.toString();
65 |       };
66 | 
67 |       const onError = (err: Error) => {
68 |         error = err;
69 |       };
70 | 
71 |       const onClose = (
72 |         _code: number | null,
73 |         _signal: NodeJS.Signals | null,
74 |       ) => {
75 |         code = _code;
76 |         signal = _signal;
77 |         cleanup();
78 |         resolve();
79 |       };
80 | 
81 |       const cleanup = () => {
82 |         child.stdout.removeListener('data', onStdout);
83 |         child.stderr.removeListener('data', onStderr);
84 |         child.removeListener('error', onError);
85 |         child.removeListener('close', onClose);
86 |         if (child.connected) {
87 |           child.disconnect();
88 |         }
89 |       };
90 | 
91 |       child.stdout.on('data', onStdout);
92 |       child.stderr.on('data', onStderr);
93 |       child.on('error', onError);
94 |       child.on('close', onClose);
95 |     });
96 | 
97 |     // if there is any error, non-zero exit code, signal, or stderr, return error details instead of stdout
98 |     if (error || code !== 0 || signal || stderr) {
99 |       const llmContent = [
100 |         `Stdout: ${stdout || '(empty)'}`,
101 |         `Stderr: ${stderr || '(empty)'}`,
102 |         `Error: ${error ?? '(none)'}`,
103 |         `Exit Code: ${code ?? '(none)'}`,
104 |         `Signal: ${signal ?? '(none)'}`,
105 |       ].join('\n');
106 |       return {
107 |         llmContent,
108 |         returnDisplay: llmContent,
109 |         error: {
110 |           message: llmContent,
111 |           type: ToolErrorType.DISCOVERED_TOOL_EXECUTION_ERROR,
112 |         },
113 |       };
114 |     }
115 | 
116 |     return {
117 |       llmContent: stdout,
118 |       returnDisplay: stdout,
119 |     };
120 |   }
121 | }
122 | 
123 | export class DiscoveredTool extends BaseDeclarativeTool<
124 |   ToolParams,
125 |   ToolResult
126 | > {
127 |   constructor(
128 |     private readonly config: Config,
129 |     name: string,
130 |     override readonly description: string,
131 |     override readonly parameterSchema: Record<string, unknown>,
132 |   ) {
133 |     const discoveryCmd = config.getToolDiscoveryCommand()!;
134 |     const callCommand = config.getToolCallCommand()!;
135 |     description += `
136 | 
137 | This tool was discovered from the project by executing the command \`${discoveryCmd}\` on project root.
138 | When called, this tool will execute the command \`${callCommand} ${name}\` on project root.
139 | Tool discovery and call commands can be configured in project or user settings.
140 | 
141 | When called, the tool call command is executed as a subprocess.
142 | On success, tool output is returned as a json string.
143 | Otherwise, the following information is returned:
144 | 
145 | Stdout: Output on stdout stream. Can be \`(empty)\` or partial.
146 | Stderr: Output on stderr stream. Can be \`(empty)\` or partial.
147 | Error: Error or \`(none)\` if no error was reported for the subprocess.
148 | Exit Code: Exit code or \`(none)\` if terminated by signal.
149 | Signal: Signal number or \`(none)\` if no signal was received.
150 | `;
151 |     super(
152 |       name,
153 |       name,
154 |       description,
155 |       Kind.Other,
156 |       parameterSchema,
157 |       false, // isOutputMarkdown
158 |       false, // canUpdateOutput
159 |     );
160 |   }
161 | 
162 |   protected createInvocation(
163 |     params: ToolParams,
164 |   ): ToolInvocation<ToolParams, ToolResult> {
165 |     return new DiscoveredToolInvocation(this.config, this.name, params);
166 |   }
167 | }
168 | 
169 | export class ToolRegistry {
170 |   // The tools keyed by tool name as seen by the LLM.
171 |   private tools: Map<string, AnyDeclarativeTool> = new Map();
172 |   private config: Config;
173 |   private mcpClientManager: McpClientManager;
174 | 
175 |   constructor(config: Config, eventEmitter?: EventEmitter) {
176 |     this.config = config;
177 |     this.mcpClientManager = new McpClientManager(
178 |       this.config.getMcpServers() ?? {},
179 |       this.config.getMcpServerCommand(),
180 |       this,
181 |       this.config.getPromptRegistry(),
182 |       this.config.getDebugMode(),
183 |       this.config.getWorkspaceContext(),
184 |       eventEmitter,
185 |     );
186 |   }
187 | 
188 |   /**
189 |    * Registers a tool definition.
190 |    * @param tool - The tool object containing schema and execution logic.
191 |    */
192 |   registerTool(tool: AnyDeclarativeTool): void {
193 |     if (this.tools.has(tool.name)) {
194 |       if (tool instanceof DiscoveredMCPTool) {
195 |         tool = tool.asFullyQualifiedTool();
196 |       } else {
197 |         // Decide on behavior: throw error, log warning, or allow overwrite
198 |         console.warn(
199 |           `Tool with name "${tool.name}" is already registered. Overwriting.`,
200 |         );
201 |       }
202 |     }
203 |     this.tools.set(tool.name, tool);
204 |   }
205 | 
206 |   private removeDiscoveredTools(): void {
207 |     for (const tool of this.tools.values()) {
208 |       if (tool instanceof DiscoveredTool || tool instanceof DiscoveredMCPTool) {
209 |         this.tools.delete(tool.name);
210 |       }
211 |     }
212 |   }
213 | 
214 |   /**
215 |    * Removes all tools from a specific MCP server.
216 |    * @param serverName The name of the server to remove tools from.
217 |    */
218 |   removeMcpToolsByServer(serverName: string): void {
219 |     for (const [name, tool] of this.tools.entries()) {
220 |       if (tool instanceof DiscoveredMCPTool && tool.serverName === serverName) {
221 |         this.tools.delete(name);
222 |       }
223 |     }
224 |   }
225 | 
226 |   /**
227 |    * Discovers tools from project (if available and configured).
228 |    * Can be called multiple times to update discovered tools.
229 |    * This will discover tools from the command line and from MCP servers.
230 |    */
231 |   async discoverAllTools(): Promise<void> {
232 |     // remove any previously discovered tools
233 |     this.removeDiscoveredTools();
234 | 
235 |     this.config.getPromptRegistry().clear();
236 | 
237 |     await this.discoverAndRegisterToolsFromCommand();
238 | 
239 |     // discover tools using MCP servers, if configured
240 |     await this.mcpClientManager.discoverAllMcpTools(this.config);
241 |   }
242 | 
243 |   /**
244 |    * Discovers tools from project (if available and configured).
245 |    * Can be called multiple times to update discovered tools.
246 |    * This will NOT discover tools from the command line, only from MCP servers.
247 |    */
248 |   async discoverMcpTools(): Promise<void> {
249 |     // remove any previously discovered tools
250 |     this.removeDiscoveredTools();
251 | 
252 |     this.config.getPromptRegistry().clear();
253 | 
254 |     // discover tools using MCP servers, if configured
255 |     await this.mcpClientManager.discoverAllMcpTools(this.config);
256 |   }
257 | 
258 |   /**
259 |    * Restarts all MCP servers and re-discovers tools.
260 |    */
261 |   async restartMcpServers(): Promise<void> {
262 |     await this.discoverMcpTools();
263 |   }
264 | 
265 |   /**
266 |    * Discover or re-discover tools for a single MCP server.
267 |    * @param serverName - The name of the server to discover tools from.
268 |    */
269 |   async discoverToolsForServer(serverName: string): Promise<void> {
270 |     // Remove any previously discovered tools from this server
271 |     for (const [name, tool] of this.tools.entries()) {
272 |       if (tool instanceof DiscoveredMCPTool && tool.serverName === serverName) {
273 |         this.tools.delete(name);
274 |       }
275 |     }
276 | 
277 |     this.config.getPromptRegistry().removePromptsByServer(serverName);
278 | 
279 |     const mcpServers = this.config.getMcpServers() ?? {};
280 |     const serverConfig = mcpServers[serverName];
281 |     if (serverConfig) {
282 |       await connectAndDiscover(
283 |         serverName,
284 |         serverConfig,
285 |         this,
286 |         this.config.getPromptRegistry(),
287 |         this.config.getDebugMode(),
288 |         this.config.getWorkspaceContext(),
289 |         this.config,
290 |       );
291 |     }
292 |   }
293 | 
294 |   private async discoverAndRegisterToolsFromCommand(): Promise<void> {
295 |     const discoveryCmd = this.config.getToolDiscoveryCommand();
296 |     if (!discoveryCmd) {
297 |       return;
298 |     }
299 | 
300 |     try {
301 |       const cmdParts = parse(discoveryCmd);
302 |       if (cmdParts.length === 0) {
303 |         throw new Error(
304 |           'Tool discovery command is empty or contains only whitespace.',
305 |         );
306 |       }
307 |       const proc = spawn(cmdParts[0] as string, cmdParts.slice(1) as string[]);
308 |       let stdout = '';
309 |       const stdoutDecoder = new StringDecoder('utf8');
310 |       let stderr = '';
311 |       const stderrDecoder = new StringDecoder('utf8');
312 |       let sizeLimitExceeded = false;
313 |       const MAX_STDOUT_SIZE = 10 * 1024 * 1024; // 10MB limit
314 |       const MAX_STDERR_SIZE = 10 * 1024 * 1024; // 10MB limit
315 | 
316 |       let stdoutByteLength = 0;
317 |       let stderrByteLength = 0;
318 | 
319 |       proc.stdout.on('data', (data) => {
320 |         if (sizeLimitExceeded) return;
321 |         if (stdoutByteLength + data.length > MAX_STDOUT_SIZE) {
322 |           sizeLimitExceeded = true;
323 |           proc.kill();
324 |           return;
325 |         }
326 |         stdoutByteLength += data.length;
327 |         stdout += stdoutDecoder.write(data);
328 |       });
329 | 
330 |       proc.stderr.on('data', (data) => {
331 |         if (sizeLimitExceeded) return;
332 |         if (stderrByteLength + data.length > MAX_STDERR_SIZE) {
333 |           sizeLimitExceeded = true;
334 |           proc.kill();
335 |           return;
336 |         }
337 |         stderrByteLength += data.length;
338 |         stderr += stderrDecoder.write(data);
339 |       });
340 | 
341 |       await new Promise<void>((resolve, reject) => {
342 |         proc.on('error', reject);
343 |         proc.on('close', (code) => {
344 |           stdout += stdoutDecoder.end();
345 |           stderr += stderrDecoder.end();
346 | 
347 |           if (sizeLimitExceeded) {
348 |             return reject(
349 |               new Error(
350 |                 `Tool discovery command output exceeded size limit of ${MAX_STDOUT_SIZE} bytes.`,
351 |               ),
352 |             );
353 |           }
354 | 
355 |           if (code !== 0) {
356 |             console.error(`Command failed with code ${code}`);
357 |             console.error(stderr);
358 |             return reject(
359 |               new Error(`Tool discovery command failed with exit code ${code}`),
360 |             );
361 |           }
362 |           resolve();
363 |         });
364 |       });
365 | 
366 |       // execute discovery command and extract function declarations (w/ or w/o "tool" wrappers)
367 |       const functions: FunctionDeclaration[] = [];
368 |       const discoveredItems = JSON.parse(stdout.trim());
369 | 
370 |       if (!discoveredItems || !Array.isArray(discoveredItems)) {
371 |         throw new Error(
372 |           'Tool discovery command did not return a JSON array of tools.',
373 |         );
374 |       }
375 | 
376 |       for (const tool of discoveredItems) {
377 |         if (tool && typeof tool === 'object') {
378 |           if (Array.isArray(tool['function_declarations'])) {
379 |             functions.push(...tool['function_declarations']);
380 |           } else if (Array.isArray(tool['functionDeclarations'])) {
381 |             functions.push(...tool['functionDeclarations']);
382 |           } else if (tool['name']) {
383 |             functions.push(tool as FunctionDeclaration);
384 |           }
385 |         }
386 |       }
387 |       // register each function as a tool
388 |       for (const func of functions) {
389 |         if (!func.name) {
390 |           console.warn('Discovered a tool with no name. Skipping.');
391 |           continue;
392 |         }
393 |         const parameters =
394 |           func.parametersJsonSchema &&
395 |           typeof func.parametersJsonSchema === 'object' &&
396 |           !Array.isArray(func.parametersJsonSchema)
397 |             ? func.parametersJsonSchema
398 |             : {};
399 |         this.registerTool(
400 |           new DiscoveredTool(
401 |             this.config,
402 |             func.name,
403 |             func.description ?? '',
404 |             parameters as Record<string, unknown>,
405 |           ),
406 |         );
407 |       }
408 |     } catch (e) {
409 |       console.error(`Tool discovery command "${discoveryCmd}" failed:`, e);
410 |       throw e;
411 |     }
412 |   }
413 | 
414 |   /**
415 |    * Retrieves the list of tool schemas (FunctionDeclaration array).
416 |    * Extracts the declarations from the ToolListUnion structure.
417 |    * Includes discovered (vs registered) tools if configured.
418 |    * @returns An array of FunctionDeclarations.
419 |    */
420 |   getFunctionDeclarations(): FunctionDeclaration[] {
421 |     const declarations: FunctionDeclaration[] = [];
422 |     this.tools.forEach((tool) => {
423 |       declarations.push(tool.schema);
424 |     });
425 |     return declarations;
426 |   }
427 | 
428 |   /**
429 |    * Retrieves a filtered list of tool schemas based on a list of tool names.
430 |    * @param toolNames - An array of tool names to include.
431 |    * @returns An array of FunctionDeclarations for the specified tools.
432 |    */
433 |   getFunctionDeclarationsFiltered(toolNames: string[]): FunctionDeclaration[] {
434 |     const declarations: FunctionDeclaration[] = [];
435 |     for (const name of toolNames) {
436 |       const tool = this.tools.get(name);
437 |       if (tool) {
438 |         declarations.push(tool.schema);
439 |       }
440 |     }
441 |     return declarations;
442 |   }
443 | 
444 |   /**
445 |    * Returns an array of all registered and discovered tool names.
446 |    */
447 |   getAllToolNames(): string[] {
448 |     return Array.from(this.tools.keys());
449 |   }
450 | 
451 |   /**
452 |    * Returns an array of all registered and discovered tool instances.
453 |    */
454 |   getAllTools(): AnyDeclarativeTool[] {
455 |     return Array.from(this.tools.values()).sort((a, b) =>
456 |       a.displayName.localeCompare(b.displayName),
457 |     );
458 |   }
459 | 
460 |   /**
461 |    * Returns an array of tools registered from a specific MCP server.
462 |    */
463 |   getToolsByServer(serverName: string): AnyDeclarativeTool[] {
464 |     const serverTools: AnyDeclarativeTool[] = [];
465 |     for (const tool of this.tools.values()) {
466 |       if ((tool as DiscoveredMCPTool)?.serverName === serverName) {
467 |         serverTools.push(tool);
468 |       }
469 |     }
470 |     return serverTools.sort((a, b) => a.name.localeCompare(b.name));
471 |   }
472 | 
473 |   /**
474 |    * Get the definition of a specific tool.
475 |    */
476 |   getTool(name: string): AnyDeclarativeTool | undefined {
477 |     return this.tools.get(name);
478 |   }
479 | }
```

src/tools/tools.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi } from 'vitest';
8 | import type { ToolInvocation, ToolResult } from './tools.js';
9 | import { DeclarativeTool, hasCycleInSchema, Kind } from './tools.js';
10 | import { ToolErrorType } from './tool-error.js';
11 | 
12 | class TestToolInvocation implements ToolInvocation<object, ToolResult> {
13 |   constructor(
14 |     readonly params: object,
15 |     private readonly executeFn: () => Promise<ToolResult>,
16 |   ) {}
17 | 
18 |   getDescription(): string {
19 |     return 'A test invocation';
20 |   }
21 | 
22 |   toolLocations() {
23 |     return [];
24 |   }
25 | 
26 |   shouldConfirmExecute(): Promise<false> {
27 |     return Promise.resolve(false);
28 |   }
29 | 
30 |   execute(): Promise<ToolResult> {
31 |     return this.executeFn();
32 |   }
33 | }
34 | 
35 | class TestTool extends DeclarativeTool<object, ToolResult> {
36 |   private readonly buildFn: (params: object) => TestToolInvocation;
37 | 
38 |   constructor(buildFn: (params: object) => TestToolInvocation) {
39 |     super('test-tool', 'Test Tool', 'A tool for testing', Kind.Other, {});
40 |     this.buildFn = buildFn;
41 |   }
42 | 
43 |   build(params: object): ToolInvocation<object, ToolResult> {
44 |     return this.buildFn(params);
45 |   }
46 | }
47 | 
48 | describe('DeclarativeTool', () => {
49 |   describe('validateBuildAndExecute', () => {
50 |     const abortSignal = new AbortController().signal;
51 | 
52 |     it('should return INVALID_TOOL_PARAMS error if build fails', async () => {
53 |       const buildError = new Error('Invalid build parameters');
54 |       const buildFn = vi.fn().mockImplementation(() => {
55 |         throw buildError;
56 |       });
57 |       const tool = new TestTool(buildFn);
58 |       const params = { foo: 'bar' };
59 | 
60 |       const result = await tool.validateBuildAndExecute(params, abortSignal);
61 | 
62 |       expect(buildFn).toHaveBeenCalledWith(params);
63 |       expect(result).toEqual({
64 |         llmContent: `Error: Invalid parameters provided. Reason: ${buildError.message}`,
65 |         returnDisplay: buildError.message,
66 |         error: {
67 |           message: buildError.message,
68 |           type: ToolErrorType.INVALID_TOOL_PARAMS,
69 |         },
70 |       });
71 |     });
72 | 
73 |     it('should return EXECUTION_FAILED error if execute fails', async () => {
74 |       const executeError = new Error('Execution failed');
75 |       const executeFn = vi.fn().mockRejectedValue(executeError);
76 |       const invocation = new TestToolInvocation({}, executeFn);
77 |       const buildFn = vi.fn().mockReturnValue(invocation);
78 |       const tool = new TestTool(buildFn);
79 |       const params = { foo: 'bar' };
80 | 
81 |       const result = await tool.validateBuildAndExecute(params, abortSignal);
82 | 
83 |       expect(buildFn).toHaveBeenCalledWith(params);
84 |       expect(executeFn).toHaveBeenCalled();
85 |       expect(result).toEqual({
86 |         llmContent: `Error: Tool call execution failed. Reason: ${executeError.message}`,
87 |         returnDisplay: executeError.message,
88 |         error: {
89 |           message: executeError.message,
90 |           type: ToolErrorType.EXECUTION_FAILED,
91 |         },
92 |       });
93 |     });
94 | 
95 |     it('should return the result of execute on success', async () => {
96 |       const successResult: ToolResult = {
97 |         llmContent: 'Success!',
98 |         returnDisplay: 'Success!',
99 |       };
100 |       const executeFn = vi.fn().mockResolvedValue(successResult);
101 |       const invocation = new TestToolInvocation({}, executeFn);
102 |       const buildFn = vi.fn().mockReturnValue(invocation);
103 |       const tool = new TestTool(buildFn);
104 |       const params = { foo: 'bar' };
105 | 
106 |       const result = await tool.validateBuildAndExecute(params, abortSignal);
107 | 
108 |       expect(buildFn).toHaveBeenCalledWith(params);
109 |       expect(executeFn).toHaveBeenCalled();
110 |       expect(result).toEqual(successResult);
111 |     });
112 |   });
113 | });
114 | 
115 | describe('hasCycleInSchema', () => {
116 |   it('should detect a simple direct cycle', () => {
117 |     const schema = {
118 |       properties: {
119 |         data: {
120 |           $ref: '#/properties/data',
121 |         },
122 |       },
123 |     };
124 |     expect(hasCycleInSchema(schema)).toBe(true);
125 |   });
126 | 
127 |   it('should detect a cycle from object properties referencing parent properties', () => {
128 |     const schema = {
129 |       type: 'object',
130 |       properties: {
131 |         data: {
132 |           type: 'object',
133 |           properties: {
134 |             child: { $ref: '#/properties/data' },
135 |           },
136 |         },
137 |       },
138 |     };
139 |     expect(hasCycleInSchema(schema)).toBe(true);
140 |   });
141 | 
142 |   it('should detect a cycle from array items referencing parent properties', () => {
143 |     const schema = {
144 |       type: 'object',
145 |       properties: {
146 |         data: {
147 |           type: 'array',
148 |           items: {
149 |             type: 'object',
150 |             properties: {
151 |               child: { $ref: '#/properties/data/items' },
152 |             },
153 |           },
154 |         },
155 |       },
156 |     };
157 |     expect(hasCycleInSchema(schema)).toBe(true);
158 |   });
159 | 
160 |   it('should detect a cycle between sibling properties', () => {
161 |     const schema = {
162 |       type: 'object',
163 |       properties: {
164 |         a: {
165 |           type: 'object',
166 |           properties: {
167 |             child: { $ref: '#/properties/b' },
168 |           },
169 |         },
170 |         b: {
171 |           type: 'object',
172 |           properties: {
173 |             child: { $ref: '#/properties/a' },
174 |           },
175 |         },
176 |       },
177 |     };
178 |     expect(hasCycleInSchema(schema)).toBe(true);
179 |   });
180 | 
181 |   it('should not detect a cycle in a valid schema', () => {
182 |     const schema = {
183 |       type: 'object',
184 |       properties: {
185 |         name: { type: 'string' },
186 |         address: { $ref: '#/definitions/address' },
187 |       },
188 |       definitions: {
189 |         address: {
190 |           type: 'object',
191 |           properties: {
192 |             street: { type: 'string' },
193 |             city: { type: 'string' },
194 |           },
195 |         },
196 |       },
197 |     };
198 |     expect(hasCycleInSchema(schema)).toBe(false);
199 |   });
200 | 
201 |   it('should handle non-cyclic sibling refs', () => {
202 |     const schema = {
203 |       properties: {
204 |         a: { $ref: '#/definitions/stringDef' },
205 |         b: { $ref: '#/definitions/stringDef' },
206 |       },
207 |       definitions: {
208 |         stringDef: { type: 'string' },
209 |       },
210 |     };
211 |     expect(hasCycleInSchema(schema)).toBe(false);
212 |   });
213 | 
214 |   it('should handle nested but not cyclic refs', () => {
215 |     const schema = {
216 |       properties: {
217 |         a: { $ref: '#/definitions/defA' },
218 |       },
219 |       definitions: {
220 |         defA: { properties: { b: { $ref: '#/definitions/defB' } } },
221 |         defB: { type: 'string' },
222 |       },
223 |     };
224 |     expect(hasCycleInSchema(schema)).toBe(false);
225 |   });
226 | 
227 |   it('should return false for an empty schema', () => {
228 |     expect(hasCycleInSchema({})).toBe(false);
229 |   });
230 | });
```

src/tools/tools.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { FunctionDeclaration, PartListUnion } from '@google/genai';
8 | import { ToolErrorType } from './tool-error.js';
9 | import type { DiffUpdateResult } from '../ide/ide-client.js';
10 | import type { ShellExecutionConfig } from '../services/shellExecutionService.js';
11 | import { SchemaValidator } from '../utils/schemaValidator.js';
12 | import type { AnsiOutput } from '../utils/terminalSerializer.js';
13 | import type { MessageBus } from '../confirmation-bus/message-bus.js';
14 | import { randomUUID } from 'node:crypto';
15 | import {
16 |   MessageBusType,
17 |   type ToolConfirmationRequest,
18 |   type ToolConfirmationResponse,
19 | } from '../confirmation-bus/types.js';
20 | 
21 | /**
22 |  * Represents a validated and ready-to-execute tool call.
23 |  * An instance of this is created by a `ToolBuilder`.
24 |  */
25 | export interface ToolInvocation<
26 |   TParams extends object,
27 |   TResult extends ToolResult,
28 | > {
29 |   /**
30 |    * The validated parameters for this specific invocation.
31 |    */
32 |   params: TParams;
33 | 
34 |   /**
35 |    * Gets a pre-execution description of the tool operation.
36 |    *
37 |    * @returns A markdown string describing what the tool will do.
38 |    */
39 |   getDescription(): string;
40 | 
41 |   /**
42 |    * Determines what file system paths the tool will affect.
43 |    * @returns A list of such paths.
44 |    */
45 |   toolLocations(): ToolLocation[];
46 | 
47 |   /**
48 |    * Determines if the tool should prompt for confirmation before execution.
49 |    * @returns Confirmation details or false if no confirmation is needed.
50 |    */
51 |   shouldConfirmExecute(
52 |     abortSignal: AbortSignal,
53 |   ): Promise<ToolCallConfirmationDetails | false>;
54 | 
55 |   /**
56 |    * Executes the tool with the validated parameters.
57 |    * @param signal AbortSignal for tool cancellation.
58 |    * @param updateOutput Optional callback to stream output.
59 |    * @returns Result of the tool execution.
60 |    */
61 |   execute(
62 |     signal: AbortSignal,
63 |     updateOutput?: (output: string | AnsiOutput) => void,
64 |     shellExecutionConfig?: ShellExecutionConfig,
65 |   ): Promise<TResult>;
66 | }
67 | 
68 | /**
69 |  * A convenience base class for ToolInvocation.
70 |  */
71 | export abstract class BaseToolInvocation<
72 |   TParams extends object,
73 |   TResult extends ToolResult,
74 | > implements ToolInvocation<TParams, TResult>
75 | {
76 |   constructor(
77 |     readonly params: TParams,
78 |     protected readonly messageBus?: MessageBus,
79 |   ) {
80 |     if (this.messageBus) {
81 |       console.log(
82 |         `[DEBUG] Tool ${this.constructor.name} created with messageBus: YES`,
83 |       );
84 |     }
85 |   }
86 | 
87 |   abstract getDescription(): string;
88 | 
89 |   toolLocations(): ToolLocation[] {
90 |     return [];
91 |   }
92 | 
93 |   shouldConfirmExecute(
94 |     _abortSignal: AbortSignal,
95 |   ): Promise<ToolCallConfirmationDetails | false> {
96 |     // If message bus is available, use it for confirmation
97 |     if (this.messageBus) {
98 |       console.log(
99 |         `[DEBUG] Using message bus for tool confirmation: ${this.constructor.name}`,
100 |       );
101 |       return this.handleMessageBusConfirmation(_abortSignal);
102 |     }
103 | 
104 |     // Fall back to existing confirmation flow
105 |     return Promise.resolve(false);
106 |   }
107 | 
108 |   /**
109 |    * Handle tool confirmation using the message bus.
110 |    * This method publishes a confirmation request and waits for the response.
111 |    */
112 |   protected async handleMessageBusConfirmation(
113 |     abortSignal: AbortSignal,
114 |   ): Promise<ToolCallConfirmationDetails | false> {
115 |     if (!this.messageBus) {
116 |       return false;
117 |     }
118 | 
119 |     const correlationId = randomUUID();
120 |     const toolCall = {
121 |       name: this.constructor.name,
122 |       args: this.params as Record<string, unknown>,
123 |     };
124 | 
125 |     return new Promise<ToolCallConfirmationDetails | false>(
126 |       (resolve, reject) => {
127 |         if (!this.messageBus) {
128 |           resolve(false);
129 |           return;
130 |         }
131 | 
132 |         let timeoutId: NodeJS.Timeout | undefined;
133 | 
134 |         // Centralized cleanup function
135 |         const cleanup = () => {
136 |           if (timeoutId) {
137 |             clearTimeout(timeoutId);
138 |             timeoutId = undefined;
139 |           }
140 |           abortSignal.removeEventListener('abort', abortHandler);
141 |           this.messageBus?.unsubscribe(
142 |             MessageBusType.TOOL_CONFIRMATION_RESPONSE,
143 |             responseHandler,
144 |           );
145 |         };
146 | 
147 |         // Set up abort handler
148 |         const abortHandler = () => {
149 |           cleanup();
150 |           reject(new Error('Tool confirmation aborted'));
151 |         };
152 | 
153 |         // Check if already aborted
154 |         if (abortSignal.aborted) {
155 |           reject(new Error('Tool confirmation aborted'));
156 |           return;
157 |         }
158 | 
159 |         // Set up response handler
160 |         const responseHandler = (response: ToolConfirmationResponse) => {
161 |           if (response.correlationId === correlationId) {
162 |             cleanup();
163 | 
164 |             if (response.confirmed) {
165 |               // Tool was confirmed, return false to indicate no further confirmation needed
166 |               resolve(false);
167 |             } else {
168 |               // Tool was denied, reject to prevent execution
169 |               reject(new Error('Tool execution denied by policy'));
170 |             }
171 |           }
172 |         };
173 | 
174 |         // Add event listener for abort signal
175 |         abortSignal.addEventListener('abort', abortHandler);
176 | 
177 |         // Set up timeout
178 |         timeoutId = setTimeout(() => {
179 |           cleanup();
180 |           resolve(false);
181 |         }, 30000); // 30 second timeout
182 | 
183 |         // Subscribe to response
184 |         this.messageBus.subscribe(
185 |           MessageBusType.TOOL_CONFIRMATION_RESPONSE,
186 |           responseHandler,
187 |         );
188 | 
189 |         // Publish confirmation request
190 |         const request: ToolConfirmationRequest = {
191 |           type: MessageBusType.TOOL_CONFIRMATION_REQUEST,
192 |           toolCall,
193 |           correlationId,
194 |         };
195 | 
196 |         try {
197 |           this.messageBus.publish(request);
198 |         } catch (_error) {
199 |           cleanup();
200 |           resolve(false);
201 |         }
202 |       },
203 |     );
204 |   }
205 | 
206 |   abstract execute(
207 |     signal: AbortSignal,
208 |     updateOutput?: (output: string | AnsiOutput) => void,
209 |     shellExecutionConfig?: ShellExecutionConfig,
210 |   ): Promise<TResult>;
211 | }
212 | 
213 | /**
214 |  * A type alias for a tool invocation where the specific parameter and result types are not known.
215 |  */
216 | export type AnyToolInvocation = ToolInvocation<object, ToolResult>;
217 | 
218 | /**
219 |  * Interface for a tool builder that validates parameters and creates invocations.
220 |  */
221 | export interface ToolBuilder<
222 |   TParams extends object,
223 |   TResult extends ToolResult,
224 | > {
225 |   /**
226 |    * The internal name of the tool (used for API calls).
227 |    */
228 |   name: string;
229 | 
230 |   /**
231 |    * The user-friendly display name of the tool.
232 |    */
233 |   displayName: string;
234 | 
235 |   /**
236 |    * Description of what the tool does.
237 |    */
238 |   description: string;
239 | 
240 |   /**
241 |    * The kind of tool for categorization and permissions
242 |    */
243 |   kind: Kind;
244 | 
245 |   /**
246 |    * Function declaration schema from @google/genai.
247 |    */
248 |   schema: FunctionDeclaration;
249 | 
250 |   /**
251 |    * Whether the tool's output should be rendered as markdown.
252 |    */
253 |   isOutputMarkdown: boolean;
254 | 
255 |   /**
256 |    * Whether the tool supports live (streaming) output.
257 |    */
258 |   canUpdateOutput: boolean;
259 | 
260 |   /**
261 |    * Validates raw parameters and builds a ready-to-execute invocation.
262 |    * @param params The raw, untrusted parameters from the model.
263 |    * @returns A valid `ToolInvocation` if successful. Throws an error if validation fails.
264 |    */
265 |   build(params: TParams): ToolInvocation<TParams, TResult>;
266 | }
267 | 
268 | /**
269 |  * New base class for tools that separates validation from execution.
270 |  * New tools should extend this class.
271 |  */
272 | export abstract class DeclarativeTool<
273 |   TParams extends object,
274 |   TResult extends ToolResult,
275 | > implements ToolBuilder<TParams, TResult>
276 | {
277 |   constructor(
278 |     readonly name: string,
279 |     readonly displayName: string,
280 |     readonly description: string,
281 |     readonly kind: Kind,
282 |     readonly parameterSchema: unknown,
283 |     readonly isOutputMarkdown: boolean = true,
284 |     readonly canUpdateOutput: boolean = false,
285 |     readonly messageBus?: MessageBus,
286 |   ) {}
287 | 
288 |   get schema(): FunctionDeclaration {
289 |     return {
290 |       name: this.name,
291 |       description: this.description,
292 |       parametersJsonSchema: this.parameterSchema,
293 |     };
294 |   }
295 | 
296 |   /**
297 |    * Validates the raw tool parameters.
298 |    * Subclasses should override this to add custom validation logic
299 |    * beyond the JSON schema check.
300 |    * @param params The raw parameters from the model.
301 |    * @returns An error message string if invalid, null otherwise.
302 |    */
303 |   validateToolParams(_params: TParams): string | null {
304 |     // Base implementation can be extended by subclasses.
305 |     return null;
306 |   }
307 | 
308 |   /**
309 |    * The core of the new pattern. It validates parameters and, if successful,
310 |    * returns a `ToolInvocation` object that encapsulates the logic for the
311 |    * specific, validated call.
312 |    * @param params The raw, untrusted parameters from the model.
313 |    * @returns A `ToolInvocation` instance.
314 |    */
315 |   abstract build(params: TParams): ToolInvocation<TParams, TResult>;
316 | 
317 |   /**
318 |    * A convenience method that builds and executes the tool in one step.
319 |    * Throws an error if validation fails.
320 |    * @param params The raw, untrusted parameters from the model.
321 |    * @param signal AbortSignal for tool cancellation.
322 |    * @param updateOutput Optional callback to stream output.
323 |    * @returns The result of the tool execution.
324 |    */
325 |   async buildAndExecute(
326 |     params: TParams,
327 |     signal: AbortSignal,
328 |     updateOutput?: (output: string | AnsiOutput) => void,
329 |     shellExecutionConfig?: ShellExecutionConfig,
330 |   ): Promise<TResult> {
331 |     const invocation = this.build(params);
332 |     return invocation.execute(signal, updateOutput, shellExecutionConfig);
333 |   }
334 | 
335 |   /**
336 |    * Similar to `build` but never throws.
337 |    * @param params The raw, untrusted parameters from the model.
338 |    * @returns A `ToolInvocation` instance.
339 |    */
340 |   private silentBuild(
341 |     params: TParams,
342 |   ): ToolInvocation<TParams, TResult> | Error {
343 |     try {
344 |       return this.build(params);
345 |     } catch (e) {
346 |       if (e instanceof Error) {
347 |         return e;
348 |       }
349 |       return new Error(String(e));
350 |     }
351 |   }
352 | 
353 |   /**
354 |    * A convenience method that builds and executes the tool in one step.
355 |    * Never throws.
356 |    * @param params The raw, untrusted parameters from the model.
357 |    * @params abortSignal a signal to abort.
358 |    * @returns The result of the tool execution.
359 |    */
360 |   async validateBuildAndExecute(
361 |     params: TParams,
362 |     abortSignal: AbortSignal,
363 |   ): Promise<ToolResult> {
364 |     const invocationOrError = this.silentBuild(params);
365 |     if (invocationOrError instanceof Error) {
366 |       const errorMessage = invocationOrError.message;
367 |       return {
368 |         llmContent: `Error: Invalid parameters provided. Reason: ${errorMessage}`,
369 |         returnDisplay: errorMessage,
370 |         error: {
371 |           message: errorMessage,
372 |           type: ToolErrorType.INVALID_TOOL_PARAMS,
373 |         },
374 |       };
375 |     }
376 | 
377 |     try {
378 |       return await invocationOrError.execute(abortSignal);
379 |     } catch (error) {
380 |       const errorMessage =
381 |         error instanceof Error ? error.message : String(error);
382 |       return {
383 |         llmContent: `Error: Tool call execution failed. Reason: ${errorMessage}`,
384 |         returnDisplay: errorMessage,
385 |         error: {
386 |           message: errorMessage,
387 |           type: ToolErrorType.EXECUTION_FAILED,
388 |         },
389 |       };
390 |     }
391 |   }
392 | }
393 | 
394 | /**
395 |  * New base class for declarative tools that separates validation from execution.
396 |  * New tools should extend this class, which provides a `build` method that
397 |  * validates parameters before deferring to a `createInvocation` method for
398 |  * the final `ToolInvocation` object instantiation.
399 |  */
400 | export abstract class BaseDeclarativeTool<
401 |   TParams extends object,
402 |   TResult extends ToolResult,
403 | > extends DeclarativeTool<TParams, TResult> {
404 |   build(params: TParams): ToolInvocation<TParams, TResult> {
405 |     const validationError = this.validateToolParams(params);
406 |     if (validationError) {
407 |       throw new Error(validationError);
408 |     }
409 |     return this.createInvocation(params, this.messageBus);
410 |   }
411 | 
412 |   override validateToolParams(params: TParams): string | null {
413 |     const errors = SchemaValidator.validate(
414 |       this.schema.parametersJsonSchema,
415 |       params,
416 |     );
417 | 
418 |     if (errors) {
419 |       return errors;
420 |     }
421 |     return this.validateToolParamValues(params);
422 |   }
423 | 
424 |   protected validateToolParamValues(_params: TParams): string | null {
425 |     // Base implementation can be extended by subclasses.
426 |     return null;
427 |   }
428 | 
429 |   protected abstract createInvocation(
430 |     params: TParams,
431 |     messageBus?: MessageBus,
432 |   ): ToolInvocation<TParams, TResult>;
433 | }
434 | 
435 | /**
436 |  * A type alias for a declarative tool where the specific parameter and result types are not known.
437 |  */
438 | export type AnyDeclarativeTool = DeclarativeTool<object, ToolResult>;
439 | 
440 | /**
441 |  * Type guard to check if an object is a Tool.
442 |  * @param obj The object to check.
443 |  * @returns True if the object is a Tool, false otherwise.
444 |  */
445 | export function isTool(obj: unknown): obj is AnyDeclarativeTool {
446 |   return (
447 |     typeof obj === 'object' &&
448 |     obj !== null &&
449 |     'name' in obj &&
450 |     'build' in obj &&
451 |     typeof (obj as AnyDeclarativeTool).build === 'function'
452 |   );
453 | }
454 | 
455 | export interface ToolResult {
456 |   /**
457 |    * Content meant to be included in LLM history.
458 |    * This should represent the factual outcome of the tool execution.
459 |    */
460 |   llmContent: PartListUnion;
461 | 
462 |   /**
463 |    * Markdown string for user display.
464 |    * This provides a user-friendly summary or visualization of the result.
465 |    * NOTE: This might also be considered UI-specific and could potentially be
466 |    * removed or modified in a further refactor if the server becomes purely API-driven.
467 |    * For now, we keep it as the core logic in ReadFileTool currently produces it.
468 |    */
469 |   returnDisplay: ToolResultDisplay;
470 | 
471 |   /**
472 |    * If this property is present, the tool call is considered a failure.
473 |    */
474 |   error?: {
475 |     message: string; // raw error message
476 |     type?: ToolErrorType; // An optional machine-readable error type (e.g., 'FILE_NOT_FOUND').
477 |   };
478 | }
479 | 
480 | /**
481 |  * Detects cycles in a JSON schemas due to `$ref`s.
482 |  * @param schema The root of the JSON schema.
483 |  * @returns `true` if a cycle is detected, `false` otherwise.
484 |  */
485 | export function hasCycleInSchema(schema: object): boolean {
486 |   function resolveRef(ref: string): object | null {
487 |     if (!ref.startsWith('#/')) {
488 |       return null;
489 |     }
490 |     const path = ref.substring(2).split('/');
491 |     let current: unknown = schema;
492 |     for (const segment of path) {
493 |       if (
494 |         typeof current !== 'object' ||
495 |         current === null ||
496 |         !Object.prototype.hasOwnProperty.call(current, segment)
497 |       ) {
498 |         return null;
499 |       }
500 |       current = (current as Record<string, unknown>)[segment];
501 |     }
502 |     return current as object;
503 |   }
504 | 
505 |   function traverse(
506 |     node: unknown,
507 |     visitedRefs: Set<string>,
508 |     pathRefs: Set<string>,
509 |   ): boolean {
510 |     if (typeof node !== 'object' || node === null) {
511 |       return false;
512 |     }
513 | 
514 |     if (Array.isArray(node)) {
515 |       for (const item of node) {
516 |         if (traverse(item, visitedRefs, pathRefs)) {
517 |           return true;
518 |         }
519 |       }
520 |       return false;
521 |     }
522 | 
523 |     if ('$ref' in node && typeof node.$ref === 'string') {
524 |       const ref = node.$ref;
525 |       if (ref === '#/' || pathRefs.has(ref)) {
526 |         // A ref to just '#/' is always a cycle.
527 |         return true; // Cycle detected!
528 |       }
529 |       if (visitedRefs.has(ref)) {
530 |         return false; // Bail early, we have checked this ref before.
531 |       }
532 | 
533 |       const resolvedNode = resolveRef(ref);
534 |       if (resolvedNode) {
535 |         // Add it to both visited and the current path
536 |         visitedRefs.add(ref);
537 |         pathRefs.add(ref);
538 |         const hasCycle = traverse(resolvedNode, visitedRefs, pathRefs);
539 |         pathRefs.delete(ref); // Backtrack, leaving it in visited
540 |         return hasCycle;
541 |       }
542 |     }
543 | 
544 |     // Crawl all the properties of node
545 |     for (const key in node) {
546 |       if (Object.prototype.hasOwnProperty.call(node, key)) {
547 |         if (
548 |           traverse(
549 |             (node as Record<string, unknown>)[key],
550 |             visitedRefs,
551 |             pathRefs,
552 |           )
553 |         ) {
554 |           return true;
555 |         }
556 |       }
557 |     }
558 | 
559 |     return false;
560 |   }
561 | 
562 |   return traverse(schema, new Set<string>(), new Set<string>());
563 | }
564 | 
565 | export type ToolResultDisplay = string | FileDiff | AnsiOutput;
566 | 
567 | export interface FileDiff {
568 |   fileDiff: string;
569 |   fileName: string;
570 |   originalContent: string | null;
571 |   newContent: string;
572 |   diffStat?: DiffStat;
573 | }
574 | 
575 | export interface DiffStat {
576 |   model_added_lines: number;
577 |   model_removed_lines: number;
578 |   model_added_chars: number;
579 |   model_removed_chars: number;
580 |   user_added_lines: number;
581 |   user_removed_lines: number;
582 |   user_added_chars: number;
583 |   user_removed_chars: number;
584 | }
585 | 
586 | export interface ToolEditConfirmationDetails {
587 |   type: 'edit';
588 |   title: string;
589 |   onConfirm: (
590 |     outcome: ToolConfirmationOutcome,
591 |     payload?: ToolConfirmationPayload,
592 |   ) => Promise<void>;
593 |   fileName: string;
594 |   filePath: string;
595 |   fileDiff: string;
596 |   originalContent: string | null;
597 |   newContent: string;
598 |   isModifying?: boolean;
599 |   ideConfirmation?: Promise<DiffUpdateResult>;
600 | }
601 | 
602 | export interface ToolConfirmationPayload {
603 |   // used to override `modifiedProposedContent` for modifiable tools in the
604 |   // inline modify flow
605 |   newContent: string;
606 | }
607 | 
608 | export interface ToolExecuteConfirmationDetails {
609 |   type: 'exec';
610 |   title: string;
611 |   onConfirm: (outcome: ToolConfirmationOutcome) => Promise<void>;
612 |   command: string;
613 |   rootCommand: string;
614 | }
615 | 
616 | export interface ToolMcpConfirmationDetails {
617 |   type: 'mcp';
618 |   title: string;
619 |   serverName: string;
620 |   toolName: string;
621 |   toolDisplayName: string;
622 |   onConfirm: (outcome: ToolConfirmationOutcome) => Promise<void>;
623 | }
624 | 
625 | export interface ToolInfoConfirmationDetails {
626 |   type: 'info';
627 |   title: string;
628 |   onConfirm: (outcome: ToolConfirmationOutcome) => Promise<void>;
629 |   prompt: string;
630 |   urls?: string[];
631 | }
632 | 
633 | export type ToolCallConfirmationDetails =
634 |   | ToolEditConfirmationDetails
635 |   | ToolExecuteConfirmationDetails
636 |   | ToolMcpConfirmationDetails
637 |   | ToolInfoConfirmationDetails;
638 | 
639 | export enum ToolConfirmationOutcome {
640 |   ProceedOnce = 'proceed_once',
641 |   ProceedAlways = 'proceed_always',
642 |   ProceedAlwaysServer = 'proceed_always_server',
643 |   ProceedAlwaysTool = 'proceed_always_tool',
644 |   ModifyWithEditor = 'modify_with_editor',
645 |   Cancel = 'cancel',
646 | }
647 | 
648 | export enum Kind {
649 |   Read = 'read',
650 |   Edit = 'edit',
651 |   Delete = 'delete',
652 |   Move = 'move',
653 |   Search = 'search',
654 |   Execute = 'execute',
655 |   Think = 'think',
656 |   Fetch = 'fetch',
657 |   Other = 'other',
658 | }
659 | 
660 | // Function kinds that have side effects
[TRUNCATED]
```

src/tools/web-fetch.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach } from 'vitest';
8 | import { WebFetchTool } from './web-fetch.js';
9 | import type { Config } from '../config/config.js';
10 | import { ApprovalMode } from '../config/config.js';
11 | import { ToolConfirmationOutcome } from './tools.js';
12 | import { ToolErrorType } from './tool-error.js';
13 | import * as fetchUtils from '../utils/fetch.js';
14 | import {
15 |   logWebFetchFallbackAttempt,
16 |   WebFetchFallbackAttemptEvent,
17 | } from '../telemetry/index.js';
18 | 
19 | const mockGenerateContent = vi.fn();
20 | const mockGetGeminiClient = vi.fn(() => ({
21 |   generateContent: mockGenerateContent,
22 | }));
23 | 
24 | vi.mock('../telemetry/index.js', () => ({
25 |   logWebFetchFallbackAttempt: vi.fn(),
26 |   WebFetchFallbackAttemptEvent: vi.fn(),
27 | }));
28 | 
29 | vi.mock('../utils/fetch.js', async (importOriginal) => {
30 |   const actual = await importOriginal<typeof fetchUtils>();
31 |   return {
32 |     ...actual,
33 |     fetchWithTimeout: vi.fn(),
34 |     isPrivateIp: vi.fn(),
35 |   };
36 | });
37 | 
38 | describe('WebFetchTool', () => {
39 |   let mockConfig: Config;
40 | 
41 |   beforeEach(() => {
42 |     vi.resetAllMocks();
43 |     mockConfig = {
44 |       getApprovalMode: vi.fn(),
45 |       setApprovalMode: vi.fn(),
46 |       getProxy: vi.fn(),
47 |       getGeminiClient: mockGetGeminiClient,
48 |     } as unknown as Config;
49 |   });
50 | 
51 |   describe('execute', () => {
52 |     it('should return WEB_FETCH_NO_URL_IN_PROMPT when no URL is in the prompt for fallback', async () => {
53 |       vi.spyOn(fetchUtils, 'isPrivateIp').mockReturnValue(true);
54 |       const tool = new WebFetchTool(mockConfig);
55 |       const params = { prompt: 'no url here' };
56 |       expect(() => tool.build(params)).toThrow(
57 |         "The 'prompt' must contain at least one valid URL (starting with http:// or https://).",
58 |       );
59 |     });
60 | 
61 |     it('should return WEB_FETCH_FALLBACK_FAILED on fallback fetch failure', async () => {
62 |       vi.spyOn(fetchUtils, 'isPrivateIp').mockReturnValue(true);
63 |       vi.spyOn(fetchUtils, 'fetchWithTimeout').mockRejectedValue(
64 |         new Error('fetch failed'),
65 |       );
66 |       const tool = new WebFetchTool(mockConfig);
67 |       const params = { prompt: 'fetch https://private.ip' };
68 |       const invocation = tool.build(params);
69 |       const result = await invocation.execute(new AbortController().signal);
70 |       expect(result.error?.type).toBe(ToolErrorType.WEB_FETCH_FALLBACK_FAILED);
71 |     });
72 | 
73 |     it('should return WEB_FETCH_PROCESSING_ERROR on general processing failure', async () => {
74 |       vi.spyOn(fetchUtils, 'isPrivateIp').mockReturnValue(false);
75 |       mockGenerateContent.mockRejectedValue(new Error('API error'));
76 |       const tool = new WebFetchTool(mockConfig);
77 |       const params = { prompt: 'fetch https://public.ip' };
78 |       const invocation = tool.build(params);
79 |       const result = await invocation.execute(new AbortController().signal);
80 |       expect(result.error?.type).toBe(ToolErrorType.WEB_FETCH_PROCESSING_ERROR);
81 |     });
82 | 
83 |     it('should log telemetry when falling back due to private IP', async () => {
84 |       vi.spyOn(fetchUtils, 'isPrivateIp').mockReturnValue(true);
85 |       // Mock fetchWithTimeout to succeed so fallback proceeds
86 |       vi.spyOn(fetchUtils, 'fetchWithTimeout').mockResolvedValue({
87 |         ok: true,
88 |         text: () => Promise.resolve('some content'),
89 |       } as Response);
90 |       mockGenerateContent.mockResolvedValue({
91 |         candidates: [{ content: { parts: [{ text: 'fallback response' }] } }],
92 |       });
93 | 
94 |       const tool = new WebFetchTool(mockConfig);
95 |       const params = { prompt: 'fetch https://private.ip' };
96 |       const invocation = tool.build(params);
97 |       await invocation.execute(new AbortController().signal);
98 | 
99 |       expect(logWebFetchFallbackAttempt).toHaveBeenCalledWith(
100 |         mockConfig,
101 |         expect.any(WebFetchFallbackAttemptEvent),
102 |       );
103 |       expect(WebFetchFallbackAttemptEvent).toHaveBeenCalledWith('private_ip');
104 |     });
105 | 
106 |     it('should log telemetry when falling back due to primary fetch failure', async () => {
107 |       vi.spyOn(fetchUtils, 'isPrivateIp').mockReturnValue(false);
108 |       // Mock primary fetch to return empty response, triggering fallback
109 |       mockGenerateContent.mockResolvedValueOnce({
110 |         candidates: [],
111 |       });
112 |       // Mock fetchWithTimeout to succeed so fallback proceeds
113 |       vi.spyOn(fetchUtils, 'fetchWithTimeout').mockResolvedValue({
114 |         ok: true,
115 |         text: () => Promise.resolve('some content'),
116 |       } as Response);
117 |       // Mock fallback LLM call
118 |       mockGenerateContent.mockResolvedValueOnce({
119 |         candidates: [{ content: { parts: [{ text: 'fallback response' }] } }],
120 |       });
121 | 
122 |       const tool = new WebFetchTool(mockConfig);
123 |       const params = { prompt: 'fetch https://public.ip' };
124 |       const invocation = tool.build(params);
125 |       await invocation.execute(new AbortController().signal);
126 | 
127 |       expect(logWebFetchFallbackAttempt).toHaveBeenCalledWith(
128 |         mockConfig,
129 |         expect.any(WebFetchFallbackAttemptEvent),
130 |       );
131 |       expect(WebFetchFallbackAttemptEvent).toHaveBeenCalledWith(
132 |         'primary_failed',
133 |       );
134 |     });
135 |   });
136 | 
137 |   describe('shouldConfirmExecute', () => {
138 |     it('should return confirmation details with the correct prompt and urls', async () => {
139 |       const tool = new WebFetchTool(mockConfig);
140 |       const params = { prompt: 'fetch https://example.com' };
141 |       const invocation = tool.build(params);
142 |       const confirmationDetails = await invocation.shouldConfirmExecute(
143 |         new AbortController().signal,
144 |       );
145 | 
146 |       expect(confirmationDetails).toEqual({
147 |         type: 'info',
148 |         title: 'Confirm Web Fetch',
149 |         prompt: 'fetch https://example.com',
150 |         urls: ['https://example.com'],
151 |         onConfirm: expect.any(Function),
152 |       });
153 |     });
154 | 
155 |     it('should convert github urls to raw format', async () => {
156 |       const tool = new WebFetchTool(mockConfig);
157 |       const params = {
158 |         prompt:
159 |           'fetch https://github.com/google/gemini-react/blob/main/README.md',
160 |       };
161 |       const invocation = tool.build(params);
162 |       const confirmationDetails = await invocation.shouldConfirmExecute(
163 |         new AbortController().signal,
164 |       );
165 | 
166 |       expect(confirmationDetails).toEqual({
167 |         type: 'info',
168 |         title: 'Confirm Web Fetch',
169 |         prompt:
170 |           'fetch https://github.com/google/gemini-react/blob/main/README.md',
171 |         urls: [
172 |           'https://raw.githubusercontent.com/google/gemini-react/main/README.md',
173 |         ],
174 |         onConfirm: expect.any(Function),
175 |       });
176 |     });
177 | 
178 |     it('should return false if approval mode is AUTO_EDIT', async () => {
179 |       vi.spyOn(mockConfig, 'getApprovalMode').mockReturnValue(
180 |         ApprovalMode.AUTO_EDIT,
181 |       );
182 |       const tool = new WebFetchTool(mockConfig);
183 |       const params = { prompt: 'fetch https://example.com' };
184 |       const invocation = tool.build(params);
185 |       const confirmationDetails = await invocation.shouldConfirmExecute(
186 |         new AbortController().signal,
187 |       );
188 | 
189 |       expect(confirmationDetails).toBe(false);
190 |     });
191 | 
192 |     it('should call setApprovalMode when onConfirm is called with ProceedAlways', async () => {
193 |       const tool = new WebFetchTool(mockConfig);
194 |       const params = { prompt: 'fetch https://example.com' };
195 |       const invocation = tool.build(params);
196 |       const confirmationDetails = await invocation.shouldConfirmExecute(
197 |         new AbortController().signal,
198 |       );
199 | 
200 |       if (
201 |         confirmationDetails &&
202 |         typeof confirmationDetails === 'object' &&
203 |         'onConfirm' in confirmationDetails
204 |       ) {
205 |         await confirmationDetails.onConfirm(
206 |           ToolConfirmationOutcome.ProceedAlways,
207 |         );
208 |       }
209 | 
210 |       expect(mockConfig.setApprovalMode).toHaveBeenCalledWith(
211 |         ApprovalMode.AUTO_EDIT,
212 |       );
213 |     });
214 |   });
215 | });
```

src/tools/web-fetch.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   ToolCallConfirmationDetails,
9 |   ToolInvocation,
10 |   ToolResult,
11 | } from './tools.js';
12 | import {
13 |   BaseDeclarativeTool,
14 |   BaseToolInvocation,
15 |   Kind,
16 |   ToolConfirmationOutcome,
17 | } from './tools.js';
18 | import { ToolErrorType } from './tool-error.js';
19 | import { getErrorMessage } from '../utils/errors.js';
20 | import type { Config } from '../config/config.js';
21 | import { ApprovalMode, DEFAULT_GEMINI_FLASH_MODEL } from '../config/config.js';
22 | import { getResponseText } from '../utils/partUtils.js';
23 | import { fetchWithTimeout, isPrivateIp } from '../utils/fetch.js';
24 | import { convert } from 'html-to-text';
25 | import { ProxyAgent, setGlobalDispatcher } from 'undici';
26 | import {
27 |   logWebFetchFallbackAttempt,
28 |   WebFetchFallbackAttemptEvent,
29 | } from '../telemetry/index.js';
30 | 
31 | const URL_FETCH_TIMEOUT_MS = 10000;
32 | const MAX_CONTENT_LENGTH = 100000;
33 | 
34 | // Helper function to extract URLs from a string
35 | function extractUrls(text: string): string[] {
36 |   const urlRegex = /(https?:\/\/[^\s]+)/g;
37 |   return text.match(urlRegex) || [];
38 | }
39 | 
40 | // Interfaces for grounding metadata (similar to web-search.ts)
41 | interface GroundingChunkWeb {
42 |   uri?: string;
43 |   title?: string;
44 | }
45 | 
46 | interface GroundingChunkItem {
47 |   web?: GroundingChunkWeb;
48 | }
49 | 
50 | interface GroundingSupportSegment {
51 |   startIndex: number;
52 |   endIndex: number;
53 |   text?: string;
54 | }
55 | 
56 | interface GroundingSupportItem {
57 |   segment?: GroundingSupportSegment;
58 |   groundingChunkIndices?: number[];
59 | }
60 | 
61 | /**
62 |  * Parameters for the WebFetch tool
63 |  */
64 | export interface WebFetchToolParams {
65 |   /**
66 |    * The prompt containing URL(s) (up to 20) and instructions for processing their content.
67 |    */
68 |   prompt: string;
69 | }
70 | 
71 | class WebFetchToolInvocation extends BaseToolInvocation<
72 |   WebFetchToolParams,
73 |   ToolResult
74 | > {
75 |   constructor(
76 |     private readonly config: Config,
77 |     params: WebFetchToolParams,
78 |   ) {
79 |     super(params);
80 |   }
81 | 
82 |   private async executeFallback(signal: AbortSignal): Promise<ToolResult> {
83 |     const urls = extractUrls(this.params.prompt);
84 |     // For now, we only support one URL for fallback
85 |     let url = urls[0];
86 | 
87 |     // Convert GitHub blob URL to raw URL
88 |     if (url.includes('github.com') && url.includes('/blob/')) {
89 |       url = url
90 |         .replace('github.com', 'raw.githubusercontent.com')
91 |         .replace('/blob/', '/');
92 |     }
93 | 
94 |     try {
95 |       const response = await fetchWithTimeout(url, URL_FETCH_TIMEOUT_MS);
96 |       if (!response.ok) {
97 |         throw new Error(
98 |           `Request failed with status code ${response.status} ${response.statusText}`,
99 |         );
100 |       }
101 |       const html = await response.text();
102 |       const textContent = convert(html, {
103 |         wordwrap: false,
104 |         selectors: [
105 |           { selector: 'a', options: { ignoreHref: true } },
106 |           { selector: 'img', format: 'skip' },
107 |         ],
108 |       }).substring(0, MAX_CONTENT_LENGTH);
109 | 
110 |       const geminiClient = this.config.getGeminiClient();
111 |       const fallbackPrompt = `The user requested the following: "${this.params.prompt}".
112 | 
113 | I was unable to access the URL directly. Instead, I have fetched the raw content of the page. Please use the following content to answer the request. Do not attempt to access the URL again.
114 | 
115 | ---
116 | ${textContent}
117 | ---
118 | `;
119 |       const result = await geminiClient.generateContent(
120 |         [{ role: 'user', parts: [{ text: fallbackPrompt }] }],
121 |         {},
122 |         signal,
123 |         DEFAULT_GEMINI_FLASH_MODEL,
124 |       );
125 |       const resultText = getResponseText(result) || '';
126 |       return {
127 |         llmContent: resultText,
128 |         returnDisplay: `Content for ${url} processed using fallback fetch.`,
129 |       };
130 |     } catch (e) {
131 |       const error = e as Error;
132 |       const errorMessage = `Error during fallback fetch for ${url}: ${error.message}`;
133 |       return {
134 |         llmContent: `Error: ${errorMessage}`,
135 |         returnDisplay: `Error: ${errorMessage}`,
136 |         error: {
137 |           message: errorMessage,
138 |           type: ToolErrorType.WEB_FETCH_FALLBACK_FAILED,
139 |         },
140 |       };
141 |     }
142 |   }
143 | 
144 |   getDescription(): string {
145 |     const displayPrompt =
146 |       this.params.prompt.length > 100
147 |         ? this.params.prompt.substring(0, 97) + '...'
148 |         : this.params.prompt;
149 |     return `Processing URLs and instructions from prompt: "${displayPrompt}"`;
150 |   }
151 | 
152 |   override async shouldConfirmExecute(): Promise<
153 |     ToolCallConfirmationDetails | false
154 |   > {
155 |     if (this.config.getApprovalMode() === ApprovalMode.AUTO_EDIT) {
156 |       return false;
157 |     }
158 | 
159 |     // Perform GitHub URL conversion here to differentiate between user-provided
160 |     // URL and the actual URL to be fetched.
161 |     const urls = extractUrls(this.params.prompt).map((url) => {
162 |       if (url.includes('github.com') && url.includes('/blob/')) {
163 |         return url
164 |           .replace('github.com', 'raw.githubusercontent.com')
165 |           .replace('/blob/', '/');
166 |       }
167 |       return url;
168 |     });
169 | 
170 |     const confirmationDetails: ToolCallConfirmationDetails = {
171 |       type: 'info',
172 |       title: `Confirm Web Fetch`,
173 |       prompt: this.params.prompt,
174 |       urls,
175 |       onConfirm: async (outcome: ToolConfirmationOutcome) => {
176 |         if (outcome === ToolConfirmationOutcome.ProceedAlways) {
177 |           this.config.setApprovalMode(ApprovalMode.AUTO_EDIT);
178 |         }
179 |       },
180 |     };
181 |     return confirmationDetails;
182 |   }
183 | 
184 |   async execute(signal: AbortSignal): Promise<ToolResult> {
185 |     const userPrompt = this.params.prompt;
186 |     const urls = extractUrls(userPrompt);
187 |     const url = urls[0];
188 |     const isPrivate = isPrivateIp(url);
189 | 
190 |     if (isPrivate) {
191 |       logWebFetchFallbackAttempt(
192 |         this.config,
193 |         new WebFetchFallbackAttemptEvent('private_ip'),
194 |       );
195 |       return this.executeFallback(signal);
196 |     }
197 | 
198 |     const geminiClient = this.config.getGeminiClient();
199 | 
200 |     try {
201 |       const response = await geminiClient.generateContent(
202 |         [{ role: 'user', parts: [{ text: userPrompt }] }],
203 |         { tools: [{ urlContext: {} }] },
204 |         signal, // Pass signal
205 |         DEFAULT_GEMINI_FLASH_MODEL,
206 |       );
207 | 
208 |       console.debug(
209 |         `[WebFetchTool] Full response for prompt "${userPrompt.substring(
210 |           0,
211 |           50,
212 |         )}...":`,
213 |         JSON.stringify(response, null, 2),
214 |       );
215 | 
216 |       let responseText = getResponseText(response) || '';
217 |       const urlContextMeta = response.candidates?.[0]?.urlContextMetadata;
218 |       const groundingMetadata = response.candidates?.[0]?.groundingMetadata;
219 |       const sources = groundingMetadata?.groundingChunks as
220 |         | GroundingChunkItem[]
221 |         | undefined;
222 |       const groundingSupports = groundingMetadata?.groundingSupports as
223 |         | GroundingSupportItem[]
224 |         | undefined;
225 | 
226 |       // Error Handling
227 |       let processingError = false;
228 | 
229 |       if (
230 |         urlContextMeta?.urlMetadata &&
231 |         urlContextMeta.urlMetadata.length > 0
232 |       ) {
233 |         const allStatuses = urlContextMeta.urlMetadata.map(
234 |           (m) => m.urlRetrievalStatus,
235 |         );
236 |         if (allStatuses.every((s) => s !== 'URL_RETRIEVAL_STATUS_SUCCESS')) {
237 |           processingError = true;
238 |         }
239 |       } else if (!responseText.trim() && !sources?.length) {
240 |         // No URL metadata and no content/sources
241 |         processingError = true;
242 |       }
243 | 
244 |       if (
245 |         !processingError &&
246 |         !responseText.trim() &&
247 |         (!sources || sources.length === 0)
248 |       ) {
249 |         // Successfully retrieved some URL (or no specific error from urlContextMeta), but no usable text or grounding data.
250 |         processingError = true;
251 |       }
252 | 
253 |       if (processingError) {
254 |         logWebFetchFallbackAttempt(
255 |           this.config,
256 |           new WebFetchFallbackAttemptEvent('primary_failed'),
257 |         );
258 |         return this.executeFallback(signal);
259 |       }
260 | 
261 |       const sourceListFormatted: string[] = [];
262 |       if (sources && sources.length > 0) {
263 |         sources.forEach((source: GroundingChunkItem, index: number) => {
264 |           const title = source.web?.title || 'Untitled';
265 |           const uri = source.web?.uri || 'Unknown URI'; // Fallback if URI is missing
266 |           sourceListFormatted.push(`[${index + 1}] ${title} (${uri})`);
267 |         });
268 | 
269 |         if (groundingSupports && groundingSupports.length > 0) {
270 |           const insertions: Array<{ index: number; marker: string }> = [];
271 |           groundingSupports.forEach((support: GroundingSupportItem) => {
272 |             if (support.segment && support.groundingChunkIndices) {
273 |               const citationMarker = support.groundingChunkIndices
274 |                 .map((chunkIndex: number) => `[${chunkIndex + 1}]`)
275 |                 .join('');
276 |               insertions.push({
277 |                 index: support.segment.endIndex,
278 |                 marker: citationMarker,
279 |               });
280 |             }
281 |           });
282 | 
283 |           insertions.sort((a, b) => b.index - a.index);
284 |           const responseChars = responseText.split('');
285 |           insertions.forEach((insertion) => {
286 |             responseChars.splice(insertion.index, 0, insertion.marker);
287 |           });
288 |           responseText = responseChars.join('');
289 |         }
290 | 
291 |         if (sourceListFormatted.length > 0) {
292 |           responseText += `
293 | 
294 | Sources:
295 | ${sourceListFormatted.join('\n')}`;
296 |         }
297 |       }
298 | 
299 |       const llmContent = responseText;
300 | 
301 |       console.debug(
302 |         `[WebFetchTool] Formatted tool response for prompt "${userPrompt}:\n\n":`,
303 |         llmContent,
304 |       );
305 | 
306 |       return {
307 |         llmContent,
308 |         returnDisplay: `Content processed from prompt.`,
309 |       };
310 |     } catch (error: unknown) {
311 |       const errorMessage = `Error processing web content for prompt "${userPrompt.substring(
312 |         0,
313 |         50,
314 |       )}...": ${getErrorMessage(error)}`;
315 |       console.error(errorMessage, error);
316 |       return {
317 |         llmContent: `Error: ${errorMessage}`,
318 |         returnDisplay: `Error: ${errorMessage}`,
319 |         error: {
320 |           message: errorMessage,
321 |           type: ToolErrorType.WEB_FETCH_PROCESSING_ERROR,
322 |         },
323 |       };
324 |     }
325 |   }
326 | }
327 | 
328 | /**
329 |  * Implementation of the WebFetch tool logic
330 |  */
331 | export class WebFetchTool extends BaseDeclarativeTool<
332 |   WebFetchToolParams,
333 |   ToolResult
334 | > {
335 |   static readonly Name: string = 'web_fetch';
336 | 
337 |   constructor(private readonly config: Config) {
338 |     super(
339 |       WebFetchTool.Name,
340 |       'WebFetch',
341 |       "Processes content from URL(s), including local and private network addresses (e.g., localhost), embedded in a prompt. Include up to 20 URLs and instructions (e.g., summarize, extract specific data) directly in the 'prompt' parameter.",
342 |       Kind.Fetch,
343 |       {
344 |         properties: {
345 |           prompt: {
346 |             description:
347 |               'A comprehensive prompt that includes the URL(s) (up to 20) to fetch and specific instructions on how to process their content (e.g., "Summarize https://example.com/article and extract key points from https://another.com/data"). Must contain as least one URL starting with http:// or https://.',
348 |             type: 'string',
349 |           },
350 |         },
351 |         required: ['prompt'],
352 |         type: 'object',
353 |       },
354 |     );
355 |     const proxy = config.getProxy();
356 |     if (proxy) {
357 |       setGlobalDispatcher(new ProxyAgent(proxy as string));
358 |     }
359 |   }
360 | 
361 |   protected override validateToolParamValues(
362 |     params: WebFetchToolParams,
363 |   ): string | null {
364 |     if (!params.prompt || params.prompt.trim() === '') {
365 |       return "The 'prompt' parameter cannot be empty and must contain URL(s) and instructions.";
366 |     }
367 |     if (
368 |       !params.prompt.includes('http://') &&
369 |       !params.prompt.includes('https://')
370 |     ) {
371 |       return "The 'prompt' must contain at least one valid URL (starting with http:// or https://).";
372 |     }
373 |     return null;
374 |   }
375 | 
376 |   protected createInvocation(
377 |     params: WebFetchToolParams,
378 |   ): ToolInvocation<WebFetchToolParams, ToolResult> {
379 |     return new WebFetchToolInvocation(this.config, params);
380 |   }
381 | }
```

src/tools/web-search.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Mock } from 'vitest';
8 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
9 | import type { WebSearchToolParams } from './web-search.js';
10 | import { WebSearchTool } from './web-search.js';
11 | import type { Config } from '../config/config.js';
12 | import { GeminiClient } from '../core/client.js';
13 | import { ToolErrorType } from './tool-error.js';
14 | 
15 | // Mock GeminiClient and Config constructor
16 | vi.mock('../core/client.js');
17 | vi.mock('../config/config.js');
18 | 
19 | describe('WebSearchTool', () => {
20 |   const abortSignal = new AbortController().signal;
21 |   let mockGeminiClient: GeminiClient;
22 |   let tool: WebSearchTool;
23 | 
24 |   beforeEach(() => {
25 |     const mockConfigInstance = {
26 |       getGeminiClient: () => mockGeminiClient,
27 |       getProxy: () => undefined,
28 |     } as unknown as Config;
29 |     mockGeminiClient = new GeminiClient(mockConfigInstance);
30 |     tool = new WebSearchTool(mockConfigInstance);
31 |   });
32 | 
33 |   afterEach(() => {
34 |     vi.restoreAllMocks();
35 |   });
36 | 
37 |   describe('build', () => {
38 |     it('should return an invocation for a valid query', () => {
39 |       const params: WebSearchToolParams = { query: 'test query' };
40 |       const invocation = tool.build(params);
41 |       expect(invocation).toBeDefined();
42 |       expect(invocation.params).toEqual(params);
43 |     });
44 | 
45 |     it('should throw an error for an empty query', () => {
46 |       const params: WebSearchToolParams = { query: '' };
47 |       expect(() => tool.build(params)).toThrow(
48 |         "The 'query' parameter cannot be empty.",
49 |       );
50 |     });
51 | 
52 |     it('should throw an error for a query with only whitespace', () => {
53 |       const params: WebSearchToolParams = { query: '   ' };
54 |       expect(() => tool.build(params)).toThrow(
55 |         "The 'query' parameter cannot be empty.",
56 |       );
57 |     });
58 |   });
59 | 
60 |   describe('getDescription', () => {
61 |     it('should return a description of the search', () => {
62 |       const params: WebSearchToolParams = { query: 'test query' };
63 |       const invocation = tool.build(params);
64 |       expect(invocation.getDescription()).toBe(
65 |         'Searching the web for: "test query"',
66 |       );
67 |     });
68 |   });
69 | 
70 |   describe('execute', () => {
71 |     it('should return search results for a successful query', async () => {
72 |       const params: WebSearchToolParams = { query: 'successful query' };
73 |       (mockGeminiClient.generateContent as Mock).mockResolvedValue({
74 |         candidates: [
75 |           {
76 |             content: {
77 |               role: 'model',
78 |               parts: [{ text: 'Here are your results.' }],
79 |             },
80 |           },
81 |         ],
82 |       });
83 | 
84 |       const invocation = tool.build(params);
85 |       const result = await invocation.execute(abortSignal);
86 | 
87 |       expect(result.llmContent).toBe(
88 |         'Web search results for "successful query":\n\nHere are your results.',
89 |       );
90 |       expect(result.returnDisplay).toBe(
91 |         'Search results for "successful query" returned.',
92 |       );
93 |       expect(result.sources).toBeUndefined();
94 |     });
95 | 
96 |     it('should handle no search results found', async () => {
97 |       const params: WebSearchToolParams = { query: 'no results query' };
98 |       (mockGeminiClient.generateContent as Mock).mockResolvedValue({
99 |         candidates: [
100 |           {
101 |             content: {
102 |               role: 'model',
103 |               parts: [{ text: '' }],
104 |             },
105 |           },
106 |         ],
107 |       });
108 | 
109 |       const invocation = tool.build(params);
110 |       const result = await invocation.execute(abortSignal);
111 | 
112 |       expect(result.llmContent).toBe(
113 |         'No search results or information found for query: "no results query"',
114 |       );
115 |       expect(result.returnDisplay).toBe('No information found.');
116 |     });
117 | 
118 |     it('should return a WEB_SEARCH_FAILED error on failure', async () => {
119 |       const params: WebSearchToolParams = { query: 'error query' };
120 |       const testError = new Error('API Failure');
121 |       (mockGeminiClient.generateContent as Mock).mockRejectedValue(testError);
122 | 
123 |       const invocation = tool.build(params);
124 |       const result = await invocation.execute(abortSignal);
125 | 
126 |       expect(result.error?.type).toBe(ToolErrorType.WEB_SEARCH_FAILED);
127 |       expect(result.llmContent).toContain('Error:');
128 |       expect(result.llmContent).toContain('API Failure');
129 |       expect(result.returnDisplay).toBe('Error performing web search.');
130 |     });
131 | 
132 |     it('should correctly format results with sources and citations', async () => {
133 |       const params: WebSearchToolParams = { query: 'grounding query' };
134 |       (mockGeminiClient.generateContent as Mock).mockResolvedValue({
135 |         candidates: [
136 |           {
137 |             content: {
138 |               role: 'model',
139 |               parts: [{ text: 'This is a test response.' }],
140 |             },
141 |             groundingMetadata: {
142 |               groundingChunks: [
143 |                 { web: { uri: 'https://example.com', title: 'Example Site' } },
144 |                 { web: { uri: 'https://google.com', title: 'Google' } },
145 |               ],
146 |               groundingSupports: [
147 |                 {
148 |                   segment: { startIndex: 5, endIndex: 14 },
149 |                   groundingChunkIndices: [0],
150 |                 },
151 |                 {
152 |                   segment: { startIndex: 15, endIndex: 24 },
153 |                   groundingChunkIndices: [0, 1],
154 |                 },
155 |               ],
156 |             },
157 |           },
158 |         ],
159 |       });
160 | 
161 |       const invocation = tool.build(params);
162 |       const result = await invocation.execute(abortSignal);
163 | 
164 |       const expectedLlmContent = `Web search results for "grounding query":
165 | 
166 | This is a test[1] response.[1][2]
167 | 
168 | Sources:
169 | [1] Example Site (https://example.com)
170 | [2] Google (https://google.com)`;
171 | 
172 |       expect(result.llmContent).toBe(expectedLlmContent);
173 |       expect(result.returnDisplay).toBe(
174 |         'Search results for "grounding query" returned.',
175 |       );
176 |       expect(result.sources).toHaveLength(2);
177 |     });
178 | 
179 |     it('should insert markers at correct byte positions for multibyte text', async () => {
180 |       const params: WebSearchToolParams = { query: 'multibyte query' };
181 |       (mockGeminiClient.generateContent as Mock).mockResolvedValue({
182 |         candidates: [
183 |           {
184 |             content: {
185 |               role: 'model',
186 |               parts: [{ text: 'こんにちは! Gemini CLI✨️' }],
187 |             },
188 |             groundingMetadata: {
189 |               groundingChunks: [
190 |                 {
191 |                   web: {
192 |                     title: 'Japanese Greeting',
193 |                     uri: 'https://example.test/japanese-greeting',
194 |                   },
195 |                 },
196 |                 {
197 |                   web: {
198 |                     title: 'google-gemini/gemini-cli',
199 |                     uri: 'https://github.com/google-gemini/gemini-cli',
200 |                   },
201 |                 },
202 |                 {
203 |                   web: {
204 |                     title: 'Gemini CLI: your open-source AI agent',
205 |                     uri: 'https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/',
206 |                   },
207 |                 },
208 |               ],
209 |               groundingSupports: [
210 |                 {
211 |                   segment: {
212 |                     // Byte range of "こんにちは!" (utf-8 encoded)
213 |                     startIndex: 0,
214 |                     endIndex: 16,
215 |                   },
216 |                   groundingChunkIndices: [0],
217 |                 },
218 |                 {
219 |                   segment: {
220 |                     // Byte range of "Gemini CLI✨️" (utf-8 encoded)
221 |                     startIndex: 17,
222 |                     endIndex: 33,
223 |                   },
224 |                   groundingChunkIndices: [1, 2],
225 |                 },
226 |               ],
227 |             },
228 |           },
229 |         ],
230 |       });
231 | 
232 |       const invocation = tool.build(params);
233 |       const result = await invocation.execute(abortSignal);
234 | 
235 |       const expectedLlmContent = `Web search results for "multibyte query":
236 | 
237 | こんにちは![1] Gemini CLI✨️[2][3]
238 | 
239 | Sources:
240 | [1] Japanese Greeting (https://example.test/japanese-greeting)
241 | [2] google-gemini/gemini-cli (https://github.com/google-gemini/gemini-cli)
242 | [3] Gemini CLI: your open-source AI agent (https://blog.google/technology/developers/introducing-gemini-cli-open-source-ai-agent/)`;
243 | 
244 |       expect(result.llmContent).toBe(expectedLlmContent);
245 |       expect(result.returnDisplay).toBe(
246 |         'Search results for "multibyte query" returned.',
247 |       );
248 |       expect(result.sources).toHaveLength(3);
249 |     });
250 |   });
251 | });
```

src/tools/web-search.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { WEB_SEARCH_TOOL_NAME } from './tool-names.js';
8 | import type { GroundingMetadata } from '@google/genai';
9 | import type { ToolInvocation, ToolResult } from './tools.js';
10 | import { BaseDeclarativeTool, BaseToolInvocation, Kind } from './tools.js';
11 | import { ToolErrorType } from './tool-error.js';
12 | 
13 | import { getErrorMessage } from '../utils/errors.js';
14 | import { type Config } from '../config/config.js';
15 | import { getResponseText } from '../utils/partUtils.js';
16 | import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';
17 | 
18 | interface GroundingChunkWeb {
19 |   uri?: string;
20 |   title?: string;
21 | }
22 | 
23 | interface GroundingChunkItem {
24 |   web?: GroundingChunkWeb;
25 |   // Other properties might exist if needed in the future
26 | }
27 | 
28 | interface GroundingSupportSegment {
29 |   startIndex: number;
30 |   endIndex: number;
31 |   text?: string; // text is optional as per the example
32 | }
33 | 
34 | interface GroundingSupportItem {
35 |   segment?: GroundingSupportSegment;
36 |   groundingChunkIndices?: number[];
37 |   confidenceScores?: number[]; // Optional as per example
38 | }
39 | 
40 | /**
41 |  * Parameters for the WebSearchTool.
42 |  */
43 | export interface WebSearchToolParams {
44 |   /**
45 |    * The search query.
46 |    */
47 | 
48 |   query: string;
49 | }
50 | 
51 | /**
52 |  * Extends ToolResult to include sources for web search.
53 |  */
54 | export interface WebSearchToolResult extends ToolResult {
55 |   sources?: GroundingMetadata extends { groundingChunks: GroundingChunkItem[] }
56 |     ? GroundingMetadata['groundingChunks']
57 |     : GroundingChunkItem[];
58 | }
59 | 
60 | class WebSearchToolInvocation extends BaseToolInvocation<
61 |   WebSearchToolParams,
62 |   WebSearchToolResult
63 | > {
64 |   constructor(
65 |     private readonly config: Config,
66 |     params: WebSearchToolParams,
67 |   ) {
68 |     super(params);
69 |   }
70 | 
71 |   override getDescription(): string {
72 |     return `Searching the web for: "${this.params.query}"`;
73 |   }
74 | 
75 |   async execute(signal: AbortSignal): Promise<WebSearchToolResult> {
76 |     const geminiClient = this.config.getGeminiClient();
77 | 
78 |     try {
79 |       const response = await geminiClient.generateContent(
80 |         [{ role: 'user', parts: [{ text: this.params.query }] }],
81 |         { tools: [{ googleSearch: {} }] },
82 |         signal,
83 |         DEFAULT_GEMINI_FLASH_MODEL,
84 |       );
85 | 
86 |       const responseText = getResponseText(response);
87 |       const groundingMetadata = response.candidates?.[0]?.groundingMetadata;
88 |       const sources = groundingMetadata?.groundingChunks as
89 |         | GroundingChunkItem[]
90 |         | undefined;
91 |       const groundingSupports = groundingMetadata?.groundingSupports as
92 |         | GroundingSupportItem[]
93 |         | undefined;
94 | 
95 |       if (!responseText || !responseText.trim()) {
96 |         return {
97 |           llmContent: `No search results or information found for query: "${this.params.query}"`,
98 |           returnDisplay: 'No information found.',
99 |         };
100 |       }
101 | 
102 |       let modifiedResponseText = responseText;
103 |       const sourceListFormatted: string[] = [];
104 | 
105 |       if (sources && sources.length > 0) {
106 |         sources.forEach((source: GroundingChunkItem, index: number) => {
107 |           const title = source.web?.title || 'Untitled';
108 |           const uri = source.web?.uri || 'No URI';
109 |           sourceListFormatted.push(`[${index + 1}] ${title} (${uri})`);
110 |         });
111 | 
112 |         if (groundingSupports && groundingSupports.length > 0) {
113 |           const insertions: Array<{ index: number; marker: string }> = [];
114 |           groundingSupports.forEach((support: GroundingSupportItem) => {
115 |             if (support.segment && support.groundingChunkIndices) {
116 |               const citationMarker = support.groundingChunkIndices
117 |                 .map((chunkIndex: number) => `[${chunkIndex + 1}]`)
118 |                 .join('');
119 |               insertions.push({
120 |                 index: support.segment.endIndex,
121 |                 marker: citationMarker,
122 |               });
123 |             }
124 |           });
125 | 
126 |           // Sort insertions by index in descending order to avoid shifting subsequent indices
127 |           insertions.sort((a, b) => b.index - a.index);
128 | 
129 |           // Use TextEncoder/TextDecoder since segment indices are UTF-8 byte positions
130 |           const encoder = new TextEncoder();
131 |           const responseBytes = encoder.encode(modifiedResponseText);
132 |           const parts: Uint8Array[] = [];
133 |           let lastIndex = responseBytes.length;
134 |           for (const ins of insertions) {
135 |             const pos = Math.min(ins.index, lastIndex);
136 |             parts.unshift(responseBytes.subarray(pos, lastIndex));
137 |             parts.unshift(encoder.encode(ins.marker));
138 |             lastIndex = pos;
139 |           }
140 |           parts.unshift(responseBytes.subarray(0, lastIndex));
141 | 
142 |           // Concatenate all parts into a single buffer
143 |           const totalLength = parts.reduce((sum, part) => sum + part.length, 0);
144 |           const finalBytes = new Uint8Array(totalLength);
145 |           let offset = 0;
146 |           for (const part of parts) {
147 |             finalBytes.set(part, offset);
148 |             offset += part.length;
149 |           }
150 |           modifiedResponseText = new TextDecoder().decode(finalBytes);
151 |         }
152 | 
153 |         if (sourceListFormatted.length > 0) {
154 |           modifiedResponseText +=
155 |             '\n\nSources:\n' + sourceListFormatted.join('\n');
156 |         }
157 |       }
158 | 
159 |       return {
160 |         llmContent: `Web search results for "${this.params.query}":\n\n${modifiedResponseText}`,
161 |         returnDisplay: `Search results for "${this.params.query}" returned.`,
162 |         sources,
163 |       };
164 |     } catch (error: unknown) {
165 |       const errorMessage = `Error during web search for query "${
166 |         this.params.query
167 |       }": ${getErrorMessage(error)}`;
168 |       console.error(errorMessage, error);
169 |       return {
170 |         llmContent: `Error: ${errorMessage}`,
171 |         returnDisplay: `Error performing web search.`,
172 |         error: {
173 |           message: errorMessage,
174 |           type: ToolErrorType.WEB_SEARCH_FAILED,
175 |         },
176 |       };
177 |     }
178 |   }
179 | }
180 | 
181 | /**
182 |  * A tool to perform web searches using Google Search via the Gemini API.
183 |  */
184 | export class WebSearchTool extends BaseDeclarativeTool<
185 |   WebSearchToolParams,
186 |   WebSearchToolResult
187 | > {
188 |   static readonly Name: string = WEB_SEARCH_TOOL_NAME;
189 | 
190 |   constructor(private readonly config: Config) {
191 |     super(
192 |       WebSearchTool.Name,
193 |       'GoogleSearch',
194 |       'Performs a web search using Google Search (via the Gemini API) and returns the results. This tool is useful for finding information on the internet based on a query.',
195 |       Kind.Search,
196 |       {
197 |         type: 'object',
198 |         properties: {
199 |           query: {
200 |             type: 'string',
201 |             description: 'The search query to find information on the web.',
202 |           },
203 |         },
204 |         required: ['query'],
205 |       },
206 |     );
207 |   }
208 | 
209 |   /**
210 |    * Validates the parameters for the WebSearchTool.
211 |    * @param params The parameters to validate
212 |    * @returns An error message string if validation fails, null if valid
213 |    */
214 |   protected override validateToolParamValues(
215 |     params: WebSearchToolParams,
216 |   ): string | null {
217 |     if (!params.query || params.query.trim() === '') {
218 |       return "The 'query' parameter cannot be empty.";
219 |     }
220 |     return null;
221 |   }
222 | 
223 |   protected createInvocation(
224 |     params: WebSearchToolParams,
225 |   ): ToolInvocation<WebSearchToolParams, WebSearchToolResult> {
226 |     return new WebSearchToolInvocation(this.config, params);
227 |   }
228 | }
```

src/tools/write-file.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   beforeEach,
12 |   afterEach,
13 |   vi,
14 |   type Mocked,
15 | } from 'vitest';
16 | import type { WriteFileToolParams } from './write-file.js';
17 | import { getCorrectedFileContent, WriteFileTool } from './write-file.js';
18 | import { ToolErrorType } from './tool-error.js';
19 | import type { FileDiff, ToolEditConfirmationDetails } from './tools.js';
20 | import { ToolConfirmationOutcome } from './tools.js';
21 | import { type EditToolParams } from './edit.js';
22 | import type { Config } from '../config/config.js';
23 | import { ApprovalMode } from '../config/config.js';
24 | import type { ToolRegistry } from './tool-registry.js';
25 | import path from 'node:path';
26 | import fs from 'node:fs';
27 | import os from 'node:os';
28 | import { GeminiClient } from '../core/client.js';
29 | import type { BaseLlmClient } from '../core/baseLlmClient.js';
30 | import type { CorrectedEditResult } from '../utils/editCorrector.js';
31 | import {
32 |   ensureCorrectEdit,
33 |   ensureCorrectFileContent,
34 | } from '../utils/editCorrector.js';
35 | import { createMockWorkspaceContext } from '../test-utils/mockWorkspaceContext.js';
36 | import { StandardFileSystemService } from '../services/fileSystemService.js';
37 | import type { DiffUpdateResult } from '../ide/ide-client.js';
38 | import { IdeClient } from '../ide/ide-client.js';
39 | 
40 | const rootDir = path.resolve(os.tmpdir(), 'gemini-cli-test-root');
41 | 
42 | // --- MOCKS ---
43 | vi.mock('../core/client.js');
44 | vi.mock('../utils/editCorrector.js');
45 | vi.mock('../ide/ide-client.js', () => ({
46 |   IdeClient: {
47 |     getInstance: vi.fn(),
48 |   },
49 | }));
50 | let mockGeminiClientInstance: Mocked<GeminiClient>;
51 | let mockBaseLlmClientInstance: Mocked<BaseLlmClient>;
52 | const mockEnsureCorrectEdit = vi.fn<typeof ensureCorrectEdit>();
53 | const mockEnsureCorrectFileContent = vi.fn<typeof ensureCorrectFileContent>();
54 | const mockIdeClient = {
55 |   openDiff: vi.fn(),
56 |   isDiffingEnabled: vi.fn(),
57 | };
58 | 
59 | // Wire up the mocked functions to be used by the actual module imports
60 | vi.mocked(ensureCorrectEdit).mockImplementation(mockEnsureCorrectEdit);
61 | vi.mocked(ensureCorrectFileContent).mockImplementation(
62 |   mockEnsureCorrectFileContent,
63 | );
64 | vi.mocked(IdeClient.getInstance).mockResolvedValue(
65 |   mockIdeClient as unknown as IdeClient,
66 | );
67 | 
68 | // Mock Config
69 | const fsService = new StandardFileSystemService();
70 | const mockConfigInternal = {
71 |   getTargetDir: () => rootDir,
72 |   getApprovalMode: vi.fn(() => ApprovalMode.DEFAULT),
73 |   setApprovalMode: vi.fn(),
74 |   getGeminiClient: vi.fn(), // Initialize as a plain mock function
75 |   getBaseLlmClient: vi.fn(), // Initialize as a plain mock function
76 |   getFileSystemService: () => fsService,
77 |   getIdeMode: vi.fn(() => false),
78 |   getWorkspaceContext: () => createMockWorkspaceContext(rootDir),
79 |   getApiKey: () => 'test-key',
80 |   getModel: () => 'test-model',
81 |   getSandbox: () => false,
82 |   getDebugMode: () => false,
83 |   getQuestion: () => undefined,
84 |   getFullContext: () => false,
85 |   getToolDiscoveryCommand: () => undefined,
86 |   getToolCallCommand: () => undefined,
87 |   getMcpServerCommand: () => undefined,
88 |   getMcpServers: () => undefined,
89 |   getUserAgent: () => 'test-agent',
90 |   getUserMemory: () => '',
91 |   setUserMemory: vi.fn(),
92 |   getGeminiMdFileCount: () => 0,
93 |   setGeminiMdFileCount: vi.fn(),
94 |   getToolRegistry: () =>
95 |     ({
96 |       registerTool: vi.fn(),
97 |       discoverTools: vi.fn(),
98 |     }) as unknown as ToolRegistry,
99 | };
100 | const mockConfig = mockConfigInternal as unknown as Config;
101 | 
102 | vi.mock('../telemetry/loggers.js', () => ({
103 |   logFileOperation: vi.fn(),
104 | }));
105 | 
106 | // --- END MOCKS ---
107 | 
108 | describe('WriteFileTool', () => {
109 |   let tool: WriteFileTool;
110 |   let tempDir: string;
111 | 
112 |   beforeEach(() => {
113 |     vi.clearAllMocks();
114 |     // Create a unique temporary directory for files created outside the root
115 |     tempDir = fs.mkdtempSync(
116 |       path.join(os.tmpdir(), 'write-file-test-external-'),
117 |     );
118 |     // Ensure the rootDir for the tool exists
119 |     if (!fs.existsSync(rootDir)) {
120 |       fs.mkdirSync(rootDir, { recursive: true });
121 |     }
122 | 
123 |     // Setup GeminiClient mock
124 |     mockGeminiClientInstance = new (vi.mocked(GeminiClient))(
125 |       mockConfig,
126 |     ) as Mocked<GeminiClient>;
127 |     vi.mocked(GeminiClient).mockImplementation(() => mockGeminiClientInstance);
128 | 
129 |     // Setup BaseLlmClient mock
130 |     mockBaseLlmClientInstance = {
131 |       generateJson: vi.fn(),
132 |     } as unknown as Mocked<BaseLlmClient>;
133 | 
134 |     vi.mocked(ensureCorrectEdit).mockImplementation(mockEnsureCorrectEdit);
135 |     vi.mocked(ensureCorrectFileContent).mockImplementation(
136 |       mockEnsureCorrectFileContent,
137 |     );
138 | 
139 |     // Now that mock instances are initialized, set the mock implementations for config getters
140 |     mockConfigInternal.getGeminiClient.mockReturnValue(
141 |       mockGeminiClientInstance,
142 |     );
143 |     mockConfigInternal.getBaseLlmClient.mockReturnValue(
144 |       mockBaseLlmClientInstance,
145 |     );
146 | 
147 |     tool = new WriteFileTool(mockConfig);
148 | 
149 |     // Reset mocks before each test
150 |     mockConfigInternal.getApprovalMode.mockReturnValue(ApprovalMode.DEFAULT);
151 |     mockConfigInternal.setApprovalMode.mockClear();
152 |     mockEnsureCorrectEdit.mockReset();
153 |     mockEnsureCorrectFileContent.mockReset();
154 | 
155 |     // Default mock implementations that return valid structures
156 |     mockEnsureCorrectEdit.mockImplementation(
157 |       async (
158 |         filePath: string,
159 |         _currentContent: string,
160 |         params: EditToolParams,
161 |         _client: GeminiClient,
162 |         _baseClient: BaseLlmClient,
163 |         signal?: AbortSignal,
164 |       ): Promise<CorrectedEditResult> => {
165 |         if (signal?.aborted) {
166 |           return Promise.reject(new Error('Aborted'));
167 |         }
168 |         return Promise.resolve({
169 |           params: { ...params, new_string: params.new_string ?? '' },
170 |           occurrences: 1,
171 |         });
172 |       },
173 |     );
174 |     mockEnsureCorrectFileContent.mockImplementation(
175 |       async (
176 |         content: string,
177 |         _baseClient: BaseLlmClient,
178 |         signal?: AbortSignal,
179 |       ): Promise<string> => {
180 |         if (signal?.aborted) {
181 |           return Promise.reject(new Error('Aborted'));
182 |         }
183 |         return Promise.resolve(content ?? '');
184 |       },
185 |     );
186 |   });
187 | 
188 |   afterEach(() => {
189 |     // Clean up the temporary directories
190 |     if (fs.existsSync(tempDir)) {
191 |       fs.rmSync(tempDir, { recursive: true, force: true });
192 |     }
193 |     if (fs.existsSync(rootDir)) {
194 |       fs.rmSync(rootDir, { recursive: true, force: true });
195 |     }
196 |     vi.clearAllMocks();
197 |   });
198 | 
199 |   describe('build', () => {
200 |     it('should return an invocation for a valid absolute path within root', () => {
201 |       const params = {
202 |         file_path: path.join(rootDir, 'test.txt'),
203 |         content: 'hello',
204 |       };
205 |       const invocation = tool.build(params);
206 |       expect(invocation).toBeDefined();
207 |       expect(invocation.params).toEqual(params);
208 |     });
209 | 
210 |     it('should throw an error for a relative path', () => {
211 |       const params = { file_path: 'test.txt', content: 'hello' };
212 |       expect(() => tool.build(params)).toThrow(/File path must be absolute/);
213 |     });
214 | 
215 |     it('should throw an error for a path outside root', () => {
216 |       const outsidePath = path.resolve(tempDir, 'outside-root.txt');
217 |       const params = {
218 |         file_path: outsidePath,
219 |         content: 'hello',
220 |       };
221 |       expect(() => tool.build(params)).toThrow(
222 |         /File path must be within one of the workspace directories/,
223 |       );
224 |     });
225 | 
226 |     it('should throw an error if path is a directory', () => {
227 |       const dirAsFilePath = path.join(rootDir, 'a_directory');
228 |       fs.mkdirSync(dirAsFilePath);
229 |       const params = {
230 |         file_path: dirAsFilePath,
231 |         content: 'hello',
232 |       };
233 |       expect(() => tool.build(params)).toThrow(
234 |         `Path is a directory, not a file: ${dirAsFilePath}`,
235 |       );
236 |     });
237 | 
238 |     it('should throw an error if the content is null', () => {
239 |       const dirAsFilePath = path.join(rootDir, 'a_directory');
240 |       fs.mkdirSync(dirAsFilePath);
241 |       const params = {
242 |         file_path: dirAsFilePath,
243 |         content: null,
244 |       } as unknown as WriteFileToolParams; // Intentionally non-conforming
245 |       expect(() => tool.build(params)).toThrow('params/content must be string');
246 |     });
247 | 
248 |     it('should throw error if the file_path is empty', () => {
249 |       const dirAsFilePath = path.join(rootDir, 'a_directory');
250 |       fs.mkdirSync(dirAsFilePath);
251 |       const params = {
252 |         file_path: '',
253 |         content: '',
254 |       };
255 |       expect(() => tool.build(params)).toThrow(`Missing or empty "file_path"`);
256 |     });
257 |   });
258 | 
259 |   describe('getCorrectedFileContent', () => {
260 |     it('should call ensureCorrectFileContent for a new file', async () => {
261 |       const filePath = path.join(rootDir, 'new_corrected_file.txt');
262 |       const proposedContent = 'Proposed new content.';
263 |       const correctedContent = 'Corrected new content.';
264 |       const abortSignal = new AbortController().signal;
265 |       // Ensure the mock is set for this specific test case if needed, or rely on beforeEach
266 |       mockEnsureCorrectFileContent.mockResolvedValue(correctedContent);
267 | 
268 |       const result = await getCorrectedFileContent(
269 |         mockConfig,
270 |         filePath,
271 |         proposedContent,
272 |         abortSignal,
273 |       );
274 | 
275 |       expect(mockEnsureCorrectFileContent).toHaveBeenCalledWith(
276 |         proposedContent,
277 |         mockBaseLlmClientInstance,
278 |         abortSignal,
279 |       );
280 |       expect(mockEnsureCorrectEdit).not.toHaveBeenCalled();
281 |       expect(result.correctedContent).toBe(correctedContent);
282 |       expect(result.originalContent).toBe('');
283 |       expect(result.fileExists).toBe(false);
284 |       expect(result.error).toBeUndefined();
285 |     });
286 | 
287 |     it('should call ensureCorrectEdit for an existing file', async () => {
288 |       const filePath = path.join(rootDir, 'existing_corrected_file.txt');
289 |       const originalContent = 'Original existing content.';
290 |       const proposedContent = 'Proposed replacement content.';
291 |       const correctedProposedContent = 'Corrected replacement content.';
292 |       const abortSignal = new AbortController().signal;
293 |       fs.writeFileSync(filePath, originalContent, 'utf8');
294 | 
295 |       // Ensure this mock is active and returns the correct structure
296 |       mockEnsureCorrectEdit.mockResolvedValue({
297 |         params: {
298 |           file_path: filePath,
299 |           old_string: originalContent,
300 |           new_string: correctedProposedContent,
301 |         },
302 |         occurrences: 1,
303 |       } as CorrectedEditResult);
304 | 
305 |       const result = await getCorrectedFileContent(
306 |         mockConfig,
307 |         filePath,
308 |         proposedContent,
309 |         abortSignal,
310 |       );
311 | 
312 |       expect(mockEnsureCorrectEdit).toHaveBeenCalledWith(
313 |         filePath,
314 |         originalContent,
315 |         {
316 |           old_string: originalContent,
317 |           new_string: proposedContent,
318 |           file_path: filePath,
319 |         },
320 |         mockGeminiClientInstance,
321 |         mockBaseLlmClientInstance,
322 |         abortSignal,
323 |       );
324 |       expect(mockEnsureCorrectFileContent).not.toHaveBeenCalled();
325 |       expect(result.correctedContent).toBe(correctedProposedContent);
326 |       expect(result.originalContent).toBe(originalContent);
327 |       expect(result.fileExists).toBe(true);
328 |       expect(result.error).toBeUndefined();
329 |     });
330 | 
331 |     it('should return error if reading an existing file fails (e.g. permissions)', async () => {
332 |       const filePath = path.join(rootDir, 'unreadable_file.txt');
333 |       const proposedContent = 'some content';
334 |       const abortSignal = new AbortController().signal;
335 |       fs.writeFileSync(filePath, 'content', { mode: 0o000 });
336 | 
337 |       const readError = new Error('Permission denied');
338 |       vi.spyOn(fsService, 'readTextFile').mockImplementationOnce(() =>
339 |         Promise.reject(readError),
340 |       );
341 | 
342 |       const result = await getCorrectedFileContent(
343 |         mockConfig,
344 |         filePath,
345 |         proposedContent,
346 |         abortSignal,
347 |       );
348 | 
349 |       expect(fsService.readTextFile).toHaveBeenCalledWith(filePath);
350 |       expect(mockEnsureCorrectEdit).not.toHaveBeenCalled();
351 |       expect(mockEnsureCorrectFileContent).not.toHaveBeenCalled();
352 |       expect(result.correctedContent).toBe(proposedContent);
353 |       expect(result.originalContent).toBe('');
354 |       expect(result.fileExists).toBe(true);
355 |       expect(result.error).toEqual({
356 |         message: 'Permission denied',
357 |         code: undefined,
358 |       });
359 | 
360 |       fs.chmodSync(filePath, 0o600);
361 |     });
362 |   });
363 | 
364 |   describe('shouldConfirmExecute', () => {
365 |     const abortSignal = new AbortController().signal;
366 | 
367 |     it('should return false if _getCorrectedFileContent returns an error', async () => {
368 |       const filePath = path.join(rootDir, 'confirm_error_file.txt');
369 |       const params = { file_path: filePath, content: 'test content' };
370 |       fs.writeFileSync(filePath, 'original', { mode: 0o000 });
371 | 
372 |       const readError = new Error('Simulated read error for confirmation');
373 |       vi.spyOn(fsService, 'readTextFile').mockImplementationOnce(() =>
374 |         Promise.reject(readError),
375 |       );
376 | 
377 |       const invocation = tool.build(params);
378 |       const confirmation = await invocation.shouldConfirmExecute(abortSignal);
379 |       expect(confirmation).toBe(false);
380 | 
381 |       fs.chmodSync(filePath, 0o600);
382 |     });
383 | 
384 |     it('should request confirmation with diff for a new file (with corrected content)', async () => {
385 |       const filePath = path.join(rootDir, 'confirm_new_file.txt');
386 |       const proposedContent = 'Proposed new content for confirmation.';
387 |       const correctedContent = 'Corrected new content for confirmation.';
388 |       mockEnsureCorrectFileContent.mockResolvedValue(correctedContent); // Ensure this mock is active
389 | 
390 |       const params = { file_path: filePath, content: proposedContent };
391 |       const invocation = tool.build(params);
392 |       const confirmation = (await invocation.shouldConfirmExecute(
393 |         abortSignal,
394 |       )) as ToolEditConfirmationDetails;
395 | 
396 |       expect(mockEnsureCorrectFileContent).toHaveBeenCalledWith(
397 |         proposedContent,
398 |         mockBaseLlmClientInstance,
399 |         abortSignal,
400 |       );
401 |       expect(confirmation).toEqual(
402 |         expect.objectContaining({
403 |           title: `Confirm Write: ${path.basename(filePath)}`,
404 |           fileName: 'confirm_new_file.txt',
405 |           fileDiff: expect.stringContaining(correctedContent),
406 |         }),
407 |       );
408 |       expect(confirmation.fileDiff).toMatch(
409 |         /--- confirm_new_file.txt\tCurrent/,
410 |       );
411 |       expect(confirmation.fileDiff).toMatch(
412 |         /\+\+\+ confirm_new_file.txt\tProposed/,
413 |       );
414 |     });
415 | 
416 |     it('should request confirmation with diff for an existing file (with corrected content)', async () => {
417 |       const filePath = path.join(rootDir, 'confirm_existing_file.txt');
418 |       const originalContent = 'Original content for confirmation.';
419 |       const proposedContent = 'Proposed replacement for confirmation.';
420 |       const correctedProposedContent =
421 |         'Corrected replacement for confirmation.';
422 |       fs.writeFileSync(filePath, originalContent, 'utf8');
423 | 
424 |       mockEnsureCorrectEdit.mockResolvedValue({
425 |         params: {
426 |           file_path: filePath,
427 |           old_string: originalContent,
428 |           new_string: correctedProposedContent,
429 |         },
430 |         occurrences: 1,
431 |       });
432 | 
433 |       const params = { file_path: filePath, content: proposedContent };
434 |       const invocation = tool.build(params);
435 |       const confirmation = (await invocation.shouldConfirmExecute(
436 |         abortSignal,
437 |       )) as ToolEditConfirmationDetails;
438 | 
439 |       expect(mockEnsureCorrectEdit).toHaveBeenCalledWith(
440 |         filePath,
441 |         originalContent,
442 |         {
443 |           old_string: originalContent,
444 |           new_string: proposedContent,
445 |           file_path: filePath,
446 |         },
447 |         mockGeminiClientInstance,
448 |         mockBaseLlmClientInstance,
449 |         abortSignal,
450 |       );
451 |       expect(confirmation).toEqual(
452 |         expect.objectContaining({
453 |           title: `Confirm Write: ${path.basename(filePath)}`,
454 |           fileName: 'confirm_existing_file.txt',
455 |           fileDiff: expect.stringContaining(correctedProposedContent),
456 |         }),
457 |       );
458 |       expect(confirmation.fileDiff).toMatch(
459 |         originalContent.replace(/[.*+?^${}()|[\\]\\]/g, '\\$&'),
460 |       );
461 |     });
462 | 
463 |     describe('with IDE integration', () => {
464 |       beforeEach(() => {
465 |         // Enable IDE mode and set connection status for these tests
466 |         mockConfigInternal.getIdeMode.mockReturnValue(true);
467 |         mockIdeClient.isDiffingEnabled.mockReturnValue(true);
468 |         mockIdeClient.openDiff.mockResolvedValue({
469 |           status: 'accepted',
470 |           content: 'ide-modified-content',
471 |         });
472 |       });
473 | 
474 |       it('should call openDiff and await it when in IDE mode and connected', async () => {
475 |         const filePath = path.join(rootDir, 'ide_confirm_file.txt');
476 |         const params = { file_path: filePath, content: 'test' };
477 |         const invocation = tool.build(params);
478 | 
479 |         const confirmation = (await invocation.shouldConfirmExecute(
480 |           abortSignal,
481 |         )) as ToolEditConfirmationDetails;
482 | 
483 |         expect(mockIdeClient.openDiff).toHaveBeenCalledWith(
484 |           filePath,
485 |           'test', // The corrected content
486 |         );
487 |         // Ensure the promise is awaited by checking the result
488 |         expect(confirmation.ideConfirmation).toBeDefined();
489 |         await confirmation.ideConfirmation; // Should resolve
490 |       });
491 | 
492 |       it('should not call openDiff if not in IDE mode', async () => {
493 |         mockConfigInternal.getIdeMode.mockReturnValue(false);
494 |         const filePath = path.join(rootDir, 'ide_disabled_file.txt');
495 |         const params = { file_path: filePath, content: 'test' };
496 |         const invocation = tool.build(params);
497 | 
498 |         await invocation.shouldConfirmExecute(abortSignal);
499 | 
500 |         expect(mockIdeClient.openDiff).not.toHaveBeenCalled();
501 |       });
502 | 
503 |       it('should not call openDiff if IDE is not connected', async () => {
504 |         mockIdeClient.isDiffingEnabled.mockReturnValue(false);
505 |         const filePath = path.join(rootDir, 'ide_disconnected_file.txt');
506 |         const params = { file_path: filePath, content: 'test' };
507 |         const invocation = tool.build(params);
508 | 
509 |         await invocation.shouldConfirmExecute(abortSignal);
510 | 
511 |         expect(mockIdeClient.openDiff).not.toHaveBeenCalled();
512 |       });
513 | 
514 |       it('should update params.content with IDE content when onConfirm is called', async () => {
515 |         const filePath = path.join(rootDir, 'ide_onconfirm_file.txt');
516 |         const params = { file_path: filePath, content: 'original-content' };
517 |         const invocation = tool.build(params);
518 | 
519 |         // This is the key part: get the confirmation details
520 |         const confirmation = (await invocation.shouldConfirmExecute(
521 |           abortSignal,
522 |         )) as ToolEditConfirmationDetails;
523 | 
524 |         // The `onConfirm` function should exist on the details object
525 |         expect(confirmation.onConfirm).toBeDefined();
526 | 
527 |         // Call `onConfirm` to trigger the logic that updates the content
528 |         await confirmation.onConfirm!(ToolConfirmationOutcome.ProceedOnce);
529 | 
530 |         // Now, check if the original `params` object (captured by the invocation) was modified
531 |         expect(invocation.params.content).toBe('ide-modified-content');
532 |       });
533 | 
534 |       it('should not await ideConfirmation promise', async () => {
535 |         const filePath = path.join(rootDir, 'ide_no_await_file.txt');
536 |         const params = { file_path: filePath, content: 'test' };
537 |         const invocation = tool.build(params);
538 | 
539 |         let diffPromiseResolved = false;
540 |         const diffPromise = new Promise<DiffUpdateResult>((resolve) => {
541 |           setTimeout(() => {
542 |             diffPromiseResolved = true;
543 |             resolve({ status: 'accepted', content: 'ide-modified-content' });
544 |           }, 50); // A small delay to ensure the check happens before resolution
545 |         });
546 |         mockIdeClient.openDiff.mockReturnValue(diffPromise);
547 | 
548 |         const confirmation = (await invocation.shouldConfirmExecute(
549 |           abortSignal,
550 |         )) as ToolEditConfirmationDetails;
551 | 
552 |         // This is the key check: the confirmation details should be returned
553 |         // *before* the diffPromise is resolved.
554 |         expect(diffPromiseResolved).toBe(false);
555 |         expect(confirmation).toBeDefined();
556 |         expect(confirmation.ideConfirmation).toBe(diffPromise);
557 | 
558 |         // Now, we can await the promise to let the test finish cleanly.
559 |         await diffPromise;
560 |         expect(diffPromiseResolved).toBe(true);
561 |       });
562 |     });
563 |   });
564 | 
565 |   describe('execute', () => {
566 |     const abortSignal = new AbortController().signal;
567 | 
568 |     it('should return error if _getCorrectedFileContent returns an error during execute', async () => {
569 |       const filePath = path.join(rootDir, 'execute_error_file.txt');
570 |       const params = { file_path: filePath, content: 'test content' };
571 |       fs.writeFileSync(filePath, 'original', { mode: 0o000 });
572 | 
573 |       vi.spyOn(fsService, 'readTextFile').mockImplementationOnce(() => {
574 |         const readError = new Error('Simulated read error for execute');
575 |         return Promise.reject(readError);
576 |       });
577 | 
578 |       const invocation = tool.build(params);
579 |       const result = await invocation.execute(abortSignal);
580 |       expect(result.llmContent).toContain('Error checking existing file');
581 |       expect(result.returnDisplay).toMatch(
[TRUNCATED]
```

src/tools/write-file.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import fs from 'node:fs';
8 | import path from 'node:path';
9 | import * as Diff from 'diff';
10 | import { WRITE_FILE_TOOL_NAME } from './tool-names.js';
11 | import type { Config } from '../config/config.js';
12 | import { ApprovalMode } from '../config/config.js';
13 | import type {
14 |   FileDiff,
15 |   ToolCallConfirmationDetails,
16 |   ToolEditConfirmationDetails,
17 |   ToolInvocation,
18 |   ToolLocation,
19 |   ToolResult,
20 | } from './tools.js';
21 | import {
22 |   BaseDeclarativeTool,
23 |   BaseToolInvocation,
24 |   Kind,
25 |   ToolConfirmationOutcome,
26 | } from './tools.js';
27 | import { ToolErrorType } from './tool-error.js';
28 | import { makeRelative, shortenPath } from '../utils/paths.js';
29 | import { getErrorMessage, isNodeError } from '../utils/errors.js';
30 | import {
31 |   ensureCorrectEdit,
32 |   ensureCorrectFileContent,
33 | } from '../utils/editCorrector.js';
34 | import { DEFAULT_DIFF_OPTIONS, getDiffStat } from './diffOptions.js';
35 | import type {
36 |   ModifiableDeclarativeTool,
37 |   ModifyContext,
38 | } from './modifiable-tool.js';
39 | import { IdeClient } from '../ide/ide-client.js';
40 | import { logFileOperation } from '../telemetry/loggers.js';
41 | import { FileOperationEvent } from '../telemetry/types.js';
42 | import { FileOperation } from '../telemetry/metrics.js';
43 | import { getSpecificMimeType } from '../utils/fileUtils.js';
44 | import { getLanguageFromFilePath } from '../utils/language-detection.js';
45 | 
46 | /**
47 |  * Parameters for the WriteFile tool
48 |  */
49 | export interface WriteFileToolParams {
50 |   /**
51 |    * The absolute path to the file to write to
52 |    */
53 |   file_path: string;
54 | 
55 |   /**
56 |    * The content to write to the file
57 |    */
58 |   content: string;
59 | 
60 |   /**
61 |    * Whether the proposed content was modified by the user.
62 |    */
63 |   modified_by_user?: boolean;
64 | 
65 |   /**
66 |    * Initially proposed content.
67 |    */
68 |   ai_proposed_content?: string;
69 | }
70 | 
71 | interface GetCorrectedFileContentResult {
72 |   originalContent: string;
73 |   correctedContent: string;
74 |   fileExists: boolean;
75 |   error?: { message: string; code?: string };
76 | }
77 | 
78 | export async function getCorrectedFileContent(
79 |   config: Config,
80 |   filePath: string,
81 |   proposedContent: string,
82 |   abortSignal: AbortSignal,
83 | ): Promise<GetCorrectedFileContentResult> {
84 |   let originalContent = '';
85 |   let fileExists = false;
86 |   let correctedContent = proposedContent;
87 | 
88 |   try {
89 |     originalContent = await config
90 |       .getFileSystemService()
91 |       .readTextFile(filePath);
92 |     fileExists = true; // File exists and was read
93 |   } catch (err) {
94 |     if (isNodeError(err) && err.code === 'ENOENT') {
95 |       fileExists = false;
96 |       originalContent = '';
97 |     } else {
98 |       // File exists but could not be read (permissions, etc.)
99 |       fileExists = true; // Mark as existing but problematic
100 |       originalContent = ''; // Can't use its content
101 |       const error = {
102 |         message: getErrorMessage(err),
103 |         code: isNodeError(err) ? err.code : undefined,
104 |       };
105 |       // Return early as we can't proceed with content correction meaningfully
106 |       return { originalContent, correctedContent, fileExists, error };
107 |     }
108 |   }
109 | 
110 |   // If readError is set, we have returned.
111 |   // So, file was either read successfully (fileExists=true, originalContent set)
112 |   // or it was ENOENT (fileExists=false, originalContent='').
113 | 
114 |   if (fileExists) {
115 |     // This implies originalContent is available
116 |     const { params: correctedParams } = await ensureCorrectEdit(
117 |       filePath,
118 |       originalContent,
119 |       {
120 |         old_string: originalContent, // Treat entire current content as old_string
121 |         new_string: proposedContent,
122 |         file_path: filePath,
123 |       },
124 |       config.getGeminiClient(),
125 |       config.getBaseLlmClient(),
126 |       abortSignal,
127 |     );
128 |     correctedContent = correctedParams.new_string;
129 |   } else {
130 |     // This implies new file (ENOENT)
131 |     correctedContent = await ensureCorrectFileContent(
132 |       proposedContent,
133 |       config.getBaseLlmClient(),
134 |       abortSignal,
135 |     );
136 |   }
137 |   return { originalContent, correctedContent, fileExists };
138 | }
139 | 
140 | class WriteFileToolInvocation extends BaseToolInvocation<
141 |   WriteFileToolParams,
142 |   ToolResult
143 | > {
144 |   constructor(
145 |     private readonly config: Config,
146 |     params: WriteFileToolParams,
147 |   ) {
148 |     super(params);
149 |   }
150 | 
151 |   override toolLocations(): ToolLocation[] {
152 |     return [{ path: this.params.file_path }];
153 |   }
154 | 
155 |   override getDescription(): string {
156 |     const relativePath = makeRelative(
157 |       this.params.file_path,
158 |       this.config.getTargetDir(),
159 |     );
160 |     return `Writing to ${shortenPath(relativePath)}`;
161 |   }
162 | 
163 |   override async shouldConfirmExecute(
164 |     abortSignal: AbortSignal,
165 |   ): Promise<ToolCallConfirmationDetails | false> {
166 |     if (this.config.getApprovalMode() === ApprovalMode.AUTO_EDIT) {
167 |       return false;
168 |     }
169 | 
170 |     const correctedContentResult = await getCorrectedFileContent(
171 |       this.config,
172 |       this.params.file_path,
173 |       this.params.content,
174 |       abortSignal,
175 |     );
176 | 
177 |     if (correctedContentResult.error) {
178 |       // If file exists but couldn't be read, we can't show a diff for confirmation.
179 |       return false;
180 |     }
181 | 
182 |     const { originalContent, correctedContent } = correctedContentResult;
183 |     const relativePath = makeRelative(
184 |       this.params.file_path,
185 |       this.config.getTargetDir(),
186 |     );
187 |     const fileName = path.basename(this.params.file_path);
188 | 
189 |     const fileDiff = Diff.createPatch(
190 |       fileName,
191 |       originalContent, // Original content (empty if new file or unreadable)
192 |       correctedContent, // Content after potential correction
193 |       'Current',
194 |       'Proposed',
195 |       DEFAULT_DIFF_OPTIONS,
196 |     );
197 | 
198 |     const ideClient = await IdeClient.getInstance();
199 |     const ideConfirmation =
200 |       this.config.getIdeMode() && ideClient.isDiffingEnabled()
201 |         ? ideClient.openDiff(this.params.file_path, correctedContent)
202 |         : undefined;
203 | 
204 |     const confirmationDetails: ToolEditConfirmationDetails = {
205 |       type: 'edit',
206 |       title: `Confirm Write: ${shortenPath(relativePath)}`,
207 |       fileName,
208 |       filePath: this.params.file_path,
209 |       fileDiff,
210 |       originalContent,
211 |       newContent: correctedContent,
212 |       onConfirm: async (outcome: ToolConfirmationOutcome) => {
213 |         if (outcome === ToolConfirmationOutcome.ProceedAlways) {
214 |           this.config.setApprovalMode(ApprovalMode.AUTO_EDIT);
215 |         }
216 | 
217 |         if (ideConfirmation) {
218 |           const result = await ideConfirmation;
219 |           if (result.status === 'accepted' && result.content) {
220 |             this.params.content = result.content;
221 |           }
222 |         }
223 |       },
224 |       ideConfirmation,
225 |     };
226 |     return confirmationDetails;
227 |   }
228 | 
229 |   async execute(abortSignal: AbortSignal): Promise<ToolResult> {
230 |     const { file_path, content, ai_proposed_content, modified_by_user } =
231 |       this.params;
232 |     const correctedContentResult = await getCorrectedFileContent(
233 |       this.config,
234 |       file_path,
235 |       content,
236 |       abortSignal,
237 |     );
238 | 
239 |     if (correctedContentResult.error) {
240 |       const errDetails = correctedContentResult.error;
241 |       const errorMsg = errDetails.code
242 |         ? `Error checking existing file '${file_path}': ${errDetails.message} (${errDetails.code})`
243 |         : `Error checking existing file: ${errDetails.message}`;
244 |       return {
245 |         llmContent: errorMsg,
246 |         returnDisplay: errorMsg,
247 |         error: {
248 |           message: errorMsg,
249 |           type: ToolErrorType.FILE_WRITE_FAILURE,
250 |         },
251 |       };
252 |     }
253 | 
254 |     const {
255 |       originalContent,
256 |       correctedContent: fileContent,
257 |       fileExists,
258 |     } = correctedContentResult;
259 |     // fileExists is true if the file existed (and was readable or unreadable but caught by readError).
260 |     // fileExists is false if the file did not exist (ENOENT).
261 |     const isNewFile =
262 |       !fileExists ||
263 |       (correctedContentResult.error !== undefined &&
264 |         !correctedContentResult.fileExists);
265 | 
266 |     try {
267 |       const dirName = path.dirname(file_path);
268 |       if (!fs.existsSync(dirName)) {
269 |         fs.mkdirSync(dirName, { recursive: true });
270 |       }
271 | 
272 |       await this.config
273 |         .getFileSystemService()
274 |         .writeTextFile(file_path, fileContent);
275 | 
276 |       // Generate diff for display result
277 |       const fileName = path.basename(file_path);
278 |       // If there was a readError, originalContent in correctedContentResult is '',
279 |       // but for the diff, we want to show the original content as it was before the write if possible.
280 |       // However, if it was unreadable, currentContentForDiff will be empty.
281 |       const currentContentForDiff = correctedContentResult.error
282 |         ? '' // Or some indicator of unreadable content
283 |         : originalContent;
284 | 
285 |       const fileDiff = Diff.createPatch(
286 |         fileName,
287 |         currentContentForDiff,
288 |         fileContent,
289 |         'Original',
290 |         'Written',
291 |         DEFAULT_DIFF_OPTIONS,
292 |       );
293 | 
294 |       const originallyProposedContent = ai_proposed_content || content;
295 |       const diffStat = getDiffStat(
296 |         fileName,
297 |         currentContentForDiff,
298 |         originallyProposedContent,
299 |         content,
300 |       );
301 | 
302 |       const llmSuccessMessageParts = [
303 |         isNewFile
304 |           ? `Successfully created and wrote to new file: ${file_path}.`
305 |           : `Successfully overwrote file: ${file_path}.`,
306 |       ];
307 |       if (modified_by_user) {
308 |         llmSuccessMessageParts.push(
309 |           `User modified the \`content\` to be: ${content}`,
310 |         );
311 |       }
312 | 
313 |       // Log file operation for telemetry (without diff_stat to avoid double-counting)
314 |       const mimetype = getSpecificMimeType(file_path);
315 |       const programmingLanguage = getLanguageFromFilePath(file_path);
316 |       const extension = path.extname(file_path);
317 |       const operation = isNewFile ? FileOperation.CREATE : FileOperation.UPDATE;
318 | 
319 |       logFileOperation(
320 |         this.config,
321 |         new FileOperationEvent(
322 |           WriteFileTool.Name,
323 |           operation,
324 |           fileContent.split('\n').length,
325 |           mimetype,
326 |           extension,
327 |           programmingLanguage,
328 |         ),
329 |       );
330 | 
331 |       const displayResult: FileDiff = {
332 |         fileDiff,
333 |         fileName,
334 |         originalContent: correctedContentResult.originalContent,
335 |         newContent: correctedContentResult.correctedContent,
336 |         diffStat,
337 |       };
338 | 
339 |       return {
340 |         llmContent: llmSuccessMessageParts.join(' '),
341 |         returnDisplay: displayResult,
342 |       };
343 |     } catch (error) {
344 |       // Capture detailed error information for debugging
345 |       let errorMsg: string;
346 |       let errorType = ToolErrorType.FILE_WRITE_FAILURE;
347 | 
348 |       if (isNodeError(error)) {
349 |         // Handle specific Node.js errors with their error codes
350 |         errorMsg = `Error writing to file '${file_path}': ${error.message} (${error.code})`;
351 | 
352 |         // Log specific error types for better debugging
353 |         if (error.code === 'EACCES') {
354 |           errorMsg = `Permission denied writing to file: ${file_path} (${error.code})`;
355 |           errorType = ToolErrorType.PERMISSION_DENIED;
356 |         } else if (error.code === 'ENOSPC') {
357 |           errorMsg = `No space left on device: ${file_path} (${error.code})`;
358 |           errorType = ToolErrorType.NO_SPACE_LEFT;
359 |         } else if (error.code === 'EISDIR') {
360 |           errorMsg = `Target is a directory, not a file: ${file_path} (${error.code})`;
361 |           errorType = ToolErrorType.TARGET_IS_DIRECTORY;
362 |         }
363 | 
364 |         // Include stack trace in debug mode for better troubleshooting
365 |         if (this.config.getDebugMode() && error.stack) {
366 |           console.error('Write file error stack:', error.stack);
367 |         }
368 |       } else if (error instanceof Error) {
369 |         errorMsg = `Error writing to file: ${error.message}`;
370 |       } else {
371 |         errorMsg = `Error writing to file: ${String(error)}`;
372 |       }
373 | 
374 |       return {
375 |         llmContent: errorMsg,
376 |         returnDisplay: errorMsg,
377 |         error: {
378 |           message: errorMsg,
379 |           type: errorType,
380 |         },
381 |       };
382 |     }
383 |   }
384 | }
385 | 
386 | /**
387 |  * Implementation of the WriteFile tool logic
388 |  */
389 | export class WriteFileTool
390 |   extends BaseDeclarativeTool<WriteFileToolParams, ToolResult>
391 |   implements ModifiableDeclarativeTool<WriteFileToolParams>
392 | {
393 |   static readonly Name: string = WRITE_FILE_TOOL_NAME;
394 | 
395 |   constructor(private readonly config: Config) {
396 |     super(
397 |       WriteFileTool.Name,
398 |       'WriteFile',
399 |       `Writes content to a specified file in the local filesystem.
400 | 
401 |       The user has the ability to modify \`content\`. If modified, this will be stated in the response.`,
402 |       Kind.Edit,
403 |       {
404 |         properties: {
405 |           file_path: {
406 |             description:
407 |               "The absolute path to the file to write to (e.g., '/home/user/project/file.txt'). Relative paths are not supported.",
408 |             type: 'string',
409 |           },
410 |           content: {
411 |             description: 'The content to write to the file.',
412 |             type: 'string',
413 |           },
414 |         },
415 |         required: ['file_path', 'content'],
416 |         type: 'object',
417 |       },
418 |     );
419 |   }
420 | 
421 |   protected override validateToolParamValues(
422 |     params: WriteFileToolParams,
423 |   ): string | null {
424 |     const filePath = params.file_path;
425 | 
426 |     if (!filePath) {
427 |       return `Missing or empty "file_path"`;
428 |     }
429 | 
430 |     if (!path.isAbsolute(filePath)) {
431 |       return `File path must be absolute: ${filePath}`;
432 |     }
433 | 
434 |     const workspaceContext = this.config.getWorkspaceContext();
435 |     if (!workspaceContext.isPathWithinWorkspace(filePath)) {
436 |       const directories = workspaceContext.getDirectories();
437 |       return `File path must be within one of the workspace directories: ${directories.join(
438 |         ', ',
439 |       )}`;
440 |     }
441 | 
442 |     try {
443 |       if (fs.existsSync(filePath)) {
444 |         const stats = fs.lstatSync(filePath);
445 |         if (stats.isDirectory()) {
446 |           return `Path is a directory, not a file: ${filePath}`;
447 |         }
448 |       }
449 |     } catch (statError: unknown) {
450 |       return `Error accessing path properties for validation: ${filePath}. Reason: ${
451 |         statError instanceof Error ? statError.message : String(statError)
452 |       }`;
453 |     }
454 | 
455 |     return null;
456 |   }
457 | 
458 |   protected createInvocation(
459 |     params: WriteFileToolParams,
460 |   ): ToolInvocation<WriteFileToolParams, ToolResult> {
461 |     return new WriteFileToolInvocation(this.config, params);
462 |   }
463 | 
464 |   getModifyContext(
465 |     abortSignal: AbortSignal,
466 |   ): ModifyContext<WriteFileToolParams> {
467 |     return {
468 |       getFilePath: (params: WriteFileToolParams) => params.file_path,
469 |       getCurrentContent: async (params: WriteFileToolParams) => {
470 |         const correctedContentResult = await getCorrectedFileContent(
471 |           this.config,
472 |           params.file_path,
473 |           params.content,
474 |           abortSignal,
475 |         );
476 |         return correctedContentResult.originalContent;
477 |       },
478 |       getProposedContent: async (params: WriteFileToolParams) => {
479 |         const correctedContentResult = await getCorrectedFileContent(
480 |           this.config,
481 |           params.file_path,
482 |           params.content,
483 |           abortSignal,
484 |         );
485 |         return correctedContentResult.correctedContent;
486 |       },
487 |       createUpdatedParams: (
488 |         _oldContent: string,
489 |         modifiedProposedContent: string,
490 |         originalParams: WriteFileToolParams,
491 |       ) => {
492 |         const content = originalParams.content;
493 |         return {
494 |           ...originalParams,
495 |           ai_proposed_content: content,
496 |           content: modifiedProposedContent,
497 |           modified_by_user: true,
498 |         };
499 |       },
500 |     };
501 |   }
502 | }
```

src/tools/write-todos.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, expect, it } from 'vitest';
8 | import { WriteTodosTool, type WriteTodosToolParams } from './write-todos.js';
9 | 
10 | describe('WriteTodosTool', () => {
11 |   const tool = new WriteTodosTool();
12 |   const signal = new AbortController().signal;
13 | 
14 |   describe('validation', () => {
15 |     it('should not throw for valid parameters', async () => {
16 |       const params: WriteTodosToolParams = {
17 |         todos: [
18 |           { description: 'Task 1', status: 'pending' },
19 |           { description: 'Task 2', status: 'in_progress' },
20 |           { description: 'Task 3', status: 'completed' },
21 |         ],
22 |       };
23 |       await expect(tool.buildAndExecute(params, signal)).resolves.toBeDefined();
24 |     });
25 | 
26 |     it('should not throw for an empty list', async () => {
27 |       const params: WriteTodosToolParams = {
28 |         todos: [],
29 |       };
30 |       await expect(tool.buildAndExecute(params, signal)).resolves.toBeDefined();
31 |     });
32 | 
33 |     it('should throw an error if todos is not an array', async () => {
34 |       const params = {
35 |         todos: 'not-an-array',
36 |       } as unknown as WriteTodosToolParams;
37 |       await expect(tool.buildAndExecute(params, signal)).rejects.toThrow(
38 |         'params/todos must be array',
39 |       );
40 |     });
41 | 
42 |     it('should throw an error if a todo item is not an object', async () => {
43 |       const params = {
44 |         todos: ['not-an-object'],
45 |       } as unknown as WriteTodosToolParams;
46 |       await expect(tool.buildAndExecute(params, signal)).rejects.toThrow(
47 |         'params/todos/0 must be object',
48 |       );
49 |     });
50 | 
51 |     it('should throw an error if a todo description is missing or empty', async () => {
52 |       const params: WriteTodosToolParams = {
53 |         todos: [{ description: '  ', status: 'pending' }],
54 |       };
55 |       await expect(tool.buildAndExecute(params, signal)).rejects.toThrow(
56 |         'Each todo must have a non-empty description string',
57 |       );
58 |     });
59 | 
60 |     it('should throw an error if a todo status is invalid', async () => {
61 |       const params = {
62 |         todos: [{ description: 'Task 1', status: 'invalid-status' }],
63 |       } as unknown as WriteTodosToolParams;
64 |       await expect(tool.buildAndExecute(params, signal)).rejects.toThrow(
65 |         'params/todos/0/status must be equal to one of the allowed values',
66 |       );
67 |     });
68 | 
69 |     it('should throw an error if more than one task is in_progress', async () => {
70 |       const params: WriteTodosToolParams = {
71 |         todos: [
72 |           { description: 'Task 1', status: 'in_progress' },
73 |           { description: 'Task 2', status: 'in_progress' },
74 |         ],
75 |       };
76 |       await expect(tool.buildAndExecute(params, signal)).rejects.toThrow(
77 |         'Invalid parameters: Only one task can be "in_progress" at a time.',
78 |       );
79 |     });
80 |   });
81 | 
82 |   describe('execute', () => {
83 |     it('should return a success message for clearing the list', async () => {
84 |       const params: WriteTodosToolParams = {
85 |         todos: [],
86 |       };
87 |       const result = await tool.buildAndExecute(params, signal);
88 |       expect(result.llmContent).toBe('Successfully cleared the todo list.');
89 |       expect(result.returnDisplay).toBe('Successfully cleared the todo list.');
90 |     });
91 | 
92 |     it('should return a formatted todo list on success', async () => {
93 |       const params: WriteTodosToolParams = {
94 |         todos: [
95 |           { description: 'First task', status: 'completed' },
96 |           { description: 'Second task', status: 'in_progress' },
97 |           { description: 'Third task', status: 'pending' },
98 |         ],
99 |       };
100 |       const result = await tool.buildAndExecute(params, signal);
101 |       const expectedOutput = `Successfully updated the todo list. The current list is now:
102 | 1. [completed] First task
103 | 2. [in_progress] Second task
104 | 3. [pending] Third task`;
105 |       expect(result.llmContent).toBe(expectedOutput);
106 |       expect(result.returnDisplay).toBe(expectedOutput);
107 |     });
108 |   });
109 | });
```

src/tools/write-todos.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { ToolInvocation } from './tools.js';
8 | import {
9 |   BaseDeclarativeTool,
10 |   BaseToolInvocation,
11 |   Kind,
12 |   type ToolResult,
13 | } from './tools.js';
14 | import { WRITE_TODOS_TOOL_NAME } from './tool-names.js';
15 | 
16 | // Inspired by langchain/deepagents.
17 | export const WRITE_TODOS_DESCRIPTION = `This tool can help you list out the current subtasks that are required to be completed for a given user request. The list of subtasks helps you keep track of the current task, organize complex queries and help ensure that you don't miss any steps. With this list, the user can also see the current progress you are making in executing a given task.
18 | 
19 | Depending on the task complexity, you should first divide a given task into subtasks and then use this tool to list out the subtasks that are required to be completed for a given user request.
20 | Each of the subtasks should be clear and distinct. 
21 | 
22 | Use this tool for complex queries that require multiple steps. If you find that the request is actually complex after you have started executing the user task, create a todo list and use it. If execution of the user task requires multiple steps, planning and generally is higher complexity than a simple Q&A, use this tool.
23 | 
24 | DO NOT use this tool for simple tasks that can be completed in less than 2 steps. If the user query is simple and straightforward, do not use the tool. If you can respond with an answer in a single turn then this tool is not required.
25 | 
26 | ## Task state definitions
27 | 
28 | - pending: Work has not begun on a given subtask.
29 | - in_progress: Marked just prior to beginning work on a given subtask. You should only have one subtask as in_progress at a time.
30 | - completed: Subtask was successfully completed with no errors or issues. If the subtask required more steps to complete, update the todo list with the subtasks. All steps should be identified as completed only when they are completed.
31 | - cancelled: As you update the todo list, some tasks are not required anymore due to the dynamic nature of the task. In this case, mark the subtasks as cancelled.
32 | 
33 | 
34 | ## Methodology for using this tool
35 | 1. Use this todo list list as soon as you receive a user request based on the complexity of the task.
36 | 2. Keep track of every subtask that you update the list with.
37 | 3. Mark a subtask as in_progress before you begin working on it. You should only have one subtask as in_progress at a time.
38 | 4. Update the subtask list as you proceed in executing the task. The subtask list is not static and should reflect your progress and current plans, which may evolve as you acquire new information.
39 | 5. Mark a subtask as completed when you have completed it.
40 | 6. Mark a subtask as cancelled if the subtask is no longer needed.
41 | 7. You must update the todo list as soon as you start, stop or cancel a subtask. Don't batch or wait to update the todo list.
42 | 
43 | 
44 | ## Examples of When to Use the Todo List
45 | 
46 | <example>
47 | User request: Create a website with a React for creating fancy logos using gemini-2.5-flash-image
48 | 
49 | ToDo list created by the agent:
50 | 1. Initialize a new React project environment (e.g., using Vite).
51 | 2. Design and build the core UI components: a text input (prompt field) for the logo description, selection controls for style parameters (if the API supports them), and an image preview area.
52 | 3. Implement state management (e.g., React Context or Zustand) to manage the user's input prompt, the API loading status (pending, success, error), and the resulting image data.
53 | 4. Create an API service module within the React app (using "fetch" or "axios") to securely format and send the prompt data via an HTTP POST request to the specified "gemini-2.5-flash-image" (Gemini model) endpoint.
54 | 5. Implement asynchronous logic to handle the API call: show a loading indicator while the request is pending, retrieve the generated image (e.g., as a URL or base64 string) upon success, and display any errors.
55 | 6. Display the returned "fancy logo" from the API response in the preview area component.
56 | 7. Add functionality (e.g., a "Download" button) to allow the user to save the generated image file.
57 | 8. Deploy the application to a web server or hosting platform.
58 | 
59 | <reasoning>
60 | The agent used the todo list to break the task into distinct, manageable steps:
61 | 1. Building an entire interactive web application from scratch is a highly complex, multi-stage process involving setup, UI development, logic integration, and deployment.
62 | 2. The agent inferred the core functionality required for a "logo creator," such as UI controls for customization (Task 3) and an export feature (Task 7), which must be tracked as distinct goals.
63 | 3. The agent rightly inferred the requirement of an API service model for interacting with the image model endpoint.
64 | </reasoning>
65 | </example>
66 | 
67 | 
68 | ## Examples of When NOT to Use the Todo List
69 | 
70 | <example>
71 | User request: Ensure that the test <test file> passes.
72 | 
73 | Agent:
74 | <Goes into a loop of running the test, identifying errors, and updating the code until the test passes.>
75 | 
76 | <reasoning>
77 | The agent did not use the todo list because this task could be completed by a tight loop of execute test->edit->execute test.
78 | </reasoning>
79 | </example>
80 | `;
81 | 
82 | export type TodoStatus = 'pending' | 'in_progress' | 'completed' | 'cancelled';
83 | 
84 | export interface Todo {
85 |   description: string;
86 |   status: TodoStatus;
87 | }
88 | 
89 | export interface WriteTodosToolParams {
90 |   /**
91 |    * The full list of todos. This will overwrite any existing list.
92 |    */
93 |   todos: Todo[];
94 | }
95 | 
96 | class WriteTodosToolInvocation extends BaseToolInvocation<
97 |   WriteTodosToolParams,
98 |   ToolResult
99 | > {
100 |   getDescription(): string {
101 |     const count = this.params.todos?.length ?? 0;
102 |     if (count === 0) {
103 |       return 'Cleared todo list';
104 |     }
105 |     return `Set ${count} todo(s)`;
106 |   }
107 | 
108 |   async execute(
109 |     _signal: AbortSignal,
110 |     _updateOutput?: (output: string) => void,
111 |   ): Promise<ToolResult> {
112 |     const todos = this.params.todos ?? [];
113 |     const todoListString = todos
114 |       .map(
115 |         (todo, index) => `${index + 1}. [${todo.status}] ${todo.description}`,
116 |       )
117 |       .join('\n');
118 | 
119 |     const llmContent =
120 |       todos.length > 0
121 |         ? `Successfully updated the todo list. The current list is now:\n${todoListString}`
122 |         : 'Successfully cleared the todo list.';
123 | 
124 |     return {
125 |       llmContent,
126 |       returnDisplay: llmContent,
127 |     };
128 |   }
129 | }
130 | 
131 | export class WriteTodosTool extends BaseDeclarativeTool<
132 |   WriteTodosToolParams,
133 |   ToolResult
134 | > {
135 |   static readonly Name: string = WRITE_TODOS_TOOL_NAME;
136 | 
137 |   constructor() {
138 |     super(
139 |       WriteTodosTool.Name,
140 |       'Write Todos',
141 |       WRITE_TODOS_DESCRIPTION,
142 |       Kind.Other,
143 |       {
144 |         type: 'object',
145 |         properties: {
146 |           todos: {
147 |             type: 'array',
148 |             description:
149 |               'The complete list of todo items. This will replace the existing list.',
150 |             items: {
151 |               type: 'object',
152 |               description: 'A single todo item.',
153 |               properties: {
154 |                 description: {
155 |                   type: 'string',
156 |                   description: 'The description of the task.',
157 |                 },
158 |                 status: {
159 |                   type: 'string',
160 |                   description: 'The current status of the task.',
161 |                   enum: ['pending', 'in_progress', 'completed'],
162 |                 },
163 |               },
164 |               required: ['description', 'status'],
165 |             },
166 |           },
167 |         },
168 |         required: ['todos'],
169 |       },
170 |     );
171 |   }
172 | 
173 |   protected override validateToolParamValues(
174 |     params: WriteTodosToolParams,
175 |   ): string | null {
176 |     const todos = params?.todos;
177 |     if (!params || !Array.isArray(todos)) {
178 |       return '`todos` parameter must be an array';
179 |     }
180 | 
181 |     for (const todo of todos) {
182 |       if (typeof todo !== 'object' || todo === null) {
183 |         return 'Each todo item must be an object';
184 |       }
185 |       if (typeof todo.description !== 'string' || !todo.description.trim()) {
186 |         return 'Each todo must have a non-empty description string';
187 |       }
188 |       if (!['pending', 'in_progress', 'completed'].includes(todo.status)) {
189 |         return 'Each todo must have a valid status (pending, in_progress, or completed)';
190 |       }
191 |     }
192 | 
193 |     const inProgressCount = todos.filter(
194 |       (todo: Todo) => todo.status === 'in_progress',
195 |     ).length;
196 | 
197 |     if (inProgressCount > 1) {
198 |       return 'Invalid parameters: Only one task can be "in_progress" at a time.';
199 |     }
200 | 
201 |     return null;
202 |   }
203 | 
204 |   protected createInvocation(
205 |     params: WriteTodosToolParams,
206 |   ): ToolInvocation<WriteTodosToolParams, ToolResult> {
207 |     return new WriteTodosToolInvocation(params);
208 |   }
209 | }
```

src/utils/LruCache.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export class LruCache<K, V> {
8 |   private cache: Map<K, V>;
9 |   private maxSize: number;
10 | 
11 |   constructor(maxSize: number) {
12 |     this.cache = new Map<K, V>();
13 |     this.maxSize = maxSize;
14 |   }
15 | 
16 |   get(key: K): V | undefined {
17 |     const value = this.cache.get(key);
18 |     if (value) {
19 |       // Move to end to mark as recently used
20 |       this.cache.delete(key);
21 |       this.cache.set(key, value);
22 |     }
23 |     return value;
24 |   }
25 | 
26 |   set(key: K, value: V): void {
27 |     if (this.cache.has(key)) {
28 |       this.cache.delete(key);
29 |     } else if (this.cache.size >= this.maxSize) {
30 |       const firstKey = this.cache.keys().next().value;
31 |       if (firstKey !== undefined) {
32 |         this.cache.delete(firstKey);
33 |       }
34 |     }
35 |     this.cache.set(key, value);
36 |   }
37 | 
38 |   clear(): void {
39 |     this.cache.clear();
40 |   }
41 | }
```

src/utils/bfsFileSearch.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach } from 'vitest';
8 | import * as fsPromises from 'node:fs/promises';
9 | import * as path from 'node:path';
10 | import * as os from 'node:os';
11 | import { bfsFileSearch } from './bfsFileSearch.js';
12 | import { FileDiscoveryService } from '../services/fileDiscoveryService.js';
13 | 
14 | describe('bfsFileSearch', () => {
15 |   let testRootDir: string;
16 | 
17 |   async function createEmptyDir(...pathSegments: string[]) {
18 |     const fullPath = path.join(testRootDir, ...pathSegments);
19 |     await fsPromises.mkdir(fullPath, { recursive: true });
20 |     return fullPath;
21 |   }
22 | 
23 |   async function createTestFile(content: string, ...pathSegments: string[]) {
24 |     const fullPath = path.join(testRootDir, ...pathSegments);
25 |     await fsPromises.mkdir(path.dirname(fullPath), { recursive: true });
26 |     await fsPromises.writeFile(fullPath, content);
27 |     return fullPath;
28 |   }
29 | 
30 |   beforeEach(async () => {
31 |     testRootDir = await fsPromises.mkdtemp(
32 |       path.join(os.tmpdir(), 'bfs-file-search-test-'),
33 |     );
34 |   });
35 | 
36 |   afterEach(async () => {
37 |     await fsPromises.rm(testRootDir, { recursive: true, force: true });
38 |   });
39 | 
40 |   it('should find a file in the root directory', async () => {
41 |     const targetFilePath = await createTestFile('content', 'target.txt');
42 |     const result = await bfsFileSearch(testRootDir, { fileName: 'target.txt' });
43 |     expect(result).toEqual([targetFilePath]);
44 |   });
45 | 
46 |   it('should find a file in a nested directory', async () => {
47 |     const targetFilePath = await createTestFile(
48 |       'content',
49 |       'a',
50 |       'b',
51 |       'target.txt',
52 |     );
53 |     const result = await bfsFileSearch(testRootDir, { fileName: 'target.txt' });
54 |     expect(result).toEqual([targetFilePath]);
55 |   });
56 | 
57 |   it('should find multiple files with the same name', async () => {
58 |     const targetFilePath1 = await createTestFile('content1', 'a', 'target.txt');
59 |     const targetFilePath2 = await createTestFile('content2', 'b', 'target.txt');
60 |     const result = await bfsFileSearch(testRootDir, { fileName: 'target.txt' });
61 |     result.sort();
62 |     expect(result).toEqual([targetFilePath1, targetFilePath2].sort());
63 |   });
64 | 
65 |   it('should return an empty array if no file is found', async () => {
66 |     await createTestFile('content', 'other.txt');
67 |     const result = await bfsFileSearch(testRootDir, { fileName: 'target.txt' });
68 |     expect(result).toEqual([]);
69 |   });
70 | 
71 |   it('should ignore directories specified in ignoreDirs', async () => {
72 |     await createTestFile('content', 'ignored', 'target.txt');
73 |     const targetFilePath = await createTestFile(
74 |       'content',
75 |       'not-ignored',
76 |       'target.txt',
77 |     );
78 |     const result = await bfsFileSearch(testRootDir, {
79 |       fileName: 'target.txt',
80 |       ignoreDirs: ['ignored'],
81 |     });
82 |     expect(result).toEqual([targetFilePath]);
83 |   });
84 | 
85 |   it('should respect the maxDirs limit and not find the file', async () => {
86 |     await createTestFile('content', 'a', 'b', 'c', 'target.txt');
87 |     const result = await bfsFileSearch(testRootDir, {
88 |       fileName: 'target.txt',
89 |       maxDirs: 3,
90 |     });
91 |     expect(result).toEqual([]);
92 |   });
93 | 
94 |   it('should respect the maxDirs limit and find the file', async () => {
95 |     const targetFilePath = await createTestFile(
96 |       'content',
97 |       'a',
98 |       'b',
99 |       'c',
100 |       'target.txt',
101 |     );
102 |     const result = await bfsFileSearch(testRootDir, {
103 |       fileName: 'target.txt',
104 |       maxDirs: 4,
105 |     });
106 |     expect(result).toEqual([targetFilePath]);
107 |   });
108 | 
109 |   describe('with FileDiscoveryService', () => {
110 |     let projectRoot: string;
111 | 
112 |     beforeEach(async () => {
113 |       projectRoot = await createEmptyDir('project');
114 |     });
115 | 
116 |     it('should ignore gitignored files', async () => {
117 |       await createEmptyDir('project', '.git');
118 |       await createTestFile('node_modules/', 'project', '.gitignore');
119 |       await createTestFile('content', 'project', 'node_modules', 'target.txt');
120 |       const targetFilePath = await createTestFile(
121 |         'content',
122 |         'project',
123 |         'not-ignored',
124 |         'target.txt',
125 |       );
126 | 
127 |       const fileService = new FileDiscoveryService(projectRoot);
128 |       const result = await bfsFileSearch(projectRoot, {
129 |         fileName: 'target.txt',
130 |         fileService,
131 |         fileFilteringOptions: {
132 |           respectGitIgnore: true,
133 |           respectGeminiIgnore: true,
134 |         },
135 |       });
136 | 
137 |       expect(result).toEqual([targetFilePath]);
138 |     });
139 | 
140 |     it('should ignore geminiignored files', async () => {
141 |       await createTestFile('node_modules/', 'project', '.geminiignore');
142 |       await createTestFile('content', 'project', 'node_modules', 'target.txt');
143 |       const targetFilePath = await createTestFile(
144 |         'content',
145 |         'project',
146 |         'not-ignored',
147 |         'target.txt',
148 |       );
149 | 
150 |       const fileService = new FileDiscoveryService(projectRoot);
151 |       const result = await bfsFileSearch(projectRoot, {
152 |         fileName: 'target.txt',
153 |         fileService,
154 |         fileFilteringOptions: {
155 |           respectGitIgnore: false,
156 |           respectGeminiIgnore: true,
157 |         },
158 |       });
159 | 
160 |       expect(result).toEqual([targetFilePath]);
161 |     });
162 | 
163 |     it('should not ignore files if respect flags are false', async () => {
164 |       await createEmptyDir('project', '.git');
165 |       await createTestFile('node_modules/', 'project', '.gitignore');
166 |       const target1 = await createTestFile(
167 |         'content',
168 |         'project',
169 |         'node_modules',
170 |         'target.txt',
171 |       );
172 |       const target2 = await createTestFile(
173 |         'content',
174 |         'project',
175 |         'not-ignored',
176 |         'target.txt',
177 |       );
178 | 
179 |       const fileService = new FileDiscoveryService(projectRoot);
180 |       const result = await bfsFileSearch(projectRoot, {
181 |         fileName: 'target.txt',
182 |         fileService,
183 |         fileFilteringOptions: {
184 |           respectGitIgnore: false,
185 |           respectGeminiIgnore: false,
186 |         },
187 |       });
188 | 
189 |       expect(result.sort()).toEqual([target1, target2].sort());
190 |     });
191 |   });
192 | 
193 |   it('should find all files in a complex directory structure', async () => {
194 |     // Create a complex directory structure to test correctness at scale
195 |     // without flaky performance checks.
196 |     const numDirs = 50;
197 |     const numFilesPerDir = 2;
198 |     const numTargetDirs = 10;
199 | 
200 |     const dirCreationPromises: Array<Promise<unknown>> = [];
201 |     for (let i = 0; i < numDirs; i++) {
202 |       dirCreationPromises.push(createEmptyDir(`dir${i}`));
203 |       dirCreationPromises.push(createEmptyDir(`dir${i}`, 'subdir1'));
204 |       dirCreationPromises.push(createEmptyDir(`dir${i}`, 'subdir2'));
205 |       dirCreationPromises.push(createEmptyDir(`dir${i}`, 'subdir1', 'deep'));
206 |     }
207 |     await Promise.all(dirCreationPromises);
208 | 
209 |     const fileCreationPromises: Array<Promise<string>> = [];
210 |     for (let i = 0; i < numTargetDirs; i++) {
211 |       // Add target files in some directories
212 |       fileCreationPromises.push(
213 |         createTestFile('content', `dir${i}`, 'GEMINI.md'),
214 |       );
215 |       fileCreationPromises.push(
216 |         createTestFile('content', `dir${i}`, 'subdir1', 'GEMINI.md'),
217 |       );
218 |     }
219 |     const expectedFiles = await Promise.all(fileCreationPromises);
220 | 
221 |     const result = await bfsFileSearch(testRootDir, {
222 |       fileName: 'GEMINI.md',
223 |       // Provide a generous maxDirs limit to ensure it doesn't prematurely stop
224 |       // in this large test case. Total dirs created is 200.
225 |       maxDirs: 250,
226 |     });
227 | 
228 |     // Verify we found the exact files we created
229 |     expect(result.length).toBe(numTargetDirs * numFilesPerDir);
230 |     expect(result.sort()).toEqual(expectedFiles.sort());
231 |   });
232 | });
```

src/utils/bfsFileSearch.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs/promises';
8 | import * as path from 'node:path';
9 | import type { FileDiscoveryService } from '../services/fileDiscoveryService.js';
10 | import type { FileFilteringOptions } from '../config/constants.js';
11 | // Simple console logger for now.
12 | // TODO: Integrate with a more robust server-side logger.
13 | const logger = {
14 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
15 |   debug: (...args: any[]) => console.debug('[DEBUG] [BfsFileSearch]', ...args),
16 | };
17 | 
18 | interface BfsFileSearchOptions {
19 |   fileName: string;
20 |   ignoreDirs?: string[];
21 |   maxDirs?: number;
22 |   debug?: boolean;
23 |   fileService?: FileDiscoveryService;
24 |   fileFilteringOptions?: FileFilteringOptions;
25 | }
26 | 
27 | /**
28 |  * Performs a breadth-first search for a specific file within a directory structure.
29 |  *
30 |  * @param rootDir The directory to start the search from.
31 |  * @param options Configuration for the search.
32 |  * @returns A promise that resolves to an array of paths where the file was found.
33 |  */
34 | export async function bfsFileSearch(
35 |   rootDir: string,
36 |   options: BfsFileSearchOptions,
37 | ): Promise<string[]> {
38 |   const {
39 |     fileName,
40 |     ignoreDirs = [],
41 |     maxDirs = Infinity,
42 |     debug = false,
43 |     fileService,
44 |   } = options;
45 |   const foundFiles: string[] = [];
46 |   const queue: string[] = [rootDir];
47 |   const visited = new Set<string>();
48 |   let scannedDirCount = 0;
49 |   let queueHead = 0; // Pointer-based queue head to avoid expensive splice operations
50 | 
51 |   // Convert ignoreDirs array to Set for O(1) lookup performance
52 |   const ignoreDirsSet = new Set(ignoreDirs);
53 | 
54 |   // Process directories in parallel batches for maximum performance
55 |   const PARALLEL_BATCH_SIZE = 15; // Parallel processing batch size for optimal performance
56 | 
57 |   while (queueHead < queue.length && scannedDirCount < maxDirs) {
58 |     // Fill batch with unvisited directories up to the desired size
59 |     const batchSize = Math.min(PARALLEL_BATCH_SIZE, maxDirs - scannedDirCount);
60 |     const currentBatch = [];
61 |     while (currentBatch.length < batchSize && queueHead < queue.length) {
62 |       const currentDir = queue[queueHead];
63 |       queueHead++;
64 |       if (!visited.has(currentDir)) {
65 |         visited.add(currentDir);
66 |         currentBatch.push(currentDir);
67 |       }
68 |     }
69 |     scannedDirCount += currentBatch.length;
70 | 
71 |     if (currentBatch.length === 0) continue;
72 | 
73 |     if (debug) {
74 |       logger.debug(
75 |         `Scanning [${scannedDirCount}/${maxDirs}]: batch of ${currentBatch.length}`,
76 |       );
77 |     }
78 | 
79 |     // Read directories in parallel instead of one by one
80 |     const readPromises = currentBatch.map(async (currentDir) => {
81 |       try {
82 |         const entries = await fs.readdir(currentDir, { withFileTypes: true });
83 |         return { currentDir, entries };
84 |       } catch (error) {
85 |         // Warn user that a directory could not be read, as this affects search results.
86 |         const message = (error as Error)?.message ?? 'Unknown error';
87 |         console.warn(
88 |           `[WARN] Skipping unreadable directory: ${currentDir} (${message})`,
89 |         );
90 |         if (debug) {
91 |           logger.debug(`Full error for ${currentDir}:`, error);
92 |         }
93 |         return { currentDir, entries: [] };
94 |       }
95 |     });
96 | 
97 |     const results = await Promise.all(readPromises);
98 | 
99 |     for (const { currentDir, entries } of results) {
100 |       for (const entry of entries) {
101 |         const fullPath = path.join(currentDir, entry.name);
102 |         const isDirectory = entry.isDirectory();
103 |         const isMatchingFile = entry.isFile() && entry.name === fileName;
104 | 
105 |         if (!isDirectory && !isMatchingFile) {
106 |           continue;
107 |         }
108 |         if (isDirectory && ignoreDirsSet.has(entry.name)) {
109 |           continue;
110 |         }
111 | 
112 |         if (
113 |           fileService?.shouldIgnoreFile(fullPath, {
114 |             respectGitIgnore: options.fileFilteringOptions?.respectGitIgnore,
115 |             respectGeminiIgnore:
116 |               options.fileFilteringOptions?.respectGeminiIgnore,
117 |           })
118 |         ) {
119 |           continue;
120 |         }
121 | 
122 |         if (isDirectory) {
123 |           queue.push(fullPath);
124 |         } else {
125 |           foundFiles.push(fullPath);
126 |         }
127 |       }
128 |     }
129 |   }
130 | 
131 |   return foundFiles;
132 | }
```

src/utils/browser.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Determines if we should attempt to launch a browser for authentication
9 |  * based on the user's environment.
10 |  *
11 |  * This is an adaptation of the logic from the Google Cloud SDK.
12 |  * @returns True if the tool should attempt to launch a browser.
13 |  */
14 | export function shouldAttemptBrowserLaunch(): boolean {
15 |   // A list of browser names that indicate we should not attempt to open a
16 |   // web browser for the user.
17 |   const browserBlocklist = ['www-browser'];
18 |   const browserEnv = process.env['BROWSER'];
19 |   if (browserEnv && browserBlocklist.includes(browserEnv)) {
20 |     return false;
21 |   }
22 |   // Common environment variables used in CI/CD or other non-interactive shells.
23 |   if (
24 |     process.env['CI'] ||
25 |     process.env['DEBIAN_FRONTEND'] === 'noninteractive'
26 |   ) {
27 |     return false;
28 |   }
29 | 
30 |   // The presence of SSH_CONNECTION indicates a remote session.
31 |   // We should not attempt to launch a browser unless a display is explicitly available
32 |   // (checked below for Linux).
33 |   const isSSH = !!process.env['SSH_CONNECTION'];
34 | 
35 |   // On Linux, the presence of a display server is a strong indicator of a GUI.
36 |   if (process.platform === 'linux') {
37 |     // These are environment variables that can indicate a running compositor on
38 |     // Linux.
39 |     const displayVariables = ['DISPLAY', 'WAYLAND_DISPLAY', 'MIR_SOCKET'];
40 |     const hasDisplay = displayVariables.some((v) => !!process.env[v]);
41 |     if (!hasDisplay) {
42 |       return false;
43 |     }
44 |   }
45 | 
46 |   // If in an SSH session on a non-Linux OS (e.g., macOS), don't launch browser.
47 |   // The Linux case is handled above (it's allowed if DISPLAY is set).
48 |   if (isSSH && process.platform !== 'linux') {
49 |     return false;
50 |   }
51 | 
52 |   // For non-Linux OSes, we generally assume a GUI is available
53 |   // unless other signals (like SSH) suggest otherwise.
54 |   // The `open` command's error handling will catch final edge cases.
55 |   return true;
56 | }
```

src/utils/editCorrector.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /* eslint-disable @typescript-eslint/no-explicit-any */
8 | import type { Mock } from 'vitest';
9 | import { vi, describe, it, expect, beforeEach, type Mocked } from 'vitest';
10 | import * as fs from 'node:fs';
11 | import { EditTool } from '../tools/edit.js';
12 | import type { BaseLlmClient } from '../core/baseLlmClient.js';
13 | 
14 | // MOCKS
15 | let callCount = 0;
16 | const mockResponses: any[] = [];
17 | 
18 | let mockGenerateJson: any;
19 | let mockStartChat: any;
20 | let mockSendMessageStream: any;
21 | 
22 | vi.mock('fs', () => ({
23 |   statSync: vi.fn(),
24 |   mkdirSync: vi.fn(),
25 | }));
26 | 
27 | vi.mock('../core/client.js', () => ({
28 |   GeminiClient: vi.fn().mockImplementation(function (
29 |     this: any,
30 |     _config: Config,
31 |   ) {
32 |     this.startChat = (...params: any[]) => mockStartChat(...params);
33 |     this.sendMessageStream = (...params: any[]) =>
34 |       mockSendMessageStream(...params);
35 |     return this;
36 |   }),
37 | }));
38 | // END MOCKS
39 | 
40 | import {
41 |   countOccurrences,
42 |   ensureCorrectEdit,
43 |   ensureCorrectFileContent,
44 |   unescapeStringForGeminiBug,
45 |   resetEditCorrectorCaches_TEST_ONLY,
46 | } from './editCorrector.js';
47 | import { GeminiClient } from '../core/client.js';
48 | import type { Config } from '../config/config.js';
49 | import { ToolRegistry } from '../tools/tool-registry.js';
50 | 
51 | vi.mock('../tools/tool-registry.js');
52 | 
53 | describe('editCorrector', () => {
54 |   describe('countOccurrences', () => {
55 |     it('should return 0 for empty string', () => {
56 |       expect(countOccurrences('', 'a')).toBe(0);
57 |     });
58 |     it('should return 0 for empty substring', () => {
59 |       expect(countOccurrences('abc', '')).toBe(0);
60 |     });
61 |     it('should return 0 if substring is not found', () => {
62 |       expect(countOccurrences('abc', 'd')).toBe(0);
63 |     });
64 |     it('should return 1 if substring is found once', () => {
65 |       expect(countOccurrences('abc', 'b')).toBe(1);
66 |     });
67 |     it('should return correct count for multiple occurrences', () => {
68 |       expect(countOccurrences('ababa', 'a')).toBe(3);
69 |       expect(countOccurrences('ababab', 'ab')).toBe(3);
70 |     });
71 |     it('should count non-overlapping occurrences', () => {
72 |       expect(countOccurrences('aaaaa', 'aa')).toBe(2);
73 |       expect(countOccurrences('ababab', 'aba')).toBe(1);
74 |     });
75 |     it('should correctly count occurrences when substring is longer', () => {
76 |       expect(countOccurrences('abc', 'abcdef')).toBe(0);
77 |     });
78 |     it('should be case-sensitive', () => {
79 |       expect(countOccurrences('abcABC', 'a')).toBe(1);
80 |       expect(countOccurrences('abcABC', 'A')).toBe(1);
81 |     });
82 |   });
83 | 
84 |   describe('unescapeStringForGeminiBug', () => {
85 |     it('should unescape common sequences', () => {
86 |       expect(unescapeStringForGeminiBug('\\n')).toBe('\n');
87 |       expect(unescapeStringForGeminiBug('\\t')).toBe('\t');
88 |       expect(unescapeStringForGeminiBug("\\'")).toBe("'");
89 |       expect(unescapeStringForGeminiBug('\\"')).toBe('"');
90 |       expect(unescapeStringForGeminiBug('\\`')).toBe('`');
91 |     });
92 |     it('should handle multiple escaped sequences', () => {
93 |       expect(unescapeStringForGeminiBug('Hello\\nWorld\\tTest')).toBe(
94 |         'Hello\nWorld\tTest',
95 |       );
96 |     });
97 |     it('should not alter already correct sequences', () => {
98 |       expect(unescapeStringForGeminiBug('\n')).toBe('\n');
99 |       expect(unescapeStringForGeminiBug('Correct string')).toBe(
100 |         'Correct string',
101 |       );
102 |     });
103 |     it('should handle mixed correct and incorrect sequences', () => {
104 |       expect(unescapeStringForGeminiBug('\\nCorrect\t\\`')).toBe(
105 |         '\nCorrect\t`',
106 |       );
107 |     });
108 |     it('should handle backslash followed by actual newline character', () => {
109 |       expect(unescapeStringForGeminiBug('\\\n')).toBe('\n');
110 |       expect(unescapeStringForGeminiBug('First line\\\nSecond line')).toBe(
111 |         'First line\nSecond line',
112 |       );
113 |     });
114 |     it('should handle multiple backslashes before an escapable character (aggressive unescaping)', () => {
115 |       expect(unescapeStringForGeminiBug('\\\\n')).toBe('\n');
116 |       expect(unescapeStringForGeminiBug('\\\\\\t')).toBe('\t');
117 |       expect(unescapeStringForGeminiBug('\\\\\\\\`')).toBe('`');
118 |     });
119 |     it('should return empty string for empty input', () => {
120 |       expect(unescapeStringForGeminiBug('')).toBe('');
121 |     });
122 |     it('should not alter strings with no targeted escape sequences', () => {
123 |       expect(unescapeStringForGeminiBug('abc def')).toBe('abc def');
124 |       expect(unescapeStringForGeminiBug('C:\\Folder\\File')).toBe(
125 |         'C:\\Folder\\File',
126 |       );
127 |     });
128 |     it('should correctly process strings with some targeted escapes', () => {
129 |       expect(unescapeStringForGeminiBug('C:\\Users\\name')).toBe(
130 |         'C:\\Users\name',
131 |       );
132 |     });
133 |     it('should handle complex cases with mixed slashes and characters', () => {
134 |       expect(
135 |         unescapeStringForGeminiBug('\\\\\\\nLine1\\\nLine2\\tTab\\\\`Tick\\"'),
136 |       ).toBe('\nLine1\nLine2\tTab`Tick"');
137 |     });
138 |     it('should handle escaped backslashes', () => {
139 |       expect(unescapeStringForGeminiBug('\\\\')).toBe('\\');
140 |       expect(unescapeStringForGeminiBug('C:\\\\Users')).toBe('C:\\Users');
141 |       expect(unescapeStringForGeminiBug('path\\\\to\\\\file')).toBe(
142 |         'path\to\\file',
143 |       );
144 |     });
145 |     it('should handle escaped backslashes mixed with other escapes (aggressive unescaping)', () => {
146 |       expect(unescapeStringForGeminiBug('line1\\\\\\nline2')).toBe(
147 |         'line1\nline2',
148 |       );
149 |       expect(unescapeStringForGeminiBug('quote\\\\"text\\\\nline')).toBe(
150 |         'quote"text\nline',
151 |       );
152 |     });
153 |   });
154 | 
155 |   describe('ensureCorrectEdit', () => {
156 |     let mockGeminiClientInstance: Mocked<GeminiClient>;
157 |     let mockBaseLlmClientInstance: Mocked<BaseLlmClient>;
158 |     let mockToolRegistry: Mocked<ToolRegistry>;
159 |     let mockConfigInstance: Config;
160 |     const abortSignal = new AbortController().signal;
161 | 
162 |     beforeEach(() => {
163 |       mockToolRegistry = new ToolRegistry({} as Config) as Mocked<ToolRegistry>;
164 |       const configParams = {
165 |         apiKey: 'test-api-key',
166 |         model: 'test-model',
167 |         sandbox: false as boolean | string,
168 |         targetDir: '/test',
169 |         debugMode: false,
170 |         question: undefined as string | undefined,
171 |         fullContext: false,
172 |         coreTools: undefined as string[] | undefined,
173 |         toolDiscoveryCommand: undefined as string | undefined,
174 |         toolCallCommand: undefined as string | undefined,
175 |         mcpServerCommand: undefined as string | undefined,
176 |         mcpServers: undefined as Record<string, any> | undefined,
177 |         userAgent: 'test-agent',
178 |         userMemory: '',
179 |         geminiMdFileCount: 0,
180 |         alwaysSkipModificationConfirmation: false,
181 |       };
182 |       mockConfigInstance = {
183 |         ...configParams,
184 |         getApiKey: vi.fn(() => configParams.apiKey),
185 |         getModel: vi.fn(() => configParams.model),
186 |         getSandbox: vi.fn(() => configParams.sandbox),
187 |         getTargetDir: vi.fn(() => configParams.targetDir),
188 |         getToolRegistry: vi.fn(() => mockToolRegistry),
189 |         getDebugMode: vi.fn(() => configParams.debugMode),
190 |         getQuestion: vi.fn(() => configParams.question),
191 |         getFullContext: vi.fn(() => configParams.fullContext),
192 |         getCoreTools: vi.fn(() => configParams.coreTools),
193 |         getToolDiscoveryCommand: vi.fn(() => configParams.toolDiscoveryCommand),
194 |         getToolCallCommand: vi.fn(() => configParams.toolCallCommand),
195 |         getMcpServerCommand: vi.fn(() => configParams.mcpServerCommand),
196 |         getMcpServers: vi.fn(() => configParams.mcpServers),
197 |         getUserAgent: vi.fn(() => configParams.userAgent),
198 |         getUserMemory: vi.fn(() => configParams.userMemory),
199 |         setUserMemory: vi.fn((mem: string) => {
200 |           configParams.userMemory = mem;
201 |         }),
202 |         getGeminiMdFileCount: vi.fn(() => configParams.geminiMdFileCount),
203 |         setGeminiMdFileCount: vi.fn((count: number) => {
204 |           configParams.geminiMdFileCount = count;
205 |         }),
206 |         getAlwaysSkipModificationConfirmation: vi.fn(
207 |           () => configParams.alwaysSkipModificationConfirmation,
208 |         ),
209 |         setAlwaysSkipModificationConfirmation: vi.fn((skip: boolean) => {
210 |           configParams.alwaysSkipModificationConfirmation = skip;
211 |         }),
212 |         getQuotaErrorOccurred: vi.fn().mockReturnValue(false),
213 |         setQuotaErrorOccurred: vi.fn(),
214 |       } as unknown as Config;
215 | 
216 |       callCount = 0;
217 |       mockResponses.length = 0;
218 |       mockGenerateJson = vi
219 |         .fn()
220 |         .mockImplementation((_contents, _schema, signal) => {
221 |           // Check if the signal is aborted. If so, throw an error or return a specific response.
222 |           if (signal && signal.aborted) {
223 |             return Promise.reject(new Error('Aborted')); // Or some other specific error/response
224 |           }
225 |           const response = mockResponses[callCount];
226 |           callCount++;
227 |           if (response === undefined) return Promise.resolve({});
228 |           return Promise.resolve(response);
229 |         });
230 |       mockStartChat = vi.fn();
231 |       mockSendMessageStream = vi.fn();
232 | 
233 |       mockGeminiClientInstance = new GeminiClient(
234 |         mockConfigInstance,
235 |       ) as Mocked<GeminiClient>;
236 |       mockGeminiClientInstance.getHistory = vi.fn().mockResolvedValue([]);
237 |       mockBaseLlmClientInstance = {
238 |         generateJson: mockGenerateJson,
239 |       } as unknown as Mocked<BaseLlmClient>;
240 |       resetEditCorrectorCaches_TEST_ONLY();
241 |     });
242 | 
243 |     describe('Scenario Group 1: originalParams.old_string matches currentContent directly', () => {
244 |       it('Test 1.1: old_string (no literal \\), new_string (escaped by Gemini) -> new_string unescaped', async () => {
245 |         const currentContent = 'This is a test string to find me.';
246 |         const originalParams = {
247 |           file_path: '/test/file.txt',
248 |           old_string: 'find me',
249 |           new_string: 'replace with \\"this\\"',
250 |         };
251 |         mockResponses.push({
252 |           corrected_new_string_escaping: 'replace with "this"',
253 |         });
254 |         const result = await ensureCorrectEdit(
255 |           '/test/file.txt',
256 |           currentContent,
257 |           originalParams,
258 |           mockGeminiClientInstance,
259 |           mockBaseLlmClientInstance,
260 |           abortSignal,
261 |         );
262 |         expect(mockGenerateJson).toHaveBeenCalledTimes(1);
263 |         expect(result.params.new_string).toBe('replace with "this"');
264 |         expect(result.params.old_string).toBe('find me');
265 |         expect(result.occurrences).toBe(1);
266 |       });
267 |       it('Test 1.2: old_string (no literal \\), new_string (correctly formatted) -> new_string unchanged', async () => {
268 |         const currentContent = 'This is a test string to find me.';
269 |         const originalParams = {
270 |           file_path: '/test/file.txt',
271 |           old_string: 'find me',
272 |           new_string: 'replace with this',
273 |         };
274 |         const result = await ensureCorrectEdit(
275 |           '/test/file.txt',
276 |           currentContent,
277 |           originalParams,
278 |           mockGeminiClientInstance,
279 |           mockBaseLlmClientInstance,
280 |           abortSignal,
281 |         );
282 |         expect(mockGenerateJson).toHaveBeenCalledTimes(0);
283 |         expect(result.params.new_string).toBe('replace with this');
284 |         expect(result.params.old_string).toBe('find me');
285 |         expect(result.occurrences).toBe(1);
286 |       });
287 |       it('Test 1.3: old_string (with literal \\), new_string (escaped by Gemini) -> new_string unchanged (still escaped)', async () => {
288 |         const currentContent = 'This is a test string to find\\me.';
289 |         const originalParams = {
290 |           file_path: '/test/file.txt',
291 |           old_string: 'find\\me',
292 |           new_string: 'replace with \\"this\\"',
293 |         };
294 |         mockResponses.push({
295 |           corrected_new_string_escaping: 'replace with "this"',
296 |         });
297 |         const result = await ensureCorrectEdit(
298 |           '/test/file.txt',
299 |           currentContent,
300 |           originalParams,
301 |           mockGeminiClientInstance,
302 |           mockBaseLlmClientInstance,
303 |           abortSignal,
304 |         );
305 |         expect(mockGenerateJson).toHaveBeenCalledTimes(1);
306 |         expect(result.params.new_string).toBe('replace with "this"');
307 |         expect(result.params.old_string).toBe('find\\me');
308 |         expect(result.occurrences).toBe(1);
309 |       });
310 |       it('Test 1.4: old_string (with literal \\), new_string (correctly formatted) -> new_string unchanged', async () => {
311 |         const currentContent = 'This is a test string to find\\me.';
312 |         const originalParams = {
313 |           file_path: '/test/file.txt',
314 |           old_string: 'find\\me',
315 |           new_string: 'replace with this',
316 |         };
317 |         const result = await ensureCorrectEdit(
318 |           '/test/file.txt',
319 |           currentContent,
320 |           originalParams,
321 |           mockGeminiClientInstance,
322 |           mockBaseLlmClientInstance,
323 |           abortSignal,
324 |         );
325 |         expect(mockGenerateJson).toHaveBeenCalledTimes(0);
326 |         expect(result.params.new_string).toBe('replace with this');
327 |         expect(result.params.old_string).toBe('find\\me');
328 |         expect(result.occurrences).toBe(1);
329 |       });
330 |     });
331 | 
332 |     describe('Scenario Group 2: originalParams.old_string does NOT match, but unescapeStringForGeminiBug(originalParams.old_string) DOES match', () => {
333 |       it('Test 2.1: old_string (over-escaped, no intended literal \\), new_string (escaped by Gemini) -> new_string unescaped', async () => {
334 |         const currentContent = 'This is a test string to find "me".';
335 |         const originalParams = {
336 |           file_path: '/test/file.txt',
337 |           old_string: 'find \\"me\\"',
338 |           new_string: 'replace with \\"this\\"',
339 |         };
340 |         mockResponses.push({ corrected_new_string: 'replace with "this"' });
341 |         const result = await ensureCorrectEdit(
342 |           '/test/file.txt',
343 |           currentContent,
344 |           originalParams,
345 |           mockGeminiClientInstance,
346 |           mockBaseLlmClientInstance,
347 |           abortSignal,
348 |         );
349 |         expect(mockGenerateJson).toHaveBeenCalledTimes(1);
350 |         expect(result.params.new_string).toBe('replace with "this"');
351 |         expect(result.params.old_string).toBe('find "me"');
352 |         expect(result.occurrences).toBe(1);
353 |       });
354 |       it('Test 2.2: old_string (over-escaped, no intended literal \\), new_string (correctly formatted) -> new_string unescaped (harmlessly)', async () => {
355 |         const currentContent = 'This is a test string to find "me".';
356 |         const originalParams = {
357 |           file_path: '/test/file.txt',
358 |           old_string: 'find \\"me\\"',
359 |           new_string: 'replace with this',
360 |         };
361 |         const result = await ensureCorrectEdit(
362 |           '/test/file.txt',
363 |           currentContent,
364 |           originalParams,
365 |           mockGeminiClientInstance,
366 |           mockBaseLlmClientInstance,
367 |           abortSignal,
368 |         );
369 |         expect(mockGenerateJson).toHaveBeenCalledTimes(0);
370 |         expect(result.params.new_string).toBe('replace with this');
371 |         expect(result.params.old_string).toBe('find "me"');
372 |         expect(result.occurrences).toBe(1);
373 |       });
374 |       it('Test 2.3: old_string (over-escaped, with intended literal \\), new_string (simple) -> new_string corrected', async () => {
375 |         const currentContent = 'This is a test string to find \\me.';
376 |         const originalParams = {
377 |           file_path: '/test/file.txt',
378 |           old_string: 'find \\\\me',
379 |           new_string: 'replace with foobar',
380 |         };
381 |         const result = await ensureCorrectEdit(
382 |           '/test/file.txt',
383 |           currentContent,
384 |           originalParams,
385 |           mockGeminiClientInstance,
386 |           mockBaseLlmClientInstance,
387 |           abortSignal,
388 |         );
389 |         expect(mockGenerateJson).toHaveBeenCalledTimes(0);
390 |         expect(result.params.new_string).toBe('replace with foobar');
391 |         expect(result.params.old_string).toBe('find \\me');
392 |         expect(result.occurrences).toBe(1);
393 |       });
394 |     });
395 | 
396 |     describe('Scenario Group 3: LLM Correction Path', () => {
397 |       it('Test 3.1: old_string (no literal \\), new_string (escaped by Gemini), LLM re-escapes new_string -> final new_string is double unescaped', async () => {
398 |         const currentContent = 'This is a test string to corrected find me.';
399 |         const originalParams = {
400 |           file_path: '/test/file.txt',
401 |           old_string: 'find me',
402 |           new_string: 'replace with \\\\"this\\\\"',
403 |         };
404 |         const llmNewString = 'LLM says replace with "that"';
405 |         mockResponses.push({ corrected_new_string_escaping: llmNewString });
406 |         const result = await ensureCorrectEdit(
407 |           '/test/file.txt',
408 |           currentContent,
409 |           originalParams,
410 |           mockGeminiClientInstance,
411 |           mockBaseLlmClientInstance,
412 |           abortSignal,
413 |         );
414 |         expect(mockGenerateJson).toHaveBeenCalledTimes(1);
415 |         expect(result.params.new_string).toBe(llmNewString);
416 |         expect(result.params.old_string).toBe('find me');
417 |         expect(result.occurrences).toBe(1);
418 |       });
419 |       it('Test 3.2: old_string (with literal \\), new_string (escaped by Gemini), LLM re-escapes new_string -> final new_string is unescaped once', async () => {
420 |         const currentContent = 'This is a test string to corrected find me.';
421 |         const originalParams = {
422 |           file_path: '/test/file.txt',
423 |           old_string: 'find\\me',
424 |           new_string: 'replace with \\\\"this\\\\"',
425 |         };
426 |         const llmCorrectedOldString = 'corrected find me';
427 |         const llmNewString = 'LLM says replace with "that"';
428 |         mockResponses.push({ corrected_target_snippet: llmCorrectedOldString });
429 |         mockResponses.push({ corrected_new_string: llmNewString });
430 |         const result = await ensureCorrectEdit(
431 |           '/test/file.txt',
432 |           currentContent,
433 |           originalParams,
434 |           mockGeminiClientInstance,
435 |           mockBaseLlmClientInstance,
436 |           abortSignal,
437 |         );
438 |         expect(mockGenerateJson).toHaveBeenCalledTimes(2);
439 |         expect(result.params.new_string).toBe(llmNewString);
440 |         expect(result.params.old_string).toBe(llmCorrectedOldString);
441 |         expect(result.occurrences).toBe(1);
442 |       });
443 |       it('Test 3.3: old_string needs LLM, new_string is fine -> old_string corrected, new_string original', async () => {
444 |         const currentContent = 'This is a test string to be corrected.';
445 |         const originalParams = {
446 |           file_path: '/test/file.txt',
447 |           old_string: 'fiiind me',
448 |           new_string: 'replace with "this"',
449 |         };
450 |         const llmCorrectedOldString = 'to be corrected';
451 |         mockResponses.push({ corrected_target_snippet: llmCorrectedOldString });
452 |         const result = await ensureCorrectEdit(
453 |           '/test/file.txt',
454 |           currentContent,
455 |           originalParams,
456 |           mockGeminiClientInstance,
457 |           mockBaseLlmClientInstance,
458 |           abortSignal,
459 |         );
460 |         expect(mockGenerateJson).toHaveBeenCalledTimes(1);
461 |         expect(result.params.new_string).toBe('replace with "this"');
462 |         expect(result.params.old_string).toBe(llmCorrectedOldString);
463 |         expect(result.occurrences).toBe(1);
464 |       });
465 |       it('Test 3.4: LLM correction path, correctNewString returns the originalNewString it was passed (which was unescaped) -> final new_string is unescaped', async () => {
466 |         const currentContent = 'This is a test string to corrected find me.';
467 |         const originalParams = {
468 |           file_path: '/test/file.txt',
469 |           old_string: 'find me',
470 |           new_string: 'replace with \\\\"this\\\\"',
471 |         };
472 |         const newStringForLLMAndReturnedByLLM = 'replace with "this"';
473 |         mockResponses.push({
474 |           corrected_new_string_escaping: newStringForLLMAndReturnedByLLM,
475 |         });
476 |         const result = await ensureCorrectEdit(
477 |           '/test/file.txt',
478 |           currentContent,
479 |           originalParams,
480 |           mockGeminiClientInstance,
481 |           mockBaseLlmClientInstance,
482 |           abortSignal,
483 |         );
484 |         expect(mockGenerateJson).toHaveBeenCalledTimes(1);
485 |         expect(result.params.new_string).toBe(newStringForLLMAndReturnedByLLM);
486 |         expect(result.occurrences).toBe(1);
487 |       });
488 |     });
489 | 
490 |     describe('Scenario Group 4: No Match Found / Multiple Matches', () => {
491 |       it('Test 4.1: No version of old_string (original, unescaped, LLM-corrected) matches -> returns original params, 0 occurrences', async () => {
492 |         const currentContent = 'This content has nothing to find.';
493 |         const originalParams = {
494 |           file_path: '/test/file.txt',
495 |           old_string: 'nonexistent string',
496 |           new_string: 'some new string',
497 |         };
498 |         mockResponses.push({ corrected_target_snippet: 'still nonexistent' });
499 |         const result = await ensureCorrectEdit(
500 |           '/test/file.txt',
501 |           currentContent,
502 |           originalParams,
503 |           mockGeminiClientInstance,
504 |           mockBaseLlmClientInstance,
505 |           abortSignal,
506 |         );
507 |         expect(mockGenerateJson).toHaveBeenCalledTimes(1);
508 |         expect(result.params).toEqual(originalParams);
509 |         expect(result.occurrences).toBe(0);
510 |       });
511 |       it('Test 4.2: unescapedOldStringAttempt results in >1 occurrences -> returns original params, count occurrences', async () => {
512 |         const currentContent =
513 |           'This content has find "me" and also find "me" again.';
514 |         const originalParams = {
515 |           file_path: '/test/file.txt',
516 |           old_string: 'find "me"',
517 |           new_string: 'some new string',
518 |         };
519 |         const result = await ensureCorrectEdit(
520 |           '/test/file.txt',
521 |           currentContent,
522 |           originalParams,
523 |           mockGeminiClientInstance,
524 |           mockBaseLlmClientInstance,
525 |           abortSignal,
526 |         );
527 |         expect(mockGenerateJson).toHaveBeenCalledTimes(0);
528 |         expect(result.params).toEqual(originalParams);
529 |         expect(result.occurrences).toBe(2);
530 |       });
531 |     });
532 | 
[TRUNCATED]
```

src/utils/editCorrector.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Content, GenerateContentConfig } from '@google/genai';
8 | import type { GeminiClient } from '../core/client.js';
9 | import type { BaseLlmClient } from '../core/baseLlmClient.js';
10 | import type { EditToolParams } from '../tools/edit.js';
11 | import { EditTool } from '../tools/edit.js';
12 | import { WRITE_FILE_TOOL_NAME } from '../tools/tool-names.js';
13 | import { ReadFileTool } from '../tools/read-file.js';
14 | import { ReadManyFilesTool } from '../tools/read-many-files.js';
15 | import { GrepTool } from '../tools/grep.js';
16 | import { LruCache } from './LruCache.js';
17 | import { DEFAULT_GEMINI_FLASH_LITE_MODEL } from '../config/models.js';
18 | import {
19 |   isFunctionResponse,
20 |   isFunctionCall,
21 | } from '../utils/messageInspectors.js';
22 | import * as fs from 'node:fs';
23 | import { promptIdContext } from './promptIdContext.js';
24 | 
25 | const EDIT_MODEL = DEFAULT_GEMINI_FLASH_LITE_MODEL;
26 | const EDIT_CONFIG: GenerateContentConfig = {
27 |   thinkingConfig: {
28 |     thinkingBudget: 0,
29 |   },
30 | };
31 | 
32 | const CODE_CORRECTION_SYSTEM_PROMPT = `
33 | You are an expert code-editing assistant. Your task is to analyze a failed edit attempt and provide a corrected version of the text snippets.
34 | The correction should be as minimal as possible, staying very close to the original.
35 | Focus ONLY on fixing issues like whitespace, indentation, line endings, or incorrect escaping.
36 | Do NOT invent a completely new edit. Your job is to fix the provided parameters to make the edit succeed.
37 | Return ONLY the corrected snippet in the specified JSON format.
38 | `.trim();
39 | 
40 | function getPromptId(): string {
41 |   return promptIdContext.getStore() ?? `edit-corrector-${Date.now()}`;
42 | }
43 | 
44 | const MAX_CACHE_SIZE = 50;
45 | 
46 | // Cache for ensureCorrectEdit results
47 | const editCorrectionCache = new LruCache<string, CorrectedEditResult>(
48 |   MAX_CACHE_SIZE,
49 | );
50 | 
51 | // Cache for ensureCorrectFileContent results
52 | const fileContentCorrectionCache = new LruCache<string, string>(MAX_CACHE_SIZE);
53 | 
54 | /**
55 |  * Defines the structure of the parameters within CorrectedEditResult
56 |  */
57 | interface CorrectedEditParams {
58 |   file_path: string;
59 |   old_string: string;
60 |   new_string: string;
61 | }
62 | 
63 | /**
64 |  * Defines the result structure for ensureCorrectEdit.
65 |  */
66 | export interface CorrectedEditResult {
67 |   params: CorrectedEditParams;
68 |   occurrences: number;
69 | }
70 | 
71 | /**
72 |  * Extracts the timestamp from the .id value, which is in format
73 |  * <tool.name>-<timestamp>-<uuid>
74 |  * @param fcnId the ID value of a functionCall or functionResponse object
75 |  * @returns -1 if the timestamp could not be extracted, else the timestamp (as a number)
76 |  */
77 | function getTimestampFromFunctionId(fcnId: string): number {
78 |   const idParts = fcnId.split('-');
79 |   if (idParts.length > 2) {
80 |     const timestamp = parseInt(idParts[1], 10);
81 |     if (!isNaN(timestamp)) {
82 |       return timestamp;
83 |     }
84 |   }
85 |   return -1;
86 | }
87 | 
88 | /**
89 |  * Will look through the gemini client history and determine when the most recent
90 |  * edit to a target file occurred. If no edit happened, it will return -1
91 |  * @param filePath the path to the file
92 |  * @param client the geminiClient, so that we can get the history
93 |  * @returns a DateTime (as a number) of when the last edit occurred, or -1 if no edit was found.
94 |  */
95 | async function findLastEditTimestamp(
96 |   filePath: string,
97 |   client: GeminiClient,
98 | ): Promise<number> {
99 |   const history = (await client.getHistory()) ?? [];
100 | 
101 |   // Tools that may reference the file path in their FunctionResponse `output`.
102 |   const toolsInResp = new Set([
103 |     WRITE_FILE_TOOL_NAME,
104 |     EditTool.Name,
105 |     ReadManyFilesTool.Name,
106 |     GrepTool.Name,
107 |   ]);
108 |   // Tools that may reference the file path in their FunctionCall `args`.
109 |   const toolsInCall = new Set([...toolsInResp, ReadFileTool.Name]);
110 | 
111 |   // Iterate backwards to find the most recent relevant action.
112 |   for (const entry of history.slice().reverse()) {
113 |     if (!entry.parts) continue;
114 | 
115 |     for (const part of entry.parts) {
116 |       let id: string | undefined;
117 |       let content: unknown;
118 | 
119 |       // Check for a relevant FunctionCall with the file path in its arguments.
120 |       if (
121 |         isFunctionCall(entry) &&
122 |         part.functionCall?.name &&
123 |         toolsInCall.has(part.functionCall.name)
124 |       ) {
125 |         id = part.functionCall.id;
126 |         content = part.functionCall.args;
127 |       }
128 |       // Check for a relevant FunctionResponse with the file path in its output.
129 |       else if (
130 |         isFunctionResponse(entry) &&
131 |         part.functionResponse?.name &&
132 |         toolsInResp.has(part.functionResponse.name)
133 |       ) {
134 |         const { response } = part.functionResponse;
135 |         if (response && !('error' in response) && 'output' in response) {
136 |           id = part.functionResponse.id;
137 |           content = response['output'];
138 |         }
139 |       }
140 | 
141 |       if (!id || content === undefined) continue;
142 | 
143 |       // Use the "blunt hammer" approach to find the file path in the content.
144 |       // Note that the tool response data is inconsistent in their formatting
145 |       // with successes and errors - so, we just check for the existence
146 |       // as the best guess to if error/failed occurred with the response.
147 |       const stringified = JSON.stringify(content);
148 |       if (
149 |         !stringified.includes('Error') && // only applicable for functionResponse
150 |         !stringified.includes('Failed') && // only applicable for functionResponse
151 |         stringified.includes(filePath)
152 |       ) {
153 |         return getTimestampFromFunctionId(id);
154 |       }
155 |     }
156 |   }
157 | 
158 |   return -1;
159 | }
160 | 
161 | /**
162 |  * Attempts to correct edit parameters if the original old_string is not found.
163 |  * It tries unescaping, and then LLM-based correction.
164 |  * Results are cached to avoid redundant processing.
165 |  *
166 |  * @param currentContent The current content of the file.
167 |  * @param originalParams The original EditToolParams
168 |  * @param client The GeminiClient for LLM calls.
169 |  * @returns A promise resolving to an object containing the (potentially corrected)
170 |  *          EditToolParams (as CorrectedEditParams) and the final occurrences count.
171 |  */
172 | export async function ensureCorrectEdit(
173 |   filePath: string,
174 |   currentContent: string,
175 |   originalParams: EditToolParams, // This is the EditToolParams from edit.ts, without \'corrected\'
176 |   geminiClient: GeminiClient,
177 |   baseLlmClient: BaseLlmClient,
178 |   abortSignal: AbortSignal,
179 | ): Promise<CorrectedEditResult> {
180 |   const cacheKey = `${currentContent}---${originalParams.old_string}---${originalParams.new_string}`;
181 |   const cachedResult = editCorrectionCache.get(cacheKey);
182 |   if (cachedResult) {
183 |     return cachedResult;
184 |   }
185 | 
186 |   let finalNewString = originalParams.new_string;
187 |   const newStringPotentiallyEscaped =
188 |     unescapeStringForGeminiBug(originalParams.new_string) !==
189 |     originalParams.new_string;
190 | 
191 |   const expectedReplacements = originalParams.expected_replacements ?? 1;
192 | 
193 |   let finalOldString = originalParams.old_string;
194 |   let occurrences = countOccurrences(currentContent, finalOldString);
195 | 
196 |   if (occurrences === expectedReplacements) {
197 |     if (newStringPotentiallyEscaped) {
198 |       finalNewString = await correctNewStringEscaping(
199 |         baseLlmClient,
200 |         finalOldString,
201 |         originalParams.new_string,
202 |         abortSignal,
203 |       );
204 |     }
205 |   } else if (occurrences > expectedReplacements) {
206 |     const expectedReplacements = originalParams.expected_replacements ?? 1;
207 | 
208 |     // If user expects multiple replacements, return as-is
209 |     if (occurrences === expectedReplacements) {
210 |       const result: CorrectedEditResult = {
211 |         params: { ...originalParams },
212 |         occurrences,
213 |       };
214 |       editCorrectionCache.set(cacheKey, result);
215 |       return result;
216 |     }
217 | 
218 |     // If user expects 1 but found multiple, try to correct (existing behavior)
219 |     if (expectedReplacements === 1) {
220 |       const result: CorrectedEditResult = {
221 |         params: { ...originalParams },
222 |         occurrences,
223 |       };
224 |       editCorrectionCache.set(cacheKey, result);
225 |       return result;
226 |     }
227 | 
228 |     // If occurrences don't match expected, return as-is (will fail validation later)
229 |     const result: CorrectedEditResult = {
230 |       params: { ...originalParams },
231 |       occurrences,
232 |     };
233 |     editCorrectionCache.set(cacheKey, result);
234 |     return result;
235 |   } else {
236 |     // occurrences is 0 or some other unexpected state initially
237 |     const unescapedOldStringAttempt = unescapeStringForGeminiBug(
238 |       originalParams.old_string,
239 |     );
240 |     occurrences = countOccurrences(currentContent, unescapedOldStringAttempt);
241 | 
242 |     if (occurrences === expectedReplacements) {
243 |       finalOldString = unescapedOldStringAttempt;
244 |       if (newStringPotentiallyEscaped) {
245 |         finalNewString = await correctNewString(
246 |           baseLlmClient,
247 |           originalParams.old_string, // original old
248 |           unescapedOldStringAttempt, // corrected old
249 |           originalParams.new_string, // original new (which is potentially escaped)
250 |           abortSignal,
251 |         );
252 |       }
253 |     } else if (occurrences === 0) {
254 |       if (filePath) {
255 |         // In order to keep from clobbering edits made outside our system,
256 |         // let's check if there was a more recent edit to the file than what
257 |         // our system has done
258 |         const lastEditedByUsTime = await findLastEditTimestamp(
259 |           filePath,
260 |           geminiClient,
261 |         );
262 | 
263 |         // Add a 1-second buffer to account for timing inaccuracies. If the file
264 |         // was modified more than a second after the last edit tool was run, we
265 |         // can assume it was modified by something else.
266 |         if (lastEditedByUsTime > 0) {
267 |           const stats = fs.statSync(filePath);
268 |           const diff = stats.mtimeMs - lastEditedByUsTime;
269 |           if (diff > 2000) {
270 |             // Hard coded for 2 seconds
271 |             // This file was edited sooner
272 |             const result: CorrectedEditResult = {
273 |               params: { ...originalParams },
274 |               occurrences: 0, // Explicitly 0 as LLM failed
275 |             };
276 |             editCorrectionCache.set(cacheKey, result);
277 |             return result;
278 |           }
279 |         }
280 |       }
281 | 
282 |       const llmCorrectedOldString = await correctOldStringMismatch(
283 |         baseLlmClient,
284 |         currentContent,
285 |         unescapedOldStringAttempt,
286 |         abortSignal,
287 |       );
288 |       const llmOldOccurrences = countOccurrences(
289 |         currentContent,
290 |         llmCorrectedOldString,
291 |       );
292 | 
293 |       if (llmOldOccurrences === expectedReplacements) {
294 |         finalOldString = llmCorrectedOldString;
295 |         occurrences = llmOldOccurrences;
296 | 
297 |         if (newStringPotentiallyEscaped) {
298 |           const baseNewStringForLLMCorrection = unescapeStringForGeminiBug(
299 |             originalParams.new_string,
300 |           );
301 |           finalNewString = await correctNewString(
302 |             baseLlmClient,
303 |             originalParams.old_string, // original old
304 |             llmCorrectedOldString, // corrected old
305 |             baseNewStringForLLMCorrection, // base new for correction
306 |             abortSignal,
307 |           );
308 |         }
309 |       } else {
310 |         // LLM correction also failed for old_string
311 |         const result: CorrectedEditResult = {
312 |           params: { ...originalParams },
313 |           occurrences: 0, // Explicitly 0 as LLM failed
314 |         };
315 |         editCorrectionCache.set(cacheKey, result);
316 |         return result;
317 |       }
318 |     } else {
319 |       // Unescaping old_string resulted in > 1 occurrence
320 |       const result: CorrectedEditResult = {
321 |         params: { ...originalParams },
322 |         occurrences, // This will be > 1
323 |       };
324 |       editCorrectionCache.set(cacheKey, result);
325 |       return result;
326 |     }
327 |   }
328 | 
329 |   const { targetString, pair } = trimPairIfPossible(
330 |     finalOldString,
331 |     finalNewString,
332 |     currentContent,
333 |     expectedReplacements,
334 |   );
335 |   finalOldString = targetString;
336 |   finalNewString = pair;
337 | 
338 |   // Final result construction
339 |   const result: CorrectedEditResult = {
340 |     params: {
341 |       file_path: originalParams.file_path,
342 |       old_string: finalOldString,
343 |       new_string: finalNewString,
344 |     },
345 |     occurrences: countOccurrences(currentContent, finalOldString), // Recalculate occurrences with the final old_string
346 |   };
347 |   editCorrectionCache.set(cacheKey, result);
348 |   return result;
349 | }
350 | 
351 | export async function ensureCorrectFileContent(
352 |   content: string,
353 |   baseLlmClient: BaseLlmClient,
354 |   abortSignal: AbortSignal,
355 | ): Promise<string> {
356 |   const cachedResult = fileContentCorrectionCache.get(content);
357 |   if (cachedResult) {
358 |     return cachedResult;
359 |   }
360 | 
361 |   const contentPotentiallyEscaped =
362 |     unescapeStringForGeminiBug(content) !== content;
363 |   if (!contentPotentiallyEscaped) {
364 |     fileContentCorrectionCache.set(content, content);
365 |     return content;
366 |   }
367 | 
368 |   const correctedContent = await correctStringEscaping(
369 |     content,
370 |     baseLlmClient,
371 |     abortSignal,
372 |   );
373 |   fileContentCorrectionCache.set(content, correctedContent);
374 |   return correctedContent;
375 | }
376 | 
377 | // Define the expected JSON schema for the LLM response for old_string correction
378 | const OLD_STRING_CORRECTION_SCHEMA: Record<string, unknown> = {
379 |   type: 'object',
380 |   properties: {
381 |     corrected_target_snippet: {
382 |       type: 'string',
383 |       description:
384 |         'The corrected version of the target snippet that exactly and uniquely matches a segment within the provided file content.',
385 |     },
386 |   },
387 |   required: ['corrected_target_snippet'],
388 | };
389 | 
390 | export async function correctOldStringMismatch(
391 |   baseLlmClient: BaseLlmClient,
392 |   fileContent: string,
393 |   problematicSnippet: string,
394 |   abortSignal: AbortSignal,
395 | ): Promise<string> {
396 |   const prompt = `
397 | Context: A process needs to find an exact literal, unique match for a specific text snippet within a file's content. The provided snippet failed to match exactly. This is most likely because it has been overly escaped.
398 | 
399 | Task: Analyze the provided file content and the problematic target snippet. Identify the segment in the file content that the snippet was *most likely* intended to match. Output the *exact*, literal text of that segment from the file content. Focus *only* on removing extra escape characters and correcting formatting, whitespace, or minor differences to achieve a PERFECT literal match. The output must be the exact literal text as it appears in the file.
400 | 
401 | Problematic target snippet:
402 | \`\`\`
403 | ${problematicSnippet}
404 | \`\`\`
405 | 
406 | File Content:
407 | \`\`\`
408 | ${fileContent}
409 | \`\`\`
410 | 
411 | For example, if the problematic target snippet was "\\\\\\nconst greeting = \`Hello \\\\\`\${name}\\\\\`\`;" and the file content had content that looked like "\nconst greeting = \`Hello ${'\\`'}\${name}${'\\`'}\`;", then corrected_target_snippet should likely be "\nconst greeting = \`Hello ${'\\`'}\${name}${'\\`'}\`;" to fix the incorrect escaping to match the original file content.
412 | If the differences are only in whitespace or formatting, apply similar whitespace/formatting changes to the corrected_target_snippet.
413 | 
414 | Return ONLY the corrected target snippet in the specified JSON format with the key 'corrected_target_snippet'. If no clear, unique match can be found, return an empty string for 'corrected_target_snippet'.
415 | `.trim();
416 | 
417 |   const contents: Content[] = [{ role: 'user', parts: [{ text: prompt }] }];
418 | 
419 |   try {
420 |     const result = await baseLlmClient.generateJson({
421 |       contents,
422 |       schema: OLD_STRING_CORRECTION_SCHEMA,
423 |       abortSignal,
424 |       model: EDIT_MODEL,
425 |       config: EDIT_CONFIG,
426 |       systemInstruction: CODE_CORRECTION_SYSTEM_PROMPT,
427 |       promptId: getPromptId(),
428 |     });
429 | 
430 |     if (
431 |       result &&
432 |       typeof result['corrected_target_snippet'] === 'string' &&
433 |       result['corrected_target_snippet'].length > 0
434 |     ) {
435 |       return result['corrected_target_snippet'];
436 |     } else {
437 |       return problematicSnippet;
438 |     }
439 |   } catch (error) {
440 |     if (abortSignal.aborted) {
441 |       throw error;
442 |     }
443 | 
444 |     console.error(
445 |       'Error during LLM call for old string snippet correction:',
446 |       error,
447 |     );
448 | 
449 |     return problematicSnippet;
450 |   }
451 | }
452 | 
453 | // Define the expected JSON schema for the new_string correction LLM response
454 | const NEW_STRING_CORRECTION_SCHEMA: Record<string, unknown> = {
455 |   type: 'object',
456 |   properties: {
457 |     corrected_new_string: {
458 |       type: 'string',
459 |       description:
460 |         'The original_new_string adjusted to be a suitable replacement for the corrected_old_string, while maintaining the original intent of the change.',
461 |     },
462 |   },
463 |   required: ['corrected_new_string'],
464 | };
465 | 
466 | /**
467 |  * Adjusts the new_string to align with a corrected old_string, maintaining the original intent.
468 |  */
469 | export async function correctNewString(
470 |   baseLlmClient: BaseLlmClient,
471 |   originalOldString: string,
472 |   correctedOldString: string,
473 |   originalNewString: string,
474 |   abortSignal: AbortSignal,
475 | ): Promise<string> {
476 |   if (originalOldString === correctedOldString) {
477 |     return originalNewString;
478 |   }
479 | 
480 |   const prompt = `
481 | Context: A text replacement operation was planned. The original text to be replaced (original_old_string) was slightly different from the actual text in the file (corrected_old_string). The original_old_string has now been corrected to match the file content.
482 | We now need to adjust the replacement text (original_new_string) so that it makes sense as a replacement for the corrected_old_string, while preserving the original intent of the change.
483 | 
484 | original_old_string (what was initially intended to be found):
485 | \`\`\`
486 | ${originalOldString}
487 | \`\`\`
488 | 
489 | corrected_old_string (what was actually found in the file and will be replaced):
490 | \`\`\`
491 | ${correctedOldString}
492 | \`\`\`
493 | 
494 | original_new_string (what was intended to replace original_old_string):
495 | \`\`\`
496 | ${originalNewString}
497 | \`\`\`
498 | 
499 | Task: Based on the differences between original_old_string and corrected_old_string, and the content of original_new_string, generate a corrected_new_string. This corrected_new_string should be what original_new_string would have been if it was designed to replace corrected_old_string directly, while maintaining the spirit of the original transformation.
500 | 
501 | For example, if original_old_string was "\\\\\\nconst greeting = \`Hello \\\\\`\${name}\\\\\`\`;" and corrected_old_string is "\nconst greeting = \`Hello ${'\\`'}\${name}${'\\`'}\`;", and original_new_string was "\\\\\\nconst greeting = \`Hello \\\\\`\${name} \${lastName}\\\\\`\`;", then corrected_new_string should likely be "\nconst greeting = \`Hello ${'\\`'}\${name} \${lastName}${'\\`'}\`;" to fix the incorrect escaping.
502 | If the differences are only in whitespace or formatting, apply similar whitespace/formatting changes to the corrected_new_string.
503 | 
504 | Return ONLY the corrected string in the specified JSON format with the key 'corrected_new_string'. If no adjustment is deemed necessary or possible, return the original_new_string.
505 |   `.trim();
506 | 
507 |   const contents: Content[] = [{ role: 'user', parts: [{ text: prompt }] }];
508 | 
509 |   try {
510 |     const result = await baseLlmClient.generateJson({
511 |       contents,
512 |       schema: NEW_STRING_CORRECTION_SCHEMA,
513 |       abortSignal,
514 |       model: EDIT_MODEL,
515 |       config: EDIT_CONFIG,
516 |       systemInstruction: CODE_CORRECTION_SYSTEM_PROMPT,
517 |       promptId: getPromptId(),
518 |     });
519 | 
520 |     if (
521 |       result &&
[TRUNCATED]
```

src/utils/editor.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   vi,
9 |   describe,
10 |   it,
11 |   expect,
12 |   beforeEach,
13 |   afterEach,
14 |   type Mock,
15 | } from 'vitest';
16 | import {
17 |   checkHasEditorType,
18 |   getDiffCommand,
19 |   openDiff,
20 |   allowEditorTypeInSandbox,
21 |   isEditorAvailable,
22 |   type EditorType,
23 | } from './editor.js';
24 | import { execSync, spawn, spawnSync } from 'node:child_process';
25 | 
26 | vi.mock('child_process', () => ({
27 |   execSync: vi.fn(),
28 |   spawn: vi.fn(),
29 |   spawnSync: vi.fn(() => ({ error: null, status: 0 })),
30 | }));
31 | 
32 | const originalPlatform = process.platform;
33 | 
34 | describe('editor utils', () => {
35 |   beforeEach(() => {
36 |     vi.clearAllMocks();
37 |     vi.unstubAllEnvs();
38 |     Object.defineProperty(process, 'platform', {
39 |       value: originalPlatform,
40 |       writable: true,
41 |     });
42 |   });
43 | 
44 |   afterEach(() => {
45 |     vi.restoreAllMocks();
46 |     vi.unstubAllEnvs();
47 |     Object.defineProperty(process, 'platform', {
48 |       value: originalPlatform,
49 |       writable: true,
50 |     });
51 |   });
52 | 
53 |   describe('checkHasEditorType', () => {
54 |     const testCases: Array<{
55 |       editor: EditorType;
56 |       commands: string[];
57 |       win32Commands: string[];
58 |     }> = [
59 |       { editor: 'vscode', commands: ['code'], win32Commands: ['code.cmd'] },
60 |       {
61 |         editor: 'vscodium',
62 |         commands: ['codium'],
63 |         win32Commands: ['codium.cmd'],
64 |       },
65 |       {
66 |         editor: 'windsurf',
67 |         commands: ['windsurf'],
68 |         win32Commands: ['windsurf'],
69 |       },
70 |       { editor: 'cursor', commands: ['cursor'], win32Commands: ['cursor'] },
71 |       { editor: 'vim', commands: ['vim'], win32Commands: ['vim'] },
72 |       { editor: 'neovim', commands: ['nvim'], win32Commands: ['nvim'] },
73 |       { editor: 'zed', commands: ['zed', 'zeditor'], win32Commands: ['zed'] },
74 |       { editor: 'emacs', commands: ['emacs'], win32Commands: ['emacs.exe'] },
75 |     ];
76 | 
77 |     for (const { editor, commands, win32Commands } of testCases) {
78 |       describe(`${editor}`, () => {
79 |         // Non-windows tests
80 |         it(`should return true if first command "${commands[0]}" exists on non-windows`, () => {
81 |           Object.defineProperty(process, 'platform', { value: 'linux' });
82 |           (execSync as Mock).mockReturnValue(
83 |             Buffer.from(`/usr/bin/${commands[0]}`),
84 |           );
85 |           expect(checkHasEditorType(editor)).toBe(true);
86 |           expect(execSync).toHaveBeenCalledWith(`command -v ${commands[0]}`, {
87 |             stdio: 'ignore',
88 |           });
89 |         });
90 | 
91 |         if (commands.length > 1) {
92 |           it(`should return true if first command doesn't exist but second command "${commands[1]}" exists on non-windows`, () => {
93 |             Object.defineProperty(process, 'platform', { value: 'linux' });
94 |             (execSync as Mock)
95 |               .mockImplementationOnce(() => {
96 |                 throw new Error(); // first command not found
97 |               })
98 |               .mockReturnValueOnce(Buffer.from(`/usr/bin/${commands[1]}`)); // second command found
99 |             expect(checkHasEditorType(editor)).toBe(true);
100 |             expect(execSync).toHaveBeenCalledTimes(2);
101 |           });
102 |         }
103 | 
104 |         it(`should return false if none of the commands exist on non-windows`, () => {
105 |           Object.defineProperty(process, 'platform', { value: 'linux' });
106 |           (execSync as Mock).mockImplementation(() => {
107 |             throw new Error(); // all commands not found
108 |           });
109 |           expect(checkHasEditorType(editor)).toBe(false);
110 |           expect(execSync).toHaveBeenCalledTimes(commands.length);
111 |         });
112 | 
113 |         // Windows tests
114 |         it(`should return true if first command "${win32Commands[0]}" exists on windows`, () => {
115 |           Object.defineProperty(process, 'platform', { value: 'win32' });
116 |           (execSync as Mock).mockReturnValue(
117 |             Buffer.from(`C:\\Program Files\\...\\${win32Commands[0]}`),
118 |           );
119 |           expect(checkHasEditorType(editor)).toBe(true);
120 |           expect(execSync).toHaveBeenCalledWith(
121 |             `where.exe ${win32Commands[0]}`,
122 |             {
123 |               stdio: 'ignore',
124 |             },
125 |           );
126 |         });
127 | 
128 |         if (win32Commands.length > 1) {
129 |           it(`should return true if first command doesn't exist but second command "${win32Commands[1]}" exists on windows`, () => {
130 |             Object.defineProperty(process, 'platform', { value: 'win32' });
131 |             (execSync as Mock)
132 |               .mockImplementationOnce(() => {
133 |                 throw new Error(); // first command not found
134 |               })
135 |               .mockReturnValueOnce(
136 |                 Buffer.from(`C:\\Program Files\\...\\${win32Commands[1]}`),
137 |               ); // second command found
138 |             expect(checkHasEditorType(editor)).toBe(true);
139 |             expect(execSync).toHaveBeenCalledTimes(2);
140 |           });
141 |         }
142 | 
143 |         it(`should return false if none of the commands exist on windows`, () => {
144 |           Object.defineProperty(process, 'platform', { value: 'win32' });
145 |           (execSync as Mock).mockImplementation(() => {
146 |             throw new Error(); // all commands not found
147 |           });
148 |           expect(checkHasEditorType(editor)).toBe(false);
149 |           expect(execSync).toHaveBeenCalledTimes(win32Commands.length);
150 |         });
151 |       });
152 |     }
153 |   });
154 | 
155 |   describe('getDiffCommand', () => {
156 |     const guiEditors: Array<{
157 |       editor: EditorType;
158 |       commands: string[];
159 |       win32Commands: string[];
160 |     }> = [
161 |       { editor: 'vscode', commands: ['code'], win32Commands: ['code.cmd'] },
162 |       {
163 |         editor: 'vscodium',
164 |         commands: ['codium'],
165 |         win32Commands: ['codium.cmd'],
166 |       },
167 |       {
168 |         editor: 'windsurf',
169 |         commands: ['windsurf'],
170 |         win32Commands: ['windsurf'],
171 |       },
172 |       { editor: 'cursor', commands: ['cursor'], win32Commands: ['cursor'] },
173 |       { editor: 'zed', commands: ['zed', 'zeditor'], win32Commands: ['zed'] },
174 |     ];
175 | 
176 |     for (const { editor, commands, win32Commands } of guiEditors) {
177 |       // Non-windows tests
178 |       it(`should use first command "${commands[0]}" when it exists on non-windows`, () => {
179 |         Object.defineProperty(process, 'platform', { value: 'linux' });
180 |         (execSync as Mock).mockReturnValue(
181 |           Buffer.from(`/usr/bin/${commands[0]}`),
182 |         );
183 |         const diffCommand = getDiffCommand('old.txt', 'new.txt', editor);
184 |         expect(diffCommand).toEqual({
185 |           command: commands[0],
186 |           args: ['--wait', '--diff', 'old.txt', 'new.txt'],
187 |         });
188 |       });
189 | 
190 |       if (commands.length > 1) {
191 |         it(`should use second command "${commands[1]}" when first doesn't exist on non-windows`, () => {
192 |           Object.defineProperty(process, 'platform', { value: 'linux' });
193 |           (execSync as Mock)
194 |             .mockImplementationOnce(() => {
195 |               throw new Error(); // first command not found
196 |             })
197 |             .mockReturnValueOnce(Buffer.from(`/usr/bin/${commands[1]}`)); // second command found
198 | 
199 |           const diffCommand = getDiffCommand('old.txt', 'new.txt', editor);
200 |           expect(diffCommand).toEqual({
201 |             command: commands[1],
202 |             args: ['--wait', '--diff', 'old.txt', 'new.txt'],
203 |           });
204 |         });
205 |       }
206 | 
207 |       it(`should fall back to last command "${commands[commands.length - 1]}" when none exist on non-windows`, () => {
208 |         Object.defineProperty(process, 'platform', { value: 'linux' });
209 |         (execSync as Mock).mockImplementation(() => {
210 |           throw new Error(); // all commands not found
211 |         });
212 | 
213 |         const diffCommand = getDiffCommand('old.txt', 'new.txt', editor);
214 |         expect(diffCommand).toEqual({
215 |           command: commands[commands.length - 1],
216 |           args: ['--wait', '--diff', 'old.txt', 'new.txt'],
217 |         });
218 |       });
219 | 
220 |       // Windows tests
221 |       it(`should use first command "${win32Commands[0]}" when it exists on windows`, () => {
222 |         Object.defineProperty(process, 'platform', { value: 'win32' });
223 |         (execSync as Mock).mockReturnValue(
224 |           Buffer.from(`C:\\Program Files\\...\\${win32Commands[0]}`),
225 |         );
226 |         const diffCommand = getDiffCommand('old.txt', 'new.txt', editor);
227 |         expect(diffCommand).toEqual({
228 |           command: win32Commands[0],
229 |           args: ['--wait', '--diff', 'old.txt', 'new.txt'],
230 |         });
231 |       });
232 | 
233 |       if (win32Commands.length > 1) {
234 |         it(`should use second command "${win32Commands[1]}" when first doesn't exist on windows`, () => {
235 |           Object.defineProperty(process, 'platform', { value: 'win32' });
236 |           (execSync as Mock)
237 |             .mockImplementationOnce(() => {
238 |               throw new Error(); // first command not found
239 |             })
240 |             .mockReturnValueOnce(
241 |               Buffer.from(`C:\\Program Files\\...\\${win32Commands[1]}`),
242 |             ); // second command found
243 | 
244 |           const diffCommand = getDiffCommand('old.txt', 'new.txt', editor);
245 |           expect(diffCommand).toEqual({
246 |             command: win32Commands[1],
247 |             args: ['--wait', '--diff', 'old.txt', 'new.txt'],
248 |           });
249 |         });
250 |       }
251 | 
252 |       it(`should fall back to last command "${win32Commands[win32Commands.length - 1]}" when none exist on windows`, () => {
253 |         Object.defineProperty(process, 'platform', { value: 'win32' });
254 |         (execSync as Mock).mockImplementation(() => {
255 |           throw new Error(); // all commands not found
256 |         });
257 | 
258 |         const diffCommand = getDiffCommand('old.txt', 'new.txt', editor);
259 |         expect(diffCommand).toEqual({
260 |           command: win32Commands[win32Commands.length - 1],
261 |           args: ['--wait', '--diff', 'old.txt', 'new.txt'],
262 |         });
263 |       });
264 |     }
265 | 
266 |     const terminalEditors: Array<{
267 |       editor: EditorType;
268 |       command: string;
269 |     }> = [
270 |       { editor: 'vim', command: 'vim' },
271 |       { editor: 'neovim', command: 'nvim' },
272 |     ];
273 | 
274 |     for (const { editor, command } of terminalEditors) {
275 |       it(`should return the correct command for ${editor}`, () => {
276 |         const diffCommand = getDiffCommand('old.txt', 'new.txt', editor);
277 |         expect(diffCommand).toEqual({
278 |           command,
279 |           args: [
280 |             '-d',
281 |             '-i',
282 |             'NONE',
283 |             '-c',
284 |             'wincmd h | set readonly | wincmd l',
285 |             '-c',
286 |             'highlight DiffAdd cterm=bold ctermbg=22 guibg=#005f00 | highlight DiffChange cterm=bold ctermbg=24 guibg=#005f87 | highlight DiffText ctermbg=21 guibg=#0000af | highlight DiffDelete ctermbg=52 guibg=#5f0000',
287 |             '-c',
288 |             'set showtabline=2 | set tabline=[Instructions]\\ :wqa(save\\ &\\ quit)\\ \\|\\ i/esc(toggle\\ edit\\ mode)',
289 |             '-c',
290 |             'wincmd h | setlocal statusline=OLD\\ FILE',
291 |             '-c',
292 |             'wincmd l | setlocal statusline=%#StatusBold#NEW\\ FILE\\ :wqa(save\\ &\\ quit)\\ \\|\\ i/esc(toggle\\ edit\\ mode)',
293 |             '-c',
294 |             'autocmd BufWritePost * wqa',
295 |             'old.txt',
296 |             'new.txt',
297 |           ],
298 |         });
299 |       });
300 |     }
301 | 
302 |     it('should return the correct command for emacs', () => {
303 |       const command = getDiffCommand('old.txt', 'new.txt', 'emacs');
304 |       expect(command).toEqual({
305 |         command: 'emacs',
306 |         args: ['--eval', '(ediff "old.txt" "new.txt")'],
307 |       });
308 |     });
309 | 
310 |     it('should return null for an unsupported editor', () => {
311 |       // @ts-expect-error Testing unsupported editor
312 |       const command = getDiffCommand('old.txt', 'new.txt', 'foobar');
313 |       expect(command).toBeNull();
314 |     });
315 |   });
316 | 
317 |   describe('openDiff', () => {
318 |     const guiEditors: EditorType[] = [
319 |       'vscode',
320 |       'vscodium',
321 |       'windsurf',
322 |       'cursor',
323 |       'zed',
324 |     ];
325 | 
326 |     for (const editor of guiEditors) {
327 |       it(`should call spawn for ${editor}`, async () => {
328 |         const mockSpawnOn = vi.fn((event, cb) => {
329 |           if (event === 'close') {
330 |             cb(0);
331 |           }
332 |         });
333 |         (spawn as Mock).mockReturnValue({ on: mockSpawnOn });
334 | 
335 |         await openDiff('old.txt', 'new.txt', editor, () => {});
336 |         const diffCommand = getDiffCommand('old.txt', 'new.txt', editor)!;
337 |         expect(spawn).toHaveBeenCalledWith(
338 |           diffCommand.command,
339 |           diffCommand.args,
340 |           {
341 |             stdio: 'inherit',
342 |             shell: process.platform === 'win32',
343 |           },
344 |         );
345 |         expect(mockSpawnOn).toHaveBeenCalledWith('close', expect.any(Function));
346 |         expect(mockSpawnOn).toHaveBeenCalledWith('error', expect.any(Function));
347 |       });
348 | 
349 |       it(`should reject if spawn for ${editor} fails`, async () => {
350 |         const mockError = new Error('spawn error');
351 |         const mockSpawnOn = vi.fn((event, cb) => {
352 |           if (event === 'error') {
353 |             cb(mockError);
354 |           }
355 |         });
356 |         (spawn as Mock).mockReturnValue({ on: mockSpawnOn });
357 | 
358 |         await expect(
359 |           openDiff('old.txt', 'new.txt', editor, () => {}),
360 |         ).rejects.toThrow('spawn error');
361 |       });
362 | 
363 |       it(`should reject if ${editor} exits with non-zero code`, async () => {
364 |         const mockSpawnOn = vi.fn((event, cb) => {
365 |           if (event === 'close') {
366 |             cb(1);
367 |           }
368 |         });
369 |         (spawn as Mock).mockReturnValue({ on: mockSpawnOn });
370 | 
371 |         await expect(
372 |           openDiff('old.txt', 'new.txt', editor, () => {}),
373 |         ).rejects.toThrow(`${editor} exited with code 1`);
374 |       });
375 |     }
376 | 
377 |     const terminalEditors: EditorType[] = ['vim', 'neovim', 'emacs'];
378 | 
379 |     for (const editor of terminalEditors) {
380 |       it(`should call spawnSync for ${editor}`, async () => {
381 |         await openDiff('old.txt', 'new.txt', editor, () => {});
382 |         const diffCommand = getDiffCommand('old.txt', 'new.txt', editor)!;
383 |         expect(spawnSync).toHaveBeenCalledWith(
384 |           diffCommand.command,
385 |           diffCommand.args,
386 |           {
387 |             stdio: 'inherit',
388 |           },
389 |         );
390 |       });
391 |     }
392 | 
393 |     it('should log an error if diff command is not available', async () => {
394 |       const consoleErrorSpy = vi
395 |         .spyOn(console, 'error')
396 |         .mockImplementation(() => {});
397 |       // @ts-expect-error Testing unsupported editor
398 |       await openDiff('old.txt', 'new.txt', 'foobar', () => {});
399 |       expect(consoleErrorSpy).toHaveBeenCalledWith(
400 |         'No diff tool available. Install a supported editor.',
401 |       );
402 |     });
403 | 
404 |     describe('onEditorClose callback', () => {
405 |       const terminalEditors: EditorType[] = ['vim', 'neovim', 'emacs'];
406 |       for (const editor of terminalEditors) {
407 |         it(`should call onEditorClose for ${editor} on close`, async () => {
408 |           const onEditorClose = vi.fn();
409 |           await openDiff('old.txt', 'new.txt', editor, onEditorClose);
410 |           expect(onEditorClose).toHaveBeenCalledTimes(1);
411 |         });
412 | 
413 |         it(`should call onEditorClose for ${editor} on error`, async () => {
414 |           const onEditorClose = vi.fn();
415 |           const mockError = new Error('spawn error');
416 |           (spawnSync as Mock).mockImplementation(() => {
417 |             throw mockError;
418 |           });
419 | 
420 |           await expect(
421 |             openDiff('old.txt', 'new.txt', editor, onEditorClose),
422 |           ).rejects.toThrow('spawn error');
423 |           expect(onEditorClose).toHaveBeenCalledTimes(1);
424 |         });
425 |       }
426 | 
427 |       const guiEditors: EditorType[] = [
428 |         'vscode',
429 |         'vscodium',
430 |         'windsurf',
431 |         'cursor',
432 |         'zed',
433 |       ];
434 |       for (const editor of guiEditors) {
435 |         it(`should not call onEditorClose for ${editor}`, async () => {
436 |           const onEditorClose = vi.fn();
437 |           const mockSpawnOn = vi.fn((event, cb) => {
438 |             if (event === 'close') {
439 |               cb(0);
440 |             }
441 |           });
442 |           (spawn as Mock).mockReturnValue({ on: mockSpawnOn });
443 |           await openDiff('old.txt', 'new.txt', editor, onEditorClose);
444 |           expect(onEditorClose).not.toHaveBeenCalled();
445 |         });
446 |       }
447 |     });
448 |   });
449 | 
450 |   describe('allowEditorTypeInSandbox', () => {
451 |     it('should allow vim in sandbox mode', () => {
452 |       vi.stubEnv('SANDBOX', 'sandbox');
453 |       expect(allowEditorTypeInSandbox('vim')).toBe(true);
454 |     });
455 | 
456 |     it('should allow vim when not in sandbox mode', () => {
457 |       expect(allowEditorTypeInSandbox('vim')).toBe(true);
458 |     });
459 | 
460 |     it('should allow emacs in sandbox mode', () => {
461 |       vi.stubEnv('SANDBOX', 'sandbox');
462 |       expect(allowEditorTypeInSandbox('emacs')).toBe(true);
463 |     });
464 | 
465 |     it('should allow emacs when not in sandbox mode', () => {
466 |       expect(allowEditorTypeInSandbox('emacs')).toBe(true);
467 |     });
468 | 
469 |     it('should allow neovim in sandbox mode', () => {
470 |       vi.stubEnv('SANDBOX', 'sandbox');
471 |       expect(allowEditorTypeInSandbox('neovim')).toBe(true);
472 |     });
473 | 
474 |     it('should allow neovim when not in sandbox mode', () => {
475 |       expect(allowEditorTypeInSandbox('neovim')).toBe(true);
476 |     });
477 | 
478 |     const guiEditors: EditorType[] = [
479 |       'vscode',
480 |       'vscodium',
481 |       'windsurf',
482 |       'cursor',
483 |       'zed',
484 |     ];
485 |     for (const editor of guiEditors) {
486 |       it(`should not allow ${editor} in sandbox mode`, () => {
487 |         vi.stubEnv('SANDBOX', 'sandbox');
488 |         expect(allowEditorTypeInSandbox(editor)).toBe(false);
489 |       });
490 | 
491 |       it(`should allow ${editor} when not in sandbox mode`, () => {
492 |         expect(allowEditorTypeInSandbox(editor)).toBe(true);
493 |       });
494 |     }
495 |   });
496 | 
497 |   describe('isEditorAvailable', () => {
498 |     it('should return false for undefined editor', () => {
499 |       expect(isEditorAvailable(undefined)).toBe(false);
500 |     });
501 | 
502 |     it('should return false for empty string editor', () => {
503 |       expect(isEditorAvailable('')).toBe(false);
504 |     });
505 | 
506 |     it('should return false for invalid editor type', () => {
507 |       expect(isEditorAvailable('invalid-editor')).toBe(false);
508 |     });
509 | 
510 |     it('should return true for vscode when installed and not in sandbox mode', () => {
511 |       (execSync as Mock).mockReturnValue(Buffer.from('/usr/bin/code'));
512 |       expect(isEditorAvailable('vscode')).toBe(true);
513 |     });
514 | 
515 |     it('should return false for vscode when not installed and not in sandbox mode', () => {
516 |       (execSync as Mock).mockImplementation(() => {
517 |         throw new Error();
518 |       });
519 |       expect(isEditorAvailable('vscode')).toBe(false);
520 |     });
521 | 
522 |     it('should return false for vscode when installed and in sandbox mode', () => {
523 |       (execSync as Mock).mockReturnValue(Buffer.from('/usr/bin/code'));
524 |       vi.stubEnv('SANDBOX', 'sandbox');
525 |       expect(isEditorAvailable('vscode')).toBe(false);
526 |     });
527 | 
528 |     it('should return true for vim when installed and in sandbox mode', () => {
529 |       (execSync as Mock).mockReturnValue(Buffer.from('/usr/bin/vim'));
530 |       vi.stubEnv('SANDBOX', 'sandbox');
531 |       expect(isEditorAvailable('vim')).toBe(true);
532 |     });
533 | 
534 |     it('should return true for emacs when installed and in sandbox mode', () => {
535 |       (execSync as Mock).mockReturnValue(Buffer.from('/usr/bin/emacs'));
536 |       vi.stubEnv('SANDBOX', 'sandbox');
537 |       expect(isEditorAvailable('emacs')).toBe(true);
538 |     });
539 | 
540 |     it('should return true for neovim when installed and in sandbox mode', () => {
541 |       (execSync as Mock).mockReturnValue(Buffer.from('/usr/bin/nvim'));
542 |       vi.stubEnv('SANDBOX', 'sandbox');
543 |       expect(isEditorAvailable('neovim')).toBe(true);
544 |     });
545 |   });
546 | });
```

src/utils/editor.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { execSync, spawn, spawnSync } from 'node:child_process';
8 | 
9 | export type EditorType =
10 |   | 'vscode'
11 |   | 'vscodium'
12 |   | 'windsurf'
13 |   | 'cursor'
14 |   | 'vim'
15 |   | 'neovim'
16 |   | 'zed'
17 |   | 'emacs';
18 | 
19 | function isValidEditorType(editor: string): editor is EditorType {
20 |   return [
21 |     'vscode',
22 |     'vscodium',
23 |     'windsurf',
24 |     'cursor',
25 |     'vim',
26 |     'neovim',
27 |     'zed',
28 |     'emacs',
29 |   ].includes(editor);
30 | }
31 | 
32 | interface DiffCommand {
33 |   command: string;
34 |   args: string[];
35 | }
36 | 
37 | function commandExists(cmd: string): boolean {
38 |   try {
39 |     execSync(
40 |       process.platform === 'win32' ? `where.exe ${cmd}` : `command -v ${cmd}`,
41 |       { stdio: 'ignore' },
42 |     );
43 |     return true;
44 |   } catch {
45 |     return false;
46 |   }
47 | }
48 | 
49 | /**
50 |  * Editor command configurations for different platforms.
51 |  * Each editor can have multiple possible command names, listed in order of preference.
52 |  */
53 | const editorCommands: Record<
54 |   EditorType,
55 |   { win32: string[]; default: string[] }
56 | > = {
57 |   vscode: { win32: ['code.cmd'], default: ['code'] },
58 |   vscodium: { win32: ['codium.cmd'], default: ['codium'] },
59 |   windsurf: { win32: ['windsurf'], default: ['windsurf'] },
60 |   cursor: { win32: ['cursor'], default: ['cursor'] },
61 |   vim: { win32: ['vim'], default: ['vim'] },
62 |   neovim: { win32: ['nvim'], default: ['nvim'] },
63 |   zed: { win32: ['zed'], default: ['zed', 'zeditor'] },
64 |   emacs: { win32: ['emacs.exe'], default: ['emacs'] },
65 | };
66 | 
67 | export function checkHasEditorType(editor: EditorType): boolean {
68 |   const commandConfig = editorCommands[editor];
69 |   const commands =
70 |     process.platform === 'win32' ? commandConfig.win32 : commandConfig.default;
71 |   return commands.some((cmd) => commandExists(cmd));
72 | }
73 | 
74 | export function allowEditorTypeInSandbox(editor: EditorType): boolean {
75 |   const notUsingSandbox = !process.env['SANDBOX'];
76 |   if (['vscode', 'vscodium', 'windsurf', 'cursor', 'zed'].includes(editor)) {
77 |     return notUsingSandbox;
78 |   }
79 |   // For terminal-based editors like vim and emacs, allow in sandbox.
80 |   return true;
81 | }
82 | 
83 | /**
84 |  * Check if the editor is valid and can be used.
85 |  * Returns false if preferred editor is not set / invalid / not available / not allowed in sandbox.
86 |  */
87 | export function isEditorAvailable(editor: string | undefined): boolean {
88 |   if (editor && isValidEditorType(editor)) {
89 |     return checkHasEditorType(editor) && allowEditorTypeInSandbox(editor);
90 |   }
91 |   return false;
92 | }
93 | 
94 | /**
95 |  * Get the diff command for a specific editor.
96 |  */
97 | export function getDiffCommand(
98 |   oldPath: string,
99 |   newPath: string,
100 |   editor: EditorType,
101 | ): DiffCommand | null {
102 |   if (!isValidEditorType(editor)) {
103 |     return null;
104 |   }
105 |   const commandConfig = editorCommands[editor];
106 |   const commands =
107 |     process.platform === 'win32' ? commandConfig.win32 : commandConfig.default;
108 |   const command =
109 |     commands.slice(0, -1).find((cmd) => commandExists(cmd)) ||
110 |     commands[commands.length - 1];
111 | 
112 |   switch (editor) {
113 |     case 'vscode':
114 |     case 'vscodium':
115 |     case 'windsurf':
116 |     case 'cursor':
117 |     case 'zed':
118 |       return { command, args: ['--wait', '--diff', oldPath, newPath] };
119 |     case 'vim':
120 |     case 'neovim':
121 |       return {
122 |         command,
123 |         args: [
124 |           '-d',
125 |           // skip viminfo file to avoid E138 errors
126 |           '-i',
127 |           'NONE',
128 |           // make the left window read-only and the right window editable
129 |           '-c',
130 |           'wincmd h | set readonly | wincmd l',
131 |           // set up colors for diffs
132 |           '-c',
133 |           'highlight DiffAdd cterm=bold ctermbg=22 guibg=#005f00 | highlight DiffChange cterm=bold ctermbg=24 guibg=#005f87 | highlight DiffText ctermbg=21 guibg=#0000af | highlight DiffDelete ctermbg=52 guibg=#5f0000',
134 |           // Show helpful messages
135 |           '-c',
136 |           'set showtabline=2 | set tabline=[Instructions]\\ :wqa(save\\ &\\ quit)\\ \\|\\ i/esc(toggle\\ edit\\ mode)',
137 |           '-c',
138 |           'wincmd h | setlocal statusline=OLD\\ FILE',
139 |           '-c',
140 |           'wincmd l | setlocal statusline=%#StatusBold#NEW\\ FILE\\ :wqa(save\\ &\\ quit)\\ \\|\\ i/esc(toggle\\ edit\\ mode)',
141 |           // Auto close all windows when one is closed
142 |           '-c',
143 |           'autocmd BufWritePost * wqa',
144 |           oldPath,
145 |           newPath,
146 |         ],
147 |       };
148 |     case 'emacs':
149 |       return {
150 |         command: 'emacs',
151 |         args: ['--eval', `(ediff "${oldPath}" "${newPath}")`],
152 |       };
153 |     default:
154 |       return null;
155 |   }
156 | }
157 | 
158 | /**
159 |  * Opens a diff tool to compare two files.
160 |  * Terminal-based editors by default blocks parent process until the editor exits.
161 |  * GUI-based editors require args such as "--wait" to block parent process.
162 |  */
163 | export async function openDiff(
164 |   oldPath: string,
165 |   newPath: string,
166 |   editor: EditorType,
167 |   onEditorClose: () => void,
168 | ): Promise<void> {
169 |   const diffCommand = getDiffCommand(oldPath, newPath, editor);
170 |   if (!diffCommand) {
171 |     console.error('No diff tool available. Install a supported editor.');
172 |     return;
173 |   }
174 | 
175 |   try {
176 |     const isTerminalEditor = ['vim', 'emacs', 'neovim'].includes(editor);
177 | 
178 |     if (isTerminalEditor) {
179 |       try {
180 |         const result = spawnSync(diffCommand.command, diffCommand.args, {
181 |           stdio: 'inherit',
182 |         });
183 |         if (result.error) {
184 |           throw result.error;
185 |         }
186 |         if (result.status !== 0) {
187 |           throw new Error(`${editor} exited with code ${result.status}`);
188 |         }
189 |       } finally {
190 |         onEditorClose();
191 |       }
192 |       return;
193 |     }
194 | 
195 |     return new Promise<void>((resolve, reject) => {
196 |       const childProcess = spawn(diffCommand.command, diffCommand.args, {
197 |         stdio: 'inherit',
198 |         shell: process.platform === 'win32',
199 |       });
200 | 
201 |       childProcess.on('close', (code) => {
202 |         if (code === 0) {
203 |           resolve();
204 |         } else {
205 |           reject(new Error(`${editor} exited with code ${code}`));
206 |         }
207 |       });
208 | 
209 |       childProcess.on('error', (error) => {
210 |         reject(error);
211 |       });
212 |     });
213 |   } catch (error) {
214 |     console.error(error);
215 |     throw error;
216 |   }
217 | }
```

src/utils/environmentContext.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   vi,
12 |   beforeEach,
13 |   afterEach,
14 |   type Mock,
15 | } from 'vitest';
16 | import {
17 |   getEnvironmentContext,
18 |   getDirectoryContextString,
19 | } from './environmentContext.js';
20 | import type { Config } from '../config/config.js';
21 | import { getFolderStructure } from './getFolderStructure.js';
22 | 
23 | vi.mock('../config/config.js');
24 | vi.mock('./getFolderStructure.js', () => ({
25 |   getFolderStructure: vi.fn(),
26 | }));
27 | vi.mock('../tools/read-many-files.js');
28 | 
29 | describe('getDirectoryContextString', () => {
30 |   let mockConfig: Partial<Config>;
31 | 
32 |   beforeEach(() => {
33 |     mockConfig = {
34 |       getWorkspaceContext: vi.fn().mockReturnValue({
35 |         getDirectories: vi.fn().mockReturnValue(['/test/dir']),
36 |       }),
37 |       getFileService: vi.fn(),
38 |     };
39 |     vi.mocked(getFolderStructure).mockResolvedValue('Mock Folder Structure');
40 |   });
41 | 
42 |   afterEach(() => {
43 |     vi.resetAllMocks();
44 |   });
45 | 
46 |   it('should return context string for a single directory', async () => {
47 |     const contextString = await getDirectoryContextString(mockConfig as Config);
48 |     expect(contextString).toContain(
49 |       "I'm currently working in the directory: /test/dir",
50 |     );
51 |     expect(contextString).toContain(
52 |       'Here is the folder structure of the current working directories:\n\nMock Folder Structure',
53 |     );
54 |   });
55 | 
56 |   it('should return context string for multiple directories', async () => {
57 |     (
58 |       vi.mocked(mockConfig.getWorkspaceContext!)().getDirectories as Mock
59 |     ).mockReturnValue(['/test/dir1', '/test/dir2']);
60 |     vi.mocked(getFolderStructure)
61 |       .mockResolvedValueOnce('Structure 1')
62 |       .mockResolvedValueOnce('Structure 2');
63 | 
64 |     const contextString = await getDirectoryContextString(mockConfig as Config);
65 |     expect(contextString).toContain(
66 |       "I'm currently working in the following directories:\n  - /test/dir1\n  - /test/dir2",
67 |     );
68 |     expect(contextString).toContain(
69 |       'Here is the folder structure of the current working directories:\n\nStructure 1\nStructure 2',
70 |     );
71 |   });
72 | });
73 | 
74 | describe('getEnvironmentContext', () => {
75 |   let mockConfig: Partial<Config>;
76 |   let mockToolRegistry: { getTool: Mock };
77 | 
78 |   beforeEach(() => {
79 |     vi.useFakeTimers();
80 |     vi.setSystemTime(new Date('2025-08-05T12:00:00Z'));
81 | 
82 |     mockToolRegistry = {
83 |       getTool: vi.fn(),
84 |     };
85 | 
86 |     mockConfig = {
87 |       getWorkspaceContext: vi.fn().mockReturnValue({
88 |         getDirectories: vi.fn().mockReturnValue(['/test/dir']),
89 |       }),
90 |       getFileService: vi.fn(),
91 |       getFullContext: vi.fn().mockReturnValue(false),
92 |       getToolRegistry: vi.fn().mockReturnValue(mockToolRegistry),
93 |     };
94 | 
95 |     vi.mocked(getFolderStructure).mockResolvedValue('Mock Folder Structure');
96 |   });
97 | 
98 |   afterEach(() => {
99 |     vi.useRealTimers();
100 |     vi.resetAllMocks();
101 |   });
102 | 
103 |   it('should return basic environment context for a single directory', async () => {
104 |     const parts = await getEnvironmentContext(mockConfig as Config);
105 | 
106 |     expect(parts.length).toBe(1);
107 |     const context = parts[0].text;
108 | 
109 |     expect(context).toContain("Today's date is");
110 |     expect(context).toContain("(formatted according to the user's locale)");
111 |     expect(context).toContain(`My operating system is: ${process.platform}`);
112 |     expect(context).toContain(
113 |       "I'm currently working in the directory: /test/dir",
114 |     );
115 |     expect(context).toContain(
116 |       'Here is the folder structure of the current working directories:\n\nMock Folder Structure',
117 |     );
118 |     expect(getFolderStructure).toHaveBeenCalledWith('/test/dir', {
119 |       fileService: undefined,
120 |     });
121 |   });
122 | 
123 |   it('should return basic environment context for multiple directories', async () => {
124 |     (
125 |       vi.mocked(mockConfig.getWorkspaceContext!)().getDirectories as Mock
126 |     ).mockReturnValue(['/test/dir1', '/test/dir2']);
127 |     vi.mocked(getFolderStructure)
128 |       .mockResolvedValueOnce('Structure 1')
129 |       .mockResolvedValueOnce('Structure 2');
130 | 
131 |     const parts = await getEnvironmentContext(mockConfig as Config);
132 | 
133 |     expect(parts.length).toBe(1);
134 |     const context = parts[0].text;
135 | 
136 |     expect(context).toContain(
137 |       "I'm currently working in the following directories:\n  - /test/dir1\n  - /test/dir2",
138 |     );
139 |     expect(context).toContain(
140 |       'Here is the folder structure of the current working directories:\n\nStructure 1\nStructure 2',
141 |     );
142 |     expect(getFolderStructure).toHaveBeenCalledTimes(2);
143 |   });
144 | 
145 |   it('should include full file context when getFullContext is true', async () => {
146 |     mockConfig.getFullContext = vi.fn().mockReturnValue(true);
147 |     const mockReadManyFilesTool = {
148 |       build: vi.fn().mockReturnValue({
149 |         execute: vi
150 |           .fn()
151 |           .mockResolvedValue({ llmContent: 'Full file content here' }),
152 |       }),
153 |     };
154 |     mockToolRegistry.getTool.mockReturnValue(mockReadManyFilesTool);
155 | 
156 |     const parts = await getEnvironmentContext(mockConfig as Config);
157 | 
158 |     expect(parts.length).toBe(2);
159 |     expect(parts[1].text).toBe(
160 |       '\n--- Full File Context ---\nFull file content here',
161 |     );
162 |     expect(mockToolRegistry.getTool).toHaveBeenCalledWith('read_many_files');
163 |     expect(mockReadManyFilesTool.build).toHaveBeenCalledWith({
164 |       paths: ['**/*'],
165 |       useDefaultExcludes: true,
166 |     });
167 |   });
168 | 
169 |   it('should handle read_many_files returning no content', async () => {
170 |     mockConfig.getFullContext = vi.fn().mockReturnValue(true);
171 |     const mockReadManyFilesTool = {
172 |       build: vi.fn().mockReturnValue({
173 |         execute: vi.fn().mockResolvedValue({ llmContent: '' }),
174 |       }),
175 |     };
176 |     mockToolRegistry.getTool.mockReturnValue(mockReadManyFilesTool);
177 | 
178 |     const parts = await getEnvironmentContext(mockConfig as Config);
179 | 
180 |     expect(parts.length).toBe(1); // No extra part added
181 |   });
182 | 
183 |   it('should handle read_many_files tool not being found', async () => {
184 |     mockConfig.getFullContext = vi.fn().mockReturnValue(true);
185 |     mockToolRegistry.getTool.mockReturnValue(null);
186 | 
187 |     const parts = await getEnvironmentContext(mockConfig as Config);
188 | 
189 |     expect(parts.length).toBe(1); // No extra part added
190 |   });
191 | 
192 |   it('should handle errors when reading full file context', async () => {
193 |     mockConfig.getFullContext = vi.fn().mockReturnValue(true);
194 |     const mockReadManyFilesTool = {
195 |       build: vi.fn().mockReturnValue({
196 |         execute: vi.fn().mockRejectedValue(new Error('Read error')),
197 |       }),
198 |     };
199 |     mockToolRegistry.getTool.mockReturnValue(mockReadManyFilesTool);
200 | 
201 |     const parts = await getEnvironmentContext(mockConfig as Config);
202 | 
203 |     expect(parts.length).toBe(2);
204 |     expect(parts[1].text).toBe('\n--- Error reading full file context ---');
205 |   });
206 | });
```

src/utils/environmentContext.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Part } from '@google/genai';
8 | import type { Config } from '../config/config.js';
9 | import { getFolderStructure } from './getFolderStructure.js';
10 | 
11 | /**
12 |  * Generates a string describing the current workspace directories and their structures.
13 |  * @param {Config} config - The runtime configuration and services.
14 |  * @returns {Promise<string>} A promise that resolves to the directory context string.
15 |  */
16 | export async function getDirectoryContextString(
17 |   config: Config,
18 | ): Promise<string> {
19 |   const workspaceContext = config.getWorkspaceContext();
20 |   const workspaceDirectories = workspaceContext.getDirectories();
21 | 
22 |   const folderStructures = await Promise.all(
23 |     workspaceDirectories.map((dir) =>
24 |       getFolderStructure(dir, {
25 |         fileService: config.getFileService(),
26 |       }),
27 |     ),
28 |   );
29 | 
30 |   const folderStructure = folderStructures.join('\n');
31 | 
32 |   let workingDirPreamble: string;
33 |   if (workspaceDirectories.length === 1) {
34 |     workingDirPreamble = `I'm currently working in the directory: ${workspaceDirectories[0]}`;
35 |   } else {
36 |     const dirList = workspaceDirectories.map((dir) => `  - ${dir}`).join('\n');
37 |     workingDirPreamble = `I'm currently working in the following directories:\n${dirList}`;
38 |   }
39 | 
40 |   return `${workingDirPreamble}
41 | Here is the folder structure of the current working directories:
42 | 
43 | ${folderStructure}`;
44 | }
45 | 
46 | /**
47 |  * Retrieves environment-related information to be included in the chat context.
48 |  * This includes the current working directory, date, operating system, and folder structure.
49 |  * Optionally, it can also include the full file context if enabled.
50 |  * @param {Config} config - The runtime configuration and services.
51 |  * @returns A promise that resolves to an array of `Part` objects containing environment information.
52 |  */
53 | export async function getEnvironmentContext(config: Config): Promise<Part[]> {
54 |   const today = new Date().toLocaleDateString(undefined, {
55 |     weekday: 'long',
56 |     year: 'numeric',
57 |     month: 'long',
58 |     day: 'numeric',
59 |   });
60 |   const platform = process.platform;
61 |   const directoryContext = await getDirectoryContextString(config);
62 | 
63 |   const context = `
64 | This is the Gemini CLI. We are setting up the context for our chat.
65 | Today's date is ${today} (formatted according to the user's locale).
66 | My operating system is: ${platform}
67 | ${directoryContext}
68 |         `.trim();
69 | 
70 |   const initialParts: Part[] = [{ text: context }];
71 |   const toolRegistry = config.getToolRegistry();
72 | 
73 |   // Add full file context if the flag is set
74 |   if (config.getFullContext()) {
75 |     try {
76 |       const readManyFilesTool = toolRegistry.getTool('read_many_files');
77 |       if (readManyFilesTool) {
78 |         const invocation = readManyFilesTool.build({
79 |           paths: ['**/*'], // Read everything recursively
80 |           useDefaultExcludes: true, // Use default excludes
81 |         });
82 | 
83 |         // Read all files in the target directory
84 |         const result = await invocation.execute(AbortSignal.timeout(30000));
85 |         if (result.llmContent) {
86 |           initialParts.push({
87 |             text: `\n--- Full File Context ---\n${result.llmContent}`,
88 |           });
89 |         } else {
90 |           console.warn(
91 |             'Full context requested, but read_many_files returned no content.',
92 |           );
93 |         }
94 |       } else {
95 |         console.warn(
96 |           'Full context requested, but read_many_files tool not found.',
97 |         );
98 |       }
99 |     } catch (error) {
100 |       // Not using reportError here as it's a startup/config phase, not a chat/generation phase error.
101 |       console.error('Error reading full file context:', error);
102 |       initialParts.push({
103 |         text: '\n--- Error reading full file context ---',
104 |       });
105 |     }
106 |   }
107 | 
108 |   return initialParts;
109 | }
```

src/utils/errorParsing.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { parseAndFormatApiError } from './errorParsing.js';
9 | import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';
10 | import { AuthType } from '../core/contentGenerator.js';
11 | import type { StructuredError } from '../core/turn.js';
12 | 
13 | describe('parseAndFormatApiError', () => {
14 |   const vertexMessage = 'request a quota increase through Vertex';
15 |   const geminiMessage = 'request a quota increase through AI Studio';
16 | 
17 |   it('should format a valid API error JSON', () => {
18 |     const errorMessage =
19 |       'got status: 400 Bad Request. {"error":{"code":400,"message":"API key not valid. Please pass a valid API key.","status":"INVALID_ARGUMENT"}}';
20 |     const expected =
21 |       '[API Error: API key not valid. Please pass a valid API key. (Status: INVALID_ARGUMENT)]';
22 |     expect(parseAndFormatApiError(errorMessage)).toBe(expected);
23 |   });
24 | 
25 |   it('should format a 429 API error with the default message', () => {
26 |     const errorMessage =
27 |       'got status: 429 Too Many Requests. {"error":{"code":429,"message":"Rate limit exceeded","status":"RESOURCE_EXHAUSTED"}}';
28 |     const result = parseAndFormatApiError(
29 |       errorMessage,
30 |       undefined,
31 |       undefined,
32 |       'gemini-2.5-pro',
33 |       DEFAULT_GEMINI_FLASH_MODEL,
34 |     );
35 |     expect(result).toContain('[API Error: Rate limit exceeded');
36 |     expect(result).toContain(
37 |       'Possible quota limitations in place or slow response times detected. Switching to the gemini-2.5-flash model',
38 |     );
39 |   });
40 | 
41 |   it('should format a 429 API error with the vertex message', () => {
42 |     const errorMessage =
43 |       'got status: 429 Too Many Requests. {"error":{"code":429,"message":"Rate limit exceeded","status":"RESOURCE_EXHAUSTED"}}';
44 |     const result = parseAndFormatApiError(errorMessage, AuthType.USE_VERTEX_AI);
45 |     expect(result).toContain('[API Error: Rate limit exceeded');
46 |     expect(result).toContain(vertexMessage);
47 |   });
48 | 
49 |   it('should return the original message if it is not a JSON error', () => {
50 |     const errorMessage = 'This is a plain old error message';
51 |     expect(parseAndFormatApiError(errorMessage)).toBe(
52 |       `[API Error: ${errorMessage}]`,
53 |     );
54 |   });
55 | 
56 |   it('should return the original message for malformed JSON', () => {
57 |     const errorMessage = '[Stream Error: {"error": "malformed}';
58 |     expect(parseAndFormatApiError(errorMessage)).toBe(
59 |       `[API Error: ${errorMessage}]`,
60 |     );
61 |   });
62 | 
63 |   it('should handle JSON that does not match the ApiError structure', () => {
64 |     const errorMessage = '[Stream Error: {"not_an_error": "some other json"}]';
65 |     expect(parseAndFormatApiError(errorMessage)).toBe(
66 |       `[API Error: ${errorMessage}]`,
67 |     );
68 |   });
69 | 
70 |   it('should format a nested API error', () => {
71 |     const nestedErrorMessage = JSON.stringify({
72 |       error: {
73 |         code: 429,
74 |         message:
75 |           "Gemini 2.5 Pro Preview doesn't have a free quota tier. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.",
76 |         status: 'RESOURCE_EXHAUSTED',
77 |       },
78 |     });
79 | 
80 |     const errorMessage = JSON.stringify({
81 |       error: {
82 |         code: 429,
83 |         message: nestedErrorMessage,
84 |         status: 'Too Many Requests',
85 |       },
86 |     });
87 | 
88 |     const result = parseAndFormatApiError(errorMessage, AuthType.USE_GEMINI);
89 |     expect(result).toContain('Gemini 2.5 Pro Preview');
90 |     expect(result).toContain(geminiMessage);
91 |   });
92 | 
93 |   it('should format a StructuredError', () => {
94 |     const error: StructuredError = {
95 |       message: 'A structured error occurred',
96 |       status: 500,
97 |     };
98 |     const expected = '[API Error: A structured error occurred]';
99 |     expect(parseAndFormatApiError(error)).toBe(expected);
100 |   });
101 | 
102 |   it('should format a 429 StructuredError with the vertex message', () => {
103 |     const error: StructuredError = {
104 |       message: 'Rate limit exceeded',
105 |       status: 429,
106 |     };
107 |     const result = parseAndFormatApiError(error, AuthType.USE_VERTEX_AI);
108 |     expect(result).toContain('[API Error: Rate limit exceeded]');
109 |     expect(result).toContain(vertexMessage);
110 |   });
111 | 
112 |   it('should handle an unknown error type', () => {
113 |     const error = 12345;
114 |     const expected = '[API Error: An unknown error occurred.]';
115 |     expect(parseAndFormatApiError(error)).toBe(expected);
116 |   });
117 | });
```

src/utils/errorParsing.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { isApiError, isStructuredError } from './quotaErrorDetection.js';
8 | import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';
9 | import type { UserTierId } from '../code_assist/types.js';
10 | import { AuthType } from '../core/contentGenerator.js';
11 | 
12 | const RATE_LIMIT_ERROR_MESSAGE_USE_GEMINI =
13 |   '\nPlease wait and try again later. To increase your limits, request a quota increase through AI Studio, or switch to another /auth method';
14 | const RATE_LIMIT_ERROR_MESSAGE_VERTEX =
15 |   '\nPlease wait and try again later. To increase your limits, request a quota increase through Vertex, or switch to another /auth method';
16 | const getRateLimitErrorMessageDefault = (
17 |   fallbackModel: string = DEFAULT_GEMINI_FLASH_MODEL,
18 | ) =>
19 |   `\nPossible quota limitations in place or slow response times detected. Switching to the ${fallbackModel} model for the rest of this session.`;
20 | 
21 | function getRateLimitMessage(
22 |   authType?: AuthType,
23 |   fallbackModel?: string,
24 | ): string {
25 |   switch (authType) {
26 |     case AuthType.USE_GEMINI:
27 |       return RATE_LIMIT_ERROR_MESSAGE_USE_GEMINI;
28 |     case AuthType.USE_VERTEX_AI:
29 |       return RATE_LIMIT_ERROR_MESSAGE_VERTEX;
30 |     default:
31 |       return getRateLimitErrorMessageDefault(fallbackModel);
32 |   }
33 | }
34 | 
35 | export function parseAndFormatApiError(
36 |   error: unknown,
37 |   authType?: AuthType,
38 |   userTier?: UserTierId,
39 |   currentModel?: string,
40 |   fallbackModel?: string,
41 | ): string {
42 |   if (isStructuredError(error)) {
43 |     let text = `[API Error: ${error.message}]`;
44 |     if (error.status === 429) {
45 |       text += getRateLimitMessage(authType, fallbackModel);
46 |     }
47 |     return text;
48 |   }
49 | 
50 |   // The error message might be a string containing a JSON object.
51 |   if (typeof error === 'string') {
52 |     const jsonStart = error.indexOf('{');
53 |     if (jsonStart === -1) {
54 |       return `[API Error: ${error}]`; // Not a JSON error, return as is.
55 |     }
56 | 
57 |     const jsonString = error.substring(jsonStart);
58 | 
59 |     try {
60 |       const parsedError = JSON.parse(jsonString) as unknown;
61 |       if (isApiError(parsedError)) {
62 |         let finalMessage = parsedError.error.message;
63 |         try {
64 |           // See if the message is a stringified JSON with another error
65 |           const nestedError = JSON.parse(finalMessage) as unknown;
66 |           if (isApiError(nestedError)) {
67 |             finalMessage = nestedError.error.message;
68 |           }
69 |         } catch (_e) {
70 |           // It's not a nested JSON error, so we just use the message as is.
71 |         }
72 |         let text = `[API Error: ${finalMessage} (Status: ${parsedError.error.status})]`;
73 |         if (parsedError.error.code === 429) {
74 |           text += getRateLimitMessage(authType, fallbackModel);
75 |         }
76 |         return text;
77 |       }
78 |     } catch (_e) {
79 |       // Not a valid JSON, fall through and return the original message.
80 |     }
81 |     return `[API Error: ${error}]`;
82 |   }
83 | 
84 |   return '[API Error: An unknown error occurred.]';
85 | }
```

src/utils/errorReporting.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import fs from 'node:fs/promises';
9 | import os from 'node:os';
10 | import path from 'node:path';
11 | import { reportError } from './errorReporting.js';
12 | 
13 | // Use a type alias for SpyInstance as it's not directly exported
14 | type SpyInstance = ReturnType<typeof vi.spyOn>;
15 | 
16 | describe('reportError', () => {
17 |   let consoleErrorSpy: SpyInstance;
18 |   let testDir: string;
19 |   const MOCK_TIMESTAMP = '2025-01-01T00-00-00-000Z';
20 | 
21 |   beforeEach(async () => {
22 |     // Create a temporary directory for logs
23 |     testDir = await fs.mkdtemp(path.join(os.tmpdir(), 'gemini-report-test-'));
24 |     vi.resetAllMocks();
25 |     consoleErrorSpy = vi.spyOn(console, 'error').mockImplementation(() => {});
26 |     vi.spyOn(Date.prototype, 'toISOString').mockReturnValue(MOCK_TIMESTAMP);
27 |   });
28 | 
29 |   afterEach(async () => {
30 |     vi.restoreAllMocks();
31 |     // Clean up the temporary directory
32 |     await fs.rm(testDir, { recursive: true, force: true });
33 |   });
34 | 
35 |   const getExpectedReportPath = (type: string) =>
36 |     path.join(testDir, `gemini-client-error-${type}-${MOCK_TIMESTAMP}.json`);
37 | 
38 |   it('should generate a report and log the path', async () => {
39 |     const error = new Error('Test error');
40 |     error.stack = 'Test stack';
41 |     const baseMessage = 'An error occurred.';
42 |     const context = { data: 'test context' };
43 |     const type = 'test-type';
44 |     const expectedReportPath = getExpectedReportPath(type);
45 | 
46 |     await reportError(error, baseMessage, context, type, testDir);
47 | 
48 |     // Verify the file was written
49 |     const reportContent = await fs.readFile(expectedReportPath, 'utf-8');
50 |     const parsedReport = JSON.parse(reportContent);
51 | 
52 |     expect(parsedReport).toEqual({
53 |       error: { message: 'Test error', stack: 'Test stack' },
54 |       context,
55 |     });
56 | 
57 |     // Verify the console log
58 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
59 |       `${baseMessage} Full report available at: ${expectedReportPath}`,
60 |     );
61 |   });
62 | 
63 |   it('should handle errors that are plain objects with a message property', async () => {
64 |     const error = { message: 'Test plain object error' };
65 |     const baseMessage = 'Another error.';
66 |     const type = 'general';
67 |     const expectedReportPath = getExpectedReportPath(type);
68 | 
69 |     await reportError(error, baseMessage, undefined, type, testDir);
70 | 
71 |     const reportContent = await fs.readFile(expectedReportPath, 'utf-8');
72 |     const parsedReport = JSON.parse(reportContent);
73 | 
74 |     expect(parsedReport).toEqual({
75 |       error: { message: 'Test plain object error' },
76 |     });
77 | 
78 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
79 |       `${baseMessage} Full report available at: ${expectedReportPath}`,
80 |     );
81 |   });
82 | 
83 |   it('should handle string errors', async () => {
84 |     const error = 'Just a string error';
85 |     const baseMessage = 'String error occurred.';
86 |     const type = 'general';
87 |     const expectedReportPath = getExpectedReportPath(type);
88 | 
89 |     await reportError(error, baseMessage, undefined, type, testDir);
90 | 
91 |     const reportContent = await fs.readFile(expectedReportPath, 'utf-8');
92 |     const parsedReport = JSON.parse(reportContent);
93 | 
94 |     expect(parsedReport).toEqual({
95 |       error: { message: 'Just a string error' },
96 |     });
97 | 
98 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
99 |       `${baseMessage} Full report available at: ${expectedReportPath}`,
100 |     );
101 |   });
102 | 
103 |   it('should log fallback message if writing report fails', async () => {
104 |     const error = new Error('Main error');
105 |     const baseMessage = 'Failed operation.';
106 |     const context = ['some context'];
107 |     const type = 'general';
108 |     const nonExistentDir = path.join(testDir, 'non-existent-dir');
109 | 
110 |     await reportError(error, baseMessage, context, type, nonExistentDir);
111 | 
112 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
113 |       `${baseMessage} Additionally, failed to write detailed error report:`,
114 |       expect.any(Error), // The actual write error
115 |     );
116 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
117 |       'Original error that triggered report generation:',
118 |       error,
119 |     );
120 |     expect(consoleErrorSpy).toHaveBeenCalledWith('Original context:', context);
121 |   });
122 | 
123 |   it('should handle stringification failure of report content (e.g. BigInt in context)', async () => {
124 |     const error = new Error('Main error');
125 |     error.stack = 'Main stack';
126 |     const baseMessage = 'Failed operation with BigInt.';
127 |     const context = { a: BigInt(1) }; // BigInt cannot be stringified by JSON.stringify
128 |     const type = 'bigint-fail';
129 |     const stringifyError = new TypeError(
130 |       'Do not know how to serialize a BigInt',
131 |     );
132 |     const expectedMinimalReportPath = getExpectedReportPath(type);
133 | 
134 |     // Simulate JSON.stringify throwing an error for the full report
135 |     const originalJsonStringify = JSON.stringify;
136 |     let callCount = 0;
137 |     vi.spyOn(JSON, 'stringify').mockImplementation((value, replacer, space) => {
138 |       callCount++;
139 |       if (callCount === 1) {
140 |         // First call is for the full report content
141 |         throw stringifyError;
142 |       }
143 |       // Subsequent calls (for minimal report) should succeed
144 |       return originalJsonStringify(value, replacer, space);
145 |     });
146 | 
147 |     await reportError(error, baseMessage, context, type, testDir);
148 | 
149 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
150 |       `${baseMessage} Could not stringify report content (likely due to context):`,
151 |       stringifyError,
152 |     );
153 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
154 |       'Original error that triggered report generation:',
155 |       error,
156 |     );
157 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
158 |       'Original context could not be stringified or included in report.',
159 |     );
160 | 
161 |     // Check that it writes a minimal report
162 |     const reportContent = await fs.readFile(expectedMinimalReportPath, 'utf-8');
163 |     const parsedReport = JSON.parse(reportContent);
164 |     expect(parsedReport).toEqual({
165 |       error: { message: error.message, stack: error.stack },
166 |     });
167 | 
168 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
169 |       `${baseMessage} Partial report (excluding context) available at: ${expectedMinimalReportPath}`,
170 |     );
171 |   });
172 | 
173 |   it('should generate a report without context if context is not provided', async () => {
174 |     const error = new Error('Error without context');
175 |     error.stack = 'No context stack';
176 |     const baseMessage = 'Simple error.';
177 |     const type = 'general';
178 |     const expectedReportPath = getExpectedReportPath(type);
179 | 
180 |     await reportError(error, baseMessage, undefined, type, testDir);
181 | 
182 |     const reportContent = await fs.readFile(expectedReportPath, 'utf-8');
183 |     const parsedReport = JSON.parse(reportContent);
184 | 
185 |     expect(parsedReport).toEqual({
186 |       error: { message: 'Error without context', stack: 'No context stack' },
187 |     });
188 | 
189 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
190 |       `${baseMessage} Full report available at: ${expectedReportPath}`,
191 |     );
192 |   });
193 | });
```

src/utils/errorReporting.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import fs from 'node:fs/promises';
8 | import os from 'node:os';
9 | import path from 'node:path';
10 | import type { Content } from '@google/genai';
11 | 
12 | interface ErrorReportData {
13 |   error: { message: string; stack?: string } | { message: string };
14 |   context?: unknown;
15 |   additionalInfo?: Record<string, unknown>;
16 | }
17 | 
18 | /**
19 |  * Generates an error report, writes it to a temporary file, and logs information to console.error.
20 |  * @param error The error object.
21 |  * @param context The relevant context (e.g., chat history, request contents).
22 |  * @param type A string to identify the type of error (e.g., 'startChat', 'generateJson-api').
23 |  * @param baseMessage The initial message to log to console.error before the report path.
24 |  */
25 | export async function reportError(
26 |   error: Error | unknown,
27 |   baseMessage: string,
28 |   context?: Content[] | Record<string, unknown> | unknown[],
29 |   type = 'general',
30 |   reportingDir = os.tmpdir(), // for testing
31 | ): Promise<void> {
32 |   const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
33 |   const reportFileName = `gemini-client-error-${type}-${timestamp}.json`;
34 |   const reportPath = path.join(reportingDir, reportFileName);
35 | 
36 |   let errorToReport: { message: string; stack?: string };
37 |   if (error instanceof Error) {
38 |     errorToReport = { message: error.message, stack: error.stack };
39 |   } else if (
40 |     typeof error === 'object' &&
41 |     error !== null &&
42 |     'message' in error
43 |   ) {
44 |     errorToReport = {
45 |       message: String((error as { message: unknown }).message),
46 |     };
47 |   } else {
48 |     errorToReport = { message: String(error) };
49 |   }
50 | 
51 |   const reportContent: ErrorReportData = { error: errorToReport };
52 | 
53 |   if (context) {
54 |     reportContent.context = context;
55 |   }
56 | 
57 |   let stringifiedReportContent: string;
58 |   try {
59 |     stringifiedReportContent = JSON.stringify(reportContent, null, 2);
60 |   } catch (stringifyError) {
61 |     // This can happen if context contains something like BigInt
62 |     console.error(
63 |       `${baseMessage} Could not stringify report content (likely due to context):`,
64 |       stringifyError,
65 |     );
66 |     console.error('Original error that triggered report generation:', error);
67 |     if (context) {
68 |       console.error(
69 |         'Original context could not be stringified or included in report.',
70 |       );
71 |     }
72 |     // Fallback: try to report only the error if context was the issue
73 |     try {
74 |       const minimalReportContent = { error: errorToReport };
75 |       stringifiedReportContent = JSON.stringify(minimalReportContent, null, 2);
76 |       // Still try to write the minimal report
77 |       await fs.writeFile(reportPath, stringifiedReportContent);
78 |       console.error(
79 |         `${baseMessage} Partial report (excluding context) available at: ${reportPath}`,
80 |       );
81 |     } catch (minimalWriteError) {
82 |       console.error(
83 |         `${baseMessage} Failed to write even a minimal error report:`,
84 |         minimalWriteError,
85 |       );
86 |     }
87 |     return;
88 |   }
89 | 
90 |   try {
91 |     await fs.writeFile(reportPath, stringifiedReportContent);
92 |     console.error(`${baseMessage} Full report available at: ${reportPath}`);
93 |   } catch (writeError) {
94 |     console.error(
95 |       `${baseMessage} Additionally, failed to write detailed error report:`,
96 |       writeError,
97 |     );
98 |     // Log the original error as a fallback if report writing fails
99 |     console.error('Original error that triggered report generation:', error);
100 |     if (context) {
101 |       // Context was stringifiable, but writing the file failed.
102 |       // We already have stringifiedReportContent, but it might be too large for console.
103 |       // So, we try to log the original context object, and if that fails, its stringified version (truncated).
104 |       try {
105 |         console.error('Original context:', context);
106 |       } catch {
107 |         try {
108 |           console.error(
109 |             'Original context (stringified, truncated):',
110 |             JSON.stringify(context).substring(0, 1000),
111 |           );
112 |         } catch {
113 |           console.error('Original context could not be logged or stringified.');
114 |         }
115 |       }
116 |     }
117 |   }
118 | }
```

src/utils/errors.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | interface GaxiosError {
8 |   response?: {
9 |     data?: unknown;
10 |   };
11 | }
12 | 
13 | export function isNodeError(error: unknown): error is NodeJS.ErrnoException {
14 |   return error instanceof Error && 'code' in error;
15 | }
16 | 
17 | export function getErrorMessage(error: unknown): string {
18 |   if (error instanceof Error) {
19 |     return error.message;
20 |   }
21 |   try {
22 |     return String(error);
23 |   } catch {
24 |     return 'Failed to get error details';
25 |   }
26 | }
27 | 
28 | export class FatalError extends Error {
29 |   constructor(
30 |     message: string,
31 |     readonly exitCode: number,
32 |   ) {
33 |     super(message);
34 |   }
35 | }
36 | 
37 | export class FatalAuthenticationError extends FatalError {
38 |   constructor(message: string) {
39 |     super(message, 41);
40 |   }
41 | }
42 | export class FatalInputError extends FatalError {
43 |   constructor(message: string) {
44 |     super(message, 42);
45 |   }
46 | }
47 | export class FatalSandboxError extends FatalError {
48 |   constructor(message: string) {
49 |     super(message, 44);
50 |   }
51 | }
52 | export class FatalConfigError extends FatalError {
53 |   constructor(message: string) {
54 |     super(message, 52);
55 |   }
56 | }
57 | export class FatalTurnLimitedError extends FatalError {
58 |   constructor(message: string) {
59 |     super(message, 53);
60 |   }
61 | }
62 | export class FatalToolExecutionError extends FatalError {
63 |   constructor(message: string) {
64 |     super(message, 54);
65 |   }
66 | }
67 | export class FatalCancellationError extends FatalError {
68 |   constructor(message: string) {
69 |     super(message, 130); // Standard exit code for SIGINT
70 |   }
71 | }
72 | 
73 | export class ForbiddenError extends Error {}
74 | export class UnauthorizedError extends Error {}
75 | export class BadRequestError extends Error {}
76 | 
77 | interface ResponseData {
78 |   error?: {
79 |     code?: number;
80 |     message?: string;
81 |   };
82 | }
83 | 
84 | export function toFriendlyError(error: unknown): unknown {
85 |   if (error && typeof error === 'object' && 'response' in error) {
86 |     const gaxiosError = error as GaxiosError;
87 |     const data = parseResponseData(gaxiosError);
88 |     if (data.error && data.error.message && data.error.code) {
89 |       switch (data.error.code) {
90 |         case 400:
91 |           return new BadRequestError(data.error.message);
92 |         case 401:
93 |           return new UnauthorizedError(data.error.message);
94 |         case 403:
95 |           // It's import to pass the message here since it might
96 |           // explain the cause like "the cloud project you're
97 |           // using doesn't have code assist enabled".
98 |           return new ForbiddenError(data.error.message);
99 |         default:
100 |       }
101 |     }
102 |   }
103 |   return error;
104 | }
105 | 
106 | function parseResponseData(error: GaxiosError): ResponseData {
107 |   // Inexplicably, Gaxios sometimes doesn't JSONify the response data.
108 |   if (typeof error.response?.data === 'string') {
109 |     return JSON.parse(error.response?.data) as ResponseData;
110 |   }
111 |   return error.response?.data as ResponseData;
112 | }
```

src/utils/fetch.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { getErrorMessage, isNodeError } from './errors.js';
8 | import { URL } from 'node:url';
9 | 
10 | const PRIVATE_IP_RANGES = [
11 |   /^10\./,
12 |   /^127\./,
13 |   /^172\.(1[6-9]|2[0-9]|3[0-1])\./,
14 |   /^192\.168\./,
15 |   /^::1$/,
16 |   /^fc00:/,
17 |   /^fe80:/,
18 | ];
19 | 
20 | export class FetchError extends Error {
21 |   constructor(
22 |     message: string,
23 |     public code?: string,
24 |   ) {
25 |     super(message);
26 |     this.name = 'FetchError';
27 |   }
28 | }
29 | 
30 | export function isPrivateIp(url: string): boolean {
31 |   try {
32 |     const hostname = new URL(url).hostname;
33 |     return PRIVATE_IP_RANGES.some((range) => range.test(hostname));
34 |   } catch (_e) {
35 |     return false;
36 |   }
37 | }
38 | 
39 | export async function fetchWithTimeout(
40 |   url: string,
41 |   timeout: number,
42 | ): Promise<Response> {
43 |   const controller = new AbortController();
44 |   const timeoutId = setTimeout(() => controller.abort(), timeout);
45 | 
46 |   try {
47 |     const response = await fetch(url, { signal: controller.signal });
48 |     return response;
49 |   } catch (error) {
50 |     if (isNodeError(error) && error.code === 'ABORT_ERR') {
51 |       throw new FetchError(`Request timed out after ${timeout}ms`, 'ETIMEDOUT');
52 |     }
53 |     throw new FetchError(getErrorMessage(error));
54 |   } finally {
55 |     clearTimeout(timeoutId);
56 |   }
57 | }
```

src/utils/fileUtils.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import {
8 |   describe,
9 |   it,
10 |   expect,
11 |   vi,
12 |   beforeEach,
13 |   afterEach,
14 |   type Mock,
15 | } from 'vitest';
16 | 
17 | import * as actualNodeFs from 'node:fs'; // For setup/teardown
18 | import fs from 'node:fs';
19 | import fsPromises from 'node:fs/promises';
20 | import path from 'node:path';
21 | import os from 'node:os';
22 | // eslint-disable-next-line import/no-internal-modules
23 | import mime from 'mime/lite';
24 | 
25 | import {
26 |   isWithinRoot,
27 |   isBinaryFile,
28 |   detectFileType,
29 |   processSingleFileContent,
30 |   detectBOM,
31 |   readFileWithEncoding,
32 |   fileExists,
33 | } from './fileUtils.js';
34 | import { StandardFileSystemService } from '../services/fileSystemService.js';
35 | 
36 | vi.mock('mime/lite', () => ({
37 |   default: { getType: vi.fn() },
38 |   getType: vi.fn(),
39 | }));
40 | 
41 | const mockMimeGetType = mime.getType as Mock;
42 | 
43 | describe('fileUtils', () => {
44 |   let tempRootDir: string;
45 |   const originalProcessCwd = process.cwd;
46 | 
47 |   let testTextFilePath: string;
48 |   let testImageFilePath: string;
49 |   let testPdfFilePath: string;
50 |   let testBinaryFilePath: string;
51 |   let nonexistentFilePath: string;
52 |   let directoryPath: string;
53 | 
54 |   beforeEach(() => {
55 |     vi.resetAllMocks(); // Reset all mocks, including mime.getType
56 | 
57 |     tempRootDir = actualNodeFs.mkdtempSync(
58 |       path.join(os.tmpdir(), 'fileUtils-test-'),
59 |     );
60 |     process.cwd = vi.fn(() => tempRootDir); // Mock cwd if necessary for relative path logic within tests
61 | 
62 |     testTextFilePath = path.join(tempRootDir, 'test.txt');
63 |     testImageFilePath = path.join(tempRootDir, 'image.png');
64 |     testPdfFilePath = path.join(tempRootDir, 'document.pdf');
65 |     testBinaryFilePath = path.join(tempRootDir, 'app.exe');
66 |     nonexistentFilePath = path.join(tempRootDir, 'nonexistent.txt');
67 |     directoryPath = path.join(tempRootDir, 'subdir');
68 | 
69 |     actualNodeFs.mkdirSync(directoryPath, { recursive: true }); // Ensure subdir exists
70 |   });
71 | 
72 |   afterEach(() => {
73 |     if (actualNodeFs.existsSync(tempRootDir)) {
74 |       actualNodeFs.rmSync(tempRootDir, { recursive: true, force: true });
75 |     }
76 |     process.cwd = originalProcessCwd;
77 |     vi.restoreAllMocks(); // Restore any spies
78 |   });
79 | 
80 |   describe('isWithinRoot', () => {
81 |     const root = path.resolve('/project/root');
82 | 
83 |     it('should return true for paths directly within the root', () => {
84 |       expect(isWithinRoot(path.join(root, 'file.txt'), root)).toBe(true);
85 |       expect(isWithinRoot(path.join(root, 'subdir', 'file.txt'), root)).toBe(
86 |         true,
87 |       );
88 |     });
89 | 
90 |     it('should return true for the root path itself', () => {
91 |       expect(isWithinRoot(root, root)).toBe(true);
92 |     });
93 | 
94 |     it('should return false for paths outside the root', () => {
95 |       expect(
96 |         isWithinRoot(path.resolve('/project/other', 'file.txt'), root),
97 |       ).toBe(false);
98 |       expect(isWithinRoot(path.resolve('/unrelated', 'file.txt'), root)).toBe(
99 |         false,
100 |       );
101 |     });
102 | 
103 |     it('should return false for paths that only partially match the root prefix', () => {
104 |       expect(
105 |         isWithinRoot(
106 |           path.resolve('/project/root-but-actually-different'),
107 |           root,
108 |         ),
109 |       ).toBe(false);
110 |     });
111 | 
112 |     it('should handle paths with trailing slashes correctly', () => {
113 |       expect(isWithinRoot(path.join(root, 'file.txt') + path.sep, root)).toBe(
114 |         true,
115 |       );
116 |       expect(isWithinRoot(root + path.sep, root)).toBe(true);
117 |     });
118 | 
119 |     it('should handle different path separators (POSIX vs Windows)', () => {
120 |       const posixRoot = '/project/root';
121 |       const posixPathInside = '/project/root/file.txt';
122 |       const posixPathOutside = '/project/other/file.txt';
123 |       expect(isWithinRoot(posixPathInside, posixRoot)).toBe(true);
124 |       expect(isWithinRoot(posixPathOutside, posixRoot)).toBe(false);
125 |     });
126 | 
127 |     it('should return false for a root path that is a sub-path of the path to check', () => {
128 |       const pathToCheck = path.resolve('/project/root/sub');
129 |       const rootSub = path.resolve('/project/root');
130 |       expect(isWithinRoot(pathToCheck, rootSub)).toBe(true);
131 | 
132 |       const pathToCheckSuper = path.resolve('/project/root');
133 |       const rootSuper = path.resolve('/project/root/sub');
134 |       expect(isWithinRoot(pathToCheckSuper, rootSuper)).toBe(false);
135 |     });
136 |   });
137 | 
138 |   describe('fileExists', () => {
139 |     it('should return true if the file exists', async () => {
140 |       const testFile = path.join(tempRootDir, 'exists.txt');
141 |       actualNodeFs.writeFileSync(testFile, 'content');
142 |       await expect(fileExists(testFile)).resolves.toBe(true);
143 |     });
144 | 
145 |     it('should return false if the file does not exist', async () => {
146 |       const testFile = path.join(tempRootDir, 'does-not-exist.txt');
147 |       await expect(fileExists(testFile)).resolves.toBe(false);
148 |     });
149 | 
150 |     it('should return true for a directory that exists', async () => {
151 |       const testDir = path.join(tempRootDir, 'exists-dir');
152 |       actualNodeFs.mkdirSync(testDir);
153 |       await expect(fileExists(testDir)).resolves.toBe(true);
154 |     });
155 |   });
156 | 
157 |   describe('isBinaryFile', () => {
158 |     let filePathForBinaryTest: string;
159 | 
160 |     beforeEach(() => {
161 |       filePathForBinaryTest = path.join(tempRootDir, 'binaryCheck.tmp');
162 |     });
163 | 
164 |     afterEach(() => {
165 |       if (actualNodeFs.existsSync(filePathForBinaryTest)) {
166 |         actualNodeFs.unlinkSync(filePathForBinaryTest);
167 |       }
168 |     });
169 | 
170 |     it('should return false for an empty file', async () => {
171 |       actualNodeFs.writeFileSync(filePathForBinaryTest, '');
172 |       expect(await isBinaryFile(filePathForBinaryTest)).toBe(false);
173 |     });
174 | 
175 |     it('should return false for a typical text file', async () => {
176 |       actualNodeFs.writeFileSync(
177 |         filePathForBinaryTest,
178 |         'Hello, world!\nThis is a test file with normal text content.',
179 |       );
180 |       expect(await isBinaryFile(filePathForBinaryTest)).toBe(false);
181 |     });
182 | 
183 |     it('should return true for a file with many null bytes', async () => {
184 |       const binaryContent = Buffer.from([
185 |         0x48, 0x65, 0x00, 0x6c, 0x6f, 0x00, 0x00, 0x00, 0x00, 0x00,
186 |       ]); // "He\0llo\0\0\0\0\0"
187 |       actualNodeFs.writeFileSync(filePathForBinaryTest, binaryContent);
188 |       expect(await isBinaryFile(filePathForBinaryTest)).toBe(true);
189 |     });
190 | 
191 |     it('should return true for a file with high percentage of non-printable ASCII', async () => {
192 |       const binaryContent = Buffer.from([
193 |         0x41, 0x42, 0x01, 0x02, 0x03, 0x04, 0x05, 0x43, 0x44, 0x06,
194 |       ]); // AB\x01\x02\x03\x04\x05CD\x06
195 |       actualNodeFs.writeFileSync(filePathForBinaryTest, binaryContent);
196 |       expect(await isBinaryFile(filePathForBinaryTest)).toBe(true);
197 |     });
198 | 
199 |     it('should return false if file access fails (e.g., ENOENT)', async () => {
200 |       // Ensure the file does not exist
201 |       if (actualNodeFs.existsSync(filePathForBinaryTest)) {
202 |         actualNodeFs.unlinkSync(filePathForBinaryTest);
203 |       }
204 |       expect(await isBinaryFile(filePathForBinaryTest)).toBe(false);
205 |     });
206 |   });
207 | 
208 |   describe('BOM detection and encoding', () => {
209 |     let testDir: string;
210 | 
211 |     beforeEach(async () => {
212 |       testDir = await fsPromises.mkdtemp(
213 |         path.join(
214 |           await fsPromises.realpath(os.tmpdir()),
215 |           'fileUtils-bom-test-',
216 |         ),
217 |       );
218 |     });
219 | 
220 |     afterEach(async () => {
221 |       if (testDir) {
222 |         await fsPromises.rm(testDir, { recursive: true, force: true });
223 |       }
224 |     });
225 | 
226 |     describe('detectBOM', () => {
227 |       it('should detect UTF-8 BOM', () => {
228 |         const buf = Buffer.from([
229 |           0xef, 0xbb, 0xbf, 0x48, 0x65, 0x6c, 0x6c, 0x6f,
230 |         ]);
231 |         const result = detectBOM(buf);
232 |         expect(result).toEqual({ encoding: 'utf8', bomLength: 3 });
233 |       });
234 | 
235 |       it('should detect UTF-16 LE BOM', () => {
236 |         const buf = Buffer.from([0xff, 0xfe, 0x48, 0x00, 0x65, 0x00]);
237 |         const result = detectBOM(buf);
238 |         expect(result).toEqual({ encoding: 'utf16le', bomLength: 2 });
239 |       });
240 | 
241 |       it('should detect UTF-16 BE BOM', () => {
242 |         const buf = Buffer.from([0xfe, 0xff, 0x00, 0x48, 0x00, 0x65]);
243 |         const result = detectBOM(buf);
244 |         expect(result).toEqual({ encoding: 'utf16be', bomLength: 2 });
245 |       });
246 | 
247 |       it('should detect UTF-32 LE BOM', () => {
248 |         const buf = Buffer.from([
249 |           0xff, 0xfe, 0x00, 0x00, 0x48, 0x00, 0x00, 0x00,
250 |         ]);
251 |         const result = detectBOM(buf);
252 |         expect(result).toEqual({ encoding: 'utf32le', bomLength: 4 });
253 |       });
254 | 
255 |       it('should detect UTF-32 BE BOM', () => {
256 |         const buf = Buffer.from([
257 |           0x00, 0x00, 0xfe, 0xff, 0x00, 0x00, 0x00, 0x48,
258 |         ]);
259 |         const result = detectBOM(buf);
260 |         expect(result).toEqual({ encoding: 'utf32be', bomLength: 4 });
261 |       });
262 | 
263 |       it('should return null for no BOM', () => {
264 |         const buf = Buffer.from([0x48, 0x65, 0x6c, 0x6c, 0x6f]);
265 |         const result = detectBOM(buf);
266 |         expect(result).toBeNull();
267 |       });
268 | 
269 |       it('should return null for empty buffer', () => {
270 |         const buf = Buffer.alloc(0);
271 |         const result = detectBOM(buf);
272 |         expect(result).toBeNull();
273 |       });
274 | 
275 |       it('should return null for partial BOM', () => {
276 |         const buf = Buffer.from([0xef, 0xbb]); // Incomplete UTF-8 BOM
277 |         const result = detectBOM(buf);
278 |         expect(result).toBeNull();
279 |       });
280 |     });
281 | 
282 |     describe('readFileWithEncoding', () => {
283 |       it('should read UTF-8 BOM file correctly', async () => {
284 |         const content = 'Hello, 世界! 🌍';
285 |         const utf8Bom = Buffer.from([0xef, 0xbb, 0xbf]);
286 |         const utf8Content = Buffer.from(content, 'utf8');
287 |         const fullBuffer = Buffer.concat([utf8Bom, utf8Content]);
288 | 
289 |         const filePath = path.join(testDir, 'utf8-bom.txt');
290 |         await fsPromises.writeFile(filePath, fullBuffer);
291 | 
292 |         const result = await readFileWithEncoding(filePath);
293 |         expect(result).toBe(content);
294 |       });
295 | 
296 |       it('should read UTF-16 LE BOM file correctly', async () => {
297 |         const content = 'Hello, 世界! 🌍';
298 |         const utf16leBom = Buffer.from([0xff, 0xfe]);
299 |         const utf16leContent = Buffer.from(content, 'utf16le');
300 |         const fullBuffer = Buffer.concat([utf16leBom, utf16leContent]);
301 | 
302 |         const filePath = path.join(testDir, 'utf16le-bom.txt');
303 |         await fsPromises.writeFile(filePath, fullBuffer);
304 | 
305 |         const result = await readFileWithEncoding(filePath);
306 |         expect(result).toBe(content);
307 |       });
308 | 
309 |       it('should read UTF-16 BE BOM file correctly', async () => {
310 |         const content = 'Hello, 世界! 🌍';
311 |         // Manually encode UTF-16 BE: each char as big-endian 16-bit
312 |         const utf16beBom = Buffer.from([0xfe, 0xff]);
313 |         const chars = Array.from(content);
314 |         const utf16beBytes: number[] = [];
315 | 
316 |         for (const char of chars) {
317 |           const code = char.codePointAt(0)!;
318 |           if (code > 0xffff) {
319 |             // Surrogate pair for emoji
320 |             const surrogate1 = 0xd800 + ((code - 0x10000) >> 10);
321 |             const surrogate2 = 0xdc00 + ((code - 0x10000) & 0x3ff);
322 |             utf16beBytes.push((surrogate1 >> 8) & 0xff, surrogate1 & 0xff);
323 |             utf16beBytes.push((surrogate2 >> 8) & 0xff, surrogate2 & 0xff);
324 |           } else {
325 |             utf16beBytes.push((code >> 8) & 0xff, code & 0xff);
326 |           }
327 |         }
328 | 
329 |         const utf16beContent = Buffer.from(utf16beBytes);
330 |         const fullBuffer = Buffer.concat([utf16beBom, utf16beContent]);
331 | 
332 |         const filePath = path.join(testDir, 'utf16be-bom.txt');
333 |         await fsPromises.writeFile(filePath, fullBuffer);
334 | 
335 |         const result = await readFileWithEncoding(filePath);
336 |         expect(result).toBe(content);
337 |       });
338 | 
339 |       it('should read UTF-32 LE BOM file correctly', async () => {
340 |         const content = 'Hello, 世界! 🌍';
341 |         const utf32leBom = Buffer.from([0xff, 0xfe, 0x00, 0x00]);
342 | 
343 |         const utf32leBytes: number[] = [];
344 |         for (const char of Array.from(content)) {
345 |           const code = char.codePointAt(0)!;
346 |           utf32leBytes.push(
347 |             code & 0xff,
348 |             (code >> 8) & 0xff,
349 |             (code >> 16) & 0xff,
350 |             (code >> 24) & 0xff,
351 |           );
352 |         }
353 | 
354 |         const utf32leContent = Buffer.from(utf32leBytes);
355 |         const fullBuffer = Buffer.concat([utf32leBom, utf32leContent]);
356 | 
357 |         const filePath = path.join(testDir, 'utf32le-bom.txt');
358 |         await fsPromises.writeFile(filePath, fullBuffer);
359 | 
360 |         const result = await readFileWithEncoding(filePath);
361 |         expect(result).toBe(content);
362 |       });
363 | 
364 |       it('should read UTF-32 BE BOM file correctly', async () => {
365 |         const content = 'Hello, 世界! 🌍';
366 |         const utf32beBom = Buffer.from([0x00, 0x00, 0xfe, 0xff]);
367 | 
368 |         const utf32beBytes: number[] = [];
369 |         for (const char of Array.from(content)) {
370 |           const code = char.codePointAt(0)!;
371 |           utf32beBytes.push(
372 |             (code >> 24) & 0xff,
373 |             (code >> 16) & 0xff,
374 |             (code >> 8) & 0xff,
375 |             code & 0xff,
376 |           );
377 |         }
378 | 
379 |         const utf32beContent = Buffer.from(utf32beBytes);
380 |         const fullBuffer = Buffer.concat([utf32beBom, utf32beContent]);
381 | 
382 |         const filePath = path.join(testDir, 'utf32be-bom.txt');
383 |         await fsPromises.writeFile(filePath, fullBuffer);
384 | 
385 |         const result = await readFileWithEncoding(filePath);
386 |         expect(result).toBe(content);
387 |       });
388 | 
389 |       it('should read file without BOM as UTF-8', async () => {
390 |         const content = 'Hello, 世界!';
391 |         const filePath = path.join(testDir, 'no-bom.txt');
392 |         await fsPromises.writeFile(filePath, content, 'utf8');
393 | 
394 |         const result = await readFileWithEncoding(filePath);
395 |         expect(result).toBe(content);
396 |       });
397 | 
398 |       it('should handle empty file', async () => {
399 |         const filePath = path.join(testDir, 'empty.txt');
400 |         await fsPromises.writeFile(filePath, '');
401 | 
402 |         const result = await readFileWithEncoding(filePath);
403 |         expect(result).toBe('');
404 |       });
405 |     });
406 | 
407 |     describe('isBinaryFile with BOM awareness', () => {
408 |       it('should not treat UTF-8 BOM file as binary', async () => {
409 |         const content = 'Hello, world!';
410 |         const utf8Bom = Buffer.from([0xef, 0xbb, 0xbf]);
411 |         const utf8Content = Buffer.from(content, 'utf8');
412 |         const fullBuffer = Buffer.concat([utf8Bom, utf8Content]);
413 | 
414 |         const filePath = path.join(testDir, 'utf8-bom-test.txt');
415 |         await fsPromises.writeFile(filePath, fullBuffer);
416 | 
417 |         const result = await isBinaryFile(filePath);
418 |         expect(result).toBe(false);
419 |       });
420 | 
421 |       it('should not treat UTF-16 LE BOM file as binary', async () => {
422 |         const content = 'Hello, world!';
423 |         const utf16leBom = Buffer.from([0xff, 0xfe]);
424 |         const utf16leContent = Buffer.from(content, 'utf16le');
425 |         const fullBuffer = Buffer.concat([utf16leBom, utf16leContent]);
426 | 
427 |         const filePath = path.join(testDir, 'utf16le-bom-test.txt');
428 |         await fsPromises.writeFile(filePath, fullBuffer);
429 | 
430 |         const result = await isBinaryFile(filePath);
431 |         expect(result).toBe(false);
432 |       });
433 | 
434 |       it('should not treat UTF-16 BE BOM file as binary', async () => {
435 |         const utf16beBom = Buffer.from([0xfe, 0xff]);
436 |         // Simple ASCII in UTF-16 BE
437 |         const utf16beContent = Buffer.from([
438 |           0x00,
439 |           0x48, // H
440 |           0x00,
441 |           0x65, // e
442 |           0x00,
443 |           0x6c, // l
444 |           0x00,
445 |           0x6c, // l
446 |           0x00,
447 |           0x6f, // o
448 |           0x00,
449 |           0x2c, // ,
450 |           0x00,
451 |           0x20, // space
452 |           0x00,
453 |           0x77, // w
454 |           0x00,
455 |           0x6f, // o
456 |           0x00,
457 |           0x72, // r
458 |           0x00,
459 |           0x6c, // l
460 |           0x00,
461 |           0x64, // d
462 |           0x00,
463 |           0x21, // !
464 |         ]);
465 |         const fullBuffer = Buffer.concat([utf16beBom, utf16beContent]);
466 | 
467 |         const filePath = path.join(testDir, 'utf16be-bom-test.txt');
468 |         await fsPromises.writeFile(filePath, fullBuffer);
469 | 
470 |         const result = await isBinaryFile(filePath);
471 |         expect(result).toBe(false);
472 |       });
473 | 
474 |       it('should not treat UTF-32 LE BOM file as binary', async () => {
475 |         const utf32leBom = Buffer.from([0xff, 0xfe, 0x00, 0x00]);
476 |         const utf32leContent = Buffer.from([
477 |           0x48,
478 |           0x00,
479 |           0x00,
480 |           0x00, // H
481 |           0x65,
482 |           0x00,
483 |           0x00,
484 |           0x00, // e
485 |           0x6c,
486 |           0x00,
487 |           0x00,
488 |           0x00, // l
489 |           0x6c,
490 |           0x00,
491 |           0x00,
492 |           0x00, // l
493 |           0x6f,
494 |           0x00,
495 |           0x00,
496 |           0x00, // o
497 |         ]);
498 |         const fullBuffer = Buffer.concat([utf32leBom, utf32leContent]);
499 | 
500 |         const filePath = path.join(testDir, 'utf32le-bom-test.txt');
501 |         await fsPromises.writeFile(filePath, fullBuffer);
502 | 
503 |         const result = await isBinaryFile(filePath);
504 |         expect(result).toBe(false);
505 |       });
506 | 
507 |       it('should not treat UTF-32 BE BOM file as binary', async () => {
508 |         const utf32beBom = Buffer.from([0x00, 0x00, 0xfe, 0xff]);
509 |         const utf32beContent = Buffer.from([
510 |           0x00,
511 |           0x00,
512 |           0x00,
513 |           0x48, // H
514 |           0x00,
515 |           0x00,
516 |           0x00,
517 |           0x65, // e
518 |           0x00,
519 |           0x00,
520 |           0x00,
521 |           0x6c, // l
522 |           0x00,
523 |           0x00,
524 |           0x00,
525 |           0x6c, // l
526 |           0x00,
527 |           0x00,
528 |           0x00,
529 |           0x6f, // o
530 |         ]);
531 |         const fullBuffer = Buffer.concat([utf32beBom, utf32beContent]);
532 | 
533 |         const filePath = path.join(testDir, 'utf32be-bom-test.txt');
534 |         await fsPromises.writeFile(filePath, fullBuffer);
535 | 
536 |         const result = await isBinaryFile(filePath);
537 |         expect(result).toBe(false);
538 |       });
539 | 
540 |       it('should still treat actual binary file as binary', async () => {
541 |         // PNG header + some binary data with null bytes
542 |         const pngHeader = Buffer.from([
543 |           0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a,
544 |         ]);
545 |         const binaryData = Buffer.from([
546 |           0x00, 0x00, 0x00, 0x0d, 0x49, 0x48, 0x44, 0x52,
547 |         ]); // IHDR chunk with nulls
548 |         const fullContent = Buffer.concat([pngHeader, binaryData]);
549 |         const filePath = path.join(testDir, 'test.png');
550 |         await fsPromises.writeFile(filePath, fullContent);
551 | 
552 |         const result = await isBinaryFile(filePath);
553 |         expect(result).toBe(true);
554 |       });
555 | 
556 |       it('should treat file with null bytes (no BOM) as binary', async () => {
557 |         const content = Buffer.from([
558 |           0x48, 0x65, 0x6c, 0x6c, 0x6f, 0x00, 0x77, 0x6f, 0x72, 0x6c, 0x64,
559 |         ]);
560 |         const filePath = path.join(testDir, 'null-bytes.bin');
[TRUNCATED]
```

src/utils/fileUtils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import fs from 'node:fs';
8 | import fsPromises from 'node:fs/promises';
9 | import path from 'node:path';
10 | import type { PartUnion } from '@google/genai';
11 | // eslint-disable-next-line import/no-internal-modules
12 | import mime from 'mime/lite';
13 | import type { FileSystemService } from '../services/fileSystemService.js';
14 | import { ToolErrorType } from '../tools/tool-error.js';
15 | import { BINARY_EXTENSIONS } from './ignorePatterns.js';
16 | 
17 | // Constants for text file processing
18 | const DEFAULT_MAX_LINES_TEXT_FILE = 2000;
19 | const MAX_LINE_LENGTH_TEXT_FILE = 2000;
20 | 
21 | // Default values for encoding and separator format
22 | export const DEFAULT_ENCODING: BufferEncoding = 'utf-8';
23 | 
24 | // --- Unicode BOM detection & decoding helpers --------------------------------
25 | 
26 | type UnicodeEncoding = 'utf8' | 'utf16le' | 'utf16be' | 'utf32le' | 'utf32be';
27 | 
28 | interface BOMInfo {
29 |   encoding: UnicodeEncoding;
30 |   bomLength: number;
31 | }
32 | 
33 | /**
34 |  * Detect a Unicode BOM (Byte Order Mark) if present.
35 |  * Reads up to the first 4 bytes and returns encoding + BOM length, else null.
36 |  */
37 | export function detectBOM(buf: Buffer): BOMInfo | null {
38 |   if (buf.length >= 4) {
39 |     // UTF-32 LE: FF FE 00 00
40 |     if (
41 |       buf[0] === 0xff &&
42 |       buf[1] === 0xfe &&
43 |       buf[2] === 0x00 &&
44 |       buf[3] === 0x00
45 |     ) {
46 |       return { encoding: 'utf32le', bomLength: 4 };
47 |     }
48 |     // UTF-32 BE: 00 00 FE FF
49 |     if (
50 |       buf[0] === 0x00 &&
51 |       buf[1] === 0x00 &&
52 |       buf[2] === 0xfe &&
53 |       buf[3] === 0xff
54 |     ) {
55 |       return { encoding: 'utf32be', bomLength: 4 };
56 |     }
57 |   }
58 |   if (buf.length >= 3) {
59 |     // UTF-8: EF BB BF
60 |     if (buf[0] === 0xef && buf[1] === 0xbb && buf[2] === 0xbf) {
61 |       return { encoding: 'utf8', bomLength: 3 };
62 |     }
63 |   }
64 |   if (buf.length >= 2) {
65 |     // UTF-16 LE: FF FE  (but not UTF-32 LE already matched above)
66 |     if (
67 |       buf[0] === 0xff &&
68 |       buf[1] === 0xfe &&
69 |       (buf.length < 4 || buf[2] !== 0x00 || buf[3] !== 0x00)
70 |     ) {
71 |       return { encoding: 'utf16le', bomLength: 2 };
72 |     }
73 |     // UTF-16 BE: FE FF
74 |     if (buf[0] === 0xfe && buf[1] === 0xff) {
75 |       return { encoding: 'utf16be', bomLength: 2 };
76 |     }
77 |   }
78 |   return null;
79 | }
80 | 
81 | /**
82 |  * Convert a UTF-16 BE buffer to a JS string by swapping to LE then using Node's decoder.
83 |  * (Node has 'utf16le' but not 'utf16be'.)
84 |  */
85 | function decodeUTF16BE(buf: Buffer): string {
86 |   if (buf.length === 0) return '';
87 |   const swapped = Buffer.from(buf); // swap16 mutates in place, so copy
88 |   swapped.swap16();
89 |   return swapped.toString('utf16le');
90 | }
91 | 
92 | /**
93 |  * Decode a UTF-32 buffer (LE or BE) into a JS string.
94 |  * Invalid code points are replaced with U+FFFD, partial trailing bytes are ignored.
95 |  */
96 | function decodeUTF32(buf: Buffer, littleEndian: boolean): string {
97 |   if (buf.length < 4) return '';
98 |   const usable = buf.length - (buf.length % 4);
99 |   let out = '';
100 |   for (let i = 0; i < usable; i += 4) {
101 |     const cp = littleEndian
102 |       ? (buf[i] |
103 |           (buf[i + 1] << 8) |
104 |           (buf[i + 2] << 16) |
105 |           (buf[i + 3] << 24)) >>>
106 |         0
107 |       : (buf[i + 3] |
108 |           (buf[i + 2] << 8) |
109 |           (buf[i + 1] << 16) |
110 |           (buf[i] << 24)) >>>
111 |         0;
112 |     // Valid planes: 0x0000..0x10FFFF excluding surrogates
113 |     if (cp <= 0x10ffff && !(cp >= 0xd800 && cp <= 0xdfff)) {
114 |       out += String.fromCodePoint(cp);
115 |     } else {
116 |       out += '\uFFFD';
117 |     }
118 |   }
119 |   return out;
120 | }
121 | 
122 | /**
123 |  * Read a file as text, honoring BOM encodings (UTF‑8/16/32) and stripping the BOM.
124 |  * Falls back to utf8 when no BOM is present.
125 |  */
126 | export async function readFileWithEncoding(filePath: string): Promise<string> {
127 |   // Read the file once; detect BOM and decode from the single buffer.
128 |   const full = await fs.promises.readFile(filePath);
129 |   if (full.length === 0) return '';
130 | 
131 |   const bom = detectBOM(full);
132 |   if (!bom) {
133 |     // No BOM → treat as UTF‑8
134 |     return full.toString('utf8');
135 |   }
136 | 
137 |   // Strip BOM and decode per encoding
138 |   const content = full.subarray(bom.bomLength);
139 |   switch (bom.encoding) {
140 |     case 'utf8':
141 |       return content.toString('utf8');
142 |     case 'utf16le':
143 |       return content.toString('utf16le');
144 |     case 'utf16be':
145 |       return decodeUTF16BE(content);
146 |     case 'utf32le':
147 |       return decodeUTF32(content, true);
148 |     case 'utf32be':
149 |       return decodeUTF32(content, false);
150 |     default:
151 |       // Defensive fallback; should be unreachable
152 |       return content.toString('utf8');
153 |   }
154 | }
155 | 
156 | /**
157 |  * Looks up the specific MIME type for a file path.
158 |  * @param filePath Path to the file.
159 |  * @returns The specific MIME type string (e.g., 'text/python', 'application/javascript') or undefined if not found or ambiguous.
160 |  */
161 | export function getSpecificMimeType(filePath: string): string | undefined {
162 |   const lookedUpMime = mime.getType(filePath);
163 |   return typeof lookedUpMime === 'string' ? lookedUpMime : undefined;
164 | }
165 | 
166 | /**
167 |  * Checks if a path is within a given root directory.
168 |  * @param pathToCheck The absolute path to check.
169 |  * @param rootDirectory The absolute root directory.
170 |  * @returns True if the path is within the root directory, false otherwise.
171 |  */
172 | export function isWithinRoot(
173 |   pathToCheck: string,
174 |   rootDirectory: string,
175 | ): boolean {
176 |   const normalizedPathToCheck = path.resolve(pathToCheck);
177 |   const normalizedRootDirectory = path.resolve(rootDirectory);
178 | 
179 |   // Ensure the rootDirectory path ends with a separator for correct startsWith comparison,
180 |   // unless it's the root path itself (e.g., '/' or 'C:\').
181 |   const rootWithSeparator =
182 |     normalizedRootDirectory === path.sep ||
183 |     normalizedRootDirectory.endsWith(path.sep)
184 |       ? normalizedRootDirectory
185 |       : normalizedRootDirectory + path.sep;
186 | 
187 |   return (
188 |     normalizedPathToCheck === normalizedRootDirectory ||
189 |     normalizedPathToCheck.startsWith(rootWithSeparator)
190 |   );
191 | }
192 | 
193 | /**
194 |  * Heuristic: determine if a file is likely binary.
195 |  * Now BOM-aware: if a Unicode BOM is detected, we treat it as text.
196 |  * For non-BOM files, retain the existing null-byte and non-printable ratio checks.
197 |  */
198 | export async function isBinaryFile(filePath: string): Promise<boolean> {
199 |   let fh: fs.promises.FileHandle | null = null;
200 |   try {
201 |     fh = await fs.promises.open(filePath, 'r');
202 |     const stats = await fh.stat();
203 |     const fileSize = stats.size;
204 |     if (fileSize === 0) return false; // empty is not binary
205 | 
206 |     // Sample up to 4KB from the head (previous behavior)
207 |     const sampleSize = Math.min(4096, fileSize);
208 |     const buf = Buffer.alloc(sampleSize);
209 |     const { bytesRead } = await fh.read(buf, 0, sampleSize, 0);
210 |     if (bytesRead === 0) return false;
211 | 
212 |     // BOM → text (avoid false positives for UTF‑16/32 with nulls)
213 |     const bom = detectBOM(buf.subarray(0, Math.min(4, bytesRead)));
214 |     if (bom) return false;
215 | 
216 |     let nonPrintableCount = 0;
217 |     for (let i = 0; i < bytesRead; i++) {
218 |       if (buf[i] === 0) return true; // strong indicator of binary when no BOM
219 |       if (buf[i] < 9 || (buf[i] > 13 && buf[i] < 32)) {
220 |         nonPrintableCount++;
221 |       }
222 |     }
223 |     // If >30% non-printable characters, consider it binary
224 |     return nonPrintableCount / bytesRead > 0.3;
225 |   } catch (error) {
226 |     console.warn(
227 |       `Failed to check if file is binary: ${filePath}`,
228 |       error instanceof Error ? error.message : String(error),
229 |     );
230 |     return false;
231 |   } finally {
232 |     if (fh) {
233 |       try {
234 |         await fh.close();
235 |       } catch (closeError) {
236 |         console.warn(
237 |           `Failed to close file handle for: ${filePath}`,
238 |           closeError instanceof Error ? closeError.message : String(closeError),
239 |         );
240 |       }
241 |     }
242 |   }
243 | }
244 | 
245 | /**
246 |  * Detects the type of file based on extension and content.
247 |  * @param filePath Path to the file.
248 |  * @returns Promise that resolves to 'text', 'image', 'pdf', 'audio', 'video', 'binary' or 'svg'.
249 |  */
250 | export async function detectFileType(
251 |   filePath: string,
252 | ): Promise<'text' | 'image' | 'pdf' | 'audio' | 'video' | 'binary' | 'svg'> {
253 |   const ext = path.extname(filePath).toLowerCase();
254 | 
255 |   // The mimetype for various TypeScript extensions (ts, mts, cts, tsx) can be
256 |   // MPEG transport stream (a video format), but we want to assume these are
257 |   // TypeScript files instead.
258 |   if (['.ts', '.mts', '.cts'].includes(ext)) {
259 |     return 'text';
260 |   }
261 | 
262 |   if (ext === '.svg') {
263 |     return 'svg';
264 |   }
265 | 
266 |   const lookedUpMimeType = mime.getType(filePath); // Returns null if not found, or the mime type string
267 |   if (lookedUpMimeType) {
268 |     if (lookedUpMimeType.startsWith('image/')) {
269 |       return 'image';
270 |     }
271 |     if (lookedUpMimeType.startsWith('audio/')) {
272 |       return 'audio';
273 |     }
274 |     if (lookedUpMimeType.startsWith('video/')) {
275 |       return 'video';
276 |     }
277 |     if (lookedUpMimeType === 'application/pdf') {
278 |       return 'pdf';
279 |     }
280 |   }
281 | 
282 |   // Stricter binary check for common non-text extensions before content check
283 |   // These are often not well-covered by mime-types or might be misidentified.
284 |   if (BINARY_EXTENSIONS.includes(ext)) {
285 |     return 'binary';
286 |   }
287 | 
288 |   // Fall back to content-based check if mime type wasn't conclusive for image/pdf
289 |   // and it's not a known binary extension.
290 |   if (await isBinaryFile(filePath)) {
291 |     return 'binary';
292 |   }
293 | 
294 |   return 'text';
295 | }
296 | 
297 | export interface ProcessedFileReadResult {
298 |   llmContent: PartUnion; // string for text, Part for image/pdf/unreadable binary
299 |   returnDisplay: string;
300 |   error?: string; // Optional error message for the LLM if file processing failed
301 |   errorType?: ToolErrorType; // Structured error type
302 |   isTruncated?: boolean; // For text files, indicates if content was truncated
303 |   originalLineCount?: number; // For text files
304 |   linesShown?: [number, number]; // For text files [startLine, endLine] (1-based for display)
305 | }
306 | 
307 | /**
308 |  * Reads and processes a single file, handling text, images, and PDFs.
309 |  * @param filePath Absolute path to the file.
310 |  * @param rootDirectory Absolute path to the project root for relative path display.
311 |  * @param offset Optional offset for text files (0-based line number).
312 |  * @param limit Optional limit for text files (number of lines to read).
313 |  * @returns ProcessedFileReadResult object.
314 |  */
315 | export async function processSingleFileContent(
316 |   filePath: string,
317 |   rootDirectory: string,
318 |   fileSystemService: FileSystemService,
319 |   offset?: number,
320 |   limit?: number,
321 | ): Promise<ProcessedFileReadResult> {
322 |   try {
323 |     if (!fs.existsSync(filePath)) {
324 |       // Sync check is acceptable before async read
325 |       return {
326 |         llmContent:
327 |           'Could not read file because no file was found at the specified path.',
328 |         returnDisplay: 'File not found.',
329 |         error: `File not found: ${filePath}`,
330 |         errorType: ToolErrorType.FILE_NOT_FOUND,
331 |       };
332 |     }
333 |     const stats = await fs.promises.stat(filePath);
334 |     if (stats.isDirectory()) {
335 |       return {
336 |         llmContent:
337 |           'Could not read file because the provided path is a directory, not a file.',
338 |         returnDisplay: 'Path is a directory.',
339 |         error: `Path is a directory, not a file: ${filePath}`,
340 |         errorType: ToolErrorType.TARGET_IS_DIRECTORY,
341 |       };
342 |     }
343 | 
344 |     const fileSizeInMB = stats.size / (1024 * 1024);
345 |     if (fileSizeInMB > 20) {
346 |       return {
347 |         llmContent: 'File size exceeds the 20MB limit.',
348 |         returnDisplay: 'File size exceeds the 20MB limit.',
349 |         error: `File size exceeds the 20MB limit: ${filePath} (${fileSizeInMB.toFixed(2)}MB)`,
350 |         errorType: ToolErrorType.FILE_TOO_LARGE,
351 |       };
352 |     }
353 | 
354 |     const fileType = await detectFileType(filePath);
355 |     const relativePathForDisplay = path
356 |       .relative(rootDirectory, filePath)
357 |       .replace(/\\/g, '/');
358 | 
359 |     switch (fileType) {
360 |       case 'binary': {
361 |         return {
362 |           llmContent: `Cannot display content of binary file: ${relativePathForDisplay}`,
363 |           returnDisplay: `Skipped binary file: ${relativePathForDisplay}`,
364 |         };
365 |       }
366 |       case 'svg': {
367 |         const SVG_MAX_SIZE_BYTES = 1 * 1024 * 1024;
368 |         if (stats.size > SVG_MAX_SIZE_BYTES) {
369 |           return {
370 |             llmContent: `Cannot display content of SVG file larger than 1MB: ${relativePathForDisplay}`,
371 |             returnDisplay: `Skipped large SVG file (>1MB): ${relativePathForDisplay}`,
372 |           };
373 |         }
374 |         const content = await readFileWithEncoding(filePath);
375 |         return {
376 |           llmContent: content,
377 |           returnDisplay: `Read SVG as text: ${relativePathForDisplay}`,
378 |         };
379 |       }
380 |       case 'text': {
381 |         // Use BOM-aware reader to avoid leaving a BOM character in content and to support UTF-16/32 transparently
382 |         const content = await readFileWithEncoding(filePath);
383 |         const lines = content.split('\n');
384 |         const originalLineCount = lines.length;
385 | 
386 |         const startLine = offset || 0;
387 |         const effectiveLimit =
388 |           limit === undefined ? DEFAULT_MAX_LINES_TEXT_FILE : limit;
389 |         // Ensure endLine does not exceed originalLineCount
390 |         const endLine = Math.min(startLine + effectiveLimit, originalLineCount);
391 |         // Ensure selectedLines doesn't try to slice beyond array bounds if startLine is too high
392 |         const actualStartLine = Math.min(startLine, originalLineCount);
393 |         const selectedLines = lines.slice(actualStartLine, endLine);
394 | 
395 |         let linesWereTruncatedInLength = false;
396 |         const formattedLines = selectedLines.map((line) => {
397 |           if (line.length > MAX_LINE_LENGTH_TEXT_FILE) {
398 |             linesWereTruncatedInLength = true;
399 |             return (
400 |               line.substring(0, MAX_LINE_LENGTH_TEXT_FILE) + '... [truncated]'
401 |             );
402 |           }
403 |           return line;
404 |         });
405 | 
406 |         const contentRangeTruncated =
407 |           startLine > 0 || endLine < originalLineCount;
408 |         const isTruncated = contentRangeTruncated || linesWereTruncatedInLength;
409 |         const llmContent = formattedLines.join('\n');
410 | 
411 |         // By default, return nothing to streamline the common case of a successful read_file.
412 |         let returnDisplay = '';
413 |         if (contentRangeTruncated) {
414 |           returnDisplay = `Read lines ${
415 |             actualStartLine + 1
416 |           }-${endLine} of ${originalLineCount} from ${relativePathForDisplay}`;
417 |           if (linesWereTruncatedInLength) {
418 |             returnDisplay += ' (some lines were shortened)';
419 |           }
420 |         } else if (linesWereTruncatedInLength) {
421 |           returnDisplay = `Read all ${originalLineCount} lines from ${relativePathForDisplay} (some lines were shortened)`;
422 |         }
423 | 
424 |         return {
425 |           llmContent,
426 |           returnDisplay,
427 |           isTruncated,
428 |           originalLineCount,
429 |           linesShown: [actualStartLine + 1, endLine],
430 |         };
431 |       }
432 |       case 'image':
433 |       case 'pdf':
434 |       case 'audio':
435 |       case 'video': {
436 |         const contentBuffer = await fs.promises.readFile(filePath);
437 |         const base64Data = contentBuffer.toString('base64');
438 |         return {
439 |           llmContent: {
440 |             inlineData: {
441 |               data: base64Data,
442 |               mimeType: mime.getType(filePath) || 'application/octet-stream',
443 |             },
444 |           },
445 |           returnDisplay: `Read ${fileType} file: ${relativePathForDisplay}`,
446 |         };
447 |       }
448 |       default: {
449 |         // Should not happen with current detectFileType logic
450 |         const exhaustiveCheck: never = fileType;
451 |         return {
452 |           llmContent: `Unhandled file type: ${exhaustiveCheck}`,
453 |           returnDisplay: `Skipped unhandled file type: ${relativePathForDisplay}`,
454 |           error: `Unhandled file type for ${filePath}`,
455 |         };
456 |       }
457 |     }
458 |   } catch (error) {
459 |     const errorMessage = error instanceof Error ? error.message : String(error);
460 |     const displayPath = path
461 |       .relative(rootDirectory, filePath)
462 |       .replace(/\\/g, '/');
463 |     return {
464 |       llmContent: `Error reading file ${displayPath}: ${errorMessage}`,
465 |       returnDisplay: `Error reading file ${displayPath}: ${errorMessage}`,
466 |       error: `Error reading file ${filePath}: ${errorMessage}`,
467 |       errorType: ToolErrorType.READ_CONTENT_FAILURE,
468 |     };
469 |   }
470 | }
471 | 
472 | export async function fileExists(filePath: string): Promise<boolean> {
473 |   try {
474 |     await fsPromises.access(filePath, fs.constants.F_OK);
475 |     return true;
476 |   } catch (_: unknown) {
477 |     return false;
478 |   }
479 | }
```

src/utils/flashFallback.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, vi } from 'vitest';
8 | import { Config } from '../config/config.js';
9 | import fs from 'node:fs';
10 | import {
11 |   setSimulate429,
12 |   disableSimulationAfterFallback,
13 |   shouldSimulate429,
14 |   resetRequestCounter,
15 | } from './testUtils.js';
16 | import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';
17 | import { retryWithBackoff } from './retry.js';
18 | import { AuthType } from '../core/contentGenerator.js';
19 | // Import the new types (Assuming this test file is in packages/core/src/utils/)
20 | import type { FallbackModelHandler } from '../fallback/types.js';
21 | import type { GoogleApiError } from './googleErrors.js';
22 | import { TerminalQuotaError } from './googleQuotaErrors.js';
23 | 
24 | vi.mock('node:fs');
25 | 
26 | // Update the description to reflect that this tests the retry utility's integration
27 | describe('Retry Utility Fallback Integration', () => {
28 |   let config: Config;
29 |   let mockGoogleApiError: GoogleApiError;
30 | 
31 |   beforeEach(() => {
32 |     vi.mocked(fs.existsSync).mockReturnValue(true);
33 |     vi.mocked(fs.statSync).mockReturnValue({
34 |       isDirectory: () => true,
35 |     } as fs.Stats);
36 |     config = new Config({
37 |       sessionId: 'test-session',
38 |       targetDir: '/test',
39 |       debugMode: false,
40 |       cwd: '/test',
41 |       model: 'gemini-2.5-pro',
42 |     });
43 |     mockGoogleApiError = {
44 |       code: 429,
45 |       message: 'mock error',
46 |       details: [],
47 |     };
48 | 
49 |     // Reset simulation state for each test
50 |     setSimulate429(false);
51 |     resetRequestCounter();
52 |   });
53 | 
54 |   // This test validates the Config's ability to store and execute the handler contract.
55 |   it('should execute the injected FallbackHandler contract correctly', async () => {
56 |     // Set up a minimal handler for testing, ensuring it matches the new type.
57 |     const fallbackHandler: FallbackModelHandler = async () => 'retry';
58 | 
59 |     // Use the generalized setter
60 |     config.setFallbackModelHandler(fallbackHandler);
61 | 
62 |     // Call the handler directly via the config property
63 |     const result = await config.fallbackModelHandler!(
64 |       'gemini-2.5-pro',
65 |       DEFAULT_GEMINI_FLASH_MODEL,
66 |       new Error('test'),
67 |     );
68 | 
69 |     // Verify it returns the correct intent
70 |     expect(result).toBe('retry');
71 |   });
72 | 
73 |   // This test validates the retry utility's logic for triggering the callback.
74 |   it('should trigger onPersistent429 on TerminalQuotaError for OAuth users', async () => {
75 |     let fallbackCalled = false;
76 | 
77 |     const mockApiCall = vi
78 |       .fn()
79 |       .mockRejectedValueOnce(
80 |         new TerminalQuotaError('Daily limit', mockGoogleApiError),
81 |       )
82 |       .mockRejectedValueOnce(
83 |         new TerminalQuotaError('Daily limit', mockGoogleApiError),
84 |       )
85 |       .mockResolvedValueOnce('success after fallback');
86 | 
87 |     const mockPersistent429Callback = vi.fn(async (_authType?: string) => {
88 |       fallbackCalled = true;
89 |       return true;
90 |     });
91 | 
92 |     const result = await retryWithBackoff(mockApiCall, {
93 |       maxAttempts: 2,
94 |       initialDelayMs: 1,
95 |       maxDelayMs: 10,
96 |       onPersistent429: mockPersistent429Callback,
97 |       authType: AuthType.LOGIN_WITH_GOOGLE,
98 |     });
99 | 
100 |     expect(fallbackCalled).toBe(true);
101 |     expect(mockPersistent429Callback).toHaveBeenCalledWith(
102 |       AuthType.LOGIN_WITH_GOOGLE,
103 |       expect.any(TerminalQuotaError),
104 |     );
105 |     expect(result).toBe('success after fallback');
106 |     expect(mockApiCall).toHaveBeenCalledTimes(3);
107 |   });
108 | 
109 |   it('should not trigger onPersistent429 for API key users', async () => {
110 |     const fallbackCallback = vi.fn();
111 | 
112 |     const mockApiCall = vi
113 |       .fn()
114 |       .mockRejectedValueOnce(
115 |         new TerminalQuotaError('Daily limit', mockGoogleApiError),
116 |       );
117 | 
118 |     const promise = retryWithBackoff(mockApiCall, {
119 |       maxAttempts: 2,
120 |       initialDelayMs: 1,
121 |       maxDelayMs: 10,
122 |       onPersistent429: fallbackCallback,
123 |       authType: AuthType.USE_GEMINI, // API key auth type
124 |     });
125 | 
126 |     await expect(promise).rejects.toThrow('Daily limit');
127 |     expect(fallbackCallback).not.toHaveBeenCalled();
128 |     expect(mockApiCall).toHaveBeenCalledTimes(1);
129 |   });
130 | 
131 |   // This test validates the test utilities themselves.
132 |   it('should properly disable simulation state after fallback (Test Utility)', () => {
133 |     // Enable simulation
134 |     setSimulate429(true);
135 | 
136 |     // Verify simulation is enabled
137 |     expect(shouldSimulate429()).toBe(true);
138 | 
139 |     // Disable simulation after fallback
140 |     disableSimulationAfterFallback();
141 | 
142 |     // Verify simulation is now disabled
143 |     expect(shouldSimulate429()).toBe(false);
144 |   });
145 | });
```

src/utils/formatters.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | 
9 | import { bytesToMB, formatMemoryUsage } from './formatters.js';
10 | 
11 | describe('bytesToMB', () => {
12 |   it('converts bytes to megabytes', () => {
13 |     expect(bytesToMB(0)).toBe(0);
14 |     expect(bytesToMB(512 * 1024)).toBeCloseTo(0.5, 5);
15 |     expect(bytesToMB(5 * 1024 * 1024)).toBe(5);
16 |   });
17 | });
18 | 
19 | describe('formatMemoryUsage', () => {
20 |   it('formats values below one megabyte in KB', () => {
21 |     expect(formatMemoryUsage(512 * 1024)).toBe('512.0 KB');
22 |   });
23 | 
24 |   it('formats values below one gigabyte in MB', () => {
25 |     expect(formatMemoryUsage(5 * 1024 * 1024)).toBe('5.0 MB');
26 |   });
27 | 
28 |   it('formats values of one gigabyte or larger in GB', () => {
29 |     expect(formatMemoryUsage(2 * 1024 * 1024 * 1024)).toBe('2.00 GB');
30 |   });
31 | });
```

src/utils/formatters.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export const bytesToMB = (bytes: number): number => bytes / (1024 * 1024);
8 | 
9 | export const formatMemoryUsage = (bytes: number): string => {
10 |   const gb = bytes / (1024 * 1024 * 1024);
11 |   if (bytes < 1024 * 1024) {
12 |     return `${(bytes / 1024).toFixed(1)} KB`;
13 |   }
14 |   if (bytes < 1024 * 1024 * 1024) {
15 |     return `${bytesToMB(bytes).toFixed(1)} MB`;
16 |   }
17 |   return `${gb.toFixed(2)} GB`;
18 | };
```

src/utils/geminiIgnoreParser.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { vi, describe, it, expect, beforeEach, afterEach } from 'vitest';
8 | import { GeminiIgnoreParser } from './geminiIgnoreParser.js';
9 | import * as fs from 'node:fs/promises';
10 | import * as path from 'node:path';
11 | import * as os from 'node:os';
12 | 
13 | describe('GeminiIgnoreParser', () => {
14 |   let projectRoot: string;
15 | 
16 |   async function createTestFile(filePath: string, content = '') {
17 |     const fullPath = path.join(projectRoot, filePath);
18 |     await fs.mkdir(path.dirname(fullPath), { recursive: true });
19 |     await fs.writeFile(fullPath, content);
20 |   }
21 | 
22 |   beforeEach(async () => {
23 |     projectRoot = await fs.mkdtemp(
24 |       path.join(os.tmpdir(), 'geminiignore-test-'),
25 |     );
26 |   });
27 | 
28 |   afterEach(async () => {
29 |     await fs.rm(projectRoot, { recursive: true, force: true });
30 |     vi.restoreAllMocks();
31 |   });
32 | 
33 |   describe('when .geminiignore exists', () => {
34 |     beforeEach(async () => {
35 |       await createTestFile(
36 |         '.geminiignore',
37 |         'ignored.txt\n# A comment\n/ignored_dir/\n',
38 |       );
39 |       await createTestFile('ignored.txt', 'ignored');
40 |       await createTestFile('not_ignored.txt', 'not ignored');
41 |       await createTestFile(
42 |         path.join('ignored_dir', 'file.txt'),
43 |         'in ignored dir',
44 |       );
45 |       await createTestFile(
46 |         path.join('subdir', 'not_ignored.txt'),
47 |         'not ignored',
48 |       );
49 |     });
50 | 
51 |     it('should ignore files specified in .geminiignore', () => {
52 |       const parser = new GeminiIgnoreParser(projectRoot);
53 |       expect(parser.getPatterns()).toEqual(['ignored.txt', '/ignored_dir/']);
54 |       expect(parser.isIgnored('ignored.txt')).toBe(true);
55 |       expect(parser.isIgnored('not_ignored.txt')).toBe(false);
56 |       expect(parser.isIgnored(path.join('ignored_dir', 'file.txt'))).toBe(true);
57 |       expect(parser.isIgnored(path.join('subdir', 'not_ignored.txt'))).toBe(
58 |         false,
59 |       );
60 |     });
61 |   });
62 | 
63 |   describe('when .geminiignore does not exist', () => {
64 |     it('should not load any patterns and not ignore any files', () => {
65 |       const parser = new GeminiIgnoreParser(projectRoot);
66 |       expect(parser.getPatterns()).toEqual([]);
67 |       expect(parser.isIgnored('any_file.txt')).toBe(false);
68 |     });
69 |   });
70 | });
```

src/utils/geminiIgnoreParser.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs';
8 | import * as path from 'node:path';
9 | import ignore from 'ignore';
10 | 
11 | export interface GeminiIgnoreFilter {
12 |   isIgnored(filePath: string): boolean;
13 |   getPatterns(): string[];
14 | }
15 | 
16 | export class GeminiIgnoreParser implements GeminiIgnoreFilter {
17 |   private projectRoot: string;
18 |   private patterns: string[] = [];
19 |   private ig = ignore();
20 | 
21 |   constructor(projectRoot: string) {
22 |     this.projectRoot = path.resolve(projectRoot);
23 |     this.loadPatterns();
24 |   }
25 | 
26 |   private loadPatterns(): void {
27 |     const patternsFilePath = path.join(this.projectRoot, '.geminiignore');
28 |     let content: string;
29 |     try {
30 |       content = fs.readFileSync(patternsFilePath, 'utf-8');
31 |     } catch (_error) {
32 |       // ignore file not found
33 |       return;
34 |     }
35 | 
36 |     this.patterns = (content ?? '')
37 |       .split('\n')
38 |       .map((p) => p.trim())
39 |       .filter((p) => p !== '' && !p.startsWith('#'));
40 | 
41 |     this.ig.add(this.patterns);
42 |   }
43 | 
44 |   isIgnored(filePath: string): boolean {
45 |     if (this.patterns.length === 0) {
46 |       return false;
47 |     }
48 | 
49 |     if (!filePath || typeof filePath !== 'string') {
50 |       return false;
51 |     }
52 | 
53 |     if (
54 |       filePath.startsWith('\\') ||
55 |       filePath === '/' ||
56 |       filePath.includes('\0')
57 |     ) {
58 |       return false;
59 |     }
60 | 
61 |     const resolved = path.resolve(this.projectRoot, filePath);
62 |     const relativePath = path.relative(this.projectRoot, resolved);
63 | 
64 |     if (relativePath === '' || relativePath.startsWith('..')) {
65 |       return false;
66 |     }
67 | 
68 |     // Even in windows, Ignore expects forward slashes.
69 |     const normalizedPath = relativePath.replace(/\\/g, '/');
70 | 
71 |     if (normalizedPath.startsWith('/') || normalizedPath === '') {
72 |       return false;
73 |     }
74 | 
75 |     return this.ig.ignores(normalizedPath);
76 |   }
77 | 
78 |   getPatterns(): string[] {
79 |     return this.patterns;
80 |   }
81 | }
```

src/utils/generateContentResponseUtilities.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import {
9 |   getResponseTextFromParts,
10 |   getFunctionCalls,
11 |   getFunctionCallsFromParts,
12 |   getFunctionCallsAsJson,
13 |   getFunctionCallsFromPartsAsJson,
14 |   getStructuredResponse,
15 |   getStructuredResponseFromParts,
16 | } from './generateContentResponseUtilities.js';
17 | import type {
18 |   GenerateContentResponse,
19 |   Part,
20 |   SafetyRating,
21 | } from '@google/genai';
22 | import { FinishReason } from '@google/genai';
23 | 
24 | const mockTextPart = (text: string): Part => ({ text });
25 | const mockFunctionCallPart = (
26 |   name: string,
27 |   args?: Record<string, unknown>,
28 | ): Part => ({
29 |   functionCall: { name, args: args ?? {} },
30 | });
31 | 
32 | const mockResponse = (
33 |   parts: Part[],
34 |   finishReason: FinishReason = FinishReason.STOP,
35 |   safetyRatings: SafetyRating[] = [],
36 | ): GenerateContentResponse => ({
37 |   candidates: [
38 |     {
39 |       content: {
40 |         parts,
41 |         role: 'model',
42 |       },
43 |       index: 0,
44 |       finishReason,
45 |       safetyRatings,
46 |     },
47 |   ],
48 |   promptFeedback: {
49 |     safetyRatings: [],
50 |   },
51 |   text: undefined,
52 |   data: undefined,
53 |   functionCalls: undefined,
54 |   executableCode: undefined,
55 |   codeExecutionResult: undefined,
56 | });
57 | 
58 | const minimalMockResponse = (
59 |   candidates: GenerateContentResponse['candidates'],
60 | ): GenerateContentResponse => ({
61 |   candidates,
62 |   promptFeedback: { safetyRatings: [] },
63 |   text: undefined,
64 |   data: undefined,
65 |   functionCalls: undefined,
66 |   executableCode: undefined,
67 |   codeExecutionResult: undefined,
68 | });
69 | 
70 | describe('generateContentResponseUtilities', () => {
71 |   describe('getResponseTextFromParts', () => {
72 |     it('should return undefined for no parts', () => {
73 |       expect(getResponseTextFromParts([])).toBeUndefined();
74 |     });
75 |     it('should extract text from a single text part', () => {
76 |       expect(getResponseTextFromParts([mockTextPart('Hello')])).toBe('Hello');
77 |     });
78 |     it('should concatenate text from multiple text parts', () => {
79 |       expect(
80 |         getResponseTextFromParts([
81 |           mockTextPart('Hello '),
82 |           mockTextPart('World'),
83 |         ]),
84 |       ).toBe('Hello World');
85 |     });
86 |     it('should ignore function call parts', () => {
87 |       expect(
88 |         getResponseTextFromParts([
89 |           mockTextPart('Hello '),
90 |           mockFunctionCallPart('testFunc'),
91 |           mockTextPart('World'),
92 |         ]),
93 |       ).toBe('Hello World');
94 |     });
95 |     it('should return undefined if only function call parts exist', () => {
96 |       expect(
97 |         getResponseTextFromParts([
98 |           mockFunctionCallPart('testFunc'),
99 |           mockFunctionCallPart('anotherFunc'),
100 |         ]),
101 |       ).toBeUndefined();
102 |     });
103 |   });
104 | 
105 |   describe('getFunctionCalls', () => {
106 |     it('should return undefined for no candidates', () => {
107 |       expect(getFunctionCalls(minimalMockResponse(undefined))).toBeUndefined();
108 |     });
109 |     it('should return undefined for empty candidates array', () => {
110 |       expect(getFunctionCalls(minimalMockResponse([]))).toBeUndefined();
111 |     });
112 |     it('should return undefined for no parts', () => {
113 |       const response = mockResponse([]);
114 |       expect(getFunctionCalls(response)).toBeUndefined();
115 |     });
116 |     it('should extract a single function call', () => {
117 |       const func = { name: 'testFunc', args: { a: 1 } };
118 |       const response = mockResponse([
119 |         mockFunctionCallPart(func.name, func.args),
120 |       ]);
121 |       expect(getFunctionCalls(response)).toEqual([func]);
122 |     });
123 |     it('should extract multiple function calls', () => {
124 |       const func1 = { name: 'testFunc1', args: { a: 1 } };
125 |       const func2 = { name: 'testFunc2', args: { b: 2 } };
126 |       const response = mockResponse([
127 |         mockFunctionCallPart(func1.name, func1.args),
128 |         mockFunctionCallPart(func2.name, func2.args),
129 |       ]);
130 |       expect(getFunctionCalls(response)).toEqual([func1, func2]);
131 |     });
132 |     it('should ignore text parts', () => {
133 |       const func = { name: 'testFunc', args: { a: 1 } };
134 |       const response = mockResponse([
135 |         mockTextPart('Some text'),
136 |         mockFunctionCallPart(func.name, func.args),
137 |         mockTextPart('More text'),
138 |       ]);
139 |       expect(getFunctionCalls(response)).toEqual([func]);
140 |     });
141 |     it('should return undefined if only text parts exist', () => {
142 |       const response = mockResponse([
143 |         mockTextPart('Some text'),
144 |         mockTextPart('More text'),
145 |       ]);
146 |       expect(getFunctionCalls(response)).toBeUndefined();
147 |     });
148 |   });
149 | 
150 |   describe('getFunctionCallsFromParts', () => {
151 |     it('should return undefined for no parts', () => {
152 |       expect(getFunctionCallsFromParts([])).toBeUndefined();
153 |     });
154 |     it('should extract a single function call', () => {
155 |       const func = { name: 'testFunc', args: { a: 1 } };
156 |       expect(
157 |         getFunctionCallsFromParts([mockFunctionCallPart(func.name, func.args)]),
158 |       ).toEqual([func]);
159 |     });
160 |     it('should extract multiple function calls', () => {
161 |       const func1 = { name: 'testFunc1', args: { a: 1 } };
162 |       const func2 = { name: 'testFunc2', args: { b: 2 } };
163 |       expect(
164 |         getFunctionCallsFromParts([
165 |           mockFunctionCallPart(func1.name, func1.args),
166 |           mockFunctionCallPart(func2.name, func2.args),
167 |         ]),
168 |       ).toEqual([func1, func2]);
169 |     });
170 |     it('should ignore text parts', () => {
171 |       const func = { name: 'testFunc', args: { a: 1 } };
172 |       expect(
173 |         getFunctionCallsFromParts([
174 |           mockTextPart('Some text'),
175 |           mockFunctionCallPart(func.name, func.args),
176 |           mockTextPart('More text'),
177 |         ]),
178 |       ).toEqual([func]);
179 |     });
180 |     it('should return undefined if only text parts exist', () => {
181 |       expect(
182 |         getFunctionCallsFromParts([
183 |           mockTextPart('Some text'),
184 |           mockTextPart('More text'),
185 |         ]),
186 |       ).toBeUndefined();
187 |     });
188 |   });
189 | 
190 |   describe('getFunctionCallsAsJson', () => {
191 |     it('should return JSON string of function calls', () => {
192 |       const func1 = { name: 'testFunc1', args: { a: 1 } };
193 |       const func2 = { name: 'testFunc2', args: { b: 2 } };
194 |       const response = mockResponse([
195 |         mockFunctionCallPart(func1.name, func1.args),
196 |         mockTextPart('text in between'),
197 |         mockFunctionCallPart(func2.name, func2.args),
198 |       ]);
199 |       const expectedJson = JSON.stringify([func1, func2], null, 2);
200 |       expect(getFunctionCallsAsJson(response)).toBe(expectedJson);
201 |     });
202 |     it('should return undefined if no function calls', () => {
203 |       const response = mockResponse([mockTextPart('Hello')]);
204 |       expect(getFunctionCallsAsJson(response)).toBeUndefined();
205 |     });
206 |   });
207 | 
208 |   describe('getFunctionCallsFromPartsAsJson', () => {
209 |     it('should return JSON string of function calls from parts', () => {
210 |       const func1 = { name: 'testFunc1', args: { a: 1 } };
211 |       const func2 = { name: 'testFunc2', args: { b: 2 } };
212 |       const parts = [
213 |         mockFunctionCallPart(func1.name, func1.args),
214 |         mockTextPart('text in between'),
215 |         mockFunctionCallPart(func2.name, func2.args),
216 |       ];
217 |       const expectedJson = JSON.stringify([func1, func2], null, 2);
218 |       expect(getFunctionCallsFromPartsAsJson(parts)).toBe(expectedJson);
219 |     });
220 |     it('should return undefined if no function calls in parts', () => {
221 |       const parts = [mockTextPart('Hello')];
222 |       expect(getFunctionCallsFromPartsAsJson(parts)).toBeUndefined();
223 |     });
224 |   });
225 | 
226 |   describe('getStructuredResponse', () => {
227 |     it('should return only text if only text exists', () => {
228 |       const response = mockResponse([mockTextPart('Hello World')]);
229 |       expect(getStructuredResponse(response)).toBe('Hello World');
230 |     });
231 |     it('should return only function call JSON if only function calls exist', () => {
232 |       const func = { name: 'testFunc', args: { data: 'payload' } };
233 |       const response = mockResponse([
234 |         mockFunctionCallPart(func.name, func.args),
235 |       ]);
236 |       const expectedJson = JSON.stringify([func], null, 2);
237 |       expect(getStructuredResponse(response)).toBe(expectedJson);
238 |     });
239 |     it('should return text and function call JSON if both exist', () => {
240 |       const text = 'Consider this data:';
241 |       const func = { name: 'processData', args: { item: 42 } };
242 |       const response = mockResponse([
243 |         mockTextPart(text),
244 |         mockFunctionCallPart(func.name, func.args),
245 |       ]);
246 |       const expectedJson = JSON.stringify([func], null, 2);
247 |       expect(getStructuredResponse(response)).toBe(`${text}\n${expectedJson}`);
248 |     });
249 |     it('should return undefined if neither text nor function calls exist', () => {
250 |       const response = mockResponse([]);
251 |       expect(getStructuredResponse(response)).toBeUndefined();
252 |     });
253 |   });
254 | 
255 |   describe('getStructuredResponseFromParts', () => {
256 |     it('should return only text if only text exists in parts', () => {
257 |       const parts = [mockTextPart('Hello World')];
258 |       expect(getStructuredResponseFromParts(parts)).toBe('Hello World');
259 |     });
260 |     it('should return only function call JSON if only function calls exist in parts', () => {
261 |       const func = { name: 'testFunc', args: { data: 'payload' } };
262 |       const parts = [mockFunctionCallPart(func.name, func.args)];
263 |       const expectedJson = JSON.stringify([func], null, 2);
264 |       expect(getStructuredResponseFromParts(parts)).toBe(expectedJson);
265 |     });
266 |     it('should return text and function call JSON if both exist in parts', () => {
267 |       const text = 'Consider this data:';
268 |       const func = { name: 'processData', args: { item: 42 } };
269 |       const parts = [
270 |         mockTextPart(text),
271 |         mockFunctionCallPart(func.name, func.args),
272 |       ];
273 |       const expectedJson = JSON.stringify([func], null, 2);
274 |       expect(getStructuredResponseFromParts(parts)).toBe(
275 |         `${text}\n${expectedJson}`,
276 |       );
277 |     });
278 |     it('should return undefined if neither text nor function calls exist in parts', () => {
279 |       const parts: Part[] = [];
280 |       expect(getStructuredResponseFromParts(parts)).toBeUndefined();
281 |     });
282 |   });
283 | });
```

src/utils/generateContentResponseUtilities.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   GenerateContentResponse,
9 |   Part,
10 |   FunctionCall,
11 | } from '@google/genai';
12 | import { getResponseText } from './partUtils.js';
13 | 
14 | export function getResponseTextFromParts(parts: Part[]): string | undefined {
15 |   if (!parts) {
16 |     return undefined;
17 |   }
18 |   const textSegments = parts
19 |     .map((part) => part.text)
20 |     .filter((text): text is string => typeof text === 'string');
21 | 
22 |   if (textSegments.length === 0) {
23 |     return undefined;
24 |   }
25 |   return textSegments.join('');
26 | }
27 | 
28 | export function getFunctionCalls(
29 |   response: GenerateContentResponse,
30 | ): FunctionCall[] | undefined {
31 |   const parts = response.candidates?.[0]?.content?.parts;
32 |   if (!parts) {
33 |     return undefined;
34 |   }
35 |   const functionCallParts = parts
36 |     .filter((part) => !!part.functionCall)
37 |     .map((part) => part.functionCall as FunctionCall);
38 |   return functionCallParts.length > 0 ? functionCallParts : undefined;
39 | }
40 | 
41 | export function getFunctionCallsFromParts(
42 |   parts: Part[],
43 | ): FunctionCall[] | undefined {
44 |   if (!parts) {
45 |     return undefined;
46 |   }
47 |   const functionCallParts = parts
48 |     .filter((part) => !!part.functionCall)
49 |     .map((part) => part.functionCall as FunctionCall);
50 |   return functionCallParts.length > 0 ? functionCallParts : undefined;
51 | }
52 | 
53 | export function getFunctionCallsAsJson(
54 |   response: GenerateContentResponse,
55 | ): string | undefined {
56 |   const functionCalls = getFunctionCalls(response);
57 |   if (!functionCalls) {
58 |     return undefined;
59 |   }
60 |   return JSON.stringify(functionCalls, null, 2);
61 | }
62 | 
63 | export function getFunctionCallsFromPartsAsJson(
64 |   parts: Part[],
65 | ): string | undefined {
66 |   const functionCalls = getFunctionCallsFromParts(parts);
67 |   if (!functionCalls) {
68 |     return undefined;
69 |   }
70 |   return JSON.stringify(functionCalls, null, 2);
71 | }
72 | 
73 | export function getStructuredResponse(
74 |   response: GenerateContentResponse,
75 | ): string | undefined {
76 |   const textContent = getResponseText(response);
77 |   const functionCallsJson = getFunctionCallsAsJson(response);
78 | 
79 |   if (textContent && functionCallsJson) {
80 |     return `${textContent}\n${functionCallsJson}`;
81 |   }
82 |   if (textContent) {
83 |     return textContent;
84 |   }
85 |   if (functionCallsJson) {
86 |     return functionCallsJson;
87 |   }
88 |   return undefined;
89 | }
90 | 
91 | export function getStructuredResponseFromParts(
92 |   parts: Part[],
93 | ): string | undefined {
94 |   const textContent = getResponseTextFromParts(parts);
95 |   const functionCallsJson = getFunctionCallsFromPartsAsJson(parts);
96 | 
97 |   if (textContent && functionCallsJson) {
98 |     return `${textContent}\n${functionCallsJson}`;
99 |   }
100 |   if (textContent) {
101 |     return textContent;
102 |   }
103 |   if (functionCallsJson) {
104 |     return functionCallsJson;
105 |   }
106 |   return undefined;
107 | }
```

src/utils/getFolderStructure.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach } from 'vitest';
8 | import fsPromises from 'node:fs/promises';
9 | import * as nodePath from 'node:path';
10 | import * as os from 'node:os';
11 | import { getFolderStructure } from './getFolderStructure.js';
12 | import { FileDiscoveryService } from '../services/fileDiscoveryService.js';
13 | import * as path from 'node:path';
14 | 
15 | describe('getFolderStructure', () => {
16 |   let testRootDir: string;
17 | 
18 |   async function createEmptyDir(...pathSegments: string[]) {
19 |     const fullPath = path.join(testRootDir, ...pathSegments);
20 |     await fsPromises.mkdir(fullPath, { recursive: true });
21 |   }
22 | 
23 |   async function createTestFile(...pathSegments: string[]) {
24 |     const fullPath = path.join(testRootDir, ...pathSegments);
25 |     await fsPromises.mkdir(path.dirname(fullPath), { recursive: true });
26 |     await fsPromises.writeFile(fullPath, '');
27 |     return fullPath;
28 |   }
29 | 
30 |   beforeEach(async () => {
31 |     testRootDir = await fsPromises.mkdtemp(
32 |       path.join(os.tmpdir(), 'folder-structure-test-'),
33 |     );
34 |   });
35 | 
36 |   afterEach(async () => {
37 |     await fsPromises.rm(testRootDir, { recursive: true, force: true });
38 |   });
39 | 
40 |   it('should return basic folder structure', async () => {
41 |     await createTestFile('fileA1.ts');
42 |     await createTestFile('fileA2.js');
43 |     await createTestFile('subfolderB', 'fileB1.md');
44 | 
45 |     const structure = await getFolderStructure(testRootDir);
46 |     expect(structure.trim()).toBe(
47 |       `
48 | Showing up to 200 items (files + folders).
49 | 
50 | ${testRootDir}${path.sep}
51 | ├───fileA1.ts
52 | ├───fileA2.js
53 | └───subfolderB${path.sep}
54 |     └───fileB1.md
55 | `.trim(),
56 |     );
57 |   });
58 | 
59 |   it('should handle an empty folder', async () => {
60 |     const structure = await getFolderStructure(testRootDir);
61 |     expect(structure.trim()).toBe(
62 |       `
63 | Showing up to 200 items (files + folders).
64 | 
65 | ${testRootDir}${path.sep}
66 | `
67 |         .trim()
68 |         .trim(),
69 |     );
70 |   });
71 | 
72 |   it('should ignore folders specified in ignoredFolders (default)', async () => {
73 |     await createTestFile('.hiddenfile');
74 |     await createTestFile('file1.txt');
75 |     await createEmptyDir('emptyFolder');
76 |     await createTestFile('node_modules', 'somepackage', 'index.js');
77 |     await createTestFile('subfolderA', 'fileA1.ts');
78 |     await createTestFile('subfolderA', 'fileA2.js');
79 |     await createTestFile('subfolderA', 'subfolderB', 'fileB1.md');
80 | 
81 |     const structure = await getFolderStructure(testRootDir);
82 |     expect(structure.trim()).toBe(
83 |       `
84 | Showing up to 200 items (files + folders). Folders or files indicated with ... contain more items not shown, were ignored, or the display limit (200 items) was reached.
85 | 
86 | ${testRootDir}${path.sep}
87 | ├───.hiddenfile
88 | ├───file1.txt
89 | ├───emptyFolder${path.sep}
90 | ├───node_modules${path.sep}...
91 | └───subfolderA${path.sep}
92 |     ├───fileA1.ts
93 |     ├───fileA2.js
94 |     └───subfolderB${path.sep}
95 |         └───fileB1.md
96 | `.trim(),
97 |     );
98 |   });
99 | 
100 |   it('should ignore folders specified in custom ignoredFolders', async () => {
101 |     await createTestFile('.hiddenfile');
102 |     await createTestFile('file1.txt');
103 |     await createEmptyDir('emptyFolder');
104 |     await createTestFile('node_modules', 'somepackage', 'index.js');
105 |     await createTestFile('subfolderA', 'fileA1.ts');
106 | 
107 |     const structure = await getFolderStructure(testRootDir, {
108 |       ignoredFolders: new Set(['subfolderA', 'node_modules']),
109 |     });
110 |     const expected = `
111 | Showing up to 200 items (files + folders). Folders or files indicated with ... contain more items not shown, were ignored, or the display limit (200 items) was reached.
112 | 
113 | ${testRootDir}${path.sep}
114 | ├───.hiddenfile
115 | ├───file1.txt
116 | ├───emptyFolder${path.sep}
117 | ├───node_modules${path.sep}...
118 | └───subfolderA${path.sep}...
119 | `.trim();
120 |     expect(structure.trim()).toBe(expected);
121 |   });
122 | 
123 |   it('should filter files by fileIncludePattern', async () => {
124 |     await createTestFile('fileA1.ts');
125 |     await createTestFile('fileA2.js');
126 |     await createTestFile('subfolderB', 'fileB1.md');
127 | 
128 |     const structure = await getFolderStructure(testRootDir, {
129 |       fileIncludePattern: /\.ts$/,
130 |     });
131 |     const expected = `
132 | Showing up to 200 items (files + folders).
133 | 
134 | ${testRootDir}${path.sep}
135 | ├───fileA1.ts
136 | └───subfolderB${path.sep}
137 | `.trim();
138 |     expect(structure.trim()).toBe(expected);
139 |   });
140 | 
141 |   it('should handle maxItems truncation for files within a folder', async () => {
142 |     await createTestFile('fileA1.ts');
143 |     await createTestFile('fileA2.js');
144 |     await createTestFile('subfolderB', 'fileB1.md');
145 | 
146 |     const structure = await getFolderStructure(testRootDir, {
147 |       maxItems: 3,
148 |     });
149 |     const expected = `
150 | Showing up to 3 items (files + folders).
151 | 
152 | ${testRootDir}${path.sep}
153 | ├───fileA1.ts
154 | ├───fileA2.js
155 | └───subfolderB${path.sep}
156 | `.trim();
157 |     expect(structure.trim()).toBe(expected);
158 |   });
159 | 
160 |   it('should handle maxItems truncation for subfolders', async () => {
161 |     for (let i = 0; i < 5; i++) {
162 |       await createTestFile(`folder-${i}`, 'child.txt');
163 |     }
164 | 
165 |     const structure = await getFolderStructure(testRootDir, {
166 |       maxItems: 4,
167 |     });
168 |     const expectedRevised = `
169 | Showing up to 4 items (files + folders). Folders or files indicated with ... contain more items not shown, were ignored, or the display limit (4 items) was reached.
170 | 
171 | ${testRootDir}${path.sep}
172 | ├───folder-0${path.sep}
173 | ├───folder-1${path.sep}
174 | ├───folder-2${path.sep}
175 | ├───folder-3${path.sep}
176 | └───...
177 | `.trim();
178 |     expect(structure.trim()).toBe(expectedRevised);
179 |   });
180 | 
181 |   it('should handle maxItems that only allows the root folder itself', async () => {
182 |     await createTestFile('fileA1.ts');
183 |     await createTestFile('fileA2.ts');
184 |     await createTestFile('subfolderB', 'fileB1.ts');
185 | 
186 |     const structure = await getFolderStructure(testRootDir, {
187 |       maxItems: 1,
188 |     });
189 |     const expected = `
190 | Showing up to 1 items (files + folders). Folders or files indicated with ... contain more items not shown, were ignored, or the display limit (1 items) was reached.
191 | 
192 | ${testRootDir}${path.sep}
193 | ├───fileA1.ts
194 | ├───...
195 | └───...
196 | `.trim();
197 |     expect(structure.trim()).toBe(expected);
198 |   });
199 | 
200 |   it('should handle non-existent directory', async () => {
201 |     const nonExistentPath = path.join(testRootDir, 'non-existent');
202 |     const structure = await getFolderStructure(nonExistentPath);
203 |     expect(structure).toContain(
204 |       `Error: Could not read directory "${nonExistentPath}". Check path and permissions.`,
205 |     );
206 |   });
207 | 
208 |   it('should handle deep folder structure within limits', async () => {
209 |     await createTestFile('level1', 'level2', 'level3', 'file.txt');
210 | 
211 |     const structure = await getFolderStructure(testRootDir, {
212 |       maxItems: 10,
213 |     });
214 |     const expected = `
215 | Showing up to 10 items (files + folders).
216 | 
217 | ${testRootDir}${path.sep}
218 | └───level1${path.sep}
219 |     └───level2${path.sep}
220 |         └───level3${path.sep}
221 |             └───file.txt
222 | `.trim();
223 |     expect(structure.trim()).toBe(expected);
224 |   });
225 | 
226 |   it('should truncate deep folder structure if maxItems is small', async () => {
227 |     await createTestFile('level1', 'level2', 'level3', 'file.txt');
228 | 
229 |     const structure = await getFolderStructure(testRootDir, {
230 |       maxItems: 3,
231 |     });
232 |     const expected = `
233 | Showing up to 3 items (files + folders).
234 | 
235 | ${testRootDir}${path.sep}
236 | └───level1${path.sep}
237 |     └───level2${path.sep}
238 |         └───level3${path.sep}
239 | `.trim();
240 |     expect(structure.trim()).toBe(expected);
241 |   });
242 | 
243 |   describe('with gitignore', () => {
244 |     beforeEach(async () => {
245 |       await fsPromises.mkdir(path.join(testRootDir, '.git'), {
246 |         recursive: true,
247 |       });
248 |     });
249 | 
250 |     it('should ignore files and folders specified in .gitignore', async () => {
251 |       await fsPromises.writeFile(
252 |         nodePath.join(testRootDir, '.gitignore'),
253 |         'ignored.txt\nnode_modules/\n.gemini/*\n!/.gemini/config.yaml',
254 |       );
255 |       await createTestFile('file1.txt');
256 |       await createTestFile('node_modules', 'some-package', 'index.js');
257 |       await createTestFile('ignored.txt');
258 |       await createTestFile('.gemini', 'config.yaml');
259 |       await createTestFile('.gemini', 'logs.json');
260 | 
261 |       const fileService = new FileDiscoveryService(testRootDir);
262 |       const structure = await getFolderStructure(testRootDir, {
263 |         fileService,
264 |       });
265 | 
266 |       expect(structure).not.toContain('ignored.txt');
267 |       expect(structure).toContain(`node_modules${path.sep}...`);
268 |       expect(structure).not.toContain('logs.json');
269 |       expect(structure).toContain('config.yaml');
270 |       expect(structure).toContain('file1.txt');
271 |     });
272 | 
273 |     it('should not ignore files if respectGitIgnore is false', async () => {
274 |       await fsPromises.writeFile(
275 |         nodePath.join(testRootDir, '.gitignore'),
276 |         'ignored.txt',
277 |       );
278 |       await createTestFile('file1.txt');
279 |       await createTestFile('ignored.txt');
280 | 
281 |       const fileService = new FileDiscoveryService(testRootDir);
282 |       const structure = await getFolderStructure(testRootDir, {
283 |         fileService,
284 |         fileFilteringOptions: {
285 |           respectGeminiIgnore: false,
286 |           respectGitIgnore: false,
287 |         },
288 |       });
289 | 
290 |       expect(structure).toContain('ignored.txt');
291 |       expect(structure).toContain('file1.txt');
292 |     });
293 |   });
294 | 
295 |   describe('with geminiignore', () => {
296 |     it('should ignore geminiignore files by default', async () => {
297 |       await fsPromises.writeFile(
298 |         nodePath.join(testRootDir, '.geminiignore'),
299 |         'ignored.txt\nnode_modules/\n.gemini/\n!/.gemini/config.yaml',
300 |       );
301 |       await createTestFile('file1.txt');
302 |       await createTestFile('node_modules', 'some-package', 'index.js');
303 |       await createTestFile('ignored.txt');
304 |       await createTestFile('.gemini', 'config.yaml');
305 |       await createTestFile('.gemini', 'logs.json');
306 | 
307 |       const fileService = new FileDiscoveryService(testRootDir);
308 |       const structure = await getFolderStructure(testRootDir, {
309 |         fileService,
310 |       });
311 |       expect(structure).not.toContain('ignored.txt');
312 |       expect(structure).toContain(`node_modules${path.sep}...`);
313 |       expect(structure).not.toContain('logs.json');
314 |     });
315 | 
316 |     it('should not ignore files if respectGeminiIgnore is false', async () => {
317 |       await fsPromises.writeFile(
318 |         nodePath.join(testRootDir, '.geminiignore'),
319 |         'ignored.txt\nnode_modules/\n.gemini/\n!/.gemini/config.yaml',
320 |       );
321 |       await createTestFile('file1.txt');
322 |       await createTestFile('node_modules', 'some-package', 'index.js');
323 |       await createTestFile('ignored.txt');
324 |       await createTestFile('.gemini', 'config.yaml');
325 |       await createTestFile('.gemini', 'logs.json');
326 | 
327 |       const fileService = new FileDiscoveryService(testRootDir);
328 |       const structure = await getFolderStructure(testRootDir, {
329 |         fileService,
330 |         fileFilteringOptions: {
331 |           respectGeminiIgnore: false,
332 |           respectGitIgnore: true, // Explicitly disable gemini ignore only
333 |         },
334 |       });
335 |       expect(structure).toContain('ignored.txt');
336 |       // node_modules is still ignored by default
337 |       expect(structure).toContain(`node_modules${path.sep}...`);
338 |     });
339 |   });
340 | });
```

src/utils/getFolderStructure.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs/promises';
8 | import type { Dirent } from 'node:fs';
9 | import * as path from 'node:path';
10 | import { getErrorMessage, isNodeError } from './errors.js';
11 | import type { FileDiscoveryService } from '../services/fileDiscoveryService.js';
12 | import type { FileFilteringOptions } from '../config/constants.js';
13 | import { DEFAULT_FILE_FILTERING_OPTIONS } from '../config/constants.js';
14 | 
15 | const MAX_ITEMS = 200;
16 | const TRUNCATION_INDICATOR = '...';
17 | const DEFAULT_IGNORED_FOLDERS = new Set(['node_modules', '.git', 'dist']);
18 | 
19 | // --- Interfaces ---
20 | 
21 | /** Options for customizing folder structure retrieval. */
22 | interface FolderStructureOptions {
23 |   /** Maximum number of files and folders combined to display. Defaults to 200. */
24 |   maxItems?: number;
25 |   /** Set of folder names to ignore completely. Case-sensitive. */
26 |   ignoredFolders?: Set<string>;
27 |   /** Optional regex to filter included files by name. */
28 |   fileIncludePattern?: RegExp;
29 |   /** For filtering files. */
30 |   fileService?: FileDiscoveryService;
31 |   /** File filtering ignore options. */
32 |   fileFilteringOptions?: FileFilteringOptions;
33 | }
34 | // Define a type for the merged options where fileIncludePattern remains optional
35 | type MergedFolderStructureOptions = Required<
36 |   Omit<FolderStructureOptions, 'fileIncludePattern' | 'fileService'>
37 | > & {
38 |   fileIncludePattern?: RegExp;
39 |   fileService?: FileDiscoveryService;
40 |   fileFilteringOptions?: FileFilteringOptions;
41 | };
42 | 
43 | /** Represents the full, unfiltered information about a folder and its contents. */
44 | interface FullFolderInfo {
45 |   name: string;
46 |   path: string;
47 |   files: string[];
48 |   subFolders: FullFolderInfo[];
49 |   totalChildren: number; // Number of files and subfolders included from this folder during BFS scan
50 |   totalFiles: number; // Number of files included from this folder during BFS scan
51 |   isIgnored?: boolean; // Flag to easily identify ignored folders later
52 |   hasMoreFiles?: boolean; // Indicates if files were truncated for this specific folder
53 |   hasMoreSubfolders?: boolean; // Indicates if subfolders were truncated for this specific folder
54 | }
55 | 
56 | // --- Interfaces ---
57 | 
58 | // --- Helper Functions ---
59 | 
60 | async function readFullStructure(
61 |   rootPath: string,
62 |   options: MergedFolderStructureOptions,
63 | ): Promise<FullFolderInfo | null> {
64 |   const rootName = path.basename(rootPath);
65 |   const rootNode: FullFolderInfo = {
66 |     name: rootName,
67 |     path: rootPath,
68 |     files: [],
69 |     subFolders: [],
70 |     totalChildren: 0,
71 |     totalFiles: 0,
72 |   };
73 | 
74 |   const queue: Array<{ folderInfo: FullFolderInfo; currentPath: string }> = [
75 |     { folderInfo: rootNode, currentPath: rootPath },
76 |   ];
77 |   let currentItemCount = 0;
78 |   // Count the root node itself as one item if we are not just listing its content
79 | 
80 |   const processedPaths = new Set<string>(); // To avoid processing same path if symlinks create loops
81 | 
82 |   while (queue.length > 0) {
83 |     const { folderInfo, currentPath } = queue.shift()!;
84 | 
85 |     if (processedPaths.has(currentPath)) {
86 |       continue;
87 |     }
88 |     processedPaths.add(currentPath);
89 | 
90 |     if (currentItemCount >= options.maxItems) {
91 |       // If the root itself caused us to exceed, we can't really show anything.
92 |       // Otherwise, this folder won't be processed further.
93 |       // The parent that queued this would have set its own hasMoreSubfolders flag.
94 |       continue;
95 |     }
96 | 
97 |     let entries: Dirent[];
98 |     try {
99 |       const rawEntries = await fs.readdir(currentPath, { withFileTypes: true });
100 |       // Sort entries alphabetically by name for consistent processing order
101 |       entries = rawEntries.sort((a, b) => a.name.localeCompare(b.name));
102 |     } catch (error: unknown) {
103 |       if (
104 |         isNodeError(error) &&
105 |         (error.code === 'EACCES' || error.code === 'ENOENT')
106 |       ) {
107 |         console.warn(
108 |           `Warning: Could not read directory ${currentPath}: ${error.message}`,
109 |         );
110 |         if (currentPath === rootPath && error.code === 'ENOENT') {
111 |           return null; // Root directory itself not found
112 |         }
113 |         // For other EACCES/ENOENT on subdirectories, just skip them.
114 |         continue;
115 |       }
116 |       throw error;
117 |     }
118 | 
119 |     const filesInCurrentDir: string[] = [];
120 |     const subFoldersInCurrentDir: FullFolderInfo[] = [];
121 | 
122 |     // Process files first in the current directory
123 |     for (const entry of entries) {
124 |       if (entry.isFile()) {
125 |         if (currentItemCount >= options.maxItems) {
126 |           folderInfo.hasMoreFiles = true;
127 |           break;
128 |         }
129 |         const fileName = entry.name;
130 |         const filePath = path.join(currentPath, fileName);
131 |         if (options.fileService) {
132 |           const shouldIgnore =
133 |             (options.fileFilteringOptions.respectGitIgnore &&
134 |               options.fileService.shouldGitIgnoreFile(filePath)) ||
135 |             (options.fileFilteringOptions.respectGeminiIgnore &&
136 |               options.fileService.shouldGeminiIgnoreFile(filePath));
137 |           if (shouldIgnore) {
138 |             continue;
139 |           }
140 |         }
141 |         if (
142 |           !options.fileIncludePattern ||
143 |           options.fileIncludePattern.test(fileName)
144 |         ) {
145 |           filesInCurrentDir.push(fileName);
146 |           currentItemCount++;
147 |           folderInfo.totalFiles++;
148 |           folderInfo.totalChildren++;
149 |         }
150 |       }
151 |     }
152 |     folderInfo.files = filesInCurrentDir;
153 | 
154 |     // Then process directories and queue them
155 |     for (const entry of entries) {
156 |       if (entry.isDirectory()) {
157 |         // Check if adding this directory ITSELF would meet or exceed maxItems
158 |         // (currentItemCount refers to items *already* added before this one)
159 |         if (currentItemCount >= options.maxItems) {
160 |           folderInfo.hasMoreSubfolders = true;
161 |           break; // Already at limit, cannot add this folder or any more
162 |         }
163 |         // If adding THIS folder makes us hit the limit exactly, and it might have children,
164 |         // it's better to show '...' for the parent, unless this is the very last item slot.
165 |         // This logic is tricky. Let's try a simpler: if we can't add this item, mark and break.
166 | 
167 |         const subFolderName = entry.name;
168 |         const subFolderPath = path.join(currentPath, subFolderName);
169 | 
170 |         let isIgnored = false;
171 |         if (options.fileService) {
172 |           isIgnored =
173 |             (options.fileFilteringOptions.respectGitIgnore &&
174 |               options.fileService.shouldGitIgnoreFile(subFolderPath)) ||
175 |             (options.fileFilteringOptions.respectGeminiIgnore &&
176 |               options.fileService.shouldGeminiIgnoreFile(subFolderPath));
177 |         }
178 | 
179 |         if (options.ignoredFolders.has(subFolderName) || isIgnored) {
180 |           const ignoredSubFolder: FullFolderInfo = {
181 |             name: subFolderName,
182 |             path: subFolderPath,
183 |             files: [],
184 |             subFolders: [],
185 |             totalChildren: 0,
186 |             totalFiles: 0,
187 |             isIgnored: true,
188 |           };
189 |           subFoldersInCurrentDir.push(ignoredSubFolder);
190 |           currentItemCount++; // Count the ignored folder itself
191 |           folderInfo.totalChildren++; // Also counts towards parent's children
192 |           continue;
193 |         }
194 | 
195 |         const subFolderNode: FullFolderInfo = {
196 |           name: subFolderName,
197 |           path: subFolderPath,
198 |           files: [],
199 |           subFolders: [],
200 |           totalChildren: 0,
201 |           totalFiles: 0,
202 |         };
203 |         subFoldersInCurrentDir.push(subFolderNode);
204 |         currentItemCount++;
205 |         folderInfo.totalChildren++; // Counts towards parent's children
206 | 
207 |         // Add to queue for processing its children later
208 |         queue.push({ folderInfo: subFolderNode, currentPath: subFolderPath });
209 |       }
210 |     }
211 |     folderInfo.subFolders = subFoldersInCurrentDir;
212 |   }
213 | 
214 |   return rootNode;
215 | }
216 | 
217 | /**
218 |  * Reads the directory structure using BFS, respecting maxItems.
219 |  * @param node The current node in the reduced structure.
220 |  * @param indent The current indentation string.
221 |  * @param isLast Sibling indicator.
222 |  * @param builder Array to build the string lines.
223 |  */
224 | function formatStructure(
225 |   node: FullFolderInfo,
226 |   currentIndent: string,
227 |   isLastChildOfParent: boolean,
228 |   isProcessingRootNode: boolean,
229 |   builder: string[],
230 | ): void {
231 |   const connector = isLastChildOfParent ? '└───' : '├───';
232 | 
233 |   // The root node of the structure (the one passed initially to getFolderStructure)
234 |   // is not printed with a connector line itself, only its name as a header.
235 |   // Its children are printed relative to that conceptual root.
236 |   // Ignored root nodes ARE printed with a connector.
237 |   if (!isProcessingRootNode || node.isIgnored) {
238 |     builder.push(
239 |       `${currentIndent}${connector}${node.name}${path.sep}${node.isIgnored ? TRUNCATION_INDICATOR : ''}`,
240 |     );
241 |   }
242 | 
243 |   // Determine the indent for the children of *this* node.
244 |   // If *this* node was the root of the whole structure, its children start with no indent before their connectors.
245 |   // Otherwise, children's indent extends from the current node's indent.
246 |   const indentForChildren = isProcessingRootNode
247 |     ? ''
248 |     : currentIndent + (isLastChildOfParent ? '    ' : '│   ');
249 | 
250 |   // Render files of the current node
251 |   const fileCount = node.files.length;
252 |   for (let i = 0; i < fileCount; i++) {
253 |     const isLastFileAmongSiblings =
254 |       i === fileCount - 1 &&
255 |       node.subFolders.length === 0 &&
256 |       !node.hasMoreSubfolders;
257 |     const fileConnector = isLastFileAmongSiblings ? '└───' : '├───';
258 |     builder.push(`${indentForChildren}${fileConnector}${node.files[i]}`);
259 |   }
260 |   if (node.hasMoreFiles) {
261 |     const isLastIndicatorAmongSiblings =
262 |       node.subFolders.length === 0 && !node.hasMoreSubfolders;
263 |     const fileConnector = isLastIndicatorAmongSiblings ? '└───' : '├───';
264 |     builder.push(`${indentForChildren}${fileConnector}${TRUNCATION_INDICATOR}`);
265 |   }
266 | 
267 |   // Render subfolders of the current node
268 |   const subFolderCount = node.subFolders.length;
269 |   for (let i = 0; i < subFolderCount; i++) {
270 |     const isLastSubfolderAmongSiblings =
271 |       i === subFolderCount - 1 && !node.hasMoreSubfolders;
272 |     // Children are never the root node being processed initially.
273 |     formatStructure(
274 |       node.subFolders[i],
275 |       indentForChildren,
276 |       isLastSubfolderAmongSiblings,
277 |       false,
278 |       builder,
279 |     );
280 |   }
281 |   if (node.hasMoreSubfolders) {
282 |     builder.push(`${indentForChildren}└───${TRUNCATION_INDICATOR}`);
283 |   }
284 | }
285 | 
286 | // --- Main Exported Function ---
287 | 
288 | /**
289 |  * Generates a string representation of a directory's structure,
290 |  * limiting the number of items displayed. Ignored folders are shown
291 |  * followed by '...' instead of their contents.
292 |  *
293 |  * @param directory The absolute or relative path to the directory.
294 |  * @param options Optional configuration settings.
295 |  * @returns A promise resolving to the formatted folder structure string.
296 |  */
297 | export async function getFolderStructure(
298 |   directory: string,
299 |   options?: FolderStructureOptions,
300 | ): Promise<string> {
301 |   const resolvedPath = path.resolve(directory);
302 |   const mergedOptions: MergedFolderStructureOptions = {
303 |     maxItems: options?.maxItems ?? MAX_ITEMS,
304 |     ignoredFolders: options?.ignoredFolders ?? DEFAULT_IGNORED_FOLDERS,
305 |     fileIncludePattern: options?.fileIncludePattern,
306 |     fileService: options?.fileService,
307 |     fileFilteringOptions:
308 |       options?.fileFilteringOptions ?? DEFAULT_FILE_FILTERING_OPTIONS,
309 |   };
310 | 
311 |   try {
312 |     // 1. Read the structure using BFS, respecting maxItems
313 |     const structureRoot = await readFullStructure(resolvedPath, mergedOptions);
314 | 
315 |     if (!structureRoot) {
316 |       return `Error: Could not read directory "${resolvedPath}". Check path and permissions.`;
317 |     }
318 | 
319 |     // 2. Format the structure into a string
320 |     const structureLines: string[] = [];
321 |     // Pass true for isRoot for the initial call
322 |     formatStructure(structureRoot, '', true, true, structureLines);
323 | 
324 |     // 3. Build the final output string
325 |     function isTruncated(node: FullFolderInfo): boolean {
326 |       if (node.hasMoreFiles || node.hasMoreSubfolders || node.isIgnored) {
327 |         return true;
328 |       }
329 |       for (const sub of node.subFolders) {
330 |         if (isTruncated(sub)) {
331 |           return true;
332 |         }
333 |       }
334 |       return false;
335 |     }
336 | 
337 |     let summary = `Showing up to ${mergedOptions.maxItems} items (files + folders).`;
338 | 
339 |     if (isTruncated(structureRoot)) {
340 |       summary += ` Folders or files indicated with ${TRUNCATION_INDICATOR} contain more items not shown, were ignored, or the display limit (${mergedOptions.maxItems} items) was reached.`;
341 |     }
342 | 
343 |     return `${summary}\n\n${resolvedPath}${path.sep}\n${structureLines.join('\n')}`;
344 |   } catch (error: unknown) {
345 |     console.error(`Error getting folder structure for ${resolvedPath}:`, error);
346 |     return `Error processing directory "${resolvedPath}": ${getErrorMessage(error)}`;
347 |   }
348 | }
```

src/utils/getPty.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export type PtyImplementation = {
8 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
9 |   module: any;
10 |   name: 'lydell-node-pty' | 'node-pty';
11 | } | null;
12 | 
13 | export interface PtyProcess {
14 |   readonly pid: number;
15 |   onData(callback: (data: string) => void): void;
16 |   onExit(callback: (e: { exitCode: number; signal?: number }) => void): void;
17 |   kill(signal?: string): void;
18 | }
19 | 
20 | export const getPty = async (): Promise<PtyImplementation> => {
21 |   try {
22 |     const lydell = '@lydell/node-pty';
23 |     const module = await import(lydell);
24 |     return { module, name: 'lydell-node-pty' };
25 |   } catch (_e) {
26 |     try {
27 |       const nodePty = 'node-pty';
28 |       const module = await import(nodePty);
29 |       return { module, name: 'node-pty' };
30 |     } catch (_e2) {
31 |       return null;
32 |     }
33 |   }
34 | };
```

src/utils/gitIgnoreParser.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach } from 'vitest';
8 | import { GitIgnoreParser } from './gitIgnoreParser.js';
9 | import * as fs from 'node:fs/promises';
10 | import * as path from 'node:path';
11 | import * as os from 'node:os';
12 | 
13 | describe('GitIgnoreParser', () => {
14 |   let parser: GitIgnoreParser;
15 |   let projectRoot: string;
16 | 
17 |   async function createTestFile(filePath: string, content = '') {
18 |     const fullPath = path.join(projectRoot, filePath);
19 |     await fs.mkdir(path.dirname(fullPath), { recursive: true });
20 |     await fs.writeFile(fullPath, content);
21 |   }
22 | 
23 |   async function setupGitRepo() {
24 |     await fs.mkdir(path.join(projectRoot, '.git'), { recursive: true });
25 |   }
26 | 
27 |   beforeEach(async () => {
28 |     projectRoot = await fs.mkdtemp(path.join(os.tmpdir(), 'gitignore-test-'));
29 |     parser = new GitIgnoreParser(projectRoot);
30 |   });
31 | 
32 |   afterEach(async () => {
33 |     await fs.rm(projectRoot, { recursive: true, force: true });
34 |   });
35 | 
36 |   describe('Basic ignore behaviors', () => {
37 |     beforeEach(async () => {
38 |       await setupGitRepo();
39 |     });
40 | 
41 |     it('should not ignore files when no .gitignore exists', async () => {
42 |       expect(parser.isIgnored('file.txt')).toBe(false);
43 |     });
44 | 
45 |     it('should ignore files based on a root .gitignore', async () => {
46 |       const gitignoreContent = `
47 | # Comment
48 | node_modules/
49 | *.log
50 | /dist
51 | .env
52 | `;
53 |       await createTestFile('.gitignore', gitignoreContent);
54 | 
55 |       expect(parser.isIgnored(path.join('node_modules', 'some-lib'))).toBe(
56 |         true,
57 |       );
58 |       expect(parser.isIgnored(path.join('src', 'app.log'))).toBe(true);
59 |       expect(parser.isIgnored(path.join('dist', 'index.js'))).toBe(true);
60 |       expect(parser.isIgnored('.env')).toBe(true);
61 |       expect(parser.isIgnored('src/index.js')).toBe(false);
62 |     });
63 | 
64 |     it('should handle git exclude file', async () => {
65 |       await createTestFile(
66 |         path.join('.git', 'info', 'exclude'),
67 |         'temp/\n*.tmp',
68 |       );
69 | 
70 |       expect(parser.isIgnored(path.join('temp', 'file.txt'))).toBe(true);
71 |       expect(parser.isIgnored(path.join('src', 'file.tmp'))).toBe(true);
72 |       expect(parser.isIgnored('src/file.js')).toBe(false);
73 |     });
74 |   });
75 | 
76 |   describe('isIgnored path handling', () => {
77 |     beforeEach(async () => {
78 |       await setupGitRepo();
79 |       const gitignoreContent = `
80 | node_modules/
81 | *.log
82 | /dist
83 | /.env
84 | src/*.tmp
85 | !src/important.tmp
86 | `;
87 |       await createTestFile('.gitignore', gitignoreContent);
88 |     });
89 | 
90 |     it('should always ignore .git directory', () => {
91 |       expect(parser.isIgnored('.git')).toBe(true);
92 |       expect(parser.isIgnored(path.join('.git', 'config'))).toBe(true);
93 |       expect(parser.isIgnored(path.join(projectRoot, '.git', 'HEAD'))).toBe(
94 |         true,
95 |       );
96 |     });
97 | 
98 |     it('should ignore files matching patterns', () => {
99 |       expect(
100 |         parser.isIgnored(path.join('node_modules', 'package', 'index.js')),
101 |       ).toBe(true);
102 |       expect(parser.isIgnored('app.log')).toBe(true);
103 |       expect(parser.isIgnored(path.join('logs', 'app.log'))).toBe(true);
104 |       expect(parser.isIgnored(path.join('dist', 'bundle.js'))).toBe(true);
105 |       expect(parser.isIgnored('.env')).toBe(true);
106 |       expect(parser.isIgnored(path.join('config', '.env'))).toBe(false); // .env is anchored to root
107 |     });
108 | 
109 |     it('should ignore files with path-specific patterns', () => {
110 |       expect(parser.isIgnored(path.join('src', 'temp.tmp'))).toBe(true);
111 |       expect(parser.isIgnored(path.join('other', 'temp.tmp'))).toBe(false);
112 |     });
113 | 
114 |     it('should handle negation patterns', () => {
115 |       expect(parser.isIgnored(path.join('src', 'important.tmp'))).toBe(false);
116 |     });
117 | 
118 |     it('should not ignore files that do not match patterns', () => {
119 |       expect(parser.isIgnored(path.join('src', 'index.ts'))).toBe(false);
120 |       expect(parser.isIgnored('README.md')).toBe(false);
121 |     });
122 | 
123 |     it('should handle absolute paths correctly', () => {
124 |       const absolutePath = path.join(projectRoot, 'node_modules', 'lib');
125 |       expect(parser.isIgnored(absolutePath)).toBe(true);
126 |     });
127 | 
128 |     it('should handle paths outside project root by not ignoring them', () => {
129 |       const outsidePath = path.resolve(projectRoot, '..', 'other', 'file.txt');
130 |       expect(parser.isIgnored(outsidePath)).toBe(false);
131 |     });
132 | 
133 |     it('should handle relative paths correctly', () => {
134 |       expect(parser.isIgnored(path.join('node_modules', 'some-package'))).toBe(
135 |         true,
136 |       );
137 |       expect(
138 |         parser.isIgnored(path.join('..', 'some', 'other', 'file.txt')),
139 |       ).toBe(false);
140 |     });
141 | 
142 |     it('should normalize path separators on Windows', () => {
143 |       expect(parser.isIgnored(path.join('node_modules', 'package'))).toBe(true);
144 |       expect(parser.isIgnored(path.join('src', 'temp.tmp'))).toBe(true);
145 |     });
146 | 
147 |     it('should handle root path "/" without throwing error', () => {
148 |       expect(() => parser.isIgnored('/')).not.toThrow();
149 |       expect(parser.isIgnored('/')).toBe(false);
150 |     });
151 | 
152 |     it('should handle absolute-like paths without throwing error', () => {
153 |       expect(() => parser.isIgnored('/some/path')).not.toThrow();
154 |       expect(parser.isIgnored('/some/path')).toBe(false);
155 |     });
156 | 
157 |     it('should handle paths that start with forward slash', () => {
158 |       expect(() => parser.isIgnored('/node_modules')).not.toThrow();
159 |       expect(parser.isIgnored('/node_modules')).toBe(false);
160 |     });
161 | 
162 |     it('should handle backslash-prefixed files without crashing', () => {
163 |       expect(() => parser.isIgnored('\\backslash-file-test.txt')).not.toThrow();
164 |       expect(parser.isIgnored('\\backslash-file-test.txt')).toBe(false);
165 |     });
166 | 
167 |     it('should handle files with absolute-like names', () => {
168 |       expect(() => parser.isIgnored('/backslash-file-test.txt')).not.toThrow();
169 |       expect(parser.isIgnored('/backslash-file-test.txt')).toBe(false);
170 |     });
171 |   });
172 | 
173 |   describe('nested .gitignore files', () => {
174 |     beforeEach(async () => {
175 |       await setupGitRepo();
176 |       // Root .gitignore
177 |       await createTestFile('.gitignore', 'root-ignored.txt');
178 |       // Nested .gitignore 1
179 |       await createTestFile('a/.gitignore', '/b\nc');
180 |       // Nested .gitignore 2
181 |       await createTestFile('a/d/.gitignore', 'e.txt\nf/g');
182 |     });
183 | 
184 |     it('should handle nested .gitignore files correctly', async () => {
185 |       // From root .gitignore
186 |       expect(parser.isIgnored('root-ignored.txt')).toBe(true);
187 |       expect(parser.isIgnored('a/root-ignored.txt')).toBe(true);
188 | 
189 |       // From a/.gitignore: /b
190 |       expect(parser.isIgnored('a/b')).toBe(true);
191 |       expect(parser.isIgnored('b')).toBe(false);
192 |       expect(parser.isIgnored('a/x/b')).toBe(false);
193 | 
194 |       // From a/.gitignore: c
195 |       expect(parser.isIgnored('a/c')).toBe(true);
196 |       expect(parser.isIgnored('a/x/y/c')).toBe(true);
197 |       expect(parser.isIgnored('c')).toBe(false);
198 | 
199 |       // From a/d/.gitignore: e.txt
200 |       expect(parser.isIgnored('a/d/e.txt')).toBe(true);
201 |       expect(parser.isIgnored('a/d/x/e.txt')).toBe(true);
202 |       expect(parser.isIgnored('a/e.txt')).toBe(false);
203 | 
204 |       // From a/d/.gitignore: f/g
205 |       expect(parser.isIgnored('a/d/f/g')).toBe(true);
206 |       expect(parser.isIgnored('a/f/g')).toBe(false);
207 |     });
208 |   });
209 | 
210 |   describe('precedence rules', () => {
211 |     beforeEach(async () => {
212 |       await setupGitRepo();
213 |     });
214 | 
215 |     it('should prioritize nested .gitignore over root .gitignore', async () => {
216 |       await createTestFile('.gitignore', '*.log');
217 |       await createTestFile('a/b/.gitignore', '!special.log');
218 | 
219 |       expect(parser.isIgnored('a/b/any.log')).toBe(true);
220 |       expect(parser.isIgnored('a/b/special.log')).toBe(false);
221 |     });
222 | 
223 |     it('should prioritize .gitignore over .git/info/exclude', async () => {
224 |       // Exclude all .log files
225 |       await createTestFile(path.join('.git', 'info', 'exclude'), '*.log');
226 |       // But make an exception in the root .gitignore
227 |       await createTestFile('.gitignore', '!important.log');
228 | 
229 |       expect(parser.isIgnored('some.log')).toBe(true);
230 |       expect(parser.isIgnored('important.log')).toBe(false);
231 |       expect(parser.isIgnored(path.join('subdir', 'some.log'))).toBe(true);
232 |       expect(parser.isIgnored(path.join('subdir', 'important.log'))).toBe(
233 |         false,
234 |       );
235 |     });
236 |   });
237 | });
```

src/utils/gitIgnoreParser.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs';
8 | import * as path from 'node:path';
9 | import ignore from 'ignore';
10 | 
11 | export interface GitIgnoreFilter {
12 |   isIgnored(filePath: string): boolean;
13 | }
14 | 
15 | export class GitIgnoreParser implements GitIgnoreFilter {
16 |   private projectRoot: string;
17 |   private cache: Map<string, string[]> = new Map();
18 |   private globalPatterns: string[] | undefined;
19 | 
20 |   constructor(projectRoot: string) {
21 |     this.projectRoot = path.resolve(projectRoot);
22 |   }
23 | 
24 |   private loadPatternsForFile(patternsFilePath: string): string[] {
25 |     let content: string;
26 |     try {
27 |       content = fs.readFileSync(patternsFilePath, 'utf-8');
28 |     } catch (_error) {
29 |       return [];
30 |     }
31 | 
32 |     const isExcludeFile = patternsFilePath.endsWith(
33 |       path.join('.git', 'info', 'exclude'),
34 |     );
35 | 
36 |     const relativeBaseDir = isExcludeFile
37 |       ? '.'
38 |       : path.dirname(path.relative(this.projectRoot, patternsFilePath));
39 | 
40 |     return content
41 |       .split('\n')
42 |       .map((p) => p.trim())
43 |       .filter((p) => p !== '' && !p.startsWith('#'))
44 |       .map((p) => {
45 |         const isNegative = p.startsWith('!');
46 |         if (isNegative) {
47 |           p = p.substring(1);
48 |         }
49 | 
50 |         const isAnchoredInFile = p.startsWith('/');
51 |         if (isAnchoredInFile) {
52 |           p = p.substring(1);
53 |         }
54 | 
55 |         // An empty pattern can result from a negated pattern like `!`,
56 |         // which we can ignore.
57 |         if (p === '') {
58 |           return '';
59 |         }
60 | 
61 |         let newPattern = p;
62 |         if (relativeBaseDir && relativeBaseDir !== '.') {
63 |           // Only in nested .gitignore files, the patterns need to be modified according to:
64 |           // - If `a/b/.gitignore` defines `/c` then it needs to be changed to `/a/b/c`
65 |           // - If `a/b/.gitignore` defines `c` then it needs to be changed to `/a/b/**/c`
66 |           // - If `a/b/.gitignore` defines `c/d` then it needs to be changed to `/a/b/c/d`
67 | 
68 |           if (!isAnchoredInFile && !p.includes('/')) {
69 |             // If no slash and not anchored in file, it matches files in any
70 |             // subdirectory.
71 |             newPattern = path.join('**', p);
72 |           }
73 | 
74 |           // Prepend the .gitignore file's directory.
75 |           newPattern = path.join(relativeBaseDir, newPattern);
76 | 
77 |           // Anchor the pattern to a nested gitignore directory.
78 |           if (!newPattern.startsWith('/')) {
79 |             newPattern = '/' + newPattern;
80 |           }
81 |         }
82 | 
83 |         // Anchor the pattern if originally anchored
84 |         if (isAnchoredInFile && !newPattern.startsWith('/')) {
85 |           newPattern = '/' + newPattern;
86 |         }
87 | 
88 |         if (isNegative) {
89 |           newPattern = '!' + newPattern;
90 |         }
91 | 
92 |         // Even in windows, Ignore expects forward slashes.
93 |         newPattern = newPattern.replace(/\\/g, '/');
94 | 
95 |         return newPattern;
96 |       })
97 |       .filter((p) => p !== '');
98 |   }
99 | 
100 |   isIgnored(filePath: string): boolean {
101 |     if (!filePath || typeof filePath !== 'string') {
102 |       return false;
103 |     }
104 | 
105 |     const absoluteFilePath = path.resolve(this.projectRoot, filePath);
106 |     if (!absoluteFilePath.startsWith(this.projectRoot)) {
107 |       return false;
108 |     }
109 | 
110 |     try {
111 |       const resolved = path.resolve(this.projectRoot, filePath);
112 |       const relativePath = path.relative(this.projectRoot, resolved);
113 | 
114 |       if (relativePath === '' || relativePath.startsWith('..')) {
115 |         return false;
116 |       }
117 | 
118 |       // Even in windows, Ignore expects forward slashes.
119 |       const normalizedPath = relativePath.replace(/\\/g, '/');
120 | 
121 |       if (normalizedPath.startsWith('/') || normalizedPath === '') {
122 |         return false;
123 |       }
124 | 
125 |       const ig = ignore();
126 | 
127 |       // Always ignore .git directory
128 |       ig.add('.git');
129 | 
130 |       // Load global patterns from .git/info/exclude on first call
131 |       if (this.globalPatterns === undefined) {
132 |         const excludeFile = path.join(
133 |           this.projectRoot,
134 |           '.git',
135 |           'info',
136 |           'exclude',
137 |         );
138 |         this.globalPatterns = fs.existsSync(excludeFile)
139 |           ? this.loadPatternsForFile(excludeFile)
140 |           : [];
141 |       }
142 |       ig.add(this.globalPatterns);
143 | 
144 |       const pathParts = relativePath.split(path.sep);
145 | 
146 |       const dirsToVisit = [this.projectRoot];
147 |       let currentAbsDir = this.projectRoot;
148 |       // Collect all directories in the path
149 |       for (let i = 0; i < pathParts.length - 1; i++) {
150 |         currentAbsDir = path.join(currentAbsDir, pathParts[i]);
151 |         dirsToVisit.push(currentAbsDir);
152 |       }
153 | 
154 |       for (const dir of dirsToVisit) {
155 |         const relativeDir = path.relative(this.projectRoot, dir);
156 |         if (relativeDir) {
157 |           const normalizedRelativeDir = relativeDir.replace(/\\/g, '/');
158 |           if (ig.ignores(normalizedRelativeDir)) {
159 |             // This directory is ignored by an ancestor's .gitignore.
160 |             // According to git behavior, we don't need to process this
161 |             // directory's .gitignore, as nothing inside it can be
162 |             // un-ignored.
163 |             break;
164 |           }
165 |         }
166 | 
167 |         if (this.cache.has(dir)) {
168 |           const patterns = this.cache.get(dir);
169 |           if (patterns) {
170 |             ig.add(patterns);
171 |           }
172 |         } else {
173 |           const gitignorePath = path.join(dir, '.gitignore');
174 |           if (fs.existsSync(gitignorePath)) {
175 |             const patterns = this.loadPatternsForFile(gitignorePath);
176 |             this.cache.set(dir, patterns);
177 |             ig.add(patterns);
178 |           } else {
179 |             this.cache.set(dir, []); // Cache miss
180 |           }
181 |         }
182 |       }
183 | 
184 |       return ig.ignores(normalizedPath);
185 |     } catch (_error) {
186 |       return false;
187 |     }
188 |   }
189 | }
```

src/utils/gitUtils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs';
8 | import * as path from 'node:path';
9 | 
10 | /**
11 |  * Checks if a directory is within a git repository
12 |  * @param directory The directory to check
13 |  * @returns true if the directory is in a git repository, false otherwise
14 |  */
15 | export function isGitRepository(directory: string): boolean {
16 |   try {
17 |     let currentDir = path.resolve(directory);
18 | 
19 |     while (true) {
20 |       const gitDir = path.join(currentDir, '.git');
21 | 
22 |       // Check if .git exists (either as directory or file for worktrees)
23 |       if (fs.existsSync(gitDir)) {
24 |         return true;
25 |       }
26 | 
27 |       const parentDir = path.dirname(currentDir);
28 | 
29 |       // If we've reached the root directory, stop searching
30 |       if (parentDir === currentDir) {
31 |         break;
32 |       }
33 | 
34 |       currentDir = parentDir;
35 |     }
36 | 
37 |     return false;
38 |   } catch (_error) {
39 |     // If any filesystem error occurs, assume not a git repo
40 |     return false;
41 |   }
42 | }
43 | 
44 | /**
45 |  * Finds the root directory of a git repository
46 |  * @param directory Starting directory to search from
47 |  * @returns The git repository root path, or null if not in a git repository
48 |  */
49 | export function findGitRoot(directory: string): string | null {
50 |   try {
51 |     let currentDir = path.resolve(directory);
52 | 
53 |     while (true) {
54 |       const gitDir = path.join(currentDir, '.git');
55 | 
56 |       if (fs.existsSync(gitDir)) {
57 |         return currentDir;
58 |       }
59 | 
60 |       const parentDir = path.dirname(currentDir);
61 | 
62 |       if (parentDir === currentDir) {
63 |         break;
64 |       }
65 | 
66 |       currentDir = parentDir;
67 |     }
68 | 
69 |     return null;
70 |   } catch (_error) {
71 |     return null;
72 |   }
73 | }
```

src/utils/googleErrors.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { parseGoogleApiError } from './googleErrors.js';
9 | import type { QuotaFailure } from './googleErrors.js';
10 | 
11 | describe('parseGoogleApiError', () => {
12 |   it('should return null for non-gaxios errors', () => {
13 |     expect(parseGoogleApiError(new Error('vanilla error'))).toBeNull();
14 |     expect(parseGoogleApiError(null)).toBeNull();
15 |     expect(parseGoogleApiError({})).toBeNull();
16 |   });
17 | 
18 |   it('should parse a standard gaxios error', () => {
19 |     const mockError = {
20 |       response: {
21 |         status: 429,
22 |         data: {
23 |           error: {
24 |             code: 429,
25 |             message: 'Quota exceeded',
26 |             details: [
27 |               {
28 |                 '@type': 'type.googleapis.com/google.rpc.QuotaFailure',
29 |                 violations: [{ subject: 'user', description: 'daily limit' }],
30 |               },
31 |             ],
32 |           },
33 |         },
34 |       },
35 |     };
36 | 
37 |     const parsed = parseGoogleApiError(mockError);
38 |     expect(parsed).not.toBeNull();
39 |     expect(parsed?.code).toBe(429);
40 |     expect(parsed?.message).toBe('Quota exceeded');
41 |     expect(parsed?.details).toHaveLength(1);
42 |     const detail = parsed?.details[0] as QuotaFailure;
43 |     expect(detail['@type']).toBe('type.googleapis.com/google.rpc.QuotaFailure');
44 |     expect(detail.violations[0].description).toBe('daily limit');
45 |   });
46 | 
47 |   it('should parse an error with details stringified in the message', () => {
48 |     const innerError = {
49 |       error: {
50 |         code: 429,
51 |         message: 'Inner quota message',
52 |         details: [
53 |           {
54 |             '@type': 'type.googleapis.com/google.rpc.RetryInfo',
55 |             retryDelay: '10s',
56 |           },
57 |         ],
58 |       },
59 |     };
60 | 
61 |     const mockError = {
62 |       response: {
63 |         status: 429,
64 |         data: {
65 |           error: {
66 |             code: 429,
67 |             message: JSON.stringify(innerError),
68 |             details: [], // Top-level details are empty
69 |           },
70 |         },
71 |       },
72 |     };
73 | 
74 |     const parsed = parseGoogleApiError(mockError);
75 |     expect(parsed).not.toBeNull();
76 |     expect(parsed?.code).toBe(429);
77 |     expect(parsed?.message).toBe('Inner quota message');
78 |     expect(parsed?.details).toHaveLength(1);
79 |     expect(parsed?.details[0]['@type']).toBe(
80 |       'type.googleapis.com/google.rpc.RetryInfo',
81 |     );
82 |   });
83 | 
84 |   it('should return null if details are not in the expected format', () => {
85 |     const mockError = {
86 |       response: {
87 |         status: 400,
88 |         data: {
89 |           error: {
90 |             code: 400,
91 |             message: 'Bad Request',
92 |             details: 'just a string', // Invalid details format
93 |           },
94 |         },
95 |       },
96 |     };
97 |     expect(parseGoogleApiError(mockError)).toBeNull();
98 |   });
99 | 
100 |   it('should return null if there are no valid details', () => {
101 |     const mockError = {
102 |       response: {
103 |         status: 400,
104 |         data: {
105 |           error: {
106 |             code: 400,
107 |             message: 'Bad Request',
108 |             details: [
109 |               {
110 |                 // missing '@type'
111 |                 reason: 'some reason',
112 |               },
113 |             ],
114 |           },
115 |         },
116 |       },
117 |     };
118 |     expect(parseGoogleApiError(mockError)).toBeNull();
119 |   });
120 | 
121 |   it('should parse a doubly nested error in the message', () => {
122 |     const innerError = {
123 |       error: {
124 |         code: 429,
125 |         message: 'Innermost quota message',
126 |         details: [
127 |           {
128 |             '@type': 'type.googleapis.com/google.rpc.RetryInfo',
129 |             retryDelay: '20s',
130 |           },
131 |         ],
132 |       },
133 |     };
134 | 
135 |     const middleError = {
136 |       error: {
137 |         code: 429,
138 |         message: JSON.stringify(innerError),
139 |         details: [],
140 |       },
141 |     };
142 | 
143 |     const mockError = {
144 |       response: {
145 |         status: 429,
146 |         data: {
147 |           error: {
148 |             code: 429,
149 |             message: JSON.stringify(middleError),
150 |             details: [],
151 |           },
152 |         },
153 |       },
154 |     };
155 | 
156 |     const parsed = parseGoogleApiError(mockError);
157 |     expect(parsed).not.toBeNull();
158 |     expect(parsed?.code).toBe(429);
159 |     expect(parsed?.message).toBe('Innermost quota message');
160 |     expect(parsed?.details).toHaveLength(1);
161 |     expect(parsed?.details[0]['@type']).toBe(
162 |       'type.googleapis.com/google.rpc.RetryInfo',
163 |     );
164 |   });
165 | 
166 |   it('should parse an error that is not in a response object', () => {
167 |     const innerError = {
168 |       error: {
169 |         code: 429,
170 |         message: 'Innermost quota message',
171 |         details: [
172 |           {
173 |             '@type': 'type.googleapis.com/google.rpc.RetryInfo',
174 |             retryDelay: '20s',
175 |           },
176 |         ],
177 |       },
178 |     };
179 | 
180 |     const mockError = {
181 |       error: {
182 |         code: 429,
183 |         message: JSON.stringify(innerError),
184 |         details: [],
185 |       },
186 |     };
187 | 
188 |     const parsed = parseGoogleApiError(mockError);
189 |     expect(parsed).not.toBeNull();
190 |     expect(parsed?.code).toBe(429);
191 |     expect(parsed?.message).toBe('Innermost quota message');
192 |     expect(parsed?.details).toHaveLength(1);
193 |     expect(parsed?.details[0]['@type']).toBe(
194 |       'type.googleapis.com/google.rpc.RetryInfo',
195 |     );
196 |   });
197 | 
198 |   it('should parse an error that is a JSON string', () => {
199 |     const innerError = {
200 |       error: {
201 |         code: 429,
202 |         message: 'Innermost quota message',
203 |         details: [
204 |           {
205 |             '@type': 'type.googleapis.com/google.rpc.RetryInfo',
206 |             retryDelay: '20s',
207 |           },
208 |         ],
209 |       },
210 |     };
211 | 
212 |     const mockError = {
213 |       error: {
214 |         code: 429,
215 |         message: JSON.stringify(innerError),
216 |         details: [],
217 |       },
218 |     };
219 | 
220 |     const parsed = parseGoogleApiError(JSON.stringify(mockError));
221 |     expect(parsed).not.toBeNull();
222 |     expect(parsed?.code).toBe(429);
223 |     expect(parsed?.message).toBe('Innermost quota message');
224 |     expect(parsed?.details).toHaveLength(1);
225 |     expect(parsed?.details[0]['@type']).toBe(
226 |       'type.googleapis.com/google.rpc.RetryInfo',
227 |     );
228 |   });
229 | 
230 |   it('should parse the user-provided nested error string', () => {
231 |     const userErrorString =
232 |       '{"error":{"message":"{\\n  \\"error\\": {\\n    \\"code\\": 429,\\n    \\"message\\": \\"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\\\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_paid_tier_input_token_count, limit: 10000\\\\nPlease retry in 40.025771073s.\\",\\n    \\"status\\": \\"RESOURCE_EXHAUSTED\\",\\n    \\"details\\": [\\n      {\\n        \\"@type\\": \\"type.googleapis.com/google.rpc.DebugInfo\\",\\n        \\"detail\\": \\"[ORIGINAL ERROR] generic::resource_exhausted: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\\\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_paid_tier_input_token_count, limit: 10000\\\\nPlease retry in 40.025771073s. [google.rpc.error_details_ext] { message: \\\\\\"You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\\\\\\\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_paid_tier_input_token_count, limit: 10000\\\\\\\\nPlease retry in 40.025771073s.\\\\\\" }\\"\\n      },\\n      {\\n        \\"@type\\": \\"type.googleapis.com/google.rpc.QuotaFailure\\",\\n        \\"violations\\": [\\n          {\\n            \\"quotaMetric\\": \\"generativelanguage.googleapis.com/generate_content_paid_tier_input_token_count\\",\\n            \\"quotaId\\": \\"GenerateContentPaidTierInputTokensPerModelPerMinute\\",\\n            \\"quotaDimensions\\": {\\n              \\"location\\": \\"global\\",\\n              \\"model\\": \\"gemini-2.5-pro\\"\\n            },\\n            \\"quotaValue\\": \\"10000\\"\\n          }\\n        ]\\n      },\\n      {\\n        \\"@type\\": \\"type.googleapis.com/google.rpc.Help\\",\\n        \\"links\\": [\\n          {\\n            \\"description\\": \\"Learn more about Gemini API quotas\\",\\n            \\"url\\": \\"https://ai.google.dev/gemini-api/docs/rate-limits\\"\\n          }\\n        ]\\n      },\\n      {\\n        \\"@type\\": \\"type.googleapis.com/google.rpc.RetryInfo\\",\\n        \\"retryDelay\\": \\"40s\\"\\n      }\\n    ]\\n  }\\n}\\n","code":429,"status":"Too Many Requests"}}';
233 | 
234 |     const parsed = parseGoogleApiError(userErrorString);
235 |     expect(parsed).not.toBeNull();
236 |     expect(parsed?.code).toBe(429);
237 |     expect(parsed?.message).toContain('You exceeded your current quota');
238 |     expect(parsed?.details).toHaveLength(4);
239 |     expect(
240 |       parsed?.details.some(
241 |         (d) => d['@type'] === 'type.googleapis.com/google.rpc.QuotaFailure',
242 |       ),
243 |     ).toBe(true);
244 |     expect(
245 |       parsed?.details.some(
246 |         (d) => d['@type'] === 'type.googleapis.com/google.rpc.RetryInfo',
247 |       ),
248 |     ).toBe(true);
249 |   });
250 | });
```

src/utils/googleErrors.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * @fileoverview
9 |  * This file contains types and functions for parsing structured Google API errors.
10 |  */
11 | 
12 | /**
13 |  * Based on google/rpc/error_details.proto
14 |  */
15 | 
16 | export interface ErrorInfo {
17 |   '@type': 'type.googleapis.com/google.rpc.ErrorInfo';
18 |   reason: string;
19 |   domain: string;
20 |   metadata: { [key: string]: string };
21 | }
22 | 
23 | export interface RetryInfo {
24 |   '@type': 'type.googleapis.com/google.rpc.RetryInfo';
25 |   retryDelay: string; // e.g. "51820.638305887s"
26 | }
27 | 
28 | export interface DebugInfo {
29 |   '@type': 'type.googleapis.com/google.rpc.DebugInfo';
30 |   stackEntries: string[];
31 |   detail: string;
32 | }
33 | 
34 | export interface QuotaFailure {
35 |   '@type': 'type.googleapis.com/google.rpc.QuotaFailure';
36 |   violations: Array<{
37 |     subject: string;
38 |     description: string;
39 |     apiService?: string;
40 |     quotaMetric?: string;
41 |     quotaId?: string;
42 |     quotaDimensions?: { [key: string]: string };
43 |     quotaValue?: number;
44 |     futureQuotaValue?: number;
45 |   }>;
46 | }
47 | 
48 | export interface PreconditionFailure {
49 |   '@type': 'type.googleapis.com/google.rpc.PreconditionFailure';
50 |   violations: Array<{
51 |     type: string;
52 |     subject: string;
53 |     description: string;
54 |   }>;
55 | }
56 | 
57 | export interface LocalizedMessage {
58 |   '@type': 'type.googleapis.com/google.rpc.LocalizedMessage';
59 |   locale: string;
60 |   message: string;
61 | }
62 | 
63 | export interface BadRequest {
64 |   '@type': 'type.googleapis.com/google.rpc.BadRequest';
65 |   fieldViolations: Array<{
66 |     field: string;
67 |     description: string;
68 |     reason?: string;
69 |     localizedMessage?: LocalizedMessage;
70 |   }>;
71 | }
72 | 
73 | export interface RequestInfo {
74 |   '@type': 'type.googleapis.com/google.rpc.RequestInfo';
75 |   requestId: string;
76 |   servingData: string;
77 | }
78 | 
79 | export interface ResourceInfo {
80 |   '@type': 'type.googleapis.com/google.rpc.ResourceInfo';
81 |   resourceType: string;
82 |   resourceName: string;
83 |   owner: string;
84 |   description: string;
85 | }
86 | 
87 | export interface Help {
88 |   '@type': 'type.googleapis.com/google.rpc.Help';
89 |   links: Array<{
90 |     description: string;
91 |     url: string;
92 |   }>;
93 | }
94 | 
95 | export type GoogleApiErrorDetail =
96 |   | ErrorInfo
97 |   | RetryInfo
98 |   | DebugInfo
99 |   | QuotaFailure
100 |   | PreconditionFailure
101 |   | BadRequest
102 |   | RequestInfo
103 |   | ResourceInfo
104 |   | Help
105 |   | LocalizedMessage;
106 | 
107 | export interface GoogleApiError {
108 |   code: number;
109 |   message: string;
110 |   details: GoogleApiErrorDetail[];
111 | }
112 | 
113 | /**
114 |  * Parses an error object to check if it's a structured Google API error
115 |  * and extracts all details.
116 |  *
117 |  * This function can handle two formats:
118 |  * 1. Standard Google API errors where `details` is a top-level field.
119 |  * 2. Errors where the entire structured error object is stringified inside
120 |  *    the `message` field of a wrapper error.
121 |  *
122 |  * @param error The error object to inspect.
123 |  * @returns A GoogleApiError object if the error matches, otherwise null.
124 |  */
125 | export function parseGoogleApiError(error: unknown): GoogleApiError | null {
126 |   if (!error) {
127 |     return null;
128 |   }
129 | 
130 |   let errorObj: unknown = error;
131 | 
132 |   // If error is a string, try to parse it.
133 |   if (typeof errorObj === 'string') {
134 |     try {
135 |       errorObj = JSON.parse(errorObj);
136 |     } catch (_) {
137 |       // Not a JSON string, can't parse.
138 |       return null;
139 |     }
140 |   }
141 | 
142 |   if (typeof errorObj !== 'object' || errorObj === null) {
143 |     return null;
144 |   }
145 | 
146 |   type ErrorShape = {
147 |     message?: string;
148 |     details?: unknown[];
149 |     code?: number;
150 |   };
151 | 
152 |   const gaxiosError = errorObj as {
153 |     response?: {
154 |       status?: number;
155 |       data?:
156 |         | {
157 |             error?: ErrorShape;
158 |           }
159 |         | string;
160 |     };
161 |     error?: ErrorShape;
162 |     code?: number;
163 |   };
164 | 
165 |   let outerError: ErrorShape | undefined;
166 |   if (gaxiosError.response?.data) {
167 |     if (typeof gaxiosError.response.data === 'string') {
168 |       try {
169 |         const parsedData = JSON.parse(gaxiosError.response.data);
170 |         if (parsedData.error) {
171 |           outerError = parsedData.error;
172 |         }
173 |       } catch (_) {
174 |         // Not a JSON string, or doesn't contain .error
175 |       }
176 |     } else if (
177 |       typeof gaxiosError.response.data === 'object' &&
178 |       gaxiosError.response.data !== null
179 |     ) {
180 |       outerError = (
181 |         gaxiosError.response.data as {
182 |           error?: ErrorShape;
183 |         }
184 |       ).error;
185 |     }
186 |   }
187 |   const responseStatus = gaxiosError.response?.status;
188 | 
189 |   if (!outerError) {
190 |     // If the gaxios structure isn't there, check for a top-level `error` property.
191 |     if (gaxiosError.error) {
192 |       outerError = gaxiosError.error;
193 |     } else {
194 |       return null;
195 |     }
196 |   }
197 | 
198 |   let currentError = outerError;
199 |   let depth = 0;
200 |   const maxDepth = 10;
201 |   // Handle cases where the actual error object is stringified inside the message
202 |   // by drilling down until we find an error that doesn't have a stringified message.
203 |   while (typeof currentError.message === 'string' && depth < maxDepth) {
204 |     try {
205 |       const parsedMessage = JSON.parse(currentError.message);
206 |       if (parsedMessage.error) {
207 |         currentError = parsedMessage.error;
208 |         depth++;
209 |       } else {
210 |         // The message is a JSON string, but not a nested error object.
211 |         break;
212 |       }
213 |     } catch (_) {
214 |       // It wasn't a JSON string, so we've drilled down as far as we can.
215 |       break;
216 |     }
217 |   }
218 | 
219 |   const code = responseStatus ?? currentError.code ?? gaxiosError.code;
220 |   const message = currentError.message;
221 |   const errorDetails = currentError.details;
222 | 
223 |   if (Array.isArray(errorDetails) && code && message) {
224 |     const details: GoogleApiErrorDetail[] = [];
225 |     for (const detail of errorDetails) {
226 |       if (detail && typeof detail === 'object' && '@type' in detail) {
227 |         // We can just cast it; the consumer will have to switch on @type
228 |         details.push(detail as GoogleApiErrorDetail);
229 |       }
230 |     }
231 | 
232 |     if (details.length > 0) {
233 |       return {
234 |         code,
235 |         message,
236 |         details,
237 |       };
238 |     }
239 |   }
240 | 
241 |   return null;
242 | }
```

src/utils/googleQuotaErrors.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, afterEach } from 'vitest';
8 | import {
9 |   classifyGoogleError,
10 |   RetryableQuotaError,
11 |   TerminalQuotaError,
12 | } from './googleQuotaErrors.js';
13 | import * as errorParser from './googleErrors.js';
14 | import type { GoogleApiError } from './googleErrors.js';
15 | 
16 | describe('classifyGoogleError', () => {
17 |   afterEach(() => {
18 |     vi.restoreAllMocks();
19 |   });
20 | 
21 |   it('should return original error if not a Google API error', () => {
22 |     const regularError = new Error('Something went wrong');
23 |     vi.spyOn(errorParser, 'parseGoogleApiError').mockReturnValue(null);
24 |     const result = classifyGoogleError(regularError);
25 |     expect(result).toBe(regularError);
26 |   });
27 | 
28 |   it('should return original error if code is not 429', () => {
29 |     const apiError: GoogleApiError = {
30 |       code: 500,
31 |       message: 'Server error',
32 |       details: [],
33 |     };
34 |     vi.spyOn(errorParser, 'parseGoogleApiError').mockReturnValue(apiError);
35 |     const originalError = new Error();
36 |     const result = classifyGoogleError(originalError);
37 |     expect(result).toBe(originalError);
38 |     expect(result).not.toBeInstanceOf(TerminalQuotaError);
39 |     expect(result).not.toBeInstanceOf(RetryableQuotaError);
40 |   });
41 | 
42 |   it('should return TerminalQuotaError for daily quota violations in QuotaFailure', () => {
43 |     const apiError: GoogleApiError = {
44 |       code: 429,
45 |       message: 'Quota exceeded',
46 |       details: [
47 |         {
48 |           '@type': 'type.googleapis.com/google.rpc.QuotaFailure',
49 |           violations: [
50 |             {
51 |               subject: 'user',
52 |               description: 'daily limit',
53 |               quotaId: 'RequestsPerDay-limit',
54 |             },
55 |           ],
56 |         },
57 |       ],
58 |     };
59 |     vi.spyOn(errorParser, 'parseGoogleApiError').mockReturnValue(apiError);
60 |     const result = classifyGoogleError(new Error());
61 |     expect(result).toBeInstanceOf(TerminalQuotaError);
62 |     expect((result as TerminalQuotaError).cause).toBe(apiError);
63 |   });
64 | 
65 |   it('should return TerminalQuotaError for daily quota violations in ErrorInfo', () => {
66 |     const apiError: GoogleApiError = {
67 |       code: 429,
68 |       message: 'Quota exceeded',
69 |       details: [
70 |         {
71 |           '@type': 'type.googleapis.com/google.rpc.ErrorInfo',
72 |           reason: 'QUOTA_EXCEEDED',
73 |           domain: 'googleapis.com',
74 |           metadata: {
75 |             quota_limit: 'RequestsPerDay_PerProject_PerUser',
76 |           },
77 |         },
78 |       ],
79 |     };
80 |     vi.spyOn(errorParser, 'parseGoogleApiError').mockReturnValue(apiError);
81 |     const result = classifyGoogleError(new Error());
82 |     expect(result).toBeInstanceOf(TerminalQuotaError);
83 |   });
84 | 
85 |   it('should return TerminalQuotaError for long retry delays', () => {
86 |     const apiError: GoogleApiError = {
87 |       code: 429,
88 |       message: 'Too many requests',
89 |       details: [
90 |         {
91 |           '@type': 'type.googleapis.com/google.rpc.RetryInfo',
92 |           retryDelay: '301s', // > 5 minutes
93 |         },
94 |       ],
95 |     };
96 |     vi.spyOn(errorParser, 'parseGoogleApiError').mockReturnValue(apiError);
97 |     const result = classifyGoogleError(new Error());
98 |     expect(result).toBeInstanceOf(TerminalQuotaError);
99 |   });
100 | 
101 |   it('should return RetryableQuotaError for short retry delays', () => {
102 |     const apiError: GoogleApiError = {
103 |       code: 429,
104 |       message: 'Too many requests',
105 |       details: [
106 |         {
107 |           '@type': 'type.googleapis.com/google.rpc.RetryInfo',
108 |           retryDelay: '45.123s',
109 |         },
110 |       ],
111 |     };
112 |     vi.spyOn(errorParser, 'parseGoogleApiError').mockReturnValue(apiError);
113 |     const result = classifyGoogleError(new Error());
114 |     expect(result).toBeInstanceOf(RetryableQuotaError);
115 |     expect((result as RetryableQuotaError).retryDelayMs).toBe(45123);
116 |   });
117 | 
118 |   it('should return RetryableQuotaError for per-minute quota violations in QuotaFailure', () => {
119 |     const apiError: GoogleApiError = {
120 |       code: 429,
121 |       message: 'Quota exceeded',
122 |       details: [
123 |         {
124 |           '@type': 'type.googleapis.com/google.rpc.QuotaFailure',
125 |           violations: [
126 |             {
127 |               subject: 'user',
128 |               description: 'per minute limit',
129 |               quotaId: 'RequestsPerMinute-limit',
130 |             },
131 |           ],
132 |         },
133 |       ],
134 |     };
135 |     vi.spyOn(errorParser, 'parseGoogleApiError').mockReturnValue(apiError);
136 |     const result = classifyGoogleError(new Error());
137 |     expect(result).toBeInstanceOf(RetryableQuotaError);
138 |     expect((result as RetryableQuotaError).retryDelayMs).toBe(60000);
139 |   });
140 | 
141 |   it('should return RetryableQuotaError for per-minute quota violations in ErrorInfo', () => {
142 |     const apiError: GoogleApiError = {
143 |       code: 429,
144 |       message: 'Quota exceeded',
145 |       details: [
146 |         {
147 |           '@type': 'type.googleapis.com/google.rpc.ErrorInfo',
148 |           reason: 'QUOTA_EXCEEDED',
149 |           domain: 'googleapis.com',
150 |           metadata: {
151 |             quota_limit: 'RequestsPerMinute_PerProject_PerUser',
152 |           },
153 |         },
154 |       ],
155 |     };
156 |     vi.spyOn(errorParser, 'parseGoogleApiError').mockReturnValue(apiError);
157 |     const result = classifyGoogleError(new Error());
158 |     expect(result).toBeInstanceOf(RetryableQuotaError);
159 |     expect((result as RetryableQuotaError).retryDelayMs).toBe(60000);
160 |   });
161 | 
162 |   it('should prioritize daily limit over retry info', () => {
163 |     const apiError: GoogleApiError = {
164 |       code: 429,
165 |       message: 'Quota exceeded',
166 |       details: [
167 |         {
168 |           '@type': 'type.googleapis.com/google.rpc.QuotaFailure',
169 |           violations: [
170 |             {
171 |               subject: 'user',
172 |               description: 'daily limit',
173 |               quotaId: 'RequestsPerDay-limit',
174 |             },
175 |           ],
176 |         },
177 |         {
178 |           '@type': 'type.googleapis.com/google.rpc.RetryInfo',
179 |           retryDelay: '10s',
180 |         },
181 |       ],
182 |     };
183 |     vi.spyOn(errorParser, 'parseGoogleApiError').mockReturnValue(apiError);
184 |     const result = classifyGoogleError(new Error());
185 |     expect(result).toBeInstanceOf(TerminalQuotaError);
186 |   });
187 | 
188 |   it('should return original error for 429 without specific details', () => {
189 |     const apiError: GoogleApiError = {
190 |       code: 429,
191 |       message: 'Too many requests',
192 |       details: [
193 |         {
194 |           '@type': 'type.googleapis.com/google.rpc.DebugInfo',
195 |           detail: 'some debug info',
196 |           stackEntries: [],
197 |         },
198 |       ],
199 |     };
200 |     vi.spyOn(errorParser, 'parseGoogleApiError').mockReturnValue(apiError);
201 |     const originalError = new Error();
202 |     const result = classifyGoogleError(originalError);
203 |     expect(result).toBe(originalError);
204 |   });
205 | });
```

src/utils/googleQuotaErrors.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   ErrorInfo,
9 |   GoogleApiError,
10 |   QuotaFailure,
11 |   RetryInfo,
12 | } from './googleErrors.js';
13 | import { parseGoogleApiError } from './googleErrors.js';
14 | 
15 | const FIVE_MINUTES_IN_SECONDS = 5 * 60;
16 | 
17 | /**
18 |  * A non-retryable error indicating a hard quota limit has been reached (e.g., daily limit).
19 |  */
20 | export class TerminalQuotaError extends Error {
21 |   constructor(
22 |     message: string,
23 |     override readonly cause: GoogleApiError,
24 |   ) {
25 |     super(message);
26 |     this.name = 'TerminalQuotaError';
27 |   }
28 | }
29 | 
30 | /**
31 |  * A retryable error indicating a temporary quota issue (e.g., per-minute limit).
32 |  */
33 | export class RetryableQuotaError extends Error {
34 |   retryDelayMs: number;
35 | 
36 |   constructor(
37 |     message: string,
38 |     override readonly cause: GoogleApiError,
39 |     retryDelaySeconds: number,
40 |   ) {
41 |     super(message);
42 |     this.name = 'RetryableQuotaError';
43 |     this.retryDelayMs = retryDelaySeconds * 1000;
44 |   }
45 | }
46 | 
47 | /**
48 |  * Parses a duration string (e.g., "34.074824224s", "60s") and returns the time in seconds.
49 |  * @param duration The duration string to parse.
50 |  * @returns The duration in seconds, or null if parsing fails.
51 |  */
52 | function parseDurationInSeconds(duration: string): number | null {
53 |   if (!duration.endsWith('s')) {
54 |     return null;
55 |   }
56 |   const seconds = parseFloat(duration.slice(0, -1));
57 |   return isNaN(seconds) ? null : seconds;
58 | }
59 | 
60 | /**
61 |  * Analyzes a caught error and classifies it as a specific quota-related error if applicable.
62 |  *
63 |  * It decides whether an error is a `TerminalQuotaError` or a `RetryableQuotaError` based on
64 |  * the following logic:
65 |  * - If the error indicates a daily limit, it's a `TerminalQuotaError`.
66 |  * - If the error suggests a retry delay of more than 5 minutes, it's a `TerminalQuotaError`.
67 |  * - If the error suggests a retry delay of 5 minutes or less, it's a `RetryableQuotaError`.
68 |  * - If the error indicates a per-minute limit, it's a `RetryableQuotaError`.
69 |  *
70 |  * @param error The error to classify.
71 |  * @returns A `TerminalQuotaError`, `RetryableQuotaError`, or the original `unknown` error.
72 |  */
73 | export function classifyGoogleError(error: unknown): unknown {
74 |   const googleApiError = parseGoogleApiError(error);
75 | 
76 |   if (!googleApiError || googleApiError.code !== 429) {
77 |     return error; // Not a 429 error we can handle.
78 |   }
79 | 
80 |   const quotaFailure = googleApiError.details.find(
81 |     (d): d is QuotaFailure =>
82 |       d['@type'] === 'type.googleapis.com/google.rpc.QuotaFailure',
83 |   );
84 | 
85 |   const errorInfo = googleApiError.details.find(
86 |     (d): d is ErrorInfo =>
87 |       d['@type'] === 'type.googleapis.com/google.rpc.ErrorInfo',
88 |   );
89 | 
90 |   const retryInfo = googleApiError.details.find(
91 |     (d): d is RetryInfo =>
92 |       d['@type'] === 'type.googleapis.com/google.rpc.RetryInfo',
93 |   );
94 | 
95 |   // 1. Check for long-term limits in QuotaFailure or ErrorInfo
96 |   if (quotaFailure) {
97 |     for (const violation of quotaFailure.violations) {
98 |       const quotaId = violation.quotaId ?? '';
99 |       if (quotaId.includes('PerDay') || quotaId.includes('Daily')) {
100 |         return new TerminalQuotaError(
101 |           `Reached a daily quota limit: ${violation.description}`,
102 |           googleApiError,
103 |         );
104 |       }
105 |     }
106 |   }
107 | 
108 |   if (errorInfo) {
109 |     const quotaLimit = errorInfo.metadata?.['quota_limit'] ?? '';
110 |     if (quotaLimit.includes('PerDay') || quotaLimit.includes('Daily')) {
111 |       return new TerminalQuotaError(
112 |         `Reached a daily quota limit: ${errorInfo.reason}`,
113 |         googleApiError,
114 |       );
115 |     }
116 |   }
117 | 
118 |   // 2. Check for long delays in RetryInfo
119 |   if (retryInfo?.retryDelay) {
120 |     const delaySeconds = parseDurationInSeconds(retryInfo.retryDelay);
121 |     if (delaySeconds !== null) {
122 |       if (delaySeconds > FIVE_MINUTES_IN_SECONDS) {
123 |         return new TerminalQuotaError(
124 |           `Quota limit requires a long delay of ${retryInfo.retryDelay}.`,
125 |           googleApiError,
126 |         );
127 |       }
128 |       // This is a retryable error with a specific delay.
129 |       return new RetryableQuotaError(
130 |         `Quota limit hit. Retrying after ${retryInfo.retryDelay}.`,
131 |         googleApiError,
132 |         delaySeconds,
133 |       );
134 |     }
135 |   }
136 | 
137 |   // 3. Check for short-term limits in QuotaFailure or ErrorInfo
138 |   if (quotaFailure) {
139 |     for (const violation of quotaFailure.violations) {
140 |       const quotaId = violation.quotaId ?? '';
141 |       if (quotaId.includes('PerMinute')) {
142 |         return new RetryableQuotaError(
143 |           `Quota limit hit: ${violation.description}. Retrying after 60s.`,
144 |           googleApiError,
145 |           60,
146 |         );
147 |       }
148 |     }
149 |   }
150 | 
151 |   if (errorInfo) {
152 |     const quotaLimit = errorInfo.metadata?.['quota_limit'] ?? '';
153 |     if (quotaLimit.includes('PerMinute')) {
154 |       return new RetryableQuotaError(
155 |         `Quota limit hit: ${errorInfo.reason}. Retrying after 60s.`,
156 |         googleApiError,
157 |         60,
158 |       );
159 |     }
160 |   }
161 |   return error; // Fallback to original error if no specific classification fits.
162 | }
```

src/utils/ignorePatterns.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi } from 'vitest';
8 | import {
9 |   FileExclusions,
10 |   BINARY_EXTENSIONS,
11 |   extractExtensionsFromPatterns,
12 | } from './ignorePatterns.js';
13 | import type { Config } from '../config/config.js';
14 | 
15 | // Mock the memoryTool module
16 | vi.mock('../tools/memoryTool.js', () => ({
17 |   getCurrentGeminiMdFilename: vi.fn(() => 'GEMINI.md'),
18 | }));
19 | 
20 | describe('FileExclusions', () => {
21 |   describe('getCoreIgnorePatterns', () => {
22 |     it('should return basic ignore patterns', () => {
23 |       const excluder = new FileExclusions();
24 |       const patterns = excluder.getCoreIgnorePatterns();
25 | 
26 |       expect(patterns).toContain('**/node_modules/**');
27 |       expect(patterns).toContain('**/.git/**');
28 |       expect(patterns).toContain('**/bower_components/**');
29 |       expect(patterns).toContain('**/.svn/**');
30 |       expect(patterns).toContain('**/.hg/**');
31 |       expect(patterns).toHaveLength(5);
32 |     });
33 |   });
34 | 
35 |   describe('getDefaultExcludePatterns', () => {
36 |     it('should return comprehensive patterns by default', () => {
37 |       const excluder = new FileExclusions();
38 |       const patterns = excluder.getDefaultExcludePatterns();
39 | 
40 |       // Should include core patterns
41 |       expect(patterns).toContain('**/node_modules/**');
42 |       expect(patterns).toContain('**/.git/**');
43 | 
44 |       // Should include directory excludes
45 |       expect(patterns).toContain('**/.vscode/**');
46 |       expect(patterns).toContain('**/dist/**');
47 |       expect(patterns).toContain('**/build/**');
48 | 
49 |       // Should include binary patterns
50 |       expect(patterns).toContain('**/*.exe');
51 |       expect(patterns).toContain('**/*.jar');
52 | 
53 |       // Should include system files
54 |       expect(patterns).toContain('**/.DS_Store');
55 |       expect(patterns).toContain('**/.env');
56 | 
57 |       // Should include dynamic patterns
58 |       expect(patterns).toContain('**/GEMINI.md');
59 |     });
60 | 
61 |     it('should respect includeDefaults option', () => {
62 |       const excluder = new FileExclusions();
63 |       const patterns = excluder.getDefaultExcludePatterns({
64 |         includeDefaults: false,
65 |         includeDynamicPatterns: false,
66 |       });
67 | 
68 |       expect(patterns).not.toContain('**/node_modules/**');
69 |       expect(patterns).not.toContain('**/.git/**');
70 |       expect(patterns).not.toContain('**/GEMINI.md');
71 |       expect(patterns).toHaveLength(0);
72 |     });
73 | 
74 |     it('should include custom patterns', () => {
75 |       const excluder = new FileExclusions();
76 |       const patterns = excluder.getDefaultExcludePatterns({
77 |         customPatterns: ['**/custom/**', '**/*.custom'],
78 |       });
79 | 
80 |       expect(patterns).toContain('**/custom/**');
81 |       expect(patterns).toContain('**/*.custom');
82 |     });
83 | 
84 |     it('should include runtime patterns', () => {
85 |       const excluder = new FileExclusions();
86 |       const patterns = excluder.getDefaultExcludePatterns({
87 |         runtimePatterns: ['**/temp/**', '**/*.tmp'],
88 |       });
89 | 
90 |       expect(patterns).toContain('**/temp/**');
91 |       expect(patterns).toContain('**/*.tmp');
92 |     });
93 | 
94 |     it('should respect includeDynamicPatterns option', () => {
95 |       const excluder = new FileExclusions();
96 |       const patternsWithDynamic = excluder.getDefaultExcludePatterns({
97 |         includeDynamicPatterns: true,
98 |       });
99 |       const patternsWithoutDynamic = excluder.getDefaultExcludePatterns({
100 |         includeDynamicPatterns: false,
101 |       });
102 | 
103 |       expect(patternsWithDynamic).toContain('**/GEMINI.md');
104 |       expect(patternsWithoutDynamic).not.toContain('**/GEMINI.md');
105 |     });
106 |   });
107 | 
108 |   describe('getReadManyFilesExcludes', () => {
109 |     it('should provide legacy compatibility', () => {
110 |       const excluder = new FileExclusions();
111 |       const patterns = excluder.getReadManyFilesExcludes(['**/*.log']);
112 | 
113 |       // Should include all default patterns
114 |       expect(patterns).toContain('**/node_modules/**');
115 |       expect(patterns).toContain('**/.git/**');
116 |       expect(patterns).toContain('**/GEMINI.md');
117 | 
118 |       // Should include additional excludes
119 |       expect(patterns).toContain('**/*.log');
120 |     });
121 |   });
122 | 
123 |   describe('getGlobExcludes', () => {
124 |     it('should return core patterns for glob operations', () => {
125 |       const excluder = new FileExclusions();
126 |       const patterns = excluder.getGlobExcludes();
127 | 
128 |       expect(patterns).toContain('**/node_modules/**');
129 |       expect(patterns).toContain('**/.git/**');
130 |       expect(patterns).toContain('**/bower_components/**');
131 |       expect(patterns).toContain('**/.svn/**');
132 |       expect(patterns).toContain('**/.hg/**');
133 | 
134 |       // Should not include comprehensive patterns by default
135 |       expect(patterns).toHaveLength(5);
136 |     });
137 | 
138 |     it('should include additional excludes', () => {
139 |       const excluder = new FileExclusions();
140 |       const patterns = excluder.getGlobExcludes(['**/temp/**']);
141 | 
142 |       expect(patterns).toContain('**/node_modules/**');
143 |       expect(patterns).toContain('**/.git/**');
144 |       expect(patterns).toContain('**/temp/**');
145 |     });
146 |   });
147 | 
148 |   describe('with Config', () => {
149 |     it('should use config custom excludes when available', () => {
150 |       const mockConfig = {
151 |         getCustomExcludes: vi.fn(() => ['**/config-exclude/**']),
152 |       } as unknown as Config;
153 | 
154 |       const excluder = new FileExclusions(mockConfig);
155 |       const patterns = excluder.getDefaultExcludePatterns();
156 | 
157 |       expect(patterns).toContain('**/config-exclude/**');
158 |       expect(mockConfig.getCustomExcludes).toHaveBeenCalled();
159 |     });
160 | 
161 |     it('should handle config without getCustomExcludes method', () => {
162 |       const mockConfig = {} as Config;
163 | 
164 |       const excluder = new FileExclusions(mockConfig);
165 |       const patterns = excluder.getDefaultExcludePatterns();
166 | 
167 |       // Should not throw and should include default patterns
168 |       expect(patterns).toContain('**/node_modules/**');
169 |       expect(patterns.length).toBeGreaterThan(0);
170 |     });
171 | 
172 |     it('should include config custom excludes in glob patterns', () => {
173 |       const mockConfig = {
174 |         getCustomExcludes: vi.fn(() => ['**/config-glob/**']),
175 |       } as unknown as Config;
176 | 
177 |       const excluder = new FileExclusions(mockConfig);
178 |       const patterns = excluder.getGlobExcludes();
179 | 
180 |       expect(patterns).toContain('**/node_modules/**');
181 |       expect(patterns).toContain('**/.git/**');
182 |       expect(patterns).toContain('**/config-glob/**');
183 |     });
184 |   });
185 | 
186 |   describe('buildExcludePatterns', () => {
187 |     it('should be an alias for getDefaultExcludePatterns', () => {
188 |       const excluder = new FileExclusions();
189 |       const options = {
190 |         includeDefaults: true,
191 |         customPatterns: ['**/test/**'],
192 |         runtimePatterns: ['**/runtime/**'],
193 |       };
194 | 
195 |       const defaultPatterns = excluder.getDefaultExcludePatterns(options);
196 |       const buildPatterns = excluder.buildExcludePatterns(options);
197 | 
198 |       expect(buildPatterns).toEqual(defaultPatterns);
199 |     });
200 |   });
201 | });
202 | 
203 | describe('BINARY_EXTENSIONS', () => {
204 |   it('should include common binary file extensions', () => {
205 |     expect(BINARY_EXTENSIONS).toContain('.exe');
206 |     expect(BINARY_EXTENSIONS).toContain('.dll');
207 |     expect(BINARY_EXTENSIONS).toContain('.jar');
208 |     expect(BINARY_EXTENSIONS).toContain('.zip');
209 |   });
210 | 
211 |   it('should include additional binary extensions', () => {
212 |     expect(BINARY_EXTENSIONS).toContain('.dat');
213 |     expect(BINARY_EXTENSIONS).toContain('.obj');
214 |     expect(BINARY_EXTENSIONS).toContain('.wasm');
215 |   });
216 | 
217 |   it('should include media file extensions', () => {
218 |     expect(BINARY_EXTENSIONS).toContain('.pdf');
219 |     expect(BINARY_EXTENSIONS).toContain('.png');
220 |     expect(BINARY_EXTENSIONS).toContain('.jpg');
221 |   });
222 | 
223 |   it('should be sorted', () => {
224 |     const sortedExtensions = [...BINARY_EXTENSIONS].sort();
225 |     expect(BINARY_EXTENSIONS).toEqual(sortedExtensions);
226 |   });
227 | 
228 |   it('should not contain invalid extensions from brace patterns', () => {
229 |     // If brace expansion was not handled correctly, we would see invalid extensions like '.{jpg,png}'
230 |     const invalidExtensions = BINARY_EXTENSIONS.filter(
231 |       (ext) => ext.includes('{') || ext.includes('}'),
232 |     );
233 |     expect(invalidExtensions).toHaveLength(0);
234 |   });
235 | });
236 | 
237 | describe('extractExtensionsFromPatterns', () => {
238 |   it('should extract simple extensions', () => {
239 |     const patterns = ['**/*.exe', '**/*.jar', '**/*.zip'];
240 |     const result = extractExtensionsFromPatterns(patterns);
241 | 
242 |     expect(result).toEqual(['.exe', '.jar', '.zip']);
243 |   });
244 | 
245 |   it('should handle brace expansion patterns', () => {
246 |     const patterns = ['**/*.{js,ts}', '**/*.{jpg,png}'];
247 |     const result = extractExtensionsFromPatterns(patterns);
248 | 
249 |     expect(result).toContain('.js');
250 |     expect(result).toContain('.ts');
251 |     expect(result).toContain('.jpg');
252 |     expect(result).toContain('.png');
253 |     expect(result).not.toContain('.{js,ts}');
254 |     expect(result).not.toContain('.{jpg,png}');
255 |   });
256 | 
257 |   it('should combine simple and brace expansion patterns', () => {
258 |     const patterns = ['**/*.exe', '**/*.{js,ts}', '**/*.pdf'];
259 |     const result = extractExtensionsFromPatterns(patterns);
260 | 
261 |     expect(result).toContain('.exe');
262 |     expect(result).toContain('.js');
263 |     expect(result).toContain('.ts');
264 |     expect(result).toContain('.pdf');
265 |   });
266 | 
267 |   it('should handle empty brace expansion', () => {
268 |     const patterns = ['**/*.{}', '**/*.{,}'];
269 |     const result = extractExtensionsFromPatterns(patterns);
270 | 
271 |     // Empty extensions should be filtered out
272 |     expect(result).toHaveLength(0);
273 |   });
274 | 
275 |   it('should ignore invalid patterns', () => {
276 |     const patterns = ['no-asterisk.exe', '**/*no-dot', '**/*.{unclosed'];
277 |     const result = extractExtensionsFromPatterns(patterns);
278 | 
279 |     expect(result).toHaveLength(0);
280 |   });
281 | 
282 |   it('should remove duplicates and sort results', () => {
283 |     const patterns = ['**/*.js', '**/*.{js,ts}', '**/*.ts'];
284 |     const result = extractExtensionsFromPatterns(patterns);
285 | 
286 |     expect(result).toEqual(['.js', '.ts']);
287 |   });
288 | 
289 |   it('should handle complex brace patterns with multiple extensions', () => {
290 |     const patterns = ['**/*.{html,css,js,jsx,ts,tsx}'];
291 |     const result = extractExtensionsFromPatterns(patterns);
292 | 
293 |     expect(result).toEqual(['.css', '.html', '.js', '.jsx', '.ts', '.tsx']);
294 |   });
295 | 
296 |   it('should handle compound extensions correctly using path.extname', () => {
297 |     const patterns = ['**/*.tar.gz', '**/*.min.js', '**/*.d.ts'];
298 |     const result = extractExtensionsFromPatterns(patterns);
299 | 
300 |     // Should extract the final extension part only
301 |     expect(result).toEqual(['.gz', '.js', '.ts']);
302 |   });
303 | 
304 |   it('should handle dotfiles correctly', () => {
305 |     const patterns = ['**/*.gitignore', '**/*.profile', '**/*.bashrc'];
306 |     const result = extractExtensionsFromPatterns(patterns);
307 | 
308 |     // Dotfiles should be extracted properly
309 |     expect(result).toEqual(['.bashrc', '.gitignore', '.profile']);
310 |   });
311 | 
312 |   it('should handle edge cases with path.extname', () => {
313 |     const patterns = ['**/*.hidden.', '**/*.config.json'];
314 |     const result = extractExtensionsFromPatterns(patterns);
315 | 
316 |     // Should handle edge cases properly (trailing dots are filtered out)
317 |     expect(result).toEqual(['.json']);
318 |   });
319 | });
```

src/utils/ignorePatterns.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import path from 'node:path';
8 | import type { Config } from '../config/config.js';
9 | import { getCurrentGeminiMdFilename } from '../tools/memoryTool.js';
10 | 
11 | /**
12 |  * Common ignore patterns used across multiple tools for basic exclusions.
13 |  * These are the most commonly ignored directories in development projects.
14 |  */
15 | export const COMMON_IGNORE_PATTERNS: string[] = [
16 |   '**/node_modules/**',
17 |   '**/.git/**',
18 |   '**/bower_components/**',
19 |   '**/.svn/**',
20 |   '**/.hg/**',
21 | ];
22 | 
23 | /**
24 |  * Binary file extension patterns that are typically excluded from text processing.
25 |  */
26 | export const BINARY_FILE_PATTERNS: string[] = [
27 |   '**/*.bin',
28 |   '**/*.exe',
29 |   '**/*.dll',
30 |   '**/*.so',
31 |   '**/*.dylib',
32 |   '**/*.class',
33 |   '**/*.jar',
34 |   '**/*.war',
35 |   '**/*.zip',
36 |   '**/*.tar',
37 |   '**/*.gz',
38 |   '**/*.bz2',
39 |   '**/*.rar',
40 |   '**/*.7z',
41 |   '**/*.doc',
42 |   '**/*.docx',
43 |   '**/*.xls',
44 |   '**/*.xlsx',
45 |   '**/*.ppt',
46 |   '**/*.pptx',
47 |   '**/*.odt',
48 |   '**/*.ods',
49 |   '**/*.odp',
50 | ];
51 | 
52 | /**
53 |  * Media file patterns that require special handling in tools like read-many-files.
54 |  * These files can be processed as inlineData when explicitly requested.
55 |  */
56 | export const MEDIA_FILE_PATTERNS: string[] = [
57 |   '**/*.pdf',
58 |   '**/*.png',
59 |   '**/*.jpg',
60 |   '**/*.jpeg',
61 |   '**/*.gif',
62 |   '**/*.webp',
63 |   '**/*.bmp',
64 |   '**/*.svg',
65 | ];
66 | 
67 | /**
68 |  * Common directory patterns that are typically ignored in development projects.
69 |  */
70 | export const COMMON_DIRECTORY_EXCLUDES: string[] = [
71 |   '**/.vscode/**',
72 |   '**/.idea/**',
73 |   '**/dist/**',
74 |   '**/build/**',
75 |   '**/coverage/**',
76 |   '**/__pycache__/**',
77 | ];
78 | 
79 | /**
80 |  * Python-specific patterns.
81 |  */
82 | export const PYTHON_EXCLUDES: string[] = ['**/*.pyc', '**/*.pyo'];
83 | 
84 | /**
85 |  * System and environment file patterns.
86 |  */
87 | export const SYSTEM_FILE_EXCLUDES: string[] = ['**/.DS_Store', '**/.env'];
88 | 
89 | /**
90 |  * Comprehensive file exclusion patterns combining all common ignore patterns.
91 |  * These patterns are compatible with glob ignore patterns.
92 |  * Note: Media files (PDF, images) are not excluded here as they need special handling in read-many-files.
93 |  */
94 | export const DEFAULT_FILE_EXCLUDES: string[] = [
95 |   ...COMMON_IGNORE_PATTERNS,
96 |   ...COMMON_DIRECTORY_EXCLUDES,
97 |   ...BINARY_FILE_PATTERNS,
98 |   ...PYTHON_EXCLUDES,
99 |   ...SYSTEM_FILE_EXCLUDES,
100 | ];
101 | 
102 | /**
103 |  * Options for configuring file exclusion patterns.
104 |  */
105 | export interface ExcludeOptions {
106 |   /**
107 |    * Whether to include default exclusion patterns. Defaults to true.
108 |    */
109 |   includeDefaults?: boolean;
110 | 
111 |   /**
112 |    * Additional custom patterns from configuration.
113 |    */
114 |   customPatterns?: string[];
115 | 
116 |   /**
117 |    * Additional patterns provided at runtime (e.g., from CLI arguments).
118 |    */
119 |   runtimePatterns?: string[];
120 | 
121 |   /**
122 |    * Whether to include dynamic patterns like the current Gemini MD filename. Defaults to true.
123 |    */
124 |   includeDynamicPatterns?: boolean;
125 | }
126 | 
127 | /**
128 |  * Centralized file exclusion utility that provides configurable and extensible
129 |  * file exclusion patterns for different tools and use cases.
130 |  */
131 | export class FileExclusions {
132 |   constructor(private config?: Config) {}
133 | 
134 |   /**
135 |    * Gets core ignore patterns for basic file operations like glob.
136 |    * These are the minimal essential patterns that should almost always be excluded.
137 |    */
138 |   getCoreIgnorePatterns(): string[] {
139 |     return [...COMMON_IGNORE_PATTERNS];
140 |   }
141 | 
142 |   /**
143 |    * Gets comprehensive default exclusion patterns for operations like read-many-files.
144 |    * Includes all standard exclusions: directories, binary files, system files, etc.
145 |    */
146 |   getDefaultExcludePatterns(options: ExcludeOptions = {}): string[] {
147 |     const {
148 |       includeDefaults = true,
149 |       customPatterns = [],
150 |       runtimePatterns = [],
151 |       includeDynamicPatterns = true,
152 |     } = options;
153 | 
154 |     const patterns: string[] = [];
155 | 
156 |     // Add base defaults if requested
157 |     if (includeDefaults) {
158 |       patterns.push(...DEFAULT_FILE_EXCLUDES);
159 |     }
160 | 
161 |     // Add dynamic patterns (like current Gemini MD filename)
162 |     if (includeDynamicPatterns) {
163 |       patterns.push(`**/${getCurrentGeminiMdFilename()}`);
164 |     }
165 | 
166 |     // Add custom patterns from configuration
167 |     // TODO: getCustomExcludes method needs to be implemented in Config interface
168 |     if (this.config) {
169 |       const configCustomExcludes = this.config.getCustomExcludes?.() ?? [];
170 |       patterns.push(...configCustomExcludes);
171 |     }
172 | 
173 |     // Add user-provided custom patterns
174 |     patterns.push(...customPatterns);
175 | 
176 |     // Add runtime patterns (e.g., from CLI)
177 |     patterns.push(...runtimePatterns);
178 | 
179 |     return patterns;
180 |   }
181 | 
182 |   /**
183 |    * Gets exclude patterns for read-many-files tool with legacy compatibility.
184 |    * This maintains the same behavior as the previous getDefaultExcludes() function.
185 |    */
186 |   getReadManyFilesExcludes(additionalExcludes: string[] = []): string[] {
187 |     return this.getDefaultExcludePatterns({
188 |       includeDefaults: true,
189 |       runtimePatterns: additionalExcludes,
190 |       includeDynamicPatterns: true,
191 |     });
192 |   }
193 | 
194 |   /**
195 |    * Gets exclude patterns for glob tool operations.
196 |    * Uses core patterns by default but can be extended with additional patterns.
197 |    */
198 |   getGlobExcludes(additionalExcludes: string[] = []): string[] {
199 |     const corePatterns = this.getCoreIgnorePatterns();
200 | 
201 |     // Add any custom patterns from config if available
202 |     // TODO: getCustomExcludes method needs to be implemented in Config interface
203 |     const configPatterns = this.config?.getCustomExcludes?.() ?? [];
204 | 
205 |     return [...corePatterns, ...configPatterns, ...additionalExcludes];
206 |   }
207 | 
208 |   /**
209 |    * Builds exclude patterns with full customization options.
210 |    * This is the most flexible method for advanced use cases.
211 |    */
212 |   buildExcludePatterns(options: ExcludeOptions): string[] {
213 |     return this.getDefaultExcludePatterns(options);
214 |   }
215 | }
216 | 
217 | /**
218 |  * Extracts file extensions from glob patterns.
219 |  * Converts patterns like glob/*.exe to .exe
220 |  * Handles brace expansion like glob/*.{js,ts} to .js and .ts
221 |  */
222 | export function extractExtensionsFromPatterns(patterns: string[]): string[] {
223 |   const extensions = new Set(
224 |     patterns
225 |       .filter((pattern) => pattern.includes('*.'))
226 |       .flatMap((pattern) => {
227 |         const extPart = pattern.substring(pattern.lastIndexOf('*.') + 1);
228 |         // Handle brace expansion e.g. `**/*.{jpg,png}`
229 |         if (extPart.startsWith('.{') && extPart.endsWith('}')) {
230 |           const inner = extPart.slice(2, -1); // get 'jpg,png'
231 |           return inner
232 |             .split(',')
233 |             .map((ext) => `.${ext.trim()}`)
234 |             .filter((ext) => ext !== '.');
235 |         }
236 |         // Handle simple/compound/dotfile extensions
237 |         if (
238 |           extPart.startsWith('.') &&
239 |           !extPart.includes('/') &&
240 |           !extPart.includes('{') &&
241 |           !extPart.includes('}')
242 |         ) {
243 |           // Using path.extname on a dummy file handles various cases like
244 |           // '.tar.gz' -> '.gz' and '.profile' -> '.profile' correctly.
245 |           const extracted = path.extname(`dummy${extPart}`);
246 |           // If extname returns empty (e.g. for '.'), use the original part.
247 |           // Then filter out empty or '.' results and invalid double dot patterns.
248 |           const result = extracted || extPart;
249 |           return result && result !== '.' && !result.substring(1).includes('.')
250 |             ? [result]
251 |             : [];
252 |         }
253 |         return [];
254 |       }),
255 |   );
256 |   return Array.from(extensions).sort();
257 | }
258 | 
259 | /**
260 |  * Binary file extensions extracted from BINARY_FILE_PATTERNS for quick lookup.
261 |  * Additional extensions not covered by the patterns are included for completeness.
262 |  */
263 | export const BINARY_EXTENSIONS: string[] = [
264 |   ...extractExtensionsFromPatterns([
265 |     ...BINARY_FILE_PATTERNS,
266 |     ...MEDIA_FILE_PATTERNS,
267 |     ...PYTHON_EXCLUDES,
268 |   ]),
269 |   // Additional binary extensions not in the main patterns
270 |   '.dat',
271 |   '.obj',
272 |   '.o',
273 |   '.a',
274 |   '.lib',
275 |   '.wasm',
276 | ].sort();
```

src/utils/installationManager.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Mock } from 'vitest';
8 | import { vi, describe, it, expect, beforeEach, afterEach } from 'vitest';
9 | import { InstallationManager } from './installationManager.js';
10 | import * as fs from 'node:fs';
11 | import * as os from 'node:os';
12 | import path from 'node:path';
13 | import { randomUUID } from 'node:crypto';
14 | 
15 | vi.mock('node:fs', async (importOriginal) => {
16 |   const actual = await importOriginal<typeof import('node:fs')>();
17 |   return {
18 |     ...actual,
19 |     readFileSync: vi.fn(actual.readFileSync),
20 |     existsSync: vi.fn(actual.existsSync),
21 |   } as typeof actual;
22 | });
23 | 
24 | vi.mock('os', async (importOriginal) => {
25 |   const os = await importOriginal<typeof import('os')>();
26 |   return {
27 |     ...os,
28 |     homedir: vi.fn(),
29 |   };
30 | });
31 | 
32 | vi.mock('crypto', async (importOriginal) => {
33 |   const crypto = await importOriginal<typeof import('crypto')>();
34 |   return {
35 |     ...crypto,
36 |     randomUUID: vi.fn(),
37 |   };
38 | });
39 | 
40 | describe('InstallationManager', () => {
41 |   let tempHomeDir: string;
42 |   let installationManager: InstallationManager;
43 |   const installationIdFile = () =>
44 |     path.join(tempHomeDir, '.gemini', 'installation_id');
45 | 
46 |   beforeEach(() => {
47 |     tempHomeDir = fs.mkdtempSync(
48 |       path.join(os.tmpdir(), 'gemini-cli-test-home-'),
49 |     );
50 |     (os.homedir as Mock).mockReturnValue(tempHomeDir);
51 |     installationManager = new InstallationManager();
52 |   });
53 | 
54 |   afterEach(() => {
55 |     fs.rmSync(tempHomeDir, { recursive: true, force: true });
56 |     vi.clearAllMocks();
57 |   });
58 | 
59 |   describe('getInstallationId', () => {
60 |     it('should create and write a new installation ID if one does not exist', () => {
61 |       const newId = 'new-uuid-123';
62 |       (randomUUID as Mock).mockReturnValue(newId);
63 | 
64 |       const installationId = installationManager.getInstallationId();
65 | 
66 |       expect(installationId).toBe(newId);
67 |       expect(fs.existsSync(installationIdFile())).toBe(true);
68 |       expect(fs.readFileSync(installationIdFile(), 'utf-8')).toBe(newId);
69 |     });
70 | 
71 |     it('should read an existing installation ID from a file', () => {
72 |       const existingId = 'existing-uuid-123';
73 |       fs.mkdirSync(path.dirname(installationIdFile()), { recursive: true });
74 |       fs.writeFileSync(installationIdFile(), existingId);
75 | 
76 |       const installationId = installationManager.getInstallationId();
77 | 
78 |       expect(installationId).toBe(existingId);
79 |     });
80 | 
81 |     it('should return the same ID on subsequent calls', () => {
82 |       const firstId = installationManager.getInstallationId();
83 |       const secondId = installationManager.getInstallationId();
84 |       expect(secondId).toBe(firstId);
85 |     });
86 | 
87 |     it('should handle read errors and return a fallback ID', () => {
88 |       vi.mocked(fs.existsSync).mockReturnValueOnce(true);
89 |       const readSpy = vi.mocked(fs.readFileSync);
90 |       readSpy.mockImplementationOnce(() => {
91 |         throw new Error('Read error');
92 |       });
93 |       const consoleErrorSpy = vi
94 |         .spyOn(console, 'error')
95 |         .mockImplementation(() => {});
96 | 
97 |       const id = installationManager.getInstallationId();
98 | 
99 |       expect(id).toBe('123456789');
100 |       expect(consoleErrorSpy).toHaveBeenCalled();
101 |     });
102 |   });
103 | });
```

src/utils/installationManager.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs';
8 | import { randomUUID } from 'node:crypto';
9 | import * as path from 'node:path';
10 | import { Storage } from '../config/storage.js';
11 | 
12 | export class InstallationManager {
13 |   private getInstallationIdPath(): string {
14 |     return Storage.getInstallationIdPath();
15 |   }
16 | 
17 |   private readInstallationIdFromFile(): string | null {
18 |     const installationIdFile = this.getInstallationIdPath();
19 |     if (fs.existsSync(installationIdFile)) {
20 |       const installationid = fs
21 |         .readFileSync(installationIdFile, 'utf-8')
22 |         .trim();
23 |       return installationid || null;
24 |     }
25 |     return null;
26 |   }
27 | 
28 |   private writeInstallationIdToFile(installationId: string) {
29 |     const installationIdFile = this.getInstallationIdPath();
30 |     const dir = path.dirname(installationIdFile);
31 |     fs.mkdirSync(dir, { recursive: true });
32 |     fs.writeFileSync(installationIdFile, installationId, 'utf-8');
33 |   }
34 | 
35 |   /**
36 |    * Retrieves the installation ID from a file, creating it if it doesn't exist.
37 |    * This ID is used for unique user installation tracking.
38 |    * @returns A UUID string for the user.
39 |    */
40 |   getInstallationId(): string {
41 |     try {
42 |       let installationId = this.readInstallationIdFromFile();
43 | 
44 |       if (!installationId) {
45 |         installationId = randomUUID();
46 |         this.writeInstallationIdToFile(installationId);
47 |       }
48 | 
49 |       return installationId;
50 |     } catch (error) {
51 |       console.error(
52 |         'Error accessing installation ID file, generating ephemeral ID:',
53 |         error,
54 |       );
55 |       return '123456789';
56 |     }
57 |   }
58 | }
```

src/utils/language-detection.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as path from 'node:path';
8 | 
9 | const extensionToLanguageMap: { [key: string]: string } = {
10 |   '.ts': 'TypeScript',
11 |   '.js': 'JavaScript',
12 |   '.mjs': 'JavaScript',
13 |   '.cjs': 'JavaScript',
14 |   '.jsx': 'JavaScript',
15 |   '.tsx': 'TypeScript',
16 |   '.py': 'Python',
17 |   '.java': 'Java',
18 |   '.go': 'Go',
19 |   '.rb': 'Ruby',
20 |   '.php': 'PHP',
21 |   '.phtml': 'PHP',
22 |   '.cs': 'C#',
23 |   '.cpp': 'C++',
24 |   '.cxx': 'C++',
25 |   '.cc': 'C++',
26 |   '.c': 'C',
27 |   '.h': 'C/C++',
28 |   '.hpp': 'C++',
29 |   '.swift': 'Swift',
30 |   '.kt': 'Kotlin',
31 |   '.rs': 'Rust',
32 |   '.m': 'Objective-C',
33 |   '.mm': 'Objective-C',
34 |   '.pl': 'Perl',
35 |   '.pm': 'Perl',
36 |   '.lua': 'Lua',
37 |   '.r': 'R',
38 |   '.scala': 'Scala',
39 |   '.sc': 'Scala',
40 |   '.sh': 'Shell',
41 |   '.ps1': 'PowerShell',
42 |   '.bat': 'Batch',
43 |   '.cmd': 'Batch',
44 |   '.sql': 'SQL',
45 |   '.html': 'HTML',
46 |   '.htm': 'HTML',
47 |   '.css': 'CSS',
48 |   '.less': 'Less',
49 |   '.sass': 'Sass',
50 |   '.scss': 'Sass',
51 |   '.json': 'JSON',
52 |   '.xml': 'XML',
53 |   '.yaml': 'YAML',
54 |   '.yml': 'YAML',
55 |   '.md': 'Markdown',
56 |   '.markdown': 'Markdown',
57 |   '.dockerfile': 'Dockerfile',
58 |   '.vim': 'Vim script',
59 |   '.vb': 'Visual Basic',
60 |   '.fs': 'F#',
61 |   '.clj': 'Clojure',
62 |   '.cljs': 'Clojure',
63 |   '.dart': 'Dart',
64 |   '.ex': 'Elixir',
65 |   '.erl': 'Erlang',
66 |   '.hs': 'Haskell',
67 |   '.lisp': 'Lisp',
68 |   '.rkt': 'Racket',
69 |   '.groovy': 'Groovy',
70 |   '.jl': 'Julia',
71 |   '.tex': 'LaTeX',
72 |   '.ino': 'Arduino',
73 |   '.asm': 'Assembly',
74 |   '.s': 'Assembly',
75 |   '.toml': 'TOML',
76 |   '.vue': 'Vue',
77 |   '.svelte': 'Svelte',
78 |   '.gohtml': 'Go Template',
79 |   '.hbs': 'Handlebars',
80 |   '.ejs': 'EJS',
81 |   '.erb': 'ERB',
82 |   '.jsp': 'JSP',
83 |   '.dockerignore': 'Docker',
84 |   '.gitignore': 'Git',
85 |   '.npmignore': 'npm',
86 |   '.editorconfig': 'EditorConfig',
87 |   '.prettierrc': 'Prettier',
88 |   '.eslintrc': 'ESLint',
89 |   '.babelrc': 'Babel',
90 |   '.tsconfig': 'TypeScript',
91 |   '.flow': 'Flow',
92 |   '.graphql': 'GraphQL',
93 |   '.proto': 'Protocol Buffers',
94 | };
95 | 
96 | export function getLanguageFromFilePath(filePath: string): string | undefined {
97 |   const extension = path.extname(filePath).toLowerCase();
98 |   if (extension) {
99 |     return extensionToLanguageMap[extension];
100 |   }
101 |   const filename = path.basename(filePath).toLowerCase();
102 |   return extensionToLanguageMap[`.${filename}`];
103 | }
```

src/utils/llm-edit-fixer.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import {
9 |   FixLLMEditWithInstruction,
10 |   resetLlmEditFixerCaches_TEST_ONLY,
11 |   type SearchReplaceEdit,
12 | } from './llm-edit-fixer.js';
13 | import { promptIdContext } from './promptIdContext.js';
14 | import type { BaseLlmClient } from '../core/baseLlmClient.js';
15 | 
16 | // Mock the BaseLlmClient
17 | const mockGenerateJson = vi.fn();
18 | const mockBaseLlmClient = {
19 |   generateJson: mockGenerateJson,
20 | } as unknown as BaseLlmClient;
21 | 
22 | describe('FixLLMEditWithInstruction', () => {
23 |   const instruction = 'Replace the title';
24 |   const old_string = '<h1>Old Title</h1>';
25 |   const new_string = '<h1>New Title</h1>';
26 |   const error = 'String not found';
27 |   const current_content = '<body><h1>Old Title</h1></body>';
28 |   const abortController = new AbortController();
29 |   const abortSignal = abortController.signal;
30 | 
31 |   beforeEach(() => {
32 |     vi.clearAllMocks();
33 |     resetLlmEditFixerCaches_TEST_ONLY(); // Ensure cache is cleared before each test
34 |   });
35 | 
36 |   afterEach(() => {
37 |     vi.useRealTimers(); // Reset timers after each test
38 |   });
39 | 
40 |   const mockApiResponse: SearchReplaceEdit = {
41 |     search: '<h1>Old Title</h1>',
42 |     replace: '<h1>New Title</h1>',
43 |     noChangesRequired: false,
44 |     explanation: 'The original search was correct.',
45 |   };
46 | 
47 |   it('should use the promptId from the AsyncLocalStorage context when available', async () => {
48 |     const testPromptId = 'test-prompt-id-12345';
49 |     mockGenerateJson.mockResolvedValue(mockApiResponse);
50 | 
51 |     await promptIdContext.run(testPromptId, async () => {
52 |       await FixLLMEditWithInstruction(
53 |         instruction,
54 |         old_string,
55 |         new_string,
56 |         error,
57 |         current_content,
58 |         mockBaseLlmClient,
59 |         abortSignal,
60 |       );
61 |     });
62 | 
63 |     // Verify that generateJson was called with the promptId from the context
64 |     expect(mockGenerateJson).toHaveBeenCalledTimes(1);
65 |     expect(mockGenerateJson).toHaveBeenCalledWith(
66 |       expect.objectContaining({
67 |         promptId: testPromptId,
68 |       }),
69 |     );
70 |   });
71 | 
72 |   it('should generate and use a fallback promptId when context is not available', async () => {
73 |     mockGenerateJson.mockResolvedValue(mockApiResponse);
74 |     const consoleWarnSpy = vi
75 |       .spyOn(console, 'warn')
76 |       .mockImplementation(() => {});
77 | 
78 |     // Run the function outside of any context
79 |     await FixLLMEditWithInstruction(
80 |       instruction,
81 |       old_string,
82 |       new_string,
83 |       error,
84 |       current_content,
85 |       mockBaseLlmClient,
86 |       abortSignal,
87 |     );
88 | 
89 |     // Verify the warning was logged
90 |     expect(consoleWarnSpy).toHaveBeenCalledWith(
91 |       expect.stringContaining(
92 |         'Could not find promptId in context. This is unexpected. Using a fallback ID: llm-fixer-fallback-',
93 |       ),
94 |     );
95 | 
96 |     // Verify that generateJson was called with the generated fallback promptId
97 |     expect(mockGenerateJson).toHaveBeenCalledTimes(1);
98 |     expect(mockGenerateJson).toHaveBeenCalledWith(
99 |       expect.objectContaining({
100 |         promptId: expect.stringContaining('llm-fixer-fallback-'),
101 |       }),
102 |     );
103 | 
104 |     // Restore mocks
105 |     consoleWarnSpy.mockRestore();
106 |   });
107 | 
108 |   it('should construct the user prompt correctly', async () => {
109 |     mockGenerateJson.mockResolvedValue(mockApiResponse);
110 |     const promptId = 'test-prompt-id-prompt-construction';
111 | 
112 |     await promptIdContext.run(promptId, async () => {
113 |       await FixLLMEditWithInstruction(
114 |         instruction,
115 |         old_string,
116 |         new_string,
117 |         error,
118 |         current_content,
119 |         mockBaseLlmClient,
120 |         abortSignal,
121 |       );
122 |     });
123 | 
124 |     const generateJsonCall = mockGenerateJson.mock.calls[0][0];
125 |     const userPromptContent = generateJsonCall.contents[0].parts[0].text;
126 | 
127 |     expect(userPromptContent).toContain(
128 |       `<instruction>\n${instruction}\n</instruction>`,
129 |     );
130 |     expect(userPromptContent).toContain(`<search>\n${old_string}\n</search>`);
131 |     expect(userPromptContent).toContain(`<replace>\n${new_string}\n</replace>`);
132 |     expect(userPromptContent).toContain(`<error>\n${error}\n</error>`);
133 |     expect(userPromptContent).toContain(
134 |       `<file_content>\n${current_content}\n</file_content>`,
135 |     );
136 |   });
137 | 
138 |   it('should return a cached result on subsequent identical calls', async () => {
139 |     mockGenerateJson.mockResolvedValue(mockApiResponse);
140 |     const testPromptId = 'test-prompt-id-caching';
141 | 
142 |     await promptIdContext.run(testPromptId, async () => {
143 |       // First call - should call the API
144 |       const result1 = await FixLLMEditWithInstruction(
145 |         instruction,
146 |         old_string,
147 |         new_string,
148 |         error,
149 |         current_content,
150 |         mockBaseLlmClient,
151 |         abortSignal,
152 |       );
153 | 
154 |       // Second call with identical parameters - should hit the cache
155 |       const result2 = await FixLLMEditWithInstruction(
156 |         instruction,
157 |         old_string,
158 |         new_string,
159 |         error,
160 |         current_content,
161 |         mockBaseLlmClient,
162 |         abortSignal,
163 |       );
164 | 
165 |       expect(result1).toEqual(mockApiResponse);
166 |       expect(result2).toEqual(mockApiResponse);
167 |       // Verify the underlying service was only called ONCE
168 |       expect(mockGenerateJson).toHaveBeenCalledTimes(1);
169 |     });
170 |   });
171 | 
172 |   it('should not use cache for calls with different parameters', async () => {
173 |     mockGenerateJson.mockResolvedValue(mockApiResponse);
174 |     const testPromptId = 'test-prompt-id-cache-miss';
175 | 
176 |     await promptIdContext.run(testPromptId, async () => {
177 |       // First call
178 |       await FixLLMEditWithInstruction(
179 |         instruction,
180 |         old_string,
181 |         new_string,
182 |         error,
183 |         current_content,
184 |         mockBaseLlmClient,
185 |         abortSignal,
186 |       );
187 | 
188 |       // Second call with a different instruction
189 |       await FixLLMEditWithInstruction(
190 |         'A different instruction',
191 |         old_string,
192 |         new_string,
193 |         error,
194 |         current_content,
195 |         mockBaseLlmClient,
196 |         abortSignal,
197 |       );
198 | 
199 |       // Verify the underlying service was called TWICE
200 |       expect(mockGenerateJson).toHaveBeenCalledTimes(2);
201 |     });
202 |   });
203 | 
204 |   describe('cache collision prevention', () => {
205 |     it('should prevent cache collisions when parameters contain separator sequences', async () => {
206 |       // This test would have failed with the old string concatenation approach
207 |       // but passes with JSON.stringify implementation
208 | 
209 |       const firstResponse: SearchReplaceEdit = {
210 |         search: 'original text',
211 |         replace: 'first replacement',
212 |         noChangesRequired: false,
213 |         explanation: 'First edit correction',
214 |       };
215 | 
216 |       const secondResponse: SearchReplaceEdit = {
217 |         search: 'different text',
218 |         replace: 'second replacement',
219 |         noChangesRequired: false,
220 |         explanation: 'Second edit correction',
221 |       };
222 | 
223 |       mockGenerateJson
224 |         .mockResolvedValueOnce(firstResponse)
225 |         .mockResolvedValueOnce(secondResponse);
226 | 
227 |       const testPromptId = 'cache-collision-test';
228 | 
229 |       await promptIdContext.run(testPromptId, async () => {
230 |         // Scenario 1: Parameters that would create collision with string concatenation
231 |         // Cache key with old method would be: "Fix YAML---content---update--some---data--error"
232 |         const call1 = await FixLLMEditWithInstruction(
233 |           'Fix YAML', // instruction
234 |           'content', // old_string
235 |           'update--some', // new_string (contains --)
236 |           'data', // current_content
237 |           'error', // error
238 |           mockBaseLlmClient,
239 |           abortSignal,
240 |         );
241 | 
242 |         // Scenario 2: Different parameters that would create same cache key with concatenation
243 |         // Cache key with old method would be: "Fix YAML---content---update--some---data--error"
244 |         const call2 = await FixLLMEditWithInstruction(
245 |           'Fix YAML---content---update', // instruction (contains ---)
246 |           'some---data', // old_string (contains ---)
247 |           'error', // new_string
248 |           '', // current_content
249 |           '', // error
250 |           mockBaseLlmClient,
251 |           abortSignal,
252 |         );
253 | 
254 |         // With the fixed JSON.stringify approach, these should be different
255 |         // and each should get its own LLM response
256 |         expect(call1).toEqual(firstResponse);
257 |         expect(call2).toEqual(secondResponse);
258 |         expect(call1).not.toEqual(call2);
259 | 
260 |         // Most importantly: the LLM should be called TWICE, not once
261 |         // (proving no cache collision occurred)
262 |         expect(mockGenerateJson).toHaveBeenCalledTimes(2);
263 |       });
264 |     });
265 | 
266 |     it('should handle YAML frontmatter without cache collisions', async () => {
267 |       // Real-world test case with YAML frontmatter containing ---
268 | 
269 |       const yamlResponse: SearchReplaceEdit = {
270 |         search: '---\ntitle: Old\n---',
271 |         replace: '---\ntitle: New\n---',
272 |         noChangesRequired: false,
273 |         explanation: 'Updated YAML frontmatter',
274 |       };
275 | 
276 |       const contentResponse: SearchReplaceEdit = {
277 |         search: 'old content',
278 |         replace: 'new content',
279 |         noChangesRequired: false,
280 |         explanation: 'Updated content',
281 |       };
282 | 
283 |       mockGenerateJson
284 |         .mockResolvedValueOnce(yamlResponse)
285 |         .mockResolvedValueOnce(contentResponse);
286 | 
287 |       const testPromptId = 'yaml-frontmatter-test';
288 | 
289 |       await promptIdContext.run(testPromptId, async () => {
290 |         // Call 1: Edit YAML frontmatter
291 |         const yamlEdit = await FixLLMEditWithInstruction(
292 |           'Update YAML frontmatter',
293 |           '---\ntitle: Old\n---', // Contains ---
294 |           '---\ntitle: New\n---', // Contains ---
295 |           'Some markdown content',
296 |           'YAML parse error',
297 |           mockBaseLlmClient,
298 |           abortSignal,
299 |         );
300 | 
301 |         // Call 2: Edit regular content
302 |         const contentEdit = await FixLLMEditWithInstruction(
303 |           'Update content',
304 |           'old content',
305 |           'new content',
306 |           'Different file content',
307 |           'Content not found',
308 |           mockBaseLlmClient,
309 |           abortSignal,
310 |         );
311 | 
312 |         // Verify both calls succeeded with different results
313 |         expect(yamlEdit).toEqual(yamlResponse);
314 |         expect(contentEdit).toEqual(contentResponse);
315 |         expect(yamlEdit).not.toEqual(contentEdit);
316 | 
317 |         // Verify no cache collision - both calls should hit the LLM
318 |         expect(mockGenerateJson).toHaveBeenCalledTimes(2);
319 |       });
320 |     });
321 |   });
322 | });
```

src/utils/llm-edit-fixer.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { createHash } from 'node:crypto';
8 | import { type Content, Type } from '@google/genai';
9 | import { type BaseLlmClient } from '../core/baseLlmClient.js';
10 | import { LruCache } from './LruCache.js';
11 | import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';
12 | import { promptIdContext } from './promptIdContext.js';
13 | 
14 | const MAX_CACHE_SIZE = 50;
15 | 
16 | const EDIT_SYS_PROMPT = `
17 | You are an expert code-editing assistant specializing in debugging and correcting failed search-and-replace operations.
18 | 
19 | # Primary Goal
20 | Your task is to analyze a failed edit attempt and provide a corrected \`search\` string that will match the text in the file precisely. The correction should be as minimal as possible, staying very close to the original, failed \`search\` string. Do NOT invent a completely new edit based on the instruction; your job is to fix the provided parameters.
21 | 
22 | It is important that you do no try to figure out if the instruction is correct. DO NOT GIVE ADVICE. Your only goal here is to do your best to perform the search and replace task! 
23 | 
24 | # Input Context
25 | You will be given:
26 | 1. The high-level instruction for the original edit.
27 | 2. The exact \`search\` and \`replace\` strings that failed.
28 | 3. The error message that was produced.
29 | 4. The full content of the latest version of the source file.
30 | 
31 | # Rules for Correction
32 | 1.  **Minimal Correction:** Your new \`search\` string must be a close variation of the original. Focus on fixing issues like whitespace, indentation, line endings, or small contextual differences.
33 | 2.  **Explain the Fix:** Your \`explanation\` MUST state exactly why the original \`search\` failed and how your new \`search\` string resolves that specific failure. (e.g., "The original search failed due to incorrect indentation; the new search corrects the indentation to match the source file.").
34 | 3.  **Preserve the \`replace\` String:** Do NOT modify the \`replace\` string unless the instruction explicitly requires it and it was the source of the error. Do not escape any characters in \`replace\`. Your primary focus is fixing the \`search\` string.
35 | 4.  **No Changes Case:** CRUCIAL: if the change is already present in the file,  set \`noChangesRequired\` to True and explain why in the \`explanation\`. It is crucial that you only do this if the changes outline in \`replace\` are already in the file and suits the instruction.
36 | 5.  **Exactness:** The final \`search\` field must be the EXACT literal text from the file. Do not escape characters.
37 | `;
38 | 
39 | const EDIT_USER_PROMPT = `
40 | # Goal of the Original Edit
41 | <instruction>
42 | {instruction}
43 | </instruction>
44 | 
45 | # Failed Attempt Details
46 | - **Original \`search\` parameter (failed):**
47 | <search>
48 | {old_string}
49 | </search>
50 | - **Original \`replace\` parameter:**
51 | <replace>
52 | {new_string}
53 | </replace>
54 | - **Error Encountered:**
55 | <error>
56 | {error}
57 | </error>
58 | 
59 | # Full File Content
60 | <file_content>
61 | {current_content}
62 | </file_content>
63 | 
64 | # Your Task
65 | Based on the error and the file content, provide a corrected \`search\` string that will succeed. Remember to keep your correction minimal and explain the precise reason for the failure in your \`explanation\`.
66 | `;
67 | 
68 | export interface SearchReplaceEdit {
69 |   search: string;
70 |   replace: string;
71 |   noChangesRequired: boolean;
72 |   explanation: string;
73 | }
74 | 
75 | const SearchReplaceEditSchema = {
76 |   type: Type.OBJECT,
77 |   properties: {
78 |     explanation: { type: Type.STRING },
79 |     search: { type: Type.STRING },
80 |     replace: { type: Type.STRING },
81 |     noChangesRequired: { type: Type.BOOLEAN },
82 |   },
83 |   required: ['search', 'replace', 'explanation'],
84 | };
85 | 
86 | const editCorrectionWithInstructionCache = new LruCache<
87 |   string,
88 |   SearchReplaceEdit
89 | >(MAX_CACHE_SIZE);
90 | 
91 | /**
92 |  * Attempts to fix a failed edit by using an LLM to generate a new search and replace pair.
93 |  * @param instruction The instruction for what needs to be done.
94 |  * @param old_string The original string to be replaced.
95 |  * @param new_string The original replacement string.
96 |  * @param error The error that occurred during the initial edit.
97 |  * @param current_content The current content of the file.
98 |  * @param baseLlmClient The BaseLlmClient to use for the LLM call.
99 |  * @param abortSignal An abort signal to cancel the operation.
100 |  * @param promptId A unique ID for the prompt.
101 |  * @returns A new search and replace pair.
102 |  */
103 | export async function FixLLMEditWithInstruction(
104 |   instruction: string,
105 |   old_string: string,
106 |   new_string: string,
107 |   error: string,
108 |   current_content: string,
109 |   baseLlmClient: BaseLlmClient,
110 |   abortSignal: AbortSignal,
111 | ): Promise<SearchReplaceEdit> {
112 |   let promptId = promptIdContext.getStore();
113 |   if (!promptId) {
114 |     promptId = `llm-fixer-fallback-${Date.now()}-${Math.random().toString(16).slice(2)}`;
115 |     console.warn(
116 |       `Could not find promptId in context. This is unexpected. Using a fallback ID: ${promptId}`,
117 |     );
118 |   }
119 | 
120 |   const cacheKey = createHash('sha256')
121 |     .update(
122 |       JSON.stringify([
123 |         current_content,
124 |         old_string,
125 |         new_string,
126 |         instruction,
127 |         error,
128 |       ]),
129 |     )
130 |     .digest('hex');
131 |   const cachedResult = editCorrectionWithInstructionCache.get(cacheKey);
132 |   if (cachedResult) {
133 |     return cachedResult;
134 |   }
135 |   const userPrompt = EDIT_USER_PROMPT.replace('{instruction}', instruction)
136 |     .replace('{old_string}', old_string)
137 |     .replace('{new_string}', new_string)
138 |     .replace('{error}', error)
139 |     .replace('{current_content}', current_content);
140 | 
141 |   const contents: Content[] = [
142 |     {
143 |       role: 'user',
144 |       parts: [{ text: userPrompt }],
145 |     },
146 |   ];
147 | 
148 |   const result = (await baseLlmClient.generateJson({
149 |     contents,
150 |     schema: SearchReplaceEditSchema,
151 |     abortSignal,
152 |     model: DEFAULT_GEMINI_FLASH_MODEL,
153 |     systemInstruction: EDIT_SYS_PROMPT,
154 |     promptId,
155 |     maxAttempts: 1,
156 |   })) as unknown as SearchReplaceEdit;
157 | 
158 |   editCorrectionWithInstructionCache.set(cacheKey, result);
159 |   return result;
160 | }
161 | 
162 | export function resetLlmEditFixerCaches_TEST_ONLY() {
163 |   editCorrectionWithInstructionCache.clear();
164 | }
```

src/utils/memoryDiscovery.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { vi, describe, it, expect, beforeEach, afterEach } from 'vitest';
8 | import * as fsPromises from 'node:fs/promises';
9 | import * as os from 'node:os';
10 | import * as path from 'node:path';
11 | import { loadServerHierarchicalMemory } from './memoryDiscovery.js';
12 | import {
13 |   setGeminiMdFilename,
14 |   DEFAULT_CONTEXT_FILENAME,
15 | } from '../tools/memoryTool.js';
16 | import { FileDiscoveryService } from '../services/fileDiscoveryService.js';
17 | import { GEMINI_DIR } from './paths.js';
18 | 
19 | vi.mock('os', async (importOriginal) => {
20 |   const actualOs = await importOriginal<typeof os>();
21 |   return {
22 |     ...actualOs,
23 |     homedir: vi.fn(),
24 |   };
25 | });
26 | 
27 | describe('loadServerHierarchicalMemory', () => {
28 |   const DEFAULT_FOLDER_TRUST = true;
29 |   let testRootDir: string;
30 |   let cwd: string;
31 |   let projectRoot: string;
32 |   let homedir: string;
33 | 
34 |   async function createEmptyDir(fullPath: string) {
35 |     await fsPromises.mkdir(fullPath, { recursive: true });
36 |     return fullPath;
37 |   }
38 | 
39 |   async function createTestFile(fullPath: string, fileContents: string) {
40 |     await fsPromises.mkdir(path.dirname(fullPath), { recursive: true });
41 |     await fsPromises.writeFile(fullPath, fileContents);
42 |     return path.resolve(testRootDir, fullPath);
43 |   }
44 | 
45 |   beforeEach(async () => {
46 |     testRootDir = await fsPromises.mkdtemp(
47 |       path.join(os.tmpdir(), 'folder-structure-test-'),
48 |     );
49 | 
50 |     vi.resetAllMocks();
51 |     // Set environment variables to indicate test environment
52 |     vi.stubEnv('NODE_ENV', 'test');
53 |     vi.stubEnv('VITEST', 'true');
54 | 
55 |     projectRoot = await createEmptyDir(path.join(testRootDir, 'project'));
56 |     cwd = await createEmptyDir(path.join(projectRoot, 'src'));
57 |     homedir = await createEmptyDir(path.join(testRootDir, 'userhome'));
58 |     vi.mocked(os.homedir).mockReturnValue(homedir);
59 |   });
60 | 
61 |   afterEach(async () => {
62 |     vi.unstubAllEnvs();
63 |     // Some tests set this to a different value.
64 |     setGeminiMdFilename(DEFAULT_CONTEXT_FILENAME);
65 |     // Clean up the temporary directory to prevent resource leaks.
66 |     // Use maxRetries option for robust cleanup without race conditions
67 |     await fsPromises.rm(testRootDir, {
68 |       recursive: true,
69 |       force: true,
70 |       maxRetries: 3,
71 |       retryDelay: 10,
72 |     });
73 |   });
74 | 
75 |   describe('when untrusted', () => {
76 |     it('does not load context files from untrusted workspaces', async () => {
77 |       await createTestFile(
78 |         path.join(projectRoot, DEFAULT_CONTEXT_FILENAME),
79 |         'Project root memory',
80 |       );
81 |       await createTestFile(
82 |         path.join(cwd, DEFAULT_CONTEXT_FILENAME),
83 |         'Src directory memory',
84 |       );
85 |       const result = await loadServerHierarchicalMemory(
86 |         cwd,
87 |         [],
88 |         false,
89 |         new FileDiscoveryService(projectRoot),
90 |         [],
91 |         false, // untrusted
92 |       );
93 | 
94 |       expect(result).toEqual({
95 |         memoryContent: '',
96 |         fileCount: 0,
97 |         filePaths: [],
98 |       });
99 |     });
100 | 
101 |     it('loads context from outside the untrusted workspace', async () => {
102 |       await createTestFile(
103 |         path.join(projectRoot, DEFAULT_CONTEXT_FILENAME),
104 |         'Project root memory', // Untrusted
105 |       );
106 |       await createTestFile(
107 |         path.join(cwd, DEFAULT_CONTEXT_FILENAME),
108 |         'Src directory memory', // Untrusted
109 |       );
110 | 
111 |       const filepath = path.join(homedir, GEMINI_DIR, DEFAULT_CONTEXT_FILENAME);
112 |       await createTestFile(filepath, 'default context content'); // In user home dir (outside untrusted space).
113 |       const { fileCount, memoryContent, filePaths } =
114 |         await loadServerHierarchicalMemory(
115 |           cwd,
116 |           [],
117 |           false,
118 |           new FileDiscoveryService(projectRoot),
119 |           [],
120 |           false, // untrusted
121 |         );
122 | 
123 |       expect(fileCount).toEqual(1);
124 |       expect(memoryContent).toContain(path.relative(cwd, filepath).toString());
125 |       expect(filePaths).toEqual([filepath]);
126 |     });
127 |   });
128 | 
129 |   it('should return empty memory and count if no context files are found', async () => {
130 |     const result = await loadServerHierarchicalMemory(
131 |       cwd,
132 |       [],
133 |       false,
134 |       new FileDiscoveryService(projectRoot),
135 |       [],
136 |       DEFAULT_FOLDER_TRUST,
137 |     );
138 | 
139 |     expect(result).toEqual({
140 |       memoryContent: '',
141 |       fileCount: 0,
142 |       filePaths: [],
143 |     });
144 |   });
145 | 
146 |   it('should load only the global context file if present and others are not (default filename)', async () => {
147 |     const defaultContextFile = await createTestFile(
148 |       path.join(homedir, GEMINI_DIR, DEFAULT_CONTEXT_FILENAME),
149 |       'default context content',
150 |     );
151 | 
152 |     const result = await loadServerHierarchicalMemory(
153 |       cwd,
154 |       [],
155 |       false,
156 |       new FileDiscoveryService(projectRoot),
157 |       [],
158 |       DEFAULT_FOLDER_TRUST,
159 |     );
160 | 
161 |     expect(result).toEqual({
162 |       memoryContent: `--- Context from: ${path.relative(cwd, defaultContextFile)} ---
163 | default context content
164 | --- End of Context from: ${path.relative(cwd, defaultContextFile)} ---`,
165 |       fileCount: 1,
166 |       filePaths: [defaultContextFile],
167 |     });
168 |   });
169 | 
170 |   it('should load only the global custom context file if present and filename is changed', async () => {
171 |     const customFilename = 'CUSTOM_AGENTS.md';
172 |     setGeminiMdFilename(customFilename);
173 | 
174 |     const customContextFile = await createTestFile(
175 |       path.join(homedir, GEMINI_DIR, customFilename),
176 |       'custom context content',
177 |     );
178 | 
179 |     const result = await loadServerHierarchicalMemory(
180 |       cwd,
181 |       [],
182 |       false,
183 |       new FileDiscoveryService(projectRoot),
184 |       [],
185 |       DEFAULT_FOLDER_TRUST,
186 |     );
187 | 
188 |     expect(result).toEqual({
189 |       memoryContent: `--- Context from: ${path.relative(cwd, customContextFile)} ---
190 | custom context content
191 | --- End of Context from: ${path.relative(cwd, customContextFile)} ---`,
192 |       fileCount: 1,
193 |       filePaths: [customContextFile],
194 |     });
195 |   });
196 | 
197 |   it('should load context files by upward traversal with custom filename', async () => {
198 |     const customFilename = 'PROJECT_CONTEXT.md';
199 |     setGeminiMdFilename(customFilename);
200 | 
201 |     const projectContextFile = await createTestFile(
202 |       path.join(projectRoot, customFilename),
203 |       'project context content',
204 |     );
205 |     const cwdContextFile = await createTestFile(
206 |       path.join(cwd, customFilename),
207 |       'cwd context content',
208 |     );
209 | 
210 |     const result = await loadServerHierarchicalMemory(
211 |       cwd,
212 |       [],
213 |       false,
214 |       new FileDiscoveryService(projectRoot),
215 |       [],
216 |       DEFAULT_FOLDER_TRUST,
217 |     );
218 | 
219 |     expect(result).toEqual({
220 |       memoryContent: `--- Context from: ${path.relative(cwd, projectContextFile)} ---
221 | project context content
222 | --- End of Context from: ${path.relative(cwd, projectContextFile)} ---
223 | 
224 | --- Context from: ${path.relative(cwd, cwdContextFile)} ---
225 | cwd context content
226 | --- End of Context from: ${path.relative(cwd, cwdContextFile)} ---`,
227 |       fileCount: 2,
228 |       filePaths: [projectContextFile, cwdContextFile],
229 |     });
230 |   });
231 | 
232 |   it('should load context files by downward traversal with custom filename', async () => {
233 |     const customFilename = 'LOCAL_CONTEXT.md';
234 |     setGeminiMdFilename(customFilename);
235 | 
236 |     const subdirCustomFile = await createTestFile(
237 |       path.join(cwd, 'subdir', customFilename),
238 |       'Subdir custom memory',
239 |     );
240 |     const cwdCustomFile = await createTestFile(
241 |       path.join(cwd, customFilename),
242 |       'CWD custom memory',
243 |     );
244 | 
245 |     const result = await loadServerHierarchicalMemory(
246 |       cwd,
247 |       [],
248 |       false,
249 |       new FileDiscoveryService(projectRoot),
250 |       [],
251 |       DEFAULT_FOLDER_TRUST,
252 |     );
253 | 
254 |     expect(result).toEqual({
255 |       memoryContent: `--- Context from: ${customFilename} ---
256 | CWD custom memory
257 | --- End of Context from: ${customFilename} ---
258 | 
259 | --- Context from: ${path.join('subdir', customFilename)} ---
260 | Subdir custom memory
261 | --- End of Context from: ${path.join('subdir', customFilename)} ---`,
262 |       fileCount: 2,
263 |       filePaths: [cwdCustomFile, subdirCustomFile],
264 |     });
265 |   });
266 | 
267 |   it('should load ORIGINAL_GEMINI_MD_FILENAME files by upward traversal from CWD to project root', async () => {
268 |     const projectRootGeminiFile = await createTestFile(
269 |       path.join(projectRoot, DEFAULT_CONTEXT_FILENAME),
270 |       'Project root memory',
271 |     );
272 |     const srcGeminiFile = await createTestFile(
273 |       path.join(cwd, DEFAULT_CONTEXT_FILENAME),
274 |       'Src directory memory',
275 |     );
276 | 
277 |     const result = await loadServerHierarchicalMemory(
278 |       cwd,
279 |       [],
280 |       false,
281 |       new FileDiscoveryService(projectRoot),
282 |       [],
283 |       DEFAULT_FOLDER_TRUST,
284 |     );
285 | 
286 |     expect(result).toEqual({
287 |       memoryContent: `--- Context from: ${path.relative(cwd, projectRootGeminiFile)} ---
288 | Project root memory
289 | --- End of Context from: ${path.relative(cwd, projectRootGeminiFile)} ---
290 | 
291 | --- Context from: ${path.relative(cwd, srcGeminiFile)} ---
292 | Src directory memory
293 | --- End of Context from: ${path.relative(cwd, srcGeminiFile)} ---`,
294 |       fileCount: 2,
295 |       filePaths: [projectRootGeminiFile, srcGeminiFile],
296 |     });
297 |   });
298 | 
299 |   it('should load ORIGINAL_GEMINI_MD_FILENAME files by downward traversal from CWD', async () => {
300 |     const subDirGeminiFile = await createTestFile(
301 |       path.join(cwd, 'subdir', DEFAULT_CONTEXT_FILENAME),
302 |       'Subdir memory',
303 |     );
304 |     const cwdGeminiFile = await createTestFile(
305 |       path.join(cwd, DEFAULT_CONTEXT_FILENAME),
306 |       'CWD memory',
307 |     );
308 | 
309 |     const result = await loadServerHierarchicalMemory(
310 |       cwd,
311 |       [],
312 |       false,
313 |       new FileDiscoveryService(projectRoot),
314 |       [],
315 |       DEFAULT_FOLDER_TRUST,
316 |     );
317 | 
318 |     expect(result).toEqual({
319 |       memoryContent: `--- Context from: ${DEFAULT_CONTEXT_FILENAME} ---
320 | CWD memory
321 | --- End of Context from: ${DEFAULT_CONTEXT_FILENAME} ---
322 | 
323 | --- Context from: ${path.join('subdir', DEFAULT_CONTEXT_FILENAME)} ---
324 | Subdir memory
325 | --- End of Context from: ${path.join('subdir', DEFAULT_CONTEXT_FILENAME)} ---`,
326 |       fileCount: 2,
327 |       filePaths: [cwdGeminiFile, subDirGeminiFile],
328 |     });
329 |   });
330 | 
331 |   it('should load and correctly order global, upward, and downward ORIGINAL_GEMINI_MD_FILENAME files', async () => {
332 |     const defaultContextFile = await createTestFile(
333 |       path.join(homedir, GEMINI_DIR, DEFAULT_CONTEXT_FILENAME),
334 |       'default context content',
335 |     );
336 |     const rootGeminiFile = await createTestFile(
337 |       path.join(testRootDir, DEFAULT_CONTEXT_FILENAME),
338 |       'Project parent memory',
339 |     );
340 |     const projectRootGeminiFile = await createTestFile(
341 |       path.join(projectRoot, DEFAULT_CONTEXT_FILENAME),
342 |       'Project root memory',
343 |     );
344 |     const cwdGeminiFile = await createTestFile(
345 |       path.join(cwd, DEFAULT_CONTEXT_FILENAME),
346 |       'CWD memory',
347 |     );
348 |     const subDirGeminiFile = await createTestFile(
349 |       path.join(cwd, 'sub', DEFAULT_CONTEXT_FILENAME),
350 |       'Subdir memory',
351 |     );
352 | 
353 |     const result = await loadServerHierarchicalMemory(
354 |       cwd,
355 |       [],
356 |       false,
357 |       new FileDiscoveryService(projectRoot),
358 |       [],
359 |       DEFAULT_FOLDER_TRUST,
360 |     );
361 | 
362 |     expect(result).toEqual({
363 |       memoryContent: `--- Context from: ${path.relative(cwd, defaultContextFile)} ---
364 | default context content
365 | --- End of Context from: ${path.relative(cwd, defaultContextFile)} ---
366 | 
367 | --- Context from: ${path.relative(cwd, rootGeminiFile)} ---
368 | Project parent memory
369 | --- End of Context from: ${path.relative(cwd, rootGeminiFile)} ---
370 | 
371 | --- Context from: ${path.relative(cwd, projectRootGeminiFile)} ---
372 | Project root memory
373 | --- End of Context from: ${path.relative(cwd, projectRootGeminiFile)} ---
374 | 
375 | --- Context from: ${path.relative(cwd, cwdGeminiFile)} ---
376 | CWD memory
377 | --- End of Context from: ${path.relative(cwd, cwdGeminiFile)} ---
378 | 
379 | --- Context from: ${path.relative(cwd, subDirGeminiFile)} ---
380 | Subdir memory
381 | --- End of Context from: ${path.relative(cwd, subDirGeminiFile)} ---`,
382 |       fileCount: 5,
383 |       filePaths: [
384 |         defaultContextFile,
385 |         rootGeminiFile,
386 |         projectRootGeminiFile,
387 |         cwdGeminiFile,
388 |         subDirGeminiFile,
389 |       ],
390 |     });
391 |   });
392 | 
393 |   it('should ignore specified directories during downward scan', async () => {
394 |     await createEmptyDir(path.join(projectRoot, '.git'));
395 |     await createTestFile(path.join(projectRoot, '.gitignore'), 'node_modules');
396 | 
397 |     await createTestFile(
398 |       path.join(cwd, 'node_modules', DEFAULT_CONTEXT_FILENAME),
399 |       'Ignored memory',
400 |     );
401 |     const regularSubDirGeminiFile = await createTestFile(
402 |       path.join(cwd, 'my_code', DEFAULT_CONTEXT_FILENAME),
403 |       'My code memory',
404 |     );
405 | 
406 |     const result = await loadServerHierarchicalMemory(
407 |       cwd,
408 |       [],
409 |       false,
410 |       new FileDiscoveryService(projectRoot),
411 |       [],
412 |       DEFAULT_FOLDER_TRUST,
413 |       'tree',
414 |       {
415 |         respectGitIgnore: true,
416 |         respectGeminiIgnore: true,
417 |       },
418 |       200, // maxDirs parameter
419 |     );
420 | 
421 |     expect(result).toEqual({
422 |       memoryContent: `--- Context from: ${path.relative(cwd, regularSubDirGeminiFile)} ---
423 | My code memory
424 | --- End of Context from: ${path.relative(cwd, regularSubDirGeminiFile)} ---`,
425 |       fileCount: 1,
426 |       filePaths: [regularSubDirGeminiFile],
427 |     });
428 |   });
429 | 
430 |   it('should respect the maxDirs parameter during downward scan', async () => {
431 |     const consoleDebugSpy = vi
432 |       .spyOn(console, 'debug')
433 |       .mockImplementation(() => {});
434 | 
435 |     // Create directories in parallel for better performance
436 |     const dirPromises = Array.from({ length: 2 }, (_, i) =>
437 |       createEmptyDir(path.join(cwd, `deep_dir_${i}`)),
438 |     );
439 |     await Promise.all(dirPromises);
440 | 
441 |     // Pass the custom limit directly to the function
442 |     await loadServerHierarchicalMemory(
443 |       cwd,
444 |       [],
445 |       true,
446 |       new FileDiscoveryService(projectRoot),
447 |       [],
448 |       DEFAULT_FOLDER_TRUST,
449 |       'tree', // importFormat
450 |       {
451 |         respectGitIgnore: true,
452 |         respectGeminiIgnore: true,
453 |       },
454 |       1, // maxDirs
455 |     );
456 | 
457 |     expect(consoleDebugSpy).toHaveBeenCalledWith(
458 |       expect.stringContaining('[DEBUG] [BfsFileSearch]'),
459 |       expect.stringContaining('Scanning [1/1]:'),
460 |     );
461 | 
462 |     vi.mocked(console.debug).mockRestore();
463 | 
464 |     const result = await loadServerHierarchicalMemory(
465 |       cwd,
466 |       [],
467 |       false,
468 |       new FileDiscoveryService(projectRoot),
469 |       [],
470 |       DEFAULT_FOLDER_TRUST,
471 |     );
472 | 
473 |     expect(result).toEqual({
474 |       memoryContent: '',
475 |       fileCount: 0,
476 |       filePaths: [],
477 |     });
478 |   });
479 | 
480 |   it('should load extension context file paths', async () => {
481 |     const extensionFilePath = await createTestFile(
482 |       path.join(testRootDir, 'extensions/ext1/GEMINI.md'),
483 |       'Extension memory content',
484 |     );
485 | 
486 |     const result = await loadServerHierarchicalMemory(
487 |       cwd,
488 |       [],
489 |       false,
490 |       new FileDiscoveryService(projectRoot),
491 |       [extensionFilePath],
492 |       DEFAULT_FOLDER_TRUST,
493 |     );
494 | 
495 |     expect(result).toEqual({
496 |       memoryContent: `--- Context from: ${path.relative(cwd, extensionFilePath)} ---
497 | Extension memory content
498 | --- End of Context from: ${path.relative(cwd, extensionFilePath)} ---`,
499 |       fileCount: 1,
500 |       filePaths: [extensionFilePath],
501 |     });
502 |   });
503 | 
504 |   it('should load memory from included directories', async () => {
505 |     const includedDir = await createEmptyDir(
506 |       path.join(testRootDir, 'included'),
507 |     );
508 |     const includedFile = await createTestFile(
509 |       path.join(includedDir, DEFAULT_CONTEXT_FILENAME),
510 |       'included directory memory',
511 |     );
512 | 
513 |     const result = await loadServerHierarchicalMemory(
514 |       cwd,
515 |       [includedDir],
516 |       false,
517 |       new FileDiscoveryService(projectRoot),
518 |       [],
519 |       DEFAULT_FOLDER_TRUST,
520 |     );
521 | 
522 |     expect(result).toEqual({
523 |       memoryContent: `--- Context from: ${path.relative(cwd, includedFile)} ---
524 | included directory memory
525 | --- End of Context from: ${path.relative(cwd, includedFile)} ---`,
526 |       fileCount: 1,
527 |       filePaths: [includedFile],
528 |     });
529 |   });
530 | 
531 |   it('should handle multiple directories and files in parallel correctly', async () => {
532 |     // Create multiple test directories with GEMINI.md files
533 |     const numDirs = 5;
534 |     const createdFiles: string[] = [];
535 | 
536 |     for (let i = 0; i < numDirs; i++) {
537 |       const dirPath = await createEmptyDir(
538 |         path.join(testRootDir, `project-${i}`),
539 |       );
540 |       const filePath = await createTestFile(
541 |         path.join(dirPath, DEFAULT_CONTEXT_FILENAME),
542 |         `Content from project ${i}`,
543 |       );
544 |       createdFiles.push(filePath);
545 |     }
546 | 
547 |     // Load memory from all directories
548 |     const result = await loadServerHierarchicalMemory(
549 |       cwd,
550 |       createdFiles.map((f) => path.dirname(f)),
551 |       false,
552 |       new FileDiscoveryService(projectRoot),
553 |       [],
554 |       DEFAULT_FOLDER_TRUST,
555 |     );
556 | 
557 |     // Should have loaded all files
558 |     expect(result.fileCount).toBe(numDirs);
559 |     expect(result.filePaths.length).toBe(numDirs);
560 |     expect(result.filePaths.sort()).toEqual(createdFiles.sort());
561 | 
562 |     // Content should include all project contents
563 |     for (let i = 0; i < numDirs; i++) {
564 |       expect(result.memoryContent).toContain(`Content from project ${i}`);
565 |     }
566 |   });
567 | 
568 |   it('should preserve order and prevent duplicates when processing multiple directories', async () => {
569 |     // Create overlapping directory structure
570 |     const parentDir = await createEmptyDir(path.join(testRootDir, 'parent'));
571 |     const childDir = await createEmptyDir(path.join(parentDir, 'child'));
572 | 
573 |     const parentFile = await createTestFile(
574 |       path.join(parentDir, DEFAULT_CONTEXT_FILENAME),
575 |       'Parent content',
576 |     );
577 |     const childFile = await createTestFile(
578 |       path.join(childDir, DEFAULT_CONTEXT_FILENAME),
579 |       'Child content',
580 |     );
581 | 
582 |     // Include both parent and child directories
583 |     const result = await loadServerHierarchicalMemory(
584 |       parentDir,
585 |       [childDir, parentDir], // Deliberately include duplicates
586 |       false,
587 |       new FileDiscoveryService(projectRoot),
588 |       [],
589 |       DEFAULT_FOLDER_TRUST,
590 |     );
591 | 
592 |     // Should have both files without duplicates
593 |     expect(result.fileCount).toBe(2);
594 |     expect(result.memoryContent).toContain('Parent content');
595 |     expect(result.memoryContent).toContain('Child content');
596 |     expect(result.filePaths.sort()).toEqual([parentFile, childFile].sort());
597 | 
598 |     // Check that files are not duplicated
599 |     const parentOccurrences = (
600 |       result.memoryContent.match(/Parent content/g) || []
601 |     ).length;
602 |     const childOccurrences = (
603 |       result.memoryContent.match(/Child content/g) || []
604 |     ).length;
605 |     expect(parentOccurrences).toBe(1);
606 |     expect(childOccurrences).toBe(1);
607 |   });
608 | });
```

src/utils/memoryDiscovery.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs/promises';
8 | import * as fsSync from 'node:fs';
9 | import * as path from 'node:path';
10 | import { homedir } from 'node:os';
11 | import { bfsFileSearch } from './bfsFileSearch.js';
12 | import { getAllGeminiMdFilenames } from '../tools/memoryTool.js';
13 | import type { FileDiscoveryService } from '../services/fileDiscoveryService.js';
14 | import { processImports } from './memoryImportProcessor.js';
15 | import type { FileFilteringOptions } from '../config/constants.js';
16 | import { DEFAULT_MEMORY_FILE_FILTERING_OPTIONS } from '../config/constants.js';
17 | import { GEMINI_DIR } from './paths.js';
18 | 
19 | // Simple console logger, similar to the one previously in CLI's config.ts
20 | // TODO: Integrate with a more robust server-side logger if available/appropriate.
21 | const logger = {
22 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
23 |   debug: (...args: any[]) =>
24 |     console.debug('[DEBUG] [MemoryDiscovery]', ...args),
25 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
26 |   warn: (...args: any[]) => console.warn('[WARN] [MemoryDiscovery]', ...args),
27 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
28 |   error: (...args: any[]) =>
29 |     console.error('[ERROR] [MemoryDiscovery]', ...args),
30 | };
31 | 
32 | interface GeminiFileContent {
33 |   filePath: string;
34 |   content: string | null;
35 | }
36 | 
37 | async function findProjectRoot(startDir: string): Promise<string | null> {
38 |   let currentDir = path.resolve(startDir);
39 |   while (true) {
40 |     const gitPath = path.join(currentDir, '.git');
41 |     try {
42 |       const stats = await fs.lstat(gitPath);
43 |       if (stats.isDirectory()) {
44 |         return currentDir;
45 |       }
46 |     } catch (error: unknown) {
47 |       // Don't log ENOENT errors as they're expected when .git doesn't exist
48 |       // Also don't log errors in test environments, which often have mocked fs
49 |       const isENOENT =
50 |         typeof error === 'object' &&
51 |         error !== null &&
52 |         'code' in error &&
53 |         (error as { code: string }).code === 'ENOENT';
54 | 
55 |       // Only log unexpected errors in non-test environments
56 |       // process.env['NODE_ENV'] === 'test' or VITEST are common test indicators
57 |       const isTestEnv =
58 |         process.env['NODE_ENV'] === 'test' || process.env['VITEST'];
59 | 
60 |       if (!isENOENT && !isTestEnv) {
61 |         if (typeof error === 'object' && error !== null && 'code' in error) {
62 |           const fsError = error as { code: string; message: string };
63 |           logger.warn(
64 |             `Error checking for .git directory at ${gitPath}: ${fsError.message}`,
65 |           );
66 |         } else {
67 |           logger.warn(
68 |             `Non-standard error checking for .git directory at ${gitPath}: ${String(error)}`,
69 |           );
70 |         }
71 |       }
72 |     }
73 |     const parentDir = path.dirname(currentDir);
74 |     if (parentDir === currentDir) {
75 |       return null;
76 |     }
77 |     currentDir = parentDir;
78 |   }
79 | }
80 | 
81 | async function getGeminiMdFilePathsInternal(
82 |   currentWorkingDirectory: string,
83 |   includeDirectoriesToReadGemini: readonly string[],
84 |   userHomePath: string,
85 |   debugMode: boolean,
86 |   fileService: FileDiscoveryService,
87 |   extensionContextFilePaths: string[] = [],
88 |   folderTrust: boolean,
89 |   fileFilteringOptions: FileFilteringOptions,
90 |   maxDirs: number,
91 | ): Promise<string[]> {
92 |   const dirs = new Set<string>([
93 |     ...includeDirectoriesToReadGemini,
94 |     currentWorkingDirectory,
95 |   ]);
96 | 
97 |   // Process directories in parallel with concurrency limit to prevent EMFILE errors
98 |   const CONCURRENT_LIMIT = 10;
99 |   const dirsArray = Array.from(dirs);
100 |   const pathsArrays: string[][] = [];
101 | 
102 |   for (let i = 0; i < dirsArray.length; i += CONCURRENT_LIMIT) {
103 |     const batch = dirsArray.slice(i, i + CONCURRENT_LIMIT);
104 |     const batchPromises = batch.map((dir) =>
105 |       getGeminiMdFilePathsInternalForEachDir(
106 |         dir,
107 |         userHomePath,
108 |         debugMode,
109 |         fileService,
110 |         extensionContextFilePaths,
111 |         folderTrust,
112 |         fileFilteringOptions,
113 |         maxDirs,
114 |       ),
115 |     );
116 | 
117 |     const batchResults = await Promise.allSettled(batchPromises);
118 | 
119 |     for (const result of batchResults) {
120 |       if (result.status === 'fulfilled') {
121 |         pathsArrays.push(result.value);
122 |       } else {
123 |         const error = result.reason;
124 |         const message = error instanceof Error ? error.message : String(error);
125 |         logger.error(`Error discovering files in directory: ${message}`);
126 |         // Continue processing other directories
127 |       }
128 |     }
129 |   }
130 | 
131 |   const paths = pathsArrays.flat();
132 |   return Array.from(new Set<string>(paths));
133 | }
134 | 
135 | async function getGeminiMdFilePathsInternalForEachDir(
136 |   dir: string,
137 |   userHomePath: string,
138 |   debugMode: boolean,
139 |   fileService: FileDiscoveryService,
140 |   extensionContextFilePaths: string[] = [],
141 |   folderTrust: boolean,
142 |   fileFilteringOptions: FileFilteringOptions,
143 |   maxDirs: number,
144 | ): Promise<string[]> {
145 |   const allPaths = new Set<string>();
146 |   const geminiMdFilenames = getAllGeminiMdFilenames();
147 | 
148 |   for (const geminiMdFilename of geminiMdFilenames) {
149 |     const resolvedHome = path.resolve(userHomePath);
150 |     const globalMemoryPath = path.join(
151 |       resolvedHome,
152 |       GEMINI_DIR,
153 |       geminiMdFilename,
154 |     );
155 | 
156 |     // This part that finds the global file always runs.
157 |     try {
158 |       await fs.access(globalMemoryPath, fsSync.constants.R_OK);
159 |       allPaths.add(globalMemoryPath);
160 |       if (debugMode)
161 |         logger.debug(
162 |           `Found readable global ${geminiMdFilename}: ${globalMemoryPath}`,
163 |         );
164 |     } catch {
165 |       // It's okay if it's not found.
166 |     }
167 | 
168 |     // FIX: Only perform the workspace search (upward and downward scans)
169 |     // if a valid currentWorkingDirectory is provided.
170 |     if (dir && folderTrust) {
171 |       const resolvedCwd = path.resolve(dir);
172 |       if (debugMode)
173 |         logger.debug(
174 |           `Searching for ${geminiMdFilename} starting from CWD: ${resolvedCwd}`,
175 |         );
176 | 
177 |       const projectRoot = await findProjectRoot(resolvedCwd);
178 |       if (debugMode)
179 |         logger.debug(`Determined project root: ${projectRoot ?? 'None'}`);
180 | 
181 |       const upwardPaths: string[] = [];
182 |       let currentDir = resolvedCwd;
183 |       const ultimateStopDir = projectRoot
184 |         ? path.dirname(projectRoot)
185 |         : path.dirname(resolvedHome);
186 | 
187 |       while (currentDir && currentDir !== path.dirname(currentDir)) {
188 |         if (currentDir === path.join(resolvedHome, GEMINI_DIR)) {
189 |           break;
190 |         }
191 | 
192 |         const potentialPath = path.join(currentDir, geminiMdFilename);
193 |         try {
194 |           await fs.access(potentialPath, fsSync.constants.R_OK);
195 |           if (potentialPath !== globalMemoryPath) {
196 |             upwardPaths.unshift(potentialPath);
197 |           }
198 |         } catch {
199 |           // Not found, continue.
200 |         }
201 | 
202 |         if (currentDir === ultimateStopDir) {
203 |           break;
204 |         }
205 | 
206 |         currentDir = path.dirname(currentDir);
207 |       }
208 |       upwardPaths.forEach((p) => allPaths.add(p));
209 | 
210 |       const mergedOptions: FileFilteringOptions = {
211 |         ...DEFAULT_MEMORY_FILE_FILTERING_OPTIONS,
212 |         ...fileFilteringOptions,
213 |       };
214 | 
215 |       const downwardPaths = await bfsFileSearch(resolvedCwd, {
216 |         fileName: geminiMdFilename,
217 |         maxDirs,
218 |         debug: debugMode,
219 |         fileService,
220 |         fileFilteringOptions: mergedOptions,
221 |       });
222 |       downwardPaths.sort();
223 |       for (const dPath of downwardPaths) {
224 |         allPaths.add(dPath);
225 |       }
226 |     }
227 |   }
228 | 
229 |   // Add extension context file paths.
230 |   for (const extensionPath of extensionContextFilePaths) {
231 |     allPaths.add(extensionPath);
232 |   }
233 | 
234 |   const finalPaths = Array.from(allPaths);
235 | 
236 |   if (debugMode)
237 |     logger.debug(
238 |       `Final ordered ${getAllGeminiMdFilenames()} paths to read: ${JSON.stringify(
239 |         finalPaths,
240 |       )}`,
241 |     );
242 |   return finalPaths;
243 | }
244 | 
245 | async function readGeminiMdFiles(
246 |   filePaths: string[],
247 |   debugMode: boolean,
248 |   importFormat: 'flat' | 'tree' = 'tree',
249 | ): Promise<GeminiFileContent[]> {
250 |   // Process files in parallel with concurrency limit to prevent EMFILE errors
251 |   const CONCURRENT_LIMIT = 20; // Higher limit for file reads as they're typically faster
252 |   const results: GeminiFileContent[] = [];
253 | 
254 |   for (let i = 0; i < filePaths.length; i += CONCURRENT_LIMIT) {
255 |     const batch = filePaths.slice(i, i + CONCURRENT_LIMIT);
256 |     const batchPromises = batch.map(
257 |       async (filePath): Promise<GeminiFileContent> => {
258 |         try {
259 |           const content = await fs.readFile(filePath, 'utf-8');
260 | 
261 |           // Process imports in the content
262 |           const processedResult = await processImports(
263 |             content,
264 |             path.dirname(filePath),
265 |             debugMode,
266 |             undefined,
267 |             undefined,
268 |             importFormat,
269 |           );
270 |           if (debugMode)
271 |             logger.debug(
272 |               `Successfully read and processed imports: ${filePath} (Length: ${processedResult.content.length})`,
273 |             );
274 | 
275 |           return { filePath, content: processedResult.content };
276 |         } catch (error: unknown) {
277 |           const isTestEnv =
278 |             process.env['NODE_ENV'] === 'test' || process.env['VITEST'];
279 |           if (!isTestEnv) {
280 |             const message =
281 |               error instanceof Error ? error.message : String(error);
282 |             logger.warn(
283 |               `Warning: Could not read ${getAllGeminiMdFilenames()} file at ${filePath}. Error: ${message}`,
284 |             );
285 |           }
286 |           if (debugMode) logger.debug(`Failed to read: ${filePath}`);
287 |           return { filePath, content: null }; // Still include it with null content
288 |         }
289 |       },
290 |     );
291 | 
292 |     const batchResults = await Promise.allSettled(batchPromises);
293 | 
294 |     for (const result of batchResults) {
295 |       if (result.status === 'fulfilled') {
296 |         results.push(result.value);
297 |       } else {
298 |         // This case shouldn't happen since we catch all errors above,
299 |         // but handle it for completeness
300 |         const error = result.reason;
301 |         const message = error instanceof Error ? error.message : String(error);
302 |         logger.error(`Unexpected error processing file: ${message}`);
303 |       }
304 |     }
305 |   }
306 | 
307 |   return results;
308 | }
309 | 
310 | function concatenateInstructions(
311 |   instructionContents: GeminiFileContent[],
312 |   // CWD is needed to resolve relative paths for display markers
313 |   currentWorkingDirectoryForDisplay: string,
314 | ): string {
315 |   return instructionContents
316 |     .filter((item) => typeof item.content === 'string')
317 |     .map((item) => {
318 |       const trimmedContent = (item.content as string).trim();
319 |       if (trimmedContent.length === 0) {
320 |         return null;
321 |       }
322 |       const displayPath = path.isAbsolute(item.filePath)
323 |         ? path.relative(currentWorkingDirectoryForDisplay, item.filePath)
324 |         : item.filePath;
325 |       return `--- Context from: ${displayPath} ---\n${trimmedContent}\n--- End of Context from: ${displayPath} ---`;
326 |     })
327 |     .filter((block): block is string => block !== null)
328 |     .join('\n\n');
329 | }
330 | 
331 | export interface LoadServerHierarchicalMemoryResponse {
332 |   memoryContent: string;
333 |   fileCount: number;
334 |   filePaths: string[];
335 | }
336 | 
337 | /**
338 |  * Loads hierarchical GEMINI.md files and concatenates their content.
339 |  * This function is intended for use by the server.
340 |  */
341 | export async function loadServerHierarchicalMemory(
342 |   currentWorkingDirectory: string,
343 |   includeDirectoriesToReadGemini: readonly string[],
344 |   debugMode: boolean,
345 |   fileService: FileDiscoveryService,
346 |   extensionContextFilePaths: string[] = [],
347 |   folderTrust: boolean,
348 |   importFormat: 'flat' | 'tree' = 'tree',
349 |   fileFilteringOptions?: FileFilteringOptions,
350 |   maxDirs: number = 200,
351 | ): Promise<LoadServerHierarchicalMemoryResponse> {
352 |   if (debugMode)
353 |     logger.debug(
354 |       `Loading server hierarchical memory for CWD: ${currentWorkingDirectory} (importFormat: ${importFormat})`,
355 |     );
356 | 
357 |   // For the server, homedir() refers to the server process's home.
358 |   // This is consistent with how MemoryTool already finds the global path.
359 |   const userHomePath = homedir();
360 |   const filePaths = await getGeminiMdFilePathsInternal(
361 |     currentWorkingDirectory,
362 |     includeDirectoriesToReadGemini,
363 |     userHomePath,
364 |     debugMode,
365 |     fileService,
366 |     extensionContextFilePaths,
367 |     folderTrust,
368 |     fileFilteringOptions || DEFAULT_MEMORY_FILE_FILTERING_OPTIONS,
369 |     maxDirs,
370 |   );
371 |   if (filePaths.length === 0) {
372 |     if (debugMode)
373 |       logger.debug('No GEMINI.md files found in hierarchy of the workspace.');
374 |     return { memoryContent: '', fileCount: 0, filePaths: [] };
375 |   }
376 |   const contentsWithPaths = await readGeminiMdFiles(
377 |     filePaths,
378 |     debugMode,
379 |     importFormat,
380 |   );
381 |   // Pass CWD for relative path display in concatenated content
382 |   const combinedInstructions = concatenateInstructions(
383 |     contentsWithPaths,
384 |     currentWorkingDirectory,
385 |   );
386 |   if (debugMode)
387 |     logger.debug(
388 |       `Combined instructions length: ${combinedInstructions.length}`,
389 |     );
390 |   if (debugMode && combinedInstructions.length > 0)
391 |     logger.debug(
392 |       `Combined instructions (snippet): ${combinedInstructions.substring(0, 500)}...`,
393 |     );
394 |   return {
395 |     memoryContent: combinedInstructions,
396 |     fileCount: contentsWithPaths.length,
397 |     filePaths,
398 |   };
399 | }
```

src/utils/memoryImportProcessor.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
8 | import * as fs from 'node:fs/promises';
9 | import * as path from 'node:path';
10 | import { marked } from 'marked';
11 | import { processImports, validateImportPath } from './memoryImportProcessor.js';
12 | 
13 | // Helper function to create platform-agnostic test paths
14 | function testPath(...segments: string[]): string {
15 |   // Start with the first segment as is (might be an absolute path on Windows)
16 |   let result = segments[0];
17 | 
18 |   // Join remaining segments with the platform-specific separator
19 |   for (let i = 1; i < segments.length; i++) {
20 |     if (segments[i].startsWith('/') || segments[i].startsWith('\\')) {
21 |       // If segment starts with a separator, remove the trailing separator from the result
22 |       result = path.normalize(result.replace(/[\\/]+$/, '') + segments[i]);
23 |     } else {
24 |       // Otherwise join with the platform separator
25 |       result = path.join(result, segments[i]);
26 |     }
27 |   }
28 | 
29 |   return path.normalize(result);
30 | }
31 | 
32 | vi.mock('fs/promises');
33 | const mockedFs = vi.mocked(fs);
34 | 
35 | // Mock console methods to capture warnings
36 | const originalConsoleWarn = console.warn;
37 | const originalConsoleError = console.error;
38 | const originalConsoleDebug = console.debug;
39 | 
40 | // Helper functions using marked for parsing and validation
41 | const parseMarkdown = (content: string) => marked.lexer(content);
42 | 
43 | const findMarkdownComments = (content: string): string[] => {
44 |   const tokens = parseMarkdown(content);
45 |   const comments: string[] = [];
46 | 
47 |   function walkTokens(tokenList: unknown[]) {
48 |     for (const token of tokenList) {
49 |       const t = token as { type: string; raw: string; tokens?: unknown[] };
50 |       if (t.type === 'html' && t.raw.includes('<!--')) {
51 |         comments.push(t.raw.trim());
52 |       }
53 |       if (t.tokens) {
54 |         walkTokens(t.tokens);
55 |       }
56 |     }
57 |   }
58 | 
59 |   walkTokens(tokens);
60 |   return comments;
61 | };
62 | 
63 | const findCodeBlocks = (
64 |   content: string,
65 | ): Array<{ type: string; content: string }> => {
66 |   const tokens = parseMarkdown(content);
67 |   const codeBlocks: Array<{ type: string; content: string }> = [];
68 | 
69 |   function walkTokens(tokenList: unknown[]) {
70 |     for (const token of tokenList) {
71 |       const t = token as { type: string; text: string; tokens?: unknown[] };
72 |       if (t.type === 'code') {
73 |         codeBlocks.push({
74 |           type: 'code_block',
75 |           content: t.text,
76 |         });
77 |       } else if (t.type === 'codespan') {
78 |         codeBlocks.push({
79 |           type: 'inline_code',
80 |           content: t.text,
81 |         });
82 |       }
83 |       if (t.tokens) {
84 |         walkTokens(t.tokens);
85 |       }
86 |     }
87 |   }
88 | 
89 |   walkTokens(tokens);
90 |   return codeBlocks;
91 | };
92 | 
93 | describe('memoryImportProcessor', () => {
94 |   beforeEach(() => {
95 |     vi.clearAllMocks();
96 |     // Mock console methods
97 |     console.warn = vi.fn();
98 |     console.error = vi.fn();
99 |     console.debug = vi.fn();
100 |   });
101 | 
102 |   afterEach(() => {
103 |     // Restore console methods
104 |     console.warn = originalConsoleWarn;
105 |     console.error = originalConsoleError;
106 |     console.debug = originalConsoleDebug;
107 |   });
108 | 
109 |   describe('processImports', () => {
110 |     it('should process basic md file imports', async () => {
111 |       const content = 'Some content @./test.md more content';
112 |       const basePath = testPath('test', 'path');
113 |       const importedContent = '# Imported Content\nThis is imported.';
114 | 
115 |       mockedFs.access.mockResolvedValue(undefined);
116 |       mockedFs.readFile.mockResolvedValue(importedContent);
117 | 
118 |       const result = await processImports(content, basePath, true);
119 | 
120 |       // Use marked to find HTML comments (import markers)
121 |       const comments = findMarkdownComments(result.content);
122 |       expect(comments.some((c) => c.includes('Imported from: ./test.md'))).toBe(
123 |         true,
124 |       );
125 |       expect(
126 |         comments.some((c) => c.includes('End of import from: ./test.md')),
127 |       ).toBe(true);
128 | 
129 |       // Verify the imported content is present
130 |       expect(result.content).toContain(importedContent);
131 | 
132 |       // Verify the markdown structure is valid
133 |       const tokens = parseMarkdown(result.content);
134 |       expect(tokens).toBeDefined();
135 |       expect(tokens.length).toBeGreaterThan(0);
136 | 
137 |       expect(mockedFs.readFile).toHaveBeenCalledWith(
138 |         path.resolve(basePath, './test.md'),
139 |         'utf-8',
140 |       );
141 |     });
142 | 
143 |     it('should import non-md files just like md files', async () => {
144 |       const content = 'Some content @./instructions.txt more content';
145 |       const basePath = testPath('test', 'path');
146 |       const importedContent =
147 |         '# Instructions\nThis is a text file with markdown.';
148 | 
149 |       mockedFs.access.mockResolvedValue(undefined);
150 |       mockedFs.readFile.mockResolvedValue(importedContent);
151 | 
152 |       const result = await processImports(content, basePath, true);
153 | 
154 |       // Use marked to find import comments
155 |       const comments = findMarkdownComments(result.content);
156 |       expect(
157 |         comments.some((c) => c.includes('Imported from: ./instructions.txt')),
158 |       ).toBe(true);
159 |       expect(
160 |         comments.some((c) =>
161 |           c.includes('End of import from: ./instructions.txt'),
162 |         ),
163 |       ).toBe(true);
164 | 
165 |       // Use marked to parse and validate the imported content structure
166 |       const tokens = parseMarkdown(result.content);
167 | 
168 |       // Find headers in the parsed content
169 |       const headers = tokens.filter((token) => token.type === 'heading');
170 |       expect(
171 |         headers.some((h) => (h as { text: string }).text === 'Instructions'),
172 |       ).toBe(true);
173 | 
174 |       // Verify the imported content is present
175 |       expect(result.content).toContain(importedContent);
176 |       expect(console.warn).not.toHaveBeenCalled();
177 |       expect(mockedFs.readFile).toHaveBeenCalledWith(
178 |         path.resolve(basePath, './instructions.txt'),
179 |         'utf-8',
180 |       );
181 |     });
182 | 
183 |     it('should handle circular imports', async () => {
184 |       const content = 'Content @./circular.md more content';
185 |       const basePath = testPath('test', 'path');
186 |       const circularContent = 'Circular @./main.md content';
187 | 
188 |       mockedFs.access.mockResolvedValue(undefined);
189 |       mockedFs.readFile.mockResolvedValue(circularContent);
190 | 
191 |       // Set up the import state to simulate we're already processing main.md
192 |       const importState = {
193 |         processedFiles: new Set<string>(),
194 |         maxDepth: 10,
195 |         currentDepth: 0,
196 |         currentFile: testPath('test', 'path', 'main.md'), // Simulate we're processing main.md
197 |       };
198 | 
199 |       const result = await processImports(content, basePath, true, importState);
200 | 
201 |       // The circular import should be detected when processing the nested import
202 |       expect(result.content).toContain(
203 |         '<!-- File already processed: ./main.md -->',
204 |       );
205 |     });
206 | 
207 |     it('should handle file not found errors', async () => {
208 |       const content = 'Content @./nonexistent.md more content';
209 |       const basePath = testPath('test', 'path');
210 | 
211 |       mockedFs.access.mockRejectedValue(new Error('File not found'));
212 | 
213 |       const result = await processImports(content, basePath, true);
214 | 
215 |       expect(result.content).toContain(
216 |         '<!-- Import failed: ./nonexistent.md - File not found -->',
217 |       );
218 |       expect(console.error).toHaveBeenCalledWith(
219 |         '[ERROR] [ImportProcessor]',
220 |         'Failed to import ./nonexistent.md: File not found',
221 |       );
222 |     });
223 | 
224 |     it('should respect max depth limit', async () => {
225 |       const content = 'Content @./deep.md more content';
226 |       const basePath = testPath('test', 'path');
227 |       const deepContent = 'Deep @./deeper.md content';
228 | 
229 |       mockedFs.access.mockResolvedValue(undefined);
230 |       mockedFs.readFile.mockResolvedValue(deepContent);
231 | 
232 |       const importState = {
233 |         processedFiles: new Set<string>(),
234 |         maxDepth: 1,
235 |         currentDepth: 1,
236 |       };
237 | 
238 |       const result = await processImports(content, basePath, true, importState);
239 | 
240 |       expect(console.warn).toHaveBeenCalledWith(
241 |         '[WARN] [ImportProcessor]',
242 |         'Maximum import depth (1) reached. Stopping import processing.',
243 |       );
244 |       expect(result.content).toBe(content);
245 |     });
246 | 
247 |     it('should handle nested imports recursively', async () => {
248 |       const content = 'Main @./nested.md content';
249 |       const basePath = testPath('test', 'path');
250 |       const nestedContent = 'Nested @./inner.md content';
251 |       const innerContent = 'Inner content';
252 | 
253 |       mockedFs.access.mockResolvedValue(undefined);
254 |       mockedFs.readFile
255 |         .mockResolvedValueOnce(nestedContent)
256 |         .mockResolvedValueOnce(innerContent);
257 | 
258 |       const result = await processImports(content, basePath, true);
259 | 
260 |       expect(result.content).toContain('<!-- Imported from: ./nested.md -->');
261 |       expect(result.content).toContain('<!-- Imported from: ./inner.md -->');
262 |       expect(result.content).toContain(innerContent);
263 |     });
264 | 
265 |     it('should handle absolute paths in imports', async () => {
266 |       const content = 'Content @/absolute/path/file.md more content';
267 |       const basePath = testPath('test', 'path');
268 |       const importedContent = 'Absolute path content';
269 | 
270 |       mockedFs.access.mockResolvedValue(undefined);
271 |       mockedFs.readFile.mockResolvedValue(importedContent);
272 | 
273 |       const result = await processImports(content, basePath, true);
274 | 
275 |       expect(result.content).toContain(
276 |         '<!-- Import failed: /absolute/path/file.md - Path traversal attempt -->',
277 |       );
278 |     });
279 | 
280 |     it('should handle multiple imports in same content', async () => {
281 |       const content = 'Start @./first.md middle @./second.md end';
282 |       const basePath = testPath('test', 'path');
283 |       const firstContent = 'First content';
284 |       const secondContent = 'Second content';
285 | 
286 |       mockedFs.access.mockResolvedValue(undefined);
287 |       mockedFs.readFile
288 |         .mockResolvedValueOnce(firstContent)
289 |         .mockResolvedValueOnce(secondContent);
290 | 
291 |       const result = await processImports(content, basePath, true);
292 | 
293 |       expect(result.content).toContain('<!-- Imported from: ./first.md -->');
294 |       expect(result.content).toContain('<!-- Imported from: ./second.md -->');
295 |       expect(result.content).toContain(firstContent);
296 |       expect(result.content).toContain(secondContent);
297 |     });
298 | 
299 |     it('should ignore imports inside code blocks', async () => {
300 |       const content = [
301 |         'Normal content @./should-import.md',
302 |         '```',
303 |         'code block with @./should-not-import.md',
304 |         '```',
305 |         'More content @./should-import2.md',
306 |       ].join('\n');
307 |       const projectRoot = testPath('test', 'project');
308 |       const basePath = testPath(projectRoot, 'src');
309 |       const importedContent1 = 'Imported 1';
310 |       const importedContent2 = 'Imported 2';
311 |       // Only the imports outside code blocks should be processed
312 |       mockedFs.access.mockResolvedValue(undefined);
313 |       mockedFs.readFile
314 |         .mockResolvedValueOnce(importedContent1)
315 |         .mockResolvedValueOnce(importedContent2);
316 |       const result = await processImports(
317 |         content,
318 |         basePath,
319 |         true,
320 |         undefined,
321 |         projectRoot,
322 |       );
323 | 
324 |       // Use marked to verify imported content is present
325 |       expect(result.content).toContain(importedContent1);
326 |       expect(result.content).toContain(importedContent2);
327 | 
328 |       // Use marked to find code blocks and verify the import wasn't processed
329 |       const codeBlocks = findCodeBlocks(result.content);
330 |       const hasUnprocessedImport = codeBlocks.some((block) =>
331 |         block.content.includes('@./should-not-import.md'),
332 |       );
333 |       expect(hasUnprocessedImport).toBe(true);
334 | 
335 |       // Verify no import comment was created for the code block import
336 |       const comments = findMarkdownComments(result.content);
337 |       expect(comments.some((c) => c.includes('should-not-import.md'))).toBe(
338 |         false,
339 |       );
340 |     });
341 | 
342 |     it('should ignore imports inside inline code', async () => {
343 |       const content = [
344 |         'Normal content @./should-import.md',
345 |         '`code with import @./should-not-import.md`',
346 |         'More content @./should-import2.md',
347 |       ].join('\n');
348 |       const projectRoot = testPath('test', 'project');
349 |       const basePath = testPath(projectRoot, 'src');
350 |       const importedContent1 = 'Imported 1';
351 |       const importedContent2 = 'Imported 2';
352 |       mockedFs.access.mockResolvedValue(undefined);
353 |       mockedFs.readFile
354 |         .mockResolvedValueOnce(importedContent1)
355 |         .mockResolvedValueOnce(importedContent2);
356 |       const result = await processImports(
357 |         content,
358 |         basePath,
359 |         true,
360 |         undefined,
361 |         projectRoot,
362 |       );
363 | 
364 |       // Verify imported content is present
365 |       expect(result.content).toContain(importedContent1);
366 |       expect(result.content).toContain(importedContent2);
367 | 
368 |       // Use marked to find inline code spans
369 |       const codeBlocks = findCodeBlocks(result.content);
370 |       const inlineCodeSpans = codeBlocks.filter(
371 |         (block) => block.type === 'inline_code',
372 |       );
373 | 
374 |       // Verify the inline code span still contains the unprocessed import
375 |       expect(
376 |         inlineCodeSpans.some((span) =>
377 |           span.content.includes('@./should-not-import.md'),
378 |         ),
379 |       ).toBe(true);
380 | 
381 |       // Verify no import comments were created for inline code imports
382 |       const comments = findMarkdownComments(result.content);
383 |       expect(comments.some((c) => c.includes('should-not-import.md'))).toBe(
384 |         false,
385 |       );
386 |     });
387 | 
388 |     it('should handle nested tokens and non-unique content correctly', async () => {
389 |       // This test verifies the robust findCodeRegions implementation
390 |       // that recursively walks the token tree and handles non-unique content
391 |       const content = [
392 |         'Normal content @./should-import.md',
393 |         'Paragraph with `inline code @./should-not-import.md` and more text.',
394 |         'Another paragraph with the same `inline code @./should-not-import.md` text.',
395 |         'More content @./should-import2.md',
396 |       ].join('\n');
397 |       const projectRoot = testPath('test', 'project');
398 |       const basePath = testPath(projectRoot, 'src');
399 |       const importedContent1 = 'Imported 1';
400 |       const importedContent2 = 'Imported 2';
401 |       mockedFs.access.mockResolvedValue(undefined);
402 |       mockedFs.readFile
403 |         .mockResolvedValueOnce(importedContent1)
404 |         .mockResolvedValueOnce(importedContent2);
405 |       const result = await processImports(
406 |         content,
407 |         basePath,
408 |         true,
409 |         undefined,
410 |         projectRoot,
411 |       );
412 | 
413 |       // Should process imports outside code regions
414 |       expect(result.content).toContain(importedContent1);
415 |       expect(result.content).toContain(importedContent2);
416 | 
417 |       // Should preserve imports inside inline code (both occurrences)
418 |       expect(result.content).toContain('`inline code @./should-not-import.md`');
419 | 
420 |       // Should not have processed the imports inside code regions
421 |       expect(result.content).not.toContain(
422 |         '<!-- Imported from: ./should-not-import.md -->',
423 |       );
424 |     });
425 | 
426 |     it('should not process imports in repeated inline code blocks', async () => {
427 |       const content = '`@noimport` and `@noimport`';
428 |       const projectRoot = testPath('test', 'project');
429 |       const basePath = testPath(projectRoot, 'src');
430 | 
431 |       const result = await processImports(
432 |         content,
433 |         basePath,
434 |         true,
435 |         undefined,
436 |         projectRoot,
437 |       );
438 | 
439 |       expect(result.content).toBe(content);
440 |     });
441 | 
442 |     it('should not import when @ is inside an inline code block', async () => {
443 |       const content =
444 |         'We should not ` @import` when the symbol is inside an inline code string.';
445 |       const testRootDir = testPath('test', 'project');
446 |       const result = await processImports(content, testRootDir);
447 |       expect(result.content).toBe(content);
448 |       expect(result.importTree.imports).toBeUndefined();
449 |     });
450 | 
451 |     it('should allow imports from parent and subdirectories within project root', async () => {
452 |       const content =
453 |         'Parent import: @../parent.md Subdir import: @./components/sub.md';
454 |       const projectRoot = testPath('test', 'project');
455 |       const basePath = testPath(projectRoot, 'src');
456 |       const importedParent = 'Parent file content';
457 |       const importedSub = 'Subdir file content';
458 |       mockedFs.access.mockResolvedValue(undefined);
459 |       mockedFs.readFile
460 |         .mockResolvedValueOnce(importedParent)
461 |         .mockResolvedValueOnce(importedSub);
462 |       const result = await processImports(
463 |         content,
464 |         basePath,
465 |         true,
466 |         undefined,
467 |         projectRoot,
468 |       );
469 |       expect(result.content).toContain(importedParent);
470 |       expect(result.content).toContain(importedSub);
471 |     });
472 | 
473 |     it('should reject imports outside project root', async () => {
474 |       const content = 'Outside import: @../../../etc/passwd';
475 |       const projectRoot = testPath('test', 'project');
476 |       const basePath = testPath(projectRoot, 'src');
477 |       const result = await processImports(
478 |         content,
479 |         basePath,
480 |         true,
481 |         undefined,
482 |         projectRoot,
483 |       );
484 |       expect(result.content).toContain(
485 |         '<!-- Import failed: ../../../etc/passwd - Path traversal attempt -->',
486 |       );
487 |     });
488 | 
489 |     it('should build import tree structure', async () => {
490 |       const content = 'Main content @./nested.md @./simple.md';
491 |       const projectRoot = testPath('test', 'project');
492 |       const basePath = testPath(projectRoot, 'src');
493 |       const nestedContent = 'Nested @./inner.md content';
494 |       const simpleContent = 'Simple content';
495 |       const innerContent = 'Inner content';
496 | 
497 |       mockedFs.access.mockResolvedValue(undefined);
498 |       mockedFs.readFile
499 |         .mockResolvedValueOnce(nestedContent)
500 |         .mockResolvedValueOnce(simpleContent)
501 |         .mockResolvedValueOnce(innerContent);
502 | 
503 |       const result = await processImports(content, basePath, true);
504 | 
505 |       // Use marked to find and validate import comments
506 |       const comments = findMarkdownComments(result.content);
507 |       const importComments = comments.filter((c) =>
508 |         c.includes('Imported from:'),
509 |       );
510 | 
511 |       expect(importComments.some((c) => c.includes('./nested.md'))).toBe(true);
512 |       expect(importComments.some((c) => c.includes('./simple.md'))).toBe(true);
513 |       expect(importComments.some((c) => c.includes('./inner.md'))).toBe(true);
514 | 
515 |       // Use marked to validate the markdown structure is well-formed
516 |       const tokens = parseMarkdown(result.content);
517 |       expect(tokens).toBeDefined();
518 |       expect(tokens.length).toBeGreaterThan(0);
519 | 
520 |       // Verify the content contains expected text using marked parsing
521 |       const textContent = tokens
522 |         .filter((token) => token.type === 'paragraph')
523 |         .map((token) => token.raw)
524 |         .join(' ');
525 | 
526 |       expect(textContent).toContain('Main content');
527 |       expect(textContent).toContain('Nested');
528 |       expect(textContent).toContain('Simple content');
529 |       expect(textContent).toContain('Inner content');
530 | 
531 |       // Verify import tree structure
532 |       expect(result.importTree.path).toBe('unknown'); // No currentFile set in test
533 |       expect(result.importTree.imports).toHaveLength(2);
534 | 
535 |       // First import: nested.md
536 |       // Check that the paths match using includes to handle potential absolute/relative differences
537 |       const expectedNestedPath = testPath(projectRoot, 'src', 'nested.md');
538 | 
539 |       expect(result.importTree.imports![0].path).toContain(expectedNestedPath);
540 |       expect(result.importTree.imports![0].imports).toHaveLength(1);
541 | 
542 |       const expectedInnerPath = testPath(projectRoot, 'src', 'inner.md');
[TRUNCATED]
```

src/utils/memoryImportProcessor.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs/promises';
8 | import * as path from 'node:path';
9 | import { isSubpath } from './paths.js';
10 | import { marked, type Token } from 'marked';
11 | 
12 | // Simple console logger for import processing
13 | const logger = {
14 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
15 |   debug: (...args: any[]) =>
16 |     console.debug('[DEBUG] [ImportProcessor]', ...args),
17 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
18 |   warn: (...args: any[]) => console.warn('[WARN] [ImportProcessor]', ...args),
19 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any
20 |   error: (...args: any[]) =>
21 |     console.error('[ERROR] [ImportProcessor]', ...args),
22 | };
23 | 
24 | /**
25 |  * Interface for tracking import processing state to prevent circular imports
26 |  */
27 | interface ImportState {
28 |   processedFiles: Set<string>;
29 |   maxDepth: number;
30 |   currentDepth: number;
31 |   currentFile?: string; // Track the current file being processed
32 | }
33 | 
34 | /**
35 |  * Interface representing a file in the import tree
36 |  */
37 | export interface MemoryFile {
38 |   path: string;
39 |   imports?: MemoryFile[]; // Direct imports, in the order they were imported
40 | }
41 | 
42 | /**
43 |  * Result of processing imports
44 |  */
45 | export interface ProcessImportsResult {
46 |   content: string;
47 |   importTree: MemoryFile;
48 | }
49 | 
50 | // Helper to find the project root (looks for .git directory)
51 | async function findProjectRoot(startDir: string): Promise<string> {
52 |   let currentDir = path.resolve(startDir);
53 |   while (true) {
54 |     const gitPath = path.join(currentDir, '.git');
55 |     try {
56 |       const stats = await fs.lstat(gitPath);
57 |       if (stats.isDirectory()) {
58 |         return currentDir;
59 |       }
60 |     } catch {
61 |       // .git not found, continue to parent
62 |     }
63 |     const parentDir = path.dirname(currentDir);
64 |     if (parentDir === currentDir) {
65 |       // Reached filesystem root
66 |       break;
67 |     }
68 |     currentDir = parentDir;
69 |   }
70 |   // Fallback to startDir if .git not found
71 |   return path.resolve(startDir);
72 | }
73 | 
74 | // Add a type guard for error objects
75 | function hasMessage(err: unknown): err is { message: string } {
76 |   return (
77 |     typeof err === 'object' &&
78 |     err !== null &&
79 |     'message' in err &&
80 |     typeof (err as { message: unknown }).message === 'string'
81 |   );
82 | }
83 | 
84 | // Helper to find all code block and inline code regions using marked
85 | /**
86 |  * Finds all import statements in content without using regex
87 |  * @returns Array of {start, _end, path} objects for each import found
88 |  */
89 | function findImports(
90 |   content: string,
91 | ): Array<{ start: number; _end: number; path: string }> {
92 |   const imports: Array<{ start: number; _end: number; path: string }> = [];
93 |   let i = 0;
94 |   const len = content.length;
95 | 
96 |   while (i < len) {
97 |     // Find next @ symbol
98 |     i = content.indexOf('@', i);
99 |     if (i === -1) break;
100 | 
101 |     // Check if it's a word boundary (not part of another word)
102 |     if (i > 0 && !isWhitespace(content[i - 1])) {
103 |       i++;
104 |       continue;
105 |     }
106 | 
107 |     // Find the end of the import path (whitespace or newline)
108 |     let j = i + 1;
109 |     while (
110 |       j < len &&
111 |       !isWhitespace(content[j]) &&
112 |       content[j] !== '\n' &&
113 |       content[j] !== '\r'
114 |     ) {
115 |       j++;
116 |     }
117 | 
118 |     // Extract the path (everything after @)
119 |     const importPath = content.slice(i + 1, j);
120 | 
121 |     // Basic validation (starts with ./ or / or letter)
122 |     if (
123 |       importPath.length > 0 &&
124 |       (importPath[0] === '.' ||
125 |         importPath[0] === '/' ||
126 |         isLetter(importPath[0]))
127 |     ) {
128 |       imports.push({
129 |         start: i,
130 |         _end: j,
131 |         path: importPath,
132 |       });
133 |     }
134 | 
135 |     i = j + 1;
136 |   }
137 | 
138 |   return imports;
139 | }
140 | 
141 | function isWhitespace(char: string): boolean {
142 |   return char === ' ' || char === '\t' || char === '\n' || char === '\r';
143 | }
144 | 
145 | function isLetter(char: string): boolean {
146 |   const code = char.charCodeAt(0);
147 |   return (
148 |     (code >= 65 && code <= 90) || // A-Z
149 |     (code >= 97 && code <= 122)
150 |   ); // a-z
151 | }
152 | 
153 | function findCodeRegions(content: string): Array<[number, number]> {
154 |   const regions: Array<[number, number]> = [];
155 |   const tokens = marked.lexer(content);
156 |   let offset = 0;
157 | 
158 |   function walk(token: Token, baseOffset: number) {
159 |     if (token.type === 'code' || token.type === 'codespan') {
160 |       regions.push([baseOffset, baseOffset + token.raw.length]);
161 |     }
162 | 
163 |     if ('tokens' in token && token.tokens) {
164 |       let childOffset = 0;
165 |       for (const child of token.tokens) {
166 |         const childIndexInParent = token.raw.indexOf(child.raw, childOffset);
167 |         if (childIndexInParent === -1) {
168 |           logger.error(
169 |             `Could not find child token in parent raw content. Aborting parsing for this branch. Child raw: "${child.raw}"`,
170 |           );
171 |           break;
172 |         }
173 |         walk(child, baseOffset + childIndexInParent);
174 |         childOffset = childIndexInParent + child.raw.length;
175 |       }
176 |     }
177 |   }
178 | 
179 |   for (const token of tokens) {
180 |     walk(token, offset);
181 |     offset += token.raw.length;
182 |   }
183 | 
184 |   return regions;
185 | }
186 | 
187 | /**
188 |  * Processes import statements in GEMINI.md content
189 |  * Supports @path/to/file syntax for importing content from other files
190 |  * @param content - The content to process for imports
191 |  * @param basePath - The directory path where the current file is located
192 |  * @param debugMode - Whether to enable debug logging
193 |  * @param importState - State tracking for circular import prevention
194 |  * @param projectRoot - The project root directory for allowed directories
195 |  * @param importFormat - The format of the import tree
196 |  * @returns Processed content with imports resolved and import tree
197 |  */
198 | export async function processImports(
199 |   content: string,
200 |   basePath: string,
201 |   debugMode: boolean = false,
202 |   importState: ImportState = {
203 |     processedFiles: new Set(),
204 |     maxDepth: 5,
205 |     currentDepth: 0,
206 |   },
207 |   projectRoot?: string,
208 |   importFormat: 'flat' | 'tree' = 'tree',
209 | ): Promise<ProcessImportsResult> {
210 |   if (!projectRoot) {
211 |     projectRoot = await findProjectRoot(basePath);
212 |   }
213 | 
214 |   if (importState.currentDepth >= importState.maxDepth) {
215 |     if (debugMode) {
216 |       logger.warn(
217 |         `Maximum import depth (${importState.maxDepth}) reached. Stopping import processing.`,
218 |       );
219 |     }
220 |     return {
221 |       content,
222 |       importTree: { path: importState.currentFile || 'unknown' },
223 |     };
224 |   }
225 | 
226 |   // --- FLAT FORMAT LOGIC ---
227 |   if (importFormat === 'flat') {
228 |     // Use a queue to process files in order of first encounter, and a set to avoid duplicates
229 |     const flatFiles: Array<{ path: string; content: string }> = [];
230 |     // Track processed files across the entire operation
231 |     const processedFiles = new Set<string>();
232 | 
233 |     // Helper to recursively process imports
234 |     async function processFlat(
235 |       fileContent: string,
236 |       fileBasePath: string,
237 |       filePath: string,
238 |       depth: number,
239 |     ) {
240 |       // Normalize the file path to ensure consistent comparison
241 |       const normalizedPath = path.normalize(filePath);
242 | 
243 |       // Skip if already processed
244 |       if (processedFiles.has(normalizedPath)) return;
245 | 
246 |       // Mark as processed before processing to prevent infinite recursion
247 |       processedFiles.add(normalizedPath);
248 | 
249 |       // Add this file to the flat list
250 |       flatFiles.push({ path: normalizedPath, content: fileContent });
251 | 
252 |       // Find imports in this file
253 |       const codeRegions = findCodeRegions(fileContent);
254 |       const imports = findImports(fileContent);
255 | 
256 |       // Process imports in reverse order to handle indices correctly
257 |       for (let i = imports.length - 1; i >= 0; i--) {
258 |         const { start, path: importPath } = imports[i];
259 | 
260 |         // Skip if inside a code region
261 |         if (
262 |           codeRegions.some(
263 |             ([regionStart, regionEnd]) =>
264 |               start >= regionStart && start < regionEnd,
265 |           )
266 |         ) {
267 |           continue;
268 |         }
269 | 
270 |         // Validate import path
271 |         if (
272 |           !validateImportPath(importPath, fileBasePath, [projectRoot || ''])
273 |         ) {
274 |           continue;
275 |         }
276 | 
277 |         const fullPath = path.resolve(fileBasePath, importPath);
278 |         const normalizedFullPath = path.normalize(fullPath);
279 | 
280 |         // Skip if already processed
281 |         if (processedFiles.has(normalizedFullPath)) continue;
282 | 
283 |         try {
284 |           await fs.access(fullPath);
285 |           const importedContent = await fs.readFile(fullPath, 'utf-8');
286 | 
287 |           // Process the imported file
288 |           await processFlat(
289 |             importedContent,
290 |             path.dirname(fullPath),
291 |             normalizedFullPath,
292 |             depth + 1,
293 |           );
294 |         } catch (error) {
295 |           if (debugMode) {
296 |             logger.warn(
297 |               `Failed to import ${fullPath}: ${hasMessage(error) ? error.message : 'Unknown error'}`,
298 |             );
299 |           }
300 |           // Continue with other imports even if one fails
301 |         }
302 |       }
303 |     }
304 | 
305 |     // Start with the root file (current file)
306 |     const rootPath = path.normalize(
307 |       importState.currentFile || path.resolve(basePath),
308 |     );
309 |     await processFlat(content, basePath, rootPath, 0);
310 | 
311 |     // Concatenate all unique files in order, Claude-style
312 |     const flatContent = flatFiles
313 |       .map(
314 |         (f) =>
315 |           `--- File: ${f.path} ---\n${f.content.trim()}\n--- End of File: ${f.path} ---`,
316 |       )
317 |       .join('\n\n');
318 | 
319 |     return {
320 |       content: flatContent,
321 |       importTree: { path: rootPath }, // Tree not meaningful in flat mode
322 |     };
323 |   }
324 | 
325 |   // --- TREE FORMAT LOGIC (existing) ---
326 |   const codeRegions = findCodeRegions(content);
327 |   let result = '';
328 |   let lastIndex = 0;
329 |   const imports: MemoryFile[] = [];
330 |   const importsList = findImports(content);
331 | 
332 |   for (const { start, _end, path: importPath } of importsList) {
333 |     // Add content before this import
334 |     result += content.substring(lastIndex, start);
335 |     lastIndex = _end;
336 | 
337 |     // Skip if inside a code region
338 |     if (codeRegions.some(([s, e]) => start >= s && start < e)) {
339 |       result += `@${importPath}`;
340 |       continue;
341 |     }
342 |     // Validate import path to prevent path traversal attacks
343 |     if (!validateImportPath(importPath, basePath, [projectRoot || ''])) {
344 |       result += `<!-- Import failed: ${importPath} - Path traversal attempt -->`;
345 |       continue;
346 |     }
347 |     const fullPath = path.resolve(basePath, importPath);
348 |     if (importState.processedFiles.has(fullPath)) {
349 |       result += `<!-- File already processed: ${importPath} -->`;
350 |       continue;
351 |     }
352 |     try {
353 |       await fs.access(fullPath);
354 |       const fileContent = await fs.readFile(fullPath, 'utf-8');
355 |       // Mark this file as processed for this import chain
356 |       const newImportState: ImportState = {
357 |         ...importState,
358 |         processedFiles: new Set(importState.processedFiles),
359 |         currentDepth: importState.currentDepth + 1,
360 |         currentFile: fullPath,
361 |       };
362 |       newImportState.processedFiles.add(fullPath);
363 |       const imported = await processImports(
364 |         fileContent,
365 |         path.dirname(fullPath),
366 |         debugMode,
367 |         newImportState,
368 |         projectRoot,
369 |         importFormat,
370 |       );
371 |       result += `<!-- Imported from: ${importPath} -->\n${imported.content}\n<!-- End of import from: ${importPath} -->`;
372 |       imports.push(imported.importTree);
373 |     } catch (err: unknown) {
374 |       let message = 'Unknown error';
375 |       if (hasMessage(err)) {
376 |         message = err.message;
377 |       } else if (typeof err === 'string') {
378 |         message = err;
379 |       }
380 |       logger.error(`Failed to import ${importPath}: ${message}`);
381 |       result += `<!-- Import failed: ${importPath} - ${message} -->`;
382 |     }
383 |   }
384 |   // Add any remaining content after the last match
385 |   result += content.substring(lastIndex);
386 | 
387 |   return {
388 |     content: result,
389 |     importTree: {
390 |       path: importState.currentFile || 'unknown',
391 |       imports: imports.length > 0 ? imports : undefined,
392 |     },
393 |   };
394 | }
395 | 
396 | export function validateImportPath(
397 |   importPath: string,
398 |   basePath: string,
399 |   allowedDirectories: string[],
400 | ): boolean {
401 |   // Reject URLs
402 |   if (/^(file|https?):\/\//.test(importPath)) {
403 |     return false;
404 |   }
405 | 
406 |   const resolvedPath = path.resolve(basePath, importPath);
407 | 
408 |   return allowedDirectories.some((allowedDir) =>
409 |     isSubpath(allowedDir, resolvedPath),
410 |   );
411 | }
```

src/utils/messageInspectors.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Content } from '@google/genai';
8 | 
9 | export function isFunctionResponse(content: Content): boolean {
10 |   return (
11 |     content.role === 'user' &&
12 |     !!content.parts &&
13 |     content.parts.every((part) => !!part.functionResponse)
14 |   );
15 | }
16 | 
17 | export function isFunctionCall(content: Content): boolean {
18 |   return (
19 |     content.role === 'model' &&
20 |     !!content.parts &&
21 |     content.parts.every((part) => !!part.functionCall)
22 |   );
23 | }
```

src/utils/nextSpeakerChecker.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Mock } from 'vitest';
8 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
9 | import type { Content } from '@google/genai';
10 | import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';
11 | import { BaseLlmClient } from '../core/baseLlmClient.js';
12 | import type { ContentGenerator } from '../core/contentGenerator.js';
13 | import type { Config } from '../config/config.js';
14 | import type { NextSpeakerResponse } from './nextSpeakerChecker.js';
15 | import { checkNextSpeaker } from './nextSpeakerChecker.js';
16 | import { GeminiChat } from '../core/geminiChat.js';
17 | 
18 | // Mock fs module to prevent actual file system operations during tests
19 | const mockFileSystem = new Map<string, string>();
20 | 
21 | vi.mock('node:fs', () => {
22 |   const fsModule = {
23 |     mkdirSync: vi.fn(),
24 |     writeFileSync: vi.fn((path: string, data: string) => {
25 |       mockFileSystem.set(path, data);
26 |     }),
27 |     readFileSync: vi.fn((path: string) => {
28 |       if (mockFileSystem.has(path)) {
29 |         return mockFileSystem.get(path);
30 |       }
31 |       throw Object.assign(new Error('ENOENT: no such file or directory'), {
32 |         code: 'ENOENT',
33 |       });
34 |     }),
35 |     existsSync: vi.fn((path: string) => mockFileSystem.has(path)),
36 |   };
37 | 
38 |   return {
39 |     default: fsModule,
40 |     ...fsModule,
41 |   };
42 | });
43 | 
44 | // Mock GeminiClient and Config constructor
45 | vi.mock('../core/baseLlmClient.js');
46 | vi.mock('../config/config.js');
47 | 
48 | describe('checkNextSpeaker', () => {
49 |   let chatInstance: GeminiChat;
50 |   let mockConfig: Config;
51 |   let mockBaseLlmClient: BaseLlmClient;
52 |   const abortSignal = new AbortController().signal;
53 |   const promptId = 'test-prompt-id';
54 | 
55 |   beforeEach(() => {
56 |     vi.resetAllMocks();
57 |     mockConfig = {
58 |       getProjectRoot: vi.fn().mockReturnValue('/test/project/root'),
59 |       getSessionId: vi.fn().mockReturnValue('test-session-id'),
60 |       getModel: () => 'test-model',
61 |       storage: {
62 |         getProjectTempDir: vi.fn().mockReturnValue('/test/temp'),
63 |       },
64 |     } as unknown as Config;
65 | 
66 |     mockBaseLlmClient = new BaseLlmClient(
67 |       {
68 |         generateContent: vi.fn(),
69 |         generateContentStream: vi.fn(),
70 |         countTokens: vi.fn(),
71 |         embedContent: vi.fn(),
72 |       } as ContentGenerator,
73 |       mockConfig,
74 |     );
75 | 
76 |     // GeminiChat will receive the mocked instances via the mocked GoogleGenAI constructor
77 |     chatInstance = new GeminiChat(
78 |       mockConfig,
79 |       {},
80 |       [], // initial history
81 |     );
82 | 
83 |     // Spy on getHistory for chatInstance
84 |     vi.spyOn(chatInstance, 'getHistory');
85 |   });
86 | 
87 |   afterEach(() => {
88 |     vi.restoreAllMocks();
89 |   });
90 | 
91 |   it('should return null if history is empty', async () => {
92 |     (chatInstance.getHistory as Mock).mockReturnValue([]);
93 |     const result = await checkNextSpeaker(
94 |       chatInstance,
95 |       mockBaseLlmClient,
96 |       abortSignal,
97 |       promptId,
98 |     );
99 |     expect(result).toBeNull();
100 |     expect(mockBaseLlmClient.generateJson).not.toHaveBeenCalled();
101 |   });
102 | 
103 |   it('should return null if the last speaker was the user', async () => {
104 |     vi.mocked(chatInstance.getHistory).mockReturnValue([
105 |       { role: 'user', parts: [{ text: 'Hello' }] },
106 |     ]);
107 |     const result = await checkNextSpeaker(
108 |       chatInstance,
109 |       mockBaseLlmClient,
110 |       abortSignal,
111 |       promptId,
112 |     );
113 |     expect(result).toBeNull();
114 |     expect(mockBaseLlmClient.generateJson).not.toHaveBeenCalled();
115 |   });
116 | 
117 |   it("should return { next_speaker: 'model' } when model intends to continue", async () => {
118 |     (chatInstance.getHistory as Mock).mockReturnValue([
119 |       { role: 'model', parts: [{ text: 'I will now do something.' }] },
120 |     ] as Content[]);
121 |     const mockApiResponse: NextSpeakerResponse = {
122 |       reasoning: 'Model stated it will do something.',
123 |       next_speaker: 'model',
124 |     };
125 |     (mockBaseLlmClient.generateJson as Mock).mockResolvedValue(mockApiResponse);
126 | 
127 |     const result = await checkNextSpeaker(
128 |       chatInstance,
129 |       mockBaseLlmClient,
130 |       abortSignal,
131 |       promptId,
132 |     );
133 |     expect(result).toEqual(mockApiResponse);
134 |     expect(mockBaseLlmClient.generateJson).toHaveBeenCalledTimes(1);
135 |   });
136 | 
137 |   it("should return { next_speaker: 'user' } when model asks a question", async () => {
138 |     (chatInstance.getHistory as Mock).mockReturnValue([
139 |       { role: 'model', parts: [{ text: 'What would you like to do?' }] },
140 |     ] as Content[]);
141 |     const mockApiResponse: NextSpeakerResponse = {
142 |       reasoning: 'Model asked a question.',
143 |       next_speaker: 'user',
144 |     };
145 |     (mockBaseLlmClient.generateJson as Mock).mockResolvedValue(mockApiResponse);
146 | 
147 |     const result = await checkNextSpeaker(
148 |       chatInstance,
149 |       mockBaseLlmClient,
150 |       abortSignal,
151 |       promptId,
152 |     );
153 |     expect(result).toEqual(mockApiResponse);
154 |   });
155 | 
156 |   it("should return { next_speaker: 'user' } when model makes a statement", async () => {
157 |     (chatInstance.getHistory as Mock).mockReturnValue([
158 |       { role: 'model', parts: [{ text: 'This is a statement.' }] },
159 |     ] as Content[]);
160 |     const mockApiResponse: NextSpeakerResponse = {
161 |       reasoning: 'Model made a statement, awaiting user input.',
162 |       next_speaker: 'user',
163 |     };
164 |     (mockBaseLlmClient.generateJson as Mock).mockResolvedValue(mockApiResponse);
165 | 
166 |     const result = await checkNextSpeaker(
167 |       chatInstance,
168 |       mockBaseLlmClient,
169 |       abortSignal,
170 |       promptId,
171 |     );
172 |     expect(result).toEqual(mockApiResponse);
173 |   });
174 | 
175 |   it('should return null if baseLlmClient.generateJson throws an error', async () => {
176 |     const consoleWarnSpy = vi
177 |       .spyOn(console, 'warn')
178 |       .mockImplementation(() => {});
179 |     (chatInstance.getHistory as Mock).mockReturnValue([
180 |       { role: 'model', parts: [{ text: 'Some model output.' }] },
181 |     ] as Content[]);
182 |     (mockBaseLlmClient.generateJson as Mock).mockRejectedValue(
183 |       new Error('API Error'),
184 |     );
185 | 
186 |     const result = await checkNextSpeaker(
187 |       chatInstance,
188 |       mockBaseLlmClient,
189 |       abortSignal,
190 |       promptId,
191 |     );
192 |     expect(result).toBeNull();
193 |     consoleWarnSpy.mockRestore();
194 |   });
195 | 
196 |   it('should return null if baseLlmClient.generateJson returns invalid JSON (missing next_speaker)', async () => {
197 |     (chatInstance.getHistory as Mock).mockReturnValue([
198 |       { role: 'model', parts: [{ text: 'Some model output.' }] },
199 |     ] as Content[]);
200 |     (mockBaseLlmClient.generateJson as Mock).mockResolvedValue({
201 |       reasoning: 'This is incomplete.',
202 |     } as unknown as NextSpeakerResponse); // Type assertion to simulate invalid response
203 | 
204 |     const result = await checkNextSpeaker(
205 |       chatInstance,
206 |       mockBaseLlmClient,
207 |       abortSignal,
208 |       promptId,
209 |     );
210 |     expect(result).toBeNull();
211 |   });
212 | 
213 |   it('should return null if baseLlmClient.generateJson returns a non-string next_speaker', async () => {
214 |     (chatInstance.getHistory as Mock).mockReturnValue([
215 |       { role: 'model', parts: [{ text: 'Some model output.' }] },
216 |     ] as Content[]);
217 |     (mockBaseLlmClient.generateJson as Mock).mockResolvedValue({
218 |       reasoning: 'Model made a statement, awaiting user input.',
219 |       next_speaker: 123, // Invalid type
220 |     } as unknown as NextSpeakerResponse);
221 | 
222 |     const result = await checkNextSpeaker(
223 |       chatInstance,
224 |       mockBaseLlmClient,
225 |       abortSignal,
226 |       promptId,
227 |     );
228 |     expect(result).toBeNull();
229 |   });
230 | 
231 |   it('should return null if baseLlmClient.generateJson returns an invalid next_speaker string value', async () => {
232 |     (chatInstance.getHistory as Mock).mockReturnValue([
233 |       { role: 'model', parts: [{ text: 'Some model output.' }] },
234 |     ] as Content[]);
235 |     (mockBaseLlmClient.generateJson as Mock).mockResolvedValue({
236 |       reasoning: 'Model made a statement, awaiting user input.',
237 |       next_speaker: 'neither', // Invalid enum value
238 |     } as unknown as NextSpeakerResponse);
239 | 
240 |     const result = await checkNextSpeaker(
241 |       chatInstance,
242 |       mockBaseLlmClient,
243 |       abortSignal,
244 |       promptId,
245 |     );
246 |     expect(result).toBeNull();
247 |   });
248 | 
249 |   it('should call generateJson with the correct parameters', async () => {
250 |     (chatInstance.getHistory as Mock).mockReturnValue([
251 |       { role: 'model', parts: [{ text: 'Some model output.' }] },
252 |     ] as Content[]);
253 |     const mockApiResponse: NextSpeakerResponse = {
254 |       reasoning: 'Model made a statement, awaiting user input.',
255 |       next_speaker: 'user',
256 |     };
257 |     (mockBaseLlmClient.generateJson as Mock).mockResolvedValue(mockApiResponse);
258 | 
259 |     await checkNextSpeaker(
260 |       chatInstance,
261 |       mockBaseLlmClient,
262 |       abortSignal,
263 |       promptId,
264 |     );
265 | 
266 |     expect(mockBaseLlmClient.generateJson).toHaveBeenCalled();
267 |     const generateJsonCall = (mockBaseLlmClient.generateJson as Mock).mock
268 |       .calls[0];
269 |     expect(generateJsonCall[0].model).toBe(DEFAULT_GEMINI_FLASH_MODEL);
270 |     expect(generateJsonCall[0].promptId).toBe(promptId);
271 |   });
272 | });
```

src/utils/nextSpeakerChecker.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Content } from '@google/genai';
8 | import { DEFAULT_GEMINI_FLASH_MODEL } from '../config/models.js';
9 | import type { BaseLlmClient } from '../core/baseLlmClient.js';
10 | import type { GeminiChat } from '../core/geminiChat.js';
11 | import { isFunctionResponse } from './messageInspectors.js';
12 | 
13 | const CHECK_PROMPT = `Analyze *only* the content and structure of your immediately preceding response (your last turn in the conversation history). Based *strictly* on that response, determine who should logically speak next: the 'user' or the 'model' (you).
14 | **Decision Rules (apply in order):**
15 | 1.  **Model Continues:** If your last response explicitly states an immediate next action *you* intend to take (e.g., "Next, I will...", "Now I'll process...", "Moving on to analyze...", indicates an intended tool call that didn't execute), OR if the response seems clearly incomplete (cut off mid-thought without a natural conclusion), then the **'model'** should speak next.
16 | 2.  **Question to User:** If your last response ends with a direct question specifically addressed *to the user*, then the **'user'** should speak next.
17 | 3.  **Waiting for User:** If your last response completed a thought, statement, or task *and* does not meet the criteria for Rule 1 (Model Continues) or Rule 2 (Question to User), it implies a pause expecting user input or reaction. In this case, the **'user'** should speak next.`;
18 | 
19 | const RESPONSE_SCHEMA: Record<string, unknown> = {
20 |   type: 'object',
21 |   properties: {
22 |     reasoning: {
23 |       type: 'string',
24 |       description:
25 |         "Brief explanation justifying the 'next_speaker' choice based *strictly* on the applicable rule and the content/structure of the preceding turn.",
26 |     },
27 |     next_speaker: {
28 |       type: 'string',
29 |       enum: ['user', 'model'],
30 |       description:
31 |         'Who should speak next based *only* on the preceding turn and the decision rules',
32 |     },
33 |   },
34 |   required: ['reasoning', 'next_speaker'],
35 | };
36 | 
37 | export interface NextSpeakerResponse {
38 |   reasoning: string;
39 |   next_speaker: 'user' | 'model';
40 | }
41 | 
42 | export async function checkNextSpeaker(
43 |   chat: GeminiChat,
44 |   baseLlmClient: BaseLlmClient,
45 |   abortSignal: AbortSignal,
46 |   promptId: string,
47 | ): Promise<NextSpeakerResponse | null> {
48 |   // We need to capture the curated history because there are many moments when the model will return invalid turns
49 |   // that when passed back up to the endpoint will break subsequent calls. An example of this is when the model decides
50 |   // to respond with an empty part collection if you were to send that message back to the server it will respond with
51 |   // a 400 indicating that model part collections MUST have content.
52 |   const curatedHistory = chat.getHistory(/* curated */ true);
53 | 
54 |   // Ensure there's a model response to analyze
55 |   if (curatedHistory.length === 0) {
56 |     // Cannot determine next speaker if history is empty.
57 |     return null;
58 |   }
59 | 
60 |   const comprehensiveHistory = chat.getHistory();
61 |   // If comprehensiveHistory is empty, there is no last message to check.
62 |   // This case should ideally be caught by the curatedHistory.length check earlier,
63 |   // but as a safeguard:
64 |   if (comprehensiveHistory.length === 0) {
65 |     return null;
66 |   }
67 |   const lastComprehensiveMessage =
68 |     comprehensiveHistory[comprehensiveHistory.length - 1];
69 | 
70 |   // If the last message is a user message containing only function_responses,
71 |   // then the model should speak next.
72 |   if (
73 |     lastComprehensiveMessage &&
74 |     isFunctionResponse(lastComprehensiveMessage)
75 |   ) {
76 |     return {
77 |       reasoning:
78 |         'The last message was a function response, so the model should speak next.',
79 |       next_speaker: 'model',
80 |     };
81 |   }
82 | 
83 |   if (
84 |     lastComprehensiveMessage &&
85 |     lastComprehensiveMessage.role === 'model' &&
86 |     lastComprehensiveMessage.parts &&
87 |     lastComprehensiveMessage.parts.length === 0
88 |   ) {
89 |     lastComprehensiveMessage.parts.push({ text: '' });
90 |     return {
91 |       reasoning:
92 |         'The last message was a filler model message with no content (nothing for user to act on), model should speak next.',
93 |       next_speaker: 'model',
94 |     };
95 |   }
96 | 
97 |   // Things checked out. Let's proceed to potentially making an LLM request.
98 | 
99 |   const lastMessage = curatedHistory[curatedHistory.length - 1];
100 |   if (!lastMessage || lastMessage.role !== 'model') {
101 |     // Cannot determine next speaker if the last turn wasn't from the model
102 |     // or if history is empty.
103 |     return null;
104 |   }
105 | 
106 |   const contents: Content[] = [
107 |     ...curatedHistory,
108 |     { role: 'user', parts: [{ text: CHECK_PROMPT }] },
109 |   ];
110 | 
111 |   try {
112 |     const parsedResponse = (await baseLlmClient.generateJson({
113 |       contents,
114 |       schema: RESPONSE_SCHEMA,
115 |       model: DEFAULT_GEMINI_FLASH_MODEL,
116 |       abortSignal,
117 |       promptId,
118 |     })) as unknown as NextSpeakerResponse;
119 | 
120 |     if (
121 |       parsedResponse &&
122 |       parsedResponse.next_speaker &&
123 |       ['user', 'model'].includes(parsedResponse.next_speaker)
124 |     ) {
125 |       return parsedResponse;
126 |     }
127 |     return null;
128 |   } catch (error) {
129 |     console.warn(
130 |       'Failed to talk to Gemini endpoint when seeing if conversation should continue.',
131 |       error,
132 |     );
133 |     return null;
134 |   }
135 | }
```

src/utils/partUtils.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import {
9 |   partToString,
10 |   getResponseText,
11 |   flatMapTextParts,
12 |   appendToLastTextPart,
13 | } from './partUtils.js';
14 | import type { GenerateContentResponse, Part, PartUnion } from '@google/genai';
15 | 
16 | const mockResponse = (
17 |   parts?: Array<{ text?: string; functionCall?: unknown }>,
18 | ): GenerateContentResponse => ({
19 |   candidates: parts
20 |     ? [{ content: { parts: parts as Part[], role: 'model' }, index: 0 }]
21 |     : [],
22 |   promptFeedback: { safetyRatings: [] },
23 |   text: undefined,
24 |   data: undefined,
25 |   functionCalls: undefined,
26 |   executableCode: undefined,
27 |   codeExecutionResult: undefined,
28 | });
29 | 
30 | describe('partUtils', () => {
31 |   describe('partToString (default behavior)', () => {
32 |     it('should return empty string for undefined or null', () => {
33 |       // @ts-expect-error Testing invalid input
34 |       expect(partToString(undefined)).toBe('');
35 |       // @ts-expect-error Testing invalid input
36 |       expect(partToString(null)).toBe('');
37 |     });
38 | 
39 |     it('should return string input unchanged', () => {
40 |       expect(partToString('hello')).toBe('hello');
41 |     });
42 | 
43 |     it('should concatenate strings from an array', () => {
44 |       expect(partToString(['a', 'b'])).toBe('ab');
45 |     });
46 | 
47 |     it('should return text property when provided a text part', () => {
48 |       expect(partToString({ text: 'hi' })).toBe('hi');
49 |     });
50 | 
51 |     it('should return empty string for non-text parts', () => {
52 |       const part: Part = { inlineData: { mimeType: 'image/png', data: '' } };
53 |       expect(partToString(part)).toBe('');
54 |       const part2: Part = { functionCall: { name: 'test' } };
55 |       expect(partToString(part2)).toBe('');
56 |     });
57 |   });
58 | 
59 |   describe('partToString (verbose)', () => {
60 |     const verboseOptions = { verbose: true };
61 | 
62 |     it('should return empty string for undefined or null', () => {
63 |       // @ts-expect-error Testing invalid input
64 |       expect(partToString(undefined, verboseOptions)).toBe('');
65 |       // @ts-expect-error Testing invalid input
66 |       expect(partToString(null, verboseOptions)).toBe('');
67 |     });
68 | 
69 |     it('should return string input unchanged', () => {
70 |       expect(partToString('hello', verboseOptions)).toBe('hello');
71 |     });
72 | 
73 |     it('should join parts if the value is an array', () => {
74 |       const parts = ['hello', { text: ' world' }];
75 |       expect(partToString(parts, verboseOptions)).toBe('hello world');
76 |     });
77 | 
78 |     it('should return the text property if the part is an object with text', () => {
79 |       const part: Part = { text: 'hello world' };
80 |       expect(partToString(part, verboseOptions)).toBe('hello world');
81 |     });
82 | 
83 |     it('should return descriptive string for videoMetadata part', () => {
84 |       const part = { videoMetadata: {} } as Part;
85 |       expect(partToString(part, verboseOptions)).toBe('[Video Metadata]');
86 |     });
87 | 
88 |     it('should return descriptive string for thought part', () => {
89 |       const part = { thought: 'thinking' } as unknown as Part;
90 |       expect(partToString(part, verboseOptions)).toBe('[Thought: thinking]');
91 |     });
92 | 
93 |     it('should return descriptive string for codeExecutionResult part', () => {
94 |       const part = { codeExecutionResult: {} } as Part;
95 |       expect(partToString(part, verboseOptions)).toBe(
96 |         '[Code Execution Result]',
97 |       );
98 |     });
99 | 
100 |     it('should return descriptive string for executableCode part', () => {
101 |       const part = { executableCode: {} } as Part;
102 |       expect(partToString(part, verboseOptions)).toBe('[Executable Code]');
103 |     });
104 | 
105 |     it('should return descriptive string for fileData part', () => {
106 |       const part = { fileData: {} } as Part;
107 |       expect(partToString(part, verboseOptions)).toBe('[File Data]');
108 |     });
109 | 
110 |     it('should return descriptive string for functionCall part', () => {
111 |       const part = { functionCall: { name: 'myFunction' } } as Part;
112 |       expect(partToString(part, verboseOptions)).toBe(
113 |         '[Function Call: myFunction]',
114 |       );
115 |     });
116 | 
117 |     it('should return descriptive string for functionResponse part', () => {
118 |       const part = { functionResponse: { name: 'myFunction' } } as Part;
119 |       expect(partToString(part, verboseOptions)).toBe(
120 |         '[Function Response: myFunction]',
121 |       );
122 |     });
123 | 
124 |     it('should return descriptive string for inlineData part', () => {
125 |       const part = { inlineData: { mimeType: 'image/png', data: '' } } as Part;
126 |       expect(partToString(part, verboseOptions)).toBe('<image/png>');
127 |     });
128 | 
129 |     it('should return an empty string for an unknown part type', () => {
130 |       const part: Part = {};
131 |       expect(partToString(part, verboseOptions)).toBe('');
132 |     });
133 | 
134 |     it('should handle complex nested arrays with various part types', () => {
135 |       const parts = [
136 |         'start ',
137 |         { text: 'middle' },
138 |         [
139 |           { functionCall: { name: 'func1' } },
140 |           ' end',
141 |           { inlineData: { mimeType: 'audio/mp3', data: '' } },
142 |         ],
143 |       ];
144 |       expect(partToString(parts as Part, verboseOptions)).toBe(
145 |         'start middle[Function Call: func1] end<audio/mp3>',
146 |       );
147 |     });
148 |   });
149 | 
150 |   describe('getResponseText', () => {
151 |     it('should return null when no candidates exist', () => {
152 |       const response = mockResponse(undefined);
153 |       expect(getResponseText(response)).toBeNull();
154 |     });
155 | 
156 |     it('should return concatenated text from first candidate', () => {
157 |       const result = mockResponse([{ text: 'a' }, { text: 'b' }]);
158 |       expect(getResponseText(result)).toBe('ab');
159 |     });
160 | 
161 |     it('should ignore parts without text', () => {
162 |       const result = mockResponse([{ functionCall: {} }, { text: 'hello' }]);
163 |       expect(getResponseText(result)).toBe('hello');
164 |     });
165 | 
166 |     it('should return null when candidate has no parts', () => {
167 |       const result = mockResponse([]);
168 |       expect(getResponseText(result)).toBeNull();
169 |     });
170 | 
171 |     it('should return null if the first candidate has no content property', () => {
172 |       const response: GenerateContentResponse = {
173 |         candidates: [
174 |           {
175 |             index: 0,
176 |           },
177 |         ],
178 |         promptFeedback: { safetyRatings: [] },
179 |         text: undefined,
180 |         data: undefined,
181 |         functionCalls: undefined,
182 |         executableCode: undefined,
183 |         codeExecutionResult: undefined,
184 |       };
185 |       expect(getResponseText(response)).toBeNull();
186 |     });
187 |   });
188 | 
189 |   describe('flatMapTextParts', () => {
190 |     // A simple async transform function that splits a string into character parts.
191 |     const splitCharsTransform = async (text: string): Promise<PartUnion[]> =>
192 |       text.split('').map((char) => ({ text: char }));
193 | 
194 |     it('should return an empty array for empty input', async () => {
195 |       const result = await flatMapTextParts([], splitCharsTransform);
196 |       expect(result).toEqual([]);
197 |     });
198 | 
199 |     it('should transform a simple string input', async () => {
200 |       const result = await flatMapTextParts('hi', splitCharsTransform);
201 |       expect(result).toEqual([{ text: 'h' }, { text: 'i' }]);
202 |     });
203 | 
204 |     it('should transform a single text part object', async () => {
205 |       const result = await flatMapTextParts(
206 |         { text: 'cat' },
207 |         splitCharsTransform,
208 |       );
209 |       expect(result).toEqual([{ text: 'c' }, { text: 'a' }, { text: 't' }]);
210 |     });
211 | 
212 |     it('should transform an array of text parts and flatten the result', async () => {
213 |       // A transform that duplicates the text to test the "flatMap" behavior.
214 |       const duplicateTransform = async (text: string): Promise<PartUnion[]> => [
215 |         { text: `${text}` },
216 |         { text: `${text}` },
217 |       ];
218 |       const parts = [{ text: 'a' }, { text: 'b' }];
219 |       const result = await flatMapTextParts(parts, duplicateTransform);
220 |       expect(result).toEqual([
221 |         { text: 'a' },
222 |         { text: 'a' },
223 |         { text: 'b' },
224 |         { text: 'b' },
225 |       ]);
226 |     });
227 | 
228 |     it('should pass through non-text parts unmodified', async () => {
229 |       const nonTextPart: Part = { functionCall: { name: 'do_stuff' } };
230 |       const result = await flatMapTextParts(nonTextPart, splitCharsTransform);
231 |       expect(result).toEqual([nonTextPart]);
232 |     });
233 | 
234 |     it('should handle a mix of text and non-text parts in an array', async () => {
235 |       const nonTextPart: Part = {
236 |         inlineData: { mimeType: 'image/jpeg', data: '' },
237 |       };
238 |       const parts: PartUnion[] = [{ text: 'go' }, nonTextPart, ' stop'];
239 |       const result = await flatMapTextParts(parts, splitCharsTransform);
240 |       expect(result).toEqual([
241 |         { text: 'g' },
242 |         { text: 'o' },
243 |         nonTextPart, // Should be passed through
244 |         { text: ' ' },
245 |         { text: 's' },
246 |         { text: 't' },
247 |         { text: 'o' },
248 |         { text: 'p' },
249 |       ]);
250 |     });
251 | 
252 |     it('should handle a transform that returns an empty array', async () => {
253 |       const removeTransform = async (_text: string): Promise<PartUnion[]> => [];
254 |       const parts: PartUnion[] = [
255 |         { text: 'remove' },
256 |         { functionCall: { name: 'keep' } },
257 |       ];
258 |       const result = await flatMapTextParts(parts, removeTransform);
259 |       expect(result).toEqual([{ functionCall: { name: 'keep' } }]);
260 |     });
261 |   });
262 | 
263 |   describe('appendToLastTextPart', () => {
264 |     it('should append to an empty prompt', () => {
265 |       const prompt: PartUnion[] = [];
266 |       const result = appendToLastTextPart(prompt, 'new text');
267 |       expect(result).toEqual([{ text: 'new text' }]);
268 |     });
269 | 
270 |     it('should append to a prompt with a string as the last part', () => {
271 |       const prompt: PartUnion[] = ['first part'];
272 |       const result = appendToLastTextPart(prompt, 'new text');
273 |       expect(result).toEqual(['first part\n\nnew text']);
274 |     });
275 | 
276 |     it('should append to a prompt with a text part object as the last part', () => {
277 |       const prompt: PartUnion[] = [{ text: 'first part' }];
278 |       const result = appendToLastTextPart(prompt, 'new text');
279 |       expect(result).toEqual([{ text: 'first part\n\nnew text' }]);
280 |     });
281 | 
282 |     it('should append a new text part if the last part is not a text part', () => {
283 |       const nonTextPart: Part = { functionCall: { name: 'do_stuff' } };
284 |       const prompt: PartUnion[] = [nonTextPart];
285 |       const result = appendToLastTextPart(prompt, 'new text');
286 |       expect(result).toEqual([nonTextPart, { text: '\n\nnew text' }]);
287 |     });
288 | 
289 |     it('should not append anything if the text to append is empty', () => {
290 |       const prompt: PartUnion[] = ['first part'];
291 |       const result = appendToLastTextPart(prompt, '');
292 |       expect(result).toEqual(['first part']);
293 |     });
294 | 
295 |     it('should use a custom separator', () => {
296 |       const prompt: PartUnion[] = ['first part'];
297 |       const result = appendToLastTextPart(prompt, 'new text', '---');
298 |       expect(result).toEqual(['first part---new text']);
299 |     });
300 |   });
301 | });
```

src/utils/partUtils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type {
8 |   GenerateContentResponse,
9 |   PartListUnion,
10 |   Part,
11 |   PartUnion,
12 | } from '@google/genai';
13 | 
14 | /**
15 |  * Converts a PartListUnion into a string.
16 |  * If verbose is true, includes summary representations of non-text parts.
17 |  */
18 | export function partToString(
19 |   value: PartListUnion,
20 |   options?: { verbose?: boolean },
21 | ): string {
22 |   if (!value) {
23 |     return '';
24 |   }
25 |   if (typeof value === 'string') {
26 |     return value;
27 |   }
28 |   if (Array.isArray(value)) {
29 |     return value.map((part) => partToString(part, options)).join('');
30 |   }
31 | 
32 |   // Cast to Part, assuming it might contain project-specific fields
33 |   const part = value as Part & {
34 |     videoMetadata?: unknown;
35 |     thought?: string;
36 |     codeExecutionResult?: unknown;
37 |     executableCode?: unknown;
38 |   };
39 | 
40 |   if (options?.verbose) {
41 |     if (part.videoMetadata !== undefined) {
42 |       return `[Video Metadata]`;
43 |     }
44 |     if (part.thought !== undefined) {
45 |       return `[Thought: ${part.thought}]`;
46 |     }
47 |     if (part.codeExecutionResult !== undefined) {
48 |       return `[Code Execution Result]`;
49 |     }
50 |     if (part.executableCode !== undefined) {
51 |       return `[Executable Code]`;
52 |     }
53 | 
54 |     // Standard Part fields
55 |     if (part.fileData !== undefined) {
56 |       return `[File Data]`;
57 |     }
58 |     if (part.functionCall !== undefined) {
59 |       return `[Function Call: ${part.functionCall.name}]`;
60 |     }
61 |     if (part.functionResponse !== undefined) {
62 |       return `[Function Response: ${part.functionResponse.name}]`;
63 |     }
64 |     if (part.inlineData !== undefined) {
65 |       return `<${part.inlineData.mimeType}>`;
66 |     }
67 |   }
68 | 
69 |   return part.text ?? '';
70 | }
71 | 
72 | export function getResponseText(
73 |   response: GenerateContentResponse,
74 | ): string | null {
75 |   if (response.candidates && response.candidates.length > 0) {
76 |     const candidate = response.candidates[0];
77 | 
78 |     if (
79 |       candidate.content &&
80 |       candidate.content.parts &&
81 |       candidate.content.parts.length > 0
82 |     ) {
83 |       return candidate.content.parts
84 |         .filter((part) => part.text)
85 |         .map((part) => part.text)
86 |         .join('');
87 |     }
88 |   }
89 |   return null;
90 | }
91 | 
92 | /**
93 |  * Asynchronously maps over a PartListUnion, applying a transformation function
94 |  * to the text content of each text-based part.
95 |  *
96 |  * @param parts The PartListUnion to process.
97 |  * @param transform A function that takes a string of text and returns a Promise
98 |  *   resolving to an array of new PartUnions.
99 |  * @returns A Promise that resolves to a new array of PartUnions with the
100 |  *   transformations applied.
101 |  */
102 | export async function flatMapTextParts(
103 |   parts: PartListUnion,
104 |   transform: (text: string) => Promise<PartUnion[]>,
105 | ): Promise<PartUnion[]> {
106 |   const result: PartUnion[] = [];
107 |   const partArray = Array.isArray(parts)
108 |     ? parts
109 |     : typeof parts === 'string'
110 |       ? [{ text: parts }]
111 |       : [parts];
112 | 
113 |   for (const part of partArray) {
114 |     let textToProcess: string | undefined;
115 |     if (typeof part === 'string') {
116 |       textToProcess = part;
117 |     } else if ('text' in part) {
118 |       textToProcess = part.text;
119 |     }
120 | 
121 |     if (textToProcess !== undefined) {
122 |       const transformedParts = await transform(textToProcess);
123 |       result.push(...transformedParts);
124 |     } else {
125 |       // Pass through non-text parts unmodified.
126 |       result.push(part);
127 |     }
128 |   }
129 |   return result;
130 | }
131 | 
132 | /**
133 |  * Appends a string of text to the last text part of a prompt, or adds a new
134 |  * text part if the last part is not a text part.
135 |  *
136 |  * @param prompt The prompt to modify.
137 |  * @param textToAppend The text to append to the prompt.
138 |  * @param separator The separator to add between existing text and the new text.
139 |  * @returns The modified prompt.
140 |  */
141 | export function appendToLastTextPart(
142 |   prompt: PartUnion[],
143 |   textToAppend: string,
144 |   separator = '\n\n',
145 | ): PartUnion[] {
146 |   if (!textToAppend) {
147 |     return prompt;
148 |   }
149 | 
150 |   if (prompt.length === 0) {
151 |     return [{ text: textToAppend }];
152 |   }
153 | 
154 |   const newPrompt = [...prompt];
155 |   const lastPart = newPrompt.at(-1);
156 | 
157 |   if (typeof lastPart === 'string') {
158 |     newPrompt[newPrompt.length - 1] = `${lastPart}${separator}${textToAppend}`;
159 |   } else if (lastPart && 'text' in lastPart) {
160 |     newPrompt[newPrompt.length - 1] = {
161 |       ...lastPart,
162 |       text: `${lastPart.text}${separator}${textToAppend}`,
163 |     };
164 |   } else {
165 |     newPrompt.push({ text: `${separator}${textToAppend}` });
166 |   }
167 | 
168 |   return newPrompt;
169 | }
```

src/utils/pathCorrector.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
8 | import * as fs from 'node:fs';
9 | import * as path from 'node:path';
10 | import * as os from 'node:os';
11 | import type { Config } from '../config/config.js';
12 | import { createMockWorkspaceContext } from '../test-utils/mockWorkspaceContext.js';
13 | import { StandardFileSystemService } from '../services/fileSystemService.js';
14 | import { correctPath } from './pathCorrector.js';
15 | 
16 | describe('pathCorrector', () => {
17 |   let tempDir: string;
18 |   let rootDir: string;
19 |   let otherWorkspaceDir: string;
20 |   let mockConfig: Config;
21 | 
22 |   beforeEach(() => {
23 |     tempDir = fs.mkdtempSync(path.join(os.tmpdir(), 'path-corrector-test-'));
24 |     rootDir = path.join(tempDir, 'root');
25 |     otherWorkspaceDir = path.join(tempDir, 'other');
26 |     fs.mkdirSync(rootDir, { recursive: true });
27 |     fs.mkdirSync(otherWorkspaceDir, { recursive: true });
28 | 
29 |     mockConfig = {
30 |       getTargetDir: () => rootDir,
31 |       getWorkspaceContext: () =>
32 |         createMockWorkspaceContext(rootDir, [otherWorkspaceDir]),
33 |       getFileSystemService: () => new StandardFileSystemService(),
34 |     } as unknown as Config;
35 |   });
36 | 
37 |   afterEach(() => {
38 |     fs.rmSync(tempDir, { recursive: true, force: true });
39 |     vi.restoreAllMocks();
40 |   });
41 | 
42 |   it('should correct a relative path if it is unambiguous in the target dir', () => {
43 |     const testFile = 'unique.txt';
44 |     fs.writeFileSync(path.join(rootDir, testFile), 'content');
45 | 
46 |     const result = correctPath(testFile, mockConfig);
47 | 
48 |     expect(result.success).toBe(true);
49 |     if (result.success) {
50 |       expect(result.correctedPath).toBe(path.join(rootDir, testFile));
51 |     }
52 |   });
53 | 
54 |   it('should correct a partial relative path if it is unambiguous in another workspace dir', () => {
55 |     const subDir = path.join(otherWorkspaceDir, 'sub');
56 |     fs.mkdirSync(subDir);
57 |     const testFile = 'file.txt';
58 |     const fullPath = path.join(subDir, testFile);
59 |     fs.writeFileSync(fullPath, 'content');
60 | 
61 |     const result = correctPath(testFile, mockConfig);
62 | 
63 |     expect(result.success).toBe(true);
64 |     if (result.success) {
65 |       expect(result.correctedPath).toBe(fullPath);
66 |     }
67 |   });
68 | 
69 |   it('should return an error for a relative path that does not exist', () => {
70 |     const result = correctPath('nonexistent.txt', mockConfig);
71 |     expect(result.success).toBe(false);
72 |     if (!result.success) {
73 |       expect(result.error).toMatch(
74 |         /File not found for 'nonexistent.txt' and path is not absolute./,
75 |       );
76 |     } else {
77 |       expect.fail('Expected path correction to fail.');
78 |     }
79 |   });
80 | 
81 |   it('should return an error for an ambiguous path', () => {
82 |     const ambiguousFile = 'component.ts';
83 |     const subDir1 = path.join(rootDir, 'module1');
84 |     const subDir2 = path.join(otherWorkspaceDir, 'module2');
85 |     fs.mkdirSync(subDir1, { recursive: true });
86 |     fs.mkdirSync(subDir2, { recursive: true });
87 |     fs.writeFileSync(path.join(subDir1, ambiguousFile), 'content 1');
88 |     fs.writeFileSync(path.join(subDir2, ambiguousFile), 'content 2');
89 | 
90 |     const result = correctPath(ambiguousFile, mockConfig);
91 | 
92 |     expect(result.success).toBe(false);
93 |     if (!result.success) {
94 |       expect(result.error).toMatch(
95 |         /The file path 'component.ts' is ambiguous and matches multiple files./,
96 |       );
97 |     } else {
98 |       expect.fail('Expected path correction to fail.');
99 |     }
100 |   });
101 | });
```

src/utils/pathCorrector.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import * as fs from 'node:fs';
8 | import * as path from 'node:path';
9 | import type { Config } from '../config/config.js';
10 | 
11 | type SuccessfulPathCorrection = {
12 |   success: true;
13 |   correctedPath: string;
14 | };
15 | 
16 | type FailedPathCorrection = {
17 |   success: false;
18 |   error: string;
19 | };
20 | 
21 | /**
22 |  * Attempts to correct a relative or ambiguous file path to a single, absolute path
23 |  * within the workspace.
24 |  *
25 |  * @param filePath The file path to correct.
26 |  * @param config The application configuration.
27 |  * @returns A `PathCorrectionResult` object with either a `correctedPath` or an `error`.
28 |  */
29 | export type PathCorrectionResult =
30 |   | SuccessfulPathCorrection
31 |   | FailedPathCorrection;
32 | export function correctPath(
33 |   filePath: string,
34 |   config: Config,
35 | ): PathCorrectionResult {
36 |   // Check for direct path relative to the primary target directory.
37 |   const directPath = path.join(config.getTargetDir(), filePath);
38 |   if (fs.existsSync(directPath)) {
39 |     return { success: true, correctedPath: directPath };
40 |   }
41 | 
42 |   // If not found directly, search across all workspace directories for ambiguous matches.
43 |   const workspaceContext = config.getWorkspaceContext();
44 |   const fileSystem = config.getFileSystemService();
45 |   const searchPaths = workspaceContext.getDirectories();
46 |   const foundFiles = fileSystem.findFiles(filePath, searchPaths);
47 | 
48 |   if (foundFiles.length === 0) {
49 |     return {
50 |       success: false,
51 |       error: `File not found for '${filePath}' and path is not absolute.`,
52 |     };
53 |   }
54 | 
55 |   if (foundFiles.length > 1) {
56 |     return {
57 |       success: false,
58 |       error: `The file path '${filePath}' is ambiguous and matches multiple files. Please provide a more specific path. Matches: ${foundFiles.join(', ')}`,
59 |     };
60 |   }
61 | 
62 |   return { success: true, correctedPath: foundFiles[0] };
63 | }
```

src/utils/pathReader.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, afterEach, vi } from 'vitest';
8 | import mock from 'mock-fs';
9 | import * as path from 'node:path';
10 | import { WorkspaceContext } from './workspaceContext.js';
11 | import { readPathFromWorkspace } from './pathReader.js';
12 | import type { Config } from '../config/config.js';
13 | import { StandardFileSystemService } from '../services/fileSystemService.js';
14 | import type { FileDiscoveryService } from '../services/fileDiscoveryService.js';
15 | 
16 | // --- Helper for creating a mock Config object ---
17 | // We use the actual implementations of WorkspaceContext and FileSystemService
18 | // to test the integration against mock-fs.
19 | const createMockConfig = (
20 |   cwd: string,
21 |   otherDirs: string[] = [],
22 |   mockFileService?: FileDiscoveryService,
23 | ): Config => {
24 |   const workspace = new WorkspaceContext(cwd, otherDirs);
25 |   const fileSystemService = new StandardFileSystemService();
26 |   return {
27 |     getWorkspaceContext: () => workspace,
28 |     // TargetDir is used by processSingleFileContent to generate relative paths in errors/output
29 |     getTargetDir: () => cwd,
30 |     getFileSystemService: () => fileSystemService,
31 |     getFileService: () => mockFileService,
32 |   } as unknown as Config;
33 | };
34 | 
35 | describe('readPathFromWorkspace', () => {
36 |   const CWD = path.resolve('/test/cwd');
37 |   const OTHER_DIR = path.resolve('/test/other');
38 |   const OUTSIDE_DIR = path.resolve('/test/outside');
39 | 
40 |   afterEach(() => {
41 |     mock.restore();
42 |     vi.resetAllMocks();
43 |   });
44 | 
45 |   it('should read a text file from the CWD', async () => {
46 |     mock({
47 |       [CWD]: {
48 |         'file.txt': 'hello from cwd',
49 |       },
50 |     });
51 |     const mockFileService = {
52 |       filterFiles: vi.fn((files) => files),
53 |     } as unknown as FileDiscoveryService;
54 |     const config = createMockConfig(CWD, [], mockFileService);
55 |     const result = await readPathFromWorkspace('file.txt', config);
56 |     // Expect [string] for text content
57 |     expect(result).toEqual(['hello from cwd']);
58 |     expect(mockFileService.filterFiles).toHaveBeenCalled();
59 |   });
60 | 
61 |   it('should read a file from a secondary workspace directory', async () => {
62 |     mock({
63 |       [CWD]: {},
64 |       [OTHER_DIR]: {
65 |         'file.txt': 'hello from other dir',
66 |       },
67 |     });
68 |     const mockFileService = {
69 |       filterFiles: vi.fn((files) => files),
70 |     } as unknown as FileDiscoveryService;
71 |     const config = createMockConfig(CWD, [OTHER_DIR], mockFileService);
72 |     const result = await readPathFromWorkspace('file.txt', config);
73 |     expect(result).toEqual(['hello from other dir']);
74 |   });
75 | 
76 |   it('should prioritize CWD when file exists in both CWD and secondary dir', async () => {
77 |     mock({
78 |       [CWD]: {
79 |         'file.txt': 'hello from cwd',
80 |       },
81 |       [OTHER_DIR]: {
82 |         'file.txt': 'hello from other dir',
83 |       },
84 |     });
85 |     const mockFileService = {
86 |       filterFiles: vi.fn((files) => files),
87 |     } as unknown as FileDiscoveryService;
88 |     const config = createMockConfig(CWD, [OTHER_DIR], mockFileService);
89 |     const result = await readPathFromWorkspace('file.txt', config);
90 |     expect(result).toEqual(['hello from cwd']);
91 |   });
92 | 
93 |   it('should read an image file and return it as inlineData (Part object)', async () => {
94 |     // Use a real PNG header for robustness
95 |     const imageData = Buffer.from([
96 |       0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a,
97 |     ]);
98 |     mock({
99 |       [CWD]: {
100 |         'image.png': imageData,
101 |       },
102 |     });
103 |     const mockFileService = {
104 |       filterFiles: vi.fn((files) => files),
105 |     } as unknown as FileDiscoveryService;
106 |     const config = createMockConfig(CWD, [], mockFileService);
107 |     const result = await readPathFromWorkspace('image.png', config);
108 |     // Expect [Part] for image content
109 |     expect(result).toEqual([
110 |       {
111 |         inlineData: {
112 |           mimeType: 'image/png',
113 |           data: imageData.toString('base64'),
114 |         },
115 |       },
116 |     ]);
117 |   });
118 | 
119 |   it('should read a generic binary file and return an info string', async () => {
120 |     // Data that is clearly binary (null bytes)
121 |     const binaryData = Buffer.from([0x00, 0x01, 0x02, 0x03]);
122 |     mock({
123 |       [CWD]: {
124 |         'data.bin': binaryData,
125 |       },
126 |     });
127 |     const mockFileService = {
128 |       filterFiles: vi.fn((files) => files),
129 |     } as unknown as FileDiscoveryService;
130 |     const config = createMockConfig(CWD, [], mockFileService);
131 |     const result = await readPathFromWorkspace('data.bin', config);
132 |     // Expect [string] containing the skip message from fileUtils
133 |     expect(result).toEqual(['Cannot display content of binary file: data.bin']);
134 |   });
135 | 
136 |   it('should read a file from an absolute path if within workspace', async () => {
137 |     const absPath = path.join(OTHER_DIR, 'abs.txt');
138 |     mock({
139 |       [CWD]: {},
140 |       [OTHER_DIR]: {
141 |         'abs.txt': 'absolute content',
142 |       },
143 |     });
144 |     const mockFileService = {
145 |       filterFiles: vi.fn((files) => files),
146 |     } as unknown as FileDiscoveryService;
147 |     const config = createMockConfig(CWD, [OTHER_DIR], mockFileService);
148 |     const result = await readPathFromWorkspace(absPath, config);
149 |     expect(result).toEqual(['absolute content']);
150 |   });
151 | 
152 |   describe('Directory Expansion', () => {
153 |     it('should expand a directory and read the content of its files', async () => {
154 |       mock({
155 |         [CWD]: {
156 |           'my-dir': {
157 |             'file1.txt': 'content of file 1',
158 |             'file2.md': 'content of file 2',
159 |           },
160 |         },
161 |       });
162 |       const mockFileService = {
163 |         filterFiles: vi.fn((files) => files),
164 |       } as unknown as FileDiscoveryService;
165 |       const config = createMockConfig(CWD, [], mockFileService);
166 |       const result = await readPathFromWorkspace('my-dir', config);
167 | 
168 |       // Convert to a single string for easier, order-independent checking
169 |       const resultText = result
170 |         .map((p) => {
171 |           if (typeof p === 'string') return p;
172 |           if (typeof p === 'object' && p && 'text' in p) return p.text;
173 |           // This part is important for handling binary/image data which isn't just text
174 |           if (typeof p === 'object' && p && 'inlineData' in p) return '';
175 |           return p;
176 |         })
177 |         .join('');
178 | 
179 |       expect(resultText).toContain(
180 |         '--- Start of content for directory: my-dir ---',
181 |       );
182 |       expect(resultText).toContain('--- file1.txt ---');
183 |       expect(resultText).toContain('content of file 1');
184 |       expect(resultText).toContain('--- file2.md ---');
185 |       expect(resultText).toContain('content of file 2');
186 |       expect(resultText).toContain(
187 |         '--- End of content for directory: my-dir ---',
188 |       );
189 |     });
190 | 
191 |     it('should recursively expand a directory and read all nested files', async () => {
192 |       mock({
193 |         [CWD]: {
194 |           'my-dir': {
195 |             'file1.txt': 'content of file 1',
196 |             'sub-dir': {
197 |               'nested.txt': 'nested content',
198 |             },
199 |           },
200 |         },
201 |       });
202 |       const mockFileService = {
203 |         filterFiles: vi.fn((files) => files),
204 |       } as unknown as FileDiscoveryService;
205 |       const config = createMockConfig(CWD, [], mockFileService);
206 |       const result = await readPathFromWorkspace('my-dir', config);
207 | 
208 |       const resultText = result
209 |         .map((p) => {
210 |           if (typeof p === 'string') return p;
211 |           if (typeof p === 'object' && p && 'text' in p) return p.text;
212 |           return '';
213 |         })
214 |         .join('');
215 | 
216 |       expect(resultText).toContain('content of file 1');
217 |       expect(resultText).toContain('nested content');
218 |       expect(resultText).toContain(
219 |         `--- ${path.join('sub-dir', 'nested.txt')} ---`,
220 |       );
221 |     });
222 | 
223 |     it('should handle mixed content and include files from subdirectories', async () => {
224 |       const imageData = Buffer.from([
225 |         0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a,
226 |       ]);
227 |       mock({
228 |         [CWD]: {
229 |           'mixed-dir': {
230 |             'info.txt': 'some text',
231 |             'photo.png': imageData,
232 |             'sub-dir': {
233 |               'nested.txt': 'this should be included',
234 |             },
235 |             'empty-sub-dir': {},
236 |           },
237 |         },
238 |       });
239 |       const mockFileService = {
240 |         filterFiles: vi.fn((files) => files),
241 |       } as unknown as FileDiscoveryService;
242 |       const config = createMockConfig(CWD, [], mockFileService);
243 |       const result = await readPathFromWorkspace('mixed-dir', config);
244 | 
245 |       // Check for the text part
246 |       const textContent = result
247 |         .map((p) => {
248 |           if (typeof p === 'string') return p;
249 |           if (typeof p === 'object' && p && 'text' in p) return p.text;
250 |           return ''; // Ignore non-text parts for this assertion
251 |         })
252 |         .join('');
253 |       expect(textContent).toContain('some text');
254 |       expect(textContent).toContain('this should be included');
255 | 
256 |       // Check for the image part
257 |       const imagePart = result.find(
258 |         (p) => typeof p === 'object' && 'inlineData' in p,
259 |       );
260 |       expect(imagePart).toEqual({
261 |         inlineData: {
262 |           mimeType: 'image/png',
263 |           data: imageData.toString('base64'),
264 |         },
265 |       });
266 |     });
267 | 
268 |     it('should handle an empty directory', async () => {
269 |       mock({
270 |         [CWD]: {
271 |           'empty-dir': {},
272 |         },
273 |       });
274 |       const mockFileService = {
275 |         filterFiles: vi.fn((files) => files),
276 |       } as unknown as FileDiscoveryService;
277 |       const config = createMockConfig(CWD, [], mockFileService);
278 |       const result = await readPathFromWorkspace('empty-dir', config);
279 |       expect(result).toEqual([
280 |         { text: '--- Start of content for directory: empty-dir ---\n' },
281 |         { text: '--- End of content for directory: empty-dir ---' },
282 |       ]);
283 |     });
284 |   });
285 | 
286 |   describe('File Ignoring', () => {
287 |     it('should return an empty array for an ignored file', async () => {
288 |       mock({
289 |         [CWD]: {
290 |           'ignored.txt': 'ignored content',
291 |         },
292 |       });
293 |       const mockFileService = {
294 |         filterFiles: vi.fn(() => []), // Simulate the file being filtered out
295 |       } as unknown as FileDiscoveryService;
296 |       const config = createMockConfig(CWD, [], mockFileService);
297 |       const result = await readPathFromWorkspace('ignored.txt', config);
298 |       expect(result).toEqual([]);
299 |       expect(mockFileService.filterFiles).toHaveBeenCalledWith(
300 |         ['ignored.txt'],
301 |         {
302 |           respectGitIgnore: true,
303 |           respectGeminiIgnore: true,
304 |         },
305 |       );
306 |     });
307 | 
308 |     it('should not read ignored files when expanding a directory', async () => {
309 |       mock({
310 |         [CWD]: {
311 |           'my-dir': {
312 |             'not-ignored.txt': 'visible',
313 |             'ignored.log': 'invisible',
314 |           },
315 |         },
316 |       });
317 |       const mockFileService = {
318 |         filterFiles: vi.fn((files: string[]) =>
319 |           files.filter((f) => !f.endsWith('ignored.log')),
320 |         ),
321 |       } as unknown as FileDiscoveryService;
322 |       const config = createMockConfig(CWD, [], mockFileService);
323 |       const result = await readPathFromWorkspace('my-dir', config);
324 |       const resultText = result
325 |         .map((p) => {
326 |           if (typeof p === 'string') return p;
327 |           if (typeof p === 'object' && p && 'text' in p) return p.text;
328 |           return '';
329 |         })
330 |         .join('');
331 | 
332 |       expect(resultText).toContain('visible');
333 |       expect(resultText).not.toContain('invisible');
334 |       expect(mockFileService.filterFiles).toHaveBeenCalled();
335 |     });
336 |   });
337 | 
338 |   it('should throw an error for an absolute path outside the workspace', async () => {
339 |     const absPath = path.join(OUTSIDE_DIR, 'secret.txt');
340 |     mock({
341 |       [CWD]: {},
342 |       [OUTSIDE_DIR]: {
343 |         'secret.txt': 'secrets',
344 |       },
345 |     });
346 |     // OUTSIDE_DIR is not added to the config's workspace
347 |     const config = createMockConfig(CWD);
348 |     await expect(readPathFromWorkspace(absPath, config)).rejects.toThrow(
349 |       `Absolute path is outside of the allowed workspace: ${absPath}`,
350 |     );
351 |   });
352 | 
353 |   it('should throw an error if a relative path is not found anywhere', async () => {
354 |     mock({
355 |       [CWD]: {},
356 |       [OTHER_DIR]: {},
357 |     });
358 |     const config = createMockConfig(CWD, [OTHER_DIR]);
359 |     await expect(
360 |       readPathFromWorkspace('not-found.txt', config),
361 |     ).rejects.toThrow('Path not found in workspace: not-found.txt');
362 |   });
363 | 
364 |   // mock-fs permission simulation is unreliable on Windows.
365 |   it.skipIf(process.platform === 'win32')(
366 |     'should return an error string if reading a file with no permissions',
367 |     async () => {
368 |       mock({
369 |         [CWD]: {
370 |           'unreadable.txt': mock.file({
371 |             content: 'you cannot read me',
372 |             mode: 0o222, // Write-only
373 |           }),
374 |         },
375 |       });
376 |       const mockFileService = {
377 |         filterFiles: vi.fn((files) => files),
378 |       } as unknown as FileDiscoveryService;
379 |       const config = createMockConfig(CWD, [], mockFileService);
380 |       // processSingleFileContent catches the error and returns an error string.
381 |       const result = await readPathFromWorkspace('unreadable.txt', config);
382 |       const textResult = result[0] as string;
383 | 
384 |       // processSingleFileContent formats errors using the relative path from the target dir (CWD).
385 |       expect(textResult).toContain('Error reading file unreadable.txt');
386 |       expect(textResult).toMatch(/(EACCES|permission denied)/i);
387 |     },
388 |   );
389 | 
390 |   it('should return an error string for files exceeding the size limit', async () => {
391 |     // Mock a file slightly larger than the 20MB limit defined in fileUtils.ts
392 |     const largeContent = 'a'.repeat(21 * 1024 * 1024); // 21MB
393 |     mock({
394 |       [CWD]: {
395 |         'large.txt': largeContent,
396 |       },
397 |     });
398 |     const mockFileService = {
399 |       filterFiles: vi.fn((files) => files),
400 |     } as unknown as FileDiscoveryService;
401 |     const config = createMockConfig(CWD, [], mockFileService);
402 |     const result = await readPathFromWorkspace('large.txt', config);
403 |     const textResult = result[0] as string;
404 |     // The error message comes directly from processSingleFileContent
405 |     expect(textResult).toBe('File size exceeds the 20MB limit.');
406 |   });
407 | });
```

src/utils/pathReader.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { promises as fs } from 'node:fs';
8 | import path from 'node:path';
9 | import { glob } from 'glob';
10 | import type { PartUnion } from '@google/genai';
11 | import { processSingleFileContent } from './fileUtils.js';
12 | import type { Config } from '../config/config.js';
13 | 
14 | /**
15 |  * Reads the content of a file or recursively expands a directory from
16 |  * within the workspace, returning content suitable for LLM input.
17 |  *
18 |  * @param pathStr The path to read (can be absolute or relative).
19 |  * @param config The application configuration, providing workspace context and services.
20 |  * @returns A promise that resolves to an array of PartUnion (string | Part).
21 |  * @throws An error if the path is not found or is outside the workspace.
22 |  */
23 | export async function readPathFromWorkspace(
24 |   pathStr: string,
25 |   config: Config,
26 | ): Promise<PartUnion[]> {
27 |   const workspace = config.getWorkspaceContext();
28 |   const fileService = config.getFileService();
29 |   let absolutePath: string | null = null;
30 | 
31 |   if (path.isAbsolute(pathStr)) {
32 |     if (!workspace.isPathWithinWorkspace(pathStr)) {
33 |       throw new Error(
34 |         `Absolute path is outside of the allowed workspace: ${pathStr}`,
35 |       );
36 |     }
37 |     absolutePath = pathStr;
38 |   } else {
39 |     // Prioritized search for relative paths.
40 |     const searchDirs = workspace.getDirectories();
41 |     for (const dir of searchDirs) {
42 |       const potentialPath = path.resolve(dir, pathStr);
43 |       try {
44 |         await fs.access(potentialPath);
45 |         absolutePath = potentialPath;
46 |         break; // Found the first match.
47 |       } catch {
48 |         // Not found, continue to the next directory.
49 |       }
50 |     }
51 |   }
52 | 
53 |   if (!absolutePath) {
54 |     throw new Error(`Path not found in workspace: ${pathStr}`);
55 |   }
56 | 
57 |   const stats = await fs.stat(absolutePath);
58 |   if (stats.isDirectory()) {
59 |     const allParts: PartUnion[] = [];
60 |     allParts.push({
61 |       text: `--- Start of content for directory: ${pathStr} ---\n`,
62 |     });
63 | 
64 |     // Use glob to recursively find all files within the directory.
65 |     const files = await glob('**/*', {
66 |       cwd: absolutePath,
67 |       nodir: true, // We only want files
68 |       dot: true, // Include dotfiles
69 |       absolute: true,
70 |     });
71 | 
72 |     const relativeFiles = files.map((p) =>
73 |       path.relative(config.getTargetDir(), p),
74 |     );
75 |     const filteredFiles = fileService.filterFiles(relativeFiles, {
76 |       respectGitIgnore: true,
77 |       respectGeminiIgnore: true,
78 |     });
79 |     const finalFiles = filteredFiles.map((p) =>
80 |       path.resolve(config.getTargetDir(), p),
81 |     );
82 | 
83 |     for (const filePath of finalFiles) {
84 |       const relativePathForDisplay = path.relative(absolutePath, filePath);
85 |       allParts.push({ text: `--- ${relativePathForDisplay} ---\n` });
86 |       const result = await processSingleFileContent(
87 |         filePath,
88 |         config.getTargetDir(),
89 |         config.getFileSystemService(),
90 |       );
91 |       allParts.push(result.llmContent);
92 |       allParts.push({ text: '\n' }); // Add a newline for separation
93 |     }
94 | 
95 |     allParts.push({ text: `--- End of content for directory: ${pathStr} ---` });
96 |     return allParts;
97 |   } else {
98 |     // It's a single file, check if it's ignored.
99 |     const relativePath = path.relative(config.getTargetDir(), absolutePath);
100 |     const filtered = fileService.filterFiles([relativePath], {
101 |       respectGitIgnore: true,
102 |       respectGeminiIgnore: true,
103 |     });
104 | 
105 |     if (filtered.length === 0) {
106 |       // File is ignored, return empty array to silently skip.
107 |       return [];
108 |     }
109 | 
110 |     // It's a single file, process it directly.
111 |     const result = await processSingleFileContent(
112 |       absolutePath,
113 |       config.getTargetDir(),
114 |       config.getFileSystemService(),
115 |     );
116 |     return [result.llmContent];
117 |   }
118 | }
```

src/utils/paths.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeAll, afterAll } from 'vitest';
8 | import { escapePath, unescapePath, isSubpath } from './paths.js';
9 | 
10 | describe('escapePath', () => {
11 |   it('should escape spaces', () => {
12 |     expect(escapePath('my file.txt')).toBe('my\\ file.txt');
13 |   });
14 | 
15 |   it('should escape tabs', () => {
16 |     expect(escapePath('file\twith\ttabs.txt')).toBe('file\\\twith\\\ttabs.txt');
17 |   });
18 | 
19 |   it('should escape parentheses', () => {
20 |     expect(escapePath('file(1).txt')).toBe('file\\(1\\).txt');
21 |   });
22 | 
23 |   it('should escape square brackets', () => {
24 |     expect(escapePath('file[backup].txt')).toBe('file\\[backup\\].txt');
25 |   });
26 | 
27 |   it('should escape curly braces', () => {
28 |     expect(escapePath('file{temp}.txt')).toBe('file\\{temp\\}.txt');
29 |   });
30 | 
31 |   it('should escape semicolons', () => {
32 |     expect(escapePath('file;name.txt')).toBe('file\\;name.txt');
33 |   });
34 | 
35 |   it('should escape ampersands', () => {
36 |     expect(escapePath('file&name.txt')).toBe('file\\&name.txt');
37 |   });
38 | 
39 |   it('should escape pipes', () => {
40 |     expect(escapePath('file|name.txt')).toBe('file\\|name.txt');
41 |   });
42 | 
43 |   it('should escape asterisks', () => {
44 |     expect(escapePath('file*.txt')).toBe('file\\*.txt');
45 |   });
46 | 
47 |   it('should escape question marks', () => {
48 |     expect(escapePath('file?.txt')).toBe('file\\?.txt');
49 |   });
50 | 
51 |   it('should escape dollar signs', () => {
52 |     expect(escapePath('file$name.txt')).toBe('file\\$name.txt');
53 |   });
54 | 
55 |   it('should escape backticks', () => {
56 |     expect(escapePath('file`name.txt')).toBe('file\\`name.txt');
57 |   });
58 | 
59 |   it('should escape single quotes', () => {
60 |     expect(escapePath("file'name.txt")).toBe("file\\'name.txt");
61 |   });
62 | 
63 |   it('should escape double quotes', () => {
64 |     expect(escapePath('file"name.txt')).toBe('file\\"name.txt');
65 |   });
66 | 
67 |   it('should escape hash symbols', () => {
68 |     expect(escapePath('file#name.txt')).toBe('file\\#name.txt');
69 |   });
70 | 
71 |   it('should escape exclamation marks', () => {
72 |     expect(escapePath('file!name.txt')).toBe('file\\!name.txt');
73 |   });
74 | 
75 |   it('should escape tildes', () => {
76 |     expect(escapePath('file~name.txt')).toBe('file\\~name.txt');
77 |   });
78 | 
79 |   it('should escape less than and greater than signs', () => {
80 |     expect(escapePath('file<name>.txt')).toBe('file\\<name\\>.txt');
81 |   });
82 | 
83 |   it('should handle multiple special characters', () => {
84 |     expect(escapePath('my file (backup) [v1.2].txt')).toBe(
85 |       'my\\ file\\ \\(backup\\)\\ \\[v1.2\\].txt',
86 |     );
87 |   });
88 | 
89 |   it('should not double-escape already escaped characters', () => {
90 |     expect(escapePath('my\\ file.txt')).toBe('my\\ file.txt');
91 |     expect(escapePath('file\\(name\\).txt')).toBe('file\\(name\\).txt');
92 |   });
93 | 
94 |   it('should handle escaped backslashes correctly', () => {
95 |     // Double backslash (escaped backslash) followed by space should escape the space
96 |     expect(escapePath('path\\\\ file.txt')).toBe('path\\\\\\ file.txt');
97 |     // Triple backslash (escaped backslash + escaping backslash) followed by space should not double-escape
98 |     expect(escapePath('path\\\\\\ file.txt')).toBe('path\\\\\\ file.txt');
99 |     // Quadruple backslash (two escaped backslashes) followed by space should escape the space
100 |     expect(escapePath('path\\\\\\\\ file.txt')).toBe('path\\\\\\\\\\ file.txt');
101 |   });
102 | 
103 |   it('should handle complex escaped backslash scenarios', () => {
104 |     // Escaped backslash before special character that needs escaping
105 |     expect(escapePath('file\\\\(test).txt')).toBe('file\\\\\\(test\\).txt');
106 |     // Multiple escaped backslashes
107 |     expect(escapePath('path\\\\\\\\with space.txt')).toBe(
108 |       'path\\\\\\\\with\\ space.txt',
109 |     );
110 |   });
111 | 
112 |   it('should handle paths without special characters', () => {
113 |     expect(escapePath('normalfile.txt')).toBe('normalfile.txt');
114 |     expect(escapePath('path/to/normalfile.txt')).toBe('path/to/normalfile.txt');
115 |   });
116 | 
117 |   it('should handle complex real-world examples', () => {
118 |     expect(escapePath('My Documents/Project (2024)/file [backup].txt')).toBe(
119 |       'My\\ Documents/Project\\ \\(2024\\)/file\\ \\[backup\\].txt',
120 |     );
121 |     expect(escapePath('file with $special &chars!.txt')).toBe(
122 |       'file\\ with\\ \\$special\\ \\&chars\\!.txt',
123 |     );
124 |   });
125 | 
126 |   it('should handle empty strings', () => {
127 |     expect(escapePath('')).toBe('');
128 |   });
129 | 
130 |   it('should handle paths with only special characters', () => {
131 |     expect(escapePath(' ()[]{};&|*?$`\'"#!~<>')).toBe(
132 |       '\\ \\(\\)\\[\\]\\{\\}\\;\\&\\|\\*\\?\\$\\`\\\'\\"\\#\\!\\~\\<\\>',
133 |     );
134 |   });
135 | });
136 | 
137 | describe('unescapePath', () => {
138 |   it('should unescape spaces', () => {
139 |     expect(unescapePath('my\\ file.txt')).toBe('my file.txt');
140 |   });
141 | 
142 |   it('should unescape tabs', () => {
143 |     expect(unescapePath('file\\\twith\\\ttabs.txt')).toBe(
144 |       'file\twith\ttabs.txt',
145 |     );
146 |   });
147 | 
148 |   it('should unescape parentheses', () => {
149 |     expect(unescapePath('file\\(1\\).txt')).toBe('file(1).txt');
150 |   });
151 | 
152 |   it('should unescape square brackets', () => {
153 |     expect(unescapePath('file\\[backup\\].txt')).toBe('file[backup].txt');
154 |   });
155 | 
156 |   it('should unescape curly braces', () => {
157 |     expect(unescapePath('file\\{temp\\}.txt')).toBe('file{temp}.txt');
158 |   });
159 | 
160 |   it('should unescape multiple special characters', () => {
161 |     expect(unescapePath('my\\ file\\ \\(backup\\)\\ \\[v1.2\\].txt')).toBe(
162 |       'my file (backup) [v1.2].txt',
163 |     );
164 |   });
165 | 
166 |   it('should handle paths without escaped characters', () => {
167 |     expect(unescapePath('normalfile.txt')).toBe('normalfile.txt');
168 |     expect(unescapePath('path/to/normalfile.txt')).toBe(
169 |       'path/to/normalfile.txt',
170 |     );
171 |   });
172 | 
173 |   it('should handle all special characters', () => {
174 |     expect(
175 |       unescapePath(
176 |         '\\ \\(\\)\\[\\]\\{\\}\\;\\&\\|\\*\\?\\$\\`\\\'\\"\\#\\!\\~\\<\\>',
177 |       ),
178 |     ).toBe(' ()[]{};&|*?$`\'"#!~<>');
179 |   });
180 | 
181 |   it('should be the inverse of escapePath', () => {
182 |     const testCases = [
183 |       'my file.txt',
184 |       'file(1).txt',
185 |       'file[backup].txt',
186 |       'My Documents/Project (2024)/file [backup].txt',
187 |       'file with $special &chars!.txt',
188 |       ' ()[]{};&|*?$`\'"#!~<>',
189 |       'file\twith\ttabs.txt',
190 |     ];
191 | 
192 |     testCases.forEach((testCase) => {
193 |       expect(unescapePath(escapePath(testCase))).toBe(testCase);
194 |     });
195 |   });
196 | 
197 |   it('should handle empty strings', () => {
198 |     expect(unescapePath('')).toBe('');
199 |   });
200 | 
201 |   it('should not affect backslashes not followed by special characters', () => {
202 |     expect(unescapePath('file\\name.txt')).toBe('file\\name.txt');
203 |     expect(unescapePath('path\\to\\file.txt')).toBe('path\\to\\file.txt');
204 |   });
205 | 
206 |   it('should handle escaped backslashes in unescaping', () => {
207 |     // Should correctly unescape when there are escaped backslashes
208 |     expect(unescapePath('path\\\\\\ file.txt')).toBe('path\\\\ file.txt');
209 |     expect(unescapePath('path\\\\\\\\\\ file.txt')).toBe(
210 |       'path\\\\\\\\ file.txt',
211 |     );
212 |     expect(unescapePath('file\\\\\\(test\\).txt')).toBe('file\\\\(test).txt');
213 |   });
214 | });
215 | 
216 | describe('isSubpath', () => {
217 |   it('should return true for a direct subpath', () => {
218 |     expect(isSubpath('/a/b', '/a/b/c')).toBe(true);
219 |   });
220 | 
221 |   it('should return true for the same path', () => {
222 |     expect(isSubpath('/a/b', '/a/b')).toBe(true);
223 |   });
224 | 
225 |   it('should return false for a parent path', () => {
226 |     expect(isSubpath('/a/b/c', '/a/b')).toBe(false);
227 |   });
228 | 
229 |   it('should return false for a completely different path', () => {
230 |     expect(isSubpath('/a/b', '/x/y')).toBe(false);
231 |   });
232 | 
233 |   it('should handle relative paths', () => {
234 |     expect(isSubpath('a/b', 'a/b/c')).toBe(true);
235 |     expect(isSubpath('a/b', 'a/c')).toBe(false);
236 |   });
237 | 
238 |   it('should handle paths with ..', () => {
239 |     expect(isSubpath('/a/b', '/a/b/../b/c')).toBe(true);
240 |     expect(isSubpath('/a/b', '/a/c/../b')).toBe(true);
241 |   });
242 | 
243 |   it('should handle root paths', () => {
244 |     expect(isSubpath('/', '/a')).toBe(true);
245 |     expect(isSubpath('/a', '/')).toBe(false);
246 |   });
247 | 
248 |   it('should handle trailing slashes', () => {
249 |     expect(isSubpath('/a/b/', '/a/b/c')).toBe(true);
250 |     expect(isSubpath('/a/b', '/a/b/c/')).toBe(true);
251 |     expect(isSubpath('/a/b/', '/a/b/c/')).toBe(true);
252 |   });
253 | });
254 | 
255 | describe('isSubpath on Windows', () => {
256 |   const originalPlatform = process.platform;
257 | 
258 |   beforeAll(() => {
259 |     Object.defineProperty(process, 'platform', {
260 |       value: 'win32',
261 |     });
262 |   });
263 | 
264 |   afterAll(() => {
265 |     Object.defineProperty(process, 'platform', {
266 |       value: originalPlatform,
267 |     });
268 |   });
269 | 
270 |   it('should return true for a direct subpath on Windows', () => {
271 |     expect(isSubpath('C:\\Users\\Test', 'C:\\Users\\Test\\file.txt')).toBe(
272 |       true,
273 |     );
274 |   });
275 | 
276 |   it('should return true for the same path on Windows', () => {
277 |     expect(isSubpath('C:\\Users\\Test', 'C:\\Users\\Test')).toBe(true);
278 |   });
279 | 
280 |   it('should return false for a parent path on Windows', () => {
281 |     expect(isSubpath('C:\\Users\\Test\\file.txt', 'C:\\Users\\Test')).toBe(
282 |       false,
283 |     );
284 |   });
285 | 
286 |   it('should return false for a different drive on Windows', () => {
287 |     expect(isSubpath('C:\\Users\\Test', 'D:\\Users\\Test')).toBe(false);
288 |   });
289 | 
290 |   it('should be case-insensitive for drive letters on Windows', () => {
291 |     expect(isSubpath('c:\\Users\\Test', 'C:\\Users\\Test\\file.txt')).toBe(
292 |       true,
293 |     );
294 |   });
295 | 
296 |   it('should be case-insensitive for path components on Windows', () => {
297 |     expect(isSubpath('C:\\Users\\Test', 'c:\\users\\test\\file.txt')).toBe(
298 |       true,
299 |     );
300 |   });
301 | 
302 |   it('should handle mixed slashes on Windows', () => {
303 |     expect(isSubpath('C:/Users/Test', 'C:\\Users\\Test\\file.txt')).toBe(true);
304 |   });
305 | 
306 |   it('should handle trailing slashes on Windows', () => {
307 |     expect(isSubpath('C:\\Users\\Test\\', 'C:\\Users\\Test\\file.txt')).toBe(
308 |       true,
309 |     );
310 |   });
311 | 
312 |   it('should handle relative paths correctly on Windows', () => {
313 |     expect(isSubpath('Users\\Test', 'Users\\Test\\file.txt')).toBe(true);
314 |     expect(isSubpath('Users\\Test\\file.txt', 'Users\\Test')).toBe(false);
315 |   });
316 | });
```

src/utils/paths.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import path from 'node:path';
8 | import os from 'node:os';
9 | import * as crypto from 'node:crypto';
10 | 
11 | export const GEMINI_DIR = '.gemini';
12 | export const GOOGLE_ACCOUNTS_FILENAME = 'google_accounts.json';
13 | 
14 | /**
15 |  * Special characters that need to be escaped in file paths for shell compatibility.
16 |  * Includes: spaces, parentheses, brackets, braces, semicolons, ampersands, pipes,
17 |  * asterisks, question marks, dollar signs, backticks, quotes, hash, and other shell metacharacters.
18 |  */
19 | export const SHELL_SPECIAL_CHARS = /[ \t()[\]{};|*?$`'"#&<>!~]/;
20 | 
21 | /**
22 |  * Replaces the home directory with a tilde.
23 |  * @param path - The path to tildeify.
24 |  * @returns The tildeified path.
25 |  */
26 | export function tildeifyPath(path: string): string {
27 |   const homeDir = os.homedir();
28 |   if (path.startsWith(homeDir)) {
29 |     return path.replace(homeDir, '~');
30 |   }
31 |   return path;
32 | }
33 | 
34 | /**
35 |  * Shortens a path string if it exceeds maxLen, prioritizing the start and end segments.
36 |  * Example: /path/to/a/very/long/file.txt -> /path/.../long/file.txt
37 |  */
38 | export function shortenPath(filePath: string, maxLen: number = 35): string {
39 |   if (filePath.length <= maxLen) {
40 |     return filePath;
41 |   }
42 | 
43 |   const parsedPath = path.parse(filePath);
44 |   const root = parsedPath.root;
45 |   const separator = path.sep;
46 | 
47 |   // Get segments of the path *after* the root
48 |   const relativePath = filePath.substring(root.length);
49 |   const segments = relativePath.split(separator).filter((s) => s !== ''); // Filter out empty segments
50 | 
51 |   // Handle cases with no segments after root (e.g., "/", "C:\") or only one segment
52 |   if (segments.length <= 1) {
53 |     // Fall back to simple start/end truncation for very short paths or single segments
54 |     const keepLen = Math.floor((maxLen - 3) / 2);
55 |     // Ensure keepLen is not negative if maxLen is very small
56 |     if (keepLen <= 0) {
57 |       return filePath.substring(0, maxLen - 3) + '...';
58 |     }
59 |     const start = filePath.substring(0, keepLen);
60 |     const end = filePath.substring(filePath.length - keepLen);
61 |     return `${start}...${end}`;
62 |   }
63 | 
64 |   const firstDir = segments[0];
65 |   const lastSegment = segments[segments.length - 1];
66 |   const startComponent = root + firstDir;
67 | 
68 |   const endPartSegments: string[] = [];
69 |   // Base length: separator + "..." + lastDir
70 |   let currentLength = separator.length + lastSegment.length;
71 | 
72 |   // Iterate backwards through segments (excluding the first one)
73 |   for (let i = segments.length - 2; i >= 0; i--) {
74 |     const segment = segments[i];
75 |     // Length needed if we add this segment: current + separator + segment
76 |     const lengthWithSegment = currentLength + separator.length + segment.length;
77 | 
78 |     if (lengthWithSegment <= maxLen) {
79 |       endPartSegments.unshift(segment); // Add to the beginning of the end part
80 |       currentLength = lengthWithSegment;
81 |     } else {
82 |       break;
83 |     }
84 |   }
85 | 
86 |   let result = endPartSegments.join(separator) + separator + lastSegment;
87 | 
88 |   if (currentLength > maxLen) {
89 |     return result;
90 |   }
91 | 
92 |   // Construct the final path
93 |   result = startComponent + separator + result;
94 | 
95 |   // As a final check, if the result is somehow still too long
96 |   // truncate the result string from the beginning, prefixing with "...".
97 |   if (result.length > maxLen) {
98 |     return '...' + result.substring(result.length - maxLen - 3);
99 |   }
100 | 
101 |   return result;
102 | }
103 | 
104 | /**
105 |  * Calculates the relative path from a root directory to a target path.
106 |  * Ensures both paths are resolved before calculating.
107 |  * Returns '.' if the target path is the same as the root directory.
108 |  *
109 |  * @param targetPath The absolute or relative path to make relative.
110 |  * @param rootDirectory The absolute path of the directory to make the target path relative to.
111 |  * @returns The relative path from rootDirectory to targetPath.
112 |  */
113 | export function makeRelative(
114 |   targetPath: string,
115 |   rootDirectory: string,
116 | ): string {
117 |   const resolvedTargetPath = path.resolve(targetPath);
118 |   const resolvedRootDirectory = path.resolve(rootDirectory);
119 | 
120 |   const relativePath = path.relative(resolvedRootDirectory, resolvedTargetPath);
121 | 
122 |   // If the paths are the same, path.relative returns '', return '.' instead
123 |   return relativePath || '.';
124 | }
125 | 
126 | /**
127 |  * Escapes special characters in a file path like macOS terminal does.
128 |  * Escapes: spaces, parentheses, brackets, braces, semicolons, ampersands, pipes,
129 |  * asterisks, question marks, dollar signs, backticks, quotes, hash, and other shell metacharacters.
130 |  */
131 | export function escapePath(filePath: string): string {
132 |   let result = '';
133 |   for (let i = 0; i < filePath.length; i++) {
134 |     const char = filePath[i];
135 | 
136 |     // Count consecutive backslashes before this character
137 |     let backslashCount = 0;
138 |     for (let j = i - 1; j >= 0 && filePath[j] === '\\'; j--) {
139 |       backslashCount++;
140 |     }
141 | 
142 |     // Character is already escaped if there's an odd number of backslashes before it
143 |     const isAlreadyEscaped = backslashCount % 2 === 1;
144 | 
145 |     // Only escape if not already escaped
146 |     if (!isAlreadyEscaped && SHELL_SPECIAL_CHARS.test(char)) {
147 |       result += '\\' + char;
148 |     } else {
149 |       result += char;
150 |     }
151 |   }
152 |   return result;
153 | }
154 | 
155 | /**
156 |  * Unescapes special characters in a file path.
157 |  * Removes backslash escaping from shell metacharacters.
158 |  */
159 | export function unescapePath(filePath: string): string {
160 |   return filePath.replace(
161 |     new RegExp(`\\\\([${SHELL_SPECIAL_CHARS.source.slice(1, -1)}])`, 'g'),
162 |     '$1',
163 |   );
164 | }
165 | 
166 | /**
167 |  * Generates a unique hash for a project based on its root path.
168 |  * @param projectRoot The absolute path to the project's root directory.
169 |  * @returns A SHA256 hash of the project root path.
170 |  */
171 | export function getProjectHash(projectRoot: string): string {
172 |   return crypto.createHash('sha256').update(projectRoot).digest('hex');
173 | }
174 | 
175 | /**
176 |  * Checks if a path is a subpath of another path.
177 |  * @param parentPath The parent path.
178 |  * @param childPath The child path.
179 |  * @returns True if childPath is a subpath of parentPath, false otherwise.
180 |  */
181 | export function isSubpath(parentPath: string, childPath: string): boolean {
182 |   const isWindows = os.platform() === 'win32';
183 |   const pathModule = isWindows ? path.win32 : path;
184 | 
185 |   // On Windows, path.relative is case-insensitive. On POSIX, it's case-sensitive.
186 |   const relative = pathModule.relative(parentPath, childPath);
187 | 
188 |   return (
189 |     !relative.startsWith(`..${pathModule.sep}`) &&
190 |     relative !== '..' &&
191 |     !pathModule.isAbsolute(relative)
192 |   );
193 | }
```

src/utils/promptIdContext.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { AsyncLocalStorage } from 'node:async_hooks';
8 | 
9 | export const promptIdContext = new AsyncLocalStorage<string>();
```

src/utils/quotaErrorDetection.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { StructuredError } from '../core/turn.js';
8 | 
9 | export interface ApiError {
10 |   error: {
11 |     code: number;
12 |     message: string;
13 |     status: string;
14 |     details: unknown[];
15 |   };
16 | }
17 | 
18 | export function isApiError(error: unknown): error is ApiError {
19 |   return (
20 |     typeof error === 'object' &&
21 |     error !== null &&
22 |     'error' in error &&
23 |     typeof (error as ApiError).error === 'object' &&
24 |     'message' in (error as ApiError).error
25 |   );
26 | }
27 | 
28 | export function isStructuredError(error: unknown): error is StructuredError {
29 |   return (
30 |     typeof error === 'object' &&
31 |     error !== null &&
32 |     'message' in error &&
33 |     typeof (error as StructuredError).message === 'string'
34 |   );
35 | }
```

src/utils/retry.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /* eslint-disable @typescript-eslint/no-explicit-any */
8 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
9 | import { ApiError } from '@google/genai';
10 | import { AuthType } from '../core/contentGenerator.js';
11 | import type { HttpError } from './retry.js';
12 | import { retryWithBackoff } from './retry.js';
13 | import { setSimulate429 } from './testUtils.js';
14 | import {
15 |   TerminalQuotaError,
16 |   RetryableQuotaError,
17 | } from './googleQuotaErrors.js';
18 | 
19 | // Helper to create a mock function that fails a certain number of times
20 | const createFailingFunction = (
21 |   failures: number,
22 |   successValue: string = 'success',
23 | ) => {
24 |   let attempts = 0;
25 |   return vi.fn(async () => {
26 |     attempts++;
27 |     if (attempts <= failures) {
28 |       // Simulate a retryable error
29 |       const error: HttpError = new Error(`Simulated error attempt ${attempts}`);
30 |       error.status = 500; // Simulate a server error
31 |       throw error;
32 |     }
33 |     return successValue;
34 |   });
35 | };
36 | 
37 | // Custom error for testing non-retryable conditions
38 | class NonRetryableError extends Error {
39 |   constructor(message: string) {
40 |     super(message);
41 |     this.name = 'NonRetryableError';
42 |   }
43 | }
44 | 
45 | describe('retryWithBackoff', () => {
46 |   beforeEach(() => {
47 |     vi.useFakeTimers();
48 |     // Disable 429 simulation for tests
49 |     setSimulate429(false);
50 |     // Suppress unhandled promise rejection warnings for tests that expect errors
51 |     console.warn = vi.fn();
52 |   });
53 | 
54 |   afterEach(() => {
55 |     vi.restoreAllMocks();
56 |     vi.useRealTimers();
57 |   });
58 | 
59 |   it('should return the result on the first attempt if successful', async () => {
60 |     const mockFn = createFailingFunction(0);
61 |     const result = await retryWithBackoff(mockFn);
62 |     expect(result).toBe('success');
63 |     expect(mockFn).toHaveBeenCalledTimes(1);
64 |   });
65 | 
66 |   it('should retry and succeed if failures are within maxAttempts', async () => {
67 |     const mockFn = createFailingFunction(2);
68 |     const promise = retryWithBackoff(mockFn, {
69 |       maxAttempts: 3,
70 |       initialDelayMs: 10,
71 |     });
72 | 
73 |     await vi.runAllTimersAsync(); // Ensure all delays and retries complete
74 | 
75 |     const result = await promise;
76 |     expect(result).toBe('success');
77 |     expect(mockFn).toHaveBeenCalledTimes(3);
78 |   });
79 | 
80 |   it('should throw an error if all attempts fail', async () => {
81 |     const mockFn = createFailingFunction(3);
82 | 
83 |     // 1. Start the retryable operation, which returns a promise.
84 |     const promise = retryWithBackoff(mockFn, {
85 |       maxAttempts: 3,
86 |       initialDelayMs: 10,
87 |     });
88 | 
89 |     // 2. Run timers and await expectation in parallel.
90 |     await Promise.all([
91 |       expect(promise).rejects.toThrow('Simulated error attempt 3'),
92 |       vi.runAllTimersAsync(),
93 |     ]);
94 | 
95 |     // 3. Finally, assert the number of calls.
96 |     expect(mockFn).toHaveBeenCalledTimes(3);
97 |   });
98 | 
99 |   it('should default to 5 maxAttempts if no options are provided', async () => {
100 |     // This function will fail more than 5 times to ensure all retries are used.
101 |     const mockFn = createFailingFunction(10);
102 | 
103 |     const promise = retryWithBackoff(mockFn);
104 | 
105 |     // Expect it to fail with the error from the 5th attempt.
106 |     await Promise.all([
107 |       expect(promise).rejects.toThrow('Simulated error attempt 10'),
108 |       vi.runAllTimersAsync(),
109 |     ]);
110 | 
111 |     expect(mockFn).toHaveBeenCalledTimes(10);
112 |   });
113 | 
114 |   it('should default to 10 maxAttempts if options.maxAttempts is undefined', async () => {
115 |     // This function will fail more than 5 times to ensure all retries are used.
116 |     const mockFn = createFailingFunction(10);
117 | 
118 |     const promise = retryWithBackoff(mockFn, { maxAttempts: undefined });
119 | 
120 |     // Expect it to fail with the error from the 5th attempt.
121 |     await Promise.all([
122 |       expect(promise).rejects.toThrow('Simulated error attempt 10'),
123 |       vi.runAllTimersAsync(),
124 |     ]);
125 | 
126 |     expect(mockFn).toHaveBeenCalledTimes(10);
127 |   });
128 | 
129 |   it('should not retry if shouldRetry returns false', async () => {
130 |     const mockFn = vi.fn(async () => {
131 |       throw new NonRetryableError('Non-retryable error');
132 |     });
133 |     const shouldRetryOnError = (error: Error) =>
134 |       !(error instanceof NonRetryableError);
135 | 
136 |     const promise = retryWithBackoff(mockFn, {
137 |       shouldRetryOnError,
138 |       initialDelayMs: 10,
139 |     });
140 | 
141 |     await expect(promise).rejects.toThrow('Non-retryable error');
142 |     expect(mockFn).toHaveBeenCalledTimes(1);
143 |   });
144 | 
145 |   it('should throw an error if maxAttempts is not a positive number', async () => {
146 |     const mockFn = createFailingFunction(1);
147 | 
148 |     // Test with 0
149 |     await expect(retryWithBackoff(mockFn, { maxAttempts: 0 })).rejects.toThrow(
150 |       'maxAttempts must be a positive number.',
151 |     );
152 | 
153 |     // The function should not be called at all if validation fails
154 |     expect(mockFn).not.toHaveBeenCalled();
155 |   });
156 | 
157 |   it('should use default shouldRetry if not provided, retrying on ApiError 429', async () => {
158 |     const mockFn = vi.fn(async () => {
159 |       throw new ApiError({ message: 'Too Many Requests', status: 429 });
160 |     });
161 | 
162 |     const promise = retryWithBackoff(mockFn, {
163 |       maxAttempts: 2,
164 |       initialDelayMs: 10,
165 |     });
166 | 
167 |     await Promise.all([
168 |       expect(promise).rejects.toThrow('Too Many Requests'),
169 |       vi.runAllTimersAsync(),
170 |     ]);
171 | 
172 |     expect(mockFn).toHaveBeenCalledTimes(2);
173 |   });
174 | 
175 |   it('should use default shouldRetry if not provided, not retrying on ApiError 400', async () => {
176 |     const mockFn = vi.fn(async () => {
177 |       throw new ApiError({ message: 'Bad Request', status: 400 });
178 |     });
179 | 
180 |     const promise = retryWithBackoff(mockFn, {
181 |       maxAttempts: 2,
182 |       initialDelayMs: 10,
183 |     });
184 |     await expect(promise).rejects.toThrow('Bad Request');
185 |     expect(mockFn).toHaveBeenCalledTimes(1);
186 |   });
187 | 
188 |   it('should use default shouldRetry if not provided, retrying on generic error with status 429', async () => {
189 |     const mockFn = vi.fn(async () => {
190 |       const error = new Error('Too Many Requests') as any;
191 |       error.status = 429;
192 |       throw error;
193 |     });
194 | 
195 |     const promise = retryWithBackoff(mockFn, {
196 |       maxAttempts: 2,
197 |       initialDelayMs: 10,
198 |     });
199 | 
200 |     // Run timers and await expectation in parallel.
201 |     await Promise.all([
202 |       expect(promise).rejects.toThrow('Too Many Requests'),
203 |       vi.runAllTimersAsync(),
204 |     ]);
205 | 
206 |     expect(mockFn).toHaveBeenCalledTimes(2);
207 |   });
208 | 
209 |   it('should use default shouldRetry if not provided, not retrying on generic error with status 400', async () => {
210 |     const mockFn = vi.fn(async () => {
211 |       const error = new Error('Bad Request') as any;
212 |       error.status = 400;
213 |       throw error;
214 |     });
215 | 
216 |     const promise = retryWithBackoff(mockFn, {
217 |       maxAttempts: 2,
218 |       initialDelayMs: 10,
219 |     });
220 |     await expect(promise).rejects.toThrow('Bad Request');
221 |     expect(mockFn).toHaveBeenCalledTimes(1);
222 |   });
223 | 
224 |   it('should respect maxDelayMs', async () => {
225 |     const mockFn = createFailingFunction(3);
226 |     const setTimeoutSpy = vi.spyOn(global, 'setTimeout');
227 | 
228 |     const promise = retryWithBackoff(mockFn, {
229 |       maxAttempts: 4,
230 |       initialDelayMs: 100,
231 |       maxDelayMs: 250, // Max delay is less than 100 * 2 * 2 = 400
232 |     });
233 | 
234 |     await vi.advanceTimersByTimeAsync(1000); // Advance well past all delays
235 |     await promise;
236 | 
237 |     const delays = setTimeoutSpy.mock.calls.map((call) => call[1] as number);
238 | 
239 |     // Delays should be around initial, initial*2, maxDelay (due to cap)
240 |     // Jitter makes exact assertion hard, so we check ranges / caps
241 |     expect(delays.length).toBe(3);
242 |     expect(delays[0]).toBeGreaterThanOrEqual(100 * 0.7);
243 |     expect(delays[0]).toBeLessThanOrEqual(100 * 1.3);
244 |     expect(delays[1]).toBeGreaterThanOrEqual(200 * 0.7);
245 |     expect(delays[1]).toBeLessThanOrEqual(200 * 1.3);
246 |     // The third delay should be capped by maxDelayMs (250ms), accounting for jitter
247 |     expect(delays[2]).toBeGreaterThanOrEqual(250 * 0.7);
248 |     expect(delays[2]).toBeLessThanOrEqual(250 * 1.3);
249 |   });
250 | 
251 |   it('should handle jitter correctly, ensuring varied delays', async () => {
252 |     let mockFn = createFailingFunction(5);
253 |     const setTimeoutSpy = vi.spyOn(global, 'setTimeout');
254 | 
255 |     // Run retryWithBackoff multiple times to observe jitter
256 |     const runRetry = () =>
257 |       retryWithBackoff(mockFn, {
258 |         maxAttempts: 2, // Only one retry, so one delay
259 |         initialDelayMs: 100,
260 |         maxDelayMs: 1000,
261 |       });
262 | 
263 |     // We expect rejections as mockFn fails 5 times
264 |     const promise1 = runRetry();
265 |     // Run timers and await expectation in parallel.
266 |     await Promise.all([
267 |       expect(promise1).rejects.toThrow(),
268 |       vi.runAllTimersAsync(),
269 |     ]);
270 | 
271 |     const firstDelaySet = setTimeoutSpy.mock.calls.map(
272 |       (call) => call[1] as number,
273 |     );
274 |     setTimeoutSpy.mockClear(); // Clear calls for the next run
275 | 
276 |     // Reset mockFn to reset its internal attempt counter for the next run
277 |     mockFn = createFailingFunction(5); // Re-initialize with 5 failures
278 | 
279 |     const promise2 = runRetry();
280 |     // Run timers and await expectation in parallel.
281 |     await Promise.all([
282 |       expect(promise2).rejects.toThrow(),
283 |       vi.runAllTimersAsync(),
284 |     ]);
285 | 
286 |     const secondDelaySet = setTimeoutSpy.mock.calls.map(
287 |       (call) => call[1] as number,
288 |     );
289 | 
290 |     // Check that the delays are not exactly the same due to jitter
291 |     // This is a probabilistic test, but with +/-30% jitter, it's highly likely they differ.
292 |     if (firstDelaySet.length > 0 && secondDelaySet.length > 0) {
293 |       // Check the first delay of each set
294 |       expect(firstDelaySet[0]).not.toBe(secondDelaySet[0]);
295 |     } else {
296 |       // If somehow no delays were captured (e.g. test setup issue), fail explicitly
297 |       throw new Error('Delays were not captured for jitter test');
298 |     }
299 | 
300 |     // Ensure delays are within the expected jitter range [70, 130] for initialDelayMs = 100
301 |     [...firstDelaySet, ...secondDelaySet].forEach((d) => {
302 |       expect(d).toBeGreaterThanOrEqual(100 * 0.7);
303 |       expect(d).toBeLessThanOrEqual(100 * 1.3);
304 |     });
305 |   });
306 | 
307 |   describe('Flash model fallback for OAuth users', () => {
308 |     it('should trigger fallback for OAuth personal users on TerminalQuotaError', async () => {
309 |       const fallbackCallback = vi.fn().mockResolvedValue('gemini-2.5-flash');
310 | 
311 |       let fallbackOccurred = false;
312 |       const mockFn = vi.fn().mockImplementation(async () => {
313 |         if (!fallbackOccurred) {
314 |           throw new TerminalQuotaError('Daily limit reached', {} as any);
315 |         }
316 |         return 'success';
317 |       });
318 | 
319 |       const promise = retryWithBackoff(mockFn, {
320 |         maxAttempts: 3,
321 |         initialDelayMs: 100,
322 |         onPersistent429: async (authType?: string, error?: unknown) => {
323 |           fallbackOccurred = true;
324 |           return await fallbackCallback(authType, error);
325 |         },
326 |         authType: 'oauth-personal',
327 |       });
328 | 
329 |       await vi.runAllTimersAsync();
330 | 
331 |       await expect(promise).resolves.toBe('success');
332 |       expect(fallbackCallback).toHaveBeenCalledWith(
333 |         'oauth-personal',
334 |         expect.any(TerminalQuotaError),
335 |       );
336 |       expect(mockFn).toHaveBeenCalledTimes(2);
337 |     });
338 | 
339 |     it('should use retryDelayMs from RetryableQuotaError', async () => {
340 |       const setTimeoutSpy = vi.spyOn(global, 'setTimeout');
341 |       const mockFn = vi.fn().mockImplementation(async () => {
342 |         throw new RetryableQuotaError('Per-minute limit', {} as any, 12.345);
343 |       });
344 | 
345 |       const promise = retryWithBackoff(mockFn, {
346 |         maxAttempts: 2,
347 |         initialDelayMs: 100,
348 |       });
349 | 
350 |       // Attach the rejection expectation *before* running timers
351 |       // eslint-disable-next-line vitest/valid-expect
352 |       const assertionPromise = expect(promise).rejects.toThrow();
353 |       await vi.runAllTimersAsync();
354 |       await assertionPromise;
355 | 
356 |       expect(setTimeoutSpy).toHaveBeenCalledWith(expect.any(Function), 12345);
357 |     });
358 | 
359 |     it.each([[AuthType.USE_GEMINI], [AuthType.USE_VERTEX_AI], [undefined]])(
360 |       'should not trigger fallback for non-Google auth users (authType: %s) on TerminalQuotaError',
361 |       async (authType) => {
362 |         const fallbackCallback = vi.fn();
363 |         const mockFn = vi.fn().mockImplementation(async () => {
364 |           throw new TerminalQuotaError('Daily limit reached', {} as any);
365 |         });
366 | 
367 |         const promise = retryWithBackoff(mockFn, {
368 |           maxAttempts: 3,
369 |           onPersistent429: fallbackCallback,
370 |           authType,
371 |         });
372 | 
373 |         await expect(promise).rejects.toThrow('Daily limit reached');
374 |         expect(fallbackCallback).not.toHaveBeenCalled();
375 |         expect(mockFn).toHaveBeenCalledTimes(1);
376 |       },
377 |     );
378 |   });
379 | });
```

src/utils/retry.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { GenerateContentResponse } from '@google/genai';
8 | import { ApiError } from '@google/genai';
9 | import { AuthType } from '../core/contentGenerator.js';
10 | import {
11 |   classifyGoogleError,
12 |   RetryableQuotaError,
13 |   TerminalQuotaError,
14 | } from './googleQuotaErrors.js';
15 | 
16 | export interface HttpError extends Error {
17 |   status?: number;
18 | }
19 | 
20 | export interface RetryOptions {
21 |   maxAttempts: number;
22 |   initialDelayMs: number;
23 |   maxDelayMs: number;
24 |   shouldRetryOnError: (error: Error) => boolean;
25 |   shouldRetryOnContent?: (content: GenerateContentResponse) => boolean;
26 |   onPersistent429?: (
27 |     authType?: string,
28 |     error?: unknown,
29 |   ) => Promise<string | boolean | null>;
30 |   authType?: string;
31 | }
32 | 
33 | const DEFAULT_RETRY_OPTIONS: RetryOptions = {
34 |   maxAttempts: 10,
35 |   initialDelayMs: 5000,
36 |   maxDelayMs: 30000, // 30 seconds
37 |   shouldRetryOnError: defaultShouldRetry,
38 | };
39 | 
40 | /**
41 |  * Default predicate function to determine if a retry should be attempted.
42 |  * Retries on 429 (Too Many Requests) and 5xx server errors.
43 |  * @param error The error object.
44 |  * @returns True if the error is a transient error, false otherwise.
45 |  */
46 | function defaultShouldRetry(error: Error | unknown): boolean {
47 |   // Priority check for ApiError
48 |   if (error instanceof ApiError) {
49 |     // Explicitly do not retry 400 (Bad Request)
50 |     if (error.status === 400) return false;
51 |     return error.status === 429 || (error.status >= 500 && error.status < 600);
52 |   }
53 | 
54 |   // Check for status using helper (handles other error shapes)
55 |   const status = getErrorStatus(error);
56 |   if (status !== undefined) {
57 |     return status === 429 || (status >= 500 && status < 600);
58 |   }
59 | 
60 |   return false;
61 | }
62 | 
63 | /**
64 |  * Delays execution for a specified number of milliseconds.
65 |  * @param ms The number of milliseconds to delay.
66 |  * @returns A promise that resolves after the delay.
67 |  */
68 | function delay(ms: number): Promise<void> {
69 |   return new Promise((resolve) => setTimeout(resolve, ms));
70 | }
71 | 
72 | /**
73 |  * Retries a function with exponential backoff and jitter.
74 |  * @param fn The asynchronous function to retry.
75 |  * @param options Optional retry configuration.
76 |  * @returns A promise that resolves with the result of the function if successful.
77 |  * @throws The last error encountered if all attempts fail.
78 |  */
79 | export async function retryWithBackoff<T>(
80 |   fn: () => Promise<T>,
81 |   options?: Partial<RetryOptions>,
82 | ): Promise<T> {
83 |   if (options?.maxAttempts !== undefined && options.maxAttempts <= 0) {
84 |     throw new Error('maxAttempts must be a positive number.');
85 |   }
86 | 
87 |   const cleanOptions = options
88 |     ? Object.fromEntries(Object.entries(options).filter(([_, v]) => v != null))
89 |     : {};
90 | 
91 |   const {
92 |     maxAttempts,
93 |     initialDelayMs,
94 |     maxDelayMs,
95 |     onPersistent429,
96 |     authType,
97 |     shouldRetryOnError,
98 |     shouldRetryOnContent,
99 |   } = {
100 |     ...DEFAULT_RETRY_OPTIONS,
101 |     ...cleanOptions,
102 |   };
103 | 
104 |   let attempt = 0;
105 |   let currentDelay = initialDelayMs;
106 | 
107 |   while (attempt < maxAttempts) {
108 |     attempt++;
109 |     try {
110 |       const result = await fn();
111 | 
112 |       if (
113 |         shouldRetryOnContent &&
114 |         shouldRetryOnContent(result as GenerateContentResponse)
115 |       ) {
116 |         const jitter = currentDelay * 0.3 * (Math.random() * 2 - 1);
117 |         const delayWithJitter = Math.max(0, currentDelay + jitter);
118 |         await delay(delayWithJitter);
119 |         currentDelay = Math.min(maxDelayMs, currentDelay * 2);
120 |         continue;
121 |       }
122 | 
123 |       return result;
124 |     } catch (error) {
125 |       const classifiedError = classifyGoogleError(error);
126 | 
127 |       if (classifiedError instanceof TerminalQuotaError) {
128 |         if (onPersistent429 && authType === AuthType.LOGIN_WITH_GOOGLE) {
129 |           try {
130 |             const fallbackModel = await onPersistent429(
131 |               authType,
132 |               classifiedError,
133 |             );
134 |             if (fallbackModel) {
135 |               attempt = 0; // Reset attempts and retry with the new model.
136 |               currentDelay = initialDelayMs;
137 |               continue;
138 |             }
139 |           } catch (fallbackError) {
140 |             console.warn('Model fallback failed:', fallbackError);
141 |           }
142 |         }
143 |         throw classifiedError; // Throw if no fallback or fallback failed.
144 |       }
145 | 
146 |       if (classifiedError instanceof RetryableQuotaError) {
147 |         if (attempt >= maxAttempts) {
148 |           throw classifiedError;
149 |         }
150 |         console.warn(
151 |           `Attempt ${attempt} failed: ${classifiedError.message}. Retrying after ${classifiedError.retryDelayMs}ms...`,
152 |         );
153 |         await delay(classifiedError.retryDelayMs);
154 |         continue;
155 |       }
156 | 
157 |       // Generic retry logic for other errors
158 |       if (attempt >= maxAttempts || !shouldRetryOnError(error as Error)) {
159 |         throw error;
160 |       }
161 | 
162 |       const errorStatus = getErrorStatus(error);
163 |       logRetryAttempt(attempt, error, errorStatus);
164 | 
165 |       // Exponential backoff with jitter for non-quota errors
166 |       const jitter = currentDelay * 0.3 * (Math.random() * 2 - 1);
167 |       const delayWithJitter = Math.max(0, currentDelay + jitter);
168 |       await delay(delayWithJitter);
169 |       currentDelay = Math.min(maxDelayMs, currentDelay * 2);
170 |     }
171 |   }
172 | 
173 |   throw new Error('Retry attempts exhausted');
174 | }
175 | 
176 | /**
177 |  * Extracts the HTTP status code from an error object.
178 |  * @param error The error object.
179 |  * @returns The HTTP status code, or undefined if not found.
180 |  */
181 | export function getErrorStatus(error: unknown): number | undefined {
182 |   if (typeof error === 'object' && error !== null) {
183 |     if ('status' in error && typeof error.status === 'number') {
184 |       return error.status;
185 |     }
186 |     // Check for error.response.status (common in axios errors)
187 |     if (
188 |       'response' in error &&
189 |       typeof (error as { response?: unknown }).response === 'object' &&
190 |       (error as { response?: unknown }).response !== null
191 |     ) {
192 |       const response = (
193 |         error as { response: { status?: unknown; headers?: unknown } }
194 |       ).response;
195 |       if ('status' in response && typeof response.status === 'number') {
196 |         return response.status;
197 |       }
198 |     }
199 |   }
200 |   return undefined;
201 | }
202 | 
203 | /**
204 |  * Logs a message for a retry attempt when using exponential backoff.
205 |  * @param attempt The current attempt number.
206 |  * @param error The error that caused the retry.
207 |  * @param errorStatus The HTTP status code of the error, if available.
208 |  */
209 | function logRetryAttempt(
210 |   attempt: number,
211 |   error: unknown,
212 |   errorStatus?: number,
213 | ): void {
214 |   let message = `Attempt ${attempt} failed. Retrying with backoff...`;
215 |   if (errorStatus) {
216 |     message = `Attempt ${attempt} failed with status ${errorStatus}. Retrying with backoff...`;
217 |   }
218 | 
219 |   if (errorStatus === 429) {
220 |     console.warn(message, error);
221 |   } else if (errorStatus && errorStatus >= 500 && errorStatus < 600) {
222 |     console.error(message, error);
223 |   } else if (error instanceof Error) {
224 |     // Fallback for errors that might not have a status but have a message
225 |     if (error.message.includes('429')) {
226 |       console.warn(
227 |         `Attempt ${attempt} failed with 429 error (no Retry-After header). Retrying with backoff...`,
228 |         error,
229 |       );
230 |     } else if (error.message.match(/5\d{2}/)) {
231 |       console.error(
232 |         `Attempt ${attempt} failed with 5xx error. Retrying with backoff...`,
233 |         error,
234 |       );
235 |     } else {
236 |       console.warn(message, error); // Default to warn for other errors
237 |     }
238 |   } else {
239 |     console.warn(message, error); // Default to warn if error type is unknown
240 |   }
241 | }
```

src/utils/safeJsonStringify.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { safeJsonStringify } from './safeJsonStringify.js';
9 | 
10 | describe('safeJsonStringify', () => {
11 |   it('should stringify normal objects without issues', () => {
12 |     const obj = { name: 'test', value: 42 };
13 |     const result = safeJsonStringify(obj);
14 |     expect(result).toBe('{"name":"test","value":42}');
15 |   });
16 | 
17 |   it('should handle circular references by replacing them with [Circular]', () => {
18 |     // eslint-disable-next-line @typescript-eslint/no-explicit-any
19 |     const obj: any = { name: 'test' };
20 |     obj.circular = obj; // Create circular reference
21 | 
22 |     const result = safeJsonStringify(obj);
23 |     expect(result).toBe('{"name":"test","circular":"[Circular]"}');
24 |   });
25 | 
26 |   it('should handle complex circular structures like HttpsProxyAgent', () => {
27 |     // eslint-disable-next-line @typescript-eslint/no-explicit-any
28 |     const agent: any = {
29 |       sockets: {},
30 |       options: { host: 'example.com' },
31 |     };
32 |     agent.sockets['example.com'] = [{ agent }];
33 | 
34 |     const result = safeJsonStringify(agent);
35 |     expect(result).toContain('[Circular]');
36 |     expect(result).toContain('example.com');
37 |   });
38 | 
39 |   it('should respect the space parameter for formatting', () => {
40 |     const obj = { name: 'test', value: 42 };
41 |     const result = safeJsonStringify(obj, 2);
42 |     expect(result).toBe('{\n  "name": "test",\n  "value": 42\n}');
43 |   });
44 | 
45 |   it('should handle circular references with formatting', () => {
46 |     // eslint-disable-next-line @typescript-eslint/no-explicit-any
47 |     const obj: any = { name: 'test' };
48 |     obj.circular = obj;
49 | 
50 |     const result = safeJsonStringify(obj, 2);
51 |     expect(result).toBe('{\n  "name": "test",\n  "circular": "[Circular]"\n}');
52 |   });
53 | 
54 |   it('should handle arrays with circular references', () => {
55 |     // eslint-disable-next-line @typescript-eslint/no-explicit-any
56 |     const arr: any[] = [{ id: 1 }];
57 |     arr[0].parent = arr; // Create circular reference
58 | 
59 |     const result = safeJsonStringify(arr);
60 |     expect(result).toBe('[{"id":1,"parent":"[Circular]"}]');
61 |   });
62 | 
63 |   it('should handle null and undefined values', () => {
64 |     expect(safeJsonStringify(null)).toBe('null');
65 |     expect(safeJsonStringify(undefined)).toBe(undefined);
66 |   });
67 | 
68 |   it('should handle primitive values', () => {
69 |     expect(safeJsonStringify('test')).toBe('"test"');
70 |     expect(safeJsonStringify(42)).toBe('42');
71 |     expect(safeJsonStringify(true)).toBe('true');
72 |   });
73 | });
```

src/utils/safeJsonStringify.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Safely stringifies an object to JSON, handling circular references by replacing them with [Circular].
9 |  *
10 |  * @param obj - The object to stringify
11 |  * @param space - Optional space parameter for formatting (defaults to no formatting)
12 |  * @returns JSON string with circular references replaced by [Circular]
13 |  */
14 | export function safeJsonStringify(
15 |   obj: unknown,
16 |   space?: string | number,
17 | ): string {
18 |   const seen = new WeakSet();
19 |   return JSON.stringify(
20 |     obj,
21 |     (key, value) => {
22 |       if (typeof value === 'object' && value !== null) {
23 |         if (seen.has(value)) {
24 |           return '[Circular]';
25 |         }
26 |         seen.add(value);
27 |       }
28 |       return value;
29 |     },
30 |     space,
31 |   );
32 | }
```

src/utils/schemaValidator.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, expect, it } from 'vitest';
8 | import { SchemaValidator } from './schemaValidator.js';
9 | 
10 | describe('SchemaValidator', () => {
11 |   it('should allow any params if schema is undefined', () => {
12 |     const params = {
13 |       foo: 'bar',
14 |     };
15 |     expect(SchemaValidator.validate(undefined, params)).toBeNull();
16 |   });
17 | 
18 |   it('rejects null params', () => {
19 |     const schema = {
20 |       type: 'object',
21 |       properties: {
22 |         foo: {
23 |           type: 'string',
24 |         },
25 |       },
26 |     };
27 |     expect(SchemaValidator.validate(schema, null)).toBe(
28 |       'Value of params must be an object',
29 |     );
30 |   });
31 | 
32 |   it('rejects params that are not objects', () => {
33 |     const schema = {
34 |       type: 'object',
35 |       properties: {
36 |         foo: {
37 |           type: 'string',
38 |         },
39 |       },
40 |     };
41 |     expect(SchemaValidator.validate(schema, 'not an object')).toBe(
42 |       'Value of params must be an object',
43 |     );
44 |   });
45 | 
46 |   it('allows schema with extra properties', () => {
47 |     const schema = {
48 |       type: 'object',
49 |       properties: {
50 |         example_enum: {
51 |           type: 'string',
52 |           enum: ['FOO', 'BAR'],
53 |           // enum-descriptions is not part of the JSON schema spec.
54 |           // This test verifies that the SchemaValidator allows the
55 |           // use of extra keywords, like this one, in the schema.
56 |           'enum-descriptions': ['a foo', 'a bar'],
57 |         },
58 |       },
59 |     };
60 |     const params = {
61 |       example_enum: 'BAR',
62 |     };
63 | 
64 |     expect(SchemaValidator.validate(schema, params)).toBeNull();
65 |   });
66 | 
67 |   it('allows custom format values', () => {
68 |     const schema = {
69 |       type: 'object',
70 |       properties: {
71 |         duration: {
72 |           type: 'string',
73 |           // See: https://cloud.google.com/docs/discovery/type-format
74 |           format: 'google-duration',
75 |         },
76 |         mask: {
77 |           type: 'string',
78 |           format: 'google-fieldmask',
79 |         },
80 |         foo: {
81 |           type: 'string',
82 |           format: 'something-totally-custom',
83 |         },
84 |       },
85 |     };
86 |     const params = {
87 |       duration: '10s',
88 |       mask: 'foo.bar,biz.baz',
89 |       foo: 'some value',
90 |     };
91 |     expect(SchemaValidator.validate(schema, params)).toBeNull();
92 |   });
93 | 
94 |   it('allows valid values for known formats', () => {
95 |     const schema = {
96 |       type: 'object',
97 |       properties: {
98 |         today: {
99 |           type: 'string',
100 |           format: 'date',
101 |         },
102 |       },
103 |     };
104 |     const params = {
105 |       today: '2025-04-08',
106 |     };
107 |     expect(SchemaValidator.validate(schema, params)).toBeNull();
108 |   });
109 | 
110 |   it('rejects invalid values for known formats', () => {
111 |     const schema = {
112 |       type: 'object',
113 |       properties: {
114 |         today: {
115 |           type: 'string',
116 |           format: 'date',
117 |         },
118 |       },
119 |     };
120 |     const params = {
121 |       today: 'this is not a date',
122 |     };
123 |     expect(SchemaValidator.validate(schema, params)).not.toBeNull();
124 |   });
125 | });
```

src/utils/schemaValidator.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import AjvPkg from 'ajv';
8 | import * as addFormats from 'ajv-formats';
9 | // Ajv's ESM/CJS interop: use 'any' for compatibility as recommended by Ajv docs
10 | // eslint-disable-next-line @typescript-eslint/no-explicit-any
11 | const AjvClass = (AjvPkg as any).default || AjvPkg;
12 | const ajValidator = new AjvClass(
13 |   // See: https://ajv.js.org/options.html#strict-mode-options
14 |   {
15 |     // strictSchema defaults to true and prevents use of JSON schemas that
16 |     // include unrecognized keywords. The JSON schema spec specifically allows
17 |     // for the use of non-standard keywords and the spec-compliant behavior
18 |     // is to ignore those keywords. Note that setting this to false also
19 |     // allows use of non-standard or custom formats (the unknown format value
20 |     // will be logged but the schema will still be considered valid).
21 |     strictSchema: false,
22 |   },
23 | );
24 | // eslint-disable-next-line @typescript-eslint/no-explicit-any
25 | const addFormatsFunc = (addFormats as any).default || addFormats;
26 | addFormatsFunc(ajValidator);
27 | 
28 | /**
29 |  * Simple utility to validate objects against JSON Schemas
30 |  */
31 | export class SchemaValidator {
32 |   /**
33 |    * Returns null if the data confroms to the schema described by schema (or if schema
34 |    *  is null). Otherwise, returns a string describing the error.
35 |    */
36 |   static validate(schema: unknown | undefined, data: unknown): string | null {
37 |     if (!schema) {
38 |       return null;
39 |     }
40 |     if (typeof data !== 'object' || data === null) {
41 |       return 'Value of params must be an object';
42 |     }
43 |     const validate = ajValidator.compile(schema);
44 |     const valid = validate(data);
45 |     if (!valid && validate.errors) {
46 |       return ajValidator.errorsText(validate.errors, { dataVar: 'params' });
47 |     }
48 |     return null;
49 |   }
50 | }
```

src/utils/secure-browser-launcher.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
8 | import { openBrowserSecurely } from './secure-browser-launcher.js';
9 | 
10 | // Create mock function using vi.hoisted
11 | const mockExecFile = vi.hoisted(() => vi.fn());
12 | 
13 | // Mock modules
14 | vi.mock('node:child_process');
15 | vi.mock('node:util', () => ({
16 |   promisify: () => mockExecFile,
17 | }));
18 | 
19 | describe('secure-browser-launcher', () => {
20 |   let originalPlatform: PropertyDescriptor | undefined;
21 | 
22 |   beforeEach(() => {
23 |     vi.clearAllMocks();
24 |     mockExecFile.mockResolvedValue({ stdout: '', stderr: '' });
25 |     originalPlatform = Object.getOwnPropertyDescriptor(process, 'platform');
26 |   });
27 | 
28 |   afterEach(() => {
29 |     if (originalPlatform) {
30 |       Object.defineProperty(process, 'platform', originalPlatform);
31 |     }
32 |   });
33 | 
34 |   function setPlatform(platform: string) {
35 |     Object.defineProperty(process, 'platform', {
36 |       value: platform,
37 |       configurable: true,
38 |     });
39 |   }
40 | 
41 |   describe('URL validation', () => {
42 |     it('should allow valid HTTP URLs', async () => {
43 |       setPlatform('darwin');
44 |       await openBrowserSecurely('http://example.com');
45 |       expect(mockExecFile).toHaveBeenCalledWith(
46 |         'open',
47 |         ['http://example.com'],
48 |         expect.any(Object),
49 |       );
50 |     });
51 | 
52 |     it('should allow valid HTTPS URLs', async () => {
53 |       setPlatform('darwin');
54 |       await openBrowserSecurely('https://example.com');
55 |       expect(mockExecFile).toHaveBeenCalledWith(
56 |         'open',
57 |         ['https://example.com'],
58 |         expect.any(Object),
59 |       );
60 |     });
61 | 
62 |     it('should reject non-HTTP(S) protocols', async () => {
63 |       await expect(openBrowserSecurely('file:///etc/passwd')).rejects.toThrow(
64 |         'Unsafe protocol',
65 |       );
66 |       await expect(openBrowserSecurely('javascript:alert(1)')).rejects.toThrow(
67 |         'Unsafe protocol',
68 |       );
69 |       await expect(openBrowserSecurely('ftp://example.com')).rejects.toThrow(
70 |         'Unsafe protocol',
71 |       );
72 |     });
73 | 
74 |     it('should reject invalid URLs', async () => {
75 |       await expect(openBrowserSecurely('not-a-url')).rejects.toThrow(
76 |         'Invalid URL',
77 |       );
78 |       await expect(openBrowserSecurely('')).rejects.toThrow('Invalid URL');
79 |     });
80 | 
81 |     it('should reject URLs with control characters', async () => {
82 |       await expect(
83 |         openBrowserSecurely('http://example.com\nmalicious-command'),
84 |       ).rejects.toThrow('invalid characters');
85 |       await expect(
86 |         openBrowserSecurely('http://example.com\rmalicious-command'),
87 |       ).rejects.toThrow('invalid characters');
88 |       await expect(
89 |         openBrowserSecurely('http://example.com\x00'),
90 |       ).rejects.toThrow('invalid characters');
91 |     });
92 |   });
93 | 
94 |   describe('Command injection prevention', () => {
95 |     it('should prevent PowerShell command injection on Windows', async () => {
96 |       setPlatform('win32');
97 | 
98 |       // The POC from the vulnerability report
99 |       const maliciousUrl =
100 |         "http://127.0.0.1:8080/?param=example#$(Invoke-Expression([System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String('Y2FsYy5leGU='))))";
101 | 
102 |       await openBrowserSecurely(maliciousUrl);
103 | 
104 |       // Verify that execFile was called (not exec) and the URL is passed safely
105 |       expect(mockExecFile).toHaveBeenCalledWith(
106 |         'powershell.exe',
107 |         [
108 |           '-NoProfile',
109 |           '-NonInteractive',
110 |           '-WindowStyle',
111 |           'Hidden',
112 |           '-Command',
113 |           `Start-Process '${maliciousUrl.replace(/'/g, "''")}'`,
114 |         ],
115 |         expect.any(Object),
116 |       );
117 |     });
118 | 
119 |     it('should handle URLs with special shell characters safely', async () => {
120 |       setPlatform('darwin');
121 | 
122 |       const urlsWithSpecialChars = [
123 |         'http://example.com/path?param=value&other=$value',
124 |         'http://example.com/path#fragment;command',
125 |         'http://example.com/$(whoami)',
126 |         'http://example.com/`command`',
127 |         'http://example.com/|pipe',
128 |         'http://example.com/>redirect',
129 |       ];
130 | 
131 |       for (const url of urlsWithSpecialChars) {
132 |         await openBrowserSecurely(url);
133 |         // Verify the URL is passed as an argument, not interpreted by shell
134 |         expect(mockExecFile).toHaveBeenCalledWith(
135 |           'open',
136 |           [url],
137 |           expect.any(Object),
138 |         );
139 |       }
140 |     });
141 | 
142 |     it('should properly escape single quotes in URLs on Windows', async () => {
143 |       setPlatform('win32');
144 | 
145 |       const urlWithSingleQuotes =
146 |         "http://example.com/path?name=O'Brien&test='value'";
147 |       await openBrowserSecurely(urlWithSingleQuotes);
148 | 
149 |       // Verify that single quotes are escaped by doubling them
150 |       expect(mockExecFile).toHaveBeenCalledWith(
151 |         'powershell.exe',
152 |         [
153 |           '-NoProfile',
154 |           '-NonInteractive',
155 |           '-WindowStyle',
156 |           'Hidden',
157 |           '-Command',
158 |           `Start-Process 'http://example.com/path?name=O''Brien&test=''value'''`,
159 |         ],
160 |         expect.any(Object),
161 |       );
162 |     });
163 |   });
164 | 
165 |   describe('Platform-specific behavior', () => {
166 |     it('should use correct command on macOS', async () => {
167 |       setPlatform('darwin');
168 |       await openBrowserSecurely('https://example.com');
169 |       expect(mockExecFile).toHaveBeenCalledWith(
170 |         'open',
171 |         ['https://example.com'],
172 |         expect.any(Object),
173 |       );
174 |     });
175 | 
176 |     it('should use PowerShell on Windows', async () => {
177 |       setPlatform('win32');
178 |       await openBrowserSecurely('https://example.com');
179 |       expect(mockExecFile).toHaveBeenCalledWith(
180 |         'powershell.exe',
181 |         expect.arrayContaining([
182 |           '-Command',
183 |           `Start-Process 'https://example.com'`,
184 |         ]),
185 |         expect.any(Object),
186 |       );
187 |     });
188 | 
189 |     it('should use xdg-open on Linux', async () => {
190 |       setPlatform('linux');
191 |       await openBrowserSecurely('https://example.com');
192 |       expect(mockExecFile).toHaveBeenCalledWith(
193 |         'xdg-open',
194 |         ['https://example.com'],
195 |         expect.any(Object),
196 |       );
197 |     });
198 | 
199 |     it('should throw on unsupported platforms', async () => {
200 |       setPlatform('aix');
201 |       await expect(openBrowserSecurely('https://example.com')).rejects.toThrow(
202 |         'Unsupported platform',
203 |       );
204 |     });
205 |   });
206 | 
207 |   describe('Error handling', () => {
208 |     it('should handle browser launch failures gracefully', async () => {
209 |       setPlatform('darwin');
210 |       mockExecFile.mockRejectedValueOnce(new Error('Command not found'));
211 | 
212 |       await expect(openBrowserSecurely('https://example.com')).rejects.toThrow(
213 |         'Failed to open browser',
214 |       );
215 |     });
216 | 
217 |     it('should try fallback browsers on Linux', async () => {
218 |       setPlatform('linux');
219 | 
220 |       // First call to xdg-open fails
221 |       mockExecFile.mockRejectedValueOnce(new Error('Command not found'));
222 |       // Second call to gnome-open succeeds
223 |       mockExecFile.mockResolvedValueOnce({ stdout: '', stderr: '' });
224 | 
225 |       await openBrowserSecurely('https://example.com');
226 | 
227 |       expect(mockExecFile).toHaveBeenCalledTimes(2);
228 |       expect(mockExecFile).toHaveBeenNthCalledWith(
229 |         1,
230 |         'xdg-open',
231 |         ['https://example.com'],
232 |         expect.any(Object),
233 |       );
234 |       expect(mockExecFile).toHaveBeenNthCalledWith(
235 |         2,
236 |         'gnome-open',
237 |         ['https://example.com'],
238 |         expect.any(Object),
239 |       );
240 |     });
241 |   });
242 | });
```

src/utils/secure-browser-launcher.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { execFile } from 'node:child_process';
8 | import { promisify } from 'node:util';
9 | import { platform } from 'node:os';
10 | import { URL } from 'node:url';
11 | 
12 | const execFileAsync = promisify(execFile);
13 | 
14 | /**
15 |  * Validates that a URL is safe to open in a browser.
16 |  * Only allows HTTP and HTTPS URLs to prevent command injection.
17 |  *
18 |  * @param url The URL to validate
19 |  * @throws Error if the URL is invalid or uses an unsafe protocol
20 |  */
21 | function validateUrl(url: string): void {
22 |   let parsedUrl: URL;
23 | 
24 |   try {
25 |     parsedUrl = new URL(url);
26 |   } catch (_error) {
27 |     throw new Error(`Invalid URL: ${url}`);
28 |   }
29 | 
30 |   // Only allow HTTP and HTTPS protocols
31 |   if (parsedUrl.protocol !== 'http:' && parsedUrl.protocol !== 'https:') {
32 |     throw new Error(
33 |       `Unsafe protocol: ${parsedUrl.protocol}. Only HTTP and HTTPS are allowed.`,
34 |     );
35 |   }
36 | 
37 |   // Additional validation: ensure no newlines or control characters
38 |   // eslint-disable-next-line no-control-regex
39 |   if (/[\r\n\x00-\x1f]/.test(url)) {
40 |     throw new Error('URL contains invalid characters');
41 |   }
42 | }
43 | 
44 | /**
45 |  * Opens a URL in the default browser using platform-specific commands.
46 |  * This implementation avoids shell injection vulnerabilities by:
47 |  * 1. Validating the URL to ensure it's HTTP/HTTPS only
48 |  * 2. Using execFile instead of exec to avoid shell interpretation
49 |  * 3. Passing the URL as an argument rather than constructing a command string
50 |  *
51 |  * @param url The URL to open
52 |  * @throws Error if the URL is invalid or if opening the browser fails
53 |  */
54 | export async function openBrowserSecurely(url: string): Promise<void> {
55 |   // Validate the URL first
56 |   validateUrl(url);
57 | 
58 |   const platformName = platform();
59 |   let command: string;
60 |   let args: string[];
61 | 
62 |   switch (platformName) {
63 |     case 'darwin':
64 |       // macOS
65 |       command = 'open';
66 |       args = [url];
67 |       break;
68 | 
69 |     case 'win32':
70 |       // Windows - use PowerShell with Start-Process
71 |       // This avoids the cmd.exe shell which is vulnerable to injection
72 |       command = 'powershell.exe';
73 |       args = [
74 |         '-NoProfile',
75 |         '-NonInteractive',
76 |         '-WindowStyle',
77 |         'Hidden',
78 |         '-Command',
79 |         `Start-Process '${url.replace(/'/g, "''")}'`,
80 |       ];
81 |       break;
82 | 
83 |     case 'linux':
84 |     case 'freebsd':
85 |     case 'openbsd':
86 |       // Linux and BSD variants
87 |       // Try xdg-open first, fall back to other options
88 |       command = 'xdg-open';
89 |       args = [url];
90 |       break;
91 | 
92 |     default:
93 |       throw new Error(`Unsupported platform: ${platformName}`);
94 |   }
95 | 
96 |   const options: Record<string, unknown> = {
97 |     // Don't inherit parent's environment to avoid potential issues
98 |     env: {
99 |       ...process.env,
100 |       // Ensure we're not in a shell that might interpret special characters
101 |       SHELL: undefined,
102 |     },
103 |     // Detach the browser process so it doesn't block
104 |     detached: true,
105 |     stdio: 'ignore',
106 |   };
107 | 
108 |   try {
109 |     await execFileAsync(command, args, options);
110 |   } catch (error) {
111 |     // For Linux, try fallback commands if xdg-open fails
112 |     if (
113 |       (platformName === 'linux' ||
114 |         platformName === 'freebsd' ||
115 |         platformName === 'openbsd') &&
116 |       command === 'xdg-open'
117 |     ) {
118 |       const fallbackCommands = [
119 |         'gnome-open',
120 |         'kde-open',
121 |         'firefox',
122 |         'chromium',
123 |         'google-chrome',
124 |       ];
125 | 
126 |       for (const fallbackCommand of fallbackCommands) {
127 |         try {
128 |           await execFileAsync(fallbackCommand, [url], options);
129 |           return; // Success!
130 |         } catch {
131 |           // Try next command
132 |           continue;
133 |         }
134 |       }
135 |     }
136 | 
137 |     // Re-throw the error if all attempts failed
138 |     throw new Error(
139 |       `Failed to open browser: ${error instanceof Error ? error.message : 'Unknown error'}`,
140 |     );
141 |   }
142 | }
143 | 
144 | /**
145 |  * Checks if the current environment should attempt to launch a browser.
146 |  * This is the same logic as in browser.ts for consistency.
147 |  *
148 |  * @returns True if the tool should attempt to launch a browser
149 |  */
150 | export function shouldLaunchBrowser(): boolean {
151 |   // A list of browser names that indicate we should not attempt to open a
152 |   // web browser for the user.
153 |   const browserBlocklist = ['www-browser'];
154 |   const browserEnv = process.env['BROWSER'];
155 |   if (browserEnv && browserBlocklist.includes(browserEnv)) {
156 |     return false;
157 |   }
158 | 
159 |   // Common environment variables used in CI/CD or other non-interactive shells.
160 |   if (
161 |     process.env['CI'] ||
162 |     process.env['DEBIAN_FRONTEND'] === 'noninteractive'
163 |   ) {
164 |     return false;
165 |   }
166 | 
167 |   // The presence of SSH_CONNECTION indicates a remote session.
168 |   // We should not attempt to launch a browser unless a display is explicitly available
169 |   // (checked below for Linux).
170 |   const isSSH = !!process.env['SSH_CONNECTION'];
171 | 
172 |   // On Linux, the presence of a display server is a strong indicator of a GUI.
173 |   if (platform() === 'linux') {
174 |     // These are environment variables that can indicate a running compositor on Linux.
175 |     const displayVariables = ['DISPLAY', 'WAYLAND_DISPLAY', 'MIR_SOCKET'];
176 |     const hasDisplay = displayVariables.some((v) => !!process.env[v]);
177 |     if (!hasDisplay) {
178 |       return false;
179 |     }
180 |   }
181 | 
182 |   // If in an SSH session on a non-Linux OS (e.g., macOS), don't launch browser.
183 |   // The Linux case is handled above (it's allowed if DISPLAY is set).
184 |   if (isSSH && platform() !== 'linux') {
185 |     return false;
186 |   }
187 | 
188 |   // For non-Linux OSes, we generally assume a GUI is available
189 |   // unless other signals (like SSH) suggest otherwise.
190 |   return true;
191 | }
```

src/utils/session.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { randomUUID } from 'node:crypto';
8 | 
9 | export const sessionId = randomUUID();
```

src/utils/shell-utils.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { expect, describe, it, beforeEach, vi, afterEach } from 'vitest';
8 | import {
9 |   checkCommandPermissions,
10 |   escapeShellArg,
11 |   getCommandRoots,
12 |   getShellConfiguration,
13 |   isCommandAllowed,
14 |   stripShellWrapper,
15 | } from './shell-utils.js';
16 | import type { Config } from '../config/config.js';
17 | 
18 | const mockPlatform = vi.hoisted(() => vi.fn());
19 | const mockHomedir = vi.hoisted(() => vi.fn());
20 | vi.mock('os', () => ({
21 |   default: {
22 |     platform: mockPlatform,
23 |     homedir: mockHomedir,
24 |   },
25 |   platform: mockPlatform,
26 |   homedir: mockHomedir,
27 | }));
28 | 
29 | const mockQuote = vi.hoisted(() => vi.fn());
30 | vi.mock('shell-quote', () => ({
31 |   quote: mockQuote,
32 | }));
33 | 
34 | let config: Config;
35 | 
36 | beforeEach(() => {
37 |   mockPlatform.mockReturnValue('linux');
38 |   mockQuote.mockImplementation((args: string[]) =>
39 |     args.map((arg) => `'${arg}'`).join(' '),
40 |   );
41 |   config = {
42 |     getCoreTools: () => [],
43 |     getExcludeTools: () => [],
44 |     getAllowedTools: () => [],
45 |   } as unknown as Config;
46 | });
47 | 
48 | afterEach(() => {
49 |   vi.clearAllMocks();
50 | });
51 | 
52 | describe('isCommandAllowed', () => {
53 |   it('should allow a command if no restrictions are provided', () => {
54 |     const result = isCommandAllowed('ls -l', config);
55 |     expect(result.allowed).toBe(true);
56 |   });
57 | 
58 |   it('should allow a command if it is in the global allowlist', () => {
59 |     config.getCoreTools = () => ['ShellTool(ls)'];
60 |     const result = isCommandAllowed('ls -l', config);
61 |     expect(result.allowed).toBe(true);
62 |   });
63 | 
64 |   it('should block a command if it is not in a strict global allowlist', () => {
65 |     config.getCoreTools = () => ['ShellTool(ls -l)'];
66 |     const result = isCommandAllowed('rm -rf /', config);
67 |     expect(result.allowed).toBe(false);
68 |     expect(result.reason).toBe(
69 |       `Command(s) not in the allowed commands list. Disallowed commands: "rm -rf /"`,
70 |     );
71 |   });
72 | 
73 |   it('should block a command if it is in the blocked list', () => {
74 |     config.getExcludeTools = () => ['ShellTool(rm -rf /)'];
75 |     const result = isCommandAllowed('rm -rf /', config);
76 |     expect(result.allowed).toBe(false);
77 |     expect(result.reason).toBe(
78 |       `Command 'rm -rf /' is blocked by configuration`,
79 |     );
80 |   });
81 | 
82 |   it('should prioritize the blocklist over the allowlist', () => {
83 |     config.getCoreTools = () => ['ShellTool(rm -rf /)'];
84 |     config.getExcludeTools = () => ['ShellTool(rm -rf /)'];
85 |     const result = isCommandAllowed('rm -rf /', config);
86 |     expect(result.allowed).toBe(false);
87 |     expect(result.reason).toBe(
88 |       `Command 'rm -rf /' is blocked by configuration`,
89 |     );
90 |   });
91 | 
92 |   it('should allow any command when a wildcard is in coreTools', () => {
93 |     config.getCoreTools = () => ['ShellTool'];
94 |     const result = isCommandAllowed('any random command', config);
95 |     expect(result.allowed).toBe(true);
96 |   });
97 | 
98 |   it('should block any command when a wildcard is in excludeTools', () => {
99 |     config.getExcludeTools = () => ['run_shell_command'];
100 |     const result = isCommandAllowed('any random command', config);
101 |     expect(result.allowed).toBe(false);
102 |     expect(result.reason).toBe(
103 |       'Shell tool is globally disabled in configuration',
104 |     );
105 |   });
106 | 
107 |   it('should block a command on the blocklist even with a wildcard allow', () => {
108 |     config.getCoreTools = () => ['ShellTool'];
109 |     config.getExcludeTools = () => ['ShellTool(rm -rf /)'];
110 |     const result = isCommandAllowed('rm -rf /', config);
111 |     expect(result.allowed).toBe(false);
112 |     expect(result.reason).toBe(
113 |       `Command 'rm -rf /' is blocked by configuration`,
114 |     );
115 |   });
116 | 
117 |   it('should allow a chained command if all parts are on the global allowlist', () => {
118 |     config.getCoreTools = () => [
119 |       'run_shell_command(echo)',
120 |       'run_shell_command(ls)',
121 |     ];
122 |     const result = isCommandAllowed('echo "hello" && ls -l', config);
123 |     expect(result.allowed).toBe(true);
124 |   });
125 | 
126 |   it('should block a chained command if any part is blocked', () => {
127 |     config.getExcludeTools = () => ['run_shell_command(rm)'];
128 |     const result = isCommandAllowed('echo "hello" && rm -rf /', config);
129 |     expect(result.allowed).toBe(false);
130 |     expect(result.reason).toBe(
131 |       `Command 'rm -rf /' is blocked by configuration`,
132 |     );
133 |   });
134 | 
135 |   describe('command substitution', () => {
136 |     it('should block command substitution using `$(...)`', () => {
137 |       const result = isCommandAllowed('echo $(rm -rf /)', config);
138 |       expect(result.allowed).toBe(false);
139 |       expect(result.reason).toContain('Command substitution');
140 |     });
141 | 
142 |     it('should block command substitution using `<(...)`', () => {
143 |       const result = isCommandAllowed('diff <(ls) <(ls -a)', config);
144 |       expect(result.allowed).toBe(false);
145 |       expect(result.reason).toContain('Command substitution');
146 |     });
147 | 
148 |     it('should block command substitution using `>(...)`', () => {
149 |       const result = isCommandAllowed(
150 |         'echo "Log message" > >(tee log.txt)',
151 |         config,
152 |       );
153 |       expect(result.allowed).toBe(false);
154 |       expect(result.reason).toContain('Command substitution');
155 |     });
156 | 
157 |     it('should block command substitution using backticks', () => {
158 |       const result = isCommandAllowed('echo `rm -rf /`', config);
159 |       expect(result.allowed).toBe(false);
160 |       expect(result.reason).toContain('Command substitution');
161 |     });
162 | 
163 |     it('should allow substitution-like patterns inside single quotes', () => {
164 |       config.getCoreTools = () => ['ShellTool(echo)'];
165 |       const result = isCommandAllowed("echo '$(pwd)'", config);
166 |       expect(result.allowed).toBe(true);
167 |     });
168 |   });
169 | });
170 | 
171 | describe('checkCommandPermissions', () => {
172 |   describe('in "Default Allow" mode (no sessionAllowlist)', () => {
173 |     it('should return a detailed success object for an allowed command', () => {
174 |       const result = checkCommandPermissions('ls -l', config);
175 |       expect(result).toEqual({
176 |         allAllowed: true,
177 |         disallowedCommands: [],
178 |       });
179 |     });
180 | 
181 |     it('should return a detailed failure object for a blocked command', () => {
182 |       config.getExcludeTools = () => ['ShellTool(rm)'];
183 |       const result = checkCommandPermissions('rm -rf /', config);
184 |       expect(result).toEqual({
185 |         allAllowed: false,
186 |         disallowedCommands: ['rm -rf /'],
187 |         blockReason: `Command 'rm -rf /' is blocked by configuration`,
188 |         isHardDenial: true,
189 |       });
190 |     });
191 | 
192 |     it('should return a detailed failure object for a command not on a strict allowlist', () => {
193 |       config.getCoreTools = () => ['ShellTool(ls)'];
194 |       const result = checkCommandPermissions('git status && ls', config);
195 |       expect(result).toEqual({
196 |         allAllowed: false,
197 |         disallowedCommands: ['git status'],
198 |         blockReason: `Command(s) not in the allowed commands list. Disallowed commands: "git status"`,
199 |         isHardDenial: false,
200 |       });
201 |     });
202 |   });
203 | 
204 |   describe('in "Default Deny" mode (with sessionAllowlist)', () => {
205 |     it('should allow a command on the sessionAllowlist', () => {
206 |       const result = checkCommandPermissions(
207 |         'ls -l',
208 |         config,
209 |         new Set(['ls -l']),
210 |       );
211 |       expect(result.allAllowed).toBe(true);
212 |     });
213 | 
214 |     it('should block a command not on the sessionAllowlist or global allowlist', () => {
215 |       const result = checkCommandPermissions(
216 |         'rm -rf /',
217 |         config,
218 |         new Set(['ls -l']),
219 |       );
220 |       expect(result.allAllowed).toBe(false);
221 |       expect(result.blockReason).toContain(
222 |         'not on the global or session allowlist',
223 |       );
224 |       expect(result.disallowedCommands).toEqual(['rm -rf /']);
225 |     });
226 | 
227 |     it('should allow a command on the global allowlist even if not on the session allowlist', () => {
228 |       config.getCoreTools = () => ['ShellTool(git status)'];
229 |       const result = checkCommandPermissions(
230 |         'git status',
231 |         config,
232 |         new Set(['ls -l']),
233 |       );
234 |       expect(result.allAllowed).toBe(true);
235 |     });
236 | 
237 |     it('should allow a chained command if parts are on different allowlists', () => {
238 |       config.getCoreTools = () => ['ShellTool(git status)'];
239 |       const result = checkCommandPermissions(
240 |         'git status && git commit',
241 |         config,
242 |         new Set(['git commit']),
243 |       );
244 |       expect(result.allAllowed).toBe(true);
245 |     });
246 | 
247 |     it('should block a command on the sessionAllowlist if it is also globally blocked', () => {
248 |       config.getExcludeTools = () => ['run_shell_command(rm)'];
249 |       const result = checkCommandPermissions(
250 |         'rm -rf /',
251 |         config,
252 |         new Set(['rm -rf /']),
253 |       );
254 |       expect(result.allAllowed).toBe(false);
255 |       expect(result.blockReason).toContain('is blocked by configuration');
256 |     });
257 | 
258 |     it('should block a chained command if one part is not on any allowlist', () => {
259 |       config.getCoreTools = () => ['run_shell_command(echo)'];
260 |       const result = checkCommandPermissions(
261 |         'echo "hello" && rm -rf /',
262 |         config,
263 |         new Set(['echo']),
264 |       );
265 |       expect(result.allAllowed).toBe(false);
266 |       expect(result.disallowedCommands).toEqual(['rm -rf /']);
267 |     });
268 |   });
269 | });
270 | 
271 | describe('getCommandRoots', () => {
272 |   it('should return a single command', () => {
273 |     expect(getCommandRoots('ls -l')).toEqual(['ls']);
274 |   });
275 | 
276 |   it('should handle paths and return the binary name', () => {
277 |     expect(getCommandRoots('/usr/local/bin/node script.js')).toEqual(['node']);
278 |   });
279 | 
280 |   it('should return an empty array for an empty string', () => {
281 |     expect(getCommandRoots('')).toEqual([]);
282 |   });
283 | 
284 |   it('should handle a mix of operators', () => {
285 |     const result = getCommandRoots('a;b|c&&d||e&f');
286 |     expect(result).toEqual(['a', 'b', 'c', 'd', 'e', 'f']);
287 |   });
288 | 
289 |   it('should correctly parse a chained command with quotes', () => {
290 |     const result = getCommandRoots('echo "hello" && git commit -m "feat"');
291 |     expect(result).toEqual(['echo', 'git']);
292 |   });
293 | });
294 | 
295 | describe('stripShellWrapper', () => {
296 |   it('should strip sh -c with quotes', () => {
297 |     expect(stripShellWrapper('sh -c "ls -l"')).toEqual('ls -l');
298 |   });
299 | 
300 |   it('should strip bash -c with extra whitespace', () => {
301 |     expect(stripShellWrapper('  bash  -c  "ls -l"  ')).toEqual('ls -l');
302 |   });
303 | 
304 |   it('should strip zsh -c without quotes', () => {
305 |     expect(stripShellWrapper('zsh -c ls -l')).toEqual('ls -l');
306 |   });
307 | 
308 |   it('should strip cmd.exe /c', () => {
309 |     expect(stripShellWrapper('cmd.exe /c "dir"')).toEqual('dir');
310 |   });
311 | 
312 |   it('should not strip anything if no wrapper is present', () => {
313 |     expect(stripShellWrapper('ls -l')).toEqual('ls -l');
314 |   });
315 | });
316 | 
317 | describe('escapeShellArg', () => {
318 |   describe('POSIX (bash)', () => {
319 |     it('should use shell-quote for escaping', () => {
320 |       mockQuote.mockReturnValueOnce("'escaped value'");
321 |       const result = escapeShellArg('raw value', 'bash');
322 |       expect(mockQuote).toHaveBeenCalledWith(['raw value']);
323 |       expect(result).toBe("'escaped value'");
324 |     });
325 | 
326 |     it('should handle empty strings', () => {
327 |       const result = escapeShellArg('', 'bash');
328 |       expect(result).toBe('');
329 |       expect(mockQuote).not.toHaveBeenCalled();
330 |     });
331 |   });
332 | 
333 |   describe('Windows', () => {
334 |     describe('when shell is cmd.exe', () => {
335 |       it('should wrap simple arguments in double quotes', () => {
336 |         const result = escapeShellArg('search term', 'cmd');
337 |         expect(result).toBe('"search term"');
338 |       });
339 | 
340 |       it('should escape internal double quotes by doubling them', () => {
341 |         const result = escapeShellArg('He said "Hello"', 'cmd');
342 |         expect(result).toBe('"He said ""Hello"""');
343 |       });
344 | 
345 |       it('should handle empty strings', () => {
346 |         const result = escapeShellArg('', 'cmd');
347 |         expect(result).toBe('');
348 |       });
349 |     });
350 | 
351 |     describe('when shell is PowerShell', () => {
352 |       it('should wrap simple arguments in single quotes', () => {
353 |         const result = escapeShellArg('search term', 'powershell');
354 |         expect(result).toBe("'search term'");
355 |       });
356 | 
357 |       it('should escape internal single quotes by doubling them', () => {
358 |         const result = escapeShellArg("It's a test", 'powershell');
359 |         expect(result).toBe("'It''s a test'");
360 |       });
361 | 
362 |       it('should handle double quotes without escaping them', () => {
363 |         const result = escapeShellArg('He said "Hello"', 'powershell');
364 |         expect(result).toBe('\'He said "Hello"\'');
365 |       });
366 | 
367 |       it('should handle empty strings', () => {
368 |         const result = escapeShellArg('', 'powershell');
369 |         expect(result).toBe('');
370 |       });
371 |     });
372 |   });
373 | });
374 | 
375 | describe('getShellConfiguration', () => {
376 |   const originalEnv = { ...process.env };
377 | 
378 |   afterEach(() => {
379 |     process.env = originalEnv;
380 |   });
381 | 
382 |   it('should return bash configuration on Linux', () => {
383 |     mockPlatform.mockReturnValue('linux');
384 |     const config = getShellConfiguration();
385 |     expect(config.executable).toBe('bash');
386 |     expect(config.argsPrefix).toEqual(['-c']);
387 |     expect(config.shell).toBe('bash');
388 |   });
389 | 
390 |   it('should return bash configuration on macOS (darwin)', () => {
391 |     mockPlatform.mockReturnValue('darwin');
392 |     const config = getShellConfiguration();
393 |     expect(config.executable).toBe('bash');
394 |     expect(config.argsPrefix).toEqual(['-c']);
395 |     expect(config.shell).toBe('bash');
396 |   });
397 | 
398 |   describe('on Windows', () => {
399 |     beforeEach(() => {
400 |       mockPlatform.mockReturnValue('win32');
401 |     });
402 | 
403 |     it('should return cmd.exe configuration by default', () => {
404 |       delete process.env['ComSpec'];
405 |       const config = getShellConfiguration();
406 |       expect(config.executable).toBe('cmd.exe');
407 |       expect(config.argsPrefix).toEqual(['/d', '/s', '/c']);
408 |       expect(config.shell).toBe('cmd');
409 |     });
410 | 
411 |     it('should respect ComSpec for cmd.exe', () => {
412 |       const cmdPath = 'C:\\WINDOWS\\system32\\cmd.exe';
413 |       process.env['ComSpec'] = cmdPath;
414 |       const config = getShellConfiguration();
415 |       expect(config.executable).toBe(cmdPath);
416 |       expect(config.argsPrefix).toEqual(['/d', '/s', '/c']);
417 |       expect(config.shell).toBe('cmd');
418 |     });
419 | 
420 |     it('should return PowerShell configuration if ComSpec points to powershell.exe', () => {
421 |       const psPath =
422 |         'C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0\\powershell.exe';
423 |       process.env['ComSpec'] = psPath;
424 |       const config = getShellConfiguration();
425 |       expect(config.executable).toBe(psPath);
426 |       expect(config.argsPrefix).toEqual(['-NoProfile', '-Command']);
427 |       expect(config.shell).toBe('powershell');
428 |     });
429 | 
430 |     it('should return PowerShell configuration if ComSpec points to pwsh.exe', () => {
431 |       const pwshPath = 'C:\\Program Files\\PowerShell\\7\\pwsh.exe';
432 |       process.env['ComSpec'] = pwshPath;
433 |       const config = getShellConfiguration();
434 |       expect(config.executable).toBe(pwshPath);
435 |       expect(config.argsPrefix).toEqual(['-NoProfile', '-Command']);
436 |       expect(config.shell).toBe('powershell');
437 |     });
438 | 
439 |     it('should be case-insensitive when checking ComSpec', () => {
440 |       process.env['ComSpec'] = 'C:\\Path\\To\\POWERSHELL.EXE';
441 |       const config = getShellConfiguration();
442 |       expect(config.executable).toBe('C:\\Path\\To\\POWERSHELL.EXE');
443 |       expect(config.argsPrefix).toEqual(['-NoProfile', '-Command']);
444 |       expect(config.shell).toBe('powershell');
445 |     });
446 |   });
447 | });
```

src/utils/shell-utils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { AnyToolInvocation } from '../index.js';
8 | import type { Config } from '../config/config.js';
9 | import os from 'node:os';
10 | import { quote } from 'shell-quote';
11 | import { doesToolInvocationMatch } from './tool-utils.js';
12 | import { spawn, type SpawnOptionsWithoutStdio } from 'node:child_process';
13 | 
14 | export const SHELL_TOOL_NAMES = ['run_shell_command', 'ShellTool'];
15 | 
16 | /**
17 |  * An identifier for the shell type.
18 |  */
19 | export type ShellType = 'cmd' | 'powershell' | 'bash';
20 | 
21 | /**
22 |  * Defines the configuration required to execute a command string within a specific shell.
23 |  */
24 | export interface ShellConfiguration {
25 |   /** The path or name of the shell executable (e.g., 'bash', 'cmd.exe'). */
26 |   executable: string;
27 |   /**
28 |    * The arguments required by the shell to execute a subsequent string argument.
29 |    */
30 |   argsPrefix: string[];
31 |   /** An identifier for the shell type. */
32 |   shell: ShellType;
33 | }
34 | 
35 | /**
36 |  * Determines the appropriate shell configuration for the current platform.
37 |  *
38 |  * This ensures we can execute command strings predictably and securely across platforms
39 |  * using the `spawn(executable, [...argsPrefix, commandString], { shell: false })` pattern.
40 |  *
41 |  * @returns The ShellConfiguration for the current environment.
42 |  */
43 | export function getShellConfiguration(): ShellConfiguration {
44 |   if (isWindows()) {
45 |     const comSpec = process.env['ComSpec'] || 'cmd.exe';
46 |     const executable = comSpec.toLowerCase();
47 | 
48 |     if (
49 |       executable.endsWith('powershell.exe') ||
50 |       executable.endsWith('pwsh.exe')
51 |     ) {
52 |       // For PowerShell, the arguments are different.
53 |       // -NoProfile: Speeds up startup.
54 |       // -Command: Executes the following command.
55 |       return {
56 |         executable: comSpec,
57 |         argsPrefix: ['-NoProfile', '-Command'],
58 |         shell: 'powershell',
59 |       };
60 |     }
61 | 
62 |     // Default to cmd.exe for anything else on Windows.
63 |     // Flags for CMD:
64 |     // /d: Skip execution of AutoRun commands.
65 |     // /s: Modifies the treatment of the command string (important for quoting).
66 |     // /c: Carries out the command specified by the string and then terminates.
67 |     return {
68 |       executable: comSpec,
69 |       argsPrefix: ['/d', '/s', '/c'],
70 |       shell: 'cmd',
71 |     };
72 |   }
73 | 
74 |   // Unix-like systems (Linux, macOS)
75 |   return { executable: 'bash', argsPrefix: ['-c'], shell: 'bash' };
76 | }
77 | 
78 | /**
79 |  * Export the platform detection constant for use in process management (e.g., killing processes).
80 |  */
81 | export const isWindows = () => os.platform() === 'win32';
82 | 
83 | /**
84 |  * Escapes a string so that it can be safely used as a single argument
85 |  * in a shell command, preventing command injection.
86 |  *
87 |  * @param arg The argument string to escape.
88 |  * @param shell The type of shell the argument is for.
89 |  * @returns The shell-escaped string.
90 |  */
91 | export function escapeShellArg(arg: string, shell: ShellType): string {
92 |   if (!arg) {
93 |     return '';
94 |   }
95 | 
96 |   switch (shell) {
97 |     case 'powershell':
98 |       // For PowerShell, wrap in single quotes and escape internal single quotes by doubling them.
99 |       return `'${arg.replace(/'/g, "''")}'`;
100 |     case 'cmd':
101 |       // Simple Windows escaping for cmd.exe: wrap in double quotes and escape inner double quotes.
102 |       return `"${arg.replace(/"/g, '""')}"`;
103 |     case 'bash':
104 |     default:
105 |       // POSIX shell escaping using shell-quote.
106 |       return quote([arg]);
107 |   }
108 | }
109 | 
110 | /**
111 |  * Splits a shell command into a list of individual commands, respecting quotes.
112 |  * This is used to separate chained commands (e.g., using &&, ||, ;).
113 |  * @param command The shell command string to parse
114 |  * @returns An array of individual command strings
115 |  */
116 | export function splitCommands(command: string): string[] {
117 |   const commands: string[] = [];
118 |   let currentCommand = '';
119 |   let inSingleQuotes = false;
120 |   let inDoubleQuotes = false;
121 |   let i = 0;
122 | 
123 |   while (i < command.length) {
124 |     const char = command[i];
125 |     const nextChar = command[i + 1];
126 | 
127 |     if (char === '\\' && i < command.length - 1) {
128 |       currentCommand += char + command[i + 1];
129 |       i += 2;
130 |       continue;
131 |     }
132 | 
133 |     if (char === "'" && !inDoubleQuotes) {
134 |       inSingleQuotes = !inSingleQuotes;
135 |     } else if (char === '"' && !inSingleQuotes) {
136 |       inDoubleQuotes = !inDoubleQuotes;
137 |     }
138 | 
139 |     if (!inSingleQuotes && !inDoubleQuotes) {
140 |       if (
141 |         (char === '&' && nextChar === '&') ||
142 |         (char === '|' && nextChar === '|')
143 |       ) {
144 |         commands.push(currentCommand.trim());
145 |         currentCommand = '';
146 |         i++; // Skip the next character
147 |       } else if (char === ';' || char === '&' || char === '|') {
148 |         commands.push(currentCommand.trim());
149 |         currentCommand = '';
150 |       } else {
151 |         currentCommand += char;
152 |       }
153 |     } else {
154 |       currentCommand += char;
155 |     }
156 |     i++;
157 |   }
158 | 
159 |   if (currentCommand.trim()) {
160 |     commands.push(currentCommand.trim());
161 |   }
162 | 
163 |   return commands.filter(Boolean); // Filter out any empty strings
164 | }
165 | 
166 | /**
167 |  * Extracts the root command from a given shell command string.
168 |  * This is used to identify the base command for permission checks.
169 |  * @param command The shell command string to parse
170 |  * @returns The root command name, or undefined if it cannot be determined
171 |  * @example getCommandRoot("ls -la /tmp") returns "ls"
172 |  * @example getCommandRoot("git status && npm test") returns "git"
173 |  */
174 | export function getCommandRoot(command: string): string | undefined {
175 |   const trimmedCommand = command.trim();
176 |   if (!trimmedCommand) {
177 |     return undefined;
178 |   }
179 | 
180 |   // This regex is designed to find the first "word" of a command,
181 |   // while respecting quotes. It looks for a sequence of non-whitespace
182 |   // characters that are not inside quotes.
183 |   const match = trimmedCommand.match(/^"([^"]+)"|^'([^']+)'|^(\S+)/);
184 |   if (match) {
185 |     // The first element in the match array is the full match.
186 |     // The subsequent elements are the capture groups.
187 |     // We prefer a captured group because it will be unquoted.
188 |     const commandRoot = match[1] || match[2] || match[3];
189 |     if (commandRoot) {
190 |       // If the command is a path, return the last component.
191 |       return commandRoot.split(/[\\/]/).pop();
192 |     }
193 |   }
194 | 
195 |   return undefined;
196 | }
197 | 
198 | export function getCommandRoots(command: string): string[] {
199 |   if (!command) {
200 |     return [];
201 |   }
202 |   return splitCommands(command)
203 |     .map((c) => getCommandRoot(c))
204 |     .filter((c): c is string => !!c);
205 | }
206 | 
207 | export function stripShellWrapper(command: string): string {
208 |   const pattern = /^\s*(?:sh|bash|zsh|cmd.exe)\s+(?:\/c|-c)\s+/;
209 |   const match = command.match(pattern);
210 |   if (match) {
211 |     let newCommand = command.substring(match[0].length).trim();
212 |     if (
213 |       (newCommand.startsWith('"') && newCommand.endsWith('"')) ||
214 |       (newCommand.startsWith("'") && newCommand.endsWith("'"))
215 |     ) {
216 |       newCommand = newCommand.substring(1, newCommand.length - 1);
217 |     }
218 |     return newCommand;
219 |   }
220 |   return command.trim();
221 | }
222 | 
223 | /**
224 |  * Detects command substitution patterns in a shell command, following bash quoting rules:
225 |  * - Single quotes ('): Everything literal, no substitution possible
226 |  * - Double quotes ("): Command substitution with $() and backticks unless escaped with \
227 |  * - No quotes: Command substitution with $(), <(), and backticks
228 |  * @param command The shell command string to check
229 |  * @returns true if command substitution would be executed by bash
230 |  */
231 | export function detectCommandSubstitution(command: string): boolean {
232 |   let inSingleQuotes = false;
233 |   let inDoubleQuotes = false;
234 |   let inBackticks = false;
235 |   let i = 0;
236 | 
237 |   while (i < command.length) {
238 |     const char = command[i];
239 |     const nextChar = command[i + 1];
240 | 
241 |     // Handle escaping - only works outside single quotes
242 |     if (char === '\\' && !inSingleQuotes) {
243 |       i += 2; // Skip the escaped character
244 |       continue;
245 |     }
246 | 
247 |     // Handle quote state changes
248 |     if (char === "'" && !inDoubleQuotes && !inBackticks) {
249 |       inSingleQuotes = !inSingleQuotes;
250 |     } else if (char === '"' && !inSingleQuotes && !inBackticks) {
251 |       inDoubleQuotes = !inDoubleQuotes;
252 |     } else if (char === '`' && !inSingleQuotes) {
253 |       // Backticks work outside single quotes (including in double quotes)
254 |       inBackticks = !inBackticks;
255 |     }
256 | 
257 |     // Check for command substitution patterns that would be executed
258 |     if (!inSingleQuotes) {
259 |       // $(...) command substitution - works in double quotes and unquoted
260 |       if (char === '$' && nextChar === '(') {
261 |         return true;
262 |       }
263 | 
264 |       // <(...) process substitution - works unquoted only (not in double quotes)
265 |       if (char === '<' && nextChar === '(' && !inDoubleQuotes && !inBackticks) {
266 |         return true;
267 |       }
268 | 
269 |       // >(...) process substitution - works unquoted only (not in double quotes)
270 |       if (char === '>' && nextChar === '(' && !inDoubleQuotes && !inBackticks) {
271 |         return true;
272 |       }
273 | 
274 |       // Backtick command substitution - check for opening backtick
275 |       // (We track the state above, so this catches the start of backtick substitution)
276 |       if (char === '`' && !inBackticks) {
277 |         return true;
278 |       }
279 |     }
280 | 
281 |     i++;
282 |   }
283 | 
284 |   return false;
285 | }
286 | 
287 | /**
288 |  * Checks a shell command against security policies and allowlists.
289 |  *
290 |  * This function operates in one of two modes depending on the presence of
291 |  * the `sessionAllowlist` parameter:
292 |  *
293 |  * 1.  **"Default Deny" Mode (sessionAllowlist is provided):** This is the
294 |  *     strictest mode, used for user-defined scripts like custom commands.
295 |  *     A command is only permitted if it is found on the global `coreTools`
296 |  *     allowlist OR the provided `sessionAllowlist`. It must not be on the
297 |  *     global `excludeTools` blocklist.
298 |  *
299 |  * 2.  **"Default Allow" Mode (sessionAllowlist is NOT provided):** This mode
300 |  *     is used for direct tool invocations (e.g., by the model). If a strict
301 |  *     global `coreTools` allowlist exists, commands must be on it. Otherwise,
302 |  *     any command is permitted as long as it is not on the `excludeTools`
303 |  *     blocklist.
304 |  *
305 |  * @param command The shell command string to validate.
306 |  * @param config The application configuration.
307 |  * @param sessionAllowlist A session-level list of approved commands. Its
308 |  *   presence activates "Default Deny" mode.
309 |  * @returns An object detailing which commands are not allowed.
310 |  */
311 | export function checkCommandPermissions(
312 |   command: string,
313 |   config: Config,
314 |   sessionAllowlist?: Set<string>,
315 | ): {
316 |   allAllowed: boolean;
317 |   disallowedCommands: string[];
318 |   blockReason?: string;
319 |   isHardDenial?: boolean;
320 | } {
321 |   // Disallow command substitution for security.
322 |   if (detectCommandSubstitution(command)) {
323 |     return {
324 |       allAllowed: false,
325 |       disallowedCommands: [command],
326 |       blockReason:
327 |         'Command substitution using $(), `` ` ``, <(), or >() is not allowed for security reasons',
328 |       isHardDenial: true,
329 |     };
330 |   }
331 | 
332 |   const normalize = (cmd: string): string => cmd.trim().replace(/\s+/g, ' ');
333 |   const commandsToValidate = splitCommands(command).map(normalize);
334 |   const invocation: AnyToolInvocation & { params: { command: string } } = {
335 |     params: { command: '' },
336 |   } as AnyToolInvocation & { params: { command: string } };
337 | 
338 |   // 1. Blocklist Check (Highest Priority)
339 |   const excludeTools = config.getExcludeTools() || [];
340 |   const isWildcardBlocked = SHELL_TOOL_NAMES.some((name) =>
341 |     excludeTools.includes(name),
342 |   );
343 | 
344 |   if (isWildcardBlocked) {
345 |     return {
346 |       allAllowed: false,
347 |       disallowedCommands: commandsToValidate,
348 |       blockReason: 'Shell tool is globally disabled in configuration',
349 |       isHardDenial: true,
350 |     };
351 |   }
352 | 
353 |   for (const cmd of commandsToValidate) {
354 |     invocation.params['command'] = cmd;
355 |     if (
356 |       doesToolInvocationMatch('run_shell_command', invocation, excludeTools)
357 |     ) {
358 |       return {
359 |         allAllowed: false,
360 |         disallowedCommands: [cmd],
361 |         blockReason: `Command '${cmd}' is blocked by configuration`,
362 |         isHardDenial: true,
363 |       };
364 |     }
365 |   }
366 | 
367 |   const coreTools = config.getCoreTools() || [];
368 |   const isWildcardAllowed = SHELL_TOOL_NAMES.some((name) =>
369 |     coreTools.includes(name),
370 |   );
371 | 
372 |   // If there's a global wildcard, all commands are allowed at this point
373 |   // because they have already passed the blocklist check.
374 |   if (isWildcardAllowed) {
375 |     return { allAllowed: true, disallowedCommands: [] };
376 |   }
377 | 
378 |   const disallowedCommands: string[] = [];
379 | 
380 |   if (sessionAllowlist) {
381 |     // "DEFAULT DENY" MODE: A session allowlist is provided.
382 |     // All commands must be in either the session or global allowlist.
383 |     const normalizedSessionAllowlist = new Set(
384 |       [...sessionAllowlist].flatMap((cmd) =>
385 |         SHELL_TOOL_NAMES.map((name) => `${name}(${cmd})`),
386 |       ),
387 |     );
388 | 
389 |     for (const cmd of commandsToValidate) {
390 |       invocation.params['command'] = cmd;
391 |       const isSessionAllowed = doesToolInvocationMatch(
392 |         'run_shell_command',
393 |         invocation,
394 |         [...normalizedSessionAllowlist],
395 |       );
396 |       if (isSessionAllowed) continue;
397 | 
398 |       const isGloballyAllowed = doesToolInvocationMatch(
399 |         'run_shell_command',
400 |         invocation,
401 |         coreTools,
402 |       );
403 |       if (isGloballyAllowed) continue;
404 | 
405 |       disallowedCommands.push(cmd);
406 |     }
407 | 
408 |     if (disallowedCommands.length > 0) {
409 |       return {
410 |         allAllowed: false,
411 |         disallowedCommands,
412 |         blockReason: `Command(s) not on the global or session allowlist. Disallowed commands: ${disallowedCommands
413 |           .map((c) => JSON.stringify(c))
414 |           .join(', ')}`,
415 |         isHardDenial: false, // This is a soft denial; confirmation is possible.
416 |       };
417 |     }
418 |   } else {
419 |     // "DEFAULT ALLOW" MODE: No session allowlist.
420 |     const hasSpecificAllowedCommands =
421 |       coreTools.filter((tool) =>
422 |         SHELL_TOOL_NAMES.some((name) => tool.startsWith(`${name}(`)),
423 |       ).length > 0;
424 | 
425 |     if (hasSpecificAllowedCommands) {
426 |       for (const cmd of commandsToValidate) {
427 |         invocation.params['command'] = cmd;
428 |         const isGloballyAllowed = doesToolInvocationMatch(
429 |           'run_shell_command',
430 |           invocation,
431 |           coreTools,
432 |         );
433 |         if (!isGloballyAllowed) {
434 |           disallowedCommands.push(cmd);
435 |         }
436 |       }
437 |       if (disallowedCommands.length > 0) {
438 |         return {
439 |           allAllowed: false,
440 |           disallowedCommands,
441 |           blockReason: `Command(s) not in the allowed commands list. Disallowed commands: ${disallowedCommands
442 |             .map((c) => JSON.stringify(c))
443 |             .join(', ')}`,
444 |           isHardDenial: false, // This is a soft denial.
445 |         };
446 |       }
447 |     }
448 |     // If no specific global allowlist exists, and it passed the blocklist,
449 |     // the command is allowed by default.
450 |   }
451 | 
452 |   // If all checks for the current mode pass, the command is allowed.
453 |   return { allAllowed: true, disallowedCommands: [] };
454 | }
455 | 
456 | /**
457 |  * Determines whether a given shell command is allowed to execute based on
458 |  * the tool's configuration including allowlists and blocklists.
459 |  *
460 |  * This function operates in "default allow" mode. It is a wrapper around
461 |  * `checkCommandPermissions`.
462 |  *
463 |  * @param command The shell command string to validate.
464 |  * @param config The application configuration.
465 |  * @returns An object with 'allowed' boolean and optional 'reason' string if not allowed.
466 |  */
467 | export const spawnAsync = (
468 |   command: string,
469 |   args: string[],
470 |   options?: SpawnOptionsWithoutStdio,
471 | ): Promise<{ stdout: string; stderr: string }> =>
472 |   new Promise((resolve, reject) => {
473 |     const child = spawn(command, args, options);
474 |     let stdout = '';
475 |     let stderr = '';
476 | 
477 |     child.stdout.on('data', (data) => {
478 |       stdout += data.toString();
479 |     });
480 | 
481 |     child.stderr.on('data', (data) => {
482 |       stderr += data.toString();
483 |     });
484 | 
485 |     child.on('close', (code) => {
486 |       if (code === 0) {
487 |         resolve({ stdout, stderr });
488 |       } else {
489 |         reject(new Error(`Command failed with exit code ${code}:\n${stderr}`));
490 |       }
491 |     });
492 | 
493 |     child.on('error', (err) => {
494 |       reject(err);
495 |     });
496 |   });
497 | 
498 | export function isCommandAllowed(
499 |   command: string,
500 |   config: Config,
501 | ): { allowed: boolean; reason?: string } {
502 |   // By not providing a sessionAllowlist, we invoke "default allow" behavior.
503 |   const { allAllowed, blockReason } = checkCommandPermissions(command, config);
504 |   if (allAllowed) {
505 |     return { allowed: true };
506 |   }
507 |   return { allowed: false, reason: blockReason };
508 | }
```

src/utils/summarizer.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Mock } from 'vitest';
8 | import { describe, it, expect, vi, beforeEach, afterEach } from 'vitest';
9 | import { GeminiClient } from '../core/client.js';
10 | import { Config } from '../config/config.js';
11 | import {
12 |   summarizeToolOutput,
13 |   llmSummarizer,
14 |   defaultSummarizer,
15 | } from './summarizer.js';
16 | import type { ToolResult } from '../tools/tools.js';
17 | 
18 | // Mock GeminiClient and Config constructor
19 | vi.mock('../core/client.js');
20 | vi.mock('../config/config.js');
21 | 
22 | describe('summarizers', () => {
23 |   let mockGeminiClient: GeminiClient;
24 |   let MockConfig: Mock;
25 |   const abortSignal = new AbortController().signal;
26 | 
27 |   beforeEach(() => {
28 |     MockConfig = vi.mocked(Config);
29 |     const mockConfigInstance = new MockConfig(
30 |       'test-api-key',
31 |       'gemini-pro',
32 |       false,
33 |       '.',
34 |       false,
35 |       undefined,
36 |       false,
37 |       undefined,
38 |       undefined,
39 |       undefined,
40 |     );
41 | 
42 |     mockGeminiClient = new GeminiClient(mockConfigInstance);
43 |     (mockGeminiClient.generateContent as Mock) = vi.fn();
44 | 
45 |     vi.spyOn(console, 'error').mockImplementation(() => {});
46 |   });
47 | 
48 |   afterEach(() => {
49 |     vi.clearAllMocks();
50 |     (console.error as Mock).mockRestore();
51 |   });
52 | 
53 |   describe('summarizeToolOutput', () => {
54 |     it('should return original text if it is shorter than maxLength', async () => {
55 |       const shortText = 'This is a short text.';
56 |       const result = await summarizeToolOutput(
57 |         shortText,
58 |         mockGeminiClient,
59 |         abortSignal,
60 |         2000,
61 |       );
62 |       expect(result).toBe(shortText);
63 |       expect(mockGeminiClient.generateContent).not.toHaveBeenCalled();
64 |     });
65 | 
66 |     it('should return original text if it is empty', async () => {
67 |       const emptyText = '';
68 |       const result = await summarizeToolOutput(
69 |         emptyText,
70 |         mockGeminiClient,
71 |         abortSignal,
72 |         2000,
73 |       );
74 |       expect(result).toBe(emptyText);
75 |       expect(mockGeminiClient.generateContent).not.toHaveBeenCalled();
76 |     });
77 | 
78 |     it('should call generateContent if text is longer than maxLength', async () => {
79 |       const longText = 'This is a very long text.'.repeat(200);
80 |       const summary = 'This is a summary.';
81 |       (mockGeminiClient.generateContent as Mock).mockResolvedValue({
82 |         candidates: [{ content: { parts: [{ text: summary }] } }],
83 |       });
84 | 
85 |       const result = await summarizeToolOutput(
86 |         longText,
87 |         mockGeminiClient,
88 |         abortSignal,
89 |         2000,
90 |       );
91 | 
92 |       expect(mockGeminiClient.generateContent).toHaveBeenCalledTimes(1);
93 |       expect(result).toBe(summary);
94 |     });
95 | 
96 |     it('should return original text if generateContent throws an error', async () => {
97 |       const longText = 'This is a very long text.'.repeat(200);
98 |       const error = new Error('API Error');
99 |       (mockGeminiClient.generateContent as Mock).mockRejectedValue(error);
100 | 
101 |       const result = await summarizeToolOutput(
102 |         longText,
103 |         mockGeminiClient,
104 |         abortSignal,
105 |         2000,
106 |       );
107 | 
108 |       expect(mockGeminiClient.generateContent).toHaveBeenCalledTimes(1);
109 |       expect(result).toBe(longText);
110 |       expect(console.error).toHaveBeenCalledWith(
111 |         'Failed to summarize tool output.',
112 |         error,
113 |       );
114 |     });
115 | 
116 |     it('should construct the correct prompt for summarization', async () => {
117 |       const longText = 'This is a very long text.'.repeat(200);
118 |       const summary = 'This is a summary.';
119 |       (mockGeminiClient.generateContent as Mock).mockResolvedValue({
120 |         candidates: [{ content: { parts: [{ text: summary }] } }],
121 |       });
122 | 
123 |       await summarizeToolOutput(longText, mockGeminiClient, abortSignal, 1000);
124 | 
125 |       const expectedPrompt = `Summarize the following tool output to be a maximum of 1000 tokens. The summary should be concise and capture the main points of the tool output.
126 | 
127 | The summarization should be done based on the content that is provided. Here are the basic rules to follow:
128 | 1. If the text is a directory listing or any output that is structural, use the history of the conversation to understand the context. Using this context try to understand what information we need from the tool output and return that as a response.
129 | 2. If the text is text content and there is nothing structural that we need, summarize the text.
130 | 3. If the text is the output of a shell command, use the history of the conversation to understand the context. Using this context try to understand what information we need from the tool output and return a summarization along with the stack trace of any error within the <error></error> tags. The stack trace should be complete and not truncated. If there are warnings, you should include them in the summary within <warning></warning> tags.
131 | 
132 | 
133 | Text to summarize:
134 | "${longText}"
135 | 
136 | Return the summary string which should first contain an overall summarization of text followed by the full stack trace of errors and warnings in the tool output.
137 | `;
138 |       const calledWith = (mockGeminiClient.generateContent as Mock).mock
139 |         .calls[0];
140 |       const contents = calledWith[0];
141 |       expect(contents[0].parts[0].text).toBe(expectedPrompt);
142 |     });
143 |   });
144 | 
145 |   describe('llmSummarizer', () => {
146 |     it('should summarize tool output using summarizeToolOutput', async () => {
147 |       const toolResult: ToolResult = {
148 |         llmContent: 'This is a very long text.'.repeat(200),
149 |         returnDisplay: '',
150 |       };
151 |       const summary = 'This is a summary.';
152 |       (mockGeminiClient.generateContent as Mock).mockResolvedValue({
153 |         candidates: [{ content: { parts: [{ text: summary }] } }],
154 |       });
155 | 
156 |       const result = await llmSummarizer(
157 |         toolResult,
158 |         mockGeminiClient,
159 |         abortSignal,
160 |       );
161 | 
162 |       expect(mockGeminiClient.generateContent).toHaveBeenCalledTimes(1);
163 |       expect(result).toBe(summary);
164 |     });
165 | 
166 |     it('should handle different llmContent types', async () => {
167 |       const longText = 'This is a very long text.'.repeat(200);
168 |       const toolResult: ToolResult = {
169 |         llmContent: [{ text: longText }],
170 |         returnDisplay: '',
171 |       };
172 |       const summary = 'This is a summary.';
173 |       (mockGeminiClient.generateContent as Mock).mockResolvedValue({
174 |         candidates: [{ content: { parts: [{ text: summary }] } }],
175 |       });
176 | 
177 |       const result = await llmSummarizer(
178 |         toolResult,
179 |         mockGeminiClient,
180 |         abortSignal,
181 |       );
182 | 
183 |       expect(mockGeminiClient.generateContent).toHaveBeenCalledTimes(1);
184 |       const calledWith = (mockGeminiClient.generateContent as Mock).mock
185 |         .calls[0];
186 |       const contents = calledWith[0];
187 |       expect(contents[0].parts[0].text).toContain(`"${longText}"`);
188 |       expect(result).toBe(summary);
189 |     });
190 |   });
191 | 
192 |   describe('defaultSummarizer', () => {
193 |     it('should stringify the llmContent', async () => {
194 |       const toolResult: ToolResult = {
195 |         llmContent: { text: 'some data' },
196 |         returnDisplay: '',
197 |       };
198 | 
199 |       const result = await defaultSummarizer(
200 |         toolResult,
201 |         mockGeminiClient,
202 |         abortSignal,
203 |       );
204 | 
205 |       expect(result).toBe(JSON.stringify({ text: 'some data' }));
206 |       expect(mockGeminiClient.generateContent).not.toHaveBeenCalled();
207 |     });
208 |   });
209 | });
```

src/utils/summarizer.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { ToolResult } from '../tools/tools.js';
8 | import type {
9 |   Content,
10 |   GenerateContentConfig,
11 |   GenerateContentResponse,
12 | } from '@google/genai';
13 | import type { GeminiClient } from '../core/client.js';
14 | import { DEFAULT_GEMINI_FLASH_LITE_MODEL } from '../config/models.js';
15 | import { getResponseText, partToString } from './partUtils.js';
16 | 
17 | /**
18 |  * A function that summarizes the result of a tool execution.
19 |  *
20 |  * @param result The result of the tool execution.
21 |  * @returns The summary of the result.
22 |  */
23 | export type Summarizer = (
24 |   result: ToolResult,
25 |   geminiClient: GeminiClient,
26 |   abortSignal: AbortSignal,
27 | ) => Promise<string>;
28 | 
29 | /**
30 |  * The default summarizer for tool results.
31 |  *
32 |  * @param result The result of the tool execution.
33 |  * @param geminiClient The Gemini client to use for summarization.
34 |  * @param abortSignal The abort signal to use for summarization.
35 |  * @returns The summary of the result.
36 |  */
37 | export const defaultSummarizer: Summarizer = (
38 |   result: ToolResult,
39 |   _geminiClient: GeminiClient,
40 |   _abortSignal: AbortSignal,
41 | ) => Promise.resolve(JSON.stringify(result.llmContent));
42 | 
43 | const SUMMARIZE_TOOL_OUTPUT_PROMPT = `Summarize the following tool output to be a maximum of {maxOutputTokens} tokens. The summary should be concise and capture the main points of the tool output.
44 | 
45 | The summarization should be done based on the content that is provided. Here are the basic rules to follow:
46 | 1. If the text is a directory listing or any output that is structural, use the history of the conversation to understand the context. Using this context try to understand what information we need from the tool output and return that as a response.
47 | 2. If the text is text content and there is nothing structural that we need, summarize the text.
48 | 3. If the text is the output of a shell command, use the history of the conversation to understand the context. Using this context try to understand what information we need from the tool output and return a summarization along with the stack trace of any error within the <error></error> tags. The stack trace should be complete and not truncated. If there are warnings, you should include them in the summary within <warning></warning> tags.
49 | 
50 | 
51 | Text to summarize:
52 | "{textToSummarize}"
53 | 
54 | Return the summary string which should first contain an overall summarization of text followed by the full stack trace of errors and warnings in the tool output.
55 | `;
56 | 
57 | export const llmSummarizer: Summarizer = (result, geminiClient, abortSignal) =>
58 |   summarizeToolOutput(
59 |     partToString(result.llmContent),
60 |     geminiClient,
61 |     abortSignal,
62 |   );
63 | 
64 | export async function summarizeToolOutput(
65 |   textToSummarize: string,
66 |   geminiClient: GeminiClient,
67 |   abortSignal: AbortSignal,
68 |   maxOutputTokens: number = 2000,
69 | ): Promise<string> {
70 |   // There is going to be a slight difference here since we are comparing length of string with maxOutputTokens.
71 |   // This is meant to be a ballpark estimation of if we need to summarize the tool output.
72 |   if (!textToSummarize || textToSummarize.length < maxOutputTokens) {
73 |     return textToSummarize;
74 |   }
75 |   const prompt = SUMMARIZE_TOOL_OUTPUT_PROMPT.replace(
76 |     '{maxOutputTokens}',
77 |     String(maxOutputTokens),
78 |   ).replace('{textToSummarize}', textToSummarize);
79 | 
80 |   const contents: Content[] = [{ role: 'user', parts: [{ text: prompt }] }];
81 |   const toolOutputSummarizerConfig: GenerateContentConfig = {
82 |     maxOutputTokens,
83 |   };
84 |   try {
85 |     const parsedResponse = (await geminiClient.generateContent(
86 |       contents,
87 |       toolOutputSummarizerConfig,
88 |       abortSignal,
89 |       DEFAULT_GEMINI_FLASH_LITE_MODEL,
90 |     )) as unknown as GenerateContentResponse;
91 |     return getResponseText(parsedResponse) || textToSummarize;
92 |   } catch (error) {
93 |     console.error('Failed to summarize tool output.', error);
94 |     return textToSummarize;
95 |   }
96 | }
```

src/utils/systemEncoding.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { vi, describe, it, expect, beforeEach, afterEach } from 'vitest';
8 | import { execSync } from 'node:child_process';
9 | import * as os from 'node:os';
10 | import { detect as chardetDetect } from 'chardet';
11 | 
12 | // Mock dependencies
13 | vi.mock('child_process');
14 | vi.mock('os');
15 | vi.mock('chardet');
16 | 
17 | // Import the functions we want to test after refactoring
18 | import {
19 |   getCachedEncodingForBuffer,
20 |   getSystemEncoding,
21 |   windowsCodePageToEncoding,
22 |   detectEncodingFromBuffer,
23 |   resetEncodingCache,
24 | } from './systemEncoding.js';
25 | 
26 | describe('Shell Command Processor - Encoding Functions', () => {
27 |   let consoleWarnSpy: ReturnType<typeof vi.spyOn>;
28 |   let mockedExecSync: ReturnType<typeof vi.mocked<typeof execSync>>;
29 |   let mockedOsPlatform: ReturnType<typeof vi.mocked<() => string>>;
30 |   let mockedChardetDetect: ReturnType<typeof vi.mocked<typeof chardetDetect>>;
31 | 
32 |   beforeEach(() => {
33 |     consoleWarnSpy = vi.spyOn(console, 'warn').mockImplementation(() => {});
34 |     mockedExecSync = vi.mocked(execSync);
35 |     mockedOsPlatform = vi.mocked(os.platform);
36 |     mockedChardetDetect = vi.mocked(chardetDetect);
37 | 
38 |     // Reset the encoding cache before each test
39 |     resetEncodingCache();
40 | 
41 |     // Clear environment variables that might affect tests
42 |     delete process.env['LC_ALL'];
43 |     delete process.env['LC_CTYPE'];
44 |     delete process.env['LANG'];
45 |   });
46 | 
47 |   afterEach(() => {
48 |     vi.restoreAllMocks();
49 |     resetEncodingCache();
50 |   });
51 | 
52 |   describe('windowsCodePageToEncoding', () => {
53 |     it('should map common Windows code pages correctly', () => {
54 |       expect(windowsCodePageToEncoding(437)).toBe('cp437');
55 |       expect(windowsCodePageToEncoding(850)).toBe('cp850');
56 |       expect(windowsCodePageToEncoding(65001)).toBe('utf-8');
57 |       expect(windowsCodePageToEncoding(1252)).toBe('windows-1252');
58 |       expect(windowsCodePageToEncoding(932)).toBe('shift_jis');
59 |       expect(windowsCodePageToEncoding(936)).toBe('gb2312');
60 |       expect(windowsCodePageToEncoding(949)).toBe('euc-kr');
61 |       expect(windowsCodePageToEncoding(950)).toBe('big5');
62 |       expect(windowsCodePageToEncoding(1200)).toBe('utf-16le');
63 |       expect(windowsCodePageToEncoding(1201)).toBe('utf-16be');
64 |     });
65 | 
66 |     it('should return null for unmapped code pages and warn', () => {
67 |       expect(windowsCodePageToEncoding(99999)).toBe(null);
68 |       expect(consoleWarnSpy).toHaveBeenCalledWith(
69 |         'Unable to determine encoding for windows code page 99999.',
70 |       );
71 |     });
72 | 
73 |     it('should handle all Windows-specific code pages', () => {
74 |       expect(windowsCodePageToEncoding(874)).toBe('windows-874');
75 |       expect(windowsCodePageToEncoding(1250)).toBe('windows-1250');
76 |       expect(windowsCodePageToEncoding(1251)).toBe('windows-1251');
77 |       expect(windowsCodePageToEncoding(1253)).toBe('windows-1253');
78 |       expect(windowsCodePageToEncoding(1254)).toBe('windows-1254');
79 |       expect(windowsCodePageToEncoding(1255)).toBe('windows-1255');
80 |       expect(windowsCodePageToEncoding(1256)).toBe('windows-1256');
81 |       expect(windowsCodePageToEncoding(1257)).toBe('windows-1257');
82 |       expect(windowsCodePageToEncoding(1258)).toBe('windows-1258');
83 |     });
84 |   });
85 | 
86 |   describe('detectEncodingFromBuffer', () => {
87 |     it('should detect encoding using chardet successfully', () => {
88 |       const buffer = Buffer.from('test content', 'utf8');
89 |       mockedChardetDetect.mockReturnValue('UTF-8');
90 | 
91 |       const result = detectEncodingFromBuffer(buffer);
92 |       expect(result).toBe('utf-8');
93 |       expect(mockedChardetDetect).toHaveBeenCalledWith(buffer);
94 |     });
95 | 
96 |     it('should handle chardet returning mixed case encoding', () => {
97 |       const buffer = Buffer.from('test content', 'utf8');
98 |       mockedChardetDetect.mockReturnValue('ISO-8859-1');
99 | 
100 |       const result = detectEncodingFromBuffer(buffer);
101 |       expect(result).toBe('iso-8859-1');
102 |     });
103 | 
104 |     it('should return null when chardet fails', () => {
105 |       const buffer = Buffer.from('test content', 'utf8');
106 |       mockedChardetDetect.mockImplementation(() => {
107 |         throw new Error('Detection failed');
108 |       });
109 | 
110 |       const result = detectEncodingFromBuffer(buffer);
111 |       expect(result).toBe(null);
112 |       expect(consoleWarnSpy).toHaveBeenCalledWith(
113 |         'Failed to detect encoding with chardet:',
114 |         expect.any(Error),
115 |       );
116 |     });
117 | 
118 |     it('should return null when chardet returns null', () => {
119 |       const buffer = Buffer.from('test content', 'utf8');
120 |       mockedChardetDetect.mockReturnValue(null);
121 | 
122 |       const result = detectEncodingFromBuffer(buffer);
123 |       expect(result).toBe(null);
124 |     });
125 | 
126 |     it('should return null when chardet returns non-string', () => {
127 |       const buffer = Buffer.from('test content', 'utf8');
128 |       mockedChardetDetect.mockReturnValue([
129 |         'utf-8',
130 |         'iso-8859-1',
131 |       ] as unknown as string);
132 | 
133 |       const result = detectEncodingFromBuffer(buffer);
134 |       expect(result).toBe(null);
135 |     });
136 |   });
137 | 
138 |   describe('getSystemEncoding - Windows', () => {
139 |     beforeEach(() => {
140 |       mockedOsPlatform.mockReturnValue('win32');
141 |     });
142 | 
143 |     it('should parse Windows chcp output correctly', () => {
144 |       mockedExecSync.mockReturnValue('Active code page: 65001');
145 | 
146 |       const result = getSystemEncoding();
147 |       expect(result).toBe('utf-8');
148 |       expect(mockedExecSync).toHaveBeenCalledWith('chcp', { encoding: 'utf8' });
149 |     });
150 | 
151 |     it('should handle different chcp output formats', () => {
152 |       mockedExecSync.mockReturnValue('Current code page: 1252');
153 | 
154 |       const result = getSystemEncoding();
155 |       expect(result).toBe('windows-1252');
156 |     });
157 | 
158 |     it('should handle chcp output with extra whitespace', () => {
159 |       mockedExecSync.mockReturnValue('Active code page:   437   ');
160 | 
161 |       const result = getSystemEncoding();
162 |       expect(result).toBe('cp437');
163 |     });
164 | 
165 |     it('should return null when chcp command fails', () => {
166 |       mockedExecSync.mockImplementation(() => {
167 |         throw new Error('Command failed');
168 |       });
169 | 
170 |       const result = getSystemEncoding();
171 |       expect(result).toBe(null);
172 |       expect(consoleWarnSpy).toHaveBeenCalledWith(
173 |         expect.stringContaining(
174 |           "Failed to get Windows code page using 'chcp' command",
175 |         ),
176 |       );
177 |     });
178 | 
179 |     it('should return null when chcp output cannot be parsed', () => {
180 |       mockedExecSync.mockReturnValue('Unexpected output format');
181 | 
182 |       const result = getSystemEncoding();
183 |       expect(result).toBe(null);
184 |       expect(consoleWarnSpy).toHaveBeenCalledWith(
185 |         expect.stringContaining(
186 |           "Failed to get Windows code page using 'chcp' command",
187 |         ),
188 |       );
189 |     });
190 | 
191 |     it('should return null when code page is not a number', () => {
192 |       mockedExecSync.mockReturnValue('Active code page: abc');
193 | 
194 |       const result = getSystemEncoding();
195 |       expect(result).toBe(null);
196 |       expect(consoleWarnSpy).toHaveBeenCalledWith(
197 |         expect.stringContaining(
198 |           "Failed to get Windows code page using 'chcp' command",
199 |         ),
200 |       );
201 |     });
202 | 
203 |     it('should return null when code page maps to null', () => {
204 |       mockedExecSync.mockReturnValue('Active code page: 99999');
205 | 
206 |       const result = getSystemEncoding();
207 |       expect(result).toBe(null);
208 |       // Should warn about unknown code page from windowsCodePageToEncoding
209 |       expect(consoleWarnSpy).toHaveBeenCalledWith(
210 |         'Unable to determine encoding for windows code page 99999.',
211 |       );
212 |     });
213 |   });
214 | 
215 |   describe('getSystemEncoding - Unix-like', () => {
216 |     beforeEach(() => {
217 |       mockedOsPlatform.mockReturnValue('linux');
218 |     });
219 | 
220 |     it('should parse locale from LC_ALL environment variable', () => {
221 |       process.env['LC_ALL'] = 'en_US.UTF-8';
222 | 
223 |       const result = getSystemEncoding();
224 |       expect(result).toBe('utf-8');
225 |     });
226 | 
227 |     it('should parse locale from LC_CTYPE when LC_ALL is not set', () => {
228 |       process.env['LC_CTYPE'] = 'fr_FR.ISO-8859-1';
229 | 
230 |       const result = getSystemEncoding();
231 |       expect(result).toBe('iso-8859-1');
232 |     });
233 | 
234 |     it('should parse locale from LANG when LC_ALL and LC_CTYPE are not set', () => {
235 |       process.env['LANG'] = 'de_DE.UTF-8';
236 | 
237 |       const result = getSystemEncoding();
238 |       expect(result).toBe('utf-8');
239 |     });
240 | 
241 |     it('should handle locale charmap command when environment variables are empty', () => {
242 |       mockedExecSync.mockReturnValue('UTF-8\n');
243 | 
244 |       const result = getSystemEncoding();
245 |       expect(result).toBe('utf-8');
246 |       expect(mockedExecSync).toHaveBeenCalledWith('locale charmap', {
247 |         encoding: 'utf8',
248 |       });
249 |     });
250 | 
251 |     it('should handle locale charmap with mixed case', () => {
252 |       mockedExecSync.mockReturnValue('ISO-8859-1\n');
253 | 
254 |       const result = getSystemEncoding();
255 |       expect(result).toBe('iso-8859-1');
256 |     });
257 | 
258 |     it('should return null when locale charmap fails', () => {
259 |       mockedExecSync.mockImplementation(() => {
260 |         throw new Error('Command failed');
261 |       });
262 | 
263 |       const result = getSystemEncoding();
264 |       expect(result).toBe(null);
265 |       expect(consoleWarnSpy).toHaveBeenCalledWith(
266 |         'Failed to get locale charmap.',
267 |       );
268 |     });
269 | 
270 |     it('should handle locale without encoding (no dot)', () => {
271 |       process.env['LANG'] = 'C';
272 | 
273 |       const result = getSystemEncoding();
274 |       expect(result).toBe('c');
275 |     });
276 | 
277 |     it('should handle empty locale environment variables', () => {
278 |       process.env['LC_ALL'] = '';
279 |       process.env['LC_CTYPE'] = '';
280 |       process.env['LANG'] = '';
281 |       mockedExecSync.mockReturnValue('UTF-8');
282 | 
283 |       const result = getSystemEncoding();
284 |       expect(result).toBe('utf-8');
285 |     });
286 | 
287 |     it('should return locale as-is when locale format has no dot', () => {
288 |       process.env['LANG'] = 'invalid_format';
289 | 
290 |       const result = getSystemEncoding();
291 |       expect(result).toBe('invalid_format');
292 |     });
293 | 
294 |     it('should prioritize LC_ALL over other environment variables', () => {
295 |       process.env['LC_ALL'] = 'en_US.UTF-8';
296 |       process.env['LC_CTYPE'] = 'fr_FR.ISO-8859-1';
297 |       process.env['LANG'] = 'de_DE.CP1252';
298 | 
299 |       const result = getSystemEncoding();
300 |       expect(result).toBe('utf-8');
301 |     });
302 | 
303 |     it('should prioritize LC_CTYPE over LANG', () => {
304 |       process.env['LC_CTYPE'] = 'fr_FR.ISO-8859-1';
305 |       process.env['LANG'] = 'de_DE.CP1252';
306 | 
307 |       const result = getSystemEncoding();
308 |       expect(result).toBe('iso-8859-1');
309 |     });
310 |   });
311 | 
312 |   describe('getEncodingForBuffer', () => {
313 |     beforeEach(() => {
314 |       mockedOsPlatform.mockReturnValue('linux');
315 |     });
316 | 
317 |     it('should use cached system encoding on subsequent calls', () => {
318 |       process.env['LANG'] = 'en_US.UTF-8';
319 |       const buffer = Buffer.from('test');
320 | 
321 |       // First call
322 |       const result1 = getCachedEncodingForBuffer(buffer);
323 |       expect(result1).toBe('utf-8');
324 | 
325 |       // Change environment (should not affect cached result)
326 |       process.env['LANG'] = 'fr_FR.ISO-8859-1';
327 | 
328 |       // Second call should use cached value
329 |       const result2 = getCachedEncodingForBuffer(buffer);
330 |       expect(result2).toBe('utf-8');
331 |     });
332 | 
333 |     it('should fall back to buffer detection when system encoding fails', () => {
334 |       // No environment variables set
335 |       mockedExecSync.mockImplementation(() => {
336 |         throw new Error('locale command failed');
337 |       });
338 | 
339 |       const buffer = Buffer.from('test');
340 |       mockedChardetDetect.mockReturnValue('ISO-8859-1');
341 | 
342 |       const result = getCachedEncodingForBuffer(buffer);
343 |       expect(result).toBe('iso-8859-1');
344 |       expect(mockedChardetDetect).toHaveBeenCalledWith(buffer);
345 |     });
346 | 
347 |     it('should fall back to utf-8 when both system and buffer detection fail', () => {
348 |       // System encoding fails
349 |       mockedExecSync.mockImplementation(() => {
350 |         throw new Error('locale command failed');
351 |       });
352 | 
353 |       // Buffer detection fails
354 |       mockedChardetDetect.mockImplementation(() => {
355 |         throw new Error('chardet failed');
356 |       });
357 | 
358 |       const buffer = Buffer.from('test');
359 |       const result = getCachedEncodingForBuffer(buffer);
360 |       expect(result).toBe('utf-8');
361 |     });
362 | 
363 |     it('should not cache buffer detection results', () => {
364 |       // System encoding fails initially
365 |       mockedExecSync.mockImplementation(() => {
366 |         throw new Error('locale command failed');
367 |       });
368 | 
369 |       const buffer1 = Buffer.from('test1');
370 |       const buffer2 = Buffer.from('test2');
371 | 
372 |       mockedChardetDetect
373 |         .mockReturnValueOnce('ISO-8859-1')
374 |         .mockReturnValueOnce('UTF-16');
375 | 
376 |       const result1 = getCachedEncodingForBuffer(buffer1);
377 |       const result2 = getCachedEncodingForBuffer(buffer2);
378 | 
379 |       expect(result1).toBe('iso-8859-1');
380 |       expect(result2).toBe('utf-16');
381 |       expect(mockedChardetDetect).toHaveBeenCalledTimes(2);
382 |     });
383 | 
384 |     it('should handle Windows system encoding', () => {
385 |       mockedOsPlatform.mockReturnValue('win32');
386 |       mockedExecSync.mockReturnValue('Active code page: 1252');
387 | 
388 |       const buffer = Buffer.from('test');
389 |       const result = getCachedEncodingForBuffer(buffer);
390 | 
391 |       expect(result).toBe('windows-1252');
392 |     });
393 | 
394 |     it('should cache null system encoding result', () => {
395 |       // Reset the cache specifically for this test
396 |       resetEncodingCache();
397 | 
398 |       // Ensure we're on Unix-like for this test
399 |       mockedOsPlatform.mockReturnValue('linux');
400 | 
401 |       // System encoding detection returns null
402 |       mockedExecSync.mockImplementation(() => {
403 |         throw new Error('locale command failed');
404 |       });
405 | 
406 |       const buffer1 = Buffer.from('test1');
407 |       const buffer2 = Buffer.from('test2');
408 | 
409 |       mockedChardetDetect
410 |         .mockReturnValueOnce('ISO-8859-1')
411 |         .mockReturnValueOnce('UTF-16');
412 | 
413 |       // Clear any previous calls from beforeEach setup or previous tests
414 |       mockedExecSync.mockClear();
415 | 
416 |       const result1 = getCachedEncodingForBuffer(buffer1);
417 |       const result2 = getCachedEncodingForBuffer(buffer2);
418 | 
419 |       // Should call execSync only once due to caching (null result is cached)
420 |       expect(mockedExecSync).toHaveBeenCalledTimes(1);
421 |       expect(result1).toBe('iso-8859-1');
422 |       expect(result2).toBe('utf-16');
423 | 
424 |       // Call a third time to verify cache is still used
425 |       const buffer3 = Buffer.from('test3');
426 |       mockedChardetDetect.mockReturnValueOnce('UTF-32');
427 |       const result3 = getCachedEncodingForBuffer(buffer3);
428 | 
429 |       // Still should be only one call to execSync
430 |       expect(mockedExecSync).toHaveBeenCalledTimes(1);
431 |       expect(result3).toBe('utf-32');
432 |     });
433 |   });
434 | 
435 |   describe('Cross-platform behavior', () => {
436 |     it('should work correctly on macOS', () => {
437 |       mockedOsPlatform.mockReturnValue('darwin');
438 |       process.env['LANG'] = 'en_US.UTF-8';
439 | 
440 |       const result = getSystemEncoding();
441 |       expect(result).toBe('utf-8');
442 |     });
443 | 
444 |     it('should work correctly on other Unix-like systems', () => {
445 |       mockedOsPlatform.mockReturnValue('freebsd');
446 |       process.env['LANG'] = 'en_US.UTF-8';
447 | 
448 |       const result = getSystemEncoding();
449 |       expect(result).toBe('utf-8');
450 |     });
451 | 
452 |     it('should handle unknown platforms as Unix-like', () => {
453 |       mockedOsPlatform.mockReturnValue('unknown' as NodeJS.Platform);
454 |       process.env['LANG'] = 'en_US.UTF-8';
455 | 
456 |       const result = getSystemEncoding();
457 |       expect(result).toBe('utf-8');
458 |     });
459 |   });
460 | 
461 |   describe('Edge cases and error handling', () => {
462 |     it('should handle empty buffer gracefully', () => {
463 |       mockedOsPlatform.mockReturnValue('linux');
464 |       process.env['LANG'] = 'en_US.UTF-8';
465 | 
466 |       const buffer = Buffer.alloc(0);
467 |       const result = getCachedEncodingForBuffer(buffer);
468 |       expect(result).toBe('utf-8');
469 |     });
470 | 
471 |     it('should handle very large buffers', () => {
472 |       mockedOsPlatform.mockReturnValue('linux');
473 |       process.env['LANG'] = 'en_US.UTF-8';
474 | 
475 |       const buffer = Buffer.alloc(1024 * 1024, 'a');
476 |       const result = getCachedEncodingForBuffer(buffer);
477 |       expect(result).toBe('utf-8');
478 |     });
479 | 
480 |     it('should handle Unicode content', () => {
481 |       mockedOsPlatform.mockReturnValue('linux');
482 |       const unicodeText = '你好世界 🌍 ñoño';
483 | 
484 |       // System encoding fails
485 |       mockedExecSync.mockImplementation(() => {
486 |         throw new Error('locale command failed');
487 |       });
488 | 
489 |       mockedChardetDetect.mockReturnValue('UTF-8');
490 | 
491 |       const buffer = Buffer.from(unicodeText, 'utf8');
492 |       const result = getCachedEncodingForBuffer(buffer);
493 |       expect(result).toBe('utf-8');
494 |     });
495 |   });
496 | });
```

src/utils/systemEncoding.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { execSync } from 'node:child_process';
8 | import os from 'node:os';
9 | import { detect as chardetDetect } from 'chardet';
10 | 
11 | // Cache for system encoding to avoid repeated detection
12 | // Use undefined to indicate "not yet checked" vs null meaning "checked but failed"
13 | let cachedSystemEncoding: string | null | undefined = undefined;
14 | 
15 | /**
16 |  * Reset the encoding cache - useful for testing
17 |  */
18 | export function resetEncodingCache(): void {
19 |   cachedSystemEncoding = undefined;
20 | }
21 | 
22 | /**
23 |  * Returns the system encoding, caching the result to avoid repeated system calls.
24 |  * If system encoding detection fails, falls back to detecting from the provided buffer.
25 |  * Note: Only the system encoding is cached - buffer-based detection runs for each buffer
26 |  * since different buffers may have different encodings.
27 |  * @param buffer A buffer to use for detecting encoding if system detection fails.
28 |  */
29 | export function getCachedEncodingForBuffer(buffer: Buffer): string {
30 |   // Cache system encoding detection since it's system-wide
31 |   if (cachedSystemEncoding === undefined) {
32 |     cachedSystemEncoding = getSystemEncoding();
33 |   }
34 | 
35 |   // If we have a cached system encoding, use it
36 |   if (cachedSystemEncoding) {
37 |     return cachedSystemEncoding;
38 |   }
39 | 
40 |   // Otherwise, detect from this specific buffer (don't cache this result)
41 |   return detectEncodingFromBuffer(buffer) || 'utf-8';
42 | }
43 | 
44 | /**
45 |  * Detects the system encoding based on the platform.
46 |  * For Windows, it uses the 'chcp' command to get the current code page.
47 |  * For Unix-like systems, it checks environment variables like LC_ALL, LC_CTYPE, and LANG.
48 |  * If those are not set, it tries to run 'locale charmap' to get the encoding.
49 |  * If detection fails, it returns null.
50 |  * @returns The system encoding as a string, or null if detection fails.
51 |  */
52 | export function getSystemEncoding(): string | null {
53 |   // Windows
54 |   if (os.platform() === 'win32') {
55 |     try {
56 |       const output = execSync('chcp', { encoding: 'utf8' });
57 |       const match = output.match(/:\s*(\d+)/);
58 |       if (match) {
59 |         const codePage = parseInt(match[1], 10);
60 |         if (!isNaN(codePage)) {
61 |           return windowsCodePageToEncoding(codePage);
62 |         }
63 |       }
64 |       // Only warn if we can't parse the output format, not if windowsCodePageToEncoding fails
65 |       throw new Error(
66 |         `Unable to parse Windows code page from 'chcp' output "${output.trim()}". `,
67 |       );
68 |     } catch (error) {
69 |       console.warn(
70 |         `Failed to get Windows code page using 'chcp' command: ${error instanceof Error ? error.message : String(error)}. ` +
71 |           `Will attempt to detect encoding from command output instead.`,
72 |       );
73 |     }
74 |     return null;
75 |   }
76 | 
77 |   // Unix-like
78 |   // Use environment variables LC_ALL, LC_CTYPE, and LANG to determine the
79 |   // system encoding. However, these environment variables might not always
80 |   // be set or accurate. Handle cases where none of these variables are set.
81 |   const env = process.env;
82 |   let locale = env['LC_ALL'] || env['LC_CTYPE'] || env['LANG'] || '';
83 | 
84 |   // Fallback to querying the system directly when environment variables are missing
85 |   if (!locale) {
86 |     try {
87 |       locale = execSync('locale charmap', { encoding: 'utf8' })
88 |         .toString()
89 |         .trim();
90 |     } catch (_e) {
91 |       console.warn('Failed to get locale charmap.');
92 |       return null;
93 |     }
94 |   }
95 | 
96 |   const match = locale.match(/\.(.+)/); // e.g., "en_US.UTF-8"
97 |   if (match && match[1]) {
98 |     return match[1].toLowerCase();
99 |   }
100 | 
101 |   // Handle cases where locale charmap returns just the encoding name (e.g., "UTF-8")
102 |   if (locale && !locale.includes('.')) {
103 |     return locale.toLowerCase();
104 |   }
105 | 
106 |   return null;
107 | }
108 | 
109 | /**
110 |  * Converts a Windows code page number to a corresponding encoding name.
111 |  * @param cp The Windows code page number (e.g., 437, 850, etc.)
112 |  * @returns The corresponding encoding name as a string, or null if no mapping exists.
113 |  */
114 | export function windowsCodePageToEncoding(cp: number): string | null {
115 |   // Most common mappings; extend as needed
116 |   const map: { [key: number]: string } = {
117 |     437: 'cp437',
118 |     850: 'cp850',
119 |     852: 'cp852',
120 |     866: 'cp866',
121 |     874: 'windows-874',
122 |     932: 'shift_jis',
123 |     936: 'gb2312',
124 |     949: 'euc-kr',
125 |     950: 'big5',
126 |     1200: 'utf-16le',
127 |     1201: 'utf-16be',
128 |     1250: 'windows-1250',
129 |     1251: 'windows-1251',
130 |     1252: 'windows-1252',
131 |     1253: 'windows-1253',
132 |     1254: 'windows-1254',
133 |     1255: 'windows-1255',
134 |     1256: 'windows-1256',
135 |     1257: 'windows-1257',
136 |     1258: 'windows-1258',
137 |     65001: 'utf-8',
138 |   };
139 | 
140 |   if (map[cp]) {
141 |     return map[cp];
142 |   }
143 | 
144 |   console.warn(`Unable to determine encoding for windows code page ${cp}.`);
145 |   return null; // Return null if no mapping found
146 | }
147 | 
148 | /**
149 |  * Attempts to detect encoding from a buffer using chardet.
150 |  * This is useful when system encoding detection fails.
151 |  * Returns the detected encoding in lowercase, or null if detection fails.
152 |  * @param buffer The buffer to analyze for encoding.
153 |  * @return The detected encoding as a lowercase string, or null if detection fails.
154 |  */
155 | export function detectEncodingFromBuffer(buffer: Buffer): string | null {
156 |   try {
157 |     const detected = chardetDetect(buffer);
158 |     if (detected && typeof detected === 'string') {
159 |       return detected.toLowerCase();
160 |     }
161 |   } catch (error) {
162 |     console.warn('Failed to detect encoding with chardet:', error);
163 |   }
164 | 
165 |   return null;
166 | }
```

src/utils/terminalSerializer.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { Terminal } from '@xterm/headless';
9 | import {
10 |   serializeTerminalToObject,
11 |   convertColorToHex,
12 |   ColorMode,
13 | } from './terminalSerializer.js';
14 | 
15 | const RED_FG = '\x1b[31m';
16 | const RESET = '\x1b[0m';
17 | 
18 | function writeToTerminal(terminal: Terminal, data: string): Promise<void> {
19 |   return new Promise((resolve) => {
20 |     terminal.write(data, resolve);
21 |   });
22 | }
23 | 
24 | describe('terminalSerializer', () => {
25 |   describe('serializeTerminalToObject', () => {
26 |     it('should handle an empty terminal', () => {
27 |       const terminal = new Terminal({
28 |         cols: 80,
29 |         rows: 24,
30 |         allowProposedApi: true,
31 |       });
32 |       const result = serializeTerminalToObject(terminal);
33 |       expect(result).toHaveLength(24);
34 |       result.forEach((line) => {
35 |         // Expect each line to be either empty or contain a single token with spaces
36 |         if (line.length > 0) {
37 |           expect(line[0].text.trim()).toBe('');
38 |         }
39 |       });
40 |     });
41 | 
42 |     it('should serialize a single line of text', async () => {
43 |       const terminal = new Terminal({
44 |         cols: 80,
45 |         rows: 24,
46 |         allowProposedApi: true,
47 |       });
48 |       await writeToTerminal(terminal, 'Hello, world!');
49 |       const result = serializeTerminalToObject(terminal);
50 |       expect(result[0][0].text).toContain('Hello, world!');
51 |     });
52 | 
53 |     it('should serialize multiple lines of text', async () => {
54 |       const terminal = new Terminal({
55 |         cols: 7,
56 |         rows: 24,
57 |         allowProposedApi: true,
58 |       });
59 |       await writeToTerminal(terminal, 'Line 1\r\nLine 2');
60 |       const result = serializeTerminalToObject(terminal);
61 |       expect(result[0][0].text).toBe('Line 1 ');
62 |       expect(result[1][0].text).toBe('Line 2');
63 |     });
64 | 
65 |     it('should handle bold text', async () => {
66 |       const terminal = new Terminal({
67 |         cols: 80,
68 |         rows: 24,
69 |         allowProposedApi: true,
70 |       });
71 |       await writeToTerminal(terminal, '\x1b[1mBold text\x1b[0m');
72 |       const result = serializeTerminalToObject(terminal);
73 |       expect(result[0][0].bold).toBe(true);
74 |       expect(result[0][0].text).toBe('Bold text');
75 |     });
76 | 
77 |     it('should handle italic text', async () => {
78 |       const terminal = new Terminal({
79 |         cols: 80,
80 |         rows: 24,
81 |         allowProposedApi: true,
82 |       });
83 |       await writeToTerminal(terminal, '\x1b[3mItalic text\x1b[0m');
84 |       const result = serializeTerminalToObject(terminal);
85 |       expect(result[0][0].italic).toBe(true);
86 |       expect(result[0][0].text).toBe('Italic text');
87 |     });
88 | 
89 |     it('should handle underlined text', async () => {
90 |       const terminal = new Terminal({
91 |         cols: 80,
92 |         rows: 24,
93 |         allowProposedApi: true,
94 |       });
95 |       await writeToTerminal(terminal, '\x1b[4mUnderlined text\x1b[0m');
96 |       const result = serializeTerminalToObject(terminal);
97 |       expect(result[0][0].underline).toBe(true);
98 |       expect(result[0][0].text).toBe('Underlined text');
99 |     });
100 | 
101 |     it('should handle dim text', async () => {
102 |       const terminal = new Terminal({
103 |         cols: 80,
104 |         rows: 24,
105 |         allowProposedApi: true,
106 |       });
107 |       await writeToTerminal(terminal, '\x1b[2mDim text\x1b[0m');
108 |       const result = serializeTerminalToObject(terminal);
109 |       expect(result[0][0].dim).toBe(true);
110 |       expect(result[0][0].text).toBe('Dim text');
111 |     });
112 | 
113 |     it('should handle inverse text', async () => {
114 |       const terminal = new Terminal({
115 |         cols: 80,
116 |         rows: 24,
117 |         allowProposedApi: true,
118 |       });
119 |       await writeToTerminal(terminal, '\x1b[7mInverse text\x1b[0m');
120 |       const result = serializeTerminalToObject(terminal);
121 |       expect(result[0][0].inverse).toBe(true);
122 |       expect(result[0][0].text).toBe('Inverse text');
123 |     });
124 | 
125 |     it('should handle foreground colors', async () => {
126 |       const terminal = new Terminal({
127 |         cols: 80,
128 |         rows: 24,
129 |         allowProposedApi: true,
130 |       });
131 |       await writeToTerminal(terminal, `${RED_FG}Red text${RESET}`);
132 |       const result = serializeTerminalToObject(terminal);
133 |       expect(result[0][0].fg).toBe('#800000');
134 |       expect(result[0][0].text).toBe('Red text');
135 |     });
136 | 
137 |     it('should handle background colors', async () => {
138 |       const terminal = new Terminal({
139 |         cols: 80,
140 |         rows: 24,
141 |         allowProposedApi: true,
142 |       });
143 |       await writeToTerminal(terminal, '\x1b[42mGreen background\x1b[0m');
144 |       const result = serializeTerminalToObject(terminal);
145 |       expect(result[0][0].bg).toBe('#008000');
146 |       expect(result[0][0].text).toBe('Green background');
147 |     });
148 | 
149 |     it('should handle RGB colors', async () => {
150 |       const terminal = new Terminal({
151 |         cols: 80,
152 |         rows: 24,
153 |         allowProposedApi: true,
154 |       });
155 |       await writeToTerminal(terminal, '\x1b[38;2;100;200;50mRGB text\x1b[0m');
156 |       const result = serializeTerminalToObject(terminal);
157 |       expect(result[0][0].fg).toBe('#64c832');
158 |       expect(result[0][0].text).toBe('RGB text');
159 |     });
160 | 
161 |     it('should handle a combination of styles', async () => {
162 |       const terminal = new Terminal({
163 |         cols: 80,
164 |         rows: 24,
165 |         allowProposedApi: true,
166 |       });
167 |       await writeToTerminal(terminal, '\x1b[1;31;42mStyled text\x1b[0m');
168 |       const result = serializeTerminalToObject(terminal);
169 |       expect(result[0][0].bold).toBe(true);
170 |       expect(result[0][0].fg).toBe('#800000');
171 |       expect(result[0][0].bg).toBe('#008000');
172 |       expect(result[0][0].text).toBe('Styled text');
173 |     });
174 |   });
175 |   describe('convertColorToHex', () => {
176 |     it('should convert RGB color to hex', () => {
177 |       const color = (100 << 16) | (200 << 8) | 50;
178 |       const hex = convertColorToHex(color, ColorMode.RGB, '#000000');
179 |       expect(hex).toBe('#64c832');
180 |     });
181 | 
182 |     it('should convert palette color to hex', () => {
183 |       const hex = convertColorToHex(1, ColorMode.PALETTE, '#000000');
184 |       expect(hex).toBe('#800000');
185 |     });
186 | 
187 |     it('should return default color for ColorMode.DEFAULT', () => {
188 |       const hex = convertColorToHex(0, ColorMode.DEFAULT, '#ffffff');
189 |       expect(hex).toBe('#ffffff');
190 |     });
191 | 
192 |     it('should return default color for invalid palette index', () => {
193 |       const hex = convertColorToHex(999, ColorMode.PALETTE, '#000000');
194 |       expect(hex).toBe('#000000');
195 |     });
196 |   });
197 | });
```

src/utils/terminalSerializer.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { IBufferCell, Terminal } from '@xterm/headless';
8 | export interface AnsiToken {
9 |   text: string;
10 |   bold: boolean;
11 |   italic: boolean;
12 |   underline: boolean;
13 |   dim: boolean;
14 |   inverse: boolean;
15 |   fg: string;
16 |   bg: string;
17 | }
18 | 
19 | export type AnsiLine = AnsiToken[];
20 | export type AnsiOutput = AnsiLine[];
21 | 
22 | const enum Attribute {
23 |   inverse = 1,
24 |   bold = 2,
25 |   italic = 4,
26 |   underline = 8,
27 |   dim = 16,
28 | }
29 | 
30 | export const enum ColorMode {
31 |   DEFAULT = 0,
32 |   PALETTE = 1,
33 |   RGB = 2,
34 | }
35 | 
36 | class Cell {
37 |   private readonly cell: IBufferCell | null;
38 |   private readonly x: number;
39 |   private readonly y: number;
40 |   private readonly cursorX: number;
41 |   private readonly cursorY: number;
42 |   private readonly attributes: number = 0;
43 |   fg = 0;
44 |   bg = 0;
45 |   fgColorMode: ColorMode = ColorMode.DEFAULT;
46 |   bgColorMode: ColorMode = ColorMode.DEFAULT;
47 | 
48 |   constructor(
49 |     cell: IBufferCell | null,
50 |     x: number,
51 |     y: number,
52 |     cursorX: number,
53 |     cursorY: number,
54 |   ) {
55 |     this.cell = cell;
56 |     this.x = x;
57 |     this.y = y;
58 |     this.cursorX = cursorX;
59 |     this.cursorY = cursorY;
60 | 
61 |     if (!cell) {
62 |       return;
63 |     }
64 | 
65 |     if (cell.isInverse()) {
66 |       this.attributes += Attribute.inverse;
67 |     }
68 |     if (cell.isBold()) {
69 |       this.attributes += Attribute.bold;
70 |     }
71 |     if (cell.isItalic()) {
72 |       this.attributes += Attribute.italic;
73 |     }
74 |     if (cell.isUnderline()) {
75 |       this.attributes += Attribute.underline;
76 |     }
77 |     if (cell.isDim()) {
78 |       this.attributes += Attribute.dim;
79 |     }
80 | 
81 |     if (cell.isFgRGB()) {
82 |       this.fgColorMode = ColorMode.RGB;
83 |     } else if (cell.isFgPalette()) {
84 |       this.fgColorMode = ColorMode.PALETTE;
85 |     } else {
86 |       this.fgColorMode = ColorMode.DEFAULT;
87 |     }
88 | 
89 |     if (cell.isBgRGB()) {
90 |       this.bgColorMode = ColorMode.RGB;
91 |     } else if (cell.isBgPalette()) {
92 |       this.bgColorMode = ColorMode.PALETTE;
93 |     } else {
94 |       this.bgColorMode = ColorMode.DEFAULT;
95 |     }
96 | 
97 |     if (this.fgColorMode === ColorMode.DEFAULT) {
98 |       this.fg = -1;
99 |     } else {
100 |       this.fg = cell.getFgColor();
101 |     }
102 | 
103 |     if (this.bgColorMode === ColorMode.DEFAULT) {
104 |       this.bg = -1;
105 |     } else {
106 |       this.bg = cell.getBgColor();
107 |     }
108 |   }
109 | 
110 |   isCursor(): boolean {
111 |     return this.x === this.cursorX && this.y === this.cursorY;
112 |   }
113 | 
114 |   getChars(): string {
115 |     return this.cell?.getChars() || ' ';
116 |   }
117 | 
118 |   isAttribute(attribute: Attribute): boolean {
119 |     return (this.attributes & attribute) !== 0;
120 |   }
121 | 
122 |   equals(other: Cell): boolean {
123 |     return (
124 |       this.attributes === other.attributes &&
125 |       this.fg === other.fg &&
126 |       this.bg === other.bg &&
127 |       this.fgColorMode === other.fgColorMode &&
128 |       this.bgColorMode === other.bgColorMode &&
129 |       this.isCursor() === other.isCursor()
130 |     );
131 |   }
132 | }
133 | 
134 | export function serializeTerminalToObject(terminal: Terminal): AnsiOutput {
135 |   const buffer = terminal.buffer.active;
136 |   const cursorX = buffer.cursorX;
137 |   const cursorY = buffer.cursorY;
138 |   const defaultFg = '';
139 |   const defaultBg = '';
140 | 
141 |   const result: AnsiOutput = [];
142 | 
143 |   for (let y = 0; y < terminal.rows; y++) {
144 |     const line = buffer.getLine(buffer.viewportY + y);
145 |     const currentLine: AnsiLine = [];
146 |     if (!line) {
147 |       result.push(currentLine);
148 |       continue;
149 |     }
150 | 
151 |     let lastCell = new Cell(null, -1, -1, cursorX, cursorY);
152 |     let currentText = '';
153 | 
154 |     for (let x = 0; x < terminal.cols; x++) {
155 |       const cellData = line.getCell(x);
156 |       const cell = new Cell(cellData || null, x, y, cursorX, cursorY);
157 | 
158 |       if (x > 0 && !cell.equals(lastCell)) {
159 |         if (currentText) {
160 |           const token: AnsiToken = {
161 |             text: currentText,
162 |             bold: lastCell.isAttribute(Attribute.bold),
163 |             italic: lastCell.isAttribute(Attribute.italic),
164 |             underline: lastCell.isAttribute(Attribute.underline),
165 |             dim: lastCell.isAttribute(Attribute.dim),
166 |             inverse:
167 |               lastCell.isAttribute(Attribute.inverse) || lastCell.isCursor(),
168 |             fg: convertColorToHex(lastCell.fg, lastCell.fgColorMode, defaultFg),
169 |             bg: convertColorToHex(lastCell.bg, lastCell.bgColorMode, defaultBg),
170 |           };
171 |           currentLine.push(token);
172 |         }
173 |         currentText = '';
174 |       }
175 |       currentText += cell.getChars();
176 |       lastCell = cell;
177 |     }
178 | 
179 |     if (currentText) {
180 |       const token: AnsiToken = {
181 |         text: currentText,
182 |         bold: lastCell.isAttribute(Attribute.bold),
183 |         italic: lastCell.isAttribute(Attribute.italic),
184 |         underline: lastCell.isAttribute(Attribute.underline),
185 |         dim: lastCell.isAttribute(Attribute.dim),
186 |         inverse: lastCell.isAttribute(Attribute.inverse) || lastCell.isCursor(),
187 |         fg: convertColorToHex(lastCell.fg, lastCell.fgColorMode, defaultFg),
188 |         bg: convertColorToHex(lastCell.bg, lastCell.bgColorMode, defaultBg),
189 |       };
190 |       currentLine.push(token);
191 |     }
192 | 
193 |     result.push(currentLine);
194 |   }
195 | 
196 |   return result;
197 | }
198 | 
199 | // ANSI color palette from https://en.wikipedia.org/wiki/ANSI_escape_code#8-bit
200 | const ANSI_COLORS = [
201 |   '#000000',
202 |   '#800000',
203 |   '#008000',
204 |   '#808000',
205 |   '#000080',
206 |   '#800080',
207 |   '#008080',
208 |   '#c0c0c0',
209 |   '#808080',
210 |   '#ff0000',
211 |   '#00ff00',
212 |   '#ffff00',
213 |   '#0000ff',
214 |   '#ff00ff',
215 |   '#00ffff',
216 |   '#ffffff',
217 |   '#000000',
218 |   '#00005f',
219 |   '#000087',
220 |   '#0000af',
221 |   '#0000d7',
222 |   '#0000ff',
223 |   '#005f00',
224 |   '#005f5f',
225 |   '#005f87',
226 |   '#005faf',
227 |   '#005fd7',
228 |   '#005fff',
229 |   '#008700',
230 |   '#00875f',
231 |   '#008787',
232 |   '#0087af',
233 |   '#0087d7',
234 |   '#0087ff',
235 |   '#00af00',
236 |   '#00af5f',
237 |   '#00af87',
238 |   '#00afaf',
239 |   '#00afd7',
240 |   '#00afff',
241 |   '#00d700',
242 |   '#00d75f',
243 |   '#00d787',
244 |   '#00d7af',
245 |   '#00d7d7',
246 |   '#00d7ff',
247 |   '#00ff00',
248 |   '#00ff5f',
249 |   '#00ff87',
250 |   '#00ffaf',
251 |   '#00ffd7',
252 |   '#00ffff',
253 |   '#5f0000',
254 |   '#5f005f',
255 |   '#5f0087',
256 |   '#5f00af',
257 |   '#5f00d7',
258 |   '#5f00ff',
259 |   '#5f5f00',
260 |   '#5f5f5f',
261 |   '#5f5f87',
262 |   '#5f5faf',
263 |   '#5f5fd7',
264 |   '#5f5fff',
265 |   '#5f8700',
266 |   '#5f875f',
267 |   '#5f8787',
268 |   '#5f87af',
269 |   '#5f87d7',
270 |   '#5f87ff',
271 |   '#5faf00',
272 |   '#5faf5f',
273 |   '#5faf87',
274 |   '#5fafaf',
275 |   '#5fafd7',
276 |   '#5fafff',
277 |   '#5fd700',
278 |   '#5fd75f',
279 |   '#5fd787',
280 |   '#5fd7af',
281 |   '#5fd7d7',
282 |   '#5fd7ff',
283 |   '#5fff00',
284 |   '#5fff5f',
285 |   '#5fff87',
286 |   '#5fffaf',
287 |   '#5fffd7',
288 |   '#5fffff',
289 |   '#870000',
290 |   '#87005f',
291 |   '#870087',
292 |   '#8700af',
293 |   '#8700d7',
294 |   '#8700ff',
295 |   '#875f00',
296 |   '#875f5f',
297 |   '#875f87',
298 |   '#875faf',
299 |   '#875fd7',
300 |   '#875fff',
301 |   '#878700',
302 |   '#87875f',
303 |   '#878787',
304 |   '#8787af',
305 |   '#8787d7',
306 |   '#8787ff',
307 |   '#87af00',
308 |   '#87af5f',
309 |   '#87af87',
310 |   '#87afaf',
311 |   '#87afd7',
312 |   '#87afff',
313 |   '#87d700',
314 |   '#87d75f',
315 |   '#87d787',
316 |   '#87d7af',
317 |   '#87d7d7',
318 |   '#87d7ff',
319 |   '#87ff00',
320 |   '#87ff5f',
321 |   '#87ff87',
322 |   '#87ffaf',
323 |   '#87ffd7',
324 |   '#87ffff',
325 |   '#af0000',
326 |   '#af005f',
327 |   '#af0087',
328 |   '#af00af',
329 |   '#af00d7',
330 |   '#af00ff',
331 |   '#af5f00',
332 |   '#af5f5f',
333 |   '#af5f87',
334 |   '#af5faf',
335 |   '#af5fd7',
336 |   '#af5fff',
337 |   '#af8700',
338 |   '#af875f',
339 |   '#af8787',
340 |   '#af87af',
341 |   '#af87d7',
342 |   '#af87ff',
343 |   '#afaf00',
344 |   '#afaf5f',
345 |   '#afaf87',
346 |   '#afafaf',
347 |   '#afafd7',
348 |   '#afafff',
349 |   '#afd700',
350 |   '#afd75f',
351 |   '#afd787',
352 |   '#afd7af',
353 |   '#afd7d7',
354 |   '#afd7ff',
355 |   '#afff00',
356 |   '#afff5f',
357 |   '#afff87',
358 |   '#afffaf',
359 |   '#afffd7',
360 |   '#afffff',
361 |   '#d70000',
362 |   '#d7005f',
363 |   '#d70087',
364 |   '#d700af',
365 |   '#d700d7',
366 |   '#d700ff',
367 |   '#d75f00',
368 |   '#d75f5f',
369 |   '#d75f87',
370 |   '#d75faf',
371 |   '#d75fd7',
372 |   '#d75fff',
373 |   '#d78700',
374 |   '#d7875f',
375 |   '#d78787',
376 |   '#d787af',
377 |   '#d787d7',
378 |   '#d787ff',
379 |   '#d7af00',
380 |   '#d7af5f',
381 |   '#d7af87',
382 |   '#d7afaf',
383 |   '#d7afd7',
384 |   '#d7afff',
385 |   '#d7d700',
386 |   '#d7d75f',
387 |   '#d7d787',
388 |   '#d7d7af',
389 |   '#d7d7d7',
390 |   '#d7d7ff',
391 |   '#d7ff00',
392 |   '#d7ff5f',
393 |   '#d7ff87',
394 |   '#d7ffaf',
395 |   '#d7ffd7',
396 |   '#d7ffff',
397 |   '#ff0000',
398 |   '#ff005f',
399 |   '#ff0087',
400 |   '#ff00af',
401 |   '#ff00d7',
402 |   '#ff00ff',
403 |   '#ff5f00',
404 |   '#ff5f5f',
405 |   '#ff5f87',
406 |   '#ff5faf',
407 |   '#ff5fd7',
408 |   '#ff5fff',
409 |   '#ff8700',
410 |   '#ff875f',
411 |   '#ff8787',
412 |   '#ff87af',
413 |   '#ff87d7',
414 |   '#ff87ff',
415 |   '#ffaf00',
416 |   '#ffaf5f',
417 |   '#ffaf87',
418 |   '#ffafaf',
419 |   '#ffafd7',
420 |   '#ffafff',
421 |   '#ffd700',
422 |   '#ffd75f',
423 |   '#ffd787',
424 |   '#ffd7af',
425 |   '#ffd7d7',
426 |   '#ffd7ff',
427 |   '#ffff00',
428 |   '#ffff5f',
429 |   '#ffff87',
430 |   '#ffffaf',
431 |   '#ffffd7',
432 |   '#ffffff',
433 |   '#080808',
434 |   '#121212',
435 |   '#1c1c1c',
436 |   '#262626',
437 |   '#303030',
438 |   '#3a3a3a',
439 |   '#444444',
440 |   '#4e4e4e',
441 |   '#585858',
442 |   '#626262',
443 |   '#6c6c6c',
444 |   '#767676',
445 |   '#808080',
446 |   '#8a8a8a',
447 |   '#949494',
448 |   '#9e9e9e',
449 |   '#a8a8a8',
450 |   '#b2b2b2',
451 |   '#bcbcbc',
452 |   '#c6c6c6',
453 |   '#d0d0d0',
454 |   '#dadada',
455 |   '#e4e4e4',
456 |   '#eeeeee',
457 | ];
458 | 
459 | export function convertColorToHex(
460 |   color: number,
461 |   colorMode: ColorMode,
462 |   defaultColor: string,
463 | ): string {
464 |   if (colorMode === ColorMode.RGB) {
465 |     const r = (color >> 16) & 255;
466 |     const g = (color >> 8) & 255;
467 |     const b = color & 255;
468 |     return `#${r.toString(16).padStart(2, '0')}${g
469 |       .toString(16)
470 |       .padStart(2, '0')}${b.toString(16).padStart(2, '0')}`;
471 |   }
472 |   if (colorMode === ColorMode.PALETTE) {
473 |     return ANSI_COLORS[color] || defaultColor;
474 |   }
475 |   return defaultColor;
476 | }
```

src/utils/testUtils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Testing utilities for simulating 429 errors in unit tests
9 |  */
10 | 
11 | let requestCounter = 0;
12 | let simulate429Enabled = false;
13 | let simulate429AfterRequests = 0;
14 | let simulate429ForAuthType: string | undefined;
15 | let fallbackOccurred = false;
16 | 
17 | /**
18 |  * Check if we should simulate a 429 error for the current request
19 |  */
20 | export function shouldSimulate429(authType?: string): boolean {
21 |   if (!simulate429Enabled || fallbackOccurred) {
22 |     return false;
23 |   }
24 | 
25 |   // If auth type filter is set, only simulate for that auth type
26 |   if (simulate429ForAuthType && authType !== simulate429ForAuthType) {
27 |     return false;
28 |   }
29 | 
30 |   requestCounter++;
31 | 
32 |   // If afterRequests is set, only simulate after that many requests
33 |   if (simulate429AfterRequests > 0) {
34 |     return requestCounter > simulate429AfterRequests;
35 |   }
36 | 
37 |   // Otherwise, simulate for every request
38 |   return true;
39 | }
40 | 
41 | /**
42 |  * Reset the request counter (useful for tests)
43 |  */
44 | export function resetRequestCounter(): void {
45 |   requestCounter = 0;
46 | }
47 | 
48 | /**
49 |  * Disable 429 simulation after successful fallback
50 |  */
51 | export function disableSimulationAfterFallback(): void {
52 |   fallbackOccurred = true;
53 | }
54 | 
55 | /**
56 |  * Create a simulated 429 error response
57 |  */
58 | export function createSimulated429Error(): Error {
59 |   const error = new Error('Rate limit exceeded (simulated)') as Error & {
60 |     status: number;
61 |   };
62 |   error.status = 429;
63 |   return error;
64 | }
65 | 
66 | /**
67 |  * Reset simulation state when switching auth methods
68 |  */
69 | export function resetSimulationState(): void {
70 |   fallbackOccurred = false;
71 |   resetRequestCounter();
72 | }
73 | 
74 | /**
75 |  * Enable/disable 429 simulation programmatically (for tests)
76 |  */
77 | export function setSimulate429(
78 |   enabled: boolean,
79 |   afterRequests = 0,
80 |   forAuthType?: string,
81 | ): void {
82 |   simulate429Enabled = enabled;
83 |   simulate429AfterRequests = afterRequests;
84 |   simulate429ForAuthType = forAuthType;
85 |   fallbackOccurred = false; // Reset fallback state when simulation is re-enabled
86 |   resetRequestCounter();
87 | }
```

src/utils/textUtils.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { safeLiteralReplace } from './textUtils.js';
9 | 
10 | describe('safeLiteralReplace', () => {
11 |   it('returns original string when oldString empty or not found', () => {
12 |     expect(safeLiteralReplace('abc', '', 'X')).toBe('abc');
13 |     expect(safeLiteralReplace('abc', 'z', 'X')).toBe('abc');
14 |   });
15 | 
16 |   it('fast path when newString has no $', () => {
17 |     expect(safeLiteralReplace('abc', 'b', 'X')).toBe('aXc');
18 |   });
19 | 
20 |   it('treats $ literally', () => {
21 |     expect(safeLiteralReplace('foo', 'foo', "bar$'baz")).toBe("bar$'baz");
22 |   });
23 | 
24 |   it("does not interpret replacement patterns like $&, $', $` and $1", () => {
25 |     expect(safeLiteralReplace('hello', 'hello', '$&-replacement')).toBe(
26 |       '$&-replacement',
27 |     );
28 |     expect(safeLiteralReplace('mid', 'mid', 'new$`content')).toBe(
29 |       'new$`content',
30 |     );
31 |     expect(safeLiteralReplace('test', 'test', '$1$2value')).toBe('$1$2value');
32 |   });
33 | 
34 |   it('preserves end-of-line $ in regex-like text', () => {
35 |     const current = "| select('match', '^[sv]d[a-z]$')";
36 |     const oldStr = "'^[sv]d[a-z]$'";
37 |     const newStr = "'^[sv]d[a-z]$' # updated";
38 |     const expected = "| select('match', '^[sv]d[a-z]$' # updated)";
39 |     expect(safeLiteralReplace(current, oldStr, newStr)).toBe(expected);
40 |   });
41 | 
42 |   it('handles multiple $ characters', () => {
43 |     expect(safeLiteralReplace('x', 'x', '$$$')).toBe('$$$');
44 |   });
45 | 
46 |   it('preserves pre-escaped $$ literally', () => {
47 |     expect(safeLiteralReplace('x', 'x', '$$value')).toBe('$$value');
48 |   });
49 | 
50 |   it('handles complex malicious patterns from PR #7871', () => {
51 |     const original = 'The price is PRICE.';
52 |     const result = safeLiteralReplace(
53 |       original,
54 |       'PRICE',
55 |       "$& Wow, that's a lot! $'",
56 |     );
57 |     expect(result).toBe("The price is $& Wow, that's a lot! $'.");
58 |   });
59 | 
60 |   it('handles multiple replacements correctly', () => {
61 |     const text = 'Replace FOO and FOO again';
62 |     const result = safeLiteralReplace(text, 'FOO', '$100');
63 |     expect(result).toBe('Replace $100 and $100 again');
64 |   });
65 | 
66 |   it('preserves $ at different positions', () => {
67 |     expect(safeLiteralReplace('test', 'test', '$')).toBe('$');
68 |     expect(safeLiteralReplace('test', 'test', 'prefix$')).toBe('prefix$');
69 |     expect(safeLiteralReplace('test', 'test', '$suffix')).toBe('$suffix');
70 |   });
71 | 
72 |   it('handles edge case with $$$$', () => {
73 |     expect(safeLiteralReplace('x', 'x', '$$$$')).toBe('$$$$');
74 |   });
75 | 
76 |   it('handles newString with only dollar signs', () => {
77 |     expect(safeLiteralReplace('abc', 'b', '$$')).toBe('a$$c');
78 |   });
79 | });
```

src/utils/textUtils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Safely replaces text with literal strings, avoiding ECMAScript GetSubstitution issues.
9 |  * Escapes $ characters to prevent template interpretation.
10 |  */
11 | export function safeLiteralReplace(
12 |   str: string,
13 |   oldString: string,
14 |   newString: string,
15 | ): string {
16 |   if (oldString === '' || !str.includes(oldString)) {
17 |     return str;
18 |   }
19 | 
20 |   if (!newString.includes('$')) {
21 |     return str.replaceAll(oldString, newString);
22 |   }
23 | 
24 |   const escapedNewString = newString.replaceAll('$', '$$$$');
25 |   return str.replaceAll(oldString, escapedNewString);
26 | }
27 | 
28 | /**
29 |  * Checks if a Buffer is likely binary by testing for the presence of a NULL byte.
30 |  * The presence of a NULL byte is a strong indicator that the data is not plain text.
31 |  * @param data The Buffer to check.
32 |  * @param sampleSize The number of bytes from the start of the buffer to test.
33 |  * @returns True if a NULL byte is found, false otherwise.
34 |  */
35 | export function isBinary(
36 |   data: Buffer | null | undefined,
37 |   sampleSize = 512,
38 | ): boolean {
39 |   if (!data) {
40 |     return false;
41 |   }
42 | 
43 |   const sample = data.length > sampleSize ? data.subarray(0, sampleSize) : data;
44 | 
45 |   for (const byte of sample) {
46 |     // The presence of a NULL byte (0x00) is one of the most reliable
47 |     // indicators of a binary file. Text files should not contain them.
48 |     if (byte === 0) {
49 |       return true;
50 |     }
51 |   }
52 | 
53 |   // If no NULL bytes were found in the sample, we assume it's text.
54 |   return false;
55 | }
```

src/utils/thoughtUtils.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { parseThought } from './thoughtUtils.js';
9 | 
10 | describe('parseThought', () => {
11 |   it.each([
12 |     {
13 |       name: 'a standard thought with subject and description',
14 |       rawText: '**Subject:** This is the description.',
15 |       expected: {
16 |         subject: 'Subject:',
17 |         description: 'This is the description.',
18 |       },
19 |     },
20 |     {
21 |       name: 'leading and trailing whitespace in the raw string',
22 |       rawText: '  **Subject** description with spaces   ',
23 |       expected: { subject: 'Subject', description: 'description with spaces' },
24 |     },
25 |     {
26 |       name: 'whitespace surrounding the subject content',
27 |       rawText: '** Subject  **',
28 |       expected: { subject: 'Subject', description: '' },
29 |     },
30 |     {
31 |       name: 'a thought with only a subject',
32 |       rawText: '**Only Subject**',
33 |       expected: { subject: 'Only Subject', description: '' },
34 |     },
35 |     {
36 |       name: 'a thought with only a description (no subject)',
37 |       rawText: 'This is just a description.',
38 |       expected: { subject: '', description: 'This is just a description.' },
39 |     },
40 |     {
41 |       name: 'an empty string input',
42 |       rawText: '',
43 |       expected: { subject: '', description: '' },
44 |     },
45 |     {
46 |       name: 'newlines within the subject and description',
47 |       rawText:
48 |         '**Multi-line\nSubject**\nHere is a description\nspread across lines.',
49 |       expected: {
50 |         subject: 'Multi-line\nSubject',
51 |         description: 'Here is a description\nspread across lines.',
52 |       },
53 |     },
54 |     {
55 |       name: 'only the first subject if multiple are present',
56 |       rawText: '**First** some text **Second**',
57 |       expected: { subject: 'First', description: 'some text **Second**' },
58 |     },
59 |     {
60 |       name: 'text before and after the subject',
61 |       rawText: 'Prefix text **Subject** Suffix text.',
62 |       expected: {
63 |         subject: 'Subject',
64 |         description: 'Prefix text  Suffix text.',
65 |       },
66 |     },
67 |     {
68 |       name: 'an unclosed subject tag',
69 |       rawText: 'Text with **an unclosed subject',
70 |       expected: { subject: '', description: 'Text with **an unclosed subject' },
71 |     },
72 |     {
73 |       name: 'an empty subject tag',
74 |       rawText: 'A thought with **** in the middle.',
75 |       expected: { subject: '', description: 'A thought with  in the middle.' },
76 |     },
77 |   ])('should correctly parse $name', ({ rawText, expected }) => {
78 |     expect(parseThought(rawText)).toEqual(expected);
79 |   });
80 | });
```

src/utils/thoughtUtils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | export type ThoughtSummary = {
8 |   subject: string;
9 |   description: string;
10 | };
11 | 
12 | const START_DELIMITER = '**';
13 | const END_DELIMITER = '**';
14 | 
15 | /**
16 |  * Parses a raw thought string into a structured ThoughtSummary object.
17 |  *
18 |  * Thoughts are expected to have a bold "subject" part enclosed in double
19 |  * asterisks (e.g., **Subject**). The rest of the string is considered
20 |  * the description. This function only parses the first valid subject found.
21 |  *
22 |  * @param rawText The raw text of the thought.
23 |  * @returns A ThoughtSummary object. If no valid subject is found, the entire
24 |  * string is treated as the description.
25 |  */
26 | export function parseThought(rawText: string): ThoughtSummary {
27 |   const startIndex = rawText.indexOf(START_DELIMITER);
28 |   if (startIndex === -1) {
29 |     // No start delimiter found, the whole text is the description.
30 |     return { subject: '', description: rawText.trim() };
31 |   }
32 | 
33 |   const endIndex = rawText.indexOf(
34 |     END_DELIMITER,
35 |     startIndex + START_DELIMITER.length,
36 |   );
37 |   if (endIndex === -1) {
38 |     // Start delimiter found but no end delimiter, so it's not a valid subject.
39 |     // Treat the entire string as the description.
40 |     return { subject: '', description: rawText.trim() };
41 |   }
42 | 
43 |   const subject = rawText
44 |     .substring(startIndex + START_DELIMITER.length, endIndex)
45 |     .trim();
46 | 
47 |   // The description is everything before the start delimiter and after the end delimiter.
48 |   const description = (
49 |     rawText.substring(0, startIndex) +
50 |     rawText.substring(endIndex + END_DELIMITER.length)
51 |   ).trim();
52 | 
53 |   return { subject, description };
54 | }
```

src/utils/tool-utils.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { expect, describe, it } from 'vitest';
8 | import { doesToolInvocationMatch } from './tool-utils.js';
9 | import type { AnyToolInvocation, Config } from '../index.js';
10 | import { ReadFileTool } from '../tools/read-file.js';
11 | 
12 | describe('doesToolInvocationMatch', () => {
13 |   it('should not match a partial command prefix', () => {
14 |     const invocation = {
15 |       params: { command: 'git commitsomething' },
16 |     } as AnyToolInvocation;
17 |     const patterns = ['ShellTool(git commit)'];
18 |     const result = doesToolInvocationMatch(
19 |       'run_shell_command',
20 |       invocation,
21 |       patterns,
22 |     );
23 |     expect(result).toBe(false);
24 |   });
25 | 
26 |   it('should match an exact command', () => {
27 |     const invocation = {
28 |       params: { command: 'git status' },
29 |     } as AnyToolInvocation;
30 |     const patterns = ['ShellTool(git status)'];
31 |     const result = doesToolInvocationMatch(
32 |       'run_shell_command',
33 |       invocation,
34 |       patterns,
35 |     );
36 |     expect(result).toBe(true);
37 |   });
38 | 
39 |   it('should match a command with an alias', () => {
40 |     const invocation = {
41 |       params: { command: 'wc -l' },
42 |     } as AnyToolInvocation;
43 |     const patterns = ['ShellTool(wc)'];
44 |     const result = doesToolInvocationMatch('ShellTool', invocation, patterns);
45 |     expect(result).toBe(true);
46 |   });
47 | 
48 |   it('should match a command that is a prefix', () => {
49 |     const invocation = {
50 |       params: { command: 'git status -v' },
51 |     } as AnyToolInvocation;
52 |     const patterns = ['ShellTool(git status)'];
53 |     const result = doesToolInvocationMatch(
54 |       'run_shell_command',
55 |       invocation,
56 |       patterns,
57 |     );
58 |     expect(result).toBe(true);
59 |   });
60 | 
61 |   describe('for non-shell tools', () => {
62 |     const readFileTool = new ReadFileTool({} as Config);
63 |     const invocation = {
64 |       params: { file: 'test.txt' },
65 |     } as AnyToolInvocation;
66 | 
67 |     it('should match by tool name', () => {
68 |       const patterns = ['read_file'];
69 |       const result = doesToolInvocationMatch(
70 |         readFileTool,
71 |         invocation,
72 |         patterns,
73 |       );
74 |       expect(result).toBe(true);
75 |     });
76 | 
77 |     it('should match by tool class name', () => {
78 |       const patterns = ['ReadFileTool'];
79 |       const result = doesToolInvocationMatch(
80 |         readFileTool,
81 |         invocation,
82 |         patterns,
83 |       );
84 |       expect(result).toBe(true);
85 |     });
86 | 
87 |     it('should not match if neither name is in the patterns', () => {
88 |       const patterns = ['some_other_tool', 'AnotherToolClass'];
89 |       const result = doesToolInvocationMatch(
90 |         readFileTool,
91 |         invocation,
92 |         patterns,
93 |       );
94 |       expect(result).toBe(false);
95 |     });
96 | 
97 |     it('should match by tool name when passed as a string', () => {
98 |       const patterns = ['read_file'];
99 |       const result = doesToolInvocationMatch('read_file', invocation, patterns);
100 |       expect(result).toBe(true);
101 |     });
102 |   });
103 | });
```

src/utils/tool-utils.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { AnyDeclarativeTool, AnyToolInvocation } from '../index.js';
8 | import { isTool } from '../index.js';
9 | import { SHELL_TOOL_NAMES } from './shell-utils.js';
10 | 
11 | /**
12 |  * Checks if a tool invocation matches any of a list of patterns.
13 |  *
14 |  * @param toolOrToolName The tool object or the name of the tool being invoked.
15 |  * @param invocation The invocation object for the tool.
16 |  * @param patterns A list of patterns to match against.
17 |  *   Patterns can be:
18 |  *   - A tool name (e.g., "ReadFileTool") to match any invocation of that tool.
19 |  *   - A tool name with a prefix (e.g., "ShellTool(git status)") to match
20 |  *     invocations where the arguments start with that prefix.
21 |  * @returns True if the invocation matches any pattern, false otherwise.
22 |  */
23 | export function doesToolInvocationMatch(
24 |   toolOrToolName: AnyDeclarativeTool | string,
25 |   invocation: AnyToolInvocation,
26 |   patterns: string[],
27 | ): boolean {
28 |   let toolNames: string[];
29 |   if (isTool(toolOrToolName)) {
30 |     toolNames = [toolOrToolName.name, toolOrToolName.constructor.name];
31 |   } else {
32 |     toolNames = [toolOrToolName as string];
33 |   }
34 | 
35 |   if (toolNames.some((name) => SHELL_TOOL_NAMES.includes(name))) {
36 |     toolNames = [...new Set([...toolNames, ...SHELL_TOOL_NAMES])];
37 |   }
38 | 
39 |   for (const pattern of patterns) {
40 |     const openParen = pattern.indexOf('(');
41 | 
42 |     if (openParen === -1) {
43 |       // No arguments, just a tool name
44 |       if (toolNames.includes(pattern)) {
45 |         return true;
46 |       }
47 |       continue;
48 |     }
49 | 
50 |     const patternToolName = pattern.substring(0, openParen);
51 |     if (!toolNames.includes(patternToolName)) {
52 |       continue;
53 |     }
54 | 
55 |     if (!pattern.endsWith(')')) {
56 |       continue;
57 |     }
58 | 
59 |     const argPattern = pattern.substring(openParen + 1, pattern.length - 1);
60 | 
61 |     if (
62 |       'command' in invocation.params &&
63 |       toolNames.some((name) => SHELL_TOOL_NAMES.includes(name))
64 |     ) {
65 |       const argValue = String(
66 |         (invocation.params as { command: string }).command,
67 |       );
68 |       if (argValue === argPattern || argValue.startsWith(argPattern + ' ')) {
69 |         return true;
70 |       }
71 |     }
72 |   }
73 | 
74 |   return false;
75 | }
```

src/utils/userAccountManager.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Mock } from 'vitest';
8 | import { vi, describe, it, expect, beforeEach, afterEach } from 'vitest';
9 | import { UserAccountManager } from './userAccountManager.js';
10 | import * as fs from 'node:fs';
11 | import * as os from 'node:os';
12 | import path from 'node:path';
13 | 
14 | vi.mock('os', async (importOriginal) => {
15 |   const os = await importOriginal<typeof import('os')>();
16 |   return {
17 |     ...os,
18 |     homedir: vi.fn(),
19 |   };
20 | });
21 | 
22 | describe('UserAccountManager', () => {
23 |   let tempHomeDir: string;
24 |   let userAccountManager: UserAccountManager;
25 |   let accountsFile: () => string;
26 | 
27 |   beforeEach(() => {
28 |     tempHomeDir = fs.mkdtempSync(
29 |       path.join(os.tmpdir(), 'gemini-cli-test-home-'),
30 |     );
31 |     (os.homedir as Mock).mockReturnValue(tempHomeDir);
32 |     accountsFile = () =>
33 |       path.join(tempHomeDir, '.gemini', 'google_accounts.json');
34 |     userAccountManager = new UserAccountManager();
35 |   });
36 | 
37 |   afterEach(() => {
38 |     fs.rmSync(tempHomeDir, { recursive: true, force: true });
39 |     vi.clearAllMocks();
40 |   });
41 | 
42 |   describe('cacheGoogleAccount', () => {
43 |     it('should create directory and write initial account file', async () => {
44 |       await userAccountManager.cacheGoogleAccount('test1@google.com');
45 | 
46 |       // Verify Google Account ID was cached
47 |       expect(fs.existsSync(accountsFile())).toBe(true);
48 |       expect(fs.readFileSync(accountsFile(), 'utf-8')).toBe(
49 |         JSON.stringify({ active: 'test1@google.com', old: [] }, null, 2),
50 |       );
51 |     });
52 | 
53 |     it('should update active account and move previous to old', async () => {
54 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
55 |       fs.writeFileSync(
56 |         accountsFile(),
57 |         JSON.stringify(
58 |           { active: 'test2@google.com', old: ['test1@google.com'] },
59 |           null,
60 |           2,
61 |         ),
62 |       );
63 | 
64 |       await userAccountManager.cacheGoogleAccount('test3@google.com');
65 | 
66 |       expect(fs.readFileSync(accountsFile(), 'utf-8')).toBe(
67 |         JSON.stringify(
68 |           {
69 |             active: 'test3@google.com',
70 |             old: ['test1@google.com', 'test2@google.com'],
71 |           },
72 |           null,
73 |           2,
74 |         ),
75 |       );
76 |     });
77 | 
78 |     it('should not add a duplicate to the old list', async () => {
79 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
80 |       fs.writeFileSync(
81 |         accountsFile(),
82 |         JSON.stringify(
83 |           { active: 'test1@google.com', old: ['test2@google.com'] },
84 |           null,
85 |           2,
86 |         ),
87 |       );
88 |       await userAccountManager.cacheGoogleAccount('test2@google.com');
89 |       await userAccountManager.cacheGoogleAccount('test1@google.com');
90 | 
91 |       expect(fs.readFileSync(accountsFile(), 'utf-8')).toBe(
92 |         JSON.stringify(
93 |           { active: 'test1@google.com', old: ['test2@google.com'] },
94 |           null,
95 |           2,
96 |         ),
97 |       );
98 |     });
99 | 
100 |     it('should handle corrupted JSON by starting fresh', async () => {
101 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
102 |       fs.writeFileSync(accountsFile(), 'not valid json');
103 |       const consoleLogSpy = vi
104 |         .spyOn(console, 'log')
105 |         .mockImplementation(() => {});
106 | 
107 |       await userAccountManager.cacheGoogleAccount('test1@google.com');
108 | 
109 |       expect(consoleLogSpy).toHaveBeenCalled();
110 |       expect(JSON.parse(fs.readFileSync(accountsFile(), 'utf-8'))).toEqual({
111 |         active: 'test1@google.com',
112 |         old: [],
113 |       });
114 |     });
115 | 
116 |     it('should handle valid JSON with incorrect schema by starting fresh', async () => {
117 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
118 |       fs.writeFileSync(
119 |         accountsFile(),
120 |         JSON.stringify({ active: 'test1@google.com', old: 'not-an-array' }),
121 |       );
122 |       const consoleLogSpy = vi
123 |         .spyOn(console, 'log')
124 |         .mockImplementation(() => {});
125 | 
126 |       await userAccountManager.cacheGoogleAccount('test2@google.com');
127 | 
128 |       expect(consoleLogSpy).toHaveBeenCalled();
129 |       expect(JSON.parse(fs.readFileSync(accountsFile(), 'utf-8'))).toEqual({
130 |         active: 'test2@google.com',
131 |         old: [],
132 |       });
133 |     });
134 |   });
135 | 
136 |   describe('getCachedGoogleAccount', () => {
137 |     it('should return the active account if file exists and is valid', () => {
138 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
139 |       fs.writeFileSync(
140 |         accountsFile(),
141 |         JSON.stringify({ active: 'active@google.com', old: [] }, null, 2),
142 |       );
143 |       const account = userAccountManager.getCachedGoogleAccount();
144 |       expect(account).toBe('active@google.com');
145 |     });
146 | 
147 |     it('should return null if file does not exist', () => {
148 |       const account = userAccountManager.getCachedGoogleAccount();
149 |       expect(account).toBeNull();
150 |     });
151 | 
152 |     it('should return null if file is empty', () => {
153 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
154 |       fs.writeFileSync(accountsFile(), '');
155 |       const account = userAccountManager.getCachedGoogleAccount();
156 |       expect(account).toBeNull();
157 |     });
158 | 
159 |     it('should return null and log if file is corrupted', () => {
160 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
161 |       fs.writeFileSync(accountsFile(), '{ "active": "test@google.com"'); // Invalid JSON
162 |       const consoleLogSpy = vi
163 |         .spyOn(console, 'log')
164 |         .mockImplementation(() => {});
165 | 
166 |       const account = userAccountManager.getCachedGoogleAccount();
167 | 
168 |       expect(account).toBeNull();
169 |       expect(consoleLogSpy).toHaveBeenCalled();
170 |     });
171 | 
172 |     it('should return null if active key is missing', () => {
173 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
174 |       fs.writeFileSync(accountsFile(), JSON.stringify({ old: [] }));
175 |       const account = userAccountManager.getCachedGoogleAccount();
176 |       expect(account).toBeNull();
177 |     });
178 |   });
179 | 
180 |   describe('clearCachedGoogleAccount', () => {
181 |     it('should set active to null and move it to old', async () => {
182 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
183 |       fs.writeFileSync(
184 |         accountsFile(),
185 |         JSON.stringify(
186 |           { active: 'active@google.com', old: ['old1@google.com'] },
187 |           null,
188 |           2,
189 |         ),
190 |       );
191 | 
192 |       await userAccountManager.clearCachedGoogleAccount();
193 | 
194 |       const stored = JSON.parse(fs.readFileSync(accountsFile(), 'utf-8'));
195 |       expect(stored.active).toBeNull();
196 |       expect(stored.old).toEqual(['old1@google.com', 'active@google.com']);
197 |     });
198 | 
199 |     it('should handle empty file gracefully', async () => {
200 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
201 |       fs.writeFileSync(accountsFile(), '');
202 |       await userAccountManager.clearCachedGoogleAccount();
203 |       const stored = JSON.parse(fs.readFileSync(accountsFile(), 'utf-8'));
204 |       expect(stored.active).toBeNull();
205 |       expect(stored.old).toEqual([]);
206 |     });
207 | 
208 |     it('should handle corrupted JSON by creating a fresh file', async () => {
209 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
210 |       fs.writeFileSync(accountsFile(), 'not valid json');
211 |       const consoleLogSpy = vi
212 |         .spyOn(console, 'log')
213 |         .mockImplementation(() => {});
214 | 
215 |       await userAccountManager.clearCachedGoogleAccount();
216 | 
217 |       expect(consoleLogSpy).toHaveBeenCalled();
218 |       const stored = JSON.parse(fs.readFileSync(accountsFile(), 'utf-8'));
219 |       expect(stored.active).toBeNull();
220 |       expect(stored.old).toEqual([]);
221 |     });
222 | 
223 |     it('should be idempotent if active account is already null', async () => {
224 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
225 |       fs.writeFileSync(
226 |         accountsFile(),
227 |         JSON.stringify({ active: null, old: ['old1@google.com'] }, null, 2),
228 |       );
229 | 
230 |       await userAccountManager.clearCachedGoogleAccount();
231 | 
232 |       const stored = JSON.parse(fs.readFileSync(accountsFile(), 'utf-8'));
233 |       expect(stored.active).toBeNull();
234 |       expect(stored.old).toEqual(['old1@google.com']);
235 |     });
236 | 
237 |     it('should not add a duplicate to the old list', async () => {
238 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
239 |       fs.writeFileSync(
240 |         accountsFile(),
241 |         JSON.stringify(
242 |           {
243 |             active: 'active@google.com',
244 |             old: ['active@google.com'],
245 |           },
246 |           null,
247 |           2,
248 |         ),
249 |       );
250 | 
251 |       await userAccountManager.clearCachedGoogleAccount();
252 | 
253 |       const stored = JSON.parse(fs.readFileSync(accountsFile(), 'utf-8'));
254 |       expect(stored.active).toBeNull();
255 |       expect(stored.old).toEqual(['active@google.com']);
256 |     });
257 |   });
258 | 
259 |   describe('getLifetimeGoogleAccounts', () => {
260 |     it('should return 0 if the file does not exist', () => {
261 |       expect(userAccountManager.getLifetimeGoogleAccounts()).toBe(0);
262 |     });
263 | 
264 |     it('should return 0 if the file is empty', () => {
265 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
266 |       fs.writeFileSync(accountsFile(), '');
267 |       expect(userAccountManager.getLifetimeGoogleAccounts()).toBe(0);
268 |     });
269 | 
270 |     it('should return 0 if the file is corrupted', () => {
271 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
272 |       fs.writeFileSync(accountsFile(), 'invalid json');
273 |       const consoleDebugSpy = vi
274 |         .spyOn(console, 'log')
275 |         .mockImplementation(() => {});
276 | 
277 |       expect(userAccountManager.getLifetimeGoogleAccounts()).toBe(0);
278 |       expect(consoleDebugSpy).toHaveBeenCalled();
279 |     });
280 | 
281 |     it('should return 1 if there is only an active account', () => {
282 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
283 |       fs.writeFileSync(
284 |         accountsFile(),
285 |         JSON.stringify({ active: 'test1@google.com', old: [] }),
286 |       );
287 |       expect(userAccountManager.getLifetimeGoogleAccounts()).toBe(1);
288 |     });
289 | 
290 |     it('should correctly count old accounts when active is null', () => {
291 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
292 |       fs.writeFileSync(
293 |         accountsFile(),
294 |         JSON.stringify({
295 |           active: null,
296 |           old: ['test1@google.com', 'test2@google.com'],
297 |         }),
298 |       );
299 |       expect(userAccountManager.getLifetimeGoogleAccounts()).toBe(2);
300 |     });
301 | 
302 |     it('should correctly count both active and old accounts', () => {
303 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
304 |       fs.writeFileSync(
305 |         accountsFile(),
306 |         JSON.stringify({
307 |           active: 'test3@google.com',
308 |           old: ['test1@google.com', 'test2@google.com'],
309 |         }),
310 |       );
311 |       expect(userAccountManager.getLifetimeGoogleAccounts()).toBe(3);
312 |     });
313 | 
314 |     it('should handle valid JSON with incorrect schema by returning 0', () => {
315 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
316 |       fs.writeFileSync(
317 |         accountsFile(),
318 |         JSON.stringify({ active: null, old: 1 }),
319 |       );
320 |       const consoleLogSpy = vi
321 |         .spyOn(console, 'log')
322 |         .mockImplementation(() => {});
323 | 
324 |       expect(userAccountManager.getLifetimeGoogleAccounts()).toBe(0);
325 |       expect(consoleLogSpy).toHaveBeenCalled();
326 |     });
327 | 
328 |     it('should not double count if active account is also in old list', () => {
329 |       fs.mkdirSync(path.dirname(accountsFile()), { recursive: true });
330 |       fs.writeFileSync(
331 |         accountsFile(),
332 |         JSON.stringify({
333 |           active: 'test1@google.com',
334 |           old: ['test1@google.com', 'test2@google.com'],
335 |         }),
336 |       );
337 |       expect(userAccountManager.getLifetimeGoogleAccounts()).toBe(2);
338 |     });
339 |   });
340 | });
```

src/utils/userAccountManager.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import path from 'node:path';
8 | import { promises as fsp, readFileSync } from 'node:fs';
9 | import { Storage } from '../config/storage.js';
10 | 
11 | interface UserAccounts {
12 |   active: string | null;
13 |   old: string[];
14 | }
15 | 
16 | export class UserAccountManager {
17 |   private getGoogleAccountsCachePath(): string {
18 |     return Storage.getGoogleAccountsPath();
19 |   }
20 | 
21 |   /**
22 |    * Parses and validates the string content of an accounts file.
23 |    * @param content The raw string content from the file.
24 |    * @returns A valid UserAccounts object.
25 |    */
26 |   private parseAndValidateAccounts(content: string): UserAccounts {
27 |     const defaultState = { active: null, old: [] };
28 |     if (!content.trim()) {
29 |       return defaultState;
30 |     }
31 | 
32 |     const parsed = JSON.parse(content);
33 | 
34 |     // Inlined validation logic
35 |     if (typeof parsed !== 'object' || parsed === null) {
36 |       console.log('Invalid accounts file schema, starting fresh.');
37 |       return defaultState;
38 |     }
39 |     const { active, old } = parsed as Partial<UserAccounts>;
40 |     const isValid =
41 |       (active === undefined || active === null || typeof active === 'string') &&
42 |       (old === undefined ||
43 |         (Array.isArray(old) && old.every((i) => typeof i === 'string')));
44 | 
45 |     if (!isValid) {
46 |       console.log('Invalid accounts file schema, starting fresh.');
47 |       return defaultState;
48 |     }
49 | 
50 |     return {
51 |       active: parsed.active ?? null,
52 |       old: parsed.old ?? [],
53 |     };
54 |   }
55 | 
56 |   private readAccountsSync(filePath: string): UserAccounts {
57 |     const defaultState = { active: null, old: [] };
58 |     try {
59 |       const content = readFileSync(filePath, 'utf-8');
60 |       return this.parseAndValidateAccounts(content);
61 |     } catch (error) {
62 |       if (
63 |         error instanceof Error &&
64 |         'code' in error &&
65 |         error.code === 'ENOENT'
66 |       ) {
67 |         return defaultState;
68 |       }
69 |       console.log('Error during sync read of accounts, starting fresh.', error);
70 |       return defaultState;
71 |     }
72 |   }
73 | 
74 |   private async readAccounts(filePath: string): Promise<UserAccounts> {
75 |     const defaultState = { active: null, old: [] };
76 |     try {
77 |       const content = await fsp.readFile(filePath, 'utf-8');
78 |       return this.parseAndValidateAccounts(content);
79 |     } catch (error) {
80 |       if (
81 |         error instanceof Error &&
82 |         'code' in error &&
83 |         error.code === 'ENOENT'
84 |       ) {
85 |         return defaultState;
86 |       }
87 |       console.log('Could not parse accounts file, starting fresh.', error);
88 |       return defaultState;
89 |     }
90 |   }
91 | 
92 |   async cacheGoogleAccount(email: string): Promise<void> {
93 |     const filePath = this.getGoogleAccountsCachePath();
94 |     await fsp.mkdir(path.dirname(filePath), { recursive: true });
95 | 
96 |     const accounts = await this.readAccounts(filePath);
97 | 
98 |     if (accounts.active && accounts.active !== email) {
99 |       if (!accounts.old.includes(accounts.active)) {
100 |         accounts.old.push(accounts.active);
101 |       }
102 |     }
103 | 
104 |     // If the new email was in the old list, remove it
105 |     accounts.old = accounts.old.filter((oldEmail) => oldEmail !== email);
106 | 
107 |     accounts.active = email;
108 |     await fsp.writeFile(filePath, JSON.stringify(accounts, null, 2), 'utf-8');
109 |   }
110 | 
111 |   getCachedGoogleAccount(): string | null {
112 |     const filePath = this.getGoogleAccountsCachePath();
113 |     const accounts = this.readAccountsSync(filePath);
114 |     return accounts.active;
115 |   }
116 | 
117 |   getLifetimeGoogleAccounts(): number {
118 |     const filePath = this.getGoogleAccountsCachePath();
119 |     const accounts = this.readAccountsSync(filePath);
120 |     const allAccounts = new Set(accounts.old);
121 |     if (accounts.active) {
122 |       allAccounts.add(accounts.active);
123 |     }
124 |     return allAccounts.size;
125 |   }
126 | 
127 |   async clearCachedGoogleAccount(): Promise<void> {
128 |     const filePath = this.getGoogleAccountsCachePath();
129 |     const accounts = await this.readAccounts(filePath);
130 | 
131 |     if (accounts.active) {
132 |       if (!accounts.old.includes(accounts.active)) {
133 |         accounts.old.push(accounts.active);
134 |       }
135 |       accounts.active = null;
136 |     }
137 | 
138 |     await fsp.writeFile(filePath, JSON.stringify(accounts, null, 2), 'utf-8');
139 |   }
140 | }
```

src/utils/workspaceContext.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';
8 | import * as fs from 'node:fs';
9 | import * as os from 'node:os';
10 | import * as path from 'node:path';
11 | import { WorkspaceContext } from './workspaceContext.js';
12 | 
13 | describe('WorkspaceContext with real filesystem', () => {
14 |   let tempDir: string;
15 |   let cwd: string;
16 |   let otherDir: string;
17 | 
18 |   beforeEach(() => {
19 |     // os.tmpdir() can return a path using a symlink (this is standard on macOS)
20 |     // Use fs.realpathSync to fully resolve the absolute path.
21 |     tempDir = fs.realpathSync(
22 |       fs.mkdtempSync(path.join(os.tmpdir(), 'workspace-context-test-')),
23 |     );
24 | 
25 |     cwd = path.join(tempDir, 'project');
26 |     otherDir = path.join(tempDir, 'other-project');
27 | 
28 |     fs.mkdirSync(cwd, { recursive: true });
29 |     fs.mkdirSync(otherDir, { recursive: true });
30 |   });
31 | 
32 |   afterEach(() => {
33 |     fs.rmSync(tempDir, { recursive: true, force: true });
34 |   });
35 | 
36 |   describe('initialization', () => {
37 |     it('should initialize with a single directory (cwd)', () => {
38 |       const workspaceContext = new WorkspaceContext(cwd);
39 |       const directories = workspaceContext.getDirectories();
40 | 
41 |       expect(directories).toEqual([cwd]);
42 |     });
43 | 
44 |     it('should validate and resolve directories to absolute paths', () => {
45 |       const workspaceContext = new WorkspaceContext(cwd, [otherDir]);
46 |       const directories = workspaceContext.getDirectories();
47 | 
48 |       expect(directories).toEqual([cwd, otherDir]);
49 |     });
50 | 
51 |     it('should handle empty initialization', () => {
52 |       const workspaceContext = new WorkspaceContext(cwd, []);
53 |       const directories = workspaceContext.getDirectories();
54 |       expect(directories).toHaveLength(1);
55 |       expect(fs.realpathSync(directories[0])).toBe(cwd);
56 |     });
57 |   });
58 | 
59 |   describe('adding directories', () => {
60 |     it('should add valid directories', () => {
61 |       const workspaceContext = new WorkspaceContext(cwd);
62 |       workspaceContext.addDirectory(otherDir);
63 |       const directories = workspaceContext.getDirectories();
64 | 
65 |       expect(directories).toEqual([cwd, otherDir]);
66 |     });
67 | 
68 |     it('should resolve relative paths to absolute', () => {
69 |       const workspaceContext = new WorkspaceContext(cwd);
70 |       const relativePath = path.relative(cwd, otherDir);
71 |       workspaceContext.addDirectory(relativePath, cwd);
72 |       const directories = workspaceContext.getDirectories();
73 | 
74 |       expect(directories).toEqual([cwd, otherDir]);
75 |     });
76 | 
77 |     it('should prevent duplicate directories', () => {
78 |       const workspaceContext = new WorkspaceContext(cwd);
79 |       workspaceContext.addDirectory(otherDir);
80 |       workspaceContext.addDirectory(otherDir);
81 |       const directories = workspaceContext.getDirectories();
82 | 
83 |       expect(directories).toHaveLength(2);
84 |     });
85 | 
86 |     it('should handle symbolic links correctly', () => {
87 |       const realDir = path.join(tempDir, 'real');
88 |       fs.mkdirSync(realDir, { recursive: true });
89 |       const symlinkDir = path.join(tempDir, 'symlink-to-real');
90 |       fs.symlinkSync(realDir, symlinkDir, 'dir');
91 |       const workspaceContext = new WorkspaceContext(cwd);
92 |       workspaceContext.addDirectory(symlinkDir);
93 | 
94 |       const directories = workspaceContext.getDirectories();
95 | 
96 |       expect(directories).toEqual([cwd, realDir]);
97 |     });
98 |   });
99 | 
100 |   describe('path validation', () => {
101 |     it('should accept paths within workspace directories', () => {
102 |       const workspaceContext = new WorkspaceContext(cwd, [otherDir]);
103 |       const validPath1 = path.join(cwd, 'src', 'file.ts');
104 |       const validPath2 = path.join(otherDir, 'lib', 'module.js');
105 | 
106 |       fs.mkdirSync(path.dirname(validPath1), { recursive: true });
107 |       fs.writeFileSync(validPath1, 'content');
108 |       fs.mkdirSync(path.dirname(validPath2), { recursive: true });
109 |       fs.writeFileSync(validPath2, 'content');
110 | 
111 |       expect(workspaceContext.isPathWithinWorkspace(validPath1)).toBe(true);
112 |       expect(workspaceContext.isPathWithinWorkspace(validPath2)).toBe(true);
113 |     });
114 | 
115 |     it('should accept non-existent paths within workspace directories', () => {
116 |       const workspaceContext = new WorkspaceContext(cwd, [otherDir]);
117 |       const validPath1 = path.join(cwd, 'src', 'file.ts');
118 |       const validPath2 = path.join(otherDir, 'lib', 'module.js');
119 | 
120 |       expect(workspaceContext.isPathWithinWorkspace(validPath1)).toBe(true);
121 |       expect(workspaceContext.isPathWithinWorkspace(validPath2)).toBe(true);
122 |     });
123 | 
124 |     it('should reject paths outside workspace', () => {
125 |       const workspaceContext = new WorkspaceContext(cwd, [otherDir]);
126 |       const invalidPath = path.join(tempDir, 'outside-workspace', 'file.txt');
127 | 
128 |       expect(workspaceContext.isPathWithinWorkspace(invalidPath)).toBe(false);
129 |     });
130 | 
131 |     it('should reject non-existent paths outside workspace', () => {
132 |       const workspaceContext = new WorkspaceContext(cwd, [otherDir]);
133 |       const invalidPath = path.join(tempDir, 'outside-workspace', 'file.txt');
134 | 
135 |       expect(workspaceContext.isPathWithinWorkspace(invalidPath)).toBe(false);
136 |     });
137 | 
138 |     it('should handle nested directories correctly', () => {
139 |       const workspaceContext = new WorkspaceContext(cwd, [otherDir]);
140 |       const nestedPath = path.join(cwd, 'deeply', 'nested', 'path', 'file.txt');
141 |       expect(workspaceContext.isPathWithinWorkspace(nestedPath)).toBe(true);
142 |     });
143 | 
144 |     it('should handle edge cases (root, parent references)', () => {
145 |       const workspaceContext = new WorkspaceContext(cwd, [otherDir]);
146 |       const rootPath = path.parse(tempDir).root;
147 |       const parentPath = path.dirname(cwd);
148 | 
149 |       expect(workspaceContext.isPathWithinWorkspace(rootPath)).toBe(false);
150 |       expect(workspaceContext.isPathWithinWorkspace(parentPath)).toBe(false);
151 |     });
152 | 
153 |     it('should handle non-existent paths correctly', () => {
154 |       const workspaceContext = new WorkspaceContext(cwd, [otherDir]);
155 |       const nonExistentPath = path.join(cwd, 'does-not-exist.txt');
156 |       expect(workspaceContext.isPathWithinWorkspace(nonExistentPath)).toBe(
157 |         true,
158 |       );
159 |     });
160 | 
161 |     describe('with symbolic link', () => {
162 |       describe('in the workspace', () => {
163 |         let realDir: string;
164 |         let symlinkDir: string;
165 |         beforeEach(() => {
166 |           realDir = path.join(cwd, 'real-dir');
167 |           fs.mkdirSync(realDir, { recursive: true });
168 | 
169 |           symlinkDir = path.join(cwd, 'symlink-file');
170 |           fs.symlinkSync(realDir, symlinkDir, 'dir');
171 |         });
172 | 
173 |         it('should accept dir paths', () => {
174 |           const workspaceContext = new WorkspaceContext(cwd);
175 | 
176 |           expect(workspaceContext.isPathWithinWorkspace(symlinkDir)).toBe(true);
177 |         });
178 | 
179 |         it('should accept non-existent paths', () => {
180 |           const filePath = path.join(symlinkDir, 'does-not-exist.txt');
181 | 
182 |           const workspaceContext = new WorkspaceContext(cwd);
183 | 
184 |           expect(workspaceContext.isPathWithinWorkspace(filePath)).toBe(true);
185 |         });
186 | 
187 |         it('should accept non-existent deep paths', () => {
188 |           const filePath = path.join(symlinkDir, 'deep', 'does-not-exist.txt');
189 | 
190 |           const workspaceContext = new WorkspaceContext(cwd);
191 | 
192 |           expect(workspaceContext.isPathWithinWorkspace(filePath)).toBe(true);
193 |         });
194 |       });
195 | 
196 |       describe('outside the workspace', () => {
197 |         let realDir: string;
198 |         let symlinkDir: string;
199 |         beforeEach(() => {
200 |           realDir = path.join(tempDir, 'real-dir');
201 |           fs.mkdirSync(realDir, { recursive: true });
202 | 
203 |           symlinkDir = path.join(cwd, 'symlink-file');
204 |           fs.symlinkSync(realDir, symlinkDir, 'dir');
205 |         });
206 | 
207 |         it('should reject dir paths', () => {
208 |           const workspaceContext = new WorkspaceContext(cwd);
209 | 
210 |           expect(workspaceContext.isPathWithinWorkspace(symlinkDir)).toBe(
211 |             false,
212 |           );
213 |         });
214 | 
215 |         it('should reject non-existent paths', () => {
216 |           const filePath = path.join(symlinkDir, 'does-not-exist.txt');
217 | 
218 |           const workspaceContext = new WorkspaceContext(cwd);
219 | 
220 |           expect(workspaceContext.isPathWithinWorkspace(filePath)).toBe(false);
221 |         });
222 | 
223 |         it('should reject non-existent deep paths', () => {
224 |           const filePath = path.join(symlinkDir, 'deep', 'does-not-exist.txt');
225 | 
226 |           const workspaceContext = new WorkspaceContext(cwd);
227 | 
228 |           expect(workspaceContext.isPathWithinWorkspace(filePath)).toBe(false);
229 |         });
230 | 
231 |         it('should reject partially non-existent deep paths', () => {
232 |           const deepDir = path.join(symlinkDir, 'deep');
233 |           fs.mkdirSync(deepDir, { recursive: true });
234 |           const filePath = path.join(deepDir, 'does-not-exist.txt');
235 | 
236 |           const workspaceContext = new WorkspaceContext(cwd);
237 | 
238 |           expect(workspaceContext.isPathWithinWorkspace(filePath)).toBe(false);
239 |         });
240 |       });
241 | 
242 |       it('should reject symbolic file links outside the workspace', () => {
243 |         const realFile = path.join(tempDir, 'real-file.txt');
244 |         fs.writeFileSync(realFile, 'content');
245 | 
246 |         const symlinkFile = path.join(cwd, 'symlink-to-real-file');
247 |         fs.symlinkSync(realFile, symlinkFile, 'file');
248 | 
249 |         const workspaceContext = new WorkspaceContext(cwd);
250 | 
251 |         expect(workspaceContext.isPathWithinWorkspace(symlinkFile)).toBe(false);
252 |       });
253 | 
254 |       it('should reject non-existent symbolic file links outside the workspace', () => {
255 |         const realFile = path.join(tempDir, 'real-file.txt');
256 | 
257 |         const symlinkFile = path.join(cwd, 'symlink-to-real-file');
258 |         fs.symlinkSync(realFile, symlinkFile, 'file');
259 | 
260 |         const workspaceContext = new WorkspaceContext(cwd);
261 | 
262 |         expect(workspaceContext.isPathWithinWorkspace(symlinkFile)).toBe(false);
263 |       });
264 | 
265 |       it('should handle circular symlinks gracefully', () => {
266 |         const workspaceContext = new WorkspaceContext(cwd);
267 |         const linkA = path.join(cwd, 'link-a');
268 |         const linkB = path.join(cwd, 'link-b');
269 |         // Create a circular dependency: linkA -> linkB -> linkA
270 |         fs.symlinkSync(linkB, linkA, 'dir');
271 |         fs.symlinkSync(linkA, linkB, 'dir');
272 | 
273 |         // fs.realpathSync should throw ELOOP, and isPathWithinWorkspace should
274 |         // handle it gracefully and return false.
275 |         expect(workspaceContext.isPathWithinWorkspace(linkA)).toBe(false);
276 |         expect(workspaceContext.isPathWithinWorkspace(linkB)).toBe(false);
277 |       });
278 |     });
279 |   });
280 | 
281 |   describe('onDirectoriesChanged', () => {
282 |     it('should call listener when adding a directory', () => {
283 |       const workspaceContext = new WorkspaceContext(cwd);
284 |       const listener = vi.fn();
285 |       workspaceContext.onDirectoriesChanged(listener);
286 | 
287 |       workspaceContext.addDirectory(otherDir);
288 | 
289 |       expect(listener).toHaveBeenCalledOnce();
290 |     });
291 | 
292 |     it('should not call listener when adding a duplicate directory', () => {
293 |       const workspaceContext = new WorkspaceContext(cwd);
294 |       workspaceContext.addDirectory(otherDir);
295 |       const listener = vi.fn();
296 |       workspaceContext.onDirectoriesChanged(listener);
297 | 
298 |       workspaceContext.addDirectory(otherDir);
299 | 
300 |       expect(listener).not.toHaveBeenCalled();
301 |     });
302 | 
303 |     it('should call listener when setting different directories', () => {
304 |       const workspaceContext = new WorkspaceContext(cwd);
305 |       const listener = vi.fn();
306 |       workspaceContext.onDirectoriesChanged(listener);
307 | 
308 |       workspaceContext.setDirectories([otherDir]);
309 | 
310 |       expect(listener).toHaveBeenCalledOnce();
311 |     });
312 | 
313 |     it('should not call listener when setting same directories', () => {
314 |       const workspaceContext = new WorkspaceContext(cwd);
315 |       const listener = vi.fn();
316 |       workspaceContext.onDirectoriesChanged(listener);
317 | 
318 |       workspaceContext.setDirectories([cwd]);
319 | 
320 |       expect(listener).not.toHaveBeenCalled();
321 |     });
322 | 
323 |     it('should support multiple listeners', () => {
324 |       const workspaceContext = new WorkspaceContext(cwd);
325 |       const listener1 = vi.fn();
326 |       const listener2 = vi.fn();
327 |       workspaceContext.onDirectoriesChanged(listener1);
328 |       workspaceContext.onDirectoriesChanged(listener2);
329 | 
330 |       workspaceContext.addDirectory(otherDir);
331 | 
332 |       expect(listener1).toHaveBeenCalledOnce();
333 |       expect(listener2).toHaveBeenCalledOnce();
334 |     });
335 | 
336 |     it('should allow unsubscribing a listener', () => {
337 |       const workspaceContext = new WorkspaceContext(cwd);
338 |       const listener = vi.fn();
339 |       const unsubscribe = workspaceContext.onDirectoriesChanged(listener);
340 | 
341 |       unsubscribe();
342 |       workspaceContext.addDirectory(otherDir);
343 | 
344 |       expect(listener).not.toHaveBeenCalled();
345 |     });
346 | 
347 |     it('should not fail if a listener throws an error', () => {
348 |       const workspaceContext = new WorkspaceContext(cwd);
349 |       const errorListener = () => {
350 |         throw new Error('test error');
351 |       };
352 |       const listener = vi.fn();
353 |       workspaceContext.onDirectoriesChanged(errorListener);
354 |       workspaceContext.onDirectoriesChanged(listener);
355 | 
356 |       expect(() => {
357 |         workspaceContext.addDirectory(otherDir);
358 |       }).not.toThrow();
359 |       expect(listener).toHaveBeenCalledOnce();
360 |     });
361 |   });
362 | 
363 |   describe('getDirectories', () => {
364 |     it('should return a copy of directories array', () => {
365 |       const workspaceContext = new WorkspaceContext(cwd);
366 |       const dirs1 = workspaceContext.getDirectories();
367 |       const dirs2 = workspaceContext.getDirectories();
368 | 
369 |       expect(dirs1).not.toBe(dirs2);
370 |       expect(dirs1).toEqual(dirs2);
371 |     });
372 |   });
373 | });
374 | 
375 | describe('WorkspaceContext with optional directories', () => {
376 |   let tempDir: string;
377 |   let cwd: string;
378 |   let existingDir1: string;
379 |   let existingDir2: string;
380 |   let nonExistentDir: string;
381 | 
382 |   beforeEach(() => {
383 |     tempDir = fs.realpathSync(
384 |       fs.mkdtempSync(path.join(os.tmpdir(), 'workspace-context-optional-')),
385 |     );
386 |     cwd = path.join(tempDir, 'project');
387 |     existingDir1 = path.join(tempDir, 'existing-dir-1');
388 |     existingDir2 = path.join(tempDir, 'existing-dir-2');
389 |     nonExistentDir = path.join(tempDir, 'non-existent-dir');
390 | 
391 |     fs.mkdirSync(cwd, { recursive: true });
392 |     fs.mkdirSync(existingDir1, { recursive: true });
393 |     fs.mkdirSync(existingDir2, { recursive: true });
394 | 
395 |     vi.spyOn(console, 'warn').mockImplementation(() => {});
396 |   });
397 | 
398 |   afterEach(() => {
399 |     fs.rmSync(tempDir, { recursive: true, force: true });
400 |     vi.restoreAllMocks();
401 |   });
402 | 
403 |   it('should skip a missing optional directory and log a warning', () => {
404 |     const workspaceContext = new WorkspaceContext(cwd, [
405 |       nonExistentDir,
406 |       existingDir1,
407 |     ]);
408 |     const directories = workspaceContext.getDirectories();
409 |     expect(directories).toEqual([cwd, existingDir1]);
410 |     expect(console.warn).toHaveBeenCalledTimes(1);
411 |     expect(console.warn).toHaveBeenCalledWith(
412 |       `[WARN] Skipping unreadable directory: ${nonExistentDir} (Directory does not exist: ${nonExistentDir})`,
413 |     );
414 |   });
415 | 
416 |   it('should include an existing optional directory', () => {
417 |     const workspaceContext = new WorkspaceContext(cwd, [existingDir1]);
418 |     const directories = workspaceContext.getDirectories();
419 |     expect(directories).toEqual([cwd, existingDir1]);
420 |     expect(console.warn).not.toHaveBeenCalled();
421 |   });
422 | });
```

src/utils/workspaceContext.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { isNodeError } from '../utils/errors.js';
8 | import * as fs from 'node:fs';
9 | import * as path from 'node:path';
10 | import * as process from 'node:process';
11 | 
12 | export type Unsubscribe = () => void;
13 | 
14 | /**
15 |  * WorkspaceContext manages multiple workspace directories and validates paths
16 |  * against them. This allows the CLI to operate on files from multiple directories
17 |  * in a single session.
18 |  */
19 | export class WorkspaceContext {
20 |   private directories = new Set<string>();
21 |   private initialDirectories: Set<string>;
22 |   private onDirectoriesChangedListeners = new Set<() => void>();
23 | 
24 |   /**
25 |    * Creates a new WorkspaceContext with the given initial directory and optional additional directories.
26 |    * @param directory The initial working directory (usually cwd)
27 |    * @param additionalDirectories Optional array of additional directories to include
28 |    */
29 |   constructor(directory: string, additionalDirectories: string[] = []) {
30 |     this.addDirectory(directory);
31 |     for (const additionalDirectory of additionalDirectories) {
32 |       this.addDirectory(additionalDirectory);
33 |     }
34 |     this.initialDirectories = new Set(this.directories);
35 |   }
36 | 
37 |   /**
38 |    * Registers a listener that is called when the workspace directories change.
39 |    * @param listener The listener to call.
40 |    * @returns A function to unsubscribe the listener.
41 |    */
42 |   onDirectoriesChanged(listener: () => void): Unsubscribe {
43 |     this.onDirectoriesChangedListeners.add(listener);
44 |     return () => {
45 |       this.onDirectoriesChangedListeners.delete(listener);
46 |     };
47 |   }
48 | 
49 |   private notifyDirectoriesChanged() {
50 |     // Iterate over a copy of the set in case a listener unsubscribes itself or others.
51 |     for (const listener of [...this.onDirectoriesChangedListeners]) {
52 |       try {
53 |         listener();
54 |       } catch (e) {
55 |         // Don't let one listener break others.
56 |         console.error('Error in WorkspaceContext listener:', e);
57 |       }
58 |     }
59 |   }
60 | 
61 |   /**
62 |    * Adds a directory to the workspace.
63 |    * @param directory The directory path to add (can be relative or absolute)
64 |    * @param basePath Optional base path for resolving relative paths (defaults to cwd)
65 |    */
66 |   addDirectory(directory: string, basePath: string = process.cwd()): void {
67 |     try {
68 |       const resolved = this.resolveAndValidateDir(directory, basePath);
69 |       if (this.directories.has(resolved)) {
70 |         return;
71 |       }
72 |       this.directories.add(resolved);
73 |       this.notifyDirectoriesChanged();
74 |     } catch (err) {
75 |       console.warn(
76 |         `[WARN] Skipping unreadable directory: ${directory} (${err instanceof Error ? err.message : String(err)})`,
77 |       );
78 |     }
79 |   }
80 | 
81 |   private resolveAndValidateDir(
82 |     directory: string,
83 |     basePath: string = process.cwd(),
84 |   ): string {
85 |     const absolutePath = path.isAbsolute(directory)
86 |       ? directory
87 |       : path.resolve(basePath, directory);
88 | 
89 |     if (!fs.existsSync(absolutePath)) {
90 |       throw new Error(`Directory does not exist: ${absolutePath}`);
91 |     }
92 |     const stats = fs.statSync(absolutePath);
93 |     if (!stats.isDirectory()) {
94 |       throw new Error(`Path is not a directory: ${absolutePath}`);
95 |     }
96 | 
97 |     return fs.realpathSync(absolutePath);
98 |   }
99 | 
100 |   /**
101 |    * Gets a copy of all workspace directories.
102 |    * @returns Array of absolute directory paths
103 |    */
104 |   getDirectories(): readonly string[] {
105 |     return Array.from(this.directories);
106 |   }
107 | 
108 |   getInitialDirectories(): readonly string[] {
109 |     return Array.from(this.initialDirectories);
110 |   }
111 | 
112 |   setDirectories(directories: readonly string[]): void {
113 |     const newDirectories = new Set<string>();
114 |     for (const dir of directories) {
115 |       newDirectories.add(this.resolveAndValidateDir(dir));
116 |     }
117 | 
118 |     if (
119 |       newDirectories.size !== this.directories.size ||
120 |       ![...newDirectories].every((d) => this.directories.has(d))
121 |     ) {
122 |       this.directories = newDirectories;
123 |       this.notifyDirectoriesChanged();
124 |     }
125 |   }
126 | 
127 |   /**
128 |    * Checks if a given path is within any of the workspace directories.
129 |    * @param pathToCheck The path to validate
130 |    * @returns True if the path is within the workspace, false otherwise
131 |    */
132 |   isPathWithinWorkspace(pathToCheck: string): boolean {
133 |     try {
134 |       const fullyResolvedPath = this.fullyResolvedPath(pathToCheck);
135 | 
136 |       for (const dir of this.directories) {
137 |         if (this.isPathWithinRoot(fullyResolvedPath, dir)) {
138 |           return true;
139 |         }
140 |       }
141 |       return false;
142 |     } catch (_error) {
143 |       return false;
144 |     }
145 |   }
146 | 
147 |   /**
148 |    * Fully resolves a path, including symbolic links.
149 |    * If the path does not exist, it returns the fully resolved path as it would be
150 |    * if it did exist.
151 |    */
152 |   private fullyResolvedPath(pathToCheck: string): string {
153 |     try {
154 |       return fs.realpathSync(pathToCheck);
155 |     } catch (e: unknown) {
156 |       if (
157 |         isNodeError(e) &&
158 |         e.code === 'ENOENT' &&
159 |         e.path &&
160 |         // realpathSync does not set e.path correctly for symlinks to
161 |         // non-existent files.
162 |         !this.isFileSymlink(e.path)
163 |       ) {
164 |         // If it doesn't exist, e.path contains the fully resolved path.
165 |         return e.path;
166 |       }
167 |       throw e;
168 |     }
169 |   }
170 | 
171 |   /**
172 |    * Checks if a path is within a given root directory.
173 |    * @param pathToCheck The absolute path to check
174 |    * @param rootDirectory The absolute root directory
175 |    * @returns True if the path is within the root directory, false otherwise
176 |    */
177 |   private isPathWithinRoot(
178 |     pathToCheck: string,
179 |     rootDirectory: string,
180 |   ): boolean {
181 |     const relative = path.relative(rootDirectory, pathToCheck);
182 |     return (
183 |       !relative.startsWith(`..${path.sep}`) &&
184 |       relative !== '..' &&
185 |       !path.isAbsolute(relative)
186 |     );
187 |   }
188 | 
189 |   /**
190 |    * Checks if a file path is a symbolic link that points to a file.
191 |    */
192 |   private isFileSymlink(filePath: string): boolean {
193 |     try {
194 |       return !fs.readlinkSync(filePath).endsWith('/');
195 |     } catch (_error) {
196 |       return false;
197 |     }
198 |   }
199 | }
```

src/__mocks__/fs/promises.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { vi } from 'vitest';
8 | import * as actualFsPromises from 'node:fs/promises';
9 | 
10 | const readFileMock = vi.fn();
11 | 
12 | // Export a control object so tests can access and manipulate the mock
13 | export const mockControl = {
14 |   mockReadFile: readFileMock,
15 | };
16 | 
17 | // Export all other functions from the actual fs/promises module
18 | export const {
19 |   access,
20 |   appendFile,
21 |   chmod,
22 |   chown,
23 |   copyFile,
24 |   cp,
25 |   lchmod,
26 |   lchown,
27 |   link,
28 |   lstat,
29 |   mkdir,
30 |   open,
31 |   opendir,
32 |   readdir,
33 |   readlink,
34 |   realpath,
35 |   rename,
36 |   rmdir,
37 |   rm,
38 |   stat,
39 |   symlink,
40 |   truncate,
41 |   unlink,
42 |   utimes,
43 |   watch,
44 |   writeFile,
45 | } = actualFsPromises;
46 | 
47 | // Override readFile with our mock
48 | export const readFile = readFileMock;
```

src/core/__snapshots__/prompts.test.ts.snap
```
1 | // Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html
2 | 
3 | exports[`Core System Prompt (prompts.ts) > should append userMemory with separator when provided 1`] = `
4 | "You are an interactive CLI agent specializing in software engineering tasks. Your primary goal is to help users safely and efficiently, adhering strictly to the following instructions and utilizing your available tools.
5 | 
6 | # Core Mandates
7 | 
8 | - **Conventions:** Rigorously adhere to existing project conventions when reading or modifying code. Analyze surrounding code, tests, and configuration first.
9 | - **Libraries/Frameworks:** NEVER assume a library/framework is available or appropriate. Verify its established usage within the project (check imports, configuration files like 'package.json', 'Cargo.toml', 'requirements.txt', 'build.gradle', etc., or observe neighboring files) before employing it.
10 | - **Style & Structure:** Mimic the style (formatting, naming), structure, framework choices, typing, and architectural patterns of existing code in the project.
11 | - **Idiomatic Changes:** When editing, understand the local context (imports, functions/classes) to ensure your changes integrate naturally and idiomatically.
12 | - **Comments:** Add code comments sparingly. Focus on *why* something is done, especially for complex logic, rather than *what* is done. Only add high-value comments if necessary for clarity or if requested by the user. Do not edit comments that are separate from the code you are changing. *NEVER* talk to the user or describe your changes through comments.
13 | - **Proactiveness:** Fulfill the user's request thoroughly. When adding features or fixing bugs, this includes adding tests to ensure quality. Consider all created files, especially tests, to be permanent artifacts unless the user says otherwise.
14 | - **Confirm Ambiguity/Expansion:** Do not take significant actions beyond the clear scope of the request without confirming with the user. If asked *how* to do something, explain first, don't just do it.
15 | - **Explaining Changes:** After completing a code modification or file operation *do not* provide summaries unless asked.
16 | - **Path Construction:** Before using any file system tool (e.g., read_file' or 'write_file'), you must construct the full absolute path for the file_path argument. Always combine the absolute path of the project's root directory with the file's path relative to the root. For example, if the project root is /path/to/project/ and the file is foo/bar/baz.txt, the final path you must use is /path/to/project/foo/bar/baz.txt. If the user provides a relative path, you must resolve it against the root directory to create an absolute path.
17 | - **Do Not revert changes:** Do not revert changes to the codebase unless asked to do so by the user. Only revert changes made by you if they have resulted in an error or if the user has explicitly asked you to revert the changes.
18 | 
19 | 
20 | # Primary Workflows
21 | 
22 | ## Software Engineering Tasks
23 | When requested to perform tasks like fixing bugs, adding features, refactoring, or explaining code, follow this sequence:
24 | 
25 | 1. **Understand:** Think about the user's request and the relevant codebase context. Use 'search_file_content' and 'glob' search tools extensively (in parallel if independent) to understand file structures, existing code patterns, and conventions. Use 'read_file' and 'read_many_files' to understand context and validate any assumptions you may have.
26 | 2. **Plan:** Build a coherent and grounded (based on the understanding in step 1) plan for how you intend to resolve the user's task. Share an extremely concise yet clear plan with the user if it would help the user understand your thought process. As part of the plan, you should use an iterative development process that includes writing unit tests to verify your changes. Use output logs or debug statements as part of this process to arrive at a solution.
27 | 3. **Implement:** Use the available tools (e.g., 'replace', 'write_file' 'run_shell_command' ...) to act on the plan, strictly adhering to the project's established conventions (detailed under 'Core Mandates').
28 | 4. **Verify (Tests):** If applicable and feasible, verify the changes using the project's testing procedures. Identify the correct test commands and frameworks by examining 'README' files, build/package configuration (e.g., 'package.json'), or existing test execution patterns. NEVER assume standard test commands.
29 | 5. **Verify (Standards):** VERY IMPORTANT: After making code changes, execute the project-specific build, linting and type-checking commands (e.g., 'tsc', 'npm run lint', 'ruff check .') that you have identified for this project (or obtained from the user). This ensures code quality and adherence to standards. If unsure about these commands, you can ask the user if they'd like you to run them and if so how to.
30 | 6. **Finalize:** After all verification passes, consider the task complete. Do not remove or revert any changes or created files (like tests). Await the user's next instruction.
31 | 
32 | ## New Applications
33 | 
34 | **Goal:** Autonomously implement and deliver a visually appealing, substantially complete, and functional prototype. Utilize all tools at your disposal to implement the application. Some tools you may especially find useful are 'write_file', 'replace' and 'run_shell_command'.
35 | 
36 | 1. **Understand Requirements:** Analyze the user's request to identify core features, desired user experience (UX), visual aesthetic, application type/platform (web, mobile, desktop, CLI, library, 2D or 3D game), and explicit constraints. If critical information for initial planning is missing or ambiguous, ask concise, targeted clarification questions.
37 | 2. **Propose Plan:** Formulate an internal development plan. Present a clear, concise, high-level summary to the user. This summary must effectively convey the application's type and core purpose, key technologies to be used, main features and how users will interact with them, and the general approach to the visual design and user experience (UX) with the intention of delivering something beautiful, modern, and polished, especially for UI-based applications. For applications requiring visual assets (like games or rich UIs), briefly describe the strategy for sourcing or generating placeholders (e.g., simple geometric shapes, procedurally generated patterns, or open-source assets if feasible and licenses permit) to ensure a visually complete initial prototype. Ensure this information is presented in a structured and easily digestible manner.
38 |   - When key technologies aren't specified, prefer the following:
39 |   - **Websites (Frontend):** React (JavaScript/TypeScript) with Bootstrap CSS, incorporating Material Design principles for UI/UX.
40 |   - **Back-End APIs:** Node.js with Express.js (JavaScript/TypeScript) or Python with FastAPI.
41 |   - **Full-stack:** Next.js (React/Node.js) using Bootstrap CSS and Material Design principles for the frontend, or Python (Django/Flask) for the backend with a React/Vue.js frontend styled with Bootstrap CSS and Material Design principles.
42 |   - **CLIs:** Python or Go.
43 |   - **Mobile App:** Compose Multiplatform (Kotlin Multiplatform) or Flutter (Dart) using Material Design libraries and principles, when sharing code between Android and iOS. Jetpack Compose (Kotlin JVM) with Material Design principles or SwiftUI (Swift) for native apps targeted at either Android or iOS, respectively.
44 |   - **3d Games:** HTML/CSS/JavaScript with Three.js.
45 |   - **2d Games:** HTML/CSS/JavaScript.
46 | 3. **User Approval:** Obtain user approval for the proposed plan.
47 | 4. **Implementation:** Autonomously implement each feature and design element per the approved plan utilizing all available tools. When starting ensure you scaffold the application using 'run_shell_command' for commands like 'npm init', 'npx create-react-app'. Aim for full scope completion. Proactively create or source necessary placeholder assets (e.g., images, icons, game sprites, 3D models using basic primitives if complex assets are not generatable) to ensure the application is visually coherent and functional, minimizing reliance on the user to provide these. If the model can generate simple assets (e.g., a uniformly colored square sprite, a simple 3D cube), it should do so. Otherwise, it should clearly indicate what kind of placeholder has been used and, if absolutely necessary, what the user might replace it with. Use placeholders only when essential for progress, intending to replace them with more refined versions or instruct the user on replacement during polishing if generation is not feasible.
48 | 5. **Verify:** Review work against the original request, the approved plan. Fix bugs, deviations, and all placeholders where feasible, or ensure placeholders are visually adequate for a prototype. Ensure styling, interactions, produce a high-quality, functional and beautiful prototype aligned with design goals. Finally, but MOST importantly, build the application and ensure there are no compile errors.
49 | 6. **Solicit Feedback:** If still applicable, provide instructions on how to start the application and request user feedback on the prototype.
50 | 
51 | # Operational Guidelines
52 | 
53 | ## Tone and Style (CLI Interaction)
54 | - **Concise & Direct:** Adopt a professional, direct, and concise tone suitable for a CLI environment.
55 | - **Minimal Output:** Aim for fewer than 3 lines of text output (excluding tool use/code generation) per response whenever practical. Focus strictly on the user's query.
56 | - **Clarity over Brevity (When Needed):** While conciseness is key, prioritize clarity for essential explanations or when seeking necessary clarification if a request is ambiguous.
57 | - **No Chitchat:** Avoid conversational filler, preambles ("Okay, I will now..."), or postambles ("I have finished the changes..."). Get straight to the action or answer.
58 | - **Formatting:** Use GitHub-flavored Markdown. Responses will be rendered in monospace.
59 | - **Tools vs. Text:** Use tools for actions, text output *only* for communication. Do not add explanatory comments within tool calls or code blocks unless specifically part of the required code/command itself.
60 | - **Handling Inability:** If unable/unwilling to fulfill a request, state so briefly (1-2 sentences) without excessive justification. Offer alternatives if appropriate.
61 | 
62 | ## Security and Safety Rules
63 | - **Explain Critical Commands:** Before executing commands with 'run_shell_command' that modify the file system, codebase, or system state, you *must* provide a brief explanation of the command's purpose and potential impact. Prioritize user understanding and safety. You should not ask permission to use the tool; the user will be presented with a confirmation dialogue upon use (you do not need to tell them this).
64 | - **Security First:** Always apply security best practices. Never introduce code that exposes, logs, or commits secrets, API keys, or other sensitive information.
65 | 
66 | ## Tool Usage
67 | - **File Paths:** Always use absolute paths when referring to files with tools like 'read_file' or 'write_file'. Relative paths are not supported. You must provide an absolute path.
68 | - **Parallelism:** Execute multiple independent tool calls in parallel when feasible (i.e. searching the codebase).
69 | - **Command Execution:** Use the 'run_shell_command' tool for running shell commands, remembering the safety rule to explain modifying commands first.
70 | - **Background Processes:** Use background processes (via \`&\`) for commands that are unlikely to stop on their own, e.g. \`node server.js &\`. If unsure, ask the user.
71 | - **Interactive Commands:** Try to avoid shell commands that are likely to require user interaction (e.g. \`git rebase -i\`). Use non-interactive versions of commands (e.g. \`npm init -y\` instead of \`npm init\`) when available, and otherwise remind the user that interactive shell commands are not supported and may cause hangs until canceled by the user.
72 | - **Remembering Facts:** Use the 'save_memory' tool to remember specific, *user-related* facts or preferences when the user explicitly asks, or when they state a clear, concise piece of information that would help personalize or streamline *your future interactions with them* (e.g., preferred coding style, common project paths they use, personal tool aliases). This tool is for user-specific information that should persist across sessions. Do *not* use it for general project context or information. If unsure whether to save something, you can ask the user, "Should I remember that for you?"
73 | - **Respect User Confirmations:** Most tool calls (also denoted as 'function calls') will first require confirmation from the user, where they will either approve or cancel the function call. If a user cancels a function call, respect their choice and do _not_ try to make the function call again. It is okay to request the tool call again _only_ if the user requests that same tool call on a subsequent prompt. When a user cancels a function call, assume best intentions from the user and consider inquiring if they prefer any alternative paths forward.
74 | 
75 | ## Interaction Details
76 | - **Help Command:** The user can use '/help' to display help information.
77 | - **Feedback:** To report a bug or provide feedback, please use the /bug command.
78 | 
79 | 
80 | # Outside of Sandbox
81 | You are running outside of a sandbox container, directly on the user's system. For critical commands that are particularly likely to modify the user's system outside of the project directory or system temp directory, as you explain the command to the user (per the Explain Critical Commands rule above), also remind the user to consider enabling sandboxing.
82 | 
83 | 
84 | 
85 | 
86 | # Examples (Illustrating Tone and Workflow)
87 | <example>
88 | user: 1 + 2
89 | model: 3
90 | </example>
91 | 
92 | <example>
93 | user: is 13 a prime number?
94 | model: true
95 | </example>
96 | 
97 | <example>
98 | user: list files here.
99 | model: [tool_call: list_directory for path '/path/to/project']
100 | </example>
101 | 
102 | <example>
103 | user: start the server implemented in server.js
104 | model: [tool_call: run_shell_command for 'node server.js &' because it must run in the background]
105 | </example>
106 | 
107 | 
108 | <example>
109 | user: Refactor the auth logic in src/auth.py to use the requests library instead of urllib.
110 | model: Okay, I can refactor 'src/auth.py'.
111 | First, I'll analyze the code and check for a test safety net before planning any changes.
112 | [tool_call: glob for path 'tests/test_auth.py']
113 | [tool_call: read_file for absolute_path '/path/to/tests/test_auth.py']
114 | (After analysis)
115 | Great, 'tests/test_auth.py' exists and covers the core authentication logic. With this safety net in place, I can safely plan the refactoring.
116 | I'll also confirm 'requests' is a dependency.
117 | [tool_call: read_file for absolute_path '/path/to/requirements.txt']
118 | (After analysis)
119 | Looks good, 'requests' is available.
120 | 
121 | Here's the plan:
122 | 1.  Replace the 'urllib' calls with 'requests'.
123 | 2.  Add proper 'try...except' error handling for the new network calls.
124 | 3.  Remove the old 'urllib' import.
125 | 4.  Run the project's linter and tests to verify the changes.
126 | 
127 | Should I proceed?
128 | user: Yes
129 | model:
130 | [tool_call: write_file or replace to apply the refactoring to 'src/auth.py']
131 | Refactoring complete. Running verification...
132 | [tool_call: run_shell_command for 'ruff check src/auth.py && pytest']
133 | (After verification passes)
134 | All checks passed. This is a stable checkpoint.
135 | 
136 | </example>
137 | 
138 | 
139 | <example>
140 | user: Delete the temp directory.
141 | model: I can run \`rm -rf /path/to/project/temp\`. This will permanently delete the directory and all its contents.
142 | </example>
143 | 
144 | <example>
145 | user: Write tests for someFile.ts
146 | model:
147 | Okay, I can write those tests. First, I'll read \`someFile.ts\` to understand its functionality.
148 | [tool_call: read_file for absolute_path '/path/to/someFile.ts' or use glob to find \`someFile.ts\` if its location is unknown]
149 | Now I'll look for existing or related test files to understand current testing conventions and dependencies.
150 | [tool_call: read_many_files for paths ['**/*.test.ts', 'src/**/*.spec.ts'] assuming someFile.ts is in the src directory]
151 | (After reviewing existing tests and the file content)
152 | [tool_call: write_file to create /path/to/someFile.test.ts with the test code]
153 | I've written the tests. Now I'll run the project's test command to verify them.
154 | [tool_call: run_shell_command for 'npm run test']
155 | </example>
156 | 
157 | 
158 | <example>
159 | user: How do I update the user's profile information in this system?
160 | model:
161 | I'm not immediately sure how user profile information is updated. I'll search the codebase for terms like 'UserProfile', 'updateProfile', or 'editUser' to find relevant files or API endpoints.
162 | [tool_call: search_file_content for pattern 'UserProfile|updateProfile|editUser']
163 | (After reviewing search results, assuming a relevant file like '/path/to/UserProfileService.java' was found)
164 | Okay, \`/path/to/UserProfileService.java\` seems like the most relevant file. I'll read its content to understand how updates are handled.
165 | [tool_call: read_file for absolute_path '/path/to/UserProfileService.java']
166 | (After reading the file)
167 | It appears the \`updateUserProfile\` method in \`UserProfileService.java\` is responsible for this. It expects a user ID and a \`UserProfileDTO\` object...
168 | </example>
169 | 
170 | 
171 | <example>
172 | user: Where are all the 'app.config' files in this project? I need to check their settings.
173 | model:
174 | [tool_call: glob for pattern '**/app.config']
175 | (Assuming GlobTool returns a list of paths like ['/path/to/moduleA/app.config', '/path/to/moduleB/app.config'])
176 | I found the following 'app.config' files:
177 | - /path/to/moduleA/app.config
178 | - /path/to/moduleB/app.config
179 | To help you check their settings, I can read their contents. Which one would you like to start with, or should I read all of them?
180 | </example>
181 | 
182 | # Final Reminder
183 | Your core function is efficient and safe assistance. Balance extreme conciseness with the crucial need for clarity, especially regarding safety and potential system modifications. Always prioritize user control and project conventions. Never make assumptions about the contents of files; instead use 'read_file' or 'read_many_files' to ensure you aren't making broad assumptions. Finally, you are an agent - please keep going until the user's query is completely resolved.
184 | 
185 | ---
186 | 
187 | This is custom user memory.
188 | Be extra polite."
189 | `;
190 | 
191 | exports[`Core System Prompt (prompts.ts) > should include git instructions when in a git repo 1`] = `
[TRUNCATED]
```

src/routing/strategies/classifierStrategy.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach } from 'vitest';
8 | import { ClassifierStrategy } from './classifierStrategy.js';
9 | import type { RoutingContext } from '../routingStrategy.js';
10 | import type { Config } from '../../config/config.js';
11 | import type { BaseLlmClient } from '../../core/baseLlmClient.js';
12 | import {
13 |   isFunctionCall,
14 |   isFunctionResponse,
15 | } from '../../utils/messageInspectors.js';
16 | import {
17 |   DEFAULT_GEMINI_FLASH_MODEL,
18 |   DEFAULT_GEMINI_FLASH_LITE_MODEL,
19 |   DEFAULT_GEMINI_MODEL,
20 | } from '../../config/models.js';
21 | import { promptIdContext } from '../../utils/promptIdContext.js';
22 | import type { Content } from '@google/genai';
23 | 
24 | vi.mock('../../core/baseLlmClient.js');
25 | vi.mock('../../utils/promptIdContext.js');
26 | 
27 | describe('ClassifierStrategy', () => {
28 |   let strategy: ClassifierStrategy;
29 |   let mockContext: RoutingContext;
30 |   let mockConfig: Config;
31 |   let mockBaseLlmClient: BaseLlmClient;
32 | 
33 |   beforeEach(() => {
34 |     vi.clearAllMocks();
35 | 
36 |     strategy = new ClassifierStrategy();
37 |     mockContext = {
38 |       history: [],
39 |       request: [{ text: 'simple task' }],
40 |       signal: new AbortController().signal,
41 |     };
42 |     mockConfig = {} as Config;
43 |     mockBaseLlmClient = {
44 |       generateJson: vi.fn(),
45 |     } as unknown as BaseLlmClient;
46 | 
47 |     vi.mocked(promptIdContext.getStore).mockReturnValue('test-prompt-id');
48 |   });
49 | 
50 |   it('should call generateJson with the correct parameters', async () => {
51 |     const mockApiResponse = {
52 |       reasoning: 'Simple task',
53 |       model_choice: 'flash',
54 |     };
55 |     vi.mocked(mockBaseLlmClient.generateJson).mockResolvedValue(
56 |       mockApiResponse,
57 |     );
58 | 
59 |     await strategy.route(mockContext, mockConfig, mockBaseLlmClient);
60 | 
61 |     expect(mockBaseLlmClient.generateJson).toHaveBeenCalledWith(
62 |       expect.objectContaining({
63 |         model: DEFAULT_GEMINI_FLASH_LITE_MODEL,
64 |         config: expect.objectContaining({
65 |           temperature: 0,
66 |           maxOutputTokens: 1024,
67 |           thinkingConfig: {
68 |             thinkingBudget: 512,
69 |           },
70 |         }),
71 |         promptId: 'test-prompt-id',
72 |       }),
73 |     );
74 |   });
75 | 
76 |   it('should route to FLASH model for a simple task', async () => {
77 |     const mockApiResponse = {
78 |       reasoning: 'This is a simple task.',
79 |       model_choice: 'flash',
80 |     };
81 |     vi.mocked(mockBaseLlmClient.generateJson).mockResolvedValue(
82 |       mockApiResponse,
83 |     );
84 | 
85 |     const decision = await strategy.route(
86 |       mockContext,
87 |       mockConfig,
88 |       mockBaseLlmClient,
89 |     );
90 | 
91 |     expect(mockBaseLlmClient.generateJson).toHaveBeenCalledOnce();
92 |     expect(decision).toEqual({
93 |       model: DEFAULT_GEMINI_FLASH_MODEL,
94 |       metadata: {
95 |         source: 'Classifier',
96 |         latencyMs: expect.any(Number),
97 |         reasoning: mockApiResponse.reasoning,
98 |       },
99 |     });
100 |   });
101 | 
102 |   it('should route to PRO model for a complex task', async () => {
103 |     const mockApiResponse = {
104 |       reasoning: 'This is a complex task.',
105 |       model_choice: 'pro',
106 |     };
107 |     vi.mocked(mockBaseLlmClient.generateJson).mockResolvedValue(
108 |       mockApiResponse,
109 |     );
110 |     mockContext.request = [{ text: 'how do I build a spaceship?' }];
111 | 
112 |     const decision = await strategy.route(
113 |       mockContext,
114 |       mockConfig,
115 |       mockBaseLlmClient,
116 |     );
117 | 
118 |     expect(mockBaseLlmClient.generateJson).toHaveBeenCalledOnce();
119 |     expect(decision).toEqual({
120 |       model: DEFAULT_GEMINI_MODEL,
121 |       metadata: {
122 |         source: 'Classifier',
123 |         latencyMs: expect.any(Number),
124 |         reasoning: mockApiResponse.reasoning,
125 |       },
126 |     });
127 |   });
128 | 
129 |   it('should return null if the classifier API call fails', async () => {
130 |     const consoleWarnSpy = vi
131 |       .spyOn(console, 'warn')
132 |       .mockImplementation(() => {});
133 |     const testError = new Error('API Failure');
134 |     vi.mocked(mockBaseLlmClient.generateJson).mockRejectedValue(testError);
135 | 
136 |     const decision = await strategy.route(
137 |       mockContext,
138 |       mockConfig,
139 |       mockBaseLlmClient,
140 |     );
141 | 
142 |     expect(decision).toBeNull();
143 |     expect(consoleWarnSpy).toHaveBeenCalled();
144 |     consoleWarnSpy.mockRestore();
145 |   });
146 | 
147 |   it('should return null if the classifier returns a malformed JSON object', async () => {
148 |     const consoleWarnSpy = vi
149 |       .spyOn(console, 'warn')
150 |       .mockImplementation(() => {});
151 |     const malformedApiResponse = {
152 |       reasoning: 'This is a simple task.',
153 |       // model_choice is missing, which will cause a Zod parsing error.
154 |     };
155 |     vi.mocked(mockBaseLlmClient.generateJson).mockResolvedValue(
156 |       malformedApiResponse,
157 |     );
158 | 
159 |     const decision = await strategy.route(
160 |       mockContext,
161 |       mockConfig,
162 |       mockBaseLlmClient,
163 |     );
164 | 
165 |     expect(decision).toBeNull();
166 |     expect(consoleWarnSpy).toHaveBeenCalled();
167 |     consoleWarnSpy.mockRestore();
168 |   });
169 | 
170 |   it('should filter out tool-related history before sending to classifier', async () => {
171 |     mockContext.history = [
172 |       { role: 'user', parts: [{ text: 'call a tool' }] },
173 |       { role: 'model', parts: [{ functionCall: { name: 'test_tool' } }] },
174 |       {
175 |         role: 'user',
176 |         parts: [
177 |           { functionResponse: { name: 'test_tool', response: { ok: true } } },
178 |         ],
179 |       },
180 |       { role: 'user', parts: [{ text: 'another user turn' }] },
181 |     ];
182 |     const mockApiResponse = {
183 |       reasoning: 'Simple.',
184 |       model_choice: 'flash',
185 |     };
186 |     vi.mocked(mockBaseLlmClient.generateJson).mockResolvedValue(
187 |       mockApiResponse,
188 |     );
189 | 
190 |     await strategy.route(mockContext, mockConfig, mockBaseLlmClient);
191 | 
192 |     const generateJsonCall = vi.mocked(mockBaseLlmClient.generateJson).mock
193 |       .calls[0][0];
194 |     const contents = generateJsonCall.contents;
195 | 
196 |     const expectedContents = [
197 |       { role: 'user', parts: [{ text: 'call a tool' }] },
198 |       { role: 'user', parts: [{ text: 'another user turn' }] },
199 |       { role: 'user', parts: [{ text: 'simple task' }] },
200 |     ];
201 | 
202 |     expect(contents).toEqual(expectedContents);
203 |   });
204 | 
205 |   it('should respect HISTORY_SEARCH_WINDOW and HISTORY_TURNS_FOR_CONTEXT', async () => {
206 |     const longHistory: Content[] = [];
207 |     for (let i = 0; i < 30; i++) {
208 |       longHistory.push({ role: 'user', parts: [{ text: `Message ${i}` }] });
209 |       // Add noise that should be filtered
210 |       if (i % 2 === 0) {
211 |         longHistory.push({
212 |           role: 'model',
213 |           parts: [{ functionCall: { name: 'noise', args: {} } }],
214 |         });
215 |       }
216 |     }
217 |     mockContext.history = longHistory;
218 |     const mockApiResponse = {
219 |       reasoning: 'Simple.',
220 |       model_choice: 'flash',
221 |     };
222 |     vi.mocked(mockBaseLlmClient.generateJson).mockResolvedValue(
223 |       mockApiResponse,
224 |     );
225 | 
226 |     await strategy.route(mockContext, mockConfig, mockBaseLlmClient);
227 | 
228 |     const generateJsonCall = vi.mocked(mockBaseLlmClient.generateJson).mock
229 |       .calls[0][0];
230 |     const contents = generateJsonCall.contents;
231 | 
232 |     // Manually calculate what the history should be
233 |     const HISTORY_SEARCH_WINDOW = 20;
234 |     const HISTORY_TURNS_FOR_CONTEXT = 4;
235 |     const historySlice = longHistory.slice(-HISTORY_SEARCH_WINDOW);
236 |     const cleanHistory = historySlice.filter(
237 |       (content) => !isFunctionCall(content) && !isFunctionResponse(content),
238 |     );
239 |     const finalHistory = cleanHistory.slice(-HISTORY_TURNS_FOR_CONTEXT);
240 | 
241 |     expect(contents).toEqual([
242 |       ...finalHistory,
243 |       { role: 'user', parts: mockContext.request },
244 |     ]);
245 |     // There should be 4 history items + the current request
246 |     expect(contents).toHaveLength(5);
247 |   });
248 | 
249 |   it('should use a fallback promptId if not found in context', async () => {
250 |     const consoleWarnSpy = vi
251 |       .spyOn(console, 'warn')
252 |       .mockImplementation(() => {});
253 |     vi.mocked(promptIdContext.getStore).mockReturnValue(undefined);
254 |     const mockApiResponse = {
255 |       reasoning: 'Simple.',
256 |       model_choice: 'flash',
257 |     };
258 |     vi.mocked(mockBaseLlmClient.generateJson).mockResolvedValue(
259 |       mockApiResponse,
260 |     );
261 | 
262 |     await strategy.route(mockContext, mockConfig, mockBaseLlmClient);
263 | 
264 |     const generateJsonCall = vi.mocked(mockBaseLlmClient.generateJson).mock
265 |       .calls[0][0];
266 | 
267 |     expect(generateJsonCall.promptId).toMatch(
268 |       /^classifier-router-fallback-\d+-\w+$/,
269 |     );
270 |     expect(consoleWarnSpy).toHaveBeenCalledWith(
271 |       expect.stringContaining(
272 |         'Could not find promptId in context. This is unexpected. Using a fallback ID:',
273 |       ),
274 |     );
275 |     consoleWarnSpy.mockRestore();
276 |   });
277 | });
```

src/routing/strategies/classifierStrategy.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { z } from 'zod';
8 | import type { BaseLlmClient } from '../../core/baseLlmClient.js';
9 | import { promptIdContext } from '../../utils/promptIdContext.js';
10 | import type {
11 |   RoutingContext,
12 |   RoutingDecision,
13 |   RoutingStrategy,
14 | } from '../routingStrategy.js';
15 | import {
16 |   DEFAULT_GEMINI_FLASH_MODEL,
17 |   DEFAULT_GEMINI_FLASH_LITE_MODEL,
18 |   DEFAULT_GEMINI_MODEL,
19 | } from '../../config/models.js';
20 | import {
21 |   type GenerateContentConfig,
22 |   createUserContent,
23 |   Type,
24 | } from '@google/genai';
25 | import type { Config } from '../../config/config.js';
26 | import {
27 |   isFunctionCall,
28 |   isFunctionResponse,
29 | } from '../../utils/messageInspectors.js';
30 | 
31 | const CLASSIFIER_GENERATION_CONFIG: GenerateContentConfig = {
32 |   temperature: 0,
33 |   maxOutputTokens: 1024,
34 |   thinkingConfig: {
35 |     thinkingBudget: 512, // This counts towards output max, so we don't want -1.
36 |   },
37 | };
38 | 
39 | // The number of recent history turns to provide to the router for context.
40 | const HISTORY_TURNS_FOR_CONTEXT = 4;
41 | const HISTORY_SEARCH_WINDOW = 20;
42 | 
43 | const FLASH_MODEL = 'flash';
44 | const PRO_MODEL = 'pro';
45 | 
46 | const CLASSIFIER_SYSTEM_PROMPT = `
47 | You are a specialized Task Routing AI. Your sole function is to analyze the user's request and classify its complexity. Choose between \`${FLASH_MODEL}\` (SIMPLE) or \`${PRO_MODEL}\` (COMPLEX).
48 | 1.  \`${FLASH_MODEL}\`: A fast, efficient model for simple, well-defined tasks.
49 | 2.  \`${PRO_MODEL}\`: A powerful, advanced model for complex, open-ended, or multi-step tasks.
50 | <complexity_rubric>
51 | A task is COMPLEX (Choose \`${PRO_MODEL}\`) if it meets ONE OR MORE of the following criteria:
52 | 1.  **High Operational Complexity (Est. 4+ Steps/Tool Calls):** Requires dependent actions, significant planning, or multiple coordinated changes.
53 | 2.  **Strategic Planning & Conceptual Design:** Asking "how" or "why." Requires advice, architecture, or high-level strategy.
54 | 3.  **High Ambiguity or Large Scope (Extensive Investigation):** Broadly defined requests requiring extensive investigation.
55 | 4.  **Deep Debugging & Root Cause Analysis:** Diagnosing unknown or complex problems from symptoms.
56 | A task is SIMPLE (Choose \`${FLASH_MODEL}\`) if it is highly specific, bounded, and has Low Operational Complexity (Est. 1-3 tool calls). Operational simplicity overrides strategic phrasing.
57 | </complexity_rubric>
58 | **Output Format:**
59 | Respond *only* in JSON format according to the following schema. Do not include any text outside the JSON structure.
60 | {
61 |   "type": "object",
62 |   "properties": {
63 |     "reasoning": {
64 |       "type": "string",
65 |       "description": "A brief, step-by-step explanation for the model choice, referencing the rubric."
66 |     },
67 |     "model_choice": {
68 |       "type": "string",
69 |       "enum": ["${FLASH_MODEL}", "${PRO_MODEL}"]
70 |     }
71 |   },
72 |   "required": ["reasoning", "model_choice"]
73 | }
74 | --- EXAMPLES ---
75 | **Example 1 (Strategic Planning):**
76 | *User Prompt:* "How should I architect the data pipeline for this new analytics service?"
77 | *Your JSON Output:*
78 | {
79 |   "reasoning": "The user is asking for high-level architectural design and strategy. This falls under 'Strategic Planning & Conceptual Design'.",
80 |   "model_choice": "${PRO_MODEL}"
81 | }
82 | **Example 2 (Simple Tool Use):**
83 | *User Prompt:* "list the files in the current directory"
84 | *Your JSON Output:*
85 | {
86 |   "reasoning": "This is a direct command requiring a single tool call (ls). It has Low Operational Complexity (1 step).",
87 |   "model_choice": "${FLASH_MODEL}"
88 | }
89 | **Example 3 (High Operational Complexity):**
90 | *User Prompt:* "I need to add a new 'email' field to the User schema in 'src/models/user.ts', migrate the database, and update the registration endpoint."
91 | *Your JSON Output:*
92 | {
93 |   "reasoning": "This request involves multiple coordinated steps across different files and systems. This meets the criteria for High Operational Complexity (4+ steps).",
94 |   "model_choice": "${PRO_MODEL}"
95 | }
96 | **Example 4 (Simple Read):**
97 | *User Prompt:* "Read the contents of 'package.json'."
98 | *Your JSON Output:*
99 | {
100 |   "reasoning": "This is a direct command requiring a single read. It has Low Operational Complexity (1 step).",
101 |   "model_choice": "${FLASH_MODEL}"
102 | }
103 | 
104 | **Example 5 (Deep Debugging):**
105 | *User Prompt:* "I'm getting an error 'Cannot read property 'map' of undefined' when I click the save button. Can you fix it?"
106 | *Your JSON Output:*
107 | {
108 |   "reasoning": "The user is reporting an error symptom without a known cause. This requires investigation and falls under 'Deep Debugging'.",
109 |   "model_choice": "${PRO_MODEL}"
110 | }
111 | **Example 6 (Simple Edit despite Phrasing):**
112 | *User Prompt:* "What is the best way to rename the variable 'data' to 'userData' in 'src/utils.js'?"
113 | *Your JSON Output:*
114 | {
115 |   "reasoning": "Although the user uses strategic language ('best way'), the underlying task is a localized edit. The operational complexity is low (1-2 steps).",
116 |   "model_choice": "${FLASH_MODEL}"
117 | }
118 | `;
119 | 
120 | const RESPONSE_SCHEMA = {
121 |   type: Type.OBJECT,
122 |   properties: {
123 |     reasoning: {
124 |       type: Type.STRING,
125 |       description:
126 |         'A brief, step-by-step explanation for the model choice, referencing the rubric.',
127 |     },
128 |     model_choice: {
129 |       type: Type.STRING,
130 |       enum: [FLASH_MODEL, PRO_MODEL],
131 |     },
132 |   },
133 |   required: ['reasoning', 'model_choice'],
134 | };
135 | 
136 | const ClassifierResponseSchema = z.object({
137 |   reasoning: z.string(),
138 |   model_choice: z.enum([FLASH_MODEL, PRO_MODEL]),
139 | });
140 | 
141 | export class ClassifierStrategy implements RoutingStrategy {
142 |   readonly name = 'classifier';
143 | 
144 |   async route(
145 |     context: RoutingContext,
146 |     _config: Config,
147 |     baseLlmClient: BaseLlmClient,
148 |   ): Promise<RoutingDecision | null> {
149 |     const startTime = Date.now();
150 |     try {
151 |       let promptId = promptIdContext.getStore();
152 |       if (!promptId) {
153 |         promptId = `classifier-router-fallback-${Date.now()}-${Math.random()
154 |           .toString(16)
155 |           .slice(2)}`;
156 |         console.warn(
157 |           `Could not find promptId in context. This is unexpected. Using a fallback ID: ${promptId}`,
158 |         );
159 |       }
160 | 
161 |       const historySlice = context.history.slice(-HISTORY_SEARCH_WINDOW);
162 | 
163 |       // Filter out tool-related turns.
164 |       // TODO - Consider using function req/res if they help accuracy.
165 |       const cleanHistory = historySlice.filter(
166 |         (content) => !isFunctionCall(content) && !isFunctionResponse(content),
167 |       );
168 | 
169 |       // Take the last N turns from the *cleaned* history.
170 |       const finalHistory = cleanHistory.slice(-HISTORY_TURNS_FOR_CONTEXT);
171 | 
172 |       const jsonResponse = await baseLlmClient.generateJson({
173 |         contents: [...finalHistory, createUserContent(context.request)],
174 |         schema: RESPONSE_SCHEMA,
175 |         model: DEFAULT_GEMINI_FLASH_LITE_MODEL,
176 |         systemInstruction: CLASSIFIER_SYSTEM_PROMPT,
177 |         config: CLASSIFIER_GENERATION_CONFIG,
178 |         abortSignal: context.signal,
179 |         promptId,
180 |       });
181 | 
182 |       const routerResponse = ClassifierResponseSchema.parse(jsonResponse);
183 | 
184 |       const reasoning = routerResponse.reasoning;
185 |       const latencyMs = Date.now() - startTime;
186 | 
187 |       if (routerResponse.model_choice === FLASH_MODEL) {
188 |         return {
189 |           model: DEFAULT_GEMINI_FLASH_MODEL,
190 |           metadata: {
191 |             source: 'Classifier',
192 |             latencyMs,
193 |             reasoning,
194 |           },
195 |         };
196 |       } else {
197 |         return {
198 |           model: DEFAULT_GEMINI_MODEL,
199 |           metadata: {
200 |             source: 'Classifier',
201 |             reasoning,
202 |             latencyMs,
203 |           },
204 |         };
205 |       }
206 |     } catch (error) {
207 |       // If the classifier fails for any reason (API error, parsing error, etc.),
208 |       // we log it and return null to allow the composite strategy to proceed.
209 |       console.warn(`[Routing] ClassifierStrategy failed:`, error);
210 |       return null;
211 |     }
212 |   }
213 | }
```

src/routing/strategies/compositeStrategy.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, beforeEach } from 'vitest';
8 | import { CompositeStrategy } from './compositeStrategy.js';
9 | import type {
10 |   RoutingContext,
11 |   RoutingDecision,
12 |   RoutingStrategy,
13 |   TerminalStrategy,
14 | } from '../routingStrategy.js';
15 | import type { Config } from '../../config/config.js';
16 | import type { BaseLlmClient } from '../../core/baseLlmClient.js';
17 | 
18 | describe('CompositeStrategy', () => {
19 |   let mockContext: RoutingContext;
20 |   let mockConfig: Config;
21 |   let mockBaseLlmClient: BaseLlmClient;
22 |   let mockStrategy1: RoutingStrategy;
23 |   let mockStrategy2: RoutingStrategy;
24 |   let mockTerminalStrategy: TerminalStrategy;
25 | 
26 |   beforeEach(() => {
27 |     vi.clearAllMocks();
28 | 
29 |     mockContext = {} as RoutingContext;
30 |     mockConfig = {} as Config;
31 |     mockBaseLlmClient = {} as BaseLlmClient;
32 | 
33 |     mockStrategy1 = {
34 |       name: 'strategy1',
35 |       route: vi.fn().mockResolvedValue(null),
36 |     };
37 | 
38 |     mockStrategy2 = {
39 |       name: 'strategy2',
40 |       route: vi.fn().mockResolvedValue(null),
41 |     };
42 | 
43 |     mockTerminalStrategy = {
44 |       name: 'terminal',
45 |       route: vi.fn().mockResolvedValue({
46 |         model: 'terminal-model',
47 |         metadata: {
48 |           source: 'terminal',
49 |           latencyMs: 10,
50 |           reasoning: 'Terminal decision',
51 |         },
52 |       }),
53 |     };
54 |   });
55 | 
56 |   it('should try strategies in order and return the first successful decision', async () => {
57 |     const decision: RoutingDecision = {
58 |       model: 'strategy2-model',
59 |       metadata: {
60 |         source: 'strategy2',
61 |         latencyMs: 20,
62 |         reasoning: 'Strategy 2 decided',
63 |       },
64 |     };
65 |     vi.spyOn(mockStrategy2, 'route').mockResolvedValue(decision);
66 | 
67 |     const composite = new CompositeStrategy(
68 |       [mockStrategy1, mockStrategy2, mockTerminalStrategy],
69 |       'test-router',
70 |     );
71 | 
72 |     const result = await composite.route(
73 |       mockContext,
74 |       mockConfig,
75 |       mockBaseLlmClient,
76 |     );
77 | 
78 |     expect(mockStrategy1.route).toHaveBeenCalledWith(
79 |       mockContext,
80 |       mockConfig,
81 |       mockBaseLlmClient,
82 |     );
83 |     expect(mockStrategy2.route).toHaveBeenCalledWith(
84 |       mockContext,
85 |       mockConfig,
86 |       mockBaseLlmClient,
87 |     );
88 |     expect(mockTerminalStrategy.route).not.toHaveBeenCalled();
89 | 
90 |     expect(result.model).toBe('strategy2-model');
91 |     expect(result.metadata.source).toBe('test-router/strategy2');
92 |   });
93 | 
94 |   it('should fall back to the terminal strategy if no other strategy provides a decision', async () => {
95 |     const composite = new CompositeStrategy(
96 |       [mockStrategy1, mockStrategy2, mockTerminalStrategy],
97 |       'test-router',
98 |     );
99 | 
100 |     const result = await composite.route(
101 |       mockContext,
102 |       mockConfig,
103 |       mockBaseLlmClient,
104 |     );
105 | 
106 |     expect(mockStrategy1.route).toHaveBeenCalledTimes(1);
107 |     expect(mockStrategy2.route).toHaveBeenCalledTimes(1);
108 |     expect(mockTerminalStrategy.route).toHaveBeenCalledTimes(1);
109 | 
110 |     expect(result.model).toBe('terminal-model');
111 |     expect(result.metadata.source).toBe('test-router/terminal');
112 |   });
113 | 
114 |   it('should handle errors in non-terminal strategies and continue', async () => {
115 |     const consoleErrorSpy = vi
116 |       .spyOn(console, 'error')
117 |       .mockImplementation(() => {});
118 |     vi.spyOn(mockStrategy1, 'route').mockRejectedValue(
119 |       new Error('Strategy 1 failed'),
120 |     );
121 | 
122 |     const composite = new CompositeStrategy(
123 |       [mockStrategy1, mockTerminalStrategy],
124 |       'test-router',
125 |     );
126 | 
127 |     const result = await composite.route(
128 |       mockContext,
129 |       mockConfig,
130 |       mockBaseLlmClient,
131 |     );
132 | 
133 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
134 |       "[Routing] Strategy 'strategy1' failed. Continuing to next strategy. Error:",
135 |       expect.any(Error),
136 |     );
137 |     expect(result.model).toBe('terminal-model');
138 |     consoleErrorSpy.mockRestore();
139 |   });
140 | 
141 |   it('should re-throw an error from the terminal strategy', async () => {
142 |     const consoleErrorSpy = vi
143 |       .spyOn(console, 'error')
144 |       .mockImplementation(() => {});
145 |     const terminalError = new Error('Terminal strategy failed');
146 |     vi.spyOn(mockTerminalStrategy, 'route').mockRejectedValue(terminalError);
147 | 
148 |     const composite = new CompositeStrategy([mockTerminalStrategy]);
149 | 
150 |     await expect(
151 |       composite.route(mockContext, mockConfig, mockBaseLlmClient),
152 |     ).rejects.toThrow(terminalError);
153 | 
154 |     expect(consoleErrorSpy).toHaveBeenCalledWith(
155 |       "[Routing] Critical Error: Terminal strategy 'terminal' failed. Routing cannot proceed. Error:",
156 |       terminalError,
157 |     );
158 |     consoleErrorSpy.mockRestore();
159 |   });
160 | 
161 |   it('should correctly finalize the decision metadata', async () => {
162 |     const decision: RoutingDecision = {
163 |       model: 'some-model',
164 |       metadata: {
165 |         source: 'child-source',
166 |         latencyMs: 50,
167 |         reasoning: 'Child reasoning',
168 |       },
169 |     };
170 |     vi.spyOn(mockStrategy1, 'route').mockResolvedValue(decision);
171 | 
172 |     const composite = new CompositeStrategy(
173 |       [mockStrategy1, mockTerminalStrategy],
174 |       'my-composite',
175 |     );
176 | 
177 |     const result = await composite.route(
178 |       mockContext,
179 |       mockConfig,
180 |       mockBaseLlmClient,
181 |     );
182 | 
183 |     expect(result.model).toBe('some-model');
184 |     expect(result.metadata.source).toBe('my-composite/child-source');
185 |     expect(result.metadata.reasoning).toBe('Child reasoning');
186 |     // It should keep the child's latency
187 |     expect(result.metadata.latencyMs).toBe(50);
188 |   });
189 | 
190 |   it('should calculate total latency if child latency is not provided', async () => {
191 |     const decision: RoutingDecision = {
192 |       model: 'some-model',
193 |       metadata: {
194 |         source: 'child-source',
195 |         // No latencyMs here
196 |         latencyMs: 0,
197 |         reasoning: 'Child reasoning',
198 |       },
199 |     };
200 |     vi.spyOn(mockStrategy1, 'route').mockResolvedValue(decision);
201 | 
202 |     const composite = new CompositeStrategy(
203 |       [mockStrategy1, mockTerminalStrategy],
204 |       'my-composite',
205 |     );
206 | 
207 |     const result = await composite.route(
208 |       mockContext,
209 |       mockConfig,
210 |       mockBaseLlmClient,
211 |     );
212 | 
213 |     expect(result.metadata.latencyMs).toBeGreaterThanOrEqual(0);
214 |   });
215 | });
```

src/routing/strategies/compositeStrategy.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Config } from '../../config/config.js';
8 | import type { BaseLlmClient } from '../../core/baseLlmClient.js';
9 | import type {
10 |   RoutingContext,
11 |   RoutingDecision,
12 |   RoutingStrategy,
13 |   TerminalStrategy,
14 | } from '../routingStrategy.js';
15 | 
16 | /**
17 |  * A strategy that attempts a list of child strategies in order (Chain of Responsibility).
18 |  */
19 | export class CompositeStrategy implements TerminalStrategy {
20 |   readonly name: string;
21 | 
22 |   private strategies: [...RoutingStrategy[], TerminalStrategy];
23 | 
24 |   /**
25 |    * Initializes the CompositeStrategy.
26 |    * @param strategies The strategies to try, in order of priority. The last strategy must be terminal.
27 |    * @param name The name of this composite configuration (e.g., 'router' or 'composite').
28 |    */
29 |   constructor(
30 |     strategies: [...RoutingStrategy[], TerminalStrategy],
31 |     name: string = 'composite',
32 |   ) {
33 |     this.strategies = strategies;
34 |     this.name = name;
35 |   }
36 | 
37 |   async route(
38 |     context: RoutingContext,
39 |     config: Config,
40 |     baseLlmClient: BaseLlmClient,
41 |   ): Promise<RoutingDecision> {
42 |     const startTime = performance.now();
43 | 
44 |     // Separate non-terminal strategies from the terminal one.
45 |     // This separation allows TypeScript to understand the control flow guarantees.
46 |     const nonTerminalStrategies = this.strategies.slice(
47 |       0,
48 |       -1,
49 |     ) as RoutingStrategy[];
50 |     const terminalStrategy = this.strategies[
51 |       this.strategies.length - 1
52 |     ] as TerminalStrategy;
53 | 
54 |     // Try non-terminal strategies, allowing them to fail gracefully.
55 |     for (const strategy of nonTerminalStrategies) {
56 |       try {
57 |         const decision = await strategy.route(context, config, baseLlmClient);
58 |         if (decision) {
59 |           return this.finalizeDecision(decision, startTime);
60 |         }
61 |       } catch (error) {
62 |         console.error(
63 |           `[Routing] Strategy '${strategy.name}' failed. Continuing to next strategy. Error:`,
64 |           error,
65 |         );
66 |       }
67 |     }
68 | 
69 |     // If no other strategy matched, execute the terminal strategy.
70 |     try {
71 |       const decision = await terminalStrategy.route(
72 |         context,
73 |         config,
74 |         baseLlmClient,
75 |       );
76 | 
77 |       return this.finalizeDecision(decision, startTime);
78 |     } catch (error) {
79 |       console.error(
80 |         `[Routing] Critical Error: Terminal strategy '${terminalStrategy.name}' failed. Routing cannot proceed. Error:`,
81 |         error,
82 |       );
83 |       throw error;
84 |     }
85 |   }
86 | 
87 |   /**
88 |    * Helper function to enhance the decision metadata with composite information.
89 |    */
90 |   private finalizeDecision(
91 |     decision: RoutingDecision,
92 |     startTime: number,
93 |   ): RoutingDecision {
94 |     const endTime = performance.now();
95 |     const compositeSource = `${this.name}/${decision.metadata.source}`;
96 | 
97 |     // Use the child's latency if it's a meaningful (non-zero) value,
98 |     // otherwise use the total time spent in the composite strategy.
99 |     const latency = decision.metadata.latencyMs || endTime - startTime;
100 | 
101 |     return {
102 |       ...decision,
103 |       metadata: {
104 |         ...decision.metadata,
105 |         source: compositeSource,
106 |         latencyMs: Math.round(latency), // Round to ensure int for telemetry.
107 |       },
108 |     };
109 |   }
110 | }
```

src/routing/strategies/defaultStrategy.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { DefaultStrategy } from './defaultStrategy.js';
9 | import type { RoutingContext } from '../routingStrategy.js';
10 | import type { BaseLlmClient } from '../../core/baseLlmClient.js';
11 | import { DEFAULT_GEMINI_MODEL } from '../../config/models.js';
12 | import type { Config } from '../../config/config.js';
13 | 
14 | describe('DefaultStrategy', () => {
15 |   it('should always route to the default Gemini model', async () => {
16 |     const strategy = new DefaultStrategy();
17 |     const mockContext = {} as RoutingContext;
18 |     const mockConfig = {} as Config;
19 |     const mockClient = {} as BaseLlmClient;
20 | 
21 |     const decision = await strategy.route(mockContext, mockConfig, mockClient);
22 | 
23 |     expect(decision).toEqual({
24 |       model: DEFAULT_GEMINI_MODEL,
25 |       metadata: {
26 |         source: 'default',
27 |         latencyMs: 0,
28 |         reasoning: `Routing to default model: ${DEFAULT_GEMINI_MODEL}`,
29 |       },
30 |     });
31 |   });
32 | });
```

src/routing/strategies/defaultStrategy.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Config } from '../../config/config.js';
8 | import type { BaseLlmClient } from '../../core/baseLlmClient.js';
9 | import type {
10 |   RoutingContext,
11 |   RoutingDecision,
12 |   TerminalStrategy,
13 | } from '../routingStrategy.js';
14 | import { DEFAULT_GEMINI_MODEL } from '../../config/models.js';
15 | 
16 | export class DefaultStrategy implements TerminalStrategy {
17 |   readonly name = 'default';
18 | 
19 |   async route(
20 |     _context: RoutingContext,
21 |     _config: Config,
22 |     _baseLlmClient: BaseLlmClient,
23 |   ): Promise<RoutingDecision> {
24 |     return {
25 |       model: DEFAULT_GEMINI_MODEL,
26 |       metadata: {
27 |         source: this.name,
28 |         latencyMs: 0,
29 |         reasoning: `Routing to default model: ${DEFAULT_GEMINI_MODEL}`,
30 |       },
31 |     };
32 |   }
33 | }
```

src/routing/strategies/fallbackStrategy.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { FallbackStrategy } from './fallbackStrategy.js';
9 | import type { RoutingContext } from '../routingStrategy.js';
10 | import type { BaseLlmClient } from '../../core/baseLlmClient.js';
11 | import type { Config } from '../../config/config.js';
12 | import {
13 |   DEFAULT_GEMINI_MODEL,
14 |   DEFAULT_GEMINI_FLASH_MODEL,
15 |   DEFAULT_GEMINI_FLASH_LITE_MODEL,
16 | } from '../../config/models.js';
17 | 
18 | describe('FallbackStrategy', () => {
19 |   const strategy = new FallbackStrategy();
20 |   const mockContext = {} as RoutingContext;
21 |   const mockClient = {} as BaseLlmClient;
22 | 
23 |   it('should return null when not in fallback mode', async () => {
24 |     const mockConfig = {
25 |       isInFallbackMode: () => false,
26 |       getModel: () => DEFAULT_GEMINI_MODEL,
27 |     } as Config;
28 | 
29 |     const decision = await strategy.route(mockContext, mockConfig, mockClient);
30 |     expect(decision).toBeNull();
31 |   });
32 | 
33 |   describe('when in fallback mode', () => {
34 |     it('should downgrade a pro model to the flash model', async () => {
35 |       const mockConfig = {
36 |         isInFallbackMode: () => true,
37 |         getModel: () => DEFAULT_GEMINI_MODEL,
38 |       } as Config;
39 | 
40 |       const decision = await strategy.route(
41 |         mockContext,
42 |         mockConfig,
43 |         mockClient,
44 |       );
45 | 
46 |       expect(decision).not.toBeNull();
47 |       expect(decision?.model).toBe(DEFAULT_GEMINI_FLASH_MODEL);
48 |       expect(decision?.metadata.source).toBe('fallback');
49 |       expect(decision?.metadata.reasoning).toContain('In fallback mode');
50 |     });
51 | 
52 |     it('should honor a lite model request', async () => {
53 |       const mockConfig = {
54 |         isInFallbackMode: () => true,
55 |         getModel: () => DEFAULT_GEMINI_FLASH_LITE_MODEL,
56 |       } as Config;
57 | 
58 |       const decision = await strategy.route(
59 |         mockContext,
60 |         mockConfig,
61 |         mockClient,
62 |       );
63 | 
64 |       expect(decision).not.toBeNull();
65 |       expect(decision?.model).toBe(DEFAULT_GEMINI_FLASH_LITE_MODEL);
66 |       expect(decision?.metadata.source).toBe('fallback');
67 |     });
68 | 
69 |     it('should use the flash model if flash is requested', async () => {
70 |       const mockConfig = {
71 |         isInFallbackMode: () => true,
72 |         getModel: () => DEFAULT_GEMINI_FLASH_MODEL,
73 |       } as Config;
74 | 
75 |       const decision = await strategy.route(
76 |         mockContext,
77 |         mockConfig,
78 |         mockClient,
79 |       );
80 | 
81 |       expect(decision).not.toBeNull();
82 |       expect(decision?.model).toBe(DEFAULT_GEMINI_FLASH_MODEL);
83 |       expect(decision?.metadata.source).toBe('fallback');
84 |     });
85 |   });
86 | });
```

src/routing/strategies/fallbackStrategy.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Config } from '../../config/config.js';
8 | import { getEffectiveModel } from '../../config/models.js';
9 | import type { BaseLlmClient } from '../../core/baseLlmClient.js';
10 | import type {
11 |   RoutingContext,
12 |   RoutingDecision,
13 |   RoutingStrategy,
14 | } from '../routingStrategy.js';
15 | 
16 | export class FallbackStrategy implements RoutingStrategy {
17 |   readonly name = 'fallback';
18 | 
19 |   async route(
20 |     _context: RoutingContext,
21 |     config: Config,
22 |     _baseLlmClient: BaseLlmClient,
23 |   ): Promise<RoutingDecision | null> {
24 |     const isInFallbackMode: boolean = config.isInFallbackMode();
25 | 
26 |     if (!isInFallbackMode) {
27 |       return null;
28 |     }
29 | 
30 |     const effectiveModel = getEffectiveModel(
31 |       isInFallbackMode,
32 |       config.getModel(),
33 |     );
34 |     return {
35 |       model: effectiveModel,
36 |       metadata: {
37 |         source: this.name,
38 |         latencyMs: 0,
39 |         reasoning: `In fallback mode. Using: ${effectiveModel}`,
40 |       },
41 |     };
42 |   }
43 | }
```

src/routing/strategies/overrideStrategy.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect } from 'vitest';
8 | import { OverrideStrategy } from './overrideStrategy.js';
9 | import type { RoutingContext } from '../routingStrategy.js';
10 | import type { BaseLlmClient } from '../../core/baseLlmClient.js';
11 | import type { Config } from '../../config/config.js';
12 | import { DEFAULT_GEMINI_MODEL_AUTO } from '../../config/models.js';
13 | 
14 | describe('OverrideStrategy', () => {
15 |   const strategy = new OverrideStrategy();
16 |   const mockContext = {} as RoutingContext;
17 |   const mockClient = {} as BaseLlmClient;
18 | 
19 |   it('should return null when the override model is auto', async () => {
20 |     const mockConfig = {
21 |       getModel: () => DEFAULT_GEMINI_MODEL_AUTO,
22 |     } as Config;
23 | 
24 |     const decision = await strategy.route(mockContext, mockConfig, mockClient);
25 |     expect(decision).toBeNull();
26 |   });
27 | 
28 |   it('should return a decision with the override model when one is specified', async () => {
29 |     const overrideModel = 'gemini-2.5-pro-custom';
30 |     const mockConfig = {
31 |       getModel: () => overrideModel,
32 |     } as Config;
33 | 
34 |     const decision = await strategy.route(mockContext, mockConfig, mockClient);
35 | 
36 |     expect(decision).not.toBeNull();
37 |     expect(decision?.model).toBe(overrideModel);
38 |     expect(decision?.metadata.source).toBe('override');
39 |     expect(decision?.metadata.reasoning).toContain(
40 |       'Routing bypassed by forced model directive',
41 |     );
42 |     expect(decision?.metadata.reasoning).toContain(overrideModel);
43 |   });
44 | 
45 |   it('should handle different override model names', async () => {
46 |     const overrideModel = 'gemini-2.5-flash-experimental';
47 |     const mockConfig = {
48 |       getModel: () => overrideModel,
49 |     } as Config;
50 | 
51 |     const decision = await strategy.route(mockContext, mockConfig, mockClient);
52 | 
53 |     expect(decision).not.toBeNull();
54 |     expect(decision?.model).toBe(overrideModel);
55 |   });
56 | });
```

src/routing/strategies/overrideStrategy.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import type { Config } from '../../config/config.js';
8 | import { DEFAULT_GEMINI_MODEL_AUTO } from '../../config/models.js';
9 | import type { BaseLlmClient } from '../../core/baseLlmClient.js';
10 | import type {
11 |   RoutingContext,
12 |   RoutingDecision,
13 |   RoutingStrategy,
14 | } from '../routingStrategy.js';
15 | 
16 | /**
17 |  * Handles cases where the user explicitly specifies a model (override).
18 |  */
19 | export class OverrideStrategy implements RoutingStrategy {
20 |   readonly name = 'override';
21 | 
22 |   async route(
23 |     _context: RoutingContext,
24 |     config: Config,
25 |     _baseLlmClient: BaseLlmClient,
26 |   ): Promise<RoutingDecision | null> {
27 |     const overrideModel = config.getModel();
28 | 
29 |     // If the model is 'auto' we should pass to the next strategy.
30 |     if (overrideModel === DEFAULT_GEMINI_MODEL_AUTO) return null;
31 | 
32 |     // Return the overridden model name.
33 |     return {
34 |       model: overrideModel,
35 |       metadata: {
36 |         source: this.name,
37 |         latencyMs: 0,
38 |         reasoning: `Routing bypassed by forced model directive. Using: ${overrideModel}`,
39 |       },
40 |     };
41 |   }
42 | }
```

src/telemetry/clearcut-logger/clearcut-logger.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import 'vitest';
8 | import {
9 |   vi,
10 |   describe,
11 |   it,
12 |   expect,
13 |   afterEach,
14 |   beforeAll,
15 |   afterAll,
16 | } from 'vitest';
17 | import type { LogEvent, LogEventEntry } from './clearcut-logger.js';
18 | import { ClearcutLogger, EventNames, TEST_ONLY } from './clearcut-logger.js';
19 | import type { ContentGeneratorConfig } from '../../core/contentGenerator.js';
20 | import { AuthType } from '../../core/contentGenerator.js';
21 | import type { SuccessfulToolCall } from '../../core/coreToolScheduler.js';
22 | import type { ConfigParameters } from '../../config/config.js';
23 | import { EventMetadataKey } from './event-metadata-key.js';
24 | import { makeFakeConfig } from '../../test-utils/config.js';
25 | import { http, HttpResponse } from 'msw';
26 | import { server } from '../../mocks/msw.js';
27 | import {
28 |   UserPromptEvent,
29 |   makeChatCompressionEvent,
30 |   ModelRoutingEvent,
31 |   ToolCallEvent,
32 |   AgentStartEvent,
33 |   AgentFinishEvent,
34 |   WebFetchFallbackAttemptEvent,
35 | } from '../types.js';
36 | import { AgentTerminateMode } from '../../agents/types.js';
37 | import { GIT_COMMIT_INFO, CLI_VERSION } from '../../generated/git-commit.js';
38 | import { UserAccountManager } from '../../utils/userAccountManager.js';
39 | import { InstallationManager } from '../../utils/installationManager.js';
40 | import { safeJsonStringify } from '../../utils/safeJsonStringify.js';
41 | 
42 | interface CustomMatchers<R = unknown> {
43 |   toHaveMetadataValue: ([key, value]: [EventMetadataKey, string]) => R;
44 |   toHaveEventName: (name: EventNames) => R;
45 |   toHaveMetadataKey: (key: EventMetadataKey) => R;
46 | }
47 | 
48 | declare module 'vitest' {
49 |   // eslint-disable-next-line @typescript-eslint/no-explicit-any, @typescript-eslint/no-empty-object-type
50 |   interface Matchers<T = any> extends CustomMatchers<T> {}
51 | }
52 | 
53 | expect.extend({
54 |   toHaveEventName(received: LogEventEntry[], name: EventNames) {
55 |     const { isNot } = this;
56 |     const event = JSON.parse(received[0].source_extension_json) as LogEvent;
57 |     const pass = event.event_name === (name as unknown as string);
58 |     return {
59 |       pass,
60 |       message: () =>
61 |         `event name ${event.event_name} does${isNot ? ' not ' : ''} match ${name}}`,
62 |     };
63 |   },
64 | 
65 |   toHaveMetadataValue(
66 |     received: LogEventEntry[],
67 |     [key, value]: [EventMetadataKey, string],
68 |   ) {
69 |     const { isNot } = this;
70 |     const event = JSON.parse(received[0].source_extension_json) as LogEvent;
71 |     const metadata = event['event_metadata'][0];
72 |     const data = metadata.find((m) => m.gemini_cli_key === key)?.value;
73 | 
74 |     const pass = data !== undefined && data === value;
75 | 
76 |     return {
77 |       pass,
78 |       message: () =>
79 |         `event ${received} does${isNot ? ' not' : ''} have ${value}}`,
80 |     };
81 |   },
82 | 
83 |   toHaveMetadataKey(received: LogEventEntry[], key: EventMetadataKey) {
84 |     const { isNot } = this;
85 |     const event = JSON.parse(received[0].source_extension_json) as LogEvent;
86 |     const metadata = event['event_metadata'][0];
87 | 
88 |     const pass = metadata.some((m) => m.gemini_cli_key === key);
89 | 
90 |     return {
91 |       pass,
92 |       message: () =>
93 |         `event ${received} ${isNot ? 'has' : 'does not have'} the metadata key ${key}`,
94 |     };
95 |   },
96 | });
97 | 
98 | vi.mock('../../utils/userAccountManager.js');
99 | vi.mock('../../utils/installationManager.js');
100 | 
101 | const mockUserAccount = vi.mocked(UserAccountManager.prototype);
102 | const mockInstallMgr = vi.mocked(InstallationManager.prototype);
103 | 
104 | // TODO(richieforeman): Consider moving this to test setup globally.
105 | beforeAll(() => {
106 |   server.listen({});
107 | });
108 | 
109 | afterEach(() => {
110 |   server.resetHandlers();
111 | });
112 | 
113 | afterAll(() => {
114 |   server.close();
115 | });
116 | 
117 | describe('ClearcutLogger', () => {
118 |   const NEXT_WAIT_MS = 1234;
119 |   const CLEARCUT_URL = 'https://play.googleapis.com/log';
120 |   const MOCK_DATE = new Date('2025-01-02T00:00:00.000Z');
121 |   const EXAMPLE_RESPONSE = `["${NEXT_WAIT_MS}",null,[[["ANDROID_BACKUP",0],["BATTERY_STATS",0],["SMART_SETUP",0],["TRON",0]],-3334737594024971225],[]]`;
122 | 
123 |   // A helper to get the internal events array for testing
124 |   const getEvents = (l: ClearcutLogger): LogEventEntry[][] =>
125 |     l['events'].toArray() as LogEventEntry[][];
126 | 
127 |   const getEventsSize = (l: ClearcutLogger): number => l['events'].size;
128 | 
129 |   const requeueFailedEvents = (l: ClearcutLogger, events: LogEventEntry[][]) =>
130 |     l['requeueFailedEvents'](events);
131 | 
132 |   afterEach(() => {
133 |     vi.unstubAllEnvs();
134 |   });
135 | 
136 |   function setup({
137 |     config = {} as Partial<ConfigParameters>,
138 |     lifetimeGoogleAccounts = 1,
139 |     cachedGoogleAccount = 'test@google.com',
140 |   } = {}) {
141 |     server.resetHandlers(
142 |       http.post(CLEARCUT_URL, () => HttpResponse.text(EXAMPLE_RESPONSE)),
143 |     );
144 | 
145 |     vi.useFakeTimers();
146 |     vi.setSystemTime(MOCK_DATE);
147 | 
148 |     const loggerConfig = makeFakeConfig({
149 |       ...config,
150 |     });
151 |     ClearcutLogger.clearInstance();
152 | 
153 |     mockUserAccount.getCachedGoogleAccount.mockReturnValue(cachedGoogleAccount);
154 |     mockUserAccount.getLifetimeGoogleAccounts.mockReturnValue(
155 |       lifetimeGoogleAccounts,
156 |     );
157 |     mockInstallMgr.getInstallationId = vi
158 |       .fn()
159 |       .mockReturnValue('test-installation-id');
160 | 
161 |     const logger = ClearcutLogger.getInstance(loggerConfig);
162 | 
163 |     return { logger, loggerConfig };
164 |   }
165 | 
166 |   afterEach(() => {
167 |     ClearcutLogger.clearInstance();
168 |     vi.useRealTimers();
169 |     vi.restoreAllMocks();
170 |   });
171 | 
172 |   describe('getInstance', () => {
173 |     it.each([
174 |       { usageStatisticsEnabled: false, expectedValue: undefined },
175 |       {
176 |         usageStatisticsEnabled: true,
177 |         expectedValue: expect.any(ClearcutLogger),
178 |       },
179 |     ])(
180 |       'returns an instance if usage statistics are enabled',
181 |       ({ usageStatisticsEnabled, expectedValue }) => {
182 |         ClearcutLogger.clearInstance();
183 |         const { logger } = setup({
184 |           config: {
185 |             usageStatisticsEnabled,
186 |           },
187 |         });
188 |         expect(logger).toEqual(expectedValue);
189 |       },
190 |     );
191 | 
192 |     it('is a singleton', () => {
193 |       ClearcutLogger.clearInstance();
194 |       const { loggerConfig } = setup();
195 |       const logger1 = ClearcutLogger.getInstance(loggerConfig);
196 |       const logger2 = ClearcutLogger.getInstance(loggerConfig);
197 |       expect(logger1).toBe(logger2);
198 |     });
199 |   });
200 | 
201 |   describe('createLogEvent', () => {
202 |     it('logs the total number of google accounts', () => {
203 |       const { logger } = setup({
204 |         lifetimeGoogleAccounts: 9001,
205 |       });
206 | 
207 |       const event = logger?.createLogEvent(EventNames.API_ERROR, []);
208 | 
209 |       expect(event?.event_metadata[0]).toContainEqual({
210 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_GOOGLE_ACCOUNTS_COUNT,
211 |         value: '9001',
212 |       });
213 |     });
214 | 
215 |     it('logs the current surface from a github action', () => {
216 |       const { logger } = setup({});
217 | 
218 |       vi.stubEnv('GITHUB_SHA', '8675309');
219 | 
220 |       const event = logger?.createLogEvent(EventNames.CHAT_COMPRESSION, []);
221 | 
222 |       expect(event?.event_metadata[0]).toContainEqual({
223 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_SURFACE,
224 |         value: 'GitHub',
225 |       });
226 |     });
227 | 
228 |     it('logs the current surface from Cloud Shell via EDITOR_IN_CLOUD_SHELL', () => {
229 |       const { logger } = setup({});
230 | 
231 |       vi.stubEnv('EDITOR_IN_CLOUD_SHELL', 'true');
232 | 
233 |       const event = logger?.createLogEvent(EventNames.CHAT_COMPRESSION, []);
234 | 
235 |       expect(event?.event_metadata[0]).toContainEqual({
236 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_SURFACE,
237 |         value: 'cloudshell',
238 |       });
239 |     });
240 | 
241 |     it('logs the current surface from Cloud Shell via CLOUD_SHELL', () => {
242 |       const { logger } = setup({});
243 | 
244 |       vi.stubEnv('CLOUD_SHELL', 'true');
245 | 
246 |       const event = logger?.createLogEvent(EventNames.CHAT_COMPRESSION, []);
247 | 
248 |       expect(event?.event_metadata[0]).toContainEqual({
249 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_SURFACE,
250 |         value: 'cloudshell',
251 |       });
252 |     });
253 | 
254 |     it('logs default metadata', () => {
255 |       // Define expected values
256 |       const session_id = 'my-session-id';
257 |       const auth_type = AuthType.USE_GEMINI;
258 |       const google_accounts = 123;
259 |       const surface = 'ide-1234';
260 |       const cli_version = CLI_VERSION;
261 |       const git_commit_hash = GIT_COMMIT_INFO;
262 |       const prompt_id = 'my-prompt-123';
263 |       const user_settings = safeJsonStringify([
264 |         { smart_edit_enabled: true, model_router_enabled: false },
265 |       ]);
266 | 
267 |       // Setup logger with expected values
268 |       const { logger, loggerConfig } = setup({
269 |         lifetimeGoogleAccounts: google_accounts,
270 |         config: { sessionId: session_id },
271 |       });
272 |       vi.spyOn(loggerConfig, 'getContentGeneratorConfig').mockReturnValue({
273 |         authType: auth_type,
274 |       } as ContentGeneratorConfig);
275 |       logger?.logNewPromptEvent(new UserPromptEvent(1, prompt_id)); // prompt_id == session_id before this
276 |       vi.stubEnv('SURFACE', surface);
277 | 
278 |       // Create log event
279 |       const event = logger?.createLogEvent(EventNames.API_ERROR, []);
280 | 
281 |       // Ensure expected values exist
282 |       expect(event?.event_metadata[0]).toEqual(
283 |         expect.arrayContaining([
284 |           {
285 |             gemini_cli_key: EventMetadataKey.GEMINI_CLI_SESSION_ID,
286 |             value: session_id,
287 |           },
288 |           {
289 |             gemini_cli_key: EventMetadataKey.GEMINI_CLI_AUTH_TYPE,
290 |             value: JSON.stringify(auth_type),
291 |           },
292 |           {
293 |             gemini_cli_key: EventMetadataKey.GEMINI_CLI_GOOGLE_ACCOUNTS_COUNT,
294 |             value: `${google_accounts}`,
295 |           },
296 |           {
297 |             gemini_cli_key: EventMetadataKey.GEMINI_CLI_SURFACE,
298 |             value: surface,
299 |           },
300 |           {
301 |             gemini_cli_key: EventMetadataKey.GEMINI_CLI_VERSION,
302 |             value: cli_version,
303 |           },
304 |           {
305 |             gemini_cli_key: EventMetadataKey.GEMINI_CLI_GIT_COMMIT_HASH,
306 |             value: git_commit_hash,
307 |           },
308 |           {
309 |             gemini_cli_key: EventMetadataKey.GEMINI_CLI_PROMPT_ID,
310 |             value: prompt_id,
311 |           },
312 |           {
313 |             gemini_cli_key: EventMetadataKey.GEMINI_CLI_OS,
314 |             value: process.platform,
315 |           },
316 |           {
317 |             gemini_cli_key: EventMetadataKey.GEMINI_CLI_USER_SETTINGS,
318 |             value: user_settings,
319 |           },
320 |         ]),
321 |       );
322 |     });
323 | 
324 |     it('logs the current nodejs version', () => {
325 |       const { logger } = setup({});
326 | 
327 |       const event = logger?.createLogEvent(EventNames.API_ERROR, []);
328 | 
329 |       expect(event?.event_metadata[0]).toContainEqual({
330 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_NODE_VERSION,
331 |         value: process.versions.node,
332 |       });
333 |     });
334 | 
335 |     it('logs the current surface', () => {
336 |       const { logger } = setup({});
337 | 
338 |       vi.stubEnv('TERM_PROGRAM', 'vscode');
339 |       vi.stubEnv('SURFACE', 'ide-1234');
340 | 
341 |       const event = logger?.createLogEvent(EventNames.API_ERROR, []);
342 | 
343 |       expect(event?.event_metadata[0]).toContainEqual({
344 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_SURFACE,
345 |         value: 'ide-1234',
346 |       });
347 |     });
348 | 
349 |     it('logs the value of config.useSmartEdit and config.useModelRouter', () => {
350 |       const user_settings = safeJsonStringify([
351 |         { smart_edit_enabled: true, model_router_enabled: true },
352 |       ]);
353 | 
354 |       const { logger } = setup({
355 |         config: { useSmartEdit: true, useModelRouter: true },
356 |       });
357 | 
358 |       vi.stubEnv('TERM_PROGRAM', 'vscode');
359 |       vi.stubEnv('SURFACE', 'ide-1234');
360 | 
361 |       const event = logger?.createLogEvent(EventNames.TOOL_CALL, []);
362 | 
363 |       expect(event?.event_metadata[0]).toContainEqual({
364 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_USER_SETTINGS,
365 |         value: user_settings,
366 |       });
367 |     });
368 | 
369 |     it.each([
370 |       {
371 |         env: {
372 |           CURSOR_TRACE_ID: 'abc123',
373 |           GITHUB_SHA: undefined,
374 |           TERM_PROGRAM: 'vscode',
375 |         },
376 |         expectedValue: 'cursor',
377 |       },
378 |       {
379 |         env: {
380 |           TERM_PROGRAM: 'vscode',
381 |           GITHUB_SHA: undefined,
382 |           MONOSPACE_ENV: '',
383 |         },
384 |         expectedValue: 'vscode',
385 |       },
386 |       {
387 |         env: {
388 |           MONOSPACE_ENV: 'true',
389 |           GITHUB_SHA: undefined,
390 |           TERM_PROGRAM: 'vscode',
391 |         },
392 |         expectedValue: 'firebasestudio',
393 |       },
394 |       {
395 |         env: {
396 |           __COG_BASHRC_SOURCED: 'true',
397 |           GITHUB_SHA: undefined,
398 |           TERM_PROGRAM: 'vscode',
399 |         },
400 |         expectedValue: 'devin',
401 |       },
402 |       {
403 |         env: {
404 |           CLOUD_SHELL: 'true',
405 |           GITHUB_SHA: undefined,
406 |           TERM_PROGRAM: 'vscode',
407 |         },
408 |         expectedValue: 'cloudshell',
409 |       },
410 |     ])(
411 |       'logs the current surface as $expectedValue, preempting vscode detection',
412 |       ({ env, expectedValue }) => {
413 |         const { logger } = setup({});
414 |         for (const [key, value] of Object.entries(env)) {
415 |           vi.stubEnv(key, value);
416 |         }
417 |         // Clear Cursor-specific environment variables that might interfere with tests
418 |         // Only clear if not explicitly testing Cursor detection
419 |         if (!env.CURSOR_TRACE_ID) {
420 |           vi.stubEnv('CURSOR_TRACE_ID', '');
421 |         }
422 |         const event = logger?.createLogEvent(EventNames.API_ERROR, []);
423 |         expect(event?.event_metadata[0][3]).toEqual({
424 |           gemini_cli_key: EventMetadataKey.GEMINI_CLI_SURFACE,
425 |           value: expectedValue,
426 |         });
427 |       },
428 |     );
429 |   });
430 | 
431 |   describe('logChatCompressionEvent', () => {
432 |     it('logs an event with proper fields', () => {
433 |       const { logger } = setup();
434 |       logger?.logChatCompressionEvent(
435 |         makeChatCompressionEvent({
436 |           tokens_before: 9001,
437 |           tokens_after: 8000,
438 |         }),
439 |       );
440 | 
441 |       const events = getEvents(logger!);
442 |       expect(events.length).toBe(1);
443 |       expect(events[0]).toHaveEventName(EventNames.CHAT_COMPRESSION);
444 |       expect(events[0]).toHaveMetadataValue([
445 |         EventMetadataKey.GEMINI_CLI_COMPRESSION_TOKENS_BEFORE,
446 |         '9001',
447 |       ]);
448 |       expect(events[0]).toHaveMetadataValue([
449 |         EventMetadataKey.GEMINI_CLI_COMPRESSION_TOKENS_AFTER,
450 |         '8000',
451 |       ]);
452 |     });
453 |   });
454 | 
455 |   describe('logRipgrepFallbackEvent', () => {
456 |     it('logs an event with the proper name', () => {
457 |       const { logger } = setup();
458 |       // Spy on flushToClearcut to prevent it from clearing the queue
459 |       const flushSpy = vi
460 |         // eslint-disable-next-line @typescript-eslint/no-explicit-any
461 |         .spyOn(logger!, 'flushToClearcut' as any)
462 |         .mockResolvedValue({ nextRequestWaitMs: 0 });
463 | 
464 |       logger?.logRipgrepFallbackEvent();
465 | 
466 |       const events = getEvents(logger!);
467 |       expect(events.length).toBe(1);
468 |       expect(events[0]).toHaveEventName(EventNames.RIPGREP_FALLBACK);
469 |       expect(flushSpy).toHaveBeenCalledOnce();
470 |     });
471 |   });
472 | 
473 |   describe('enqueueLogEvent', () => {
474 |     it('should add events to the queue', () => {
475 |       const { logger } = setup();
476 |       logger!.enqueueLogEvent(logger!.createLogEvent(EventNames.API_ERROR));
477 |       expect(getEventsSize(logger!)).toBe(1);
478 |     });
479 | 
480 |     it('should evict the oldest event when the queue is full', () => {
481 |       const { logger } = setup();
482 | 
483 |       for (let i = 0; i < TEST_ONLY.MAX_EVENTS; i++) {
484 |         logger!.enqueueLogEvent(
485 |           logger!.createLogEvent(EventNames.API_ERROR, [
486 |             {
487 |               gemini_cli_key: EventMetadataKey.GEMINI_CLI_AI_ADDED_LINES,
488 |               value: `${i}`,
489 |             },
490 |           ]),
491 |         );
492 |       }
493 | 
494 |       let events = getEvents(logger!);
495 |       expect(events.length).toBe(TEST_ONLY.MAX_EVENTS);
496 |       expect(events[0]).toHaveMetadataValue([
497 |         EventMetadataKey.GEMINI_CLI_AI_ADDED_LINES,
498 |         '0',
499 |       ]);
500 | 
501 |       // This should push out the first event
502 |       logger!.enqueueLogEvent(
503 |         logger!.createLogEvent(EventNames.API_ERROR, [
504 |           {
505 |             gemini_cli_key: EventMetadataKey.GEMINI_CLI_AI_ADDED_LINES,
506 |             value: `${TEST_ONLY.MAX_EVENTS}`,
507 |           },
508 |         ]),
509 |       );
510 |       events = getEvents(logger!);
511 |       expect(events.length).toBe(TEST_ONLY.MAX_EVENTS);
512 |       expect(events[0]).toHaveMetadataValue([
513 |         EventMetadataKey.GEMINI_CLI_AI_ADDED_LINES,
514 |         '1',
515 |       ]);
516 | 
517 |       expect(events.at(TEST_ONLY.MAX_EVENTS - 1)).toHaveMetadataValue([
518 |         EventMetadataKey.GEMINI_CLI_AI_ADDED_LINES,
519 |         `${TEST_ONLY.MAX_EVENTS}`,
520 |       ]);
521 |     });
522 |   });
523 | 
524 |   describe('flushToClearcut', () => {
525 |     it('allows for usage with a configured proxy agent', async () => {
526 |       const { logger } = setup({
527 |         config: {
528 |           proxy: 'http://mycoolproxy.whatever.com:3128',
529 |         },
530 |       });
531 | 
532 |       logger!.enqueueLogEvent(logger!.createLogEvent(EventNames.API_ERROR));
533 | 
534 |       const response = await logger!.flushToClearcut();
535 | 
536 |       expect(response.nextRequestWaitMs).toBe(NEXT_WAIT_MS);
537 |     });
538 | 
539 |     it('should clear events on successful flush', async () => {
540 |       const { logger } = setup();
541 | 
542 |       logger!.enqueueLogEvent(logger!.createLogEvent(EventNames.API_ERROR));
543 |       const response = await logger!.flushToClearcut();
544 | 
545 |       expect(getEvents(logger!)).toEqual([]);
546 |       expect(response.nextRequestWaitMs).toBe(NEXT_WAIT_MS);
547 |     });
548 | 
549 |     it('should handle a network error and requeue events', async () => {
550 |       const { logger } = setup();
551 | 
552 |       server.resetHandlers(http.post(CLEARCUT_URL, () => HttpResponse.error()));
553 |       logger!.enqueueLogEvent(logger!.createLogEvent(EventNames.API_REQUEST));
554 |       logger!.enqueueLogEvent(logger!.createLogEvent(EventNames.API_ERROR));
555 |       expect(getEventsSize(logger!)).toBe(2);
556 | 
557 |       const x = logger!.flushToClearcut();
558 |       await x;
559 | 
560 |       expect(getEventsSize(logger!)).toBe(2);
561 |       const events = getEvents(logger!);
562 | 
563 |       expect(events.length).toBe(2);
564 |       expect(events[0]).toHaveEventName(EventNames.API_REQUEST);
565 |     });
566 | 
567 |     it('should handle an HTTP error and requeue events', async () => {
568 |       const { logger } = setup();
569 | 
570 |       server.resetHandlers(
571 |         http.post(
572 |           CLEARCUT_URL,
573 |           () =>
574 |             new HttpResponse(
575 |               { 'the system is down': true },
576 |               {
577 |                 status: 500,
578 |               },
579 |             ),
580 |         ),
581 |       );
582 | 
583 |       logger!.enqueueLogEvent(logger!.createLogEvent(EventNames.API_REQUEST));
584 |       logger!.enqueueLogEvent(logger!.createLogEvent(EventNames.API_ERROR));
585 | 
586 |       expect(getEvents(logger!).length).toBe(2);
587 |       await logger!.flushToClearcut();
588 | 
589 |       const events = getEvents(logger!);
590 | 
591 |       expect(events[0]).toHaveEventName(EventNames.API_REQUEST);
592 |     });
593 |   });
594 | 
595 |   describe('requeueFailedEvents logic', () => {
596 |     it('should limit the number of requeued events to max_retry_events', () => {
597 |       const { logger } = setup();
598 |       const eventsToLogCount = TEST_ONLY.MAX_RETRY_EVENTS + 5;
599 |       const eventsToSend: LogEventEntry[][] = [];
600 |       for (let i = 0; i < eventsToLogCount; i++) {
601 |         eventsToSend.push([
602 |           {
603 |             event_time_ms: Date.now(),
604 |             source_extension_json: JSON.stringify({ event_id: i }),
605 |           },
606 |         ]);
607 |       }
608 | 
609 |       requeueFailedEvents(logger!, eventsToSend);
610 | 
611 |       expect(getEventsSize(logger!)).toBe(TEST_ONLY.MAX_RETRY_EVENTS);
612 |       const firstRequeuedEvent = JSON.parse(
613 |         getEvents(logger!)[0][0].source_extension_json,
614 |       ) as { event_id: string };
615 |       // The last `maxRetryEvents` are kept. The oldest of those is at index `eventsToLogCount - maxRetryEvents`.
616 |       expect(firstRequeuedEvent.event_id).toBe(
617 |         eventsToLogCount - TEST_ONLY.MAX_RETRY_EVENTS,
618 |       );
619 |     });
[TRUNCATED]
```

src/telemetry/clearcut-logger/clearcut-logger.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { HttpsProxyAgent } from 'https-proxy-agent';
8 | import type {
9 |   StartSessionEvent,
10 |   UserPromptEvent,
11 |   ToolCallEvent,
12 |   ApiRequestEvent,
13 |   ApiResponseEvent,
14 |   ApiErrorEvent,
15 |   LoopDetectedEvent,
16 |   NextSpeakerCheckEvent,
17 |   SlashCommandEvent,
18 |   MalformedJsonResponseEvent,
19 |   IdeConnectionEvent,
20 |   ConversationFinishedEvent,
21 |   KittySequenceOverflowEvent,
22 |   ChatCompressionEvent,
23 |   FileOperationEvent,
24 |   InvalidChunkEvent,
25 |   ContentRetryEvent,
26 |   ContentRetryFailureEvent,
27 |   ExtensionInstallEvent,
28 |   ToolOutputTruncatedEvent,
29 |   ExtensionUninstallEvent,
30 |   ModelRoutingEvent,
31 |   ExtensionEnableEvent,
32 |   ModelSlashCommandEvent,
33 |   ExtensionDisableEvent,
34 |   SmartEditStrategyEvent,
35 |   SmartEditCorrectionEvent,
36 |   AgentStartEvent,
37 |   AgentFinishEvent,
38 |   WebFetchFallbackAttemptEvent,
39 |   ExtensionUpdateEvent,
40 | } from '../types.js';
41 | import { EventMetadataKey } from './event-metadata-key.js';
42 | import type { Config } from '../../config/config.js';
43 | import { InstallationManager } from '../../utils/installationManager.js';
44 | import { UserAccountManager } from '../../utils/userAccountManager.js';
45 | import { safeJsonStringify } from '../../utils/safeJsonStringify.js';
46 | import { FixedDeque } from 'mnemonist';
47 | import { GIT_COMMIT_INFO, CLI_VERSION } from '../../generated/git-commit.js';
48 | import {
49 |   IDE_DEFINITIONS,
50 |   detectIdeFromEnv,
51 |   isCloudShell,
52 | } from '../../ide/detect-ide.js';
53 | 
54 | export enum EventNames {
55 |   START_SESSION = 'start_session',
56 |   NEW_PROMPT = 'new_prompt',
57 |   TOOL_CALL = 'tool_call',
58 |   FILE_OPERATION = 'file_operation',
59 |   API_REQUEST = 'api_request',
60 |   API_RESPONSE = 'api_response',
61 |   API_ERROR = 'api_error',
62 |   END_SESSION = 'end_session',
63 |   FLASH_FALLBACK = 'flash_fallback',
64 |   RIPGREP_FALLBACK = 'ripgrep_fallback',
65 |   LOOP_DETECTED = 'loop_detected',
66 |   LOOP_DETECTION_DISABLED = 'loop_detection_disabled',
67 |   NEXT_SPEAKER_CHECK = 'next_speaker_check',
68 |   SLASH_COMMAND = 'slash_command',
69 |   MALFORMED_JSON_RESPONSE = 'malformed_json_response',
70 |   IDE_CONNECTION = 'ide_connection',
71 |   KITTY_SEQUENCE_OVERFLOW = 'kitty_sequence_overflow',
72 |   CHAT_COMPRESSION = 'chat_compression',
73 |   CONVERSATION_FINISHED = 'conversation_finished',
74 |   INVALID_CHUNK = 'invalid_chunk',
75 |   CONTENT_RETRY = 'content_retry',
76 |   CONTENT_RETRY_FAILURE = 'content_retry_failure',
77 |   EXTENSION_ENABLE = 'extension_enable',
78 |   EXTENSION_DISABLE = 'extension_disable',
79 |   EXTENSION_INSTALL = 'extension_install',
80 |   EXTENSION_UNINSTALL = 'extension_uninstall',
81 |   EXTENSION_UPDATE = 'extension_update',
82 |   TOOL_OUTPUT_TRUNCATED = 'tool_output_truncated',
83 |   MODEL_ROUTING = 'model_routing',
84 |   MODEL_SLASH_COMMAND = 'model_slash_command',
85 |   SMART_EDIT_STRATEGY = 'smart_edit_strategy',
86 |   SMART_EDIT_CORRECTION = 'smart_edit_correction',
87 |   AGENT_START = 'agent_start',
88 |   AGENT_FINISH = 'agent_finish',
89 |   WEB_FETCH_FALLBACK_ATTEMPT = 'web_fetch_fallback_attempt',
90 | }
91 | 
92 | export interface LogResponse {
93 |   nextRequestWaitMs?: number;
94 | }
95 | 
96 | export interface LogEventEntry {
97 |   event_time_ms: number;
98 |   source_extension_json: string;
99 | }
100 | 
101 | export interface EventValue {
102 |   gemini_cli_key: EventMetadataKey;
103 |   value: string;
104 | }
105 | 
106 | export interface LogEvent {
107 |   console_type: 'GEMINI_CLI';
108 |   application: number;
109 |   event_name: string;
110 |   event_metadata: EventValue[][];
111 |   client_email?: string;
112 |   client_install_id?: string;
113 | }
114 | 
115 | export interface LogRequest {
116 |   log_source_name: 'CONCORD';
117 |   request_time_ms: number;
118 |   log_event: LogEventEntry[][];
119 | }
120 | 
121 | /**
122 |  * Determine the surface that the user is currently using.  Surface is effectively the
123 |  * distribution channel in which the user is using Gemini CLI.  Gemini CLI comes bundled
124 |  * w/ Firebase Studio and Cloud Shell.  Users that manually download themselves will
125 |  * likely be "SURFACE_NOT_SET".
126 |  *
127 |  * This is computed based upon a series of environment variables these distribution
128 |  * methods might have in their runtimes.
129 |  */
130 | function determineSurface(): string {
131 |   if (process.env['SURFACE']) {
132 |     return process.env['SURFACE'];
133 |   } else if (isCloudShell()) {
134 |     return IDE_DEFINITIONS.cloudshell.name;
135 |   } else if (process.env['GITHUB_SHA']) {
136 |     return 'GitHub';
137 |   } else if (process.env['TERM_PROGRAM'] === 'vscode') {
138 |     return detectIdeFromEnv().name || IDE_DEFINITIONS.vscode.name;
139 |   } else {
140 |     return 'SURFACE_NOT_SET';
141 |   }
142 | }
143 | 
144 | /**
145 |  * Clearcut URL to send logging events to.
146 |  */
147 | const CLEARCUT_URL = 'https://play.googleapis.com/log?format=json&hasfast=true';
148 | 
149 | /**
150 |  * Interval in which buffered events are sent to clearcut.
151 |  */
152 | const FLUSH_INTERVAL_MS = 1000 * 60;
153 | 
154 | /**
155 |  * Maximum amount of events to keep in memory. Events added after this amount
156 |  * are dropped until the next flush to clearcut, which happens periodically as
157 |  * defined by {@link FLUSH_INTERVAL_MS}.
158 |  */
159 | const MAX_EVENTS = 1000;
160 | 
161 | /**
162 |  * Maximum events to retry after a failed clearcut flush
163 |  */
164 | const MAX_RETRY_EVENTS = 100;
165 | 
166 | // Singleton class for batch posting log events to Clearcut. When a new event comes in, the elapsed time
167 | // is checked and events are flushed to Clearcut if at least a minute has passed since the last flush.
168 | export class ClearcutLogger {
169 |   private static instance: ClearcutLogger;
170 |   private config?: Config;
171 |   private sessionData: EventValue[] = [];
172 |   private promptId: string = '';
173 |   private readonly installationManager: InstallationManager;
174 |   private readonly userAccountManager: UserAccountManager;
175 | 
176 |   /**
177 |    * Queue of pending events that need to be flushed to the server.  New events
178 |    * are added to this queue and then flushed on demand (via `flushToClearcut`)
179 |    */
180 |   private readonly events: FixedDeque<LogEventEntry[]>;
181 | 
182 |   /**
183 |    * The last time that the events were successfully flushed to the server.
184 |    */
185 |   private lastFlushTime: number = Date.now();
186 | 
187 |   /**
188 |    * the value is true when there is a pending flush happening. This prevents
189 |    * concurrent flush operations.
190 |    */
191 |   private flushing: boolean = false;
192 | 
193 |   /**
194 |    * This value is true when a flush was requested during an ongoing flush.
195 |    */
196 |   private pendingFlush: boolean = false;
197 | 
198 |   private constructor(config: Config) {
199 |     this.config = config;
200 |     this.events = new FixedDeque<LogEventEntry[]>(Array, MAX_EVENTS);
201 |     this.promptId = config?.getSessionId() ?? '';
202 |     this.installationManager = new InstallationManager();
203 |     this.userAccountManager = new UserAccountManager();
204 |   }
205 | 
206 |   static getInstance(config?: Config): ClearcutLogger | undefined {
207 |     if (config === undefined || !config?.getUsageStatisticsEnabled())
208 |       return undefined;
209 |     if (!ClearcutLogger.instance) {
210 |       ClearcutLogger.instance = new ClearcutLogger(config);
211 |     }
212 |     return ClearcutLogger.instance;
213 |   }
214 | 
215 |   /** For testing purposes only. */
216 |   static clearInstance(): void {
217 |     // @ts-expect-error - ClearcutLogger is a singleton, but we need to clear it for tests.
218 |     ClearcutLogger.instance = undefined;
219 |   }
220 | 
221 |   enqueueLogEvent(event: LogEvent): void {
222 |     try {
223 |       // Manually handle overflow for FixedDeque, which throws when full.
224 |       const wasAtCapacity = this.events.size >= MAX_EVENTS;
225 | 
226 |       if (wasAtCapacity) {
227 |         this.events.shift(); // Evict oldest element to make space.
228 |       }
229 | 
230 |       this.events.push([
231 |         {
232 |           event_time_ms: Date.now(),
233 |           source_extension_json: safeJsonStringify(event),
234 |         },
235 |       ]);
236 | 
237 |       if (wasAtCapacity && this.config?.getDebugMode()) {
238 |         console.debug(
239 |           `ClearcutLogger: Dropped old event to prevent memory leak (queue size: ${this.events.size})`,
240 |         );
241 |       }
242 |     } catch (error) {
243 |       if (this.config?.getDebugMode()) {
244 |         console.error('ClearcutLogger: Failed to enqueue log event.', error);
245 |       }
246 |     }
247 |   }
248 | 
249 |   createLogEvent(eventName: EventNames, data: EventValue[] = []): LogEvent {
250 |     const email = this.userAccountManager.getCachedGoogleAccount();
251 | 
252 |     if (eventName !== EventNames.START_SESSION) {
253 |       data.push(...this.sessionData);
254 |     }
255 |     const totalAccounts = this.userAccountManager.getLifetimeGoogleAccounts();
256 | 
257 |     data = this.addDefaultFields(data, totalAccounts);
258 | 
259 |     const logEvent: LogEvent = {
260 |       console_type: 'GEMINI_CLI',
261 |       application: 102, // GEMINI_CLI
262 |       event_name: eventName as string,
263 |       event_metadata: [data],
264 |     };
265 | 
266 |     // Should log either email or install ID, not both. See go/cloudmill-1p-oss-instrumentation#define-sessionable-id
267 |     if (email) {
268 |       logEvent.client_email = email;
269 |     } else {
270 |       logEvent.client_install_id = this.installationManager.getInstallationId();
271 |     }
272 | 
273 |     return logEvent;
274 |   }
275 | 
276 |   flushIfNeeded(): void {
277 |     if (Date.now() - this.lastFlushTime < FLUSH_INTERVAL_MS) {
278 |       return;
279 |     }
280 | 
281 |     this.flushToClearcut().catch((error) => {
282 |       console.debug('Error flushing to Clearcut:', error);
283 |     });
284 |   }
285 | 
286 |   async flushToClearcut(): Promise<LogResponse> {
287 |     if (this.flushing) {
288 |       if (this.config?.getDebugMode()) {
289 |         console.debug(
290 |           'ClearcutLogger: Flush already in progress, marking pending flush.',
291 |         );
292 |       }
293 |       this.pendingFlush = true;
294 |       return Promise.resolve({});
295 |     }
296 |     this.flushing = true;
297 | 
298 |     if (this.config?.getDebugMode()) {
299 |       console.log('Flushing log events to Clearcut.');
300 |     }
301 |     const eventsToSend = this.events.toArray() as LogEventEntry[][];
302 |     this.events.clear();
303 | 
304 |     const request: LogRequest[] = [
305 |       {
306 |         log_source_name: 'CONCORD',
307 |         request_time_ms: Date.now(),
308 |         log_event: eventsToSend,
309 |       },
310 |     ];
311 | 
312 |     let result: LogResponse = {};
313 | 
314 |     try {
315 |       const response = await fetch(CLEARCUT_URL, {
316 |         method: 'POST',
317 |         body: safeJsonStringify(request),
318 |         headers: {
319 |           'Content-Type': 'application/json',
320 |         },
321 |       });
322 | 
323 |       const responseBody = await response.text();
324 | 
325 |       if (response.status >= 200 && response.status < 300) {
326 |         this.lastFlushTime = Date.now();
327 |         const nextRequestWaitMs = Number(JSON.parse(responseBody)[0]);
328 |         result = {
329 |           ...result,
330 |           nextRequestWaitMs,
331 |         };
332 |       } else {
333 |         if (this.config?.getDebugMode()) {
334 |           console.error(
335 |             `Error flushing log events: HTTP ${response.status}: ${response.statusText}`,
336 |           );
337 |         }
338 | 
339 |         // Re-queue failed events for retry
340 |         this.requeueFailedEvents(eventsToSend);
341 |       }
342 |     } catch (e: unknown) {
343 |       if (this.config?.getDebugMode()) {
344 |         console.error('Error flushing log events:', e as Error);
345 |       }
346 | 
347 |       // Re-queue failed events for retry
348 |       this.requeueFailedEvents(eventsToSend);
349 |     }
350 | 
351 |     this.flushing = false;
352 | 
353 |     // If a flush was requested while we were flushing, flush again
354 |     if (this.pendingFlush) {
355 |       this.pendingFlush = false;
356 |       // Fire and forget the pending flush
357 |       this.flushToClearcut().catch((error) => {
358 |         if (this.config?.getDebugMode()) {
359 |           console.debug('Error in pending flush to Clearcut:', error);
360 |         }
361 |       });
362 |     }
363 | 
364 |     return result;
365 |   }
366 | 
367 |   logStartSessionEvent(event: StartSessionEvent): void {
368 |     const data: EventValue[] = [
369 |       {
370 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_START_SESSION_MODEL,
371 |         value: event.model,
372 |       },
373 |       {
374 |         gemini_cli_key:
375 |           EventMetadataKey.GEMINI_CLI_START_SESSION_EMBEDDING_MODEL,
376 |         value: event.embedding_model,
377 |       },
378 |       {
379 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_START_SESSION_SANDBOX,
380 |         value: event.sandbox_enabled.toString(),
381 |       },
382 |       {
383 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_START_SESSION_CORE_TOOLS,
384 |         value: event.core_tools_enabled,
385 |       },
386 |       {
387 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_START_SESSION_APPROVAL_MODE,
388 |         value: event.approval_mode,
389 |       },
390 |       {
391 |         gemini_cli_key:
392 |           EventMetadataKey.GEMINI_CLI_START_SESSION_API_KEY_ENABLED,
393 |         value: event.api_key_enabled.toString(),
394 |       },
395 |       {
396 |         gemini_cli_key:
397 |           EventMetadataKey.GEMINI_CLI_START_SESSION_VERTEX_API_ENABLED,
398 |         value: event.vertex_ai_enabled.toString(),
399 |       },
400 |       {
401 |         gemini_cli_key:
402 |           EventMetadataKey.GEMINI_CLI_START_SESSION_DEBUG_MODE_ENABLED,
403 |         value: event.debug_enabled.toString(),
404 |       },
405 |       {
406 |         gemini_cli_key:
407 |           EventMetadataKey.GEMINI_CLI_START_SESSION_VERTEX_API_ENABLED,
408 |         value: event.vertex_ai_enabled.toString(),
409 |       },
410 |       {
411 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_START_SESSION_MCP_SERVERS,
412 |         value: event.mcp_servers,
413 |       },
414 |       {
415 |         gemini_cli_key:
416 |           EventMetadataKey.GEMINI_CLI_START_SESSION_VERTEX_API_ENABLED,
417 |         value: event.vertex_ai_enabled.toString(),
418 |       },
419 |       {
420 |         gemini_cli_key:
421 |           EventMetadataKey.GEMINI_CLI_START_SESSION_TELEMETRY_ENABLED,
422 |         value: event.telemetry_enabled.toString(),
423 |       },
424 |       {
425 |         gemini_cli_key:
426 |           EventMetadataKey.GEMINI_CLI_START_SESSION_TELEMETRY_LOG_USER_PROMPTS_ENABLED,
427 |         value: event.telemetry_log_user_prompts_enabled.toString(),
428 |       },
429 |       {
430 |         gemini_cli_key:
431 |           EventMetadataKey.GEMINI_CLI_START_SESSION_MCP_SERVERS_COUNT,
432 |         value: event.mcp_servers_count
433 |           ? event.mcp_servers_count.toString()
434 |           : '',
435 |       },
436 |       {
437 |         gemini_cli_key:
438 |           EventMetadataKey.GEMINI_CLI_START_SESSION_MCP_TOOLS_COUNT,
439 |         value: event.mcp_tools_count?.toString() ?? '',
440 |       },
441 |       {
442 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_START_SESSION_MCP_TOOLS,
443 |         value: event.mcp_tools ? event.mcp_tools : '',
444 |       },
445 |     ];
446 |     this.sessionData = data;
447 | 
448 |     // Flush start event immediately
449 |     this.enqueueLogEvent(this.createLogEvent(EventNames.START_SESSION, data));
450 |     this.flushToClearcut().catch((error) => {
451 |       console.debug('Error flushing to Clearcut:', error);
452 |     });
453 |   }
454 | 
455 |   logNewPromptEvent(event: UserPromptEvent): void {
456 |     this.promptId = event.prompt_id;
457 |     const data: EventValue[] = [
458 |       {
459 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_USER_PROMPT_LENGTH,
460 |         value: JSON.stringify(event.prompt_length),
461 |       },
462 |     ];
463 | 
464 |     this.enqueueLogEvent(this.createLogEvent(EventNames.NEW_PROMPT, data));
465 |     this.flushIfNeeded();
466 |   }
467 | 
468 |   logToolCallEvent(event: ToolCallEvent): void {
469 |     const data: EventValue[] = [
470 |       {
471 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_TOOL_CALL_NAME,
472 |         value: JSON.stringify(event.function_name),
473 |       },
474 |       {
475 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_TOOL_CALL_DECISION,
476 |         value: JSON.stringify(event.decision),
477 |       },
478 |       {
479 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_TOOL_CALL_SUCCESS,
480 |         value: JSON.stringify(event.success),
481 |       },
482 |       {
483 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_TOOL_CALL_DURATION_MS,
484 |         value: JSON.stringify(event.duration_ms),
485 |       },
486 |       {
487 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_TOOL_CALL_ERROR_TYPE,
488 |         value: JSON.stringify(event.error_type),
489 |       },
490 |       {
491 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_TOOL_TYPE,
492 |         value: JSON.stringify(event.tool_type),
493 |       },
494 |       {
495 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_TOOL_CALL_CONTENT_LENGTH,
496 |         value: JSON.stringify(event.content_length),
497 |       },
498 |       {
499 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_TOOL_CALL_MCP_SERVER_NAME,
500 |         value: JSON.stringify(event.mcp_server_name),
501 |       },
502 |     ];
503 | 
504 |     if (event.metadata) {
505 |       const metadataMapping: { [key: string]: EventMetadataKey } = {
506 |         model_added_lines: EventMetadataKey.GEMINI_CLI_AI_ADDED_LINES,
507 |         model_removed_lines: EventMetadataKey.GEMINI_CLI_AI_REMOVED_LINES,
508 |         model_added_chars: EventMetadataKey.GEMINI_CLI_AI_ADDED_CHARS,
509 |         model_removed_chars: EventMetadataKey.GEMINI_CLI_AI_REMOVED_CHARS,
510 |         user_added_lines: EventMetadataKey.GEMINI_CLI_USER_ADDED_LINES,
511 |         user_removed_lines: EventMetadataKey.GEMINI_CLI_USER_REMOVED_LINES,
512 |         user_added_chars: EventMetadataKey.GEMINI_CLI_USER_ADDED_CHARS,
513 |         user_removed_chars: EventMetadataKey.GEMINI_CLI_USER_REMOVED_CHARS,
514 |       };
515 | 
516 |       for (const [key, gemini_cli_key] of Object.entries(metadataMapping)) {
517 |         if (event.metadata[key] !== undefined) {
518 |           data.push({
519 |             gemini_cli_key,
520 |             value: JSON.stringify(event.metadata[key]),
521 |           });
522 |         }
523 |       }
524 |     }
525 | 
526 |     const logEvent = this.createLogEvent(EventNames.TOOL_CALL, data);
527 |     this.enqueueLogEvent(logEvent);
528 |     this.flushIfNeeded();
529 |   }
530 | 
531 |   logFileOperationEvent(event: FileOperationEvent): void {
532 |     const data: EventValue[] = [
533 |       {
534 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_TOOL_CALL_NAME,
535 |         value: JSON.stringify(event.tool_name),
536 |       },
537 |       {
538 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_FILE_OPERATION_TYPE,
539 |         value: JSON.stringify(event.operation),
540 |       },
541 |       {
542 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_FILE_OPERATION_LINES,
543 |         value: JSON.stringify(event.lines),
544 |       },
545 |       {
546 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_FILE_OPERATION_MIMETYPE,
547 |         value: JSON.stringify(event.mimetype),
548 |       },
549 |       {
550 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_FILE_OPERATION_EXTENSION,
551 |         value: JSON.stringify(event.extension),
552 |       },
553 |     ];
554 | 
555 |     if (event.programming_language) {
556 |       data.push({
557 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_PROGRAMMING_LANGUAGE,
558 |         value: event.programming_language,
559 |       });
560 |     }
561 | 
562 |     const logEvent = this.createLogEvent(EventNames.FILE_OPERATION, data);
563 |     this.enqueueLogEvent(logEvent);
564 |     this.flushIfNeeded();
565 |   }
566 | 
567 |   logApiRequestEvent(event: ApiRequestEvent): void {
568 |     const data: EventValue[] = [
569 |       {
570 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_API_REQUEST_MODEL,
571 |         value: JSON.stringify(event.model),
572 |       },
573 |     ];
574 | 
575 |     this.enqueueLogEvent(this.createLogEvent(EventNames.API_REQUEST, data));
576 |     this.flushIfNeeded();
577 |   }
578 | 
579 |   logApiResponseEvent(event: ApiResponseEvent): void {
580 |     const data: EventValue[] = [
581 |       {
582 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_API_RESPONSE_MODEL,
583 |         value: JSON.stringify(event.model),
584 |       },
585 |       {
586 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_API_RESPONSE_STATUS_CODE,
587 |         value: JSON.stringify(event.status_code),
588 |       },
589 |       {
590 |         gemini_cli_key: EventMetadataKey.GEMINI_CLI_API_RESPONSE_DURATION_MS,
591 |         value: JSON.stringify(event.duration_ms),
592 |       },
593 |       {
594 |         gemini_cli_key:
595 |           EventMetadataKey.GEMINI_CLI_API_RESPONSE_INPUT_TOKEN_COUNT,
596 |         value: JSON.stringify(event.input_token_count),
597 |       },
598 |       {
[TRUNCATED]
```

src/telemetry/clearcut-logger/event-metadata-key.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | // Defines valid event metadata keys for Clearcut logging.
8 | export enum EventMetadataKey {
9 |   // Deleted enums: 24
10 |   // Next ID: 117
11 | 
12 |   GEMINI_CLI_KEY_UNKNOWN = 0,
13 | 
14 |   // ==========================================================================
15 |   // Start Session Event Keys
16 |   // ===========================================================================
17 | 
18 |   // Logs the model id used in the session.
19 |   GEMINI_CLI_START_SESSION_MODEL = 1,
20 | 
21 |   // Logs the embedding model id used in the session.
22 |   GEMINI_CLI_START_SESSION_EMBEDDING_MODEL = 2,
23 | 
24 |   // Logs the sandbox that was used in the session.
25 |   GEMINI_CLI_START_SESSION_SANDBOX = 3,
26 | 
27 |   // Logs the core tools that were enabled in the session.
28 |   GEMINI_CLI_START_SESSION_CORE_TOOLS = 4,
29 | 
30 |   // Logs the approval mode that was used in the session.
31 |   GEMINI_CLI_START_SESSION_APPROVAL_MODE = 5,
32 | 
33 |   // Logs whether an API key was used in the session.
34 |   GEMINI_CLI_START_SESSION_API_KEY_ENABLED = 6,
35 | 
36 |   // Logs whether the Vertex API was used in the session.
37 |   GEMINI_CLI_START_SESSION_VERTEX_API_ENABLED = 7,
38 | 
39 |   // Logs whether debug mode was enabled in the session.
40 |   GEMINI_CLI_START_SESSION_DEBUG_MODE_ENABLED = 8,
41 | 
42 |   // Logs the MCP servers that were enabled in the session.
43 |   GEMINI_CLI_START_SESSION_MCP_SERVERS = 9,
44 | 
45 |   // Logs whether user-collected telemetry was enabled in the session.
46 |   GEMINI_CLI_START_SESSION_TELEMETRY_ENABLED = 10,
47 | 
48 |   // Logs whether prompt collection was enabled for user-collected telemetry.
49 |   GEMINI_CLI_START_SESSION_TELEMETRY_LOG_USER_PROMPTS_ENABLED = 11,
50 | 
51 |   // Logs whether the session was configured to respect gitignore files.
52 |   GEMINI_CLI_START_SESSION_RESPECT_GITIGNORE = 12,
53 | 
54 |   // Logs the output format of the session.
55 |   GEMINI_CLI_START_SESSION_OUTPUT_FORMAT = 94,
56 | 
57 |   // ==========================================================================
58 |   // User Prompt Event Keys
59 |   // ===========================================================================
60 | 
61 |   // Logs the length of the prompt.
62 |   GEMINI_CLI_USER_PROMPT_LENGTH = 13,
63 | 
64 |   // ==========================================================================
65 |   // Tool Call Event Keys
66 |   // ===========================================================================
67 | 
68 |   // Logs the function name.
69 |   GEMINI_CLI_TOOL_CALL_NAME = 14,
70 | 
71 |   // Logs the MCP server name.
72 |   GEMINI_CLI_TOOL_CALL_MCP_SERVER_NAME = 95,
73 | 
74 |   // Logs the user's decision about how to handle the tool call.
75 |   GEMINI_CLI_TOOL_CALL_DECISION = 15,
76 | 
77 |   // Logs whether the tool call succeeded.
78 |   GEMINI_CLI_TOOL_CALL_SUCCESS = 16,
79 | 
80 |   // Logs the tool call duration in milliseconds.
81 |   GEMINI_CLI_TOOL_CALL_DURATION_MS = 17,
82 | 
83 |   // Do not use.
84 |   DEPRECATED_GEMINI_CLI_TOOL_ERROR_MESSAGE = 18,
85 | 
86 |   // Logs the tool call error type, if any.
87 |   GEMINI_CLI_TOOL_CALL_ERROR_TYPE = 19,
88 | 
89 |   // Logs the length of tool output
90 |   GEMINI_CLI_TOOL_CALL_CONTENT_LENGTH = 93,
91 | 
92 |   // ==========================================================================
93 |   // Replace Tool Call Event Keys
94 |   // ===========================================================================
95 | 
96 |   // Logs a smart edit tool strategy choice.
97 |   GEMINI_CLI_SMART_EDIT_STRATEGY = 109,
98 | 
99 |   // Logs a smart edit correction event.
100 |   GEMINI_CLI_SMART_EDIT_CORRECTION = 110,
101 | 
102 |   // Logs the reason for web fetch fallback.
103 |   GEMINI_CLI_WEB_FETCH_FALLBACK_REASON = 116,
104 | 
105 |   // ==========================================================================
106 |   // GenAI API Request Event Keys
107 |   // ===========================================================================
108 | 
109 |   // Logs the model id of the request.
110 |   GEMINI_CLI_API_REQUEST_MODEL = 20,
111 | 
112 |   // ==========================================================================
113 |   // GenAI API Response Event Keys
114 |   // ===========================================================================
115 | 
116 |   // Logs the model id of the API call.
117 |   GEMINI_CLI_API_RESPONSE_MODEL = 21,
118 | 
119 |   // Logs the status code of the response.
120 |   GEMINI_CLI_API_RESPONSE_STATUS_CODE = 22,
121 | 
122 |   // Logs the duration of the API call in milliseconds.
123 |   GEMINI_CLI_API_RESPONSE_DURATION_MS = 23,
124 | 
125 |   // Logs the input token count of the API call.
126 |   GEMINI_CLI_API_RESPONSE_INPUT_TOKEN_COUNT = 25,
127 | 
128 |   // Logs the output token count of the API call.
129 |   GEMINI_CLI_API_RESPONSE_OUTPUT_TOKEN_COUNT = 26,
130 | 
131 |   // Logs the cached token count of the API call.
132 |   GEMINI_CLI_API_RESPONSE_CACHED_TOKEN_COUNT = 27,
133 | 
134 |   // Logs the thinking token count of the API call.
135 |   GEMINI_CLI_API_RESPONSE_THINKING_TOKEN_COUNT = 28,
136 | 
137 |   // Logs the tool use token count of the API call.
138 |   GEMINI_CLI_API_RESPONSE_TOOL_TOKEN_COUNT = 29,
139 | 
140 |   // ==========================================================================
141 |   // GenAI API Error Event Keys
142 |   // ===========================================================================
143 | 
144 |   // Logs the model id of the API call.
145 |   GEMINI_CLI_API_ERROR_MODEL = 30,
146 | 
147 |   // Logs the error type.
148 |   GEMINI_CLI_API_ERROR_TYPE = 31,
149 | 
150 |   // Logs the status code of the error response.
151 |   GEMINI_CLI_API_ERROR_STATUS_CODE = 32,
152 | 
153 |   // Logs the duration of the API call in milliseconds.
154 |   GEMINI_CLI_API_ERROR_DURATION_MS = 33,
155 | 
156 |   // ==========================================================================
157 |   // End Session Event Keys
158 |   // ===========================================================================
159 | 
160 |   // Logs the end of a session.
161 |   GEMINI_CLI_END_SESSION_ID = 34,
162 | 
163 |   // ==========================================================================
164 |   // Shared Keys
165 |   // ===========================================================================
166 | 
167 |   // Logs the Prompt Id
168 |   GEMINI_CLI_PROMPT_ID = 35,
169 | 
170 |   // Logs the Auth type for the prompt, api responses and errors.
171 |   GEMINI_CLI_AUTH_TYPE = 36,
172 | 
173 |   // Logs the total number of Google accounts ever used.
174 |   GEMINI_CLI_GOOGLE_ACCOUNTS_COUNT = 37,
175 | 
176 |   // Logs the Surface from where the Gemini CLI was invoked, eg: VSCode.
177 |   GEMINI_CLI_SURFACE = 39,
178 | 
179 |   // Logs the session id
180 |   GEMINI_CLI_SESSION_ID = 40,
181 | 
182 |   // Logs the Gemini CLI version
183 |   GEMINI_CLI_VERSION = 54,
184 | 
185 |   // Logs the Gemini CLI Git commit hash
186 |   GEMINI_CLI_GIT_COMMIT_HASH = 55,
187 | 
188 |   // Logs the Gemini CLI OS
189 |   GEMINI_CLI_OS = 82,
190 | 
191 |   // Logs active user settings
192 |   GEMINI_CLI_USER_SETTINGS = 84,
193 | 
194 |   // ==========================================================================
195 |   // Loop Detected Event Keys
196 |   // ===========================================================================
197 | 
198 |   // Logs the type of loop detected.
199 |   GEMINI_CLI_LOOP_DETECTED_TYPE = 38,
200 | 
201 |   // ==========================================================================
202 |   // Slash Command Event Keys
203 |   // ===========================================================================
204 | 
205 |   // Logs the name of the slash command.
206 |   GEMINI_CLI_SLASH_COMMAND_NAME = 41,
207 | 
208 |   // Logs the subcommand of the slash command.
209 |   GEMINI_CLI_SLASH_COMMAND_SUBCOMMAND = 42,
210 | 
211 |   // Logs the status of the slash command (e.g. 'success', 'error')
212 |   GEMINI_CLI_SLASH_COMMAND_STATUS = 51,
213 | 
214 |   // ==========================================================================
215 |   // Next Speaker Check Event Keys
216 |   // ===========================================================================
217 | 
218 |   // Logs the finish reason of the previous streamGenerateContent response
219 |   GEMINI_CLI_RESPONSE_FINISH_REASON = 43,
220 | 
221 |   // Logs the result of the next speaker check
222 |   GEMINI_CLI_NEXT_SPEAKER_CHECK_RESULT = 44,
223 | 
224 |   // ==========================================================================
225 |   // Malformed JSON Response Event Keys
226 |   // ==========================================================================
227 | 
228 |   // Logs the model that produced the malformed JSON response.
229 |   GEMINI_CLI_MALFORMED_JSON_RESPONSE_MODEL = 45,
230 | 
231 |   // ==========================================================================
232 |   // IDE Connection Event Keys
233 |   // ===========================================================================
234 | 
235 |   // Logs the type of the IDE connection.
236 |   GEMINI_CLI_IDE_CONNECTION_TYPE = 46,
237 | 
238 |   // Logs AI added lines in edit/write tool response.
239 |   GEMINI_CLI_AI_ADDED_LINES = 47,
240 | 
241 |   // Logs AI removed lines in edit/write tool response.
242 |   GEMINI_CLI_AI_REMOVED_LINES = 48,
243 | 
244 |   // Logs user added lines in edit/write tool response.
245 |   GEMINI_CLI_USER_ADDED_LINES = 49,
246 | 
247 |   // Logs user removed lines in edit/write tool response.
248 |   GEMINI_CLI_USER_REMOVED_LINES = 50,
249 | 
250 |   // Logs AI added characters in edit/write tool response.
251 |   GEMINI_CLI_AI_ADDED_CHARS = 103,
252 | 
253 |   // Logs AI removed characters in edit/write tool response.
254 |   GEMINI_CLI_AI_REMOVED_CHARS = 104,
255 | 
256 |   // Logs user added characters in edit/write tool response.
257 |   GEMINI_CLI_USER_ADDED_CHARS = 105,
258 | 
259 |   // Logs user removed characters in edit/write tool response.
260 |   GEMINI_CLI_USER_REMOVED_CHARS = 106,
261 | 
262 |   // ==========================================================================
263 |   // Kitty Sequence Overflow Event Keys
264 |   // ===========================================================================
265 | 
266 |   // Do not use.
267 |   DEPRECATED_GEMINI_CLI_KITTY_TRUNCATED_SEQUENCE = 52,
268 | 
269 |   // Logs the length of the kitty sequence that overflowed.
270 |   GEMINI_CLI_KITTY_SEQUENCE_LENGTH = 53,
271 | 
272 |   // ==========================================================================
273 |   // Conversation Finished Event Keys
274 |   // ===========================================================================
275 | 
276 |   // Logs the approval mode of the session.
277 |   GEMINI_CLI_APPROVAL_MODE = 58,
278 | 
279 |   // Logs the number of turns
280 |   GEMINI_CLI_CONVERSATION_TURN_COUNT = 59,
281 | 
282 |   // Logs the number of tokens before context window compression.
283 |   GEMINI_CLI_COMPRESSION_TOKENS_BEFORE = 60,
284 | 
285 |   // Logs the number of tokens after context window compression.
286 |   GEMINI_CLI_COMPRESSION_TOKENS_AFTER = 61,
287 | 
288 |   // Logs tool type whether it is mcp or native.
289 |   GEMINI_CLI_TOOL_TYPE = 62,
290 | 
291 |   // Logs count of MCP servers in Start Session Event
292 |   GEMINI_CLI_START_SESSION_MCP_SERVERS_COUNT = 63,
293 | 
294 |   // Logs count of MCP tools in Start Session Event
295 |   GEMINI_CLI_START_SESSION_MCP_TOOLS_COUNT = 64,
296 | 
297 |   // Logs name of MCP tools as comma separated string
298 |   GEMINI_CLI_START_SESSION_MCP_TOOLS = 65,
299 | 
300 |   // ==========================================================================
301 |   // Research Event Keys
302 |   // ===========================================================================
303 | 
304 |   // Logs the research opt-in status (true/false)
305 |   GEMINI_CLI_RESEARCH_OPT_IN_STATUS = 66,
306 | 
307 |   // Logs the contact email for research participation
308 |   GEMINI_CLI_RESEARCH_CONTACT_EMAIL = 67,
309 | 
310 |   // Logs the user ID for research events
311 |   GEMINI_CLI_RESEARCH_USER_ID = 68,
312 | 
313 |   // Logs the type of research feedback
314 |   GEMINI_CLI_RESEARCH_FEEDBACK_TYPE = 69,
315 | 
316 |   // Logs the content of research feedback
317 |   GEMINI_CLI_RESEARCH_FEEDBACK_CONTENT = 70,
318 | 
319 |   // Logs survey responses for research feedback (JSON stringified)
320 |   GEMINI_CLI_RESEARCH_SURVEY_RESPONSES = 71,
321 | 
322 |   // ==========================================================================
323 |   // File Operation Event Keys
324 |   // ===========================================================================
325 | 
326 |   // Logs the programming language of the project.
327 |   GEMINI_CLI_PROGRAMMING_LANGUAGE = 56,
328 | 
329 |   // Logs the operation type of the file operation.
330 |   GEMINI_CLI_FILE_OPERATION_TYPE = 57,
331 | 
332 |   // Logs the number of lines in the file operation.
333 |   GEMINI_CLI_FILE_OPERATION_LINES = 72,
334 | 
335 |   // Logs the mimetype of the file in the file operation.
336 |   GEMINI_CLI_FILE_OPERATION_MIMETYPE = 73,
337 | 
338 |   // Logs the extension of the file in the file operation.
339 |   GEMINI_CLI_FILE_OPERATION_EXTENSION = 74,
340 | 
341 |   // ==========================================================================
342 |   // Content Streaming Event Keys
343 |   // ===========================================================================
344 | 
345 |   // Logs the error message for an invalid chunk.
346 |   GEMINI_CLI_INVALID_CHUNK_ERROR_MESSAGE = 75,
347 | 
348 |   // Logs the attempt number for a content retry.
349 |   GEMINI_CLI_CONTENT_RETRY_ATTEMPT_NUMBER = 76,
350 | 
351 |   // Logs the error type for a content retry.
352 |   GEMINI_CLI_CONTENT_RETRY_ERROR_TYPE = 77,
353 | 
354 |   // Logs the delay in milliseconds for a content retry.
355 |   GEMINI_CLI_CONTENT_RETRY_DELAY_MS = 78,
356 | 
357 |   // Logs the total number of attempts for a content retry failure.
358 |   GEMINI_CLI_CONTENT_RETRY_FAILURE_TOTAL_ATTEMPTS = 79,
359 | 
360 |   // Logs the final error type for a content retry failure.
361 |   GEMINI_CLI_CONTENT_RETRY_FAILURE_FINAL_ERROR_TYPE = 80,
362 | 
363 |   // Logs the total duration in milliseconds for a content retry failure.
364 |   GEMINI_CLI_CONTENT_RETRY_FAILURE_TOTAL_DURATION_MS = 81,
365 | 
366 |   // Logs the current nodejs version
367 |   GEMINI_CLI_NODE_VERSION = 83,
368 | 
369 |   // ==========================================================================
370 |   // Extension Event Keys
371 |   // ===========================================================================
372 | 
373 |   // Logs the name of the extension.
374 |   GEMINI_CLI_EXTENSION_NAME = 85,
375 | 
376 |   // Logs the version of the extension.
377 |   GEMINI_CLI_EXTENSION_VERSION = 86,
378 | 
379 |   // Logs the previous version of the extension.
380 |   GEMINI_CLI_EXTENSION_PREVIOUS_VERSION = 117,
381 | 
382 |   // Logs the source of the extension.
383 |   GEMINI_CLI_EXTENSION_SOURCE = 87,
384 | 
385 |   // Logs the status of the extension install.
386 |   GEMINI_CLI_EXTENSION_INSTALL_STATUS = 88,
387 | 
388 |   // Logs the status of the extension uninstall
389 |   GEMINI_CLI_EXTENSION_UNINSTALL_STATUS = 96,
390 | 
391 |   // Logs the status of the extension uninstall
392 |   GEMINI_CLI_EXTENSION_UPDATE_STATUS = 118,
393 | 
394 |   // Logs the setting scope for an extension enablement.
395 |   GEMINI_CLI_EXTENSION_ENABLE_SETTING_SCOPE = 102,
396 | 
397 |   // Logs the setting scope for an extension disablement.
398 |   GEMINI_CLI_EXTENSION_DISABLE_SETTING_SCOPE = 107,
399 | 
400 |   // ==========================================================================
401 |   // Tool Output Truncated Event Keys
402 |   // ===========================================================================
403 | 
404 |   // Logs the original length of the tool output.
405 |   GEMINI_CLI_TOOL_OUTPUT_TRUNCATED_ORIGINAL_LENGTH = 89,
406 | 
407 |   // Logs the truncated length of the tool output.
408 |   GEMINI_CLI_TOOL_OUTPUT_TRUNCATED_TRUNCATED_LENGTH = 90,
409 | 
410 |   // Logs the threshold at which the tool output was truncated.
411 |   GEMINI_CLI_TOOL_OUTPUT_TRUNCATED_THRESHOLD = 91,
412 | 
413 |   // Logs the number of lines the tool output was truncated to.
414 |   GEMINI_CLI_TOOL_OUTPUT_TRUNCATED_LINES = 92,
415 | 
416 |   // ==========================================================================
417 |   // Model Router Event Keys
418 |   // ==========================================================================
419 | 
420 |   // Logs the outcome of a model routing decision (e.g., which route/model was
421 |   // selected).
422 |   GEMINI_CLI_ROUTING_DECISION = 97,
423 | 
424 |   // Logs an event when the model router fails to make a decision or the chosen
425 |   // route fails.
426 |   GEMINI_CLI_ROUTING_FAILURE = 98,
427 | 
428 |   // Logs the latency in milliseconds for the router to make a decision.
429 |   GEMINI_CLI_ROUTING_LATENCY_MS = 99,
430 | 
431 |   // Logs a specific reason for a routing failure.
432 |   GEMINI_CLI_ROUTING_FAILURE_REASON = 100,
433 | 
434 |   // Logs the source of the decision.
435 |   GEMINI_CLI_ROUTING_DECISION_SOURCE = 101,
436 | 
437 |   // Logs an event when the user uses the /model command.
438 |   GEMINI_CLI_MODEL_SLASH_COMMAND = 108,
439 | 
440 |   // ==========================================================================
441 |   // Agent Event Keys
442 |   // ==========================================================================
443 | 
444 |   // Logs the name of the agent.
445 |   GEMINI_CLI_AGENT_NAME = 111,
446 | 
447 |   // Logs the unique ID of the agent instance.
448 |   GEMINI_CLI_AGENT_ID = 112,
449 | 
450 |   // Logs the duration of the agent execution in milliseconds.
451 |   GEMINI_CLI_AGENT_DURATION_MS = 113,
452 | 
453 |   // Logs the number of turns the agent took.
454 |   GEMINI_CLI_AGENT_TURN_COUNT = 114,
455 | 
456 |   // Logs the reason for agent termination.
457 |   GEMINI_CLI_AGENT_TERMINATE_REASON = 115,
458 | }
```

src/tools/__snapshots__/shell.test.ts.snap
```
1 | // Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html
2 | 
3 | exports[`ShellTool > getDescription > should return the non-windows description when not on windows 1`] = `
4 | "This tool executes a given shell command as \`bash -c <command>\`. Command can start background processes using \`&\`. Command is executed as a subprocess that leads its own process group. Command process group can be terminated as \`kill -- -PGID\` or signaled as \`kill -s SIGNAL -- -PGID\`.
5 | 
6 |       The following information is returned:
7 | 
8 |       Command: Executed command.
9 |       Directory: Directory where command was executed, or \`(root)\`.
10 |       Stdout: Output on stdout stream. Can be \`(empty)\` or partial on error and for any unwaited background processes.
11 |       Stderr: Output on stderr stream. Can be \`(empty)\` or partial on error and for any unwaited background processes.
12 |       Error: Error or \`(none)\` if no error was reported for the subprocess.
13 |       Exit Code: Exit code or \`(none)\` if terminated by signal.
14 |       Signal: Signal number or \`(none)\` if no signal was received.
15 |       Background PIDs: List of background processes started or \`(none)\`.
16 |       Process Group PGID: Process group started or \`(none)\`"
17 | `;
18 | 
19 | exports[`ShellTool > getDescription > should return the windows description when on windows 1`] = `
20 | "This tool executes a given shell command as \`cmd.exe /c <command>\`. Command can start background processes using \`start /b\`.
21 | 
22 |       The following information is returned:
23 | 
24 |       Command: Executed command.
25 |       Directory: Directory where command was executed, or \`(root)\`.
26 |       Stdout: Output on stdout stream. Can be \`(empty)\` or partial on error and for any unwaited background processes.
27 |       Stderr: Output on stderr stream. Can be \`(empty)\` or partial on error and for any unwaited background processes.
28 |       Error: Error or \`(none)\` if no error was reported for the subprocess.
29 |       Exit Code: Exit code or \`(none)\` if terminated by signal.
30 |       Signal: Signal number or \`(none)\` if no signal was received.
31 |       Background PIDs: List of background processes started or \`(none)\`.
32 |       Process Group PGID: Process group started or \`(none)\`"
33 | `;
```

src/utils/filesearch/crawlCache.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, vi, afterEach, beforeEach } from 'vitest';
8 | import { getCacheKey, read, write, clear } from './crawlCache.js';
9 | 
10 | describe('CrawlCache', () => {
11 |   describe('getCacheKey', () => {
12 |     it('should generate a consistent hash', () => {
13 |       const key1 = getCacheKey('/foo', 'bar');
14 |       const key2 = getCacheKey('/foo', 'bar');
15 |       expect(key1).toBe(key2);
16 |     });
17 | 
18 |     it('should generate a different hash for different directories', () => {
19 |       const key1 = getCacheKey('/foo', 'bar');
20 |       const key2 = getCacheKey('/bar', 'bar');
21 |       expect(key1).not.toBe(key2);
22 |     });
23 | 
24 |     it('should generate a different hash for different ignore content', () => {
25 |       const key1 = getCacheKey('/foo', 'bar');
26 |       const key2 = getCacheKey('/foo', 'baz');
27 |       expect(key1).not.toBe(key2);
28 |     });
29 | 
30 |     it('should generate a different hash for different maxDepth values', () => {
31 |       const key1 = getCacheKey('/foo', 'bar', 1);
32 |       const key2 = getCacheKey('/foo', 'bar', 2);
33 |       const key3 = getCacheKey('/foo', 'bar', undefined);
34 |       const key4 = getCacheKey('/foo', 'bar');
35 |       expect(key1).not.toBe(key2);
36 |       expect(key1).not.toBe(key3);
37 |       expect(key2).not.toBe(key3);
38 |       expect(key3).toBe(key4);
39 |     });
40 |   });
41 | 
42 |   describe('in-memory cache operations', () => {
43 |     beforeEach(() => {
44 |       // Ensure a clean slate before each test
45 |       clear();
46 |     });
47 | 
48 |     afterEach(() => {
49 |       // Restore real timers after each test that uses fake ones
50 |       vi.useRealTimers();
51 |     });
52 | 
53 |     it('should write and read data from the cache', () => {
54 |       const key = 'test-key';
55 |       const data = ['foo', 'bar'];
56 |       write(key, data, 10000); // 10 second TTL
57 |       const cachedData = read(key);
58 |       expect(cachedData).toEqual(data);
59 |     });
60 | 
61 |     it('should return undefined for a nonexistent key', () => {
62 |       const cachedData = read('nonexistent-key');
63 |       expect(cachedData).toBeUndefined();
64 |     });
65 | 
66 |     it('should clear the cache', () => {
67 |       const key = 'test-key';
68 |       const data = ['foo', 'bar'];
69 |       write(key, data, 10000);
70 |       clear();
71 |       const cachedData = read(key);
72 |       expect(cachedData).toBeUndefined();
73 |     });
74 | 
75 |     it('should automatically evict a cache entry after its TTL expires', async () => {
76 |       vi.useFakeTimers();
77 |       const key = 'ttl-key';
78 |       const data = ['foo'];
79 |       const ttl = 5000; // 5 seconds
80 | 
81 |       write(key, data, ttl);
82 | 
83 |       // Should exist immediately after writing
84 |       expect(read(key)).toEqual(data);
85 | 
86 |       // Advance time just before expiration
87 |       await vi.advanceTimersByTimeAsync(ttl - 1);
88 |       expect(read(key)).toEqual(data);
89 | 
90 |       // Advance time past expiration
91 |       await vi.advanceTimersByTimeAsync(1);
92 |       expect(read(key)).toBeUndefined();
93 |     });
94 | 
95 |     it('should reset the timer when an entry is updated', async () => {
96 |       vi.useFakeTimers();
97 |       const key = 'update-key';
98 |       const initialData = ['initial'];
99 |       const updatedData = ['updated'];
100 |       const ttl = 5000; // 5 seconds
101 | 
102 |       // Write initial data
103 |       write(key, initialData, ttl);
104 | 
105 |       // Advance time, but not enough to expire
106 |       await vi.advanceTimersByTimeAsync(3000);
107 |       expect(read(key)).toEqual(initialData);
108 | 
109 |       // Update the data, which should reset the timer
110 |       write(key, updatedData, ttl);
111 |       expect(read(key)).toEqual(updatedData);
112 | 
113 |       // Advance time again. If the timer wasn't reset, the total elapsed
114 |       // time (3000 + 3000 = 6000) would cause an eviction.
115 |       await vi.advanceTimersByTimeAsync(3000);
116 |       expect(read(key)).toEqual(updatedData);
117 | 
118 |       // Advance past the new expiration time
119 |       await vi.advanceTimersByTimeAsync(2001);
120 |       expect(read(key)).toBeUndefined();
121 |     });
122 |   });
123 | });
```

src/utils/filesearch/crawlCache.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import crypto from 'node:crypto';
8 | 
9 | const crawlCache = new Map<string, string[]>();
10 | const cacheTimers = new Map<string, NodeJS.Timeout>();
11 | 
12 | /**
13 |  * Generates a unique cache key based on the project directory and the content
14 |  * of ignore files. This ensures that the cache is invalidated if the project
15 |  * or ignore rules change.
16 |  */
17 | export const getCacheKey = (
18 |   directory: string,
19 |   ignoreContent: string,
20 |   maxDepth?: number,
21 | ): string => {
22 |   const hash = crypto.createHash('sha256');
23 |   hash.update(directory);
24 |   hash.update(ignoreContent);
25 |   if (maxDepth !== undefined) {
26 |     hash.update(String(maxDepth));
27 |   }
28 |   return hash.digest('hex');
29 | };
30 | 
31 | /**
32 |  * Reads cached data from the in-memory cache.
33 |  * Returns undefined if the key is not found.
34 |  */
35 | export const read = (key: string): string[] | undefined => crawlCache.get(key);
36 | 
37 | /**
38 |  * Writes data to the in-memory cache and sets a timer to evict it after the TTL.
39 |  */
40 | export const write = (key: string, results: string[], ttlMs: number): void => {
41 |   // Clear any existing timer for this key to prevent premature deletion
42 |   if (cacheTimers.has(key)) {
43 |     clearTimeout(cacheTimers.get(key)!);
44 |   }
45 | 
46 |   // Store the new data
47 |   crawlCache.set(key, results);
48 | 
49 |   // Set a timer to automatically delete the cache entry after the TTL
50 |   const timerId = setTimeout(() => {
51 |     crawlCache.delete(key);
52 |     cacheTimers.delete(key);
53 |   }, ttlMs);
54 | 
55 |   // Store the timer handle so we can clear it if the entry is updated
56 |   cacheTimers.set(key, timerId);
57 | };
58 | 
59 | /**
60 |  * Clears the entire cache and all active timers.
61 |  * Primarily used for testing.
62 |  */
63 | export const clear = (): void => {
64 |   for (const timerId of cacheTimers.values()) {
65 |     clearTimeout(timerId);
66 |   }
67 |   crawlCache.clear();
68 |   cacheTimers.clear();
69 | };
```

src/utils/filesearch/crawler.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, afterEach, vi, beforeEach } from 'vitest';
8 | import * as fs from 'node:fs/promises';
9 | import * as path from 'node:path';
10 | import * as cache from './crawlCache.js';
11 | import { crawl } from './crawler.js';
12 | import { createTmpDir, cleanupTmpDir } from '@google/gemini-cli-test-utils';
13 | import type { Ignore } from './ignore.js';
14 | import { loadIgnoreRules } from './ignore.js';
15 | 
16 | describe('crawler', () => {
17 |   let tmpDir: string;
18 |   afterEach(async () => {
19 |     if (tmpDir) {
20 |       await cleanupTmpDir(tmpDir);
21 |     }
22 |     vi.restoreAllMocks();
23 |   });
24 | 
25 |   it('should use .geminiignore rules', async () => {
26 |     tmpDir = await createTmpDir({
27 |       '.geminiignore': 'dist/',
28 |       dist: ['ignored.js'],
29 |       src: ['not-ignored.js'],
30 |     });
31 | 
32 |     const ignore = loadIgnoreRules({
33 |       projectRoot: tmpDir,
34 |       useGitignore: false,
35 |       useGeminiignore: true,
36 |       ignoreDirs: [],
37 |     });
38 | 
39 |     const results = await crawl({
40 |       crawlDirectory: tmpDir,
41 |       cwd: tmpDir,
42 |       ignore,
43 |       cache: false,
44 |       cacheTtl: 0,
45 |     });
46 | 
47 |     expect(results).toEqual(
48 |       expect.arrayContaining([
49 |         '.',
50 |         'src/',
51 |         '.geminiignore',
52 |         'src/not-ignored.js',
53 |       ]),
54 |     );
55 |   });
56 | 
57 |   it('should combine .gitignore and .geminiignore rules', async () => {
58 |     tmpDir = await createTmpDir({
59 |       '.gitignore': 'dist/',
60 |       '.geminiignore': 'build/',
61 |       dist: ['ignored-by-git.js'],
62 |       build: ['ignored-by-gemini.js'],
63 |       src: ['not-ignored.js'],
64 |     });
65 | 
66 |     const ignore = loadIgnoreRules({
67 |       projectRoot: tmpDir,
68 |       useGitignore: true,
69 |       useGeminiignore: true,
70 |       ignoreDirs: [],
71 |     });
72 | 
73 |     const results = await crawl({
74 |       crawlDirectory: tmpDir,
75 |       cwd: tmpDir,
76 |       ignore,
77 |       cache: false,
78 |       cacheTtl: 0,
79 |     });
80 | 
81 |     expect(results).toEqual(
82 |       expect.arrayContaining([
83 |         '.',
84 |         'src/',
85 |         '.geminiignore',
86 |         '.gitignore',
87 |         'src/not-ignored.js',
88 |       ]),
89 |     );
90 |   });
91 | 
92 |   it('should use ignoreDirs option', async () => {
93 |     tmpDir = await createTmpDir({
94 |       logs: ['some.log'],
95 |       src: ['main.js'],
96 |     });
97 | 
98 |     const ignore = loadIgnoreRules({
99 |       projectRoot: tmpDir,
100 |       useGitignore: false,
101 |       useGeminiignore: false,
102 |       ignoreDirs: ['logs'],
103 |     });
104 | 
105 |     const results = await crawl({
106 |       crawlDirectory: tmpDir,
107 |       cwd: tmpDir,
108 |       ignore,
109 |       cache: false,
110 |       cacheTtl: 0,
111 |     });
112 | 
113 |     expect(results).toEqual(
114 |       expect.arrayContaining(['.', 'src/', 'src/main.js']),
115 |     );
116 |   });
117 | 
118 |   it('should handle negated directories', async () => {
119 |     tmpDir = await createTmpDir({
120 |       '.gitignore': ['build/**', '!build/public', '!build/public/**'].join(
121 |         '\n',
122 |       ),
123 |       build: {
124 |         'private.js': '',
125 |         public: ['index.html'],
126 |       },
127 |       src: ['main.js'],
128 |     });
129 | 
130 |     const ignore = loadIgnoreRules({
131 |       projectRoot: tmpDir,
132 |       useGitignore: true,
133 |       useGeminiignore: false,
134 |       ignoreDirs: [],
135 |     });
136 | 
137 |     const results = await crawl({
138 |       crawlDirectory: tmpDir,
139 |       cwd: tmpDir,
140 |       ignore,
141 |       cache: false,
142 |       cacheTtl: 0,
143 |     });
144 | 
145 |     expect(results).toEqual(
146 |       expect.arrayContaining([
147 |         '.',
148 |         'build/',
149 |         'build/public/',
150 |         'src/',
151 |         '.gitignore',
152 |         'build/public/index.html',
153 |         'src/main.js',
154 |       ]),
155 |     );
156 |   });
157 | 
158 |   it('should handle root-level file negation', async () => {
159 |     tmpDir = await createTmpDir({
160 |       '.gitignore': ['*.mk', '!Foo.mk'].join('\n'),
161 |       'bar.mk': '',
162 |       'Foo.mk': '',
163 |     });
164 | 
165 |     const ignore = loadIgnoreRules({
166 |       projectRoot: tmpDir,
167 |       useGitignore: true,
168 |       useGeminiignore: false,
169 |       ignoreDirs: [],
170 |     });
171 | 
172 |     const results = await crawl({
173 |       crawlDirectory: tmpDir,
174 |       cwd: tmpDir,
175 |       ignore,
176 |       cache: false,
177 |       cacheTtl: 0,
178 |     });
179 | 
180 |     expect(results).toEqual(
181 |       expect.arrayContaining(['.', '.gitignore', 'Foo.mk', 'bar.mk']),
182 |     );
183 |   });
184 | 
185 |   it('should handle directory negation with glob', async () => {
186 |     tmpDir = await createTmpDir({
187 |       '.gitignore': [
188 |         'third_party/**',
189 |         '!third_party/foo',
190 |         '!third_party/foo/bar',
191 |         '!third_party/foo/bar/baz_buffer',
192 |       ].join('\n'),
193 |       third_party: {
194 |         foo: {
195 |           bar: {
196 |             baz_buffer: '',
197 |           },
198 |         },
199 |         ignore_this: '',
200 |       },
201 |     });
202 | 
203 |     const ignore = loadIgnoreRules({
204 |       projectRoot: tmpDir,
205 |       useGitignore: true,
206 |       useGeminiignore: false,
207 |       ignoreDirs: [],
208 |     });
209 | 
210 |     const results = await crawl({
211 |       crawlDirectory: tmpDir,
212 |       cwd: tmpDir,
213 |       ignore,
214 |       cache: false,
215 |       cacheTtl: 0,
216 |     });
217 | 
218 |     expect(results).toEqual(
219 |       expect.arrayContaining([
220 |         '.',
221 |         'third_party/',
222 |         'third_party/foo/',
223 |         'third_party/foo/bar/',
224 |         '.gitignore',
225 |         'third_party/foo/bar/baz_buffer',
226 |       ]),
227 |     );
228 |   });
229 | 
230 |   it('should correctly handle negated patterns in .gitignore', async () => {
231 |     tmpDir = await createTmpDir({
232 |       '.gitignore': ['dist/**', '!dist/keep.js'].join('\n'),
233 |       dist: ['ignore.js', 'keep.js'],
234 |       src: ['main.js'],
235 |     });
236 | 
237 |     const ignore = loadIgnoreRules({
238 |       projectRoot: tmpDir,
239 |       useGitignore: true,
240 |       useGeminiignore: false,
241 |       ignoreDirs: [],
242 |     });
243 | 
244 |     const results = await crawl({
245 |       crawlDirectory: tmpDir,
246 |       cwd: tmpDir,
247 |       ignore,
248 |       cache: false,
249 |       cacheTtl: 0,
250 |     });
251 | 
252 |     expect(results).toEqual(
253 |       expect.arrayContaining([
254 |         '.',
255 |         'dist/',
256 |         'src/',
257 |         '.gitignore',
258 |         'dist/keep.js',
259 |         'src/main.js',
260 |       ]),
261 |     );
262 |   });
263 | 
264 |   it('should initialize correctly when ignore files are missing', async () => {
265 |     tmpDir = await createTmpDir({
266 |       src: ['file1.js'],
267 |     });
268 | 
269 |     const ignore = loadIgnoreRules({
270 |       projectRoot: tmpDir,
271 |       useGitignore: true,
272 |       useGeminiignore: true,
273 |       ignoreDirs: [],
274 |     });
275 | 
276 |     const results = await crawl({
277 |       crawlDirectory: tmpDir,
278 |       cwd: tmpDir,
279 |       ignore,
280 |       cache: false,
281 |       cacheTtl: 0,
282 |     });
283 |     expect(results).toEqual(
284 |       expect.arrayContaining(['.', 'src/', 'src/file1.js']),
285 |     );
286 |   });
287 | 
288 |   it('should handle empty or commented-only ignore files', async () => {
289 |     tmpDir = await createTmpDir({
290 |       '.gitignore': '# This is a comment\n\n   \n',
291 |       src: ['main.js'],
292 |     });
293 | 
294 |     const ignore = loadIgnoreRules({
295 |       projectRoot: tmpDir,
296 |       useGitignore: true,
297 |       useGeminiignore: false,
298 |       ignoreDirs: [],
299 |     });
300 | 
301 |     const results = await crawl({
302 |       crawlDirectory: tmpDir,
303 |       cwd: tmpDir,
304 |       ignore,
305 |       cache: false,
306 |       cacheTtl: 0,
307 |     });
308 | 
309 |     expect(results).toEqual(
310 |       expect.arrayContaining(['.', 'src/', '.gitignore', 'src/main.js']),
311 |     );
312 |   });
313 | 
314 |   it('should always ignore the .git directory', async () => {
315 |     tmpDir = await createTmpDir({
316 |       '.git': ['config', 'HEAD'],
317 |       src: ['main.js'],
318 |     });
319 | 
320 |     const ignore = loadIgnoreRules({
321 |       projectRoot: tmpDir,
322 |       useGitignore: false,
323 |       useGeminiignore: false,
324 |       ignoreDirs: [],
325 |     });
326 | 
327 |     const results = await crawl({
328 |       crawlDirectory: tmpDir,
329 |       cwd: tmpDir,
330 |       ignore,
331 |       cache: false,
332 |       cacheTtl: 0,
333 |     });
334 | 
335 |     expect(results).toEqual(
336 |       expect.arrayContaining(['.', 'src/', 'src/main.js']),
337 |     );
338 |   });
339 | 
340 |   describe('with in-memory cache', () => {
341 |     beforeEach(() => {
342 |       cache.clear();
343 |       vi.useFakeTimers();
344 |     });
345 | 
346 |     afterEach(() => {
347 |       vi.useRealTimers();
348 |     });
349 | 
350 |     it('should hit the cache for subsequent crawls', async () => {
351 |       tmpDir = await createTmpDir({ 'file1.js': '' });
352 |       const ignore = loadIgnoreRules({
353 |         projectRoot: tmpDir,
354 |         useGitignore: false,
355 |         useGeminiignore: false,
356 |         ignoreDirs: [],
357 |       });
358 |       const options = {
359 |         crawlDirectory: tmpDir,
360 |         cwd: tmpDir,
361 |         ignore,
362 |         cache: true,
363 |         cacheTtl: 10,
364 |       };
365 | 
366 |       const crawlSpy = vi.spyOn(cache, 'read');
367 | 
368 |       await crawl(options);
369 |       expect(crawlSpy).toHaveBeenCalledTimes(1);
370 | 
371 |       await crawl(options);
372 |       expect(crawlSpy).toHaveBeenCalledTimes(2);
373 |       // fdir should not have been called a second time.
374 |       // We can't spy on it directly, but we can check the cache was hit.
375 |       const cacheKey = cache.getCacheKey(
376 |         options.crawlDirectory,
377 |         options.ignore.getFingerprint(),
378 |         undefined,
379 |       );
380 |       expect(cache.read(cacheKey)).toBeDefined();
381 |     });
382 | 
383 |     it('should miss the cache when ignore rules change', async () => {
384 |       tmpDir = await createTmpDir({
385 |         '.gitignore': 'a.txt',
386 |         'a.txt': '',
387 |         'b.txt': '',
388 |       });
389 |       const getIgnore = () =>
390 |         loadIgnoreRules({
391 |           projectRoot: tmpDir,
392 |           useGitignore: true,
393 |           useGeminiignore: false,
394 |           ignoreDirs: [],
395 |         });
396 |       const getOptions = (ignore: Ignore) => ({
397 |         crawlDirectory: tmpDir,
398 |         cwd: tmpDir,
399 |         ignore,
400 |         cache: true,
401 |         cacheTtl: 10000,
402 |       });
403 | 
404 |       // Initial crawl to populate the cache
405 |       const ignore1 = getIgnore();
406 |       const results1 = await crawl(getOptions(ignore1));
407 |       expect(results1).toEqual(
408 |         expect.arrayContaining(['.', '.gitignore', 'b.txt']),
409 |       );
410 | 
411 |       // Modify the ignore file
412 |       await fs.writeFile(path.join(tmpDir, '.gitignore'), 'b.txt');
413 | 
414 |       // Second crawl should miss the cache and trigger a recrawl
415 |       const ignore2 = getIgnore();
416 |       const results2 = await crawl(getOptions(ignore2));
417 |       expect(results2).toEqual(
418 |         expect.arrayContaining(['.', '.gitignore', 'a.txt']),
419 |       );
420 |     });
421 | 
422 |     it('should miss the cache after TTL expires', async () => {
423 |       tmpDir = await createTmpDir({ 'file1.js': '' });
424 |       const ignore = loadIgnoreRules({
425 |         projectRoot: tmpDir,
426 |         useGitignore: false,
427 |         useGeminiignore: false,
428 |         ignoreDirs: [],
429 |       });
430 |       const options = {
431 |         crawlDirectory: tmpDir,
432 |         cwd: tmpDir,
433 |         ignore,
434 |         cache: true,
435 |         cacheTtl: 10, // 10 seconds
436 |       };
437 | 
438 |       const readSpy = vi.spyOn(cache, 'read');
439 |       const writeSpy = vi.spyOn(cache, 'write');
440 | 
441 |       await crawl(options);
442 |       expect(readSpy).toHaveBeenCalledTimes(1);
443 |       expect(writeSpy).toHaveBeenCalledTimes(1);
444 | 
445 |       // Advance time past the TTL
446 |       await vi.advanceTimersByTimeAsync(11000);
447 | 
448 |       await crawl(options);
449 |       expect(readSpy).toHaveBeenCalledTimes(2);
450 |       expect(writeSpy).toHaveBeenCalledTimes(2);
451 |     });
452 | 
453 |     it('should miss the cache when maxDepth changes', async () => {
454 |       tmpDir = await createTmpDir({ 'file1.js': '' });
455 |       const ignore = loadIgnoreRules({
456 |         projectRoot: tmpDir,
457 |         useGitignore: false,
458 |         useGeminiignore: false,
459 |         ignoreDirs: [],
460 |       });
461 |       const getOptions = (maxDepth?: number) => ({
462 |         crawlDirectory: tmpDir,
463 |         cwd: tmpDir,
464 |         ignore,
465 |         cache: true,
466 |         cacheTtl: 10000,
467 |         maxDepth,
468 |       });
469 | 
470 |       const readSpy = vi.spyOn(cache, 'read');
471 |       const writeSpy = vi.spyOn(cache, 'write');
472 | 
473 |       // 1. First crawl with maxDepth: 1
474 |       await crawl(getOptions(1));
475 |       expect(readSpy).toHaveBeenCalledTimes(1);
476 |       expect(writeSpy).toHaveBeenCalledTimes(1);
477 | 
478 |       // 2. Second crawl with maxDepth: 2, should be a cache miss
479 |       await crawl(getOptions(2));
480 |       expect(readSpy).toHaveBeenCalledTimes(2);
481 |       expect(writeSpy).toHaveBeenCalledTimes(2);
482 | 
483 |       // 3. Third crawl with maxDepth: 1 again, should be a cache hit.
484 |       await crawl(getOptions(1));
485 |       expect(readSpy).toHaveBeenCalledTimes(3);
486 |       expect(writeSpy).toHaveBeenCalledTimes(2); // No new write
487 |     });
488 |   });
489 | 
490 |   describe('with maxDepth', () => {
491 |     beforeEach(async () => {
492 |       tmpDir = await createTmpDir({
493 |         'file-root.txt': '',
494 |         level1: {
495 |           'file-level1.txt': '',
496 |           level2: {
497 |             'file-level2.txt': '',
498 |             level3: {
499 |               'file-level3.txt': '',
500 |             },
501 |           },
502 |         },
503 |       });
504 |     });
505 | 
506 |     const getCrawlResults = (maxDepth?: number) => {
507 |       const ignore = loadIgnoreRules({
508 |         projectRoot: tmpDir,
509 |         useGitignore: false,
510 |         useGeminiignore: false,
511 |         ignoreDirs: [],
512 |       });
513 |       return crawl({
514 |         crawlDirectory: tmpDir,
515 |         cwd: tmpDir,
516 |         ignore,
517 |         cache: false,
518 |         cacheTtl: 0,
519 |         maxDepth,
520 |       });
521 |     };
522 | 
523 |     it('should only crawl top-level files when maxDepth is 0', async () => {
524 |       const results = await getCrawlResults(0);
525 |       expect(results).toEqual(
526 |         expect.arrayContaining(['.', 'level1/', 'file-root.txt']),
527 |       );
528 |     });
529 | 
530 |     it('should crawl one level deep when maxDepth is 1', async () => {
531 |       const results = await getCrawlResults(1);
532 |       expect(results).toEqual(
533 |         expect.arrayContaining([
534 |           '.',
535 |           'level1/',
536 |           'level1/level2/',
537 |           'file-root.txt',
538 |           'level1/file-level1.txt',
539 |         ]),
540 |       );
541 |     });
542 | 
543 |     it('should crawl two levels deep when maxDepth is 2', async () => {
544 |       const results = await getCrawlResults(2);
545 |       expect(results).toEqual(
546 |         expect.arrayContaining([
547 |           '.',
548 |           'level1/',
549 |           'level1/level2/',
550 |           'level1/level2/level3/',
551 |           'file-root.txt',
552 |           'level1/file-level1.txt',
553 |           'level1/level2/file-level2.txt',
554 |         ]),
555 |       );
556 |     });
557 | 
558 |     it('should perform a full recursive crawl when maxDepth is undefined', async () => {
559 |       const results = await getCrawlResults(undefined);
560 |       expect(results).toEqual(
561 |         expect.arrayContaining([
562 |           '.',
563 |           'level1/',
564 |           'level1/level2/',
565 |           'level1/level2/level3/',
566 |           'file-root.txt',
567 |           'level1/file-level1.txt',
568 |           'level1/level2/file-level2.txt',
569 |           'level1/level2/level3/file-level3.txt',
570 |         ]),
571 |       );
572 |     });
573 |   });
574 | });
```

src/utils/filesearch/crawler.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import path from 'node:path';
8 | import { fdir } from 'fdir';
9 | import type { Ignore } from './ignore.js';
10 | import * as cache from './crawlCache.js';
11 | 
12 | export interface CrawlOptions {
13 |   // The directory to start the crawl from.
14 |   crawlDirectory: string;
15 |   // The project's root directory, for path relativity.
16 |   cwd: string;
17 |   // The fdir maxDepth option.
18 |   maxDepth?: number;
19 |   // A pre-configured Ignore instance.
20 |   ignore: Ignore;
21 |   // Caching options.
22 |   cache: boolean;
23 |   cacheTtl: number;
24 | }
25 | 
26 | function toPosixPath(p: string) {
27 |   return p.split(path.sep).join(path.posix.sep);
28 | }
29 | 
30 | export async function crawl(options: CrawlOptions): Promise<string[]> {
31 |   if (options.cache) {
32 |     const cacheKey = cache.getCacheKey(
33 |       options.crawlDirectory,
34 |       options.ignore.getFingerprint(),
35 |       options.maxDepth,
36 |     );
37 |     const cachedResults = cache.read(cacheKey);
38 | 
39 |     if (cachedResults) {
40 |       return cachedResults;
41 |     }
42 |   }
43 | 
44 |   const posixCwd = toPosixPath(options.cwd);
45 |   const posixCrawlDirectory = toPosixPath(options.crawlDirectory);
46 | 
47 |   let results: string[];
48 |   try {
49 |     const dirFilter = options.ignore.getDirectoryFilter();
50 |     const api = new fdir()
51 |       .withRelativePaths()
52 |       .withDirs()
53 |       .withPathSeparator('/') // Always use unix style paths
54 |       .exclude((_, dirPath) => {
55 |         const relativePath = path.posix.relative(posixCrawlDirectory, dirPath);
56 |         return dirFilter(`${relativePath}/`);
57 |       });
58 | 
59 |     if (options.maxDepth !== undefined) {
60 |       api.withMaxDepth(options.maxDepth);
61 |     }
62 | 
63 |     results = await api.crawl(options.crawlDirectory).withPromise();
64 |   } catch (_e) {
65 |     // The directory probably doesn't exist.
66 |     return [];
67 |   }
68 | 
69 |   const relativeToCrawlDir = path.posix.relative(posixCwd, posixCrawlDirectory);
70 | 
71 |   const relativeToCwdResults = results.map((p) =>
72 |     path.posix.join(relativeToCrawlDir, p),
73 |   );
74 | 
75 |   if (options.cache) {
76 |     const cacheKey = cache.getCacheKey(
77 |       options.crawlDirectory,
78 |       options.ignore.getFingerprint(),
79 |       options.maxDepth,
80 |     );
81 |     cache.write(cacheKey, relativeToCwdResults, options.cacheTtl * 1000);
82 |   }
83 | 
84 |   return relativeToCwdResults;
85 | }
```

src/utils/filesearch/fileSearch.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, afterEach, vi } from 'vitest';
8 | import { FileSearchFactory, AbortError, filter } from './fileSearch.js';
9 | import { createTmpDir, cleanupTmpDir } from '@google/gemini-cli-test-utils';
10 | 
11 | describe('FileSearch', () => {
12 |   let tmpDir: string;
13 |   afterEach(async () => {
14 |     if (tmpDir) {
15 |       await cleanupTmpDir(tmpDir);
16 |     }
17 |     vi.restoreAllMocks();
18 |   });
19 | 
20 |   it('should use .geminiignore rules', async () => {
21 |     tmpDir = await createTmpDir({
22 |       '.geminiignore': 'dist/',
23 |       dist: ['ignored.js'],
24 |       src: ['not-ignored.js'],
25 |     });
26 | 
27 |     const fileSearch = FileSearchFactory.create({
28 |       projectRoot: tmpDir,
29 |       useGitignore: false,
30 |       useGeminiignore: true,
31 |       ignoreDirs: [],
32 |       cache: false,
33 |       cacheTtl: 0,
34 |       enableRecursiveFileSearch: true,
35 |       disableFuzzySearch: false,
36 |     });
37 | 
38 |     await fileSearch.initialize();
39 |     const results = await fileSearch.search('');
40 | 
41 |     expect(results).toEqual(['src/', '.geminiignore', 'src/not-ignored.js']);
42 |   });
43 | 
44 |   it('should combine .gitignore and .geminiignore rules', async () => {
45 |     tmpDir = await createTmpDir({
46 |       '.gitignore': 'dist/',
47 |       '.geminiignore': 'build/',
48 |       dist: ['ignored-by-git.js'],
49 |       build: ['ignored-by-gemini.js'],
50 |       src: ['not-ignored.js'],
51 |     });
52 | 
53 |     const fileSearch = FileSearchFactory.create({
54 |       projectRoot: tmpDir,
55 |       useGitignore: true,
56 |       useGeminiignore: true,
57 |       ignoreDirs: [],
58 |       cache: false,
59 |       cacheTtl: 0,
60 |       enableRecursiveFileSearch: true,
61 |       disableFuzzySearch: false,
62 |     });
63 | 
64 |     await fileSearch.initialize();
65 |     const results = await fileSearch.search('');
66 | 
67 |     expect(results).toEqual([
68 |       'src/',
69 |       '.geminiignore',
70 |       '.gitignore',
71 |       'src/not-ignored.js',
72 |     ]);
73 |   });
74 | 
75 |   it('should use ignoreDirs option', async () => {
76 |     tmpDir = await createTmpDir({
77 |       logs: ['some.log'],
78 |       src: ['main.js'],
79 |     });
80 | 
81 |     const fileSearch = FileSearchFactory.create({
82 |       projectRoot: tmpDir,
83 |       useGitignore: false,
84 |       useGeminiignore: false,
85 |       ignoreDirs: ['logs'],
86 |       cache: false,
87 |       cacheTtl: 0,
88 |       enableRecursiveFileSearch: true,
89 |       disableFuzzySearch: false,
90 |     });
91 | 
92 |     await fileSearch.initialize();
93 |     const results = await fileSearch.search('');
94 | 
95 |     expect(results).toEqual(['src/', 'src/main.js']);
96 |   });
97 | 
98 |   it('should handle negated directories', async () => {
99 |     tmpDir = await createTmpDir({
100 |       '.gitignore': ['build/**', '!build/public', '!build/public/**'].join(
101 |         '\n',
102 |       ),
103 |       build: {
104 |         'private.js': '',
105 |         public: ['index.html'],
106 |       },
107 |       src: ['main.js'],
108 |     });
109 | 
110 |     const fileSearch = FileSearchFactory.create({
111 |       projectRoot: tmpDir,
112 |       useGitignore: true,
113 |       useGeminiignore: false,
114 |       ignoreDirs: [],
115 |       cache: false,
116 |       cacheTtl: 0,
117 |       enableRecursiveFileSearch: true,
118 |       disableFuzzySearch: false,
119 |     });
120 | 
121 |     await fileSearch.initialize();
122 |     const results = await fileSearch.search('');
123 | 
124 |     expect(results).toEqual([
125 |       'build/',
126 |       'build/public/',
127 |       'src/',
128 |       '.gitignore',
129 |       'build/public/index.html',
130 |       'src/main.js',
131 |     ]);
132 |   });
133 | 
134 |   it('should filter results with a search pattern', async () => {
135 |     tmpDir = await createTmpDir({
136 |       src: {
137 |         'main.js': '',
138 |         'util.ts': '',
139 |         'style.css': '',
140 |       },
141 |     });
142 | 
143 |     const fileSearch = FileSearchFactory.create({
144 |       projectRoot: tmpDir,
145 |       useGitignore: false,
146 |       useGeminiignore: false,
147 |       ignoreDirs: [],
148 |       cache: false,
149 |       cacheTtl: 0,
150 |       enableRecursiveFileSearch: true,
151 |       disableFuzzySearch: false,
152 |     });
153 | 
154 |     await fileSearch.initialize();
155 |     const results = await fileSearch.search('**/*.js');
156 | 
157 |     expect(results).toEqual(['src/main.js']);
158 |   });
159 | 
160 |   it('should handle root-level file negation', async () => {
161 |     tmpDir = await createTmpDir({
162 |       '.gitignore': ['*.mk', '!Foo.mk'].join('\n'),
163 |       'bar.mk': '',
164 |       'Foo.mk': '',
165 |     });
166 | 
167 |     const fileSearch = FileSearchFactory.create({
168 |       projectRoot: tmpDir,
169 |       useGitignore: true,
170 |       useGeminiignore: false,
171 |       ignoreDirs: [],
172 |       cache: false,
173 |       cacheTtl: 0,
174 |       enableRecursiveFileSearch: true,
175 |       disableFuzzySearch: false,
176 |     });
177 | 
178 |     await fileSearch.initialize();
179 |     const results = await fileSearch.search('');
180 | 
181 |     expect(results).toEqual(['.gitignore', 'Foo.mk']);
182 |   });
183 | 
184 |   it('should handle directory negation with glob', async () => {
185 |     tmpDir = await createTmpDir({
186 |       '.gitignore': [
187 |         'third_party/**',
188 |         '!third_party/foo',
189 |         '!third_party/foo/bar',
190 |         '!third_party/foo/bar/baz_buffer',
191 |       ].join('\n'),
192 |       third_party: {
193 |         foo: {
194 |           bar: {
195 |             baz_buffer: '',
196 |           },
197 |         },
198 |         ignore_this: '',
199 |       },
200 |     });
201 | 
202 |     const fileSearch = FileSearchFactory.create({
203 |       projectRoot: tmpDir,
204 |       useGitignore: true,
205 |       useGeminiignore: false,
206 |       ignoreDirs: [],
207 |       cache: false,
208 |       cacheTtl: 0,
209 |       enableRecursiveFileSearch: true,
210 |       disableFuzzySearch: false,
211 |     });
212 | 
213 |     await fileSearch.initialize();
214 |     const results = await fileSearch.search('');
215 | 
216 |     expect(results).toEqual([
217 |       'third_party/',
218 |       'third_party/foo/',
219 |       'third_party/foo/bar/',
220 |       '.gitignore',
221 |       'third_party/foo/bar/baz_buffer',
222 |     ]);
223 |   });
224 | 
225 |   it('should correctly handle negated patterns in .gitignore', async () => {
226 |     tmpDir = await createTmpDir({
227 |       '.gitignore': ['dist/**', '!dist/keep.js'].join('\n'),
228 |       dist: ['ignore.js', 'keep.js'],
229 |       src: ['main.js'],
230 |     });
231 | 
232 |     const fileSearch = FileSearchFactory.create({
233 |       projectRoot: tmpDir,
234 |       useGitignore: true,
235 |       useGeminiignore: false,
236 |       ignoreDirs: [],
237 |       cache: false,
238 |       cacheTtl: 0,
239 |       enableRecursiveFileSearch: true,
240 |       disableFuzzySearch: false,
241 |     });
242 | 
243 |     await fileSearch.initialize();
244 |     const results = await fileSearch.search('');
245 | 
246 |     expect(results).toEqual([
247 |       'dist/',
248 |       'src/',
249 |       '.gitignore',
250 |       'dist/keep.js',
251 |       'src/main.js',
252 |     ]);
253 |   });
254 | 
255 |   // New test cases start here
256 | 
257 |   it('should initialize correctly when ignore files are missing', async () => {
258 |     tmpDir = await createTmpDir({
259 |       src: ['file1.js'],
260 |     });
261 | 
262 |     const fileSearch = FileSearchFactory.create({
263 |       projectRoot: tmpDir,
264 |       useGitignore: true,
265 |       useGeminiignore: true,
266 |       ignoreDirs: [],
267 |       cache: false,
268 |       cacheTtl: 0,
269 |       enableRecursiveFileSearch: true,
270 |       disableFuzzySearch: false,
271 |     });
272 | 
273 |     // Expect no errors to be thrown during initialization
274 |     await expect(fileSearch.initialize()).resolves.toBeUndefined();
275 |     const results = await fileSearch.search('');
276 |     expect(results).toEqual(['src/', 'src/file1.js']);
277 |   });
278 | 
279 |   it('should respect maxResults option in search', async () => {
280 |     tmpDir = await createTmpDir({
281 |       src: {
282 |         'file1.js': '',
283 |         'file2.js': '',
284 |         'file3.js': '',
285 |         'file4.js': '',
286 |       },
287 |     });
288 | 
289 |     const fileSearch = FileSearchFactory.create({
290 |       projectRoot: tmpDir,
291 |       useGitignore: false,
292 |       useGeminiignore: false,
293 |       ignoreDirs: [],
294 |       cache: false,
295 |       cacheTtl: 0,
296 |       enableRecursiveFileSearch: true,
297 |       disableFuzzySearch: false,
298 |     });
299 | 
300 |     await fileSearch.initialize();
301 |     const results = await fileSearch.search('**/*.js', { maxResults: 2 });
302 | 
303 |     expect(results).toEqual(['src/file1.js', 'src/file2.js']); // Assuming alphabetical sort
304 |   });
305 | 
306 |   it('should use fzf for fuzzy matching when pattern does not contain wildcards', async () => {
307 |     tmpDir = await createTmpDir({
308 |       src: {
309 |         'main.js': '',
310 |         'util.ts': '',
311 |         'style.css': '',
312 |       },
313 |     });
314 | 
315 |     const fileSearch = FileSearchFactory.create({
316 |       projectRoot: tmpDir,
317 |       useGitignore: false,
318 |       useGeminiignore: false,
319 |       ignoreDirs: [],
320 |       cache: false,
321 |       cacheTtl: 0,
322 |       enableRecursiveFileSearch: true,
323 |       disableFuzzySearch: false,
324 |     });
325 | 
326 |     await fileSearch.initialize();
327 |     const results = await fileSearch.search('sst');
328 | 
329 |     expect(results).toEqual(['src/style.css']);
330 |   });
331 | 
332 |   it('should not use fzf for fuzzy matching when disableFuzzySearch is true', async () => {
333 |     tmpDir = await createTmpDir({
334 |       src: {
335 |         'file1.js': '',
336 |         'flexible.js': '',
337 |         'other.ts': '',
338 |       },
339 |     });
340 | 
341 |     const fileSearch = FileSearchFactory.create({
342 |       projectRoot: tmpDir,
343 |       useGitignore: false,
344 |       useGeminiignore: false,
345 |       ignoreDirs: [],
346 |       cache: false,
347 |       cacheTtl: 0,
348 |       enableRecursiveFileSearch: true,
349 |       disableFuzzySearch: true,
350 |     });
351 | 
352 |     await fileSearch.initialize();
353 |     const results = await fileSearch.search('fle');
354 | 
355 |     expect(results).toEqual(['src/flexible.js']);
356 |   });
357 | 
358 |   it('should use fzf for fuzzy matching when disableFuzzySearch is false', async () => {
359 |     tmpDir = await createTmpDir({
360 |       src: {
361 |         'file1.js': '',
362 |         'flexible.js': '',
363 |         'other.ts': '',
364 |       },
365 |     });
366 | 
367 |     const fileSearch = FileSearchFactory.create({
368 |       projectRoot: tmpDir,
369 |       useGitignore: false,
370 |       useGeminiignore: false,
371 |       ignoreDirs: [],
372 |       cache: false,
373 |       cacheTtl: 0,
374 |       enableRecursiveFileSearch: true,
375 |       disableFuzzySearch: false,
376 |     });
377 | 
378 |     await fileSearch.initialize();
379 |     const results = await fileSearch.search('fle');
380 | 
381 |     expect(results).toEqual(
382 |       expect.arrayContaining(['src/file1.js', 'src/flexible.js']),
383 |     );
384 |   });
385 | 
386 |   it('should return empty array when no matches are found', async () => {
387 |     tmpDir = await createTmpDir({
388 |       src: ['file1.js'],
389 |     });
390 | 
391 |     const fileSearch = FileSearchFactory.create({
392 |       projectRoot: tmpDir,
393 |       useGitignore: false,
394 |       useGeminiignore: false,
395 |       ignoreDirs: [],
396 |       cache: false,
397 |       cacheTtl: 0,
398 |       enableRecursiveFileSearch: true,
399 |       disableFuzzySearch: false,
400 |     });
401 | 
402 |     await fileSearch.initialize();
403 |     const results = await fileSearch.search('nonexistent-file.xyz');
404 | 
405 |     expect(results).toEqual([]);
406 |   });
407 | 
408 |   it('should throw AbortError when filter is aborted', async () => {
409 |     const controller = new AbortController();
410 |     const dummyPaths = Array.from({ length: 5000 }, (_, i) => `file${i}.js`); // Large array to ensure yielding
411 | 
412 |     const filterPromise = filter(dummyPaths, '*.js', controller.signal);
413 | 
414 |     // Abort after a short delay to ensure filter has started
415 |     setTimeout(() => controller.abort(), 1);
416 | 
417 |     await expect(filterPromise).rejects.toThrow(AbortError);
418 |   });
419 | 
420 |   it('should throw an error if search is called before initialization', async () => {
421 |     tmpDir = await createTmpDir({});
422 |     const fileSearch = FileSearchFactory.create({
423 |       projectRoot: tmpDir,
424 |       useGitignore: false,
425 |       useGeminiignore: false,
426 |       ignoreDirs: [],
427 |       cache: false,
428 |       cacheTtl: 0,
429 |       enableRecursiveFileSearch: true,
430 |       disableFuzzySearch: false,
431 |     });
432 | 
433 |     await expect(fileSearch.search('')).rejects.toThrow(
434 |       'Engine not initialized. Call initialize() first.',
435 |     );
436 |   });
437 | 
438 |   it('should handle empty or commented-only ignore files', async () => {
439 |     tmpDir = await createTmpDir({
440 |       '.gitignore': '# This is a comment\n\n   \n',
441 |       src: ['main.js'],
442 |     });
443 | 
444 |     const fileSearch = FileSearchFactory.create({
445 |       projectRoot: tmpDir,
446 |       useGitignore: true,
447 |       useGeminiignore: false,
448 |       ignoreDirs: [],
449 |       cache: false,
450 |       cacheTtl: 0,
451 |       enableRecursiveFileSearch: true,
452 |       disableFuzzySearch: false,
453 |     });
454 | 
455 |     await fileSearch.initialize();
456 |     const results = await fileSearch.search('');
457 | 
458 |     expect(results).toEqual(['src/', '.gitignore', 'src/main.js']);
459 |   });
460 | 
461 |   it('should always ignore the .git directory', async () => {
462 |     tmpDir = await createTmpDir({
463 |       '.git': ['config', 'HEAD'],
464 |       src: ['main.js'],
465 |     });
466 | 
467 |     const fileSearch = FileSearchFactory.create({
468 |       projectRoot: tmpDir,
469 |       useGitignore: false, // Explicitly disable .gitignore to isolate this rule
470 |       useGeminiignore: false,
471 |       ignoreDirs: [],
472 |       cache: false,
473 |       cacheTtl: 0,
474 |       enableRecursiveFileSearch: true,
475 |       disableFuzzySearch: false,
476 |     });
477 | 
478 |     await fileSearch.initialize();
479 |     const results = await fileSearch.search('');
480 | 
481 |     expect(results).toEqual(['src/', 'src/main.js']);
482 |   });
483 | 
484 |   it('should be cancellable via AbortSignal', async () => {
485 |     const largeDir: Record<string, string> = {};
486 |     for (let i = 0; i < 100; i++) {
487 |       largeDir[`file${i}.js`] = '';
488 |     }
489 |     tmpDir = await createTmpDir(largeDir);
490 | 
491 |     const fileSearch = FileSearchFactory.create({
492 |       projectRoot: tmpDir,
493 |       useGitignore: false,
494 |       useGeminiignore: false,
495 |       ignoreDirs: [],
496 |       cache: false,
497 |       cacheTtl: 0,
498 |       enableRecursiveFileSearch: true,
499 |       disableFuzzySearch: false,
500 |     });
501 | 
502 |     await fileSearch.initialize();
503 | 
504 |     const controller = new AbortController();
505 |     const searchPromise = fileSearch.search('**/*.js', {
506 |       signal: controller.signal,
507 |     });
508 | 
509 |     // Yield to allow the search to start before aborting.
510 |     await new Promise((resolve) => setImmediate(resolve));
511 | 
512 |     controller.abort();
513 | 
514 |     await expect(searchPromise).rejects.toThrow(AbortError);
515 |   });
516 | 
517 |   it('should leverage ResultCache for bestBaseQuery optimization', async () => {
518 |     tmpDir = await createTmpDir({
519 |       src: {
520 |         'foo.js': '',
521 |         'bar.ts': '',
522 |         nested: {
523 |           'baz.js': '',
524 |         },
525 |       },
526 |     });
527 | 
528 |     const fileSearch = FileSearchFactory.create({
529 |       projectRoot: tmpDir,
530 |       useGitignore: false,
531 |       useGeminiignore: false,
532 |       ignoreDirs: [],
533 |       cache: true, // Enable caching for this test
534 |       cacheTtl: 0,
535 |       enableRecursiveFileSearch: true,
536 |       disableFuzzySearch: false,
537 |     });
538 | 
539 |     await fileSearch.initialize();
540 | 
541 |     // Perform a broad search to prime the cache
542 |     const broadResults = await fileSearch.search('src/**');
543 |     expect(broadResults).toEqual([
544 |       'src/',
545 |       'src/nested/',
546 |       'src/bar.ts',
547 |       'src/foo.js',
548 |       'src/nested/baz.js',
549 |     ]);
550 | 
551 |     // Perform a more specific search that should leverage the broad search's cached results
552 |     const specificResults = await fileSearch.search('src/**/*.js');
553 |     expect(specificResults).toEqual(['src/foo.js', 'src/nested/baz.js']);
554 | 
555 |     // Although we can't directly inspect ResultCache.hits/misses from here,
556 |     // the correctness of specificResults after a broad search implicitly
557 |     // verifies that the caching mechanism, including bestBaseQuery, is working.
558 |   });
559 | 
560 |   it('should be case-insensitive by default', async () => {
561 |     tmpDir = await createTmpDir({
562 |       'File1.Js': '',
563 |       'file2.js': '',
564 |       'FILE3.JS': '',
565 |       'other.txt': '',
566 |     });
567 | 
568 |     const fileSearch = FileSearchFactory.create({
569 |       projectRoot: tmpDir,
570 |       useGitignore: false,
571 |       useGeminiignore: false,
572 |       ignoreDirs: [],
573 |       cache: false,
574 |       cacheTtl: 0,
575 |       enableRecursiveFileSearch: true,
576 |       disableFuzzySearch: false,
577 |     });
578 | 
579 |     await fileSearch.initialize();
580 | 
581 |     // Search with a lowercase pattern
582 |     let results = await fileSearch.search('file*.js');
583 |     expect(results).toHaveLength(3);
584 |     expect(results).toEqual(
585 |       expect.arrayContaining(['File1.Js', 'file2.js', 'FILE3.JS']),
586 |     );
587 | 
588 |     // Search with an uppercase pattern
589 |     results = await fileSearch.search('FILE*.JS');
590 |     expect(results).toHaveLength(3);
591 |     expect(results).toEqual(
592 |       expect.arrayContaining(['File1.Js', 'file2.js', 'FILE3.JS']),
593 |     );
594 | 
595 |     // Search with a mixed-case pattern
596 |     results = await fileSearch.search('FiLe*.Js');
597 |     expect(results).toHaveLength(3);
598 |     expect(results).toEqual(
599 |       expect.arrayContaining(['File1.Js', 'file2.js', 'FILE3.JS']),
600 |     );
601 |   });
602 | 
603 |   it('should respect maxResults even when the cache returns an exact match', async () => {
604 |     tmpDir = await createTmpDir({
605 |       'file1.js': '',
606 |       'file2.js': '',
607 |       'file3.js': '',
608 |       'file4.js': '',
609 |       'file5.js': '',
610 |     });
611 | 
612 |     const fileSearch = FileSearchFactory.create({
613 |       projectRoot: tmpDir,
614 |       useGitignore: false,
615 |       useGeminiignore: false,
616 |       ignoreDirs: [],
617 |       cache: true, // Ensure caching is enabled
618 |       cacheTtl: 10000,
619 |       enableRecursiveFileSearch: true,
620 |       disableFuzzySearch: false,
621 |     });
622 | 
623 |     await fileSearch.initialize();
624 | 
625 |     // 1. Perform a broad search to populate the cache with an exact match.
626 |     const initialResults = await fileSearch.search('*.js');
627 |     expect(initialResults).toEqual([
628 |       'file1.js',
629 |       'file2.js',
630 |       'file3.js',
631 |       'file4.js',
632 |       'file5.js',
633 |     ]);
634 | 
635 |     // 2. Perform the same search again, but this time with a maxResults limit.
636 |     const limitedResults = await fileSearch.search('*.js', { maxResults: 2 });
637 | 
638 |     // 3. Assert that the maxResults limit was respected, even with a cache hit.
639 |     expect(limitedResults).toEqual(['file1.js', 'file2.js']);
640 |   });
641 | 
642 |   it('should handle file paths with special characters that need escaping', async () => {
643 |     tmpDir = await createTmpDir({
644 |       src: {
645 |         'file with (special) chars.txt': '',
646 |         'another-file.txt': '',
647 |       },
648 |     });
649 | 
650 |     const fileSearch = FileSearchFactory.create({
651 |       projectRoot: tmpDir,
652 |       useGitignore: false,
653 |       useGeminiignore: false,
654 |       ignoreDirs: [],
655 |       cache: false,
656 |       cacheTtl: 0,
657 |       enableRecursiveFileSearch: true,
658 |       disableFuzzySearch: false,
659 |     });
660 | 
661 |     await fileSearch.initialize();
662 | 
663 |     // Search for the file using a pattern that contains special characters.
664 |     // The `unescapePath` function should handle the escaped path correctly.
665 |     const results = await fileSearch.search(
666 |       'src/file with \\(special\\) chars.txt',
667 |     );
668 | 
669 |     expect(results).toEqual(['src/file with (special) chars.txt']);
670 |   });
671 | 
672 |   describe('DirectoryFileSearch', () => {
673 |     it('should search for files in the current directory', async () => {
674 |       tmpDir = await createTmpDir({
675 |         'file1.js': '',
676 |         'file2.ts': '',
677 |         'file3.js': '',
678 |       });
679 | 
680 |       const fileSearch = FileSearchFactory.create({
681 |         projectRoot: tmpDir,
682 |         useGitignore: false,
683 |         useGeminiignore: false,
684 |         ignoreDirs: [],
685 |         cache: false,
686 |         cacheTtl: 0,
687 |         enableRecursiveFileSearch: false,
688 |         disableFuzzySearch: false,
689 |       });
690 | 
691 |       await fileSearch.initialize();
692 |       const results = await fileSearch.search('*.js');
693 |       expect(results).toEqual(['file1.js', 'file3.js']);
694 |     });
695 | 
[TRUNCATED]
```

src/utils/filesearch/fileSearch.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import path from 'node:path';
8 | import picomatch from 'picomatch';
9 | import type { Ignore } from './ignore.js';
10 | import { loadIgnoreRules } from './ignore.js';
11 | import { ResultCache } from './result-cache.js';
12 | import { crawl } from './crawler.js';
13 | import type { FzfResultItem } from 'fzf';
14 | import { AsyncFzf } from 'fzf';
15 | import { unescapePath } from '../paths.js';
16 | 
17 | export interface FileSearchOptions {
18 |   projectRoot: string;
19 |   ignoreDirs: string[];
20 |   useGitignore: boolean;
21 |   useGeminiignore: boolean;
22 |   cache: boolean;
23 |   cacheTtl: number;
24 |   enableRecursiveFileSearch: boolean;
25 |   disableFuzzySearch: boolean;
26 |   maxDepth?: number;
27 | }
28 | 
29 | export class AbortError extends Error {
30 |   constructor(message = 'Search aborted') {
31 |     super(message);
32 |     this.name = 'AbortError';
33 |   }
34 | }
35 | 
36 | /**
37 |  * Filters a list of paths based on a given pattern.
38 |  * @param allPaths The list of all paths to filter.
39 |  * @param pattern The picomatch pattern to filter by.
40 |  * @param signal An AbortSignal to cancel the operation.
41 |  * @returns A promise that resolves to the filtered and sorted list of paths.
42 |  */
43 | export async function filter(
44 |   allPaths: string[],
45 |   pattern: string,
46 |   signal: AbortSignal | undefined,
47 | ): Promise<string[]> {
48 |   const patternFilter = picomatch(pattern, {
49 |     dot: true,
50 |     contains: true,
51 |     nocase: true,
52 |   });
53 | 
54 |   const results: string[] = [];
55 |   for (const [i, p] of allPaths.entries()) {
56 |     // Yield control to the event loop periodically to prevent blocking.
57 |     if (i % 1000 === 0) {
58 |       await new Promise((resolve) => setImmediate(resolve));
59 |       if (signal?.aborted) {
60 |         throw new AbortError();
61 |       }
62 |     }
63 | 
64 |     if (patternFilter(p)) {
65 |       results.push(p);
66 |     }
67 |   }
68 | 
69 |   results.sort((a, b) => {
70 |     const aIsDir = a.endsWith('/');
71 |     const bIsDir = b.endsWith('/');
72 | 
73 |     if (aIsDir && !bIsDir) return -1;
74 |     if (!aIsDir && bIsDir) return 1;
75 | 
76 |     // This is 40% faster than localeCompare and the only thing we would really
77 |     // gain from localeCompare is case-sensitive sort
78 |     return a < b ? -1 : a > b ? 1 : 0;
79 |   });
80 | 
81 |   return results;
82 | }
83 | 
84 | export interface SearchOptions {
85 |   signal?: AbortSignal;
86 |   maxResults?: number;
87 | }
88 | 
89 | export interface FileSearch {
90 |   initialize(): Promise<void>;
91 |   search(pattern: string, options?: SearchOptions): Promise<string[]>;
92 | }
93 | 
94 | class RecursiveFileSearch implements FileSearch {
95 |   private ignore: Ignore | undefined;
96 |   private resultCache: ResultCache | undefined;
97 |   private allFiles: string[] = [];
98 |   private fzf: AsyncFzf<string[]> | undefined;
99 | 
100 |   constructor(private readonly options: FileSearchOptions) {}
101 | 
102 |   async initialize(): Promise<void> {
103 |     this.ignore = loadIgnoreRules(this.options);
104 | 
105 |     this.allFiles = await crawl({
106 |       crawlDirectory: this.options.projectRoot,
107 |       cwd: this.options.projectRoot,
108 |       ignore: this.ignore,
109 |       cache: this.options.cache,
110 |       cacheTtl: this.options.cacheTtl,
111 |       maxDepth: this.options.maxDepth,
112 |     });
113 |     this.buildResultCache();
114 |   }
115 | 
116 |   async search(
117 |     pattern: string,
118 |     options: SearchOptions = {},
119 |   ): Promise<string[]> {
120 |     if (
121 |       !this.resultCache ||
122 |       (!this.fzf && !this.options.disableFuzzySearch) ||
123 |       !this.ignore
124 |     ) {
125 |       throw new Error('Engine not initialized. Call initialize() first.');
126 |     }
127 | 
128 |     pattern = unescapePath(pattern) || '*';
129 | 
130 |     let filteredCandidates;
131 |     const { files: candidates, isExactMatch } =
132 |       await this.resultCache!.get(pattern);
133 | 
134 |     if (isExactMatch) {
135 |       // Use the cached result.
136 |       filteredCandidates = candidates;
137 |     } else {
138 |       let shouldCache = true;
139 |       if (pattern.includes('*') || !this.fzf) {
140 |         filteredCandidates = await filter(candidates, pattern, options.signal);
141 |       } else {
142 |         filteredCandidates = await this.fzf
143 |           .find(pattern)
144 |           .then((results: Array<FzfResultItem<string>>) =>
145 |             results.map((entry: FzfResultItem<string>) => entry.item),
146 |           )
147 |           .catch(() => {
148 |             shouldCache = false;
149 |             return [];
150 |           });
151 |       }
152 | 
153 |       if (shouldCache) {
154 |         this.resultCache!.set(pattern, filteredCandidates);
155 |       }
156 |     }
157 | 
158 |     const fileFilter = this.ignore.getFileFilter();
159 |     const results: string[] = [];
160 |     for (const [i, candidate] of filteredCandidates.entries()) {
161 |       if (i % 1000 === 0) {
162 |         await new Promise((resolve) => setImmediate(resolve));
163 |         if (options.signal?.aborted) {
164 |           throw new AbortError();
165 |         }
166 |       }
167 | 
168 |       if (results.length >= (options.maxResults ?? Infinity)) {
169 |         break;
170 |       }
171 |       if (candidate === '.') {
172 |         continue;
173 |       }
174 |       if (!fileFilter(candidate)) {
175 |         results.push(candidate);
176 |       }
177 |     }
178 |     return results;
179 |   }
180 | 
181 |   private buildResultCache(): void {
182 |     this.resultCache = new ResultCache(this.allFiles);
183 |     if (!this.options.disableFuzzySearch) {
184 |       // The v1 algorithm is much faster since it only looks at the first
185 |       // occurence of the pattern. We use it for search spaces that have >20k
186 |       // files, because the v2 algorithm is just too slow in those cases.
187 |       this.fzf = new AsyncFzf(this.allFiles, {
188 |         fuzzy: this.allFiles.length > 20000 ? 'v1' : 'v2',
189 |       });
190 |     }
191 |   }
192 | }
193 | 
194 | class DirectoryFileSearch implements FileSearch {
195 |   private ignore: Ignore | undefined;
196 | 
197 |   constructor(private readonly options: FileSearchOptions) {}
198 | 
199 |   async initialize(): Promise<void> {
200 |     this.ignore = loadIgnoreRules(this.options);
201 |   }
202 | 
203 |   async search(
204 |     pattern: string,
205 |     options: SearchOptions = {},
206 |   ): Promise<string[]> {
207 |     if (!this.ignore) {
208 |       throw new Error('Engine not initialized. Call initialize() first.');
209 |     }
210 |     pattern = pattern || '*';
211 | 
212 |     const dir = pattern.endsWith('/') ? pattern : path.dirname(pattern);
213 |     const results = await crawl({
214 |       crawlDirectory: path.join(this.options.projectRoot, dir),
215 |       cwd: this.options.projectRoot,
216 |       maxDepth: 0,
217 |       ignore: this.ignore,
218 |       cache: this.options.cache,
219 |       cacheTtl: this.options.cacheTtl,
220 |     });
221 | 
222 |     const filteredResults = await filter(results, pattern, options.signal);
223 | 
224 |     const fileFilter = this.ignore.getFileFilter();
225 |     const finalResults: string[] = [];
226 |     for (const candidate of filteredResults) {
227 |       if (finalResults.length >= (options.maxResults ?? Infinity)) {
228 |         break;
229 |       }
230 |       if (candidate === '.') {
231 |         continue;
232 |       }
233 |       if (!fileFilter(candidate)) {
234 |         finalResults.push(candidate);
235 |       }
236 |     }
237 |     return finalResults;
238 |   }
239 | }
240 | 
241 | export class FileSearchFactory {
242 |   static create(options: FileSearchOptions): FileSearch {
243 |     if (options.enableRecursiveFileSearch) {
244 |       return new RecursiveFileSearch(options);
245 |     }
246 |     return new DirectoryFileSearch(options);
247 |   }
248 | }
```

src/utils/filesearch/ignore.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { describe, it, expect, afterEach } from 'vitest';
8 | import { Ignore, loadIgnoreRules } from './ignore.js';
9 | import { createTmpDir, cleanupTmpDir } from '@google/gemini-cli-test-utils';
10 | 
11 | describe('Ignore', () => {
12 |   describe('getDirectoryFilter', () => {
13 |     it('should ignore directories matching directory patterns', () => {
14 |       const ig = new Ignore().add(['foo/', 'bar/']);
15 |       const dirFilter = ig.getDirectoryFilter();
16 |       expect(dirFilter('foo/')).toBe(true);
17 |       expect(dirFilter('bar/')).toBe(true);
18 |       expect(dirFilter('baz/')).toBe(false);
19 |     });
20 | 
21 |     it('should not ignore directories with file patterns', () => {
22 |       const ig = new Ignore().add(['foo.js', '*.log']);
23 |       const dirFilter = ig.getDirectoryFilter();
24 |       expect(dirFilter('foo.js')).toBe(false);
25 |       expect(dirFilter('foo.log')).toBe(false);
26 |     });
27 |   });
28 | 
29 |   describe('getFileFilter', () => {
30 |     it('should not ignore files with directory patterns', () => {
31 |       const ig = new Ignore().add(['foo/', 'bar/']);
32 |       const fileFilter = ig.getFileFilter();
33 |       expect(fileFilter('foo')).toBe(false);
34 |       expect(fileFilter('foo/file.txt')).toBe(false);
35 |     });
36 | 
37 |     it('should ignore files matching file patterns', () => {
38 |       const ig = new Ignore().add(['*.log', 'foo.js']);
39 |       const fileFilter = ig.getFileFilter();
40 |       expect(fileFilter('foo.log')).toBe(true);
41 |       expect(fileFilter('foo.js')).toBe(true);
42 |       expect(fileFilter('bar.txt')).toBe(false);
43 |     });
44 |   });
45 | 
46 |   it('should accumulate patterns across multiple add() calls', () => {
47 |     const ig = new Ignore().add('foo.js');
48 |     ig.add('bar.js');
49 |     const fileFilter = ig.getFileFilter();
50 |     expect(fileFilter('foo.js')).toBe(true);
51 |     expect(fileFilter('bar.js')).toBe(true);
52 |     expect(fileFilter('baz.js')).toBe(false);
53 |   });
54 | 
55 |   it('should return a stable and consistent fingerprint', () => {
56 |     const ig1 = new Ignore().add(['foo', '!bar']);
57 |     const ig2 = new Ignore().add('foo\n!bar');
58 | 
59 |     // Fingerprints should be identical for the same rules.
60 |     expect(ig1.getFingerprint()).toBe(ig2.getFingerprint());
61 | 
62 |     // Adding a new rule should change the fingerprint.
63 |     ig2.add('baz');
64 |     expect(ig1.getFingerprint()).not.toBe(ig2.getFingerprint());
65 |   });
66 | });
67 | 
68 | describe('loadIgnoreRules', () => {
69 |   let tmpDir: string;
70 | 
71 |   afterEach(async () => {
72 |     if (tmpDir) {
73 |       await cleanupTmpDir(tmpDir);
74 |     }
75 |   });
76 | 
77 |   it('should load rules from .gitignore', async () => {
78 |     tmpDir = await createTmpDir({
79 |       '.gitignore': '*.log',
80 |     });
81 |     const ignore = loadIgnoreRules({
82 |       projectRoot: tmpDir,
83 |       useGitignore: true,
84 |       useGeminiignore: false,
85 |       ignoreDirs: [],
86 |     });
87 |     const fileFilter = ignore.getFileFilter();
88 |     expect(fileFilter('test.log')).toBe(true);
89 |     expect(fileFilter('test.txt')).toBe(false);
90 |   });
91 | 
92 |   it('should load rules from .geminiignore', async () => {
93 |     tmpDir = await createTmpDir({
94 |       '.geminiignore': '*.log',
95 |     });
96 |     const ignore = loadIgnoreRules({
97 |       projectRoot: tmpDir,
98 |       useGitignore: false,
99 |       useGeminiignore: true,
100 |       ignoreDirs: [],
101 |     });
102 |     const fileFilter = ignore.getFileFilter();
103 |     expect(fileFilter('test.log')).toBe(true);
104 |     expect(fileFilter('test.txt')).toBe(false);
105 |   });
106 | 
107 |   it('should combine rules from .gitignore and .geminiignore', async () => {
108 |     tmpDir = await createTmpDir({
109 |       '.gitignore': '*.log',
110 |       '.geminiignore': '*.txt',
111 |     });
112 |     const ignore = loadIgnoreRules({
113 |       projectRoot: tmpDir,
114 |       useGitignore: true,
115 |       useGeminiignore: true,
116 |       ignoreDirs: [],
117 |     });
118 |     const fileFilter = ignore.getFileFilter();
119 |     expect(fileFilter('test.log')).toBe(true);
120 |     expect(fileFilter('test.txt')).toBe(true);
121 |     expect(fileFilter('test.md')).toBe(false);
122 |   });
123 | 
124 |   it('should add ignoreDirs', async () => {
125 |     tmpDir = await createTmpDir({});
126 |     const ignore = loadIgnoreRules({
127 |       projectRoot: tmpDir,
128 |       useGitignore: false,
129 |       useGeminiignore: false,
130 |       ignoreDirs: ['logs/'],
131 |     });
132 |     const dirFilter = ignore.getDirectoryFilter();
133 |     expect(dirFilter('logs/')).toBe(true);
134 |     expect(dirFilter('src/')).toBe(false);
135 |   });
136 | 
137 |   it('should handle missing ignore files gracefully', async () => {
138 |     tmpDir = await createTmpDir({});
139 |     const ignore = loadIgnoreRules({
140 |       projectRoot: tmpDir,
141 |       useGitignore: true,
142 |       useGeminiignore: true,
143 |       ignoreDirs: [],
144 |     });
145 |     const fileFilter = ignore.getFileFilter();
146 |     expect(fileFilter('anyfile.txt')).toBe(false);
147 |   });
148 | 
149 |   it('should always add .git to the ignore list', async () => {
150 |     tmpDir = await createTmpDir({});
151 |     const ignore = loadIgnoreRules({
152 |       projectRoot: tmpDir,
153 |       useGitignore: false,
154 |       useGeminiignore: false,
155 |       ignoreDirs: [],
156 |     });
157 |     const dirFilter = ignore.getDirectoryFilter();
158 |     expect(dirFilter('.git/')).toBe(true);
159 |   });
160 | });
```

src/utils/filesearch/ignore.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import fs from 'node:fs';
8 | import path from 'node:path';
9 | import ignore from 'ignore';
10 | import picomatch from 'picomatch';
11 | 
12 | const hasFileExtension = picomatch('**/*[*.]*');
13 | 
14 | export interface LoadIgnoreRulesOptions {
15 |   projectRoot: string;
16 |   useGitignore: boolean;
17 |   useGeminiignore: boolean;
18 |   ignoreDirs: string[];
19 | }
20 | 
21 | export function loadIgnoreRules(options: LoadIgnoreRulesOptions): Ignore {
22 |   const ignorer = new Ignore();
23 |   if (options.useGitignore) {
24 |     const gitignorePath = path.join(options.projectRoot, '.gitignore');
25 |     if (fs.existsSync(gitignorePath)) {
26 |       ignorer.add(fs.readFileSync(gitignorePath, 'utf8'));
27 |     }
28 |   }
29 | 
30 |   if (options.useGeminiignore) {
31 |     const geminiignorePath = path.join(options.projectRoot, '.geminiignore');
32 |     if (fs.existsSync(geminiignorePath)) {
33 |       ignorer.add(fs.readFileSync(geminiignorePath, 'utf8'));
34 |     }
35 |   }
36 | 
37 |   const ignoreDirs = ['.git', ...options.ignoreDirs];
38 |   ignorer.add(
39 |     ignoreDirs.map((dir) => {
40 |       if (dir.endsWith('/')) {
41 |         return dir;
42 |       }
43 |       return `${dir}/`;
44 |     }),
45 |   );
46 | 
47 |   return ignorer;
48 | }
49 | 
50 | export class Ignore {
51 |   private readonly allPatterns: string[] = [];
52 |   private dirIgnorer = ignore();
53 |   private fileIgnorer = ignore();
54 | 
55 |   /**
56 |    * Adds one or more ignore patterns.
57 |    * @param patterns A single pattern string or an array of pattern strings.
58 |    *                 Each pattern can be a glob-like string similar to .gitignore rules.
59 |    * @returns The `Ignore` instance for chaining.
60 |    */
61 |   add(patterns: string | string[]): this {
62 |     if (typeof patterns === 'string') {
63 |       patterns = patterns.split(/\r?\n/);
64 |     }
65 | 
66 |     for (const p of patterns) {
67 |       const pattern = p.trim();
68 | 
69 |       if (pattern === '' || pattern.startsWith('#')) {
70 |         continue;
71 |       }
72 | 
73 |       this.allPatterns.push(pattern);
74 | 
75 |       const isPositiveDirPattern =
76 |         pattern.endsWith('/') && !pattern.startsWith('!');
77 | 
78 |       if (isPositiveDirPattern) {
79 |         this.dirIgnorer.add(pattern);
80 |       } else {
81 |         // An ambiguous pattern (e.g., "build") could match a file or a
82 |         // directory. To optimize the file system crawl, we use a heuristic:
83 |         // patterns without a dot in the last segment are included in the
84 |         // directory exclusion check.
85 |         //
86 |         // This heuristic can fail. For example, an ignore pattern of "my.assets"
87 |         // intended to exclude a directory will not be treated as a directory
88 |         // pattern because it contains a ".". This results in crawling a
89 |         // directory that should have been excluded, reducing efficiency.
90 |         // Correctness is still maintained. The incorrectly crawled directory
91 |         // will be filtered out by the final ignore check.
92 |         //
93 |         // For maximum crawl efficiency, users should explicitly mark directory
94 |         // patterns with a trailing slash (e.g., "my.assets/").
95 |         this.fileIgnorer.add(pattern);
96 |         if (!hasFileExtension(pattern)) {
97 |           this.dirIgnorer.add(pattern);
98 |         }
99 |       }
100 |     }
101 | 
102 |     return this;
103 |   }
104 | 
105 |   /**
106 |    * Returns a predicate that matches explicit directory ignore patterns (patterns ending with '/').
107 |    * @returns {(dirPath: string) => boolean}
108 |    */
109 |   getDirectoryFilter(): (dirPath: string) => boolean {
110 |     return (dirPath: string) => this.dirIgnorer.ignores(dirPath);
111 |   }
112 | 
113 |   /**
114 |    * Returns a predicate that matches file ignore patterns (all patterns not ending with '/').
115 |    * Note: This may also match directories if a file pattern matches a directory name, but all explicit directory patterns are handled by getDirectoryFilter.
116 |    * @returns {(filePath: string) => boolean}
117 |    */
118 |   getFileFilter(): (filePath: string) => boolean {
119 |     return (filePath: string) => this.fileIgnorer.ignores(filePath);
120 |   }
121 | 
122 |   /**
123 |    * Returns a string representing the current set of ignore patterns.
124 |    * This can be used to generate a unique identifier for the ignore configuration,
125 |    * useful for caching purposes.
126 |    * @returns A string fingerprint of the ignore patterns.
127 |    */
128 |   getFingerprint(): string {
129 |     return this.allPatterns.join('\n');
130 |   }
131 | }
```

src/utils/filesearch/result-cache.test.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | import { test, expect } from 'vitest';
8 | import { ResultCache } from './result-cache.js';
9 | 
10 | test('ResultCache basic usage', async () => {
11 |   const files = [
12 |     'foo.txt',
13 |     'bar.js',
14 |     'baz.md',
15 |     'subdir/file.txt',
16 |     'subdir/other.js',
17 |     'subdir/nested/file.md',
18 |   ];
19 |   const cache = new ResultCache(files);
20 |   const { files: resultFiles, isExactMatch } = await cache.get('*.js');
21 |   expect(resultFiles).toEqual(files);
22 |   expect(isExactMatch).toBe(false);
23 | });
24 | 
25 | test('ResultCache cache hit/miss', async () => {
26 |   const files = ['foo.txt', 'bar.js', 'baz.md'];
27 |   const cache = new ResultCache(files);
28 |   // First call: miss
29 |   const { files: result1Files, isExactMatch: isExactMatch1 } =
30 |     await cache.get('*.js');
31 |   expect(result1Files).toEqual(files);
32 |   expect(isExactMatch1).toBe(false);
33 | 
34 |   // Simulate FileSearch applying the filter and setting the result
35 |   cache.set('*.js', ['bar.js']);
36 | 
37 |   // Second call: hit
38 |   const { files: result2Files, isExactMatch: isExactMatch2 } =
39 |     await cache.get('*.js');
40 |   expect(result2Files).toEqual(['bar.js']);
41 |   expect(isExactMatch2).toBe(true);
42 | });
43 | 
44 | test('ResultCache best base query', async () => {
45 |   const files = ['foo.txt', 'foobar.js', 'baz.md'];
46 |   const cache = new ResultCache(files);
47 | 
48 |   // Cache a broader query
49 |   cache.set('foo', ['foo.txt', 'foobar.js']);
50 | 
51 |   // Search for a more specific query that starts with the broader one
52 |   const { files: resultFiles, isExactMatch } = await cache.get('foobar');
53 |   expect(resultFiles).toEqual(['foo.txt', 'foobar.js']);
54 |   expect(isExactMatch).toBe(false);
55 | });
```

src/utils/filesearch/result-cache.ts
```
1 | /**
2 |  * @license
3 |  * Copyright 2025 Google LLC
4 |  * SPDX-License-Identifier: Apache-2.0
5 |  */
6 | 
7 | /**
8 |  * Implements an in-memory cache for file search results.
9 |  * This cache optimizes subsequent searches by leveraging previously computed results.
10 |  */
11 | export class ResultCache {
12 |   private readonly cache: Map<string, string[]>;
13 |   private hits = 0;
14 |   private misses = 0;
15 | 
16 |   constructor(private readonly allFiles: string[]) {
17 |     this.cache = new Map();
18 |   }
19 | 
20 |   /**
21 |    * Retrieves cached search results for a given query, or provides a base set
22 |    * of files to search from.
23 |    * @param query The search query pattern.
24 |    * @returns An object containing the files to search and a boolean indicating
25 |    *          if the result is an exact cache hit.
26 |    */
27 |   async get(
28 |     query: string,
29 |   ): Promise<{ files: string[]; isExactMatch: boolean }> {
30 |     const isCacheHit = this.cache.has(query);
31 | 
32 |     if (isCacheHit) {
33 |       this.hits++;
34 |       return { files: this.cache.get(query)!, isExactMatch: true };
35 |     }
36 | 
37 |     this.misses++;
38 | 
39 |     // This is the core optimization of the memory cache.
40 |     // If a user first searches for "foo", and then for "foobar",
41 |     // we don't need to search through all files again. We can start
42 |     // from the results of the "foo" search.
43 |     // This finds the most specific, already-cached query that is a prefix
44 |     // of the current query.
45 |     let bestBaseQuery = '';
46 |     for (const key of this.cache?.keys?.() ?? []) {
47 |       if (query.startsWith(key) && key.length > bestBaseQuery.length) {
48 |         bestBaseQuery = key;
49 |       }
50 |     }
51 | 
52 |     const filesToSearch = bestBaseQuery
53 |       ? this.cache.get(bestBaseQuery)!
54 |       : this.allFiles;
55 | 
56 |     return { files: filesToSearch, isExactMatch: false };
57 |   }
58 | 
59 |   /**
60 |    * Stores search results in the cache.
61 |    * @param query The search query pattern.
62 |    * @param results The matching file paths to cache.
63 |    */
64 |   set(query: string, results: string[]): void {
65 |     this.cache.set(query, results);
66 |   }
67 | }
```
