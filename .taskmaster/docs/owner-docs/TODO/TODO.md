# TODO

## TUI TO-DO'S

* (todo)TUI for easy prompt selection picker etc... and many other useful functions

  * -v | verbose: output config specs that model loaded with

  * Iterate on templates of choice that were previously generated for mass iteratation variations

* (todo)Option for users to inject /nothink for qwen3 models

* (todo)Add a percentage of progress during inferences so users can see how much longer is left on the job.

* (todo)Gather llm provider model options from their respective docs to further fine-tune the jobs by tweaking model parameters.

* (feature)Analyze and research bug fixes for errors (using web searching functionality from top rated sites docs etc...)

* (improved idea)Setup analysis signatures for codefetch files and increment inferences on each in by code fences, so file by file.

* (feature)Setup codex-5 bridge to use as provider i.e., have gpt-5-codex as an option for users similiar to how task-master-ai has the options for gpt-5-codex, gemini-cli, and others

* (todo) have checks for user workspace to detect if on WSL trying to call lm-studio on windows host, then prompts users with warning to enable toggle and configures BASE_URL to correct address. This can be optional, just in case users have custom workspaces where this might not be viable with a simple replacement of the ip address retrieved in a scan tool. y/n | if no , then do nothing else scan local ip and change base url accordingly.
